<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-11-12T09:03:29+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Financial Assertion of Aspect-Based Sentiment (md, Medium)</title><link href="/2023/11/11/finassertion_aspect_based_sentiment_md_en.html" rel="alternate" type="text/html" title="Financial Assertion of Aspect-Based Sentiment (md, Medium)" /><published>2023-11-11T00:00:00+00:00</published><updated>2023-11-11T00:00:00+00:00</updated><id>/2023/11/11/finassertion_aspect_based_sentiment_md_en</id><content type="html" xml:base="/2023/11/11/finassertion_aspect_based_sentiment_md_en.html">&lt;h2 id=&quot;description&quot;&gt;Description&lt;/h2&gt;

&lt;p&gt;This assertion model classifies financial entities into an aspect-based sentiment. It is designed to be used together with the associated NER model.&lt;/p&gt;

&lt;h2 id=&quot;predicted-entities&quot;&gt;Predicted Entities&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSITIVE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NEGATIVE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NEUTRAL&lt;/code&gt;&lt;/p&gt;

&lt;p class=&quot;btn-box&quot;&gt;&lt;button class=&quot;button button-orange&quot; disabled=&quot;&quot;&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled=&quot;&quot;&gt;Open in Colab&lt;/button&gt;
&lt;a href=&quot;https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finassertion_aspect_based_sentiment_md_en_1.0.0_3.0_1699705705778.zip&quot; class=&quot;button button-orange button-orange-trans arr button-icon hidden&quot;&gt;Download&lt;/a&gt;
&lt;a href=&quot;s3://auxdata.johnsnowlabs.com/finance/models/finassertion_aspect_based_sentiment_md_en_1.0.0_3.0_1699705705778.zip&quot; class=&quot;button button-orange button-orange-trans button-icon button-copy-s3&quot;&gt;Copy S3 URI&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-to-use&quot;&gt;How to use&lt;/h2&gt;

&lt;div class=&quot;tabs-box&quot;&gt;
  &lt;div class=&quot;tabs-model-aproach-head&quot;&gt;&lt;button class=&quot;tab-li-model-aproach tabheader_active&quot;&gt;Python&lt;/button&gt;&lt;button class=&quot;tab-li-model-aproach&quot;&gt;Scala&lt;/button&gt;&lt;button class=&quot;tab-li-model-aproach&quot;&gt;NLU&lt;/button&gt;&lt;/div&gt;
  &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;documentAssembler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DocumentAssembler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Sentence Detector annotator, processes various sentences per line
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentenceDetector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SentenceDetector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Tokenizer splits words in a relevant format for NLP
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;bert_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BertEmbeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bert_embeddings_sec_bert_base&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;embeddings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setMaxSentenceLength&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;finance_ner&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NerModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;finner_aspect_based_sentiment_md&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;finance/models&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;embeddings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ner_converter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NerConverterInternal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner_chunk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;assertion_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AssertionDLModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;finassertion_aspect_based_sentiment_md&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;finance/models&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ner_chunk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;embeddings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;assertion&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;nlpPipeline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;stages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;documentAssembler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sentenceDetector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;bert_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;finance_ner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ner_converter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;assertion_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Equity and earnings of affiliates in Latin America increased to $4.8 million in the quarter from $2.2 million in the prior year as the commodity markets in Latin America remain strong through the end of the quarter.&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;spark_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createDataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toDF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlpPipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark_df&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;explode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrays_zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner_chunk.result&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ner_chunk.metadata&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;assertion.result&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;assertion.metadata&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;\
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols['0']&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;entity&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols['1']['entity']&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;label&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols['2']&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;assertion&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols['3']['confidence']&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;confidence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/div&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+--------+---------+---------+----------+
|entity  |label    |assertion|confidence|
+--------+---------+---------+----------+
|Equity  |LIABILITY|POSITIVE |0.9895    |
|earnings|PROFIT   |POSITIVE |0.995     |
+--------+---------+---------+----------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 class=&quot;model-param&quot; id=&quot;model-information&quot;&gt;Model Information&lt;/h2&gt;

&lt;table class=&quot;table-model&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Model Name:&lt;/td&gt;
      &lt;td&gt;finassertion_aspect_based_sentiment_md&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Compatibility:&lt;/td&gt;
      &lt;td&gt;Finance NLP 1.0.0+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;License:&lt;/td&gt;
      &lt;td&gt;Licensed&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edition:&lt;/td&gt;
      &lt;td&gt;Official&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Input Labels:&lt;/td&gt;
      &lt;td&gt;[document, chunk, embeddings]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Output Labels:&lt;/td&gt;
      &lt;td&gt;[assertion]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Language:&lt;/td&gt;
      &lt;td&gt;en&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Size:&lt;/td&gt;
      &lt;td&gt;2.7 MB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;benchmarking&quot;&gt;Benchmarking&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; label         precision  recall  f1-score  support 
 NEGATIVE      0.68       0.43    0.53      232     
 NEUTRAL       0.44       0.65    0.53      441     
 POSITIVE      0.79       0.69    0.74      947     
 accuracy      -          -       0.64      1620    
 macro-avg     0.64       0.59    0.60      1620    
 weighted-avg  0.68       0.64    0.65      1620    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>John Snow Labs</name></author><category term="assertion" /><category term="licensed" /><category term="en" /><category term="finance" /><summary type="html">Description This assertion model classifies financial entities into an aspect-based sentiment. It is designed to be used together with the associated NER model. Predicted Entities POSITIVE, NEGATIVE, NEUTRAL Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) # Sentence Detector annotator, processes various sentences per line sentenceDetector = nlp.SentenceDetector()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) # Tokenizer splits words in a relevant format for NLP tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;)\ .setInputCols(&quot;sentence&quot;, &quot;token&quot;)\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512) finance_ner = finance.NerModel.pretrained(&quot;finner_aspect_based_sentiment_md&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = finance.NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) assertion_model = finance.AssertionDLModel.pretrained(&quot;finassertion_aspect_based_sentiment_md&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;assertion&quot;) nlpPipeline = nlp.Pipeline( stages=[documentAssembler, sentenceDetector, tokenizer, bert_embeddings, finance_ner, ner_converter, assertion_model]) text = &quot;Equity and earnings of affiliates in Latin America increased to $4.8 million in the quarter from $2.2 million in the prior year as the commodity markets in Latin America remain strong through the end of the quarter.&quot; spark_df = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) result = nlpPipeline.fit(spark_df ).transform(spark_df) result.select(F.explode(F.arrays_zip(&quot;ner_chunk.result&quot;, &quot;ner_chunk.metadata&quot;, &quot;assertion.result&quot;, &quot;assertion.metadata&quot;)).alias(&quot;cols&quot;))\ .select(F.expr(&quot;cols['0']&quot;).alias(&quot;entity&quot;), F.expr(&quot;cols['1']['entity']&quot;).alias(&quot;label&quot;), F.expr(&quot;cols['2']&quot;).alias(&quot;assertion&quot;), F.expr(&quot;cols['3']['confidence']&quot;).alias(&quot;confidence&quot;)).show(50, truncate=False) Results +--------+---------+---------+----------+ |entity |label |assertion|confidence| +--------+---------+---------+----------+ |Equity |LIABILITY|POSITIVE |0.9895 | |earnings|PROFIT |POSITIVE |0.995 | +--------+---------+---------+----------+ Model Information Model Name: finassertion_aspect_based_sentiment_md Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, chunk, embeddings] Output Labels: [assertion] Language: en Size: 2.7 MB Benchmarking label precision recall f1-score support NEGATIVE 0.68 0.43 0.53 232 NEUTRAL 0.44 0.65 0.53 441 POSITIVE 0.79 0.69 0.74 947 accuracy - - 0.64 1620 macro-avg 0.64 0.59 0.60 1620 weighted-avg 0.68 0.64 0.65 1620</summary></entry><entry><title type="html">Financial NER on Aspect-Based Sentiment Analysis</title><link href="/2023/11/11/finner_aspect_based_sentiment_md_en.html" rel="alternate" type="text/html" title="Financial NER on Aspect-Based Sentiment Analysis" /><published>2023-11-11T00:00:00+00:00</published><updated>2023-11-11T00:00:00+00:00</updated><id>/2023/11/11/finner_aspect_based_sentiment_md_en</id><content type="html" xml:base="/2023/11/11/finner_aspect_based_sentiment_md_en.html">&lt;h2 id=&quot;description&quot;&gt;Description&lt;/h2&gt;

&lt;p&gt;This NER model identifies entities that can be associated with a financial sentiment. The model is designed to be used with the associated Assertion Status model that classifies the entities into a sentiment category.&lt;/p&gt;

&lt;h2 id=&quot;predicted-entities&quot;&gt;Predicted Entities&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ASSET&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CASHFLOW&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPENSE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FREE_CASH_FLOW&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GAINS&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;KPI&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIABILITY&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LOSSES&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PROFIT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;REVENUE&lt;/code&gt;&lt;/p&gt;

&lt;p class=&quot;btn-box&quot;&gt;&lt;button class=&quot;button button-orange&quot; disabled=&quot;&quot;&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled=&quot;&quot;&gt;Open in Colab&lt;/button&gt;
&lt;a href=&quot;https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finner_aspect_based_sentiment_md_en_1.0.0_3.0_1699704469251.zip&quot; class=&quot;button button-orange button-orange-trans arr button-icon hidden&quot;&gt;Download&lt;/a&gt;
&lt;a href=&quot;s3://auxdata.johnsnowlabs.com/finance/models/finner_aspect_based_sentiment_md_en_1.0.0_3.0_1699704469251.zip&quot; class=&quot;button button-orange button-orange-trans button-icon button-copy-s3&quot;&gt;Copy S3 URI&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-to-use&quot;&gt;How to use&lt;/h2&gt;

&lt;div class=&quot;tabs-box&quot;&gt;
  &lt;div class=&quot;tabs-model-aproach-head&quot;&gt;&lt;button class=&quot;tab-li-model-aproach tabheader_active&quot;&gt;Python&lt;/button&gt;&lt;button class=&quot;tab-li-model-aproach&quot;&gt;Scala&lt;/button&gt;&lt;button class=&quot;tab-li-model-aproach&quot;&gt;NLU&lt;/button&gt;&lt;/div&gt;
  &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;documentAssembler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DocumentAssembler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Sentence Detector annotator, processes various sentences per line
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentenceDetector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SentenceDetector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Tokenizer splits words in a relevant format for NLP
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;bert_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BertEmbeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bert_embeddings_sec_bert_base&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;embeddings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setMaxSentenceLength&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;ner_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NerModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;finner_aspect_based_sentiment_md&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;finance/models&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;embeddings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ner_converter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NerConverter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner_chunk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;nlpPipeline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;documentAssembler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sentenceDetector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;bert_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ner_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ner_converter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;empty_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createDataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toDF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlpPipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Equity and earnings of affiliates in Latin America increased to $4.8 million in the quarter from $2.2 million in the prior year as the commodity markets in Latin America remain strong through the end of the quarter.&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createDataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toDF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyspark.sql&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;functions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;explode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrays_zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ner_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ner_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ner_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ner_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; \
               &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols['0']&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;chunk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols['1']&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;begin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols['2']&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;end&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cols['3']['entity']&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner_label&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/div&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+--------+-----+---+---------+
|chunk   |begin|end|ner_label|
+--------+-----+---+---------+
|Equity  |1    |6  |LIABILITY|
|earnings|12   |19 |PROFIT   |
+--------+-----+---+---------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 class=&quot;model-param&quot; id=&quot;model-information&quot;&gt;Model Information&lt;/h2&gt;

&lt;table class=&quot;table-model&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Model Name:&lt;/td&gt;
      &lt;td&gt;finner_aspect_based_sentiment_md&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Compatibility:&lt;/td&gt;
      &lt;td&gt;Finance NLP 1.0.0+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;License:&lt;/td&gt;
      &lt;td&gt;Licensed&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edition:&lt;/td&gt;
      &lt;td&gt;Official&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Input Labels:&lt;/td&gt;
      &lt;td&gt;[sentence, token, embeddings]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Output Labels:&lt;/td&gt;
      &lt;td&gt;[ner]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Language:&lt;/td&gt;
      &lt;td&gt;en&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Size:&lt;/td&gt;
      &lt;td&gt;16.5 MB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;benchmarking&quot;&gt;Benchmarking&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; label           precision  recall  f1-score  support 
 ASSET           0.50       0.72    0.59      53      
 CASHFLOW        0.78       0.60    0.68      30      
 EXPENSE         0.71       0.68    0.70      151     
 FREE_CASH_FLOW  1.00       1.00    1.00      19      
 GAINS           0.80       0.78    0.79      55      
 KPI             0.72       0.58    0.64      106     
 LIABILITY       0.65       0.51    0.57      39      
 LOSSES          0.77       0.59    0.67      29      
 PROFIT          0.77       0.74    0.75      101     
 REVENUE         0.74       0.78    0.76      231     
 micro-avg       0.72       0.71    0.71      814     
 macro-avg       0.74       0.70    0.71      814     
 weighted-avg    0.73       0.71    0.71      814  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>John Snow Labs</name></author><category term="ner" /><category term="licensed" /><category term="finance" /><category term="en" /><summary type="html">Description This NER model identifies entities that can be associated with a financial sentiment. The model is designed to be used with the associated Assertion Status model that classifies the entities into a sentiment category. Predicted Entities ASSET, CASHFLOW, EXPENSE, FREE_CASH_FLOW, GAINS, KPI, LIABILITY, LOSSES, PROFIT, REVENUE Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) # Sentence Detector annotator, processes various sentences per line sentenceDetector = nlp.SentenceDetector()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) # Tokenizer splits words in a relevant format for NLP tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;)\ .setInputCols(&quot;sentence&quot;, &quot;token&quot;)\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512) ner_model = finance.NerModel().pretrained(&quot;finner_aspect_based_sentiment_md&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, bert_embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;Equity and earnings of affiliates in Latin America increased to $4.8 million in the quarter from $2.2 million in the prior year as the commodity markets in Latin America remain strong through the end of the quarter.&quot;&quot;&quot;] result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) from pyspark.sql import functions as F result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.begin, result.ner_chunk.end, result.ner_chunk.metadata)).alias(&quot;cols&quot;)) \ .select(F.expr(&quot;cols['0']&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols['1']&quot;).alias(&quot;begin&quot;), F.expr(&quot;cols['2']&quot;).alias(&quot;end&quot;), F.expr(&quot;cols['3']['entity']&quot;).alias(&quot;ner_label&quot;) ).show(100, truncate=False) Results +--------+-----+---+---------+ |chunk |begin|end|ner_label| +--------+-----+---+---------+ |Equity |1 |6 |LIABILITY| |earnings|12 |19 |PROFIT | +--------+-----+---+---------+ Model Information Model Name: finner_aspect_based_sentiment_md Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 16.5 MB Benchmarking label precision recall f1-score support ASSET 0.50 0.72 0.59 53 CASHFLOW 0.78 0.60 0.68 30 EXPENSE 0.71 0.68 0.70 151 FREE_CASH_FLOW 1.00 1.00 1.00 19 GAINS 0.80 0.78 0.79 55 KPI 0.72 0.58 0.64 106 LIABILITY 0.65 0.51 0.57 39 LOSSES 0.77 0.59 0.67 29 PROFIT 0.77 0.74 0.75 101 REVENUE 0.74 0.78 0.76 231 micro-avg 0.72 0.71 0.71 814 macro-avg 0.74 0.70 0.71 814 weighted-avg 0.73 0.71 0.71 814</summary></entry><entry><title type="html">Finance E5 Embedding Large</title><link href="/2023/11/09/finembedding_e5_large_en.html" rel="alternate" type="text/html" title="Finance E5 Embedding Large" /><published>2023-11-09T00:00:00+00:00</published><updated>2023-11-09T00:00:00+00:00</updated><id>/2023/11/09/finembedding_e5_large_en</id><content type="html" xml:base="/2023/11/09/finembedding_e5_large_en.html">&lt;h2 id=&quot;description&quot;&gt;Description&lt;/h2&gt;

&lt;p&gt;This model is a financial version of the E5 large model fine-tuned on in-house curated financial datasets. Reference: Wang, Liang, et al. “Text embeddings by weakly-supervised contrastive pre-training.” arXiv preprint arXiv:2212.03533 (2022).&lt;/p&gt;

&lt;h2 id=&quot;predicted-entities&quot;&gt;Predicted Entities&lt;/h2&gt;

&lt;p class=&quot;btn-box&quot;&gt;&lt;button class=&quot;button button-orange&quot; disabled=&quot;&quot;&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled=&quot;&quot;&gt;Open in Colab&lt;/button&gt;
&lt;a href=&quot;https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finembedding_e5_large_en_1.0.0_3.0_1699530885080.zip&quot; class=&quot;button button-orange button-orange-trans arr button-icon hidden&quot;&gt;Download&lt;/a&gt;
&lt;a href=&quot;s3://auxdata.johnsnowlabs.com/finance/models/finembedding_e5_large_en_1.0.0_3.0_1699530885080.zip&quot; class=&quot;button button-orange button-orange-trans button-icon button-copy-s3&quot;&gt;Copy S3 URI&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-to-use&quot;&gt;How to use&lt;/h2&gt;

&lt;div class=&quot;tabs-box&quot;&gt;
  &lt;div class=&quot;tabs-model-aproach-head&quot;&gt;&lt;button class=&quot;tab-li-model-aproach tabheader_active&quot;&gt;Python&lt;/button&gt;&lt;button class=&quot;tab-li-model-aproach&quot;&gt;Scala&lt;/button&gt;&lt;button class=&quot;tab-li-model-aproach&quot;&gt;NLU&lt;/button&gt;&lt;/div&gt;
  &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;document_assembler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DocumentAssembler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;E5_embedding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E5Embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;finembedding_e5_large&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;finance/models&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;E5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pipeline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;document_assembler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E5_embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createDataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;What is the best way to invest in the stock market?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toDF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;E5.result&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/div&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+----------------------------------------------------------------------------------------------------+
|                                                                                          embeddings|
+----------------------------------------------------------------------------------------------------+
|[0.8358813, &lt;span class=&quot;nt&quot;&gt;-1&lt;/span&gt;.30341, &lt;span class=&quot;nt&quot;&gt;-0&lt;/span&gt;.576791, 0.25893408, 0.26888973, 0.028243342, 0.47971666, 0.47653574, 0.4...|
+----------------------------------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 class=&quot;model-param&quot; id=&quot;model-information&quot;&gt;Model Information&lt;/h2&gt;

&lt;table class=&quot;table-model&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Model Name:&lt;/td&gt;
      &lt;td&gt;finembedding_e5_large&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Compatibility:&lt;/td&gt;
      &lt;td&gt;Finance NLP 1.0.0+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;License:&lt;/td&gt;
      &lt;td&gt;Licensed&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edition:&lt;/td&gt;
      &lt;td&gt;Official&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Input Labels:&lt;/td&gt;
      &lt;td&gt;[document]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Output Labels:&lt;/td&gt;
      &lt;td&gt;[E5]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Language:&lt;/td&gt;
      &lt;td&gt;en&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Size:&lt;/td&gt;
      &lt;td&gt;1.2 GB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;In-house annotated financial datasets.&lt;/p&gt;</content><author><name>John Snow Labs</name></author><category term="finance" /><category term="en" /><category term="licensed" /><category term="e5" /><category term="sentence_embedding" /><category term="onnx" /><summary type="html">Description This model is a financial version of the E5 large model fine-tuned on in-house curated financial datasets. Reference: Wang, Liang, et al. “Text embeddings by weakly-supervised contrastive pre-training.” arXiv preprint arXiv:2212.03533 (2022). Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = ( nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) ) E5_embedding = ( nlp.E5Embeddings.pretrained( &quot;finembedding_e5_large&quot;, &quot;en&quot;, &quot;finance/models&quot; ) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;E5&quot;) ) pipeline = nlp.Pipeline(stages=[document_assembler, E5_embedding]) data = spark.createDataFrame( [[&quot;What is the best way to invest in the stock market?&quot;]] ).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result. Select(&quot;E5.result&quot;).show() Results +----------------------------------------------------------------------------------------------------+ | embeddings| +----------------------------------------------------------------------------------------------------+ |[0.8358813, -1.30341, -0.576791, 0.25893408, 0.26888973, 0.028243342, 0.47971666, 0.47653574, 0.4...| +----------------------------------------------------------------------------------------------------+ Model Information Model Name: finembedding_e5_large Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document] Output Labels: [E5] Language: en Size: 1.2 GB References In-house annotated financial datasets.</summary></entry><entry><title type="html">Detect Risk Factors (LangTest)</title><link href="/2023/11/06/ner_risk_factors_langtest_en.html" rel="alternate" type="text/html" title="Detect Risk Factors (LangTest)" /><published>2023-11-06T00:00:00+00:00</published><updated>2023-11-06T00:00:00+00:00</updated><id>/2023/11/06/ner_risk_factors_langtest_en</id><content type="html" xml:base="/2023/11/06/ner_risk_factors_langtest_en.html">## Description

Pretrained named entity recognition deep learning model for Heart Disease Risk Factors and Personal Health Information. It is the version of [ner_risk_factors](https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html) model augmented with `langtest` library.

| **test_type**        | **before fail_count** | **after fail_count** | **before pass_count** | **after pass_count** | **minimum pass_rate** | **before pass_rate** | **after pass_rate** |
|----------------------|-----------------------|----------------------|-----------------------|----------------------|-----------------------|----------------------|---------------------|
| **add_ocr_typo**     | 376                   | 255                  | 5287                  | 5408                 | 95%                   | 93%                  | 95%                 |
| **lowercase**        | 616                   | 403                  | 5957                  | 6170                 | 92%                   | 91%                  | 94%                 |
| **titlecase**        | 603                   | 360                  | 6083                  | 6326                 | 94%                   | 91%                  | 95%                 |
| **uppercase**        | 1054                  | 587                  | 5715                  | 6182                 | 90%                   | 84%                  | 91%                 |
| **weighted average** | **2649**              | **1605**             | **23042**             | **24086**            | **93%**               | **89.69%**           | **93.75%**          |

## Predicted Entities

`CAD`, `DIABETES`, `FAMILY_HIST`, `HYPERLIPIDEMIA`, `HYPERTENSION`, `MEDICATION`, `OBESE`, `PHI`, `SMOKER`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_risk_factors_langtest_en_5.1.1_3.0_1699259077185.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_risk_factors_langtest_en_5.1.1_3.0_1699259077185.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)
         
sentence_detector = SentenceDetector()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

clinical_ner = MedicalNerModel.pretrained(&quot;ner_risk_factors_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverter()\
 	.setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
 	.setOutputCol(&quot;ner_chunk&quot;)

nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter])

model = nlp_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))

result = model.transform(spark.createDataFrame([[&quot;&quot;&quot;PAST SURGICAL HISTORY: She has also had a hysterectomy, salpingoophorectomy, appendectomy, tonsillectomy, two carpal tunnel releases. She also has had a parathyroidectomy but still has had some borderline elevated calcium. Also, hypertension, hyperlipidemia, as well as diabetes. She also has osteoporosis.

SOCIAL HISTORY: The patient still smokes about a third of a pack a day, also drinks only occasional alcoholic drinks. The patient is married. She has three grown sons, all of which are very successful in professional positions. One son is a gastroenterologist in San Diego, California.

MEDICATIONS: Nifedipine-XR 90 mg daily, furosemide 20 mg half tablet b.i.d., lisinopril 20 mg daily, gemfibrozil 600 mg b.i.d., Synthroid 0.1 mg daily, Miacalcin one spray in alternate nostrils daily, Ogen 0.625 mg daily, Daypro 600 mg t.i.d., also Lortab 7.5 two or three a day, also Flexeril occasionally, also other vitamin.

ALLERGIES: She had some adverse reactions to penicillin, sulfa, perhaps contrast medium, and some mycins.&quot;&quot;&quot;]], [&quot;text&quot;]))
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)
         
val sentence_detector = new SentenceDetector()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner = MedicalNerModel.pretrained(&quot;ner_risk_factors_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverter()
 	.setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
 	.setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, ner, ner_converter))

val data = Seq(&quot;&quot;&quot;PAST SURGICAL HISTORY: She has also had a hysterectomy, salpingoophorectomy, appendectomy, tonsillectomy, two carpal tunnel releases. She also has had a parathyroidectomy but still has had some borderline elevated calcium. Also, hypertension, hyperlipidemia, as well as diabetes. She also has osteoporosis.

SOCIAL HISTORY: The patient still smokes about a third of a pack a day, also drinks only occasional alcoholic drinks. The patient is married. She has three grown sons, all of which are very successful in professional positions. One son is a gastroenterologist in San Diego, California.

MEDICATIONS: Nifedipine-XR 90 mg daily, furosemide 20 mg half tablet b.i.d., lisinopril 20 mg daily, gemfibrozil 600 mg b.i.d., Synthroid 0.1 mg daily, Miacalcin one spray in alternate nostrils daily, Ogen 0.625 mg daily, Daypro 600 mg t.i.d., also Lortab 7.5 two or three a day, also Flexeril occasionally, also other vitamin.

ALLERGIES: She had some adverse reactions to penicillin, sulfa, perhaps contrast medium, and some mycins.&quot;&quot;&quot;).toDS().toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+------------------------------------------+--------------+
|chunk                                     |ner_label     |
+------------------------------------------+--------------+
|hypertension                              |HYPERTENSION  |
|hyperlipidemia                            |HYPERLIPIDEMIA|
|diabetes                                  |DIABETES      |
|still smokes about a third of a pack a day|SMOKER        |
|San Diego                                 |PHI           |
|California                                |PHI           |
|lisinopril                                |MEDICATION    |
|gemfibrozil                               |MEDICATION    |
+------------------------------------------+--------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_risk_factors_langtest|
|Compatibility:|Healthcare NLP 5.1.1+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|14.7 MB|

## References

Trained on plain n2c2 2014: De-identification and Heart Disease Risk Factors Challenge datasets with `embeddings_clinical`. https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/

## Benchmarking

```bash
label             precision  recall  f1-score  support 
B-CAD             0.55       0.48    0.51      183     
B-DIABETES        0.74       0.80    0.77      246     
B-FAMILY_HIST     0.00       0.00    0.00      3       
B-HYPERLIPIDEMIA  0.85       0.89    0.87      95      
B-HYPERTENSION    0.73       0.81    0.77      233     
B-MEDICATION      0.84       0.85    0.84      894     
B-OBESE           0.69       0.82    0.75      49      
B-PHI             0.81       0.80    0.81      2106    
B-SMOKER          0.66       0.19    0.30      118     
I-CAD             0.38       0.36    0.37      476     
I-DIABETES        0.59       0.59    0.59      214     
I-FAMILY_HIST     0.83       0.29    0.43      17      
I-HYPERLIPIDEMIA  0.55       0.35    0.43      17      
I-HYPERTENSION    0.24       0.31    0.27      108     
I-MEDICATION      0.73       0.20    0.31      347     
I-OBESE           0.23       0.43    0.30      7       
I-PHI             0.79       0.72    0.75      618     
I-SMOKER          0.74       0.30    0.43      220     
micro-avg         0.73       0.67    0.70      5951    
macro-avg         0.61       0.51    0.53      5951    
weighted-avg      0.73       0.67    0.69      5951   
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="ner" /><category term="clinical" /><category term="licensed" /><category term="langtest" /><summary type="html">Description Pretrained named entity recognition deep learning model for Heart Disease Risk Factors and Personal Health Information. It is the version of ner_risk_factors model augmented with langtest library. test_type before fail_count after fail_count before pass_count after pass_count minimum pass_rate before pass_rate after pass_rate add_ocr_typo 376 255 5287 5408 95% 93% 95% lowercase 616 403 5957 6170 92% 91% 94% titlecase 603 360 6083 6326 94% 91% 95% uppercase 1054 587 5715 6182 90% 84% 91% weighted average 2649 1605 23042 24086 93% 89.69% 93.75% Predicted Entities CAD, DIABETES, FAMILY_HIST, HYPERLIPIDEMIA, HYPERTENSION, MEDICATION, OBESE, PHI, SMOKER Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetector()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_risk_factors_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter]) model = nlp_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) result = model.transform(spark.createDataFrame([[&quot;&quot;&quot;PAST SURGICAL HISTORY: She has also had a hysterectomy, salpingoophorectomy, appendectomy, tonsillectomy, two carpal tunnel releases. She also has had a parathyroidectomy but still has had some borderline elevated calcium. Also, hypertension, hyperlipidemia, as well as diabetes. She also has osteoporosis. SOCIAL HISTORY: The patient still smokes about a third of a pack a day, also drinks only occasional alcoholic drinks. The patient is married. She has three grown sons, all of which are very successful in professional positions. One son is a gastroenterologist in San Diego, California. MEDICATIONS: Nifedipine-XR 90 mg daily, furosemide 20 mg half tablet b.i.d., lisinopril 20 mg daily, gemfibrozil 600 mg b.i.d., Synthroid 0.1 mg daily, Miacalcin one spray in alternate nostrils daily, Ogen 0.625 mg daily, Daypro 600 mg t.i.d., also Lortab 7.5 two or three a day, also Flexeril occasionally, also other vitamin. ALLERGIES: She had some adverse reactions to penicillin, sulfa, perhaps contrast medium, and some mycins.&quot;&quot;&quot;]], [&quot;text&quot;])) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner = MedicalNerModel.pretrained(&quot;ner_risk_factors_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, ner, ner_converter)) val data = Seq(&quot;&quot;&quot;PAST SURGICAL HISTORY: She has also had a hysterectomy, salpingoophorectomy, appendectomy, tonsillectomy, two carpal tunnel releases. She also has had a parathyroidectomy but still has had some borderline elevated calcium. Also, hypertension, hyperlipidemia, as well as diabetes. She also has osteoporosis. SOCIAL HISTORY: The patient still smokes about a third of a pack a day, also drinks only occasional alcoholic drinks. The patient is married. She has three grown sons, all of which are very successful in professional positions. One son is a gastroenterologist in San Diego, California. MEDICATIONS: Nifedipine-XR 90 mg daily, furosemide 20 mg half tablet b.i.d., lisinopril 20 mg daily, gemfibrozil 600 mg b.i.d., Synthroid 0.1 mg daily, Miacalcin one spray in alternate nostrils daily, Ogen 0.625 mg daily, Daypro 600 mg t.i.d., also Lortab 7.5 two or three a day, also Flexeril occasionally, also other vitamin. ALLERGIES: She had some adverse reactions to penicillin, sulfa, perhaps contrast medium, and some mycins.&quot;&quot;&quot;).toDS().toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +------------------------------------------+--------------+ |chunk |ner_label | +------------------------------------------+--------------+ |hypertension |HYPERTENSION | |hyperlipidemia |HYPERLIPIDEMIA| |diabetes |DIABETES | |still smokes about a third of a pack a day|SMOKER | |San Diego |PHI | |California |PHI | |lisinopril |MEDICATION | |gemfibrozil |MEDICATION | +------------------------------------------+--------------+ Model Information Model Name: ner_risk_factors_langtest Compatibility: Healthcare NLP 5.1.1+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 14.7 MB References Trained on plain n2c2 2014: De-identification and Heart Disease Risk Factors Challenge datasets with embeddings_clinical. https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/ Benchmarking label precision recall f1-score support B-CAD 0.55 0.48 0.51 183 B-DIABETES 0.74 0.80 0.77 246 B-FAMILY_HIST 0.00 0.00 0.00 3 B-HYPERLIPIDEMIA 0.85 0.89 0.87 95 B-HYPERTENSION 0.73 0.81 0.77 233 B-MEDICATION 0.84 0.85 0.84 894 B-OBESE 0.69 0.82 0.75 49 B-PHI 0.81 0.80 0.81 2106 B-SMOKER 0.66 0.19 0.30 118 I-CAD 0.38 0.36 0.37 476 I-DIABETES 0.59 0.59 0.59 214 I-FAMILY_HIST 0.83 0.29 0.43 17 I-HYPERLIPIDEMIA 0.55 0.35 0.43 17 I-HYPERTENSION 0.24 0.31 0.27 108 I-MEDICATION 0.73 0.20 0.31 347 I-OBESE 0.23 0.43 0.30 7 I-PHI 0.79 0.72 0.75 618 I-SMOKER 0.74 0.30 0.43 220 micro-avg 0.73 0.67 0.70 5951 macro-avg 0.61 0.51 0.53 5951 weighted-avg 0.73 0.67 0.69 5951</summary></entry><entry><title type="html">Date of Brith Contextual Parser Model</title><link href="/2023/11/05/date_of_birth_parser_en.html" rel="alternate" type="text/html" title="Date of Brith Contextual Parser Model" /><published>2023-11-05T00:00:00+00:00</published><updated>2023-11-05T00:00:00+00:00</updated><id>/2023/11/05/date_of_birth_parser_en</id><content type="html" xml:base="/2023/11/05/date_of_birth_parser_en.html">## Description

This model is a `ContextualParserModel` that can extract date-of-birth (DOB) entities in clinical texts.

## Predicted Entities

`DOB`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/date_of_birth_parser_en_5.0.2_3.0_1699191960551.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/date_of_birth_parser_en_5.0.2_3.0_1699191960551.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python
document_assembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer() \
    .setInputCols([&quot;sentence&quot;]) \
    .setOutputCol(&quot;token&quot;)

dob_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_birth_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;chunk_dob&quot;) 

chunk_converter = ChunkConverter() \
    .setInputCols([&quot;chunk_dob&quot;]) \
    .setOutputCol(&quot;ner_chunk&quot;)

parserPipeline = Pipeline(stages=[
        document_assembler,
        sentence_detector,
        tokenizer,
        dob_contextual_parser,
    chunk_converter
        ])

model = parserPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))

sample_text = &quot;&quot;&quot;
Record date : 2081-01-04
DB : 11.04.1962
DT : 12-03-1978
DOD : 10.25.23

SOCIAL HISTORY:
She was born on Nov 04, 1962 in London and got married on 04/05/1979. When she got pregnant on 15 May 1079, the doctor wanted to verify her DOB was November 4, 1962. Her date of birth was confirmed to be 11-04-1962, the patient is 45 years old on 25 Sep 2007.

PROCEDURES:
Patient was evaluated on 1988-03-15 for allergies. She was seen by the endocrinology service and she was discharged on 9/23/1988.

MEDICATIONS
1. Coumadin 1 mg daily. Last INR was on August 14, 2007, and her INR was 2.3.&quot;&quot;&quot;

result = model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;))
```
```scala
val document_assembler = new DocumentAssembler() 
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer() 
    .setInputCols(&quot;sentence&quot;) 
    .setOutputCol(&quot;token&quot;)

val dob_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_birth_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) 
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) 
    .setOutputCol(&quot;chunk_dob&quot;) 

val chunk_converter = new ChunkConverter() 
    .setInputCols(Array(&quot;chunk_dob&quot;)) 
    .setOutputCol(&quot;ner_chunk&quot;)

val parserPipeline = new Pipeline().setStages(Array(
        document_assembler,
        sentence_detector,
        tokenizer,
        dob_contextual_parser,
        chunk_converter
        ))

val data = Seq(Array(&quot;&quot;&quot;
Record date : 2081-01-04 
DB : 11.04.1962
DT : 12-03-1978 
DOD : 10.25.23 

SOCIAL HISTORY:
She was born on Nov 04, 1962 in London and got married on 04/05/1979. When she got pregnant on 15 May 1079, the doctor wanted to verify her DOB was November 4, 1962. Her date of birth was confirmed to be 11-04-1962, the patient is 45 years old on 25 Sep 2007.

PROCEDURES:
Patient was evaluated on 1988-03-15 for allergies. She was seen by the endocrinology service and she was discharged on 9/23/1988. 

MEDICATIONS
1. Coumadin 1 mg daily. Last INR was on August 14, 2007, and her INR was 2.3.&quot;&quot;&quot;
)).toDS.toDF(&quot;text&quot;)

val result = parserPipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+-----------+----------------+-----+---+---------+
|sentence_id|chunk           |begin|end|ner_label|
+-----------+----------------+-----+---+---------+
|1          |11.04.1962      |31   |40 |DOB      |
|3          |Nov 04, 1962    |107  |118|DOB      |
|4          |November 4, 1962|239  |254|DOB      |
|5          |11-04-1962      |295  |304|DOB      |
+-----------+----------------+-----+---+---------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|date_of_birth_parser|
|Compatibility:|Healthcare NLP 5.0.2+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[chunk_dob]|
|Language:|en|
|Size:|4.9 KB|
|Case sensitive:|false|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="contextual_parser" /><category term="date_of_birth" /><category term="dob" /><category term="clinical" /><summary type="html">Description This model is a ContextualParserModel that can extract date-of-birth (DOB) entities in clinical texts. Predicted Entities DOB Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;sentence&quot;]) \ .setOutputCol(&quot;token&quot;) dob_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_birth_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;chunk_dob&quot;) chunk_converter = ChunkConverter() \ .setInputCols([&quot;chunk_dob&quot;]) \ .setOutputCol(&quot;ner_chunk&quot;) parserPipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, dob_contextual_parser, chunk_converter ]) model = parserPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) sample_text = &quot;&quot;&quot; Record date : 2081-01-04 DB : 11.04.1962 DT : 12-03-1978 DOD : 10.25.23 SOCIAL HISTORY: She was born on Nov 04, 1962 in London and got married on 04/05/1979. When she got pregnant on 15 May 1079, the doctor wanted to verify her DOB was November 4, 1962. Her date of birth was confirmed to be 11-04-1962, the patient is 45 years old on 25 Sep 2007. PROCEDURES: Patient was evaluated on 1988-03-15 for allergies. She was seen by the endocrinology service and she was discharged on 9/23/1988. MEDICATIONS 1. Coumadin 1 mg daily. Last INR was on August 14, 2007, and her INR was 2.3.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val dob_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_birth_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;chunk_dob&quot;) val chunk_converter = new ChunkConverter() .setInputCols(Array(&quot;chunk_dob&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val parserPipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, dob_contextual_parser, chunk_converter )) val data = Seq(Array(&quot;&quot;&quot; Record date : 2081-01-04 DB : 11.04.1962 DT : 12-03-1978 DOD : 10.25.23 SOCIAL HISTORY: She was born on Nov 04, 1962 in London and got married on 04/05/1979. When she got pregnant on 15 May 1079, the doctor wanted to verify her DOB was November 4, 1962. Her date of birth was confirmed to be 11-04-1962, the patient is 45 years old on 25 Sep 2007. PROCEDURES: Patient was evaluated on 1988-03-15 for allergies. She was seen by the endocrinology service and she was discharged on 9/23/1988. MEDICATIONS 1. Coumadin 1 mg daily. Last INR was on August 14, 2007, and her INR was 2.3.&quot;&quot;&quot; )).toDS.toDF(&quot;text&quot;) val result = parserPipeline.fit(data).transform(data) Results +-----------+----------------+-----+---+---------+ |sentence_id|chunk |begin|end|ner_label| +-----------+----------------+-----+---+---------+ |1 |11.04.1962 |31 |40 |DOB | |3 |Nov 04, 1962 |107 |118|DOB | |4 |November 4, 1962|239 |254|DOB | |5 |11-04-1962 |295 |304|DOB | +-----------+----------------+-----+---+---------+ Model Information Model Name: date_of_birth_parser Compatibility: Healthcare NLP 5.0.2+ License: Licensed Edition: Official Input Labels: [sentence, token] Output Labels: [chunk_dob] Language: en Size: 4.9 KB Case sensitive: false</summary></entry><entry><title type="html">Date of Death Contextual Parser Model</title><link href="/2023/11/05/date_of_death_parser_en.html" rel="alternate" type="text/html" title="Date of Death Contextual Parser Model" /><published>2023-11-05T00:00:00+00:00</published><updated>2023-11-05T00:00:00+00:00</updated><id>/2023/11/05/date_of_death_parser_en</id><content type="html" xml:base="/2023/11/05/date_of_death_parser_en.html">## Description

This model is a `ContextualParserModel` that can extract date-of-death (DOD) entities in clinical texts.

## Predicted Entities

`DOD`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/date_of_death_parser_en_5.1.2_3.0_1699192712408.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/date_of_death_parser_en_5.1.2_3.0_1699192712408.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python
document_assembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer() \
    .setInputCols([&quot;sentence&quot;]) \
    .setOutputCol(&quot;token&quot;)

dod_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_death_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;chunk_dod&quot;) 

chunk_converter = ChunkConverter() \
    .setInputCols([&quot;chunk_dod&quot;]) \
    .setOutputCol(&quot;ner_chunk&quot;)

parserPipeline = Pipeline(stages=[
        document_assembler,
        sentence_detector,
        tokenizer,
        dod_contextual_parser,
        chunk_converter
        ])

model = parserPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))

sample_text = &quot;&quot;&quot;
Record date : 2081-01-04
DB : 11.04.1962
DT : 12-03-1978
DOD : 10.25.23

SOCIAL HISTORY:
Jane Doe was born on November 4, 1962, in London, and she got married on April 5, 1979.
When she got pregnant on May 15, 1979, the doctor wanted to verify her date of birth, which was confirmed to be November 4, 1962.
Jane was 45 years old when she sadly passed away on September 25, 2007.

PROCEDURES:
Patient Jane Doe was evaluated on March 15, 1988, for allergies. She was seen by the endocrinology service and was discharged on September 23, 1988.

MEDICATIONS:
1. Coumadin 1 mg daily. Jane's last INR was measured on August 14, 2007, and it was 2.3.&quot;&quot;&quot;

result = model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;))

```
```scala
val document_assembler = new DocumentAssembler() 
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer() 
    .setInputCols(&quot;sentence&quot;) 
    .setOutputCol(&quot;token&quot;)

val dod_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_death_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) 
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) 
    .setOutputCol(&quot;chunk_dod&quot;) 

val chunk_converter = new ChunkConverter() 
    .setInputCols(Array(&quot;chunk_dod&quot;)) 
    .setOutputCol(&quot;ner_chunk&quot;)

val parserPipeline = new Pipeline().setStages(Array(
        document_assembler,
        sentence_detector,
        tokenizer,
        dod_contextual_parser,
        chunk_converter
        ))

val data = Seq(Array(&quot;&quot;&quot;
Record date : 2081-01-04
DB : 11.04.1962
DT : 12-03-1978
DOD : 10.25.23

SOCIAL HISTORY:
Jane Doe was born on November 4, 1962, in London, and she got married on April 5, 1979.
When she got pregnant on May 15, 1979, the doctor wanted to verify her date of birth, which was confirmed to be November 4, 1962.
Jane was 45 years old when she sadly passed away on September 25, 2007.

PROCEDURES:
Patient Jane Doe was evaluated on March 15, 1988, for allergies. She was seen by the endocrinology service and was discharged on September 23, 1988.

MEDICATIONS:
1. Coumadin 1 mg daily. Jane's last INR was measured on August 14, 2007, and it was 2.3.&quot;&quot;&quot;
)).toDS.toDF(&quot;text&quot;)

val result = parserPipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+-----------+------------------+-----+---+---------+
|sentence_id|chunk             |begin|end|ner_label|
+-----------+------------------+-----+---+---------+
|3          |10.25.23          |64   |71 |DOD      |
|5          |September 25, 2007|360  |377|DOD      |
+-----------+------------------+-----+---+---------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|date_of_death_parser|
|Compatibility:|Healthcare NLP 5.1.2+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[chunk_dod]|
|Language:|en|
|Size:|5.0 KB|
|Case sensitive:|false|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="clinical" /><category term="date_of_death" /><category term="contextual_parser" /><category term="dod" /><category term="licensed" /><summary type="html">Description This model is a ContextualParserModel that can extract date-of-death (DOD) entities in clinical texts. Predicted Entities DOD Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;sentence&quot;]) \ .setOutputCol(&quot;token&quot;) dod_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_death_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;chunk_dod&quot;) chunk_converter = ChunkConverter() \ .setInputCols([&quot;chunk_dod&quot;]) \ .setOutputCol(&quot;ner_chunk&quot;) parserPipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, dod_contextual_parser, chunk_converter ]) model = parserPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) sample_text = &quot;&quot;&quot; Record date : 2081-01-04 DB : 11.04.1962 DT : 12-03-1978 DOD : 10.25.23 SOCIAL HISTORY: Jane Doe was born on November 4, 1962, in London, and she got married on April 5, 1979. When she got pregnant on May 15, 1979, the doctor wanted to verify her date of birth, which was confirmed to be November 4, 1962. Jane was 45 years old when she sadly passed away on September 25, 2007. PROCEDURES: Patient Jane Doe was evaluated on March 15, 1988, for allergies. She was seen by the endocrinology service and was discharged on September 23, 1988. MEDICATIONS: 1. Coumadin 1 mg daily. Jane's last INR was measured on August 14, 2007, and it was 2.3.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val dod_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_death_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;chunk_dod&quot;) val chunk_converter = new ChunkConverter() .setInputCols(Array(&quot;chunk_dod&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val parserPipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, dod_contextual_parser, chunk_converter )) val data = Seq(Array(&quot;&quot;&quot; Record date : 2081-01-04 DB : 11.04.1962 DT : 12-03-1978 DOD : 10.25.23 SOCIAL HISTORY: Jane Doe was born on November 4, 1962, in London, and she got married on April 5, 1979. When she got pregnant on May 15, 1979, the doctor wanted to verify her date of birth, which was confirmed to be November 4, 1962. Jane was 45 years old when she sadly passed away on September 25, 2007. PROCEDURES: Patient Jane Doe was evaluated on March 15, 1988, for allergies. She was seen by the endocrinology service and was discharged on September 23, 1988. MEDICATIONS: 1. Coumadin 1 mg daily. Jane's last INR was measured on August 14, 2007, and it was 2.3.&quot;&quot;&quot; )).toDS.toDF(&quot;text&quot;) val result = parserPipeline.fit(data).transform(data) Results +-----------+------------------+-----+---+---------+ |sentence_id|chunk |begin|end|ner_label| +-----------+------------------+-----+---+---------+ |3 |10.25.23 |64 |71 |DOD | |5 |September 25, 2007|360 |377|DOD | +-----------+------------------+-----+---+---------+ Model Information Model Name: date_of_death_parser Compatibility: Healthcare NLP 5.1.2+ License: Licensed Edition: Official Input Labels: [sentence, token] Output Labels: [chunk_dod] Language: en Size: 5.0 KB Case sensitive: false</summary></entry><entry><title type="html">Social Determinants of Healthcare for Frailty Classifier</title><link href="/2023/11/05/bert_sequence_classifier_sdoh_frailty_en.html" rel="alternate" type="text/html" title="Social Determinants of Healthcare for Frailty Classifier" /><published>2023-11-05T00:00:00+00:00</published><updated>2023-11-05T00:00:00+00:00</updated><id>/2023/11/05/bert_sequence_classifier_sdoh_frailty_en</id><content type="html" xml:base="/2023/11/05/bert_sequence_classifier_sdoh_frailty_en.html">## Description

The Frailty classifier employs [BioBERT](https://arxiv.org/abs/1901.08746v2) within a robust classifier architecture. Trained on a diverse dataset, this model provides accurate label assignments and confidence scores for its predictions. The primary goal of this model is to categorize text into two key labels: 'High_or_Low_Frailty' and 'No_Frailty_or_Unknown.'

`High_or_Low_Frailty`: This category encompasses statements that indicate the presence of significant concerns or symptoms related to frailty conditions, suggesting either high or low risks. This label reflects substantial worries about frailty and the need for relevant medical measures.

`No_Frailty_or_Unknown`: This category includes statements that do not contain clear concerns related to frailty or where the frailty condition is unknown. This label indicates the absence of frailty-related issues or insufficient information in the text.

## Predicted Entities

`High_or_Low_Frailty`, `No_Frailty_or_Unknown`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/bert_sequence_classifier_sdoh_frailty_en_5.1.2_3.0_1699190332760.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/bert_sequence_classifier_sdoh_frailty_en_5.1.2_3.0_1699190332760.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler()\
    .setInputCol('text')\
    .setOutputCol('document')

tokenizer = Tokenizer()\
    .setInputCols(['document'])\
    .setOutputCol('token')

sequenceClassifier = MedicalBertForSequenceClassification.pretrained('bert_sequence_classifier_sdoh_frailty', 'en', 'clinical/models')\
    .setInputCols([&quot;document&quot;,'token'])\
    .setOutputCol(&quot;prediction&quot;)

pipeline = Pipeline(stages=[
    document_assembler,
    tokenizer,
    sequenceClassifier
])

sample_texts=[  &quot;Patient B is a 40-year-old female who was diagnosed with breast cancer. She has received a treatment plan that includes surgery, chemotherapy, and radiation therapy.&quot;,
                &quot;Post-chemotherapy, the patient was under regular surveillance for osteosarcoma. Recent imaging showed no signs of local recurrence or distant metastasis. Whereas the recovery was challenging, current evaluation confirms patient is in remission.&quot;,
                &quot;The patient was diagnosed with stage II colon cancer and will be undergoing a treatment regimen that includes both chemotherapy and radiation therapy.&quot;,
                &quot;Thyroid nodules detected during routine examination; fine-needle aspiration was conducted. Cytology results indicated no malignancy, consistent with a benign thyroid adenoma. However, patient is advised for a follow-up ultrasound in 12 months to monitor nodule size.&quot;,
                &quot;The patient's persistent lymphadenopathy led to further tests, which confirmed a diagnosis of AIDS.&quot;,
                &quot;Female patient presented with pelvic discomfort. Ovarian cysts were found during ultrasound; however, CA-125 levels are within normal range, and repeat imaging has shown consistent cyst size. No features of ovarian cancer were present, and a follow-up is scheduled in six months.&quot;
                ]

sample_data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(sample_data).transform(sample_data)

result.select(&quot;text&quot;, &quot;prediction.result&quot;).show(30,truncate=100)
```
```scala
val documenter = new DocumentAssembler() 
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_sdoh_frailty&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
    .setOutputCol(&quot;prediction&quot;)

val pipeline = new Pipeline().setStages(Array(documenter, tokenizer, sequenceClassifier))

val data = Seq(Array(&quot;Patient B is a 40-year-old female who was diagnosed with breast cancer. She has received a treatment plan that includes surgery, chemotherapy, and radiation therapy.&quot;,
                &quot;Post-chemotherapy, the patient was under regular surveillance for osteosarcoma. Recent imaging showed no signs of local recurrence or distant metastasis. Whereas the recovery was challenging, current evaluation confirms patient is in remission.&quot;,
                &quot;The patient was diagnosed with stage II colon cancer and will be undergoing a treatment regimen that includes both chemotherapy and radiation therapy.&quot;,
                &quot;Thyroid nodules detected during routine examination; fine-needle aspiration was conducted. Cytology results indicated no malignancy, consistent with a benign thyroid adenoma. However, patient is advised for a follow-up ultrasound in 12 months to monitor nodule size.&quot;,
                &quot;The patient's persistent lymphadenopathy led to further tests, which confirmed a diagnosis of AIDS.&quot;,
                &quot;Female patient presented with pelvic discomfort. Ovarian cysts were found during ultrasound; however, CA-125 levels are within normal range, and repeat imaging has shown consistent cyst size. No features of ovarian cancer were present, and a follow-up is scheduled in six months.&quot;
)).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+----------------------------------------------------------------------------------------------------+-----------------------+
|                                                                                                text|                 result|
+----------------------------------------------------------------------------------------------------+-----------------------+
|Patient B is a 40-year-old female who was diagnosed with breast cancer. She has received a treatm...|  [High_or_Low_Frailty]|
|Post-chemotherapy, the patient was under regular surveillance for osteosarcoma. Recent imaging sh...|[No_Frailty_or_Unknown]|
|The patient was diagnosed with stage II colon cancer and will be undergoing a treatment regimen t...|  [High_or_Low_Frailty]|
|Thyroid nodules detected during routine examination; fine-needle aspiration was conducted. Cytolo...|[No_Frailty_or_Unknown]|
| The patient's persistent lymphadenopathy led to further tests, which confirmed a diagnosis of AIDS.|  [High_or_Low_Frailty]|
|Female patient presented with pelvic discomfort. Ovarian cysts were found during ultrasound; howe...|[No_Frailty_or_Unknown]|
+----------------------------------------------------------------------------------------------------+-----------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_sequence_classifier_sdoh_frailty|
|Compatibility:|Healthcare NLP 5.1.2+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[prediction]|
|Language:|en|
|Size:|406.4 MB|
|Case sensitive:|true|
|Max sentence length:|512|

## Benchmarking

```bash
                label  precision    recall  f1-score   support
  High_or_Low_Frailty   0.898067  0.891798  0.894921       573
No_Frailty_or_Unknown   0.908148  0.913562  0.910847       671
             accuracy          -         -  0.903537      1244
            macro-avg   0.903107  0.902680  0.902884      1244
         weighted-avg   0.903505  0.903537  0.903511      1244
```</content><author><name>John Snow Labs</name></author><category term="licenced" /><category term="en" /><category term="sdoh" /><category term="clinical" /><category term="social_determinants_of_heathcare" /><category term="public_health" /><category term="frailty" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description The Frailty classifier employs BioBERT within a robust classifier architecture. Trained on a diverse dataset, this model provides accurate label assignments and confidence scores for its predictions. The primary goal of this model is to categorize text into two key labels: ‘High_or_Low_Frailty’ and ‘No_Frailty_or_Unknown.’ High_or_Low_Frailty: This category encompasses statements that indicate the presence of significant concerns or symptoms related to frailty conditions, suggesting either high or low risks. This label reflects substantial worries about frailty and the need for relevant medical measures. No_Frailty_or_Unknown: This category includes statements that do not contain clear concerns related to frailty or where the frailty condition is unknown. This label indicates the absence of frailty-related issues or insufficient information in the text. Predicted Entities High_or_Low_Frailty, No_Frailty_or_Unknown Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol('text')\ .setOutputCol('document') tokenizer = Tokenizer()\ .setInputCols(['document'])\ .setOutputCol('token') sequenceClassifier = MedicalBertForSequenceClassification.pretrained('bert_sequence_classifier_sdoh_frailty', 'en', 'clinical/models')\ .setInputCols([&quot;document&quot;,'token'])\ .setOutputCol(&quot;prediction&quot;) pipeline = Pipeline(stages=[ document_assembler, tokenizer, sequenceClassifier ]) sample_texts=[ &quot;Patient B is a 40-year-old female who was diagnosed with breast cancer. She has received a treatment plan that includes surgery, chemotherapy, and radiation therapy.&quot;, &quot;Post-chemotherapy, the patient was under regular surveillance for osteosarcoma. Recent imaging showed no signs of local recurrence or distant metastasis. Whereas the recovery was challenging, current evaluation confirms patient is in remission.&quot;, &quot;The patient was diagnosed with stage II colon cancer and will be undergoing a treatment regimen that includes both chemotherapy and radiation therapy.&quot;, &quot;Thyroid nodules detected during routine examination; fine-needle aspiration was conducted. Cytology results indicated no malignancy, consistent with a benign thyroid adenoma. However, patient is advised for a follow-up ultrasound in 12 months to monitor nodule size.&quot;, &quot;The patient's persistent lymphadenopathy led to further tests, which confirmed a diagnosis of AIDS.&quot;, &quot;Female patient presented with pelvic discomfort. Ovarian cysts were found during ultrasound; however, CA-125 levels are within normal range, and repeat imaging has shown consistent cyst size. No features of ovarian cancer were present, and a follow-up is scheduled in six months.&quot; ] sample_data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(sample_data).transform(sample_data) result.select(&quot;text&quot;, &quot;prediction.result&quot;).show(30,truncate=100) val documenter = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_sdoh_frailty&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;prediction&quot;) val pipeline = new Pipeline().setStages(Array(documenter, tokenizer, sequenceClassifier)) val data = Seq(Array(&quot;Patient B is a 40-year-old female who was diagnosed with breast cancer. She has received a treatment plan that includes surgery, chemotherapy, and radiation therapy.&quot;, &quot;Post-chemotherapy, the patient was under regular surveillance for osteosarcoma. Recent imaging showed no signs of local recurrence or distant metastasis. Whereas the recovery was challenging, current evaluation confirms patient is in remission.&quot;, &quot;The patient was diagnosed with stage II colon cancer and will be undergoing a treatment regimen that includes both chemotherapy and radiation therapy.&quot;, &quot;Thyroid nodules detected during routine examination; fine-needle aspiration was conducted. Cytology results indicated no malignancy, consistent with a benign thyroid adenoma. However, patient is advised for a follow-up ultrasound in 12 months to monitor nodule size.&quot;, &quot;The patient's persistent lymphadenopathy led to further tests, which confirmed a diagnosis of AIDS.&quot;, &quot;Female patient presented with pelvic discomfort. Ovarian cysts were found during ultrasound; however, CA-125 levels are within normal range, and repeat imaging has shown consistent cyst size. No features of ovarian cancer were present, and a follow-up is scheduled in six months.&quot; )).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +----------------------------------------------------------------------------------------------------+-----------------------+ | text| result| +----------------------------------------------------------------------------------------------------+-----------------------+ |Patient B is a 40-year-old female who was diagnosed with breast cancer. She has received a treatm...| [High_or_Low_Frailty]| |Post-chemotherapy, the patient was under regular surveillance for osteosarcoma. Recent imaging sh...|[No_Frailty_or_Unknown]| |The patient was diagnosed with stage II colon cancer and will be undergoing a treatment regimen t...| [High_or_Low_Frailty]| |Thyroid nodules detected during routine examination; fine-needle aspiration was conducted. Cytolo...|[No_Frailty_or_Unknown]| | The patient's persistent lymphadenopathy led to further tests, which confirmed a diagnosis of AIDS.| [High_or_Low_Frailty]| |Female patient presented with pelvic discomfort. Ovarian cysts were found during ultrasound; howe...|[No_Frailty_or_Unknown]| +----------------------------------------------------------------------------------------------------+-----------------------+ Model Information Model Name: bert_sequence_classifier_sdoh_frailty Compatibility: Healthcare NLP 5.1.2+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [prediction] Language: en Size: 406.4 MB Case sensitive: true Max sentence length: 512 Benchmarking label precision recall f1-score support High_or_Low_Frailty 0.898067 0.891798 0.894921 573 No_Frailty_or_Unknown 0.908148 0.913562 0.910847 671 accuracy - - 0.903537 1244 macro-avg 0.903107 0.902680 0.902884 1244 weighted-avg 0.903505 0.903537 0.903511 1244</summary></entry><entry><title type="html">Detect Genes and Human Phenotypes (LangTest)</title><link href="/2023/11/04/ner_human_phenotype_gene_clinical_langtest_en.html" rel="alternate" type="text/html" title="Detect Genes and Human Phenotypes (LangTest)" /><published>2023-11-04T00:00:00+00:00</published><updated>2023-11-04T00:00:00+00:00</updated><id>/2023/11/04/ner_human_phenotype_gene_clinical_langtest_en</id><content type="html" xml:base="/2023/11/04/ner_human_phenotype_gene_clinical_langtest_en.html">## Description

This model detects mentions of genes and human phenotypes (hp) in medical text. It is the version of [ner_human_phenotype_gene_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html) model augmented with `langtest` library.

| **test_type**        | **before fail_count** | **after fail_count** | **before pass_count** | **after pass_count** | **minimum pass_rate** | **before pass_rate** | **after pass_rate** |
|----------------------|-----------------------|----------------------|-----------------------|----------------------|-----------------------|----------------------|---------------------|
| **add_ocr_typo**     | 175                   | 120                  | 606                   | 661                  | 85%                   | 78%                  | 85%                 |
| **lowercase**        | 262                   | 110                  | 521                   | 673                  | 85%                   | 67%                  | 86%                 |
| **swap_entities**    | 123                   | 112                  | 600                   | 614                  | 80%                   | 83%                  | 85%                 |
| **titlecase**        | 704                   | 155                  | 79                    | 628                  | 75%                   | 10%                  | 80%                 |
| **uppercase**        | 709                   | 174                  | 74                    | 609                  | 75%                   | 9%                   | 78%                 |
| **weighted average** | **1973**              | **671**              | **1880**              | **3185**             | **80%**               | **48.79%**           | **82.60%**          |

## Predicted Entities

`GENE`, `HP`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_human_phenotype_gene_clinical_langtest_en_5.1.1_3.0_1699104573201.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_human_phenotype_gene_clinical_langtest_en_5.1.1_3.0_1699104573201.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)
     
sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

clinical_ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_gene_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverter()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)
    
nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter])

model = nlp_pipeline.fit(spark.createDataFrame([['']]).toDF(&quot;text&quot;))

result = model.transform(spark.createDataFrame([[&quot;We will systematically examine seven genes (CHN1, MDH1, PCP4, RTN1, SLC14A1, SNAP25 and VSNL1) that are altered in the three neurodegenerative diseases.&quot;]]).toDF(&quot;text&quot;))
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_gene_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverter()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, ner, ner_converter))

val data = Seq(&quot;&quot;&quot;We will systematically examine seven genes (CHN1, MDH1, PCP4, RTN1, SLC14A1, SNAP25 and VSNL1) that are altered in the three neurodegenerative diseases.&quot;&quot;&quot;).toDS().toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+--------------------------+---------+
|chunk                     |ner_label|
+--------------------------+---------+
|CHN1                      |GENE     |
|MDH1                      |GENE     |
|PCP4                      |GENE     |
|RTN1                      |GENE     |
|SLC14A1                   |GENE     |
|SNAP25                    |GENE     |
|VSNL1                     |GENE     |
|neurodegenerative diseases|HP       |
+--------------------------+---------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_human_phenotype_gene_clinical_langtest|
|Compatibility:|Healthcare NLP 5.1.1+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|14.7 MB|

## Benchmarking

```bash
label         precision  recall  f1-score  support 
GENE          0.85       0.89    0.87      1082    
HP            0.89       0.88    0.88      878     
micro-avg     0.87       0.88    0.87      1960    
macro-avg     0.87       0.88    0.87      1960    
weighted-avg  0.87       0.88    0.87      1960    
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="ner" /><category term="clinical" /><category term="licensed" /><category term="langtest" /><category term="human" /><category term="phenotype" /><category term="gene" /><summary type="html">Description This model detects mentions of genes and human phenotypes (hp) in medical text. It is the version of ner_human_phenotype_gene_clinical model augmented with langtest library. test_type before fail_count after fail_count before pass_count after pass_count minimum pass_rate before pass_rate after pass_rate add_ocr_typo 175 120 606 661 85% 78% 85% lowercase 262 110 521 673 85% 67% 86% swap_entities 123 112 600 614 80% 83% 85% titlecase 704 155 79 628 75% 10% 80% uppercase 709 174 74 609 75% 9% 78% weighted average 1973 671 1880 3185 80% 48.79% 82.60% Predicted Entities GENE, HP Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_gene_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter]) model = nlp_pipeline.fit(spark.createDataFrame([['']]).toDF(&quot;text&quot;)) result = model.transform(spark.createDataFrame([[&quot;We will systematically examine seven genes (CHN1, MDH1, PCP4, RTN1, SLC14A1, SNAP25 and VSNL1) that are altered in the three neurodegenerative diseases.&quot;]]).toDF(&quot;text&quot;)) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_gene_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, ner, ner_converter)) val data = Seq(&quot;&quot;&quot;We will systematically examine seven genes (CHN1, MDH1, PCP4, RTN1, SLC14A1, SNAP25 and VSNL1) that are altered in the three neurodegenerative diseases.&quot;&quot;&quot;).toDS().toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +--------------------------+---------+ |chunk |ner_label| +--------------------------+---------+ |CHN1 |GENE | |MDH1 |GENE | |PCP4 |GENE | |RTN1 |GENE | |SLC14A1 |GENE | |SNAP25 |GENE | |VSNL1 |GENE | |neurodegenerative diseases|HP | +--------------------------+---------+ Model Information Model Name: ner_human_phenotype_gene_clinical_langtest Compatibility: Healthcare NLP 5.1.1+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 14.7 MB Benchmarking label precision recall f1-score support GENE 0.85 0.89 0.87 1082 HP 0.89 0.88 0.88 878 micro-avg 0.87 0.88 0.87 1960 macro-avg 0.87 0.88 0.87 1960 weighted-avg 0.87 0.88 0.87 1960</summary></entry><entry><title type="html">Detect Normalized Genes and Human Phenotypes (LangTest)</title><link href="/2023/11/04/ner_human_phenotype_go_clinical_langtest_en.html" rel="alternate" type="text/html" title="Detect Normalized Genes and Human Phenotypes (LangTest)" /><published>2023-11-04T00:00:00+00:00</published><updated>2023-11-04T00:00:00+00:00</updated><id>/2023/11/04/ner_human_phenotype_go_clinical_langtest_en</id><content type="html" xml:base="/2023/11/04/ner_human_phenotype_go_clinical_langtest_en.html">## Description

This model can be used to detect normalized mentions of genes (go) and human phenotypes (hp) in medical text. It is the version of [ner_human_phenotype_go_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html) model augmented with `langtest` library.

| **test_type**        | **before fail_count** | **after fail_count** | **before pass_count** | **after pass_count** | **minimum pass_rate** | **before pass_rate** | **after pass_rate** |
|----------------------|-----------------------|----------------------|-----------------------|----------------------|-----------------------|----------------------|---------------------|
| **add_abbreviation** | 116                   | 53                   | 475                   | 538                  | 85%                   | 80%                  | 91%                 |
| **add_ocr_typo**     | 517                   | 93                   | 192                   | 616                  | 70%                   | 27%                  | 87%                 |
| **add_typo**         | 201                   | 92                   | 480                   | 594                  | 75%                   | 70%                  | 87%                 |
| **lowercase**        | 71                    | 44                   | 622                   | 649                  | 90%                   | 90%                  | 94%                 |
| **titlecase**        | 701                   | 123                  | 8                     | 586                  | 70%                   | 1%                   | 83%                 |
| **uppercase**        | 707                   | 186                  | 2                     | 523                  | 70%                   | 0%                   | 74%                 |
| **weighted average** | **2313**              | **591**              | **1779**              | **3506**             | **77%**               | **43.48%**           | **85.57%**          |

## Predicted Entities

`GO`, `HP`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_human_phenotype_go_clinical_langtest_en_5.1.1_3.0_1699113634845.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_human_phenotype_go_clinical_langtest_en_5.1.1_3.0_1699113634845.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
	
```python
document_assembler = DocumentAssembler()\
	.setInputCol(&quot;text&quot;)\
	.setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
	.setInputCols([&quot;document&quot;]) \
	.setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
	.setInputCols([&quot;sentence&quot;])\
	.setOutputCol(&quot;token&quot;)

word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
	.setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
	.setOutputCol(&quot;embeddings&quot;)

clinical_ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_go_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
	.setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \
	.setOutputCol(&quot;ner&quot;)

ner_converter = NerConverter() \
	.setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) \
	.setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[document_assembler,
                            sentence_detector,
                            tokenizer,
                            word_embeddings,
                            clinical_ner,
                            ner_converter])

data = spark.createDataFrame([[&quot;&quot;&quot;Another disease that shares two of the tumor components of CT, namely GIST and the tricarboxylic acid cycle is the Carney-Stratakis syndrome (CSS) or dyad.&quot;&quot;&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
	.setInputCol(&quot;text&quot;)
	.setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
	.setInputCols(&quot;document&quot;)
	.setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
	.setInputCols(&quot;sentence&quot;)
	.setOutputCol(&quot;token&quot;)

val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
	.setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
	.setOutputCol(&quot;embeddings&quot;)

val ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_go_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
	.setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
	.setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverter()
	.setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
	.setOutputCol(&quot;entities&quot;)

val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, ner, ner_converter))

val data = Seq(&quot;Another disease that shares two of the tumor components of CT, namely GIST and tricarboxylic acid cycle is the Carney-Stratakis syndrome (CSS) or dyad.&quot;).toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+------------------------+---------+
|chunk                   |ner_label|
+------------------------+---------+
|tumor                   |HP       |
|tricarboxylic acid cycle|GO       |
+------------------------+---------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_human_phenotype_go_clinical_langtest|
|Compatibility:|Healthcare NLP 5.1.1+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|14.6 MB|

## Benchmarking

```bash
label         precision  recall  f1-score  support 
GO            0.89       0.81    0.85      1363    
HP            0.84       0.85    0.85      762     
micro-avg     0.87       0.82    0.85      2125    
macro-avg     0.86       0.83    0.85      2125    
weighted-avg  0.87       0.82    0.85      2125    
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="ner" /><category term="clinical" /><category term="licensed" /><category term="langtest" /><category term="human" /><category term="phenotype" /><summary type="html">Description This model can be used to detect normalized mentions of genes (go) and human phenotypes (hp) in medical text. It is the version of ner_human_phenotype_go_clinical model augmented with langtest library. test_type before fail_count after fail_count before pass_count after pass_count minimum pass_rate before pass_rate after pass_rate add_abbreviation 116 53 475 538 85% 80% 91% add_ocr_typo 517 93 192 616 70% 27% 87% add_typo 201 92 480 594 75% 70% 87% lowercase 71 44 622 649 90% 90% 94% titlecase 701 123 8 586 70% 1% 83% uppercase 707 186 2 523 70% 0% 74% weighted average 2313 591 1779 3506 77% 43.48% 85.57% Predicted Entities GO, HP Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_go_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) \ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter]) data = spark.createDataFrame([[&quot;&quot;&quot;Another disease that shares two of the tumor components of CT, namely GIST and the tricarboxylic acid cycle is the Carney-Stratakis syndrome (CSS) or dyad.&quot;&quot;&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_go_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;entities&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, ner, ner_converter)) val data = Seq(&quot;Another disease that shares two of the tumor components of CT, namely GIST and tricarboxylic acid cycle is the Carney-Stratakis syndrome (CSS) or dyad.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +------------------------+---------+ |chunk |ner_label| +------------------------+---------+ |tumor |HP | |tricarboxylic acid cycle|GO | +------------------------+---------+ Model Information Model Name: ner_human_phenotype_go_clinical_langtest Compatibility: Healthcare NLP 5.1.1+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 14.6 MB Benchmarking label precision recall f1-score support GO 0.89 0.81 0.85 1363 HP 0.84 0.85 0.85 762 micro-avg 0.87 0.82 0.85 2125 macro-avg 0.86 0.83 0.85 2125 weighted-avg 0.87 0.82 0.85 2125</summary></entry><entry><title type="html">Detect Problems, Tests and Treatments (ner_clinical) in Hebrew</title><link href="/2023/10/23/ner_clinical_he.html" rel="alternate" type="text/html" title="Detect Problems, Tests and Treatments (ner_clinical) in Hebrew" /><published>2023-10-23T00:00:00+00:00</published><updated>2023-10-23T00:00:00+00:00</updated><id>/2023/10/23/ner_clinical_he</id><content type="html" xml:base="/2023/10/23/ner_clinical_he.html">## Description

Pretrained named entity recognition deep learning model for clinical terms in Hebrew. The SparkNLP deep learning model (MedicalNerModel) is inspired by a former state of the art model for NER: Chiu &amp; Nicols, Named Entity Recognition with Bidirectional LSTM-CNN.

## Predicted Entities

`PROBLEM`, `TEST`, `TREATMENT`

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/healthcare/NER_CLINICAL_MULTI/){:.button.button-orange}
[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_CLINICAL_MULTI.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_clinical_he_5.1.1_3.0_1698090197863.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_clinical_he_5.1.1_3.0_1698090197863.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

embeddings = BertEmbeddings.pretrained(&quot;alephbertgimmel_base_512&quot;,&quot;he&quot;) \
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;he&quot;, &quot;clinical/models&quot;) \
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    embeddings,
    ner_model,
    ner_converter   
    ])

sample_text = &quot;&quot;&quot;פה רגיל צוואר רגיל תרואיד תקין שדיים רגילים ללא גושים בולטים פטילות רגילות הפוכות [ב] , מתפשטות עם גירוי חזה רגיל LCTA COR תקין RRR בטן רגילה מעוברת רגליים רגילות עור רגיל צמיגים רגילים פרטים רגילים ללא גידולים פלפים רגילים ללא תסמין נמוך רגיל פרטים לבנים דקים כמות קטנה של פ 4.5 , קוה + אמין , NS + רמז , טריש - רגיל רחם רגיל 1/100/0 SROM ברור סגור נפשות רגילות ללא גידולים פלפים NT רגיל רחם רגיל גודל בשבועות תקין מעי רגיל ללא גידולים חיצוניים.&quot;&quot;&quot;


data = spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val embeddings = BertEmbeddings.pretrained(&quot;alephbertgimmel_base_512&quot;,&quot;he&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;he&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    embeddings,
    ner_model,
    ner_converter   
))

sample_data = Seq(&quot;&quot;&quot;פה רגיל צוואר רגיל תרואיד תקין שדיים רגילים ללא גושים בולטים פטילות רגילות הפוכות [ב] , מתפשטות עם גירוי חזה רגיל LCTA COR תקין RRR בטן רגילה מעוברת רגליים רגילות עור רגיל צמיגים רגילים פרטים רגילים ללא גידולים פלפים רגילים ללא תסמין נמוך רגיל פרטים לבנים דקים כמות קטנה של פ 4.5 , קוה + אמין , NS + רמז , טריש - רגיל רחם רגיל 1/100/0 SROM ברור סגור נפשות רגילות ללא גידולים פלפים NT רגיל רחם רגיל גודל בשבועות תקין מעי רגיל ללא גידולים חיצוניים.&quot;&quot;&quot;).toDS.toDF(&quot;text&quot;)


val result = pipeline.fit(sample_data).transform(sample_data)
```
&lt;/div&gt;

## Results

```bash
+--------------------------+-----------+
|chunk                     | ner_label |
+--------------------------+-----------+
| גושים בולטים               | PROBLEM   |
| הפוכות                    | PROBLEM   |
| מתפשטות עם גירוי חזה        | TREATMENT |
| כמות קטנה של פ            | TEST      |
| קוה                      | TEST      |
| NS                      | TEST      |
| טריש                     | TEST      |
| SROM                    | PROBLEM   |
+--------------------------+-----------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_clinical|
|Compatibility:|Healthcare NLP 5.1.1+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|he|
|Size:|3.4 MB|

## Benchmarking

```bash
       label  precision    recall  f1-score   support
     PROBLEM       0.80      0.78      0.79       607
   TREATMENT       0.80      0.64      0.71       280
        TEST       0.85      0.85      0.85       354
   micro-avg       0.81      0.77      0.79      1241
   macro-avg       0.82      0.75      0.78      1241
weighted-avg       0.81      0.77      0.79      1241
```</content><author><name>John Snow Labs</name></author><category term="ner" /><category term="clinical" /><category term="licensed" /><category term="he" /><summary type="html">Description Pretrained named entity recognition deep learning model for clinical terms in Hebrew. The SparkNLP deep learning model (MedicalNerModel) is inspired by a former state of the art model for NER: Chiu &amp;amp; Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. Predicted Entities PROBLEM, TEST, TREATMENT Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = BertEmbeddings.pretrained(&quot;alephbertgimmel_base_512&quot;,&quot;he&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;he&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter ]) sample_text = &quot;&quot;&quot;פה רגיל צוואר רגיל תרואיד תקין שדיים רגילים ללא גושים בולטים פטילות רגילות הפוכות [ב] , מתפשטות עם גירוי חזה רגיל LCTA COR תקין RRR בטן רגילה מעוברת רגליים רגילות עור רגיל צמיגים רגילים פרטים רגילים ללא גידולים פלפים רגילים ללא תסמין נמוך רגיל פרטים לבנים דקים כמות קטנה של פ 4.5 , קוה + אמין , NS + רמז , טריש - רגיל רחם רגיל 1/100/0 SROM ברור סגור נפשות רגילות ללא גידולים פלפים NT רגיל רחם רגיל גודל בשבועות תקין מעי רגיל ללא גידולים חיצוניים.&quot;&quot;&quot; data = spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained(&quot;alephbertgimmel_base_512&quot;,&quot;he&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;he&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter )) sample_data = Seq(&quot;&quot;&quot;פה רגיל צוואר רגיל תרואיד תקין שדיים רגילים ללא גושים בולטים פטילות רגילות הפוכות [ב] , מתפשטות עם גירוי חזה רגיל LCTA COR תקין RRR בטן רגילה מעוברת רגליים רגילות עור רגיל צמיגים רגילים פרטים רגילים ללא גידולים פלפים רגילים ללא תסמין נמוך רגיל פרטים לבנים דקים כמות קטנה של פ 4.5 , קוה + אמין , NS + רמז , טריש - רגיל רחם רגיל 1/100/0 SROM ברור סגור נפשות רגילות ללא גידולים פלפים NT רגיל רחם רגיל גודל בשבועות תקין מעי רגיל ללא גידולים חיצוניים.&quot;&quot;&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(sample_data).transform(sample_data) Results +--------------------------+-----------+ |chunk | ner_label | +--------------------------+-----------+ | גושים בולטים | PROBLEM | | הפוכות | PROBLEM | | מתפשטות עם גירוי חזה | TREATMENT | | כמות קטנה של פ | TEST | | קוה | TEST | | NS | TEST | | טריש | TEST | | SROM | PROBLEM | +--------------------------+-----------+ Model Information Model Name: ner_clinical Compatibility: Healthcare NLP 5.1.1+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: he Size: 3.4 MB Benchmarking label precision recall f1-score support PROBLEM 0.80 0.78 0.79 607 TREATMENT 0.80 0.64 0.71 280 TEST 0.85 0.85 0.85 354 micro-avg 0.81 0.77 0.79 1241 macro-avg 0.82 0.75 0.78 1241 weighted-avg 0.81 0.77 0.79 1241</summary></entry></feed>