<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-11-19T19:08:10+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Pretrained Pipeline for Reading Printed Text with Image Documents</title><link href="/2023/11/15/image_printed_transformer_extraction_en_3_2.html" rel="alternate" type="text/html" title="Pretrained Pipeline for Reading Printed Text with Image Documents" /><published>2023-11-15T00:00:00+00:00</published><updated>2023-11-15T00:00:00+00:00</updated><id>/2023/11/15/image_printed_transformer_extraction_en_3_2</id><content type="html" xml:base="/2023/11/15/image_printed_transformer_extraction_en_3_2.html">## Description

Pretrained pipeline designed to extract printed text from document images. It empowers accurate and efficient conversion of printed content into digital text, making it an invaluable tool for text recognition tasks.


## Predicted Entities

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/ocr/PP_IMAGE_PRINTED_TRANSFORMER_EXTRACTION/){:.button.button-orange.button-orange-trans.co.button-icon}
[Open in Colab](https://github.com/JohnSnowLabs/spark-ocr-workshop/blob/master/jupyter/Cards/SparkOcrPretrainedPipelinesImagePrintedTransformerExtraction.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/ocr/image_printed_transformer_extraction_en_5.0.2_3.0_1699469925000.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use

&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
img_pipeline = PretrainedPipeline('image_printed_transformer_extraction', 'en', 'clinical/ocr')

img_path = '/content/images/'
img_example_df = spark.read.format(&quot;binaryFile&quot;).load(img_path).cache()

result = img_pipeline.transform(img_example_df)
```
```scala
val img_pipeline = new PretrainedPipeline(&quot;image_printed_transformer_extraction&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;)

val img_path = &quot;/content/images/&quot;
val img_example_df = spark.read.format(&quot;binaryFile&quot;).load(img_path).cache()

val result = img_pipeline.transform(img_example_df)
```
&lt;/div&gt;

## Example

### Input
![Screenshot](/assets/images/examples_ocr/image2.png)

### Output
```bash
STARBUCKS Store #19208
11902 Euclid Avenue
Cleveland, OH (216) 229-U749

CHK 664250
12/07/2014 06:43 PM
112003. Drawers 2. Reg: 2

¥t Pep Mocha 4.5
Sbux Card 495
AMXARKERARANG 228
Subtotal $4.95
Total $4.95
Change Cue BO LOO
- Check Closed ~

&quot;49/07/2014 06:43 py

oBUX Card «3228 New Balance: 37.45
Card is registertd
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|image_printed_transformer_extraction|
|Type:|pipeline|
|Compatibility:|Visual NLP 5.0.2+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="printed" /><category term="ocr" /><summary type="html">Description Pretrained pipeline designed to extract printed text from document images. It empowers accurate and efficient conversion of printed content into digital text, making it an invaluable tool for text recognition tasks. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU img_pipeline = PretrainedPipeline('image_printed_transformer_extraction', 'en', 'clinical/ocr') img_path = '/content/images/' img_example_df = spark.read.format(&quot;binaryFile&quot;).load(img_path).cache() result = img_pipeline.transform(img_example_df) val img_pipeline = new PretrainedPipeline(&quot;image_printed_transformer_extraction&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) val img_path = &quot;/content/images/&quot; val img_example_df = spark.read.format(&quot;binaryFile&quot;).load(img_path).cache() val result = img_pipeline.transform(img_example_df) Example Input Output STARBUCKS Store #19208 11902 Euclid Avenue Cleveland, OH (216) 229-U749 CHK 664250 12/07/2014 06:43 PM 112003. Drawers 2. Reg: 2 ¥t Pep Mocha 4.5 Sbux Card 495 AMXARKERARANG 228 Subtotal $4.95 Total $4.95 Change Cue BO LOO - Check Closed ~ &quot;49/07/2014 06:43 py oBUX Card «3228 New Balance: 37.45 Card is registertd Model Information Model Name: image_printed_transformer_extraction Type: pipeline Compatibility: Visual NLP 5.0.2+ License: Licensed Edition: Official Language: en</summary></entry><entry><title type="html">Pretrained Pipeline for Reading and Removing Noise in Mixed Scanned and Digital PDF Documents</title><link href="/2023/11/15/mixed_scanned_digital_pdf_image_cleaner_en_3_2.html" rel="alternate" type="text/html" title="Pretrained Pipeline for Reading and Removing Noise in Mixed Scanned and Digital PDF Documents" /><published>2023-11-15T00:00:00+00:00</published><updated>2023-11-15T00:00:00+00:00</updated><id>/2023/11/15/mixed_scanned_digital_pdf_image_cleaner_en_3_2</id><content type="html" xml:base="/2023/11/15/mixed_scanned_digital_pdf_image_cleaner_en_3_2.html">## Description

Pretrained pipeline designed to remove noise in input printed documents, enhancing OCR readability for more accurate text extraction.

## Predicted Entities

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/ocr/PP_MIXED_SCANNED_DIGITAL_PDF_IMAGE_CLEANER/){:.button.button-orange.button-orange-trans.co.button-icon}
[Open in Colab](https://github.com/JohnSnowLabs/spark-ocr-workshop/blob/master/jupyter/Cards/SparkOcrPretrainedPipelinesMixedScannedDigitalPdfImageCleaner.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/ocr/mixed_scanned_digital_pdf_image_cleaner_en_4.3.4_3.0_1679597686000.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use

&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
pdf_pipeline = PretrainedPipeline('mixed_scanned_digital_pdf_image_cleaner', 'en', 'clinical/ocr')

pdf_path = '/content/pdfs/'
pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache()

result = pdf_pipeline.transform(pdf_example_df)
```
```scala
val pdf_pipeline = new PretrainedPipeline(&quot;mixed_scanned_digital_pdf_image_cleaner&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;)

val pdf_path = &quot;/content/pdfs/&quot;
val pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache()

val result = pdf_pipeline.transform(pdf_example_df)
```
&lt;/div&gt;


## Example

### Input
![Screenshot](/assets/images/examples_ocr/image4.png)

### Output
![Screenshot](/assets/images/examples_ocr/image4_out.png)
```bash
Sample specifications written by
 , BLEND CASING RECASING

- OLD GOLD STRAIGHT Tobacco Blend

Control for Sample No. 5030

Cigarettes:

OLD GOLD STRAIGHT

 

John H. M. Bohlken

FINAL FLAVOR MENTHOL FLAVOR

Tars and Nicotine, Taste Panel, Burning Time, Gas Phase Analysis,
Benzo (A) Pyrene Analyses — T/C -CF~ O.C S51: Fee -

Written by -- John H. M. Bohlken
Original to -Mr. C. L. Tucker, dr.
Copies to ---Dr. A. W. Spears

C

~
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|mixed_scanned_digital_pdf_image_cleaner|
|Type:|pipeline|
|Compatibility:|Visual NLP 5.0.2+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="cleaner" /><category term="ocr" /><summary type="html">Description Pretrained pipeline designed to remove noise in input printed documents, enhancing OCR readability for more accurate text extraction. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU pdf_pipeline = PretrainedPipeline('mixed_scanned_digital_pdf_image_cleaner', 'en', 'clinical/ocr') pdf_path = '/content/pdfs/' pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache() result = pdf_pipeline.transform(pdf_example_df) val pdf_pipeline = new PretrainedPipeline(&quot;mixed_scanned_digital_pdf_image_cleaner&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) val pdf_path = &quot;/content/pdfs/&quot; val pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache() val result = pdf_pipeline.transform(pdf_example_df) Example Input Output Sample specifications written by , BLEND CASING RECASING - OLD GOLD STRAIGHT Tobacco Blend Control for Sample No. 5030 Cigarettes: OLD GOLD STRAIGHT John H. M. Bohlken FINAL FLAVOR MENTHOL FLAVOR Tars and Nicotine, Taste Panel, Burning Time, Gas Phase Analysis, Benzo (A) Pyrene Analyses — T/C -CF~ O.C S51: Fee - Written by -- John H. M. Bohlken Original to -Mr. C. L. Tucker, dr. Copies to ---Dr. A. W. Spears C ~ Model Information Model Name: mixed_scanned_digital_pdf_image_cleaner Type: pipeline Compatibility: Visual NLP 5.0.2+ License: Licensed Edition: Official Language: en</summary></entry><entry><title type="html">Pretrained Pipeline for Reading Handwritten Text with PDF Documents</title><link href="/2023/11/15/pdf_handwritten_transformer_extraction_en_3_2.html" rel="alternate" type="text/html" title="Pretrained Pipeline for Reading Handwritten Text with PDF Documents" /><published>2023-11-15T00:00:00+00:00</published><updated>2023-11-15T00:00:00+00:00</updated><id>/2023/11/15/pdf_handwritten_transformer_extraction_en_3_2</id><content type="html" xml:base="/2023/11/15/pdf_handwritten_transformer_extraction_en_3_2.html">## Description

Pretrained pipeline designed to extract handwritten text from document PDFs. It empowers accurate and efficient conversion of handwritten content into digital text, making it an invaluable tool for text recognition tasks.


## Predicted Entities

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/ocr/PP_PDF_HANDWRITTEN_TRANSFORMER_EXTRACTION/){:.button.button-orange.button-orange-trans.co.button-icon}
[Open in Colab](https://github.com/JohnSnowLabs/spark-ocr-workshop/blob/master/jupyter/Cards/SparkOcrPretrainedPipelinesPdfHandwrittenTransformerExtraction.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/ocr/pdf_handwritten_transformer_extraction_en_5.0.2_3.0_1699469925000.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use

&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
pdf_pipeline = PretrainedPipeline('pdf_handwritten_transformer_extraction', 'en', 'clinical/ocr')

pdf_path = '/content/pdfs/'
pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache()

result = pdf_pipeline.transform(pdf_example_df)
```
```scala
val pdf_pipeline = new PretrainedPipeline(&quot;pdf_handwritten_transformer_extraction&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;)

val pdf_path = &quot;/content/pdfs/&quot;
val pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache()

val result = pdf_pipeline.transform(pdf_example_df)
```
&lt;/div&gt;

## Example

### Input
![Screenshot](/assets/images/examples_ocr/image3_1.jpg)

### Output
```bash
&quot;This is an example of handwritten
text .
Let's # check the performance !
I hope it will be awesome .&quot;
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|pdf_handwritten_transformer_extraction|
|Type:|pipeline|
|Compatibility:|Visual NLP 5.0.2+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="handwritten" /><category term="pdf" /><category term="ocr" /><summary type="html">Description Pretrained pipeline designed to extract handwritten text from document PDFs. It empowers accurate and efficient conversion of handwritten content into digital text, making it an invaluable tool for text recognition tasks. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU pdf_pipeline = PretrainedPipeline('pdf_handwritten_transformer_extraction', 'en', 'clinical/ocr') pdf_path = '/content/pdfs/' pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache() result = pdf_pipeline.transform(pdf_example_df) val pdf_pipeline = new PretrainedPipeline(&quot;pdf_handwritten_transformer_extraction&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) val pdf_path = &quot;/content/pdfs/&quot; val pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache() val result = pdf_pipeline.transform(pdf_example_df) Example Input Output &quot;This is an example of handwritten text . Let's # check the performance ! I hope it will be awesome .&quot; Model Information Model Name: pdf_handwritten_transformer_extraction Type: pipeline Compatibility: Visual NLP 5.0.2+ License: Licensed Edition: Official Language: en</summary></entry><entry><title type="html">Pretrained Pipeline for Reading Printed Text with PDF Documents</title><link href="/2023/11/15/pdf_printed_transformer_extraction_en_3_2.html" rel="alternate" type="text/html" title="Pretrained Pipeline for Reading Printed Text with PDF Documents" /><published>2023-11-15T00:00:00+00:00</published><updated>2023-11-15T00:00:00+00:00</updated><id>/2023/11/15/pdf_printed_transformer_extraction_en_3_2</id><content type="html" xml:base="/2023/11/15/pdf_printed_transformer_extraction_en_3_2.html">## Description

Pretrained pipeline designed to extract printed text from document PDFs. It empowers accurate and efficient conversion of printed content into digital text, making it an invaluable tool for text recognition tasks.


## Predicted Entities

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/ocr/PP_PDF_PRINTED_TRANSFORMER_EXTRACTION/){:.button.button-orange.button-orange-trans.co.button-icon}
[Open in Colab](https://github.com/JohnSnowLabs/spark-ocr-workshop/blob/master/jupyter/Cards/SparkOcrPretrainedPipelinesPdfPrintedTransformerExtraction.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/ocr/pdf_printed_transformer_extraction_en_5.0.2_3.0_1699469925000.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use

&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
pdf_pipeline = PretrainedPipeline('pdf_printed_transformer_extraction', 'en', 'clinical/ocr')

pdf_path = '/content/pdfs/'
pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache()

result = pdf_pipeline.transform(pdf_example_df)
```
```scala
val pdf_pipeline = new PretrainedPipeline(&quot;pdf_printed_transformer_extraction&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;)

val pdf_path = &quot;/content/pdfs/&quot;
val pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache()

val result = pdf_pipeline.transform(pdf_example_df)
```
&lt;/div&gt;

## Example

### Input
![Screenshot](/assets/images/examples_ocr/image2.png)

### Output
```bash
STARBUCKS Store #19208
11902 Euclid Avenue
Cleveland, OH (216) 229-U749

CHK 664250
12/07/2014 06:43 PM
112003. Drawers 2. Reg: 2

¥t Pep Mocha 4.5
Sbux Card 495
AMXARKERARANG 228
Subtotal $4.95
Total $4.95
Change Cue BO LOO
- Check Closed ~

&quot;49/07/2014 06:43 py

oBUX Card «3228 New Balance: 37.45
Card is registertd
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|pdf_printed_transformer_extraction|
|Type:|pipeline|
|Compatibility:|Visual NLP 5.0.2+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="printed" /><category term="pdf" /><category term="ocr" /><summary type="html">Description Pretrained pipeline designed to extract printed text from document PDFs. It empowers accurate and efficient conversion of printed content into digital text, making it an invaluable tool for text recognition tasks. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU pdf_pipeline = PretrainedPipeline('pdf_printed_transformer_extraction', 'en', 'clinical/ocr') pdf_path = '/content/pdfs/' pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache() result = pdf_pipeline.transform(pdf_example_df) val pdf_pipeline = new PretrainedPipeline(&quot;pdf_printed_transformer_extraction&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) val pdf_path = &quot;/content/pdfs/&quot; val pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache() val result = pdf_pipeline.transform(pdf_example_df) Example Input Output STARBUCKS Store #19208 11902 Euclid Avenue Cleveland, OH (216) 229-U749 CHK 664250 12/07/2014 06:43 PM 112003. Drawers 2. Reg: 2 ¥t Pep Mocha 4.5 Sbux Card 495 AMXARKERARANG 228 Subtotal $4.95 Total $4.95 Change Cue BO LOO - Check Closed ~ &quot;49/07/2014 06:43 py oBUX Card «3228 New Balance: 37.45 Card is registertd Model Information Model Name: pdf_printed_transformer_extraction Type: pipeline Compatibility: Visual NLP 5.0.2+ License: Licensed Edition: Official Language: en</summary></entry><entry><title type="html">Financial Assertion of Aspect-Based Sentiment (md, Medium)</title><link href="/2023/11/11/finassertion_aspect_based_sentiment_md_en.html" rel="alternate" type="text/html" title="Financial Assertion of Aspect-Based Sentiment (md, Medium)" /><published>2023-11-11T00:00:00+00:00</published><updated>2023-11-11T00:00:00+00:00</updated><id>/2023/11/11/finassertion_aspect_based_sentiment_md_en</id><content type="html" xml:base="/2023/11/11/finassertion_aspect_based_sentiment_md_en.html">## Description

This assertion model classifies financial entities into an aspect-based sentiment. It is designed to be used together with the associated NER model.

## Predicted Entities

`POSITIVE`, `NEGATIVE`, `NEUTRAL`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finassertion_aspect_based_sentiment_md_en_1.0.0_3.0_1699705705778.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finassertion_aspect_based_sentiment_md_en_1.0.0_3.0_1699705705778.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

# Sentence Detector annotator, processes various sentences per line
sentenceDetector = nlp.SentenceDetector()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

# Tokenizer splits words in a relevant format for NLP
tokenizer = nlp.Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;)\
    .setInputCols(&quot;sentence&quot;, &quot;token&quot;)\
    .setOutputCol(&quot;embeddings&quot;)\
    .setMaxSentenceLength(512)

finance_ner = finance.NerModel.pretrained(&quot;finner_aspect_based_sentiment_md&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = finance.NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

assertion_model = finance.AssertionDLModel.pretrained(&quot;finassertion_aspect_based_sentiment_md&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;assertion&quot;)


nlpPipeline = nlp.Pipeline(
    stages=[documentAssembler,
            sentenceDetector,
            tokenizer,
            bert_embeddings,
            finance_ner,
            ner_converter,
            assertion_model])

text = &quot;Equity and earnings of affiliates in Latin America increased to $4.8 million in the quarter from $2.2 million in the prior year as the commodity markets in Latin America remain strong through the end of the quarter.&quot;

spark_df = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)

result = nlpPipeline.fit(spark_df ).transform(spark_df)

result.select(F.explode(F.arrays_zip(&quot;ner_chunk.result&quot;, &quot;ner_chunk.metadata&quot;, &quot;assertion.result&quot;, &quot;assertion.metadata&quot;)).alias(&quot;cols&quot;))\
      .select(F.expr(&quot;cols['0']&quot;).alias(&quot;entity&quot;),
              F.expr(&quot;cols['1']['entity']&quot;).alias(&quot;label&quot;),
              F.expr(&quot;cols['2']&quot;).alias(&quot;assertion&quot;),
              F.expr(&quot;cols['3']['confidence']&quot;).alias(&quot;confidence&quot;)).show(50, truncate=False)
```

&lt;/div&gt;

## Results

```bash
+--------+---------+---------+----------+
|entity  |label    |assertion|confidence|
+--------+---------+---------+----------+
|Equity  |LIABILITY|POSITIVE |0.9895    |
|earnings|PROFIT   |POSITIVE |0.995     |
+--------+---------+---------+----------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finassertion_aspect_based_sentiment_md|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, chunk, embeddings]|
|Output Labels:|[assertion]|
|Language:|en|
|Size:|2.7 MB|

## Benchmarking

```bash
 label         precision  recall  f1-score  support 
 NEGATIVE      0.68       0.43    0.53      232     
 NEUTRAL       0.44       0.65    0.53      441     
 POSITIVE      0.79       0.69    0.74      947     
 accuracy      -          -       0.64      1620    
 macro-avg     0.64       0.59    0.60      1620    
 weighted-avg  0.68       0.64    0.65      1620    
```</content><author><name>John Snow Labs</name></author><category term="assertion" /><category term="licensed" /><category term="en" /><category term="finance" /><summary type="html">Description This assertion model classifies financial entities into an aspect-based sentiment. It is designed to be used together with the associated NER model. Predicted Entities POSITIVE, NEGATIVE, NEUTRAL Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) # Sentence Detector annotator, processes various sentences per line sentenceDetector = nlp.SentenceDetector()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) # Tokenizer splits words in a relevant format for NLP tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;)\ .setInputCols(&quot;sentence&quot;, &quot;token&quot;)\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512) finance_ner = finance.NerModel.pretrained(&quot;finner_aspect_based_sentiment_md&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = finance.NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) assertion_model = finance.AssertionDLModel.pretrained(&quot;finassertion_aspect_based_sentiment_md&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;assertion&quot;) nlpPipeline = nlp.Pipeline( stages=[documentAssembler, sentenceDetector, tokenizer, bert_embeddings, finance_ner, ner_converter, assertion_model]) text = &quot;Equity and earnings of affiliates in Latin America increased to $4.8 million in the quarter from $2.2 million in the prior year as the commodity markets in Latin America remain strong through the end of the quarter.&quot; spark_df = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) result = nlpPipeline.fit(spark_df ).transform(spark_df) result.select(F.explode(F.arrays_zip(&quot;ner_chunk.result&quot;, &quot;ner_chunk.metadata&quot;, &quot;assertion.result&quot;, &quot;assertion.metadata&quot;)).alias(&quot;cols&quot;))\ .select(F.expr(&quot;cols['0']&quot;).alias(&quot;entity&quot;), F.expr(&quot;cols['1']['entity']&quot;).alias(&quot;label&quot;), F.expr(&quot;cols['2']&quot;).alias(&quot;assertion&quot;), F.expr(&quot;cols['3']['confidence']&quot;).alias(&quot;confidence&quot;)).show(50, truncate=False) Results +--------+---------+---------+----------+ |entity |label |assertion|confidence| +--------+---------+---------+----------+ |Equity |LIABILITY|POSITIVE |0.9895 | |earnings|PROFIT |POSITIVE |0.995 | +--------+---------+---------+----------+ Model Information Model Name: finassertion_aspect_based_sentiment_md Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, chunk, embeddings] Output Labels: [assertion] Language: en Size: 2.7 MB Benchmarking label precision recall f1-score support NEGATIVE 0.68 0.43 0.53 232 NEUTRAL 0.44 0.65 0.53 441 POSITIVE 0.79 0.69 0.74 947 accuracy - - 0.64 1620 macro-avg 0.64 0.59 0.60 1620 weighted-avg 0.68 0.64 0.65 1620</summary></entry><entry><title type="html">Financial NER on Aspect-Based Sentiment Analysis</title><link href="/2023/11/11/finner_aspect_based_sentiment_md_en.html" rel="alternate" type="text/html" title="Financial NER on Aspect-Based Sentiment Analysis" /><published>2023-11-11T00:00:00+00:00</published><updated>2023-11-11T00:00:00+00:00</updated><id>/2023/11/11/finner_aspect_based_sentiment_md_en</id><content type="html" xml:base="/2023/11/11/finner_aspect_based_sentiment_md_en.html">## Description

This NER model identifies entities that can be associated with a financial sentiment. The model is designed to be used with the associated Assertion Status model that classifies the entities into a sentiment category.

## Predicted Entities

`ASSET`, `CASHFLOW`, `EXPENSE`, `FREE_CASH_FLOW`, `GAINS`, `KPI`, `LIABILITY`, `LOSSES`, `PROFIT`, `REVENUE`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finner_aspect_based_sentiment_md_en_1.0.0_3.0_1699704469251.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finner_aspect_based_sentiment_md_en_1.0.0_3.0_1699704469251.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

# Sentence Detector annotator, processes various sentences per line
sentenceDetector = nlp.SentenceDetector()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

# Tokenizer splits words in a relevant format for NLP
tokenizer = nlp.Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;)\
    .setInputCols(&quot;sentence&quot;, &quot;token&quot;)\
    .setOutputCol(&quot;embeddings&quot;)\
    .setMaxSentenceLength(512)


ner_model = finance.NerModel().pretrained(&quot;finner_aspect_based_sentiment_md&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = nlp.Pipeline(stages=[
        documentAssembler,
        sentenceDetector,
        tokenizer,
        bert_embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)
model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;Equity and earnings of affiliates in Latin America increased to $4.8 million in the quarter from $2.2 million in the prior year as the commodity markets in Latin America remain strong through the end of the quarter.&quot;&quot;&quot;]
result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))

from pyspark.sql import functions as F

result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.begin, result.ner_chunk.end, result.ner_chunk.metadata)).alias(&quot;cols&quot;)) \
               .select(F.expr(&quot;cols['0']&quot;).alias(&quot;chunk&quot;),
                       F.expr(&quot;cols['1']&quot;).alias(&quot;begin&quot;),
                       F.expr(&quot;cols['2']&quot;).alias(&quot;end&quot;),
                       F.expr(&quot;cols['3']['entity']&quot;).alias(&quot;ner_label&quot;)
                       ).show(100, truncate=False)
```

&lt;/div&gt;

## Results

```bash
+--------+-----+---+---------+
|chunk   |begin|end|ner_label|
+--------+-----+---+---------+
|Equity  |1    |6  |LIABILITY|
|earnings|12   |19 |PROFIT   |
+--------+-----+---+---------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finner_aspect_based_sentiment_md|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|16.5 MB|

## Benchmarking

```bash
 label           precision  recall  f1-score  support 
 ASSET           0.50       0.72    0.59      53      
 CASHFLOW        0.78       0.60    0.68      30      
 EXPENSE         0.71       0.68    0.70      151     
 FREE_CASH_FLOW  1.00       1.00    1.00      19      
 GAINS           0.80       0.78    0.79      55      
 KPI             0.72       0.58    0.64      106     
 LIABILITY       0.65       0.51    0.57      39      
 LOSSES          0.77       0.59    0.67      29      
 PROFIT          0.77       0.74    0.75      101     
 REVENUE         0.74       0.78    0.76      231     
 micro-avg       0.72       0.71    0.71      814     
 macro-avg       0.74       0.70    0.71      814     
 weighted-avg    0.73       0.71    0.71      814  
```</content><author><name>John Snow Labs</name></author><category term="ner" /><category term="licensed" /><category term="finance" /><category term="en" /><summary type="html">Description This NER model identifies entities that can be associated with a financial sentiment. The model is designed to be used with the associated Assertion Status model that classifies the entities into a sentiment category. Predicted Entities ASSET, CASHFLOW, EXPENSE, FREE_CASH_FLOW, GAINS, KPI, LIABILITY, LOSSES, PROFIT, REVENUE Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) # Sentence Detector annotator, processes various sentences per line sentenceDetector = nlp.SentenceDetector()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) # Tokenizer splits words in a relevant format for NLP tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;)\ .setInputCols(&quot;sentence&quot;, &quot;token&quot;)\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512) ner_model = finance.NerModel().pretrained(&quot;finner_aspect_based_sentiment_md&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, bert_embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;Equity and earnings of affiliates in Latin America increased to $4.8 million in the quarter from $2.2 million in the prior year as the commodity markets in Latin America remain strong through the end of the quarter.&quot;&quot;&quot;] result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) from pyspark.sql import functions as F result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.begin, result.ner_chunk.end, result.ner_chunk.metadata)).alias(&quot;cols&quot;)) \ .select(F.expr(&quot;cols['0']&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols['1']&quot;).alias(&quot;begin&quot;), F.expr(&quot;cols['2']&quot;).alias(&quot;end&quot;), F.expr(&quot;cols['3']['entity']&quot;).alias(&quot;ner_label&quot;) ).show(100, truncate=False) Results +--------+-----+---+---------+ |chunk |begin|end|ner_label| +--------+-----+---+---------+ |Equity |1 |6 |LIABILITY| |earnings|12 |19 |PROFIT | +--------+-----+---+---------+ Model Information Model Name: finner_aspect_based_sentiment_md Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 16.5 MB Benchmarking label precision recall f1-score support ASSET 0.50 0.72 0.59 53 CASHFLOW 0.78 0.60 0.68 30 EXPENSE 0.71 0.68 0.70 151 FREE_CASH_FLOW 1.00 1.00 1.00 19 GAINS 0.80 0.78 0.79 55 KPI 0.72 0.58 0.64 106 LIABILITY 0.65 0.51 0.57 39 LOSSES 0.77 0.59 0.67 29 PROFIT 0.77 0.74 0.75 101 REVENUE 0.74 0.78 0.76 231 micro-avg 0.72 0.71 0.71 814 macro-avg 0.74 0.70 0.71 814 weighted-avg 0.73 0.71 0.71 814</summary></entry><entry><title type="html">Legal Embeddings BGE Base</title><link href="/2023/11/10/legembeddings_bge_base_en.html" rel="alternate" type="text/html" title="Legal Embeddings BGE Base" /><published>2023-11-10T00:00:00+00:00</published><updated>2023-11-10T00:00:00+00:00</updated><id>/2023/11/10/legembeddings_bge_base_en</id><content type="html" xml:base="/2023/11/10/legembeddings_bge_base_en.html">## Description

This model is a legal version of the BGE base model fine-tuned on in-house curated datasets. Reference: Xiao, S., Liu, Z., Zhang, P., &amp; Muennighof, N. (2023). C-pack: Packaged resources to advance general chinese embedding. arXiv preprint arXiv:2309.07597.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legembeddings_bge_base_en_1.0.0_3.0_1699632504201.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legembeddings_bge_base_en_1.0.0_3.0_1699632504201.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler() \
.setInputCol(&quot;text&quot;) \
.setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer() \
.setInputCols(&quot;document&quot;) \
.setOutputCol(&quot;token&quot;)

BGE_loaded = nlp.BertEmbeddings.load(&quot;legembeddings_bge_base&quot;,&quot;en&quot;, &quot;legal/models&quot;)\
    .setInputCols([&quot;document&quot;,&quot;token&quot;])\
    .setOutputCol(&quot;BGE&quot;)\

pipeline = nlp.Pipeline(
    stages = [
        documentAssembler,
        tokenizer,
        BGE_loaded
  ])

data = spark.createDataFrame([['''Receiving Party shall not use any Confidential Information for any purpose other than the purposes stated in Agreement.''']]).toDF(&quot;text&quot;)

model = pipeline.fit(data)
result = model.transform(data)
result.show(truncate=150)
```

&lt;/div&gt;

## Results

```bash
+----------------------------------------------------------------------------------------------------+
|                                                                                          embeddings|
+----------------------------------------------------------------------------------------------------+
|[-0.060075462, -0.26741037, 0.32553613, 0.13449538, 0.22019976, -0.35624868, 1.1038424, 0.8212698...|
|[-0.10228735, -0.3738884, 0.27723783, 0.17312518, 0.26656383, -0.24942908, 1.1518378, 0.7217457, ...|
|[-0.38215938, -0.5851373, 0.35209915, -0.30132422, -0.9744857, 0.5976255, 0.86980593, 0.5825193, ...|
|[-0.8023102, -0.1705234, 0.4355616, -0.16370925, -0.99943596, -0.13651904, 1.0603938, 0.76027215,...|
|[0.17291568, -0.74328834, 0.43998405, -0.1694346, -0.7754292, -0.025751337, 1.1425712, 0.43741557...|
|[-0.27675575, -0.17631046, 0.09160468, -0.22860324, -0.6295841, -0.11335259, 1.0146872, 0.6610859...|
|[-0.11538671, -0.31234437, 0.21929267, 0.10618421, 0.2265009, -0.37587893, 1.1389759, 0.7971325, ...|
|[0.009457495, -0.33288023, 0.2432522, 0.12458266, 0.2707794, -0.36873063, 1.0906105, 0.70786965, ...|
|[-0.295701, -0.61499435, 0.07829141, -0.74933016, -0.531358, -0.18479005, 1.1679127, 0.5615579, 0...|
|[-0.67664135, 0.12311895, 0.08994642, -0.07882077, -0.6767479, -0.16962644, 1.0955209, 0.6912421,...|
|[-0.33884412, -0.26324403, -0.03943791, 0.12610006, -0.6458304, -0.3981361, 0.6717623, 0.5545144,...|
|[-0.84253764, -0.18777902, -0.0011436939, -0.29669517, -0.008230045, -0.19728595, 0.9491053, 0.67...|
|[-0.70816183, -0.22422114, -0.07173601, -0.18688664, -0.1930152, -0.30726036, 0.8886021, 0.789013...|
|[-0.18011564, 0.055544622, 0.061416026, -0.110076465, -0.028466597, -0.27377772, 0.98722064, 0.91...|
|[-0.4780874, -0.28484517, -0.105963364, 0.060177833, -0.75987476, -0.36107045, 0.6527582, 0.53413...|
|[-0.39539725, -0.6021485, -0.018175352, -0.12834826, -0.71462053, -0.17749298, 0.8468195, 0.59975...|
|[-0.095429584, -0.8838102, 0.5930538, -0.33268213, 0.010708451, 0.06336981, 1.2200518, 0.9934566,...|
|[0.06960945, -0.17862234, 0.36319345, 0.28421152, 0.22127056, -0.4145783, 1.0451053, 1.0578575, 0...|
|[-0.07706641, -0.09056446, 0.47557953, -0.14709732, 0.37253422, -0.39098266, 1.2081625, 1.2230319...|
+----------------------------------------------------------------------------------------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legembeddings_bge_base|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|1.2 GB|
|Case sensitive:|true|

## References

In-house curated legal datasets.</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="onnx" /><category term="embeddings" /><summary type="html">Description This model is a legal version of the BGE base model fine-tuned on in-house curated datasets. Reference: Xiao, S., Liu, Z., Zhang, P., &amp;amp; Muennighof, N. (2023). C-pack: Packaged resources to advance general chinese embedding. arXiv preprint arXiv:2309.07597. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) BGE_loaded = nlp.BertEmbeddings.load(&quot;legembeddings_bge_base&quot;,&quot;en&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;BGE&quot;)\ pipeline = nlp.Pipeline( stages = [ documentAssembler, tokenizer, BGE_loaded ]) data = spark.createDataFrame([['''Receiving Party shall not use any Confidential Information for any purpose other than the purposes stated in Agreement.''']]).toDF(&quot;text&quot;) model = pipeline.fit(data) result = model.transform(data) result.show(truncate=150) Results +----------------------------------------------------------------------------------------------------+ | embeddings| +----------------------------------------------------------------------------------------------------+ |[-0.060075462, -0.26741037, 0.32553613, 0.13449538, 0.22019976, -0.35624868, 1.1038424, 0.8212698...| |[-0.10228735, -0.3738884, 0.27723783, 0.17312518, 0.26656383, -0.24942908, 1.1518378, 0.7217457, ...| |[-0.38215938, -0.5851373, 0.35209915, -0.30132422, -0.9744857, 0.5976255, 0.86980593, 0.5825193, ...| |[-0.8023102, -0.1705234, 0.4355616, -0.16370925, -0.99943596, -0.13651904, 1.0603938, 0.76027215,...| |[0.17291568, -0.74328834, 0.43998405, -0.1694346, -0.7754292, -0.025751337, 1.1425712, 0.43741557...| |[-0.27675575, -0.17631046, 0.09160468, -0.22860324, -0.6295841, -0.11335259, 1.0146872, 0.6610859...| |[-0.11538671, -0.31234437, 0.21929267, 0.10618421, 0.2265009, -0.37587893, 1.1389759, 0.7971325, ...| |[0.009457495, -0.33288023, 0.2432522, 0.12458266, 0.2707794, -0.36873063, 1.0906105, 0.70786965, ...| |[-0.295701, -0.61499435, 0.07829141, -0.74933016, -0.531358, -0.18479005, 1.1679127, 0.5615579, 0...| |[-0.67664135, 0.12311895, 0.08994642, -0.07882077, -0.6767479, -0.16962644, 1.0955209, 0.6912421,...| |[-0.33884412, -0.26324403, -0.03943791, 0.12610006, -0.6458304, -0.3981361, 0.6717623, 0.5545144,...| |[-0.84253764, -0.18777902, -0.0011436939, -0.29669517, -0.008230045, -0.19728595, 0.9491053, 0.67...| |[-0.70816183, -0.22422114, -0.07173601, -0.18688664, -0.1930152, -0.30726036, 0.8886021, 0.789013...| |[-0.18011564, 0.055544622, 0.061416026, -0.110076465, -0.028466597, -0.27377772, 0.98722064, 0.91...| |[-0.4780874, -0.28484517, -0.105963364, 0.060177833, -0.75987476, -0.36107045, 0.6527582, 0.53413...| |[-0.39539725, -0.6021485, -0.018175352, -0.12834826, -0.71462053, -0.17749298, 0.8468195, 0.59975...| |[-0.095429584, -0.8838102, 0.5930538, -0.33268213, 0.010708451, 0.06336981, 1.2200518, 0.9934566,...| |[0.06960945, -0.17862234, 0.36319345, 0.28421152, 0.22127056, -0.4145783, 1.0451053, 1.0578575, 0...| |[-0.07706641, -0.09056446, 0.47557953, -0.14709732, 0.37253422, -0.39098266, 1.2081625, 1.2230319...| +----------------------------------------------------------------------------------------------------+ Model Information Model Name: legembeddings_bge_base Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token] Output Labels: [bert] Language: en Size: 1.2 GB Case sensitive: true References In-house curated legal datasets.</summary></entry><entry><title type="html">Finance E5 Embedding Large</title><link href="/2023/11/09/finembedding_e5_large_en.html" rel="alternate" type="text/html" title="Finance E5 Embedding Large" /><published>2023-11-09T00:00:00+00:00</published><updated>2023-11-09T00:00:00+00:00</updated><id>/2023/11/09/finembedding_e5_large_en</id><content type="html" xml:base="/2023/11/09/finembedding_e5_large_en.html">## Description

This model is a financial version of the E5 large model fine-tuned on in-house curated financial datasets. Reference: Wang, Liang, et al. “Text embeddings by weakly-supervised contrastive pre-training.” arXiv preprint arXiv:2212.03533 (2022).

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finembedding_e5_large_en_1.0.0_3.0_1699530885080.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finembedding_e5_large_en_1.0.0_3.0_1699530885080.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = (
    nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;)
)

E5_embedding = (
    nlp.E5Embeddings.pretrained(
        &quot;finembedding_e5_large&quot;, &quot;en&quot;, &quot;finance/models&quot;
    )
    .setInputCols([&quot;document&quot;])
    .setOutputCol(&quot;E5&quot;)
)
pipeline = nlp.Pipeline(stages=[document_assembler, E5_embedding])

data = spark.createDataFrame(
    [[&quot;What is the best way to invest in the stock market?&quot;]]
).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
result. Select(&quot;E5.result&quot;).show()
```

&lt;/div&gt;

## Results

```bash
+----------------------------------------------------------------------------------------------------+
|                                                                                          embeddings|
+----------------------------------------------------------------------------------------------------+
|[0.8358813, -1.30341, -0.576791, 0.25893408, 0.26888973, 0.028243342, 0.47971666, 0.47653574, 0.4...|
+----------------------------------------------------------------------------------------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finembedding_e5_large|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[E5]|
|Language:|en|
|Size:|1.2 GB|

## References

In-house annotated financial datasets.</content><author><name>John Snow Labs</name></author><category term="finance" /><category term="en" /><category term="licensed" /><category term="e5" /><category term="sentence_embedding" /><category term="onnx" /><summary type="html">Description This model is a financial version of the E5 large model fine-tuned on in-house curated financial datasets. Reference: Wang, Liang, et al. “Text embeddings by weakly-supervised contrastive pre-training.” arXiv preprint arXiv:2212.03533 (2022). Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = ( nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) ) E5_embedding = ( nlp.E5Embeddings.pretrained( &quot;finembedding_e5_large&quot;, &quot;en&quot;, &quot;finance/models&quot; ) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;E5&quot;) ) pipeline = nlp.Pipeline(stages=[document_assembler, E5_embedding]) data = spark.createDataFrame( [[&quot;What is the best way to invest in the stock market?&quot;]] ).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result. Select(&quot;E5.result&quot;).show() Results +----------------------------------------------------------------------------------------------------+ | embeddings| +----------------------------------------------------------------------------------------------------+ |[0.8358813, -1.30341, -0.576791, 0.25893408, 0.26888973, 0.028243342, 0.47971666, 0.47653574, 0.4...| +----------------------------------------------------------------------------------------------------+ Model Information Model Name: finembedding_e5_large Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document] Output Labels: [E5] Language: en Size: 1.2 GB References In-house annotated financial datasets.</summary></entry><entry><title type="html">Pretrained Pipeline for Reading Handwritten Text with Image Documents</title><link href="/2023/11/06/image_handwritten_transformer_extraction_en_3_2.html" rel="alternate" type="text/html" title="Pretrained Pipeline for Reading Handwritten Text with Image Documents" /><published>2023-11-06T00:00:00+00:00</published><updated>2023-11-06T00:00:00+00:00</updated><id>/2023/11/06/image_handwritten_transformer_extraction_en_3_2</id><content type="html" xml:base="/2023/11/06/image_handwritten_transformer_extraction_en_3_2.html">## Description

Pretrained pipeline designed to extract handwritten text from document images. It empowers accurate and efficient conversion of handwritten content into digital text, making it an invaluable tool for text recognition tasks.


## Predicted Entities

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/ocr/PP_IMAGE_HANDWRITTEN_TRANSFORMER_EXTRACTION/){:.button.button-orange.button-orange-trans.co.button-icon}
[Open in Colab](https://github.com/JohnSnowLabs/spark-ocr-workshop/blob/master/jupyter/Cards/SparkOcrPretrainedPipelinesImageHandwrittenTransformerExtraction.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/ocr/image_handwritten_transformer_extraction_en_5.0.2_3.0_1680289435000.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use

&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
img_pipeline = PretrainedPipeline('image_handwritten_transformer_extraction', 'en', 'clinical/ocr')

img_path = '/content/images/'
img_example_df = spark.read.format(&quot;binaryFile&quot;).load(img_path).cache()

result = img_pipeline.transform(img_example_df)
```
```scala
val img_pipeline = new PretrainedPipeline(&quot;image_handwritten_transformer_extraction&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;)

val img_path = &quot;/content/images/&quot;
val img_example_df = spark.read.format(&quot;binaryFile&quot;).load(img_path).cache()

val result = img_pipeline.transform(img_example_df)
```
&lt;/div&gt;

## Example

### Input
![Screenshot](/assets/images/examples_ocr/image3_1.jpg)

### Output
```bash
&quot;This is an example of handwritten
text .
Let's # check the performance !
I hope it will be awesome .&quot;
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|image_handwritten_transformer_extraction|
|Type:|pipeline|
|Compatibility:|Visual NLP 5.0.2+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="handwritten" /><category term="ocr" /><summary type="html">Description Pretrained pipeline designed to extract handwritten text from document images. It empowers accurate and efficient conversion of handwritten content into digital text, making it an invaluable tool for text recognition tasks. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU img_pipeline = PretrainedPipeline('image_handwritten_transformer_extraction', 'en', 'clinical/ocr') img_path = '/content/images/' img_example_df = spark.read.format(&quot;binaryFile&quot;).load(img_path).cache() result = img_pipeline.transform(img_example_df) val img_pipeline = new PretrainedPipeline(&quot;image_handwritten_transformer_extraction&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) val img_path = &quot;/content/images/&quot; val img_example_df = spark.read.format(&quot;binaryFile&quot;).load(img_path).cache() val result = img_pipeline.transform(img_example_df) Example Input Output &quot;This is an example of handwritten text . Let's # check the performance ! I hope it will be awesome .&quot; Model Information Model Name: image_handwritten_transformer_extraction Type: pipeline Compatibility: Visual NLP 5.0.2+ License: Licensed Edition: Official Language: en</summary></entry><entry><title type="html">Pretrained Pipeline for Reading in Mixed Scanned and Digital PDF Documents</title><link href="/2023/11/06/mixed_scanned_digital_pdf_en_3_2.html" rel="alternate" type="text/html" title="Pretrained Pipeline for Reading in Mixed Scanned and Digital PDF Documents" /><published>2023-11-06T00:00:00+00:00</published><updated>2023-11-06T00:00:00+00:00</updated><id>/2023/11/06/mixed_scanned_digital_pdf_en_3_2</id><content type="html" xml:base="/2023/11/06/mixed_scanned_digital_pdf_en_3_2.html">## Description

Pretrained pipeline for conducting Optical Character Recognition (OCR) on mixed scanned and digital PDF documents. It ensures precise and efficient text extraction from PDFs of various origins and formats, improving the overall OCR accuracy.

## Predicted Entities

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/ocr/PP_MIXED_SCANNED_DIGITAL_PDF/){:.button.button-orange.button-orange-trans.co.button-icon}
[Open in Colab](https://github.com/JohnSnowLabs/spark-ocr-workshop/blob/master/jupyter/Cards/SparkOcrPretrainedPipelinesMixedScannedDigitalPdf.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/ocr/mixed_scanned_digital_pdf_en_4.3.4_3.0_1679597686000.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use

&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
pdf_pipeline = PretrainedPipeline('mixed_scanned_digital_pdf', 'en', 'clinical/ocr')

pdf_path = '/content/pdfs/'
pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache()

result = pdf_pipeline.transform(pdf_example_df)
```
```scala
val pdf_pipeline = new PretrainedPipeline(&quot;mixed_scanned_digital_pdf&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;)

val pdf_path = &quot;/content/pdfs/&quot;
val pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache()

val result = pdf_pipeline.transform(pdf_example_df)
```
&lt;/div&gt;

## Example

### Input
![Screenshot](/assets/images/examples_ocr/pp_printed.jpg)

### Output
```bash
&quot;ROMINVENT\n\nINDUSTRIAL PROPERTY AGENCY - ESTABLISHED IN 1953\n\nRebecca Gritschke\n\nDate: 26-Nov-2021\n\nMERCK KGaA\n\nYour ref.: TM24134RO00\n\nGroup Legal &amp; Compliance/Trademarks\n\nLE-TA\n\nOur ref.: 214766 / C/2-21243/SI/SI\n\nFrankfurter Str. 250\n\nClient ID: 1119\n\nD-64293 Darmstadt\n\nGERMANY\n\nVAT No: DE 811850788\n\nFax: +49 6151 72 3378\n\nE-mail: rebecca.gritschke@merckgroup.com\n\nRe\n\nRenewal application for CONCOR AM, reg. no. 118032 in class 5 in Romania.\n\nOwner: MERCK KGaA;\n\nINVOICE NO. M210695\n\nNo.\n\nDescription\n\nOfficial fees\n\nOur services\n\nEUR\n\ncharges\n\nEUR\n\nApplication for renewal of an individual trademark\n\n1\n\nTrademark renewal\n\n1 class black &amp; white\n\nIncrease of 50% (grace period), 1 class black &amp; white\n\n180\n\n180\n\nReporting of Renewal Certificate\n\nIssuing of Renewal Certificate\n\n50\n\n50\n\nSubtotal\n\n230\n\n230\n\nTotal\n\nEUR 460.00\n\n* Official and Rominvent's fees are in EURO; as such, the conversion from EURO to USD will generate amounts with decimal places.\n\nPayment deadline: within 30 days from issue. Currency: 1 EUR = 4.9490 RON. published on 2021-11-25\n\nVAT in accordance with Art 133(2) of the Romanian Law 571/2003. . VIES consultation number: WAPIAAAAX1 bnp!ICx\n\nThe supply is subject to the reverse charge procedure according Art 44, 196 of the Council Directive 2006/112/EC.\n\nIMPORTANT * When arranging the wire transfer, please make sure that the bank charges are debited to your account.\n\n* Please always refer to our Invoice no. in your Payment Order. (Please also send a remittance advice with all payments)\n\nBank name: BRD-GSG, MCC Branch. SWIFT: BRDEROBU\n\nBank name: BCR, Lipscani Branch. SWIFT: RNCBROBU\n\nAddress:1-7 lon Mihalache Blvd, Sector 1, Bucharest, 011171, RO\n\nAddress:5 Regina Elisabeta Blvd, Sector 3, Bucharest, RO\n\nIBAN Account No EUR:RO39BRDE450SV00768494500\n\nIBAN Account No EUR:RO69RNCB0090000505820005\n\nIBAN Account No USD:RO12BRDE450SV008 19474500\n\nIBAN Account No USD:RO53RNCB0090000505820002\n\nAddress: ROMINVENT S.A., 35, Ermil Pangratti Str., 1st Floor, Sector 1, Bucharest 011882, ROMANIA\n\nPhone: +4021-231 2515/-231 2353 Fax: +4021-231 2550/-231 2454 E-mail: office@rominvent.ro Internet: www.rominvent.ro\n\nTrade Register No.: J40/13380/1993 VAT: RO4140325 Assets: 330.000 Lei\n&quot;
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|mixed_scanned_digital_pdf|
|Type:|pipeline|
|Compatibility:|Visual NLP 5.0.2+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="ocr" /><summary type="html">Description Pretrained pipeline for conducting Optical Character Recognition (OCR) on mixed scanned and digital PDF documents. It ensures precise and efficient text extraction from PDFs of various origins and formats, improving the overall OCR accuracy. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU pdf_pipeline = PretrainedPipeline('mixed_scanned_digital_pdf', 'en', 'clinical/ocr') pdf_path = '/content/pdfs/' pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache() result = pdf_pipeline.transform(pdf_example_df) val pdf_pipeline = new PretrainedPipeline(&quot;mixed_scanned_digital_pdf&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) val pdf_path = &quot;/content/pdfs/&quot; val pdf_example_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path).cache() val result = pdf_pipeline.transform(pdf_example_df) Example Input Output &quot;ROMINVENT\n\nINDUSTRIAL PROPERTY AGENCY - ESTABLISHED IN 1953\n\nRebecca Gritschke\n\nDate: 26-Nov-2021\n\nMERCK KGaA\n\nYour ref.: TM24134RO00\n\nGroup Legal &amp;amp; Compliance/Trademarks\n\nLE-TA\n\nOur ref.: 214766 / C/2-21243/SI/SI\n\nFrankfurter Str. 250\n\nClient ID: 1119\n\nD-64293 Darmstadt\n\nGERMANY\n\nVAT No: DE 811850788\n\nFax: +49 6151 72 3378\n\nE-mail: rebecca.gritschke@merckgroup.com\n\nRe\n\nRenewal application for CONCOR AM, reg. no. 118032 in class 5 in Romania.\n\nOwner: MERCK KGaA;\n\nINVOICE NO. M210695\n\nNo.\n\nDescription\n\nOfficial fees\n\nOur services\n\nEUR\n\ncharges\n\nEUR\n\nApplication for renewal of an individual trademark\n\n1\n\nTrademark renewal\n\n1 class black &amp;amp; white\n\nIncrease of 50% (grace period), 1 class black &amp;amp; white\n\n180\n\n180\n\nReporting of Renewal Certificate\n\nIssuing of Renewal Certificate\n\n50\n\n50\n\nSubtotal\n\n230\n\n230\n\nTotal\n\nEUR 460.00\n\n* Official and Rominvent's fees are in EURO; as such, the conversion from EURO to USD will generate amounts with decimal places.\n\nPayment deadline: within 30 days from issue. Currency: 1 EUR = 4.9490 RON. published on 2021-11-25\n\nVAT in accordance with Art 133(2) of the Romanian Law 571/2003. . VIES consultation number: WAPIAAAAX1 bnp!ICx\n\nThe supply is subject to the reverse charge procedure according Art 44, 196 of the Council Directive 2006/112/EC.\n\nIMPORTANT * When arranging the wire transfer, please make sure that the bank charges are debited to your account.\n\n* Please always refer to our Invoice no. in your Payment Order. (Please also send a remittance advice with all payments)\n\nBank name: BRD-GSG, MCC Branch. SWIFT: BRDEROBU\n\nBank name: BCR, Lipscani Branch. SWIFT: RNCBROBU\n\nAddress:1-7 lon Mihalache Blvd, Sector 1, Bucharest, 011171, RO\n\nAddress:5 Regina Elisabeta Blvd, Sector 3, Bucharest, RO\n\nIBAN Account No EUR:RO39BRDE450SV00768494500\n\nIBAN Account No EUR:RO69RNCB0090000505820005\n\nIBAN Account No USD:RO12BRDE450SV008 19474500\n\nIBAN Account No USD:RO53RNCB0090000505820002\n\nAddress: ROMINVENT S.A., 35, Ermil Pangratti Str., 1st Floor, Sector 1, Bucharest 011882, ROMANIA\n\nPhone: +4021-231 2515/-231 2353 Fax: +4021-231 2550/-231 2454 E-mail: office@rominvent.ro Internet: www.rominvent.ro\n\nTrade Register No.: J40/13380/1993 VAT: RO4140325 Assets: 330.000 Lei\n&quot; Model Information Model Name: mixed_scanned_digital_pdf Type: pipeline Compatibility: Visual NLP 5.0.2+ License: Licensed Edition: Official Language: en</summary></entry></feed>