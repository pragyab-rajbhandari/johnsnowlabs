{
  "0": {
    "id": "0",
    "title": "404",
    "content": "404 Page not found :( &lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; Pipeline to Social Determinants of Health (LangTest) | ner_sdoh_langtest_pipeline | Healthcare NLP 5.1.0 &lt;meta name=&quot;description&quot; content=&quot;DescriptionThis pretrained pipeline is built on the top of ner_sdoh_langtest model.Live DemoOpen in ColabDownloadCopy S3 URIHow to use PythonScalaNLU from sparknlp.pretrained import PretrainedPipelinener_pipeline = PretrainedPipeline(&quot;ner_sdoh_langtest_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)result = ner_pipeline.annot...&quot;&gt; HomeDocsLearnModelsDemo Edit on GitHub John Snow Labs Sep 09, 2023 Pipeline to Social Determinants of Health (LangTest)licensedensdohpipelinener Description This pretrained pipeline is built on the top of ner_sdoh_langtest model. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.pretrained import PretrainedPipeline ner_pipeline = PretrainedPipeline(&quot;ner_sdoh_langtest_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = ner_pipeline.annotate(&quot;&quot;&quot;Smith is 55 years old, living in New York, a divorced Mexcian American woman with financial problems. She speaks Spanish and Portuguese. She lives in an apartment. She has been struggling with diabetes for the past 10 years and has recently been experiencing frequent hospitalizations due to uncontrolled blood sugar levels. Smith works as a cleaning assistant and cannot access health insurance or paid sick leave. She has a son, a student at college. Pt with likely long-standing depression. She is aware she needs rehab. Pt reports having her catholic faith as a means of support as well. She has a long history of etoh abuse, beginning in her teens. She reports she has been a daily drinker for 30 years, most recently drinking beer daily. She smokes a pack of cigarettes a day. She had DUI in April and was due to court this week.&quot;&quot;&quot;) import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline val ner_pipeline = PretrainedPipeline(&quot;ner_sdoh_langtest_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) val result = ner_pipeline.annotate(&quot;&quot;&quot;Smith is 55 years old, living in New York, a divorced Mexcian American woman with financial problems. She speaks Spanish and Portuguese. She lives in an apartment. She has been struggling with diabetes for the past 10 years and has recently been experiencing frequent hospitalizations due to uncontrolled blood sugar levels. Smith works as a cleaning assistant and cannot access health insurance or paid sick leave. She has a son, a student at college. Pt with likely long-standing depression. She is aware she needs rehab. Pt reports having her catholic faith as a means of support as well. She has a long history of etoh abuse, beginning in her teens. She reports she has been a daily drinker for 30 years, most recently drinking beer daily. She smokes a pack of cigarettes a day. She had DUI in April and was due to court this week.&quot;&quot;&quot;) Results | | chunks | begin | end | entities | |:|:|--:|:|:--| | 0 | 55 years old | 9 | 20 | Age | | 1 | New York | 33 | 40 | Geographic_Entity | | 2 | divorced | 45 | 52 | Marital_Status | | 3 | Mexcian American | 54 | 69 | Race_Ethnicity | | 4 | woman | 71 | 75 | Gender | | 5 | financial problems | 82 | 99 | Financial_Status | | 6 | She | 102 | 104 | Gender | | 7 | Spanish | 113 | 119 | Language | | 8 | Portuguese | 125 | 134 | Language | | 9 | She | 137 | 139 | Gender | | 10 | apartment | 153 | 161 | Housing | | 11 | She | 164 | 166 | Gender | | 12 | diabetes | 193 | 200 | Other_Disease | | 13 | hospitalizations | 268 | 283 | Other_SDoH_Keywords | | 14 | cleaning assistant | 342 | 359 | Employment | | 15 | access health insurance | 372 | 394 | Insurance_Status | | 16 | She | 416 | 418 | Gender | | 17 | son | 426 | 428 | Family_Member | | 18 | student | 433 | 439 | Education | | 19 | college | 444 | 450 | Education | | 20 | depression | 482 | 491 | Mental_Health | | 21 | She | 494 | 496 | Gender | | 22 | she | 507 | 509 | Gender | | 23 | rehab | 517 | 521 | Access_To_Care | | 24 | her | 542 | 544 | Gender | | 25 | catholic faith | 546 | 559 | Spiritual_Beliefs | | 26 | support | 575 | 581 | Social_Support | | 27 | She | 593 | 595 | Gender | | 28 | etoh abuse | 619 | 628 | Alcohol | | 29 | her | 644 | 646 | Gender | | 30 | teens | 648 | 652 | Age | | 31 | She | 655 | 657 | Gender | | 32 | she | 667 | 669 | Gender | | 33 | daily | 682 | 686 | Substance_Frequency | | 34 | drinker | 688 | 694 | Alcohol | | 35 | 30 years | 700 | 707 | Substance_Duration | | 36 | drinking | 724 | 731 | Alcohol | | 37 | beer | 733 | 736 | Alcohol | | 38 | daily | 738 | 742 | Substance_Frequency | | 39 | She | 745 | 747 | Gender | | 40 | smokes | 749 | 754 | Smoking | | 41 | a pack | 756 | 761 | Substance_Quantity | | 42 | cigarettes | 766 | 775 | Smoking | | 43 | a day | 777 | 781 | Substance_Frequency | | 44 | She | 784 | 786 | Gender | | 45 | DUI | 792 | 794 | Legal_Issues | Model Information Model Name: ner_sdoh_langtest_pipeline Type: pipeline Compatibility: Healthcare NLP 5.1.0+ License: Licensed Edition: Official Language: en Size: 1.7 GB Included Models DocumentAssembler SentenceDetectorDLModel TokenizerModel WordEmbeddingsModel MedicalNerModel NerConverterInternalModel PREVIOUSPipeline to Extract Mentions of Response to Cancer Treatment (langtest) © John Snow Labs Inc. Terms of Service | Privacy Policy &lt;/html&gt;",
    "url": "/404.html",
    "relUrl": "/404.html"
  },
  "1": {
    "id": "1",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSAnonymousCredentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSAnonymousCredentials.html"
  },
  "2": {
    "id": "2",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSBasicCredentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSBasicCredentials.html"
  },
  "3": {
    "id": "3",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSCredentialsProvider.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSCredentialsProvider.html"
  },
  "4": {
    "id": "4",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSGateway.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSGateway.html"
  },
  "5": {
    "id": "5",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSProfileCredentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSProfileCredentials.html"
  },
  "6": {
    "id": "6",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSTokenCredentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSTokenCredentials.html"
  },
  "7": {
    "id": "7",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ActivationFunction$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ActivationFunction$.html"
  },
  "8": {
    "id": "8",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/AgeToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/AgeToken.html"
  },
  "9": {
    "id": "9",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/AhoCorasickAutomaton$Node.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/AhoCorasickAutomaton$Node.html"
  },
  "10": {
    "id": "10",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/AhoCorasickAutomaton.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/AhoCorasickAutomaton.html"
  },
  "11": {
    "id": "11",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings$.html"
  },
  "12": {
    "id": "12",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.html"
  },
  "13": {
    "id": "13",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering$.html"
  },
  "14": {
    "id": "14",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering.html"
  },
  "15": {
    "id": "15",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification$.html"
  },
  "16": {
    "id": "16",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification.html"
  },
  "17": {
    "id": "17",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification$.html"
  },
  "18": {
    "id": "18",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification.html"
  },
  "19": {
    "id": "19",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Alphabet.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Alphabet.html"
  },
  "20": {
    "id": "20",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Annotated$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Annotated$.html"
  },
  "21": {
    "id": "21",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Annotated.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Annotated.html"
  },
  "22": {
    "id": "22",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation$$AnnotationContainer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation$$AnnotationContainer.html"
  },
  "23": {
    "id": "23",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation$$extractors$$AnnotationData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation$$extractors$$AnnotationData.html"
  },
  "24": {
    "id": "24",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation$$extractors$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation$$extractors$.html"
  },
  "25": {
    "id": "25",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation$.html"
  },
  "26": {
    "id": "26",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation.html"
  },
  "27": {
    "id": "27",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationAudio$$AnnotationContainer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationAudio$$AnnotationContainer.html"
  },
  "28": {
    "id": "28",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationAudio$$AudioFields.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationAudio$$AudioFields.html"
  },
  "29": {
    "id": "29",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationAudio$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationAudio$.html"
  },
  "30": {
    "id": "30",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationAudio.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationAudio.html"
  },
  "31": {
    "id": "31",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationImage$$AnnotationContainer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationImage$$AnnotationContainer.html"
  },
  "32": {
    "id": "32",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationImage$$ImageFields.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationImage$$ImageFields.html"
  },
  "33": {
    "id": "33",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationImage$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationImage$.html"
  },
  "34": {
    "id": "34",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationImage.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationImage.html"
  },
  "35": {
    "id": "35",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotatorApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotatorApproach.html"
  },
  "36": {
    "id": "36",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotatorModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotatorModel.html"
  },
  "37": {
    "id": "37",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam$SerializableFormat$$SerializableDateFormat.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam$SerializableFormat$$SerializableDateFormat.html"
  },
  "38": {
    "id": "38",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam$SerializableFormat$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam$SerializableFormat$.html"
  },
  "39": {
    "id": "39",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam.html"
  },
  "40": {
    "id": "40",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotatorType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotatorType$.html"
  },
  "41": {
    "id": "41",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/ArrayFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/ArrayFeature.html"
  },
  "42": {
    "id": "42",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/Attr.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/Attr.html"
  },
  "43": {
    "id": "43",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/AttrFeature.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/AttrFeature.html"
  },
  "44": {
    "id": "44",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/AttrStat.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/AttrStat.html"
  },
  "45": {
    "id": "45",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AudioAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AudioAssembler$.html"
  },
  "46": {
    "id": "46",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AudioAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AudioAssembler.html"
  },
  "47": {
    "id": "47",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/AveragedPerceptron.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/AveragedPerceptron.html"
  },
  "48": {
    "id": "48",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/Benchmark$.html",
    "relUrl": "/api/com/johnsnowlabs/util/Benchmark$.html"
  },
  "49": {
    "id": "49",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/BertEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/BertEmbeddings$.html"
  },
  "50": {
    "id": "50",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.html"
  },
  "51": {
    "id": "51",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering$.html"
  },
  "52": {
    "id": "52",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering.html"
  },
  "53": {
    "id": "53",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification$.html"
  },
  "54": {
    "id": "54",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification.html"
  },
  "55": {
    "id": "55",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification$.html"
  },
  "56": {
    "id": "56",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification.html"
  },
  "57": {
    "id": "57",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings$.html"
  },
  "58": {
    "id": "58",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.html"
  },
  "59": {
    "id": "59",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher$.html"
  },
  "60": {
    "id": "60",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher.html"
  },
  "61": {
    "id": "61",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel$.html"
  },
  "62": {
    "id": "62",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel.html"
  },
  "63": {
    "id": "63",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/BpeTokenizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/BpeTokenizer$.html"
  },
  "64": {
    "id": "64",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/Build$.html",
    "relUrl": "/api/com/johnsnowlabs/util/Build$.html"
  },
  "65": {
    "id": "65",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/BytesKey.html",
    "relUrl": "/api/com/johnsnowlabs/storage/BytesKey.html"
  },
  "66": {
    "id": "66",
    "title": "CPU NER Benchmarks",
    "content": "CPU NER Benchmarks NER (BiLSTM-CNN-Char Architecture) CPU Benchmark Experiment Dataset : 1000 Clinical Texts from MTSamples Oncology Dataset, approx. 500 tokens per text. Versions : spark-nlp Version: v3.4.4 spark-nlp-jsl Version : v3.5.2 Spark Version : v3.1.2 Spark NLP Pipeline : nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings_clinical, clinical_ner, ner_converter ]) NOTE: Spark NLP Pipeline output data frame (except word_embeddings column) was written as parquet format in transform benchmarks. Plarform Process Repartition Time 2 CPU cores, 13 GB RAM (Google COLAB) LP (fullAnnotate) - 16min 52s Transform (parquet) 10 4min 47s 100 4min 16s 1000 5min 4s 16 CPU cores, 27 GB RAM (AWS EC2 machine) LP (fullAnnotate) - 14min 28s Transform (parquet) 10 1min 5s 100 1min 1s 1000 1min 19s",
    "url": "/docs/en/cpu-ner-benchmark",
    "relUrl": "/docs/en/cpu-ner-benchmark"
  },
  "67": {
    "id": "67",
    "title": "GPU vs CPU benchmark",
    "content": "This section includes benchmarks for different Approach() (training classes), comparing their performance when running in m5.8xlarge CPU vs a Tesla V100 SXM2 GPU, as described in the Machine Specs section below. Different benchmarks, as well as their takeaways and some conclusions of how to get the best of GPU, are included as well, to guide you in the process of getting the best performance out of Spark NLP on GPU. Each major release comes with big improvements, so please, make sure you use at least that version to fully levearge Spark NLP capabilities on GPU. Machine specs CPU An AWS m5.8xlarge machine was used for the CPU benchmarking. This machine consists of 32 vCPUs and 128 GB of RAM, as you can check in the official specification webpage available here GPU A Tesla V100 SXM2 GPU with 32GB of memory was used to calculate the GPU benchmarking. Versions The benchmarking was carried out with the following Spark NLP versions: Spark version: 3.0.2 Hadoop version: 3.2.0 SparkNLP version: 3.3.4 Spark nodes: 1 Benchmark on classifierDLApproach() This experiment consisted of training a Deep Learning Binary Classifier (Question vs Statement classes) at sentence-level, using a fully connected CNN and Bert Sentence Embeddings. Only 1 Spark node was usd for the training. We used the Spark NLP class ClassifierDL and it’s method Approach() as described in the documentation. The pipeline looks as follows: Dataset The size of the dataset was relatively small (200K), consisting of: Training (rows): 162250 Test (rows): 40301 Training params Different batch sizes were tested to demonstrate how GPU performance improves with bigger batches compared to CPU, for a constant number of epochs and learning rate. Epochs: 10 Learning rate: 0.003 Batch sizes: 32, 64, 256, 1024 Results Even for this average-sized dataset, we can observe that GPU is able to beat the CPU machine by a 76% in both training and inference times. Training times depending on batch (in minutes) Batch size CPU GPU 32 66 16.1 64 65 15.3 256 64 14.5 1024 64 14 Inference times (in minutes) The average inference time remained more or less constant regardless the batch size: CPU: 8.7 min GPU: 2 min Performance metrics A weighted F1-score of 0.88 was achieved, with a 0.90 score for question detection and 0.83 for statements. Benchmark on NerDLApproach() This experiment consisted of training a Name Entity Recognition model (token-level), using our class NerDLApproach(), using Bert Word Embeddings and a Char-CNN-BiLSTM Neural Network. Only 1 Spark node was used for the training. We used the Spark NLP class NerDL and it’s method Approach() as described in the documentation. The pipeline looks as follows: Dataset The size of the dataset was small (17K), consisting of: Training (rows): 14041 Test (rows): 3250 Training params Different batch sizes were tested to demonstrate how GPU performance improves with bigger batches compared to CPU, for a constant number of epochs and learning rate. Epochs: 10 Learning rate: 0.003 Batch sizes: 32, 64, 256, 512, 1024, 2048 Results Even for this small dataset, we can observe that GPU is able to beat the CPU machine by a 62% in training time and a 68% in inference times. It’s important to mention that the batch size is very relevant when using GPU, since CPU scales much worse with bigger batch sizes than GPU. Training times depending on batch (in minutes) Batch size CPU GPU 32 9.5 10 64 8.1 6.5 256 6.9 3.5 512 6.7 3 1024 6.5 2.5 2048 6.5 2.5 Inference times (in minutes) Although CPU times in inference remain more or less constant regardless the batch sizes, GPU time experiment good improvements the bigger the batch size is. CPU times: ~29 min Batch size GPU 32 10 64 6.5 256 3.5 512 3 1024 2.5 2048 2.5 Performance metrics A macro F1-score of about 0.92 (0.90 in micro) was achieved, with the following charts extracted from the NERDLApproach() logs: Inference benchmark on BertSentenceEmbeddings() This experiment consisted of benchmarking the improvement obtained in inference by using GPU on BertSentenceEmbeddings(). We used the Spark NLP class BertSentenceEmbeddings() described in the Transformers documentation. The pipeline contains only two components and looks as follows: Dataset The size of the dataset was bigger than the previous ones, with 417735 rows for inference. Results We have observed in previous experiments, using BertSentenceEmbeddings (classifierDL) and also BertEmbeddings (NerDL) how GPU improved both training and inference times. In this case, we observe again big improvements in inference, what is already pointing that one of the main reasons of why GPU improves so much over CPU is the better management of Embeddings (word, sentence level) and bigger batch sizes. Batch sizes: 32, 64, 256, 1024 Inference times depending on batch (in minutes) Batch size CPU GPU 32 80 9.9 64 77 9.8 256 63 9.4 1024 62 9.1 Takeaways: How to get the best of the GPU You will experiment big GPU improvements in the following cases: Embeddings and Transformers are used in your pipeline. Take into consideration that GPU will performance very well in Embeddings / Transformer components, but other components of your pipeline may not leverage as well GPU capabilities; Bigger batch sizes get the best of GPU, while CPU does not scale with bigger batch sizes; Bigger dataset sizes get the best of GPU, while may be a bottleneck while running in CPU and lead to performance drops; MultiGPU training Right now, we don’t support multigpu training (1 model in different GPUs in parallel), but you can train different models in different GPU. Where to look for more information about Training Please, take a look at the Spark NLP and Spark NLP for Healthcare Training sections, and feel free to reach us out in case you want to maximize the performance on your GPU.",
    "url": "/docs/en/CPUvsGPUbenchmark",
    "relUrl": "/docs/en/CPUvsGPUbenchmark"
  },
  "68": {
    "id": "68",
    "title": "GPU vs CPU benchmark",
    "content": "This section includes a benchmark for MedicalNerApproach(), comparing its performance when running in m5.8xlarge CPU vs a Tesla V100 SXM2 GPU, as described in the Machine Specs section below. Big improvements have been carried out from version 3.3.4, so please, make sure you use at least that version to fully levearge Spark NLP capabilities on GPU. Machine specs CPU An AWS m5.8xlarge machine was used for the CPU benchmarking. This machine consists of 32 vCPUs and 128 GB of RAM, as you can check in the official specification webpage available here GPU A Tesla V100 SXM2 GPU with 32GB of memory was used to calculate the GPU benchmarking. Versions The benchmarking was carried out with the following Spark NLP versions: Spark version: 3.0.2 Hadoop version: 3.2.0 SparkNLP version: 3.3.4 SparkNLP for Healthcare version: 3.3.4 Spark nodes: 1 Benchmark on MedicalNerDLApproach() This experiment consisted of training a Name Entity Recognition model (token-level), using our class NerDLApproach(), using Bert Word Embeddings and a Char-CNN-BiLSTM Neural Network. Only 1 Spark node was used for the training. We used the Spark NLP class MedicalNer and it’s method Approach() as described in the documentation. The pipeline looks as follows: Dataset The size of the dataset was small (17K), consisting of: Training (rows): 14041 Test (rows): 3250 Training params Different batch sizes were tested to demonstrate how GPU performance improves with bigger batches compared to CPU, for a constant number of epochs and learning rate. Epochs: 10 Learning rate: 0.003 Batch sizes: 32, 64, 256, 512, 1024, 2048 Results Even for this small dataset, we can observe that GPU is able to beat the CPU machine by a 62% in training time and a 68% in inference times. It’s important to mention that the batch size is very relevant when using GPU, since CPU scales much worse with bigger batch sizes than GPU. Training times depending on batch (in minutes) Batch size CPU GPU 32 9.5 10 64 8.1 6.5 256 6.9 3.5 512 6.7 3 1024 6.5 2.5 2048 6.5 2.5 Inference times (in minutes) Although CPU times in inference remain more or less constant regardless the batch sizes, GPU time experiment good improvements the bigger the batch size is. CPU times: ~29 min Batch size GPU 32 10 64 6.5 256 3.5 512 3 1024 2.5 2048 2.5 Performance metrics A macro F1-score of about 0.92 (0.90 in micro) was achieved, with the following charts extracted from the MedicalNerApproach() logs: Takeaways: How to get the best of the GPU You will experiment big GPU improvements in the following cases: Embeddings and Transformers are used in your pipeline. Take into consideration that GPU will performance very well in Embeddings / Transformer components, but other components of your pipeline may not leverage as well GPU capabilities; Bigger batch sizes get the best of GPU, while CPU does not scale with bigger batch sizes; Bigger dataset sizes get the best of GPU, while may be a bottleneck while running in CPU and lead to performance drops; MultiGPU Inference on Databricks In this part, we will give you an idea on how to choose appropriate hardware specifications for Databricks. Here is a few different hardwares, their prices, as well as their performance: Apparently, GPU hardware is the cheapest among them although it performs the best. Let’s see how overall performance looks like: Figure above clearly shows us that GPU should be the first option of ours. In conclusion, please find the best specifications for your use case since these benchmarks might depend on dataset size, inference batch size, quickness, pricing and so on. Please refer to this video for further info: https://events.johnsnowlabs.com/webinar-speed-optimization-benchmarks-in-spark-nlp-3-making-the-most-of-modern-hardware?hsCtaTracking=a9bb6358-92bd-4cf3-b97c-e76cb1dfb6ef%7C4edba435-1adb-49fc-83fd-891a7506a417 MultiGPU training Currently, we don’t support multiGPU training, meaning training 1 model in different GPUs in parallel. However, you can train different models in different GPUs. MultiGPU inference Spark NLP can carry out MultiGPU inference if GPUs are in different cluster nodes. For example, if you have a cluster with different GPUs, you can repartition your data to match the number of GPU nodes and then coalesce to retrieve the results back to the master node. Currently, inference on multiple GPUs on the same machine is not supported. Where to look for more information about Training Please, take a look at the Spark NLP and Spark NLP for Healthcare Training sections, and feel free to reach us out in case you want to maximize the performance on your GPU.",
    "url": "/docs/en/CPUvsGPUbenchmark_healthcare",
    "relUrl": "/docs/en/CPUvsGPUbenchmark_healthcare"
  },
  "69": {
    "id": "69",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings$.html"
  },
  "70": {
    "id": "70",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings.html"
  },
  "71": {
    "id": "71",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering$.html"
  },
  "72": {
    "id": "72",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering.html"
  },
  "73": {
    "id": "73",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification$.html"
  },
  "74": {
    "id": "74",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification.html"
  },
  "75": {
    "id": "75",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification$.html"
  },
  "76": {
    "id": "76",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification.html"
  },
  "77": {
    "id": "77",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/CanBeLazy.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/CanBeLazy.html"
  },
  "78": {
    "id": "78",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/CandidateStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/CandidateStrategy$.html"
  },
  "79": {
    "id": "79",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Chunk2Doc$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Chunk2Doc$.html"
  },
  "80": {
    "id": "80",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Chunk2Doc.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Chunk2Doc.html"
  },
  "81": {
    "id": "81",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings$.html"
  },
  "82": {
    "id": "82",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings.html"
  },
  "83": {
    "id": "83",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/ChunkSplit$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/ChunkSplit$.html"
  },
  "84": {
    "id": "84",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizer$.html"
  },
  "85": {
    "id": "85",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizer.html"
  },
  "86": {
    "id": "86",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel$.html"
  },
  "87": {
    "id": "87",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel.html"
  },
  "88": {
    "id": "88",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Chunker$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Chunker$.html"
  },
  "89": {
    "id": "89",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Chunker.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Chunker.html"
  },
  "90": {
    "id": "90",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach$.html"
  },
  "91": {
    "id": "91",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach.html"
  },
  "92": {
    "id": "92",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel$.html"
  },
  "93": {
    "id": "93",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.html"
  },
  "94": {
    "id": "94",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/ClassifierDatasetEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/ClassifierDatasetEncoder.html"
  },
  "95": {
    "id": "95",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/ClassifierDatasetEncoderParams.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/ClassifierDatasetEncoderParams.html"
  },
  "96": {
    "id": "96",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierEncoder.html"
  },
  "97": {
    "id": "97",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierMetrics.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierMetrics.html"
  },
  "98": {
    "id": "98",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLL.html"
  },
  "99": {
    "id": "99",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLL2003NerReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLL2003NerReader.html"
  },
  "100": {
    "id": "100",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLDocument.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLDocument.html"
  },
  "101": {
    "id": "101",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/CoNLLGenerator$.html",
    "relUrl": "/api/com/johnsnowlabs/util/CoNLLGenerator$.html"
  },
  "102": {
    "id": "102",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$$CoNLLSentenceCols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$$CoNLLSentenceCols.html"
  },
  "103": {
    "id": "103",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$$CoNLLTokenCols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$$CoNLLTokenCols.html"
  },
  "104": {
    "id": "104",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$.html"
  },
  "105": {
    "id": "105",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLU.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLU.html"
  },
  "106": {
    "id": "106",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLUCols$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLUCols$.html"
  },
  "107": {
    "id": "107",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLUDocument.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLUDocument.html"
  },
  "108": {
    "id": "108",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Collector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Collector.html"
  },
  "109": {
    "id": "109",
    "title": "",
    "content": "",
    "url": "/api/python/third_party/Comet.html",
    "relUrl": "/api/python/third_party/Comet.html"
  },
  "110": {
    "id": "110",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/ConfigHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/util/ConfigHelper$.html"
  },
  "111": {
    "id": "111",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/ConfigLoader$.html",
    "relUrl": "/api/com/johnsnowlabs/util/ConfigLoader$.html"
  },
  "112": {
    "id": "112",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/Conll09Reader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/Conll09Reader.html"
  },
  "113": {
    "id": "113",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/ConllData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/ConllData.html"
  },
  "114": {
    "id": "114",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/ConllSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/ConllSentence.html"
  },
  "115": {
    "id": "115",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/ConllUReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/ConllUReader.html"
  },
  "116": {
    "id": "116",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/ConllWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/ConllWriter.html"
  },
  "117": {
    "id": "117",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach$ArrayHelper.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach$ArrayHelper.html"
  },
  "118": {
    "id": "118",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach.html"
  },
  "119": {
    "id": "119",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel$.html"
  },
  "120": {
    "id": "120",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel$StringTools.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel$StringTools.html"
  },
  "121": {
    "id": "121",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel.html"
  },
  "122": {
    "id": "122",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/CredentialParams.html",
    "relUrl": "/api/com/johnsnowlabs/client/CredentialParams.html"
  },
  "123": {
    "id": "123",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/Credentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/Credentials.html"
  },
  "124": {
    "id": "124",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/CrfDataset.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/CrfDataset.html"
  },
  "125": {
    "id": "125",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/CrfParams.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/CrfParams.html"
  },
  "126": {
    "id": "126",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/CustomPragmaticMethod.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/CustomPragmaticMethod.html"
  },
  "127": {
    "id": "127",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/Database$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/Database$.html"
  },
  "128": {
    "id": "128",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/Database.html",
    "relUrl": "/api/com/johnsnowlabs/storage/Database.html"
  },
  "129": {
    "id": "129",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/DatasetEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/DatasetEncoder.html"
  },
  "130": {
    "id": "130",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/DatasetEncoderParams.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/DatasetEncoderParams.html"
  },
  "131": {
    "id": "131",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/DatasetHelpers$$DataFrameHelper.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/DatasetHelpers$$DataFrameHelper.html"
  },
  "132": {
    "id": "132",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/DatasetHelpers$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/DatasetHelpers$.html"
  },
  "133": {
    "id": "133",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/DatasetMetadata.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/DatasetMetadata.html"
  },
  "134": {
    "id": "134",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/DatasetReader$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/DatasetReader$.html"
  },
  "135": {
    "id": "135",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Date2Chunk$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Date2Chunk$.html"
  },
  "136": {
    "id": "136",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Date2Chunk.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Date2Chunk.html"
  },
  "137": {
    "id": "137",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcher$.html"
  },
  "138": {
    "id": "138",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcher.html"
  },
  "139": {
    "id": "139",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherTranslator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherTranslator.html"
  },
  "140": {
    "id": "140",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherTranslatorPolicy.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherTranslatorPolicy.html"
  },
  "141": {
    "id": "141",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherUtils.html"
  },
  "142": {
    "id": "142",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/DateToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/DateToken.html"
  },
  "143": {
    "id": "143",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/ai/DeBerta.html",
    "relUrl": "/api/com/johnsnowlabs/ml/ai/DeBerta.html"
  },
  "144": {
    "id": "144",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings$.html"
  },
  "145": {
    "id": "145",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings.html"
  },
  "146": {
    "id": "146",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering$.html"
  },
  "147": {
    "id": "147",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering.html"
  },
  "148": {
    "id": "148",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification$.html"
  },
  "149": {
    "id": "149",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification.html"
  },
  "150": {
    "id": "150",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification$.html"
  },
  "151": {
    "id": "151",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification.html"
  },
  "152": {
    "id": "152",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/DefaultPragmaticMethod.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/DefaultPragmaticMethod.html"
  },
  "153": {
    "id": "153",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyArcList.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyArcList.html"
  },
  "154": {
    "id": "154",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyInstance.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyInstance.html"
  },
  "155": {
    "id": "155",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/DependencyLabel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/DependencyLabel.html"
  },
  "156": {
    "id": "156",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$.html"
  },
  "157": {
    "id": "157",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$CurrentState.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$CurrentState.html"
  },
  "158": {
    "id": "158",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$ParseState.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$ParseState.html"
  },
  "159": {
    "id": "159",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker.html"
  },
  "160": {
    "id": "160",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/DependencyParsed$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/DependencyParsed$.html"
  },
  "161": {
    "id": "161",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/DependencyParsedSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/DependencyParsedSentence.html"
  },
  "162": {
    "id": "162",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach$.html"
  },
  "163": {
    "id": "163",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach.html"
  },
  "164": {
    "id": "164",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel$.html"
  },
  "165": {
    "id": "165",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel.html"
  },
  "166": {
    "id": "166",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyPipe.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyPipe.html"
  },
  "167": {
    "id": "167",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/DependencyReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/DependencyReader.html"
  },
  "168": {
    "id": "168",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Dictionary.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Dictionary.html"
  },
  "169": {
    "id": "169",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/DictionaryFeatures$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/DictionaryFeatures$.html"
  },
  "170": {
    "id": "170",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/DictionaryFeatures.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/DictionaryFeatures.html"
  },
  "171": {
    "id": "171",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/DictionarySet.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/DictionarySet.html"
  },
  "172": {
    "id": "172",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings$.html"
  },
  "173": {
    "id": "173",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings.html"
  },
  "174": {
    "id": "174",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering$.html"
  },
  "175": {
    "id": "175",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering.html"
  },
  "176": {
    "id": "176",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification$.html"
  },
  "177": {
    "id": "177",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification.html"
  },
  "178": {
    "id": "178",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification$.html"
  },
  "179": {
    "id": "179",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification.html"
  },
  "180": {
    "id": "180",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Doc2Chunk$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Doc2Chunk$.html"
  },
  "181": {
    "id": "181",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Doc2Chunk.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Doc2Chunk.html"
  },
  "182": {
    "id": "182",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach$.html"
  },
  "183": {
    "id": "183",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach.html"
  },
  "184": {
    "id": "184",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecModel$.html"
  },
  "185": {
    "id": "185",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecModel.html"
  },
  "186": {
    "id": "186",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/DocumentAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/DocumentAssembler$.html"
  },
  "187": {
    "id": "187",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/DocumentAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/DocumentAssembler.html"
  },
  "188": {
    "id": "188",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DocumentNormalizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DocumentNormalizer$.html"
  },
  "189": {
    "id": "189",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DocumentNormalizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DocumentNormalizer.html"
  },
  "190": {
    "id": "190",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/EdgeCalculator$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/EdgeCalculator$.html"
  },
  "191": {
    "id": "191",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings$.html"
  },
  "192": {
    "id": "192",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings.html"
  },
  "193": {
    "id": "193",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/EmbeddingsCoverage$CoverageResult.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/EmbeddingsCoverage$CoverageResult.html"
  },
  "194": {
    "id": "194",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/EmbeddingsCoverage.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/EmbeddingsCoverage.html"
  },
  "195": {
    "id": "195",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/EmbeddingsFinisher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/EmbeddingsFinisher$.html"
  },
  "196": {
    "id": "196",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/EmbeddingsFinisher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/EmbeddingsFinisher.html"
  },
  "197": {
    "id": "197",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/EmbeddingsWithSentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/EmbeddingsWithSentence$.html"
  },
  "198": {
    "id": "198",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/EnglishStemmer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/EnglishStemmer$.html"
  },
  "199": {
    "id": "199",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityPattern.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityPattern.html"
  },
  "200": {
    "id": "200",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerApproach.html"
  },
  "201": {
    "id": "201",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerFeatures.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerFeatures.html"
  },
  "202": {
    "id": "202",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel$.html"
  },
  "203": {
    "id": "203",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel.html"
  },
  "204": {
    "id": "204",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerUtil$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerUtil$.html"
  },
  "205": {
    "id": "205",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/EvaluationDLParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/EvaluationDLParams.html"
  },
  "206": {
    "id": "206",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ExternalResource$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ExternalResource$.html"
  },
  "207": {
    "id": "207",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ExternalResource.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ExternalResource.html"
  },
  "208": {
    "id": "208",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/ExternalResourceParam.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/ExternalResourceParam.html"
  },
  "209": {
    "id": "209",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/FbCalculator.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/FbCalculator.html"
  },
  "210": {
    "id": "210",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/Feature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/Feature.html"
  },
  "211": {
    "id": "211",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/FeatureGenerator$TokenType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/FeatureGenerator$TokenType$.html"
  },
  "212": {
    "id": "212",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/FeatureGenerator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/FeatureGenerator.html"
  },
  "213": {
    "id": "213",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/FeatureTemplate.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/FeatureTemplate.html"
  },
  "214": {
    "id": "214",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/FeatureVector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/FeatureVector.html"
  },
  "215": {
    "id": "215",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/FeaturesReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/FeaturesReader.html"
  },
  "216": {
    "id": "216",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/FeaturesWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/FeaturesWriter.html"
  },
  "217": {
    "id": "217",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/FileHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/util/FileHelper$.html"
  },
  "218": {
    "id": "218",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Finisher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Finisher$.html"
  },
  "219": {
    "id": "219",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Finisher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Finisher.html"
  },
  "220": {
    "id": "220",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/FinisherUtil$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/FinisherUtil$.html"
  },
  "221": {
    "id": "221",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/FlattenEntityPattern.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/FlattenEntityPattern.html"
  },
  "222": {
    "id": "222",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/gcp/GCPGateway.html",
    "relUrl": "/api/com/johnsnowlabs/client/gcp/GCPGateway.html"
  },
  "223": {
    "id": "223",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer$.html"
  },
  "224": {
    "id": "224",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer.html"
  },
  "225": {
    "id": "225",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/GenericRegexParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/GenericRegexParser.html"
  },
  "226": {
    "id": "226",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/GenericVocabParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/GenericVocabParser.html"
  },
  "227": {
    "id": "227",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/Gpt2Tokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/Gpt2Tokenizer.html"
  },
  "228": {
    "id": "228",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/GraphBuilder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/GraphBuilder.html"
  },
  "229": {
    "id": "229",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/GraphExtraction.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/GraphExtraction.html"
  },
  "230": {
    "id": "230",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/GraphFinisher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/GraphFinisher.html"
  },
  "231": {
    "id": "231",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/GreedyTransitionApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/GreedyTransitionApproach$.html"
  },
  "232": {
    "id": "232",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasAudioFeatureProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasAudioFeatureProperties.html"
  },
  "233": {
    "id": "233",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotate.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotate.html"
  },
  "234": {
    "id": "234",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotateAudio.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotateAudio.html"
  },
  "235": {
    "id": "235",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotateImage.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotateImage.html"
  },
  "236": {
    "id": "236",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasCaseSensitiveProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasCaseSensitiveProperties.html"
  },
  "237": {
    "id": "237",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasClassifierActivationProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasClassifierActivationProperties.html"
  },
  "238": {
    "id": "238",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasConnection.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasConnection.html"
  },
  "239": {
    "id": "239",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/HasEmbeddingsProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/HasEmbeddingsProperties.html"
  },
  "240": {
    "id": "240",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasEnableCachingProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasEnableCachingProperties.html"
  },
  "241": {
    "id": "241",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasEngine.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasEngine.html"
  },
  "242": {
    "id": "242",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasFeatures.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasFeatures.html"
  },
  "243": {
    "id": "243",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasImageFeatureProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasImageFeatureProperties.html"
  },
  "244": {
    "id": "244",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasInputAnnotationCols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasInputAnnotationCols.html"
  },
  "245": {
    "id": "245",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasMultipleInputAnnotationCols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasMultipleInputAnnotationCols.html"
  },
  "246": {
    "id": "246",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasOutputAnnotationCol.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasOutputAnnotationCol.html"
  },
  "247": {
    "id": "247",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasOutputAnnotatorType.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasOutputAnnotatorType.html"
  },
  "248": {
    "id": "248",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasPretrained.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasPretrained.html"
  },
  "249": {
    "id": "249",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasRecursiveFit.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasRecursiveFit.html"
  },
  "250": {
    "id": "250",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasRecursiveTransform.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasRecursiveTransform.html"
  },
  "251": {
    "id": "251",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasSimpleAnnotate.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasSimpleAnnotate.html"
  },
  "252": {
    "id": "252",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorage.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorage.html"
  },
  "253": {
    "id": "253",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageModel.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageModel.html"
  },
  "254": {
    "id": "254",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageOptions.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageOptions.html"
  },
  "255": {
    "id": "255",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageReader.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageReader.html"
  },
  "256": {
    "id": "256",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageRef$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageRef$.html"
  },
  "257": {
    "id": "257",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageRef.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageRef.html"
  },
  "258": {
    "id": "258",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/HasTransducerFeatures.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/HasTransducerFeatures.html"
  },
  "259": {
    "id": "259",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC$.html"
  },
  "260": {
    "id": "260",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC.html"
  },
  "261": {
    "id": "261",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/IAnnotation.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/IAnnotation.html"
  },
  "262": {
    "id": "262",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ImageAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ImageAssembler$.html"
  },
  "263": {
    "id": "263",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ImageAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ImageAssembler.html"
  },
  "264": {
    "id": "264",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/IndexedTaggedWord.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/IndexedTaggedWord.html"
  },
  "265": {
    "id": "265",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/IndexedToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/IndexedToken.html"
  },
  "266": {
    "id": "266",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/InfixToken$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/InfixToken$.html"
  },
  "267": {
    "id": "267",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/InfixToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/InfixToken.html"
  },
  "268": {
    "id": "268",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/Instance.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/Instance.html"
  },
  "269": {
    "id": "269",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/InstanceLabels.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/InstanceLabels.html"
  },
  "270": {
    "id": "270",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/JavaAnnotation.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/JavaAnnotation.html"
  },
  "271": {
    "id": "271",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/JsonParser$.html",
    "relUrl": "/api/com/johnsnowlabs/util/JsonParser$.html"
  },
  "272": {
    "id": "272",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/L2DecayStrategy.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/L2DecayStrategy.html"
  },
  "273": {
    "id": "273",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/LabeledDependency$$DependencyInfo.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/LabeledDependency$$DependencyInfo.html"
  },
  "274": {
    "id": "274",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/LabeledDependency$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/LabeledDependency$.html"
  },
  "275": {
    "id": "275",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/LangModelSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/LangModelSentence.html"
  },
  "276": {
    "id": "276",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL$.html"
  },
  "277": {
    "id": "277",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.html"
  },
  "278": {
    "id": "278",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Lemmatizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Lemmatizer$.html"
  },
  "279": {
    "id": "279",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Lemmatizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Lemmatizer.html"
  },
  "280": {
    "id": "280",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel$.html"
  },
  "281": {
    "id": "281",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel.html"
  },
  "282": {
    "id": "282",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LfuCache$CachedItem.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LfuCache$CachedItem.html"
  },
  "283": {
    "id": "283",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LfuCache$DoubleLinked.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LfuCache$DoubleLinked.html"
  },
  "284": {
    "id": "284",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LfuCache$FrequencyList.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LfuCache$FrequencyList.html"
  },
  "285": {
    "id": "285",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LfuCache.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LfuCache.html"
  },
  "286": {
    "id": "286",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/LightPipeline.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/LightPipeline.html"
  },
  "287": {
    "id": "287",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/LinearChainCrf.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/LinearChainCrf.html"
  },
  "288": {
    "id": "288",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/LinearChainCrfModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/LinearChainCrfModel.html"
  },
  "289": {
    "id": "289",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/util/LoadExternalModel$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/util/LoadExternalModel$.html"
  },
  "290": {
    "id": "290",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/LoadsContrib$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/LoadsContrib$.html"
  },
  "291": {
    "id": "291",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/LocalFeatureData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/LocalFeatureData.html"
  },
  "292": {
    "id": "292",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/LocationClass.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/LocationClass.html"
  },
  "293": {
    "id": "293",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/Logging.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/Logging.html"
  },
  "294": {
    "id": "294",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/spark/LongMapAccumulator.html",
    "relUrl": "/api/com/johnsnowlabs/util/spark/LongMapAccumulator.html"
  },
  "295": {
    "id": "295",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings$.html"
  },
  "296": {
    "id": "296",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings.html"
  },
  "297": {
    "id": "297",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering$.html"
  },
  "298": {
    "id": "298",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering.html"
  },
  "299": {
    "id": "299",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification$.html"
  },
  "300": {
    "id": "300",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification.html"
  },
  "301": {
    "id": "301",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification$.html"
  },
  "302": {
    "id": "302",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification.html"
  },
  "303": {
    "id": "303",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/LookAroundManager$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/LookAroundManager$.html"
  },
  "304": {
    "id": "304",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/LowRankTensor.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/LowRankTensor.html"
  },
  "305": {
    "id": "305",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LruMap$KeyPriority.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LruMap$KeyPriority.html"
  },
  "306": {
    "id": "306",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LruMap$KeyPriorityOrdering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LruMap$KeyPriorityOrdering$.html"
  },
  "307": {
    "id": "307",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LruMap.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LruMap.html"
  },
  "308": {
    "id": "308",
    "title": "",
    "content": "",
    "url": "/api/python/third_party/MLflow.html",
    "relUrl": "/api/python/third_party/MLflow.html"
  },
  "309": {
    "id": "309",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/MainVocab.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/MainVocab.html"
  },
  "310": {
    "id": "310",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/spark/MapAccumulator.html",
    "relUrl": "/api/com/johnsnowlabs/util/spark/MapAccumulator.html"
  },
  "311": {
    "id": "311",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/MapFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/MapFeature.html"
  },
  "312": {
    "id": "312",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer$.html"
  },
  "313": {
    "id": "313",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer.html"
  },
  "314": {
    "id": "314",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/MatchStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/MatchStrategy$.html"
  },
  "315": {
    "id": "315",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/MedicationClass.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/MedicationClass.html"
  },
  "316": {
    "id": "316",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/ai/MergeTokenStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/ai/MergeTokenStrategy$.html"
  },
  "317": {
    "id": "317",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/Metrics.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/Metrics.html"
  },
  "318": {
    "id": "318",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/MixedPragmaticMethod.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/MixedPragmaticMethod.html"
  },
  "319": {
    "id": "319",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/util/ModelEngine$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/util/ModelEngine$.html"
  },
  "320": {
    "id": "320",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/ModelMetrics$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/ModelMetrics$.html"
  },
  "321": {
    "id": "321",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/ModelSignature.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/ModelSignature.html"
  },
  "322": {
    "id": "322",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AttentionMask$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AttentionMask$.html"
  },
  "323": {
    "id": "323",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AttentionMaskV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AttentionMaskV1$.html"
  },
  "324": {
    "id": "324",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AudioValuesInput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AudioValuesInput$.html"
  },
  "325": {
    "id": "325",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DType$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DType$.html"
  },
  "326": {
    "id": "326",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderAttentionMask$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderAttentionMask$.html"
  },
  "327": {
    "id": "327",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderEncoderAttentionMask$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderEncoderAttentionMask$.html"
  },
  "328": {
    "id": "328",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderEncoderInputIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderEncoderInputIds$.html"
  },
  "329": {
    "id": "329",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderInputIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderInputIds$.html"
  },
  "330": {
    "id": "330",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderOutput$.html"
  },
  "331": {
    "id": "331",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DimCount$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DimCount$.html"
  },
  "332": {
    "id": "332",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderAttentionMask$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderAttentionMask$.html"
  },
  "333": {
    "id": "333",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderInputIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderInputIds$.html"
  },
  "334": {
    "id": "334",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderOutput$.html"
  },
  "335": {
    "id": "335",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EndLogitsOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EndLogitsOutput$.html"
  },
  "336": {
    "id": "336",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$InputIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$InputIds$.html"
  },
  "337": {
    "id": "337",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$InputIdsV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$InputIdsV1$.html"
  },
  "338": {
    "id": "338",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LastHiddenState$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LastHiddenState$.html"
  },
  "339": {
    "id": "339",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LastHiddenStateV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LastHiddenStateV1$.html"
  },
  "340": {
    "id": "340",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LogitsOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LogitsOutput$.html"
  },
  "341": {
    "id": "341",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$Name$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$Name$.html"
  },
  "342": {
    "id": "342",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PixelValuesInput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PixelValuesInput$.html"
  },
  "343": {
    "id": "343",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PoolerOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PoolerOutput$.html"
  },
  "344": {
    "id": "344",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PoolerOutputV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PoolerOutputV1$.html"
  },
  "345": {
    "id": "345",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$SerializedSize$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$SerializedSize$.html"
  },
  "346": {
    "id": "346",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$ShapeDimList$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$ShapeDimList$.html"
  },
  "347": {
    "id": "347",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$StartLogitsOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$StartLogitsOutput$.html"
  },
  "348": {
    "id": "348",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TFInfoDescriptor.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TFInfoDescriptor.html"
  },
  "349": {
    "id": "349",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TFInfoNameMapper.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TFInfoNameMapper.html"
  },
  "350": {
    "id": "350",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TapasLogitsAggregationOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TapasLogitsAggregationOutput$.html"
  },
  "351": {
    "id": "351",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TapasLogitsOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TapasLogitsOutput$.html"
  },
  "352": {
    "id": "352",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TokenTypeIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TokenTypeIds$.html"
  },
  "353": {
    "id": "353",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TokenTypeIdsV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TokenTypeIdsV1$.html"
  },
  "354": {
    "id": "354",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$.html"
  },
  "355": {
    "id": "355",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureManager$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureManager$.html"
  },
  "356": {
    "id": "356",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLApproach.html"
  },
  "357": {
    "id": "357",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel$.html"
  },
  "358": {
    "id": "358",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.html"
  },
  "359": {
    "id": "359",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/MultiDateMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/MultiDateMatcher$.html"
  },
  "360": {
    "id": "360",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/MultiDateMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/MultiDateMatcher.html"
  },
  "361": {
    "id": "361",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/MultiDatePolicy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/MultiDatePolicy$.html"
  },
  "362": {
    "id": "362",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/MultiDocumentAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/MultiDocumentAssembler$.html"
  },
  "363": {
    "id": "363",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/MultiDocumentAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/MultiDocumentAssembler.html"
  },
  "364": {
    "id": "364",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NGramGenerator$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NGramGenerator$.html"
  },
  "365": {
    "id": "365",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NGramGenerator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NGramGenerator.html"
  },
  "366": {
    "id": "366",
    "title": "NLU under the hood",
    "content": "This page acts as reference on the internal working and implementation of NLU. It acts as a reference for internal development and open source contributers. How do NLU internals work? NLU defines a universe of components which act as building blocks of user definable machine learning pipelines. The possibilities of creating unique and useful pipelines with NLU are only limited by onces imagination and RAM. The NLU component universe There are many different types of Components in the NLU universe. Each of the components acts as a wrapper around multiple different Spark NLP transformers. NLU spellbook NLU defines a mapping for every of its model references to a specific Spark NLP model, pipeline or annotator. You can view the mapping in the [TODO] file . If no model is found, NLU will ping the John Snow Labs modelhub for any new models. If the modelhub cannot resolve a Spark NLP reference for a NLU reference. NLU whill throw an exception, indicating that a component could not be resolved. If the NLU reference points to a Spark NLP pipeline, it will unpack each model from the Spark NLP pipeline and and package it inside of corrosponding NLU components. NLU pipeline building steps A NLU pipeline object cann either be created via the nlu.load(‘nlu.reference’) API or alternatively via the nlu.build([Component1,Component2]) API. The pipeline will not start its building steps until the .predict() function is called for the first time on it. When .predict() is called, the following steps occur Check for every NLU component, wether all its inputs are satisfied. I.e. if a user builds a pipeline with a classifier model in it but does not provide any embeddings. NLU will auto resolve the correct embeddings for the passed model Check and fix for every model if the input names align with the output names of the components they depend on. Check and fix for every model that it is in the correct order in the pipeline. I.e. a sentence classifier must come after the sentence embeddings are generated in the pipeline, not before. NLU output generation steps The .predict() method invokes a series of steps to ensure that the generated output is in the most usable format for further downstream ML tasks. The steps are the following : NLU converts the input data to a Spark Dataframe and lets the pipeline transform it to a new Spark Dataframe which contains all the features If the output level is not set by the user, it will check what is the last component of the pipe and the infer from that what the output level should be. Each components default output level can be viewed in its corrosponding component.json file. Some components output level depend on their input, i.e classifiers can classify on sentences or documents. NLU does additional steps to infer the output level for these kinds of components. Decide which columns to keep and which to drop All the output columns that are at the same outputlevel as the pipe will be zipped and exploded. All columns which are at diferent output level will be selected from the Spark Dataframe, which results in lists in the final output. After all these steps the final pandas dataframe will be returned from the .predict() method",
    "url": "/docs/en/jsl/under_the_hood",
    "relUrl": "/docs/en/jsl/under_the_hood"
  },
  "367": {
    "id": "367",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NamedEntity.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NamedEntity.html"
  },
  "368": {
    "id": "368",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/NamesClass.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/NamesClass.html"
  },
  "369": {
    "id": "369",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerApproach.html"
  },
  "370": {
    "id": "370",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/NerBatch$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/NerBatch$.html"
  },
  "371": {
    "id": "371",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/NerBatch.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/NerBatch.html"
  },
  "372": {
    "id": "372",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter$.html"
  },
  "373": {
    "id": "373",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter.html"
  },
  "374": {
    "id": "374",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach$.html"
  },
  "375": {
    "id": "375",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach.html"
  },
  "376": {
    "id": "376",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel$.html"
  },
  "377": {
    "id": "377",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel.html"
  },
  "378": {
    "id": "378",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach$.html"
  },
  "379": {
    "id": "379",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach.html"
  },
  "380": {
    "id": "380",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel$.html"
  },
  "381": {
    "id": "381",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.html"
  },
  "382": {
    "id": "382",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModelPythonReader$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModelPythonReader$.html"
  },
  "383": {
    "id": "383",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/NerDatasetEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/NerDatasetEncoder.html"
  },
  "384": {
    "id": "384",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter$.html"
  },
  "385": {
    "id": "385",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter.html"
  },
  "386": {
    "id": "386",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/NerTagged$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/NerTagged$.html"
  },
  "387": {
    "id": "387",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerTagsEncoding$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerTagsEncoding$.html"
  },
  "388": {
    "id": "388",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Normalizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Normalizer$.html"
  },
  "389": {
    "id": "389",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Normalizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Normalizer.html"
  },
  "390": {
    "id": "390",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel$.html"
  },
  "391": {
    "id": "391",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel$TokenizerAndNormalizerMap.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel$TokenizerAndNormalizerMap.html"
  },
  "392": {
    "id": "392",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel.html"
  },
  "393": {
    "id": "393",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach$.html"
  },
  "394": {
    "id": "394",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach.html"
  },
  "395": {
    "id": "395",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel$.html"
  },
  "396": {
    "id": "396",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel.html"
  },
  "397": {
    "id": "397",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingParams.html"
  },
  "398": {
    "id": "398",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/NumberToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/NumberToken.html"
  },
  "399": {
    "id": "399",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/Options.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/Options.html"
  },
  "400": {
    "id": "400",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/OutputHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/OutputHelper$.html"
  },
  "401": {
    "id": "401",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/POS.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/POS.html"
  },
  "402": {
    "id": "402",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/Parameters.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/Parameters.html"
  },
  "403": {
    "id": "403",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ParamsAndFeaturesReadable.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ParamsAndFeaturesReadable.html"
  },
  "404": {
    "id": "404",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ParamsAndFeaturesWritable.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ParamsAndFeaturesWritable.html"
  },
  "405": {
    "id": "405",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/PatternsReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/PatternsReadWriter.html"
  },
  "406": {
    "id": "406",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/PatternsReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/PatternsReader.html"
  },
  "407": {
    "id": "407",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Perceptron$WeightLearner.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Perceptron$WeightLearner.html"
  },
  "408": {
    "id": "408",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Perceptron.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Perceptron.html"
  },
  "409": {
    "id": "409",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach$.html"
  },
  "410": {
    "id": "410",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach.html"
  },
  "411": {
    "id": "411",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproachDistributed$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproachDistributed$.html"
  },
  "412": {
    "id": "412",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproachDistributed.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproachDistributed.html"
  },
  "413": {
    "id": "413",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel$.html"
  },
  "414": {
    "id": "414",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.html"
  },
  "415": {
    "id": "415",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronPredictionUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronPredictionUtils.html"
  },
  "416": {
    "id": "416",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronTrainingUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronTrainingUtils.html"
  },
  "417": {
    "id": "417",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronUtils.html"
  },
  "418": {
    "id": "418",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/PipelineModels$.html",
    "relUrl": "/api/com/johnsnowlabs/util/PipelineModels$.html"
  },
  "419": {
    "id": "419",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/PoolingStrategy$$AnnotatorType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/PoolingStrategy$$AnnotatorType$.html"
  },
  "420": {
    "id": "420",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/PoolingStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/PoolingStrategy$.html"
  },
  "421": {
    "id": "421",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/PosTagged$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/PosTagged$.html"
  },
  "422": {
    "id": "422",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticContentFormatter$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticContentFormatter$.html"
  },
  "423": {
    "id": "423",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticContentFormatter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticContentFormatter.html"
  },
  "424": {
    "id": "424",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticDictionaries$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticDictionaries$.html"
  },
  "425": {
    "id": "425",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticMethod.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticMethod.html"
  },
  "426": {
    "id": "426",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/PragmaticScorer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/PragmaticScorer.html"
  },
  "427": {
    "id": "427",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticSentenceExtractor.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticSentenceExtractor.html"
  },
  "428": {
    "id": "428",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticSymbols$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticSymbols$.html"
  },
  "429": {
    "id": "429",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/PredictionParameters.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/PredictionParameters.html"
  },
  "430": {
    "id": "430",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/PrefixedToken$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/PrefixedToken$.html"
  },
  "431": {
    "id": "431",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/PrefixedToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/PrefixedToken.html"
  },
  "432": {
    "id": "432",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/PreprocessingParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/PreprocessingParser.html"
  },
  "433": {
    "id": "433",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/PretrainedAnnotations$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/PretrainedAnnotations$.html"
  },
  "434": {
    "id": "434",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/PretrainedPipeline$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/PretrainedPipeline$.html"
  },
  "435": {
    "id": "435",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/PretrainedPipeline.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/PretrainedPipeline.html"
  },
  "436": {
    "id": "436",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/PubTator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/PubTator.html"
  },
  "437": {
    "id": "437",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/PythonResourceDownloader$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/PythonResourceDownloader$.html"
  },
  "438": {
    "id": "438",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/RawAnnotator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/RawAnnotator.html"
  },
  "439": {
    "id": "439",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadAlbertDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadAlbertDLModel.html"
  },
  "440": {
    "id": "440",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForQuestionAnsweringDLModel.html"
  },
  "441": {
    "id": "441",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForSequenceDLModel.html"
  },
  "442": {
    "id": "442",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForTokenDLModel.html"
  },
  "443": {
    "id": "443",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ReadAs$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ReadAs$.html"
  },
  "444": {
    "id": "444",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadBertDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadBertDLModel.html"
  },
  "445": {
    "id": "445",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForQuestionAnsweringDLModel.html"
  },
  "446": {
    "id": "446",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForSequenceDLModel.html"
  },
  "447": {
    "id": "447",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForTokenDLModel.html"
  },
  "448": {
    "id": "448",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadBertSentenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadBertSentenceDLModel.html"
  },
  "449": {
    "id": "449",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadCamemBertDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadCamemBertDLModel.html"
  },
  "450": {
    "id": "450",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForQADLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForQADLModel.html"
  },
  "451": {
    "id": "451",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForSequenceDLModel.html"
  },
  "452": {
    "id": "452",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForTokenDLModel.html"
  },
  "453": {
    "id": "453",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadClassifierDLTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadClassifierDLTensorflowModel.html"
  },
  "454": {
    "id": "454",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadDeBertaDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadDeBertaDLModel.html"
  },
  "455": {
    "id": "455",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForQuestionAnsweringDLModel.html"
  },
  "456": {
    "id": "456",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForSequenceDLModel.html"
  },
  "457": {
    "id": "457",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForTokenDLModel.html"
  },
  "458": {
    "id": "458",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadDistilBertDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadDistilBertDLModel.html"
  },
  "459": {
    "id": "459",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForQuestionAnsweringDLModel.html"
  },
  "460": {
    "id": "460",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForSequenceDLModel.html"
  },
  "461": {
    "id": "461",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForTokenDLModel.html"
  },
  "462": {
    "id": "462",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadElmoDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadElmoDLModel.html"
  },
  "463": {
    "id": "463",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadGPT2TransformerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadGPT2TransformerDLModel.html"
  },
  "464": {
    "id": "464",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadHubertForAudioDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadHubertForAudioDLModel.html"
  },
  "465": {
    "id": "465",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/ReadLanguageDetectorDLTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/ReadLanguageDetectorDLTensorflowModel.html"
  },
  "466": {
    "id": "466",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadLongformerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadLongformerDLModel.html"
  },
  "467": {
    "id": "467",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForQuestionAnsweringDLModel.html"
  },
  "468": {
    "id": "468",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForSequenceDLModel.html"
  },
  "469": {
    "id": "469",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForTokenDLModel.html"
  },
  "470": {
    "id": "470",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadMarianMTDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadMarianMTDLModel.html"
  },
  "471": {
    "id": "471",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadMultiClassifierDLTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadMultiClassifierDLTensorflowModel.html"
  },
  "472": {
    "id": "472",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForQuestionAnsweringDLModel.html"
  },
  "473": {
    "id": "473",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForSequenceDLModel.html"
  },
  "474": {
    "id": "474",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForTokenDLModel.html"
  },
  "475": {
    "id": "475",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadRobertaDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadRobertaDLModel.html"
  },
  "476": {
    "id": "476",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadRobertaSentenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadRobertaSentenceDLModel.html"
  },
  "477": {
    "id": "477",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/ReadSentencePieceModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/ReadSentencePieceModel.html"
  },
  "478": {
    "id": "478",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadSentimentDLTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadSentimentDLTensorflowModel.html"
  },
  "479": {
    "id": "479",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/ReadSpanBertCorefTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/ReadSpanBertCorefTensorflowModel.html"
  },
  "480": {
    "id": "480",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadSwinForImageDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadSwinForImageDLModel.html"
  },
  "481": {
    "id": "481",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadT5TransformerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadT5TransformerDLModel.html"
  },
  "482": {
    "id": "482",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadTapasForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadTapasForQuestionAnsweringDLModel.html"
  },
  "483": {
    "id": "483",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/ReadTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/ReadTensorflowModel.html"
  },
  "484": {
    "id": "484",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadUSEDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadUSEDLModel.html"
  },
  "485": {
    "id": "485",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadViTForImageDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadViTForImageDLModel.html"
  },
  "486": {
    "id": "486",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadWav2Vec2ForAudioDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadWav2Vec2ForAudioDLModel.html"
  },
  "487": {
    "id": "487",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForQuestionAnsweringDLModel.html"
  },
  "488": {
    "id": "488",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForSequenceDLModel.html"
  },
  "489": {
    "id": "489",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForTokenDLModel.html"
  },
  "490": {
    "id": "490",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlmRobertaDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlmRobertaDLModel.html"
  },
  "491": {
    "id": "491",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlmRobertaSentenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlmRobertaSentenceDLModel.html"
  },
  "492": {
    "id": "492",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlnetDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlnetDLModel.html"
  },
  "493": {
    "id": "493",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlnetForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlnetForSequenceDLModel.html"
  },
  "494": {
    "id": "494",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlnetForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlnetForTokenDLModel.html"
  },
  "495": {
    "id": "495",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadZeroShotNerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadZeroShotNerDLModel.html"
  },
  "496": {
    "id": "496",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForQAModel.html"
  },
  "497": {
    "id": "497",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForSequenceModel.html"
  },
  "498": {
    "id": "498",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForTokenModel.html"
  },
  "499": {
    "id": "499",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedAlbertModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedAlbertModel.html"
  },
  "500": {
    "id": "500",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForQAModel.html"
  },
  "501": {
    "id": "501",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForSequenceModel.html"
  },
  "502": {
    "id": "502",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForTokenModel.html"
  },
  "503": {
    "id": "503",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedBertModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedBertModel.html"
  },
  "504": {
    "id": "504",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedBertSentenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedBertSentenceModel.html"
  },
  "505": {
    "id": "505",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/ReadablePretrainedBigTextMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/ReadablePretrainedBigTextMatcher.html"
  },
  "506": {
    "id": "506",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForQAModel.html"
  },
  "507": {
    "id": "507",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForSequenceModel.html"
  },
  "508": {
    "id": "508",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForTokenModel.html"
  },
  "509": {
    "id": "509",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedCamemBertModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedCamemBertModel.html"
  },
  "510": {
    "id": "510",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedClassifierDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedClassifierDL.html"
  },
  "511": {
    "id": "511",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ReadablePretrainedContextSpell.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ReadablePretrainedContextSpell.html"
  },
  "512": {
    "id": "512",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForQAModel.html"
  },
  "513": {
    "id": "513",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForSequenceModel.html"
  },
  "514": {
    "id": "514",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForTokenModel.html"
  },
  "515": {
    "id": "515",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDeBertaModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDeBertaModel.html"
  },
  "516": {
    "id": "516",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/ReadablePretrainedDependency.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/ReadablePretrainedDependency.html"
  },
  "517": {
    "id": "517",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForQAModel.html"
  },
  "518": {
    "id": "518",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForSequenceModel.html"
  },
  "519": {
    "id": "519",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForTokenModel.html"
  },
  "520": {
    "id": "520",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDistilBertModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDistilBertModel.html"
  },
  "521": {
    "id": "521",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDoc2Vec.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDoc2Vec.html"
  },
  "522": {
    "id": "522",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedElmoModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedElmoModel.html"
  },
  "523": {
    "id": "523",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/ReadablePretrainedEntityRuler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/ReadablePretrainedEntityRuler.html"
  },
  "524": {
    "id": "524",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedGPT2TransformerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedGPT2TransformerModel.html"
  },
  "525": {
    "id": "525",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadablePretrainedHubertForAudioModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadablePretrainedHubertForAudioModel.html"
  },
  "526": {
    "id": "526",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/ReadablePretrainedLanguageDetectorDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/ReadablePretrainedLanguageDetectorDLModel.html"
  },
  "527": {
    "id": "527",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedLemmatizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedLemmatizer.html"
  },
  "528": {
    "id": "528",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForQAModel.html"
  },
  "529": {
    "id": "529",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForSequenceModel.html"
  },
  "530": {
    "id": "530",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForTokenModel.html"
  },
  "531": {
    "id": "531",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedLongformerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedLongformerModel.html"
  },
  "532": {
    "id": "532",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedMarianMTModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedMarianMTModel.html"
  },
  "533": {
    "id": "533",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedMultiClassifierDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedMultiClassifierDL.html"
  },
  "534": {
    "id": "534",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/ReadablePretrainedNerCrf.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/ReadablePretrainedNerCrf.html"
  },
  "535": {
    "id": "535",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadablePretrainedNerDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadablePretrainedNerDL.html"
  },
  "536": {
    "id": "536",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/ReadablePretrainedNorvig.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/ReadablePretrainedNorvig.html"
  },
  "537": {
    "id": "537",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/ReadablePretrainedPerceptron.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/ReadablePretrainedPerceptron.html"
  },
  "538": {
    "id": "538",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForQAModel.html"
  },
  "539": {
    "id": "539",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForSequenceModel.html"
  },
  "540": {
    "id": "540",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForTokenModel.html"
  },
  "541": {
    "id": "541",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedRobertaModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedRobertaModel.html"
  },
  "542": {
    "id": "542",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedRobertaSentenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedRobertaSentenceModel.html"
  },
  "543": {
    "id": "543",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/ReadablePretrainedSentenceDetectorDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/ReadablePretrainedSentenceDetectorDL.html"
  },
  "544": {
    "id": "544",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedSentimentDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedSentimentDL.html"
  },
  "545": {
    "id": "545",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/ReadablePretrainedSpanBertCorefModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/ReadablePretrainedSpanBertCorefModel.html"
  },
  "546": {
    "id": "546",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedStopWordsCleanerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedStopWordsCleanerModel.html"
  },
  "547": {
    "id": "547",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadablePretrainedSwinForImageModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadablePretrainedSwinForImageModel.html"
  },
  "548": {
    "id": "548",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/ReadablePretrainedSymmetric.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/ReadablePretrainedSymmetric.html"
  },
  "549": {
    "id": "549",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedT5TransformerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedT5TransformerModel.html"
  },
  "550": {
    "id": "550",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedTapasForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedTapasForQAModel.html"
  },
  "551": {
    "id": "551",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedTextMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedTextMatcher.html"
  },
  "552": {
    "id": "552",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedTokenizer.html"
  },
  "553": {
    "id": "553",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/ReadablePretrainedTypedDependency.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/ReadablePretrainedTypedDependency.html"
  },
  "554": {
    "id": "554",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedUSEModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedUSEModel.html"
  },
  "555": {
    "id": "555",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadablePretrainedViTForImageModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadablePretrainedViTForImageModel.html"
  },
  "556": {
    "id": "556",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ReadablePretrainedVivekn.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ReadablePretrainedVivekn.html"
  },
  "557": {
    "id": "557",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadablePretrainedWav2Vec2ForAudioModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadablePretrainedWav2Vec2ForAudioModel.html"
  },
  "558": {
    "id": "558",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedWord2Vec.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedWord2Vec.html"
  },
  "559": {
    "id": "559",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedWordEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedWordEmbeddings.html"
  },
  "560": {
    "id": "560",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/ReadablePretrainedWordSegmenter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/ReadablePretrainedWordSegmenter.html"
  },
  "561": {
    "id": "561",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForQAModel.html"
  },
  "562": {
    "id": "562",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForSequenceModel.html"
  },
  "563": {
    "id": "563",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForTokenModel.html"
  },
  "564": {
    "id": "564",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlmRobertaModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlmRobertaModel.html"
  },
  "565": {
    "id": "565",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlmRobertaSentenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlmRobertaSentenceModel.html"
  },
  "566": {
    "id": "566",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlnetForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlnetForSequenceModel.html"
  },
  "567": {
    "id": "567",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlnetForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlnetForTokenModel.html"
  },
  "568": {
    "id": "568",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlnetModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlnetModel.html"
  },
  "569": {
    "id": "569",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadablePretrainedZeroShotNer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadablePretrainedZeroShotNer.html"
  },
  "570": {
    "id": "570",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadsFromBytes.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadsFromBytes.html"
  },
  "571": {
    "id": "571",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ReadsLanguageModelGraph.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ReadsLanguageModelGraph.html"
  },
  "572": {
    "id": "572",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadsNERGraph.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadsNERGraph.html"
  },
  "573": {
    "id": "573",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/ReadsSentenceDetectorDLGraph.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/ReadsSentenceDetectorDLGraph.html"
  },
  "574": {
    "id": "574",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/RecursivePipeline.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/RecursivePipeline.html"
  },
  "575": {
    "id": "575",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/RecursivePipelineModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/RecursivePipelineModel.html"
  },
  "576": {
    "id": "576",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizer.html"
  },
  "577": {
    "id": "577",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel$.html"
  },
  "578": {
    "id": "578",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel.html"
  },
  "579": {
    "id": "579",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcher$.html"
  },
  "580": {
    "id": "580",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcher.html"
  },
  "581": {
    "id": "581",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcherModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcherModel$.html"
  },
  "582": {
    "id": "582",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcherModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcherModel.html"
  },
  "583": {
    "id": "583",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/RegexParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/RegexParser.html"
  },
  "584": {
    "id": "584",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/RegexPatternsReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/RegexPatternsReadWriter.html"
  },
  "585": {
    "id": "585",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/RegexPatternsReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/RegexPatternsReader.html"
  },
  "586": {
    "id": "586",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/RegexRule.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/RegexRule.html"
  },
  "587": {
    "id": "587",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer$.html"
  },
  "588": {
    "id": "588",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer.html"
  },
  "589": {
    "id": "589",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/RepositoryMetadata.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/RepositoryMetadata.html"
  },
  "590": {
    "id": "590",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceDownloader$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceDownloader$.html"
  },
  "591": {
    "id": "591",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceDownloader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceDownloader.html"
  },
  "592": {
    "id": "592",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ResourceHelper$$SourceStream.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ResourceHelper$$SourceStream.html"
  },
  "593": {
    "id": "593",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ResourceHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ResourceHelper$.html"
  },
  "594": {
    "id": "594",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceMetadata$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceMetadata$.html"
  },
  "595": {
    "id": "595",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceMetadata.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceMetadata.html"
  },
  "596": {
    "id": "596",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceRequest.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceRequest.html"
  },
  "597": {
    "id": "597",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceType$.html"
  },
  "598": {
    "id": "598",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings$.html"
  },
  "599": {
    "id": "599",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings.html"
  },
  "600": {
    "id": "600",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering$.html"
  },
  "601": {
    "id": "601",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering.html"
  },
  "602": {
    "id": "602",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification$.html"
  },
  "603": {
    "id": "603",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification.html"
  },
  "604": {
    "id": "604",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification$.html"
  },
  "605": {
    "id": "605",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification.html"
  },
  "606": {
    "id": "606",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings$.html"
  },
  "607": {
    "id": "607",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings.html"
  },
  "608": {
    "id": "608",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/RobertaTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/RobertaTokenizer.html"
  },
  "609": {
    "id": "609",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/RocksDBConnection$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/RocksDBConnection$.html"
  },
  "610": {
    "id": "610",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/RocksDBConnection.html",
    "relUrl": "/api/com/johnsnowlabs/storage/RocksDBConnection.html"
  },
  "611": {
    "id": "611",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory$$RuleMatch.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory$$RuleMatch.html"
  },
  "612": {
    "id": "612",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory$.html"
  },
  "613": {
    "id": "613",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory.html"
  },
  "614": {
    "id": "614",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/RuleSymbols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/RuleSymbols.html"
  },
  "615": {
    "id": "615",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/S3ResourceDownloader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/S3ResourceDownloader.html"
  },
  "616": {
    "id": "616",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/ScoreCollector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/ScoreCollector.html"
  },
  "617": {
    "id": "617",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/SearchTrie$.html",
    "relUrl": "/api/com/johnsnowlabs/collections/SearchTrie$.html"
  },
  "618": {
    "id": "618",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/SearchTrie.html",
    "relUrl": "/api/com/johnsnowlabs/collections/SearchTrie.html"
  },
  "619": {
    "id": "619",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Sentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Sentence$.html"
  },
  "620": {
    "id": "620",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Sentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Sentence.html"
  },
  "621": {
    "id": "621",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector$.html"
  },
  "622": {
    "id": "622",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector.html"
  },
  "623": {
    "id": "623",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLApproach.html"
  },
  "624": {
    "id": "624",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoder$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoder$.html"
  },
  "625": {
    "id": "625",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoder.html"
  },
  "626": {
    "id": "626",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoderParam.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoderParam.html"
  },
  "627": {
    "id": "627",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel$.html"
  },
  "628": {
    "id": "628",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel.html"
  },
  "629": {
    "id": "629",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/SentenceDetectorParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/SentenceDetectorParams.html"
  },
  "630": {
    "id": "630",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings$.html"
  },
  "631": {
    "id": "631",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings.html"
  },
  "632": {
    "id": "632",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/SentenceGrouper.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/SentenceGrouper.html"
  },
  "633": {
    "id": "633",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceException.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceException.html"
  },
  "634": {
    "id": "634",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceProcessor.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceProcessor.html"
  },
  "635": {
    "id": "635",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceWrapper$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceWrapper$.html"
  },
  "636": {
    "id": "636",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/SentenceSplit$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/SentenceSplit$.html"
  },
  "637": {
    "id": "637",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentApproach$.html"
  },
  "638": {
    "id": "638",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLApproach.html"
  },
  "639": {
    "id": "639",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel$.html"
  },
  "640": {
    "id": "640",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.html"
  },
  "641": {
    "id": "641",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector$.html"
  },
  "642": {
    "id": "642",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector.html"
  },
  "643": {
    "id": "643",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel$.html"
  },
  "644": {
    "id": "644",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel.html"
  },
  "645": {
    "id": "645",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/SerializableClass.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/SerializableClass.html"
  },
  "646": {
    "id": "646",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/SerializedAnnotatorComponent.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/SerializedAnnotatorComponent.html"
  },
  "647": {
    "id": "647",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SerializedDatasetMetadata.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SerializedDatasetMetadata.html"
  },
  "648": {
    "id": "648",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/SerializedExternalResource.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/SerializedExternalResource.html"
  },
  "649": {
    "id": "649",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SerializedLinearChainCrfModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SerializedLinearChainCrfModel.html"
  },
  "650": {
    "id": "650",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/SetFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/SetFeature.html"
  },
  "651": {
    "id": "651",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/SingleDatePolicy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/SingleDatePolicy$.html"
  },
  "652": {
    "id": "652",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/SpacyToAnnotation.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/SpacyToAnnotation.html"
  },
  "653": {
    "id": "653",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel$.html"
  },
  "654": {
    "id": "654",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel.html"
  },
  "655": {
    "id": "655",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/SparkNLP$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/SparkNLP$.html"
  },
  "656": {
    "id": "656",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/SparkNlpConfigKeys$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/SparkNlpConfigKeys$.html"
  },
  "657": {
    "id": "657",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/spark/SparkUtil$.html",
    "relUrl": "/api/com/johnsnowlabs/util/spark/SparkUtil$.html"
  },
  "658": {
    "id": "658",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SparseArray$$SeqWrapper.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SparseArray$$SeqWrapper.html"
  },
  "659": {
    "id": "659",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SparseArray$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SparseArray$.html"
  },
  "660": {
    "id": "660",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SparseArray.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SparseArray.html"
  },
  "661": {
    "id": "661",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/SpecialClassParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/SpecialClassParser.html"
  },
  "662": {
    "id": "662",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/SpecialToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/SpecialToken.html"
  },
  "663": {
    "id": "663",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Stemmer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Stemmer$.html"
  },
  "664": {
    "id": "664",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Stemmer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Stemmer.html"
  },
  "665": {
    "id": "665",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/StopWordsCleaner$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/StopWordsCleaner$.html"
  },
  "666": {
    "id": "666",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.html"
  },
  "667": {
    "id": "667",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageBatchWriter.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageBatchWriter.html"
  },
  "668": {
    "id": "668",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageFormat.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageFormat.html"
  },
  "669": {
    "id": "669",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageHelper$.html"
  },
  "670": {
    "id": "670",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageLocator$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageLocator$.html"
  },
  "671": {
    "id": "671",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageLocator.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageLocator.html"
  },
  "672": {
    "id": "672",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageReadWriter.html"
  },
  "673": {
    "id": "673",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageReadable.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageReadable.html"
  },
  "674": {
    "id": "674",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageReader.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageReader.html"
  },
  "675": {
    "id": "675",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/StorageSearchTrie$.html",
    "relUrl": "/api/com/johnsnowlabs/collections/StorageSearchTrie$.html"
  },
  "676": {
    "id": "676",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/StorageSearchTrie.html",
    "relUrl": "/api/com/johnsnowlabs/collections/StorageSearchTrie.html"
  },
  "677": {
    "id": "677",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageWriter.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageWriter.html"
  },
  "678": {
    "id": "678",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/StringMapStringDoubleAccumulator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/StringMapStringDoubleAccumulator.html"
  },
  "679": {
    "id": "679",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/StructFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/StructFeature.html"
  },
  "680": {
    "id": "680",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/SuffixedToken$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/SuffixedToken$.html"
  },
  "681": {
    "id": "681",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/SuffixedToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/SuffixedToken.html"
  },
  "682": {
    "id": "682",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification$.html"
  },
  "683": {
    "id": "683",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification.html"
  },
  "684": {
    "id": "684",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach$.html"
  },
  "685": {
    "id": "685",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach.html"
  },
  "686": {
    "id": "686",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel$.html"
  },
  "687": {
    "id": "687",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel$SuggestedWord.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel$SuggestedWord.html"
  },
  "688": {
    "id": "688",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel.html"
  },
  "689": {
    "id": "689",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteParams.html"
  },
  "690": {
    "id": "690",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/SyntacticFeatureFactory.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/SyntacticFeatureFactory.html"
  },
  "691": {
    "id": "691",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer$.html"
  },
  "692": {
    "id": "692",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer.html"
  },
  "693": {
    "id": "693",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMEdgesReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMEdgesReadWriter.html"
  },
  "694": {
    "id": "694",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMEdgesReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMEdgesReader.html"
  },
  "695": {
    "id": "695",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMNodesReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMNodesReader.html"
  },
  "696": {
    "id": "696",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMNodesWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMNodesWriter.html"
  },
  "697": {
    "id": "697",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMVocabReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMVocabReadWriter.html"
  },
  "698": {
    "id": "698",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMVocabReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMVocabReader.html"
  },
  "699": {
    "id": "699",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/TableAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/TableAssembler$.html"
  },
  "700": {
    "id": "700",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/TableAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/TableAssembler.html"
  },
  "701": {
    "id": "701",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TableData$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TableData$.html"
  },
  "702": {
    "id": "702",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TableData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TableData.html"
  },
  "703": {
    "id": "703",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/TagDictionary$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/TagDictionary$.html"
  },
  "704": {
    "id": "704",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Tagged.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Tagged.html"
  },
  "705": {
    "id": "705",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedSentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedSentence$.html"
  },
  "706": {
    "id": "706",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedSentence.html"
  },
  "707": {
    "id": "707",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedWord.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedWord.html"
  },
  "708": {
    "id": "708",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Tagger$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Tagger$.html"
  },
  "709": {
    "id": "709",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Tagger.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Tagger.html"
  },
  "710": {
    "id": "710",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/TagsType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/TagsType$.html"
  },
  "711": {
    "id": "711",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellDate$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellDate$.html"
  },
  "712": {
    "id": "712",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellDate.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellDate.html"
  },
  "713": {
    "id": "713",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellValue$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellValue$.html"
  },
  "714": {
    "id": "714",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellValue.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellValue.html"
  },
  "715": {
    "id": "715",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasEncoder.html"
  },
  "716": {
    "id": "716",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering$.html"
  },
  "717": {
    "id": "717",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering.html"
  },
  "718": {
    "id": "718",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasInputData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasInputData.html"
  },
  "719": {
    "id": "719",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericRelation$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericRelation$.html"
  },
  "720": {
    "id": "720",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericValueSpan$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericValueSpan$.html"
  },
  "721": {
    "id": "721",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericValueSpan.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericValueSpan.html"
  },
  "722": {
    "id": "722",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorResources$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorResources$.html"
  },
  "723": {
    "id": "723",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorResources.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorResources.html"
  },
  "724": {
    "id": "724",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowClassifier.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowClassifier.html"
  },
  "725": {
    "id": "725",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowWrapper$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowWrapper$.html"
  },
  "726": {
    "id": "726",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowWrapper.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowWrapper.html"
  },
  "727": {
    "id": "727",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TextMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TextMatcher$.html"
  },
  "728": {
    "id": "728",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TextMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TextMatcher.html"
  },
  "729": {
    "id": "729",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TextMatcherModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TextMatcherModel$.html"
  },
  "730": {
    "id": "730",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TextMatcherModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TextMatcherModel.html"
  },
  "731": {
    "id": "731",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/TextSentenceAttrs.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/TextSentenceAttrs.html"
  },
  "732": {
    "id": "732",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/TextSentenceLabels.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/TextSentenceLabels.html"
  },
  "733": {
    "id": "733",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/Token.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/Token.html"
  },
  "734": {
    "id": "734",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Token2Chunk$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Token2Chunk$.html"
  },
  "735": {
    "id": "735",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Token2Chunk.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Token2Chunk.html"
  },
  "736": {
    "id": "736",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/TokenAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/TokenAssembler$.html"
  },
  "737": {
    "id": "737",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/TokenAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/TokenAssembler.html"
  },
  "738": {
    "id": "738",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPiece.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPiece.html"
  },
  "739": {
    "id": "739",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPieceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPieceEmbeddings$.html"
  },
  "740": {
    "id": "740",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPieceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPieceEmbeddings.html"
  },
  "741": {
    "id": "741",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenizedSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenizedSentence.html"
  },
  "742": {
    "id": "742",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenizedWithSentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenizedWithSentence$.html"
  },
  "743": {
    "id": "743",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Tokenizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Tokenizer$.html"
  },
  "744": {
    "id": "744",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Tokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Tokenizer.html"
  },
  "745": {
    "id": "745",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TokenizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TokenizerModel$.html"
  },
  "746": {
    "id": "746",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TokenizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TokenizerModel.html"
  },
  "747": {
    "id": "747",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TrainDependencies.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TrainDependencies.html"
  },
  "748": {
    "id": "748",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TrainFile.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TrainFile.html"
  },
  "749": {
    "id": "749",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/TrainingHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/util/TrainingHelper$.html"
  },
  "750": {
    "id": "750",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/TrainingPerceptronLegacy.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/TrainingPerceptronLegacy.html"
  },
  "751": {
    "id": "751",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/TransducerFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/TransducerFeature.html"
  },
  "752": {
    "id": "752",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/TransducerSeqFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/TransducerSeqFeature.html"
  },
  "753": {
    "id": "753",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/TransformStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/TransformStrategy$.html"
  },
  "754": {
    "id": "754",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/Transition.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/Transition.html"
  },
  "755": {
    "id": "755",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TrieNode.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TrieNode.html"
  },
  "756": {
    "id": "756",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/TupleKeyLongDoubleMapAccumulator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/TupleKeyLongDoubleMapAccumulator.html"
  },
  "757": {
    "id": "757",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParser.html"
  },
  "758": {
    "id": "758",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach$.html"
  },
  "759": {
    "id": "759",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach.html"
  },
  "760": {
    "id": "760",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel$.html"
  },
  "761": {
    "id": "761",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel.html"
  },
  "762": {
    "id": "762",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/UnitToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/UnitToken.html"
  },
  "763": {
    "id": "763",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder$.html"
  },
  "764": {
    "id": "764",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.html"
  },
  "765": {
    "id": "765",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/util/Utilities$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/util/Utilities$.html"
  },
  "766": {
    "id": "766",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/Utilities$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/Utilities$.html"
  },
  "767": {
    "id": "767",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Utils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Utils.html"
  },
  "768": {
    "id": "768",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/Variables.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/Variables.html"
  },
  "769": {
    "id": "769",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/VectorMath$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/VectorMath$.html"
  },
  "770": {
    "id": "770",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/Verbose$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/Verbose$.html"
  },
  "771": {
    "id": "771",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/Version$.html",
    "relUrl": "/api/com/johnsnowlabs/util/Version$.html"
  },
  "772": {
    "id": "772",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/Version.html",
    "relUrl": "/api/com/johnsnowlabs/util/Version.html"
  },
  "773": {
    "id": "773",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification$.html"
  },
  "774": {
    "id": "774",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification.html"
  },
  "775": {
    "id": "775",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentApproach.html"
  },
  "776": {
    "id": "776",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel$.html"
  },
  "777": {
    "id": "777",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel.html"
  },
  "778": {
    "id": "778",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentUtils.html"
  },
  "779": {
    "id": "779",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/VocabParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/VocabParser.html"
  },
  "780": {
    "id": "780",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC$.html"
  },
  "781": {
    "id": "781",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC.html"
  },
  "782": {
    "id": "782",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/WeightedLevenshtein.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/WeightedLevenshtein.html"
  },
  "783": {
    "id": "783",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/WithGraphResolver.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/WithGraphResolver.html"
  },
  "784": {
    "id": "784",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach$.html"
  },
  "785": {
    "id": "785",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach.html"
  },
  "786": {
    "id": "786",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel$.html"
  },
  "787": {
    "id": "787",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel.html"
  },
  "788": {
    "id": "788",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/WordAttrs.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/WordAttrs.html"
  },
  "789": {
    "id": "789",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddings$.html"
  },
  "790": {
    "id": "790",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddings.html"
  },
  "791": {
    "id": "791",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsBinaryIndexer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsBinaryIndexer$.html"
  },
  "792": {
    "id": "792",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel$.html"
  },
  "793": {
    "id": "793",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.html"
  },
  "794": {
    "id": "794",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsReader.html"
  },
  "795": {
    "id": "795",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsTextIndexer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsTextIndexer$.html"
  },
  "796": {
    "id": "796",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsWriter.html"
  },
  "797": {
    "id": "797",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach$.html"
  },
  "798": {
    "id": "798",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach.html"
  },
  "799": {
    "id": "799",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel$.html"
  },
  "800": {
    "id": "800",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel.html"
  },
  "801": {
    "id": "801",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordWithDependency.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordWithDependency.html"
  },
  "802": {
    "id": "802",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceEmbeddingsSentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceEmbeddingsSentence$.html"
  },
  "803": {
    "id": "803",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceEmbeddingsSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceEmbeddingsSentence.html"
  },
  "804": {
    "id": "804",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceTokenized$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceTokenized$.html"
  },
  "805": {
    "id": "805",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceTokenizedSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceTokenizedSentence.html"
  },
  "806": {
    "id": "806",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/WritableAnnotatorComponent.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/WritableAnnotatorComponent.html"
  },
  "807": {
    "id": "807",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/WriteSentencePieceModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/WriteSentencePieceModel.html"
  },
  "808": {
    "id": "808",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/WriteTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/WriteTensorflowModel.html"
  },
  "809": {
    "id": "809",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings$.html"
  },
  "810": {
    "id": "810",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings.html"
  },
  "811": {
    "id": "811",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering$.html"
  },
  "812": {
    "id": "812",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering.html"
  },
  "813": {
    "id": "813",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification$.html"
  },
  "814": {
    "id": "814",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification.html"
  },
  "815": {
    "id": "815",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification$.html"
  },
  "816": {
    "id": "816",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification.html"
  },
  "817": {
    "id": "817",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings$.html"
  },
  "818": {
    "id": "818",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings.html"
  },
  "819": {
    "id": "819",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings$.html"
  },
  "820": {
    "id": "820",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.html"
  },
  "821": {
    "id": "821",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification$.html"
  },
  "822": {
    "id": "822",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification.html"
  },
  "823": {
    "id": "823",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification$.html"
  },
  "824": {
    "id": "824",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification.html"
  },
  "825": {
    "id": "825",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeKeywordExtraction$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeKeywordExtraction$.html"
  },
  "826": {
    "id": "826",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeKeywordExtraction.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeKeywordExtraction.html"
  },
  "827": {
    "id": "827",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeParams.html"
  },
  "828": {
    "id": "828",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel$.html"
  },
  "829": {
    "id": "829",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel.html"
  },
  "830": {
    "id": "830",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/ZipArchiveUtil$.html",
    "relUrl": "/api/com/johnsnowlabs/util/ZipArchiveUtil$.html"
  },
  "831": {
    "id": "831",
    "title": "Active Learning",
    "content": "Project Owners or Managers can enable the Active Learning feature by clicking on the corresponding Switch available on Model Training tab. If this feature is enabled, the NER training gets triggered automatically on every 50/100/200 new completions. It is possible to change the target completions number by dropdown which is visible only when Active Learning is enabled. While enabling this feature, users are asked whether they want to deploy the newly trained model right after the training process or not. If the user chooses not to automatically deploy the newly trained model, this can be done on demand by navigating to the target project Setup &gt; Configuration &gt; 3. Predefined Labels. Search for the new model by name of the project, select it and add it to your configuration. This will update the Project Configuration (the name of the model is changed in the corresponding label tags). Training date and time of each trained model is also displayed in the predefined labels widget. If the user opts to deploy the model after the training, the Project Configuration is automatically updated for each label that is included in the newly trained model. The value of the model param is updated with the name of the new model. If there is any mistake in the name of models, the validation error is displayed in the Interface Preview Section present on the right side of the Labeling Config area.",
    "url": "/docs/en/alab/active_learning",
    "relUrl": "/docs/en/alab/active_learning"
  },
  "832": {
    "id": "832",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/albert_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/albert_embeddings.html"
  },
  "833": {
    "id": "833",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_question_answering.html"
  },
  "834": {
    "id": "834",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_sequence_classification.html"
  },
  "835": {
    "id": "835",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_token_classification.html"
  },
  "836": {
    "id": "836",
    "title": "Analytics Permission",
    "content": "By default, dashboards in the Analytics page is disabled for a project. Users can request the admin to enable the Analytics page. The request is then listed on the Analytics Request page under the Settings menu. This page is only accessible to the admin user. After the admin user approves the request, the user can access the various dashboards in the Analytics page. Analytics Requests The Analytics Requests page lists all the pending requests for the Analytics page from one or more users. The admin user can grant or deny the permission to the requests as needed. It is accessible from Settings &gt; Analytics Requests. Each request contains information such as the name of project for which the analytics request was made, the user who initiated the request, and the date when the request was made. Granting a request All the requests granted by the admin user is listed under this tab. The table shows information about the granted requests, like the name of the project for which the analytics request was made, the user who initiated the request, the user who granted the request, the date when the request was granted, the latest date when the analytics were updated. The admin user can also revoke an already granted request from this list. Denying/Revoking a request All the requests denied or revoked by the admin user is listed under this tab. The table shows information about the denied/revoked requests, like the name of the project for which the analytics request was made, the user who initiated the request, the user who denied/revoked the request, the date when the request was denied/revoked, the latest date when the analytics were updated.",
    "url": "/docs/en/alab/analytics_permission",
    "relUrl": "/docs/en/alab/analytics_permission"
  },
  "837": {
    "id": "837",
    "title": "Analyze Biomedical Research - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_biomedical_research",
    "relUrl": "/analyze_biomedical_research"
  },
  "838": {
    "id": "838",
    "title": "Analyze Clinical Notes - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_clinical_notes",
    "relUrl": "/analyze_clinical_notes"
  },
  "839": {
    "id": "839",
    "title": "Analyze Clinical Trial Protocols - Healthcare NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_clinical_trial_protocols",
    "relUrl": "/analyze_clinical_trial_protocols"
  },
  "840": {
    "id": "840",
    "title": "Analyze Medical Texts in Spanish - Medical NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_medical_text_spanish",
    "relUrl": "/analyze_medical_text_spanish"
  },
  "841": {
    "id": "841",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/analyze_non_english_medical_text",
    "relUrl": "/analyze_non_english_medical_text"
  },
  "842": {
    "id": "842",
    "title": "Analyze Non-English Text & Documents - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_non_english_text_documents",
    "relUrl": "/analyze_non_english_text_documents"
  },
  "843": {
    "id": "843",
    "title": "Analyze Spelling & Grammar - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_spelling_grammar",
    "relUrl": "/analyze_spelling_grammar"
  },
  "844": {
    "id": "844",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/annotation.html",
    "relUrl": "/api/python/user_guide/annotation.html"
  },
  "845": {
    "id": "845",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotation.html",
    "relUrl": "/api/python/modules/sparknlp/annotation.html"
  },
  "846": {
    "id": "846",
    "title": "Manual Annotation",
    "content": "The Annotation Lab keeps a human expert as productive as possible. It minimizes the number of mouse clicks, keystrokes, and eye movements in the main workflow. The continuous improvement in the UI and the UX is from iterative feedback from the users. Annotation Lab supports keyboard shortcuts for all types of annotations. It enables having one hand on the keyboard, one hand on the mouse, and both eyes on the screen at all times. One-click completion and automatic switching to the next task keep experts in the loop. On the header of the Labeling area, you can find the list of labels defined for the project. In the center, it displays the content of the task. On the right, there are several widgets categorized into different groups. Annotations Versions Progress Labeling Widgets Completions A completion is a list of annotations manually defined by a user for a given task. After completing annotation on a task (e.g., all entities highlighted in the text, or one or more classes is assigned to the task in the case of classification projects) user clicks on the Save button to save their progress or Submit button to submit the completion. A submitted completion is no longer editable, and the user cannot delete it. Creating a new copy of the submitted completion is the only option to edit it. An annotator can modify or delete their completions only if completions are not submitted yet. Dedicated action icons are available on the completions widgets to allow users to quickly run actions like delete, copy, set ground-truth. It is an important to ensure a complete audit trail of all user actions. Annotation Lab tracks the history and details of any deleted completions. It means it is possible to see the name of the completion creator, date of creation, and deletion. Predictions A prediction is a list of annotations created automatically by Spark NLP pre-trained models or from the rules. A project owner/manager can create predictions using the Pre-Annotate button from the Tasks page. Predictions are read-only, which means users can see the predictions but cannot modify those. To reuse a prediction to bootstrap the annotation process, users can copy it to a new completion. This new completion bootstrapped from the prediction is editable. Confidence From version 3.3.0, running pre-annotations on a text project provides one extra piece of information for the automatic annotations - the confidence score. This score shows the confidence the model has for each of the labeled chunks it predicts. It is calculated based on the benchmarking information of the model used to pre-annotate and the score of each prediction. The confidence score is available when working on Named Entity Recognition, Relation Extraction, Assertion, and Classification projects and is also generated when using Rules. On the Labeling page, when selecting the Prediction widget, users can see all preannotation in the Annotations section with a score assigned to them. Using the confidence slider, users can filter out low confidence labels before starting to edit/correct the labels. Both Accept Prediction and Add a new completion based on this prediction operation apply to the filtered annotations from the confidence slider. Annotations The Annotations widget has two sections. Regions Gives a list overview of all annotated chunks. When you click on any annotation, it gets automatically highlighted in the labeling editor. We can edit or remove annotations from here. Relations Lists all the relations that have been created. When the user moves the mouse over any one relation, it is highlighted in the labeling editor. Progress Annotator/Reviewer can see their overall work progress from within the labeling page. The status is calculated for their assigned work. For Annotator View: For Reviewer View: Text Annotation Named Entity Recognition To extract information using NER labels, we first click on the label to select it or press the shortcut key assigned to it, and then, with the mouse, select the relevant part of the text. We can easily edit the incorrect labeling by clicking on the labeled text and then selecting the new label you want to assign to this text. To delete the label from the text, we first click on the text on the labeling editor and then press backspace. Trim leading and ending special characters in annotated chunks When annotating text, it is possible and probable that the annotation is not very precise and the chunks contain leading/trailing spaces and punctuation marks. By default all the leading/trailing spaces and punctuation marks are excluded from the annotated chunk. The labeling editor settings has a new configuration option that can be used to enable/disable this feature if necessary. Assertion Labels To add an assertion label to an extracted entity, select the assertion label and select the labeled entity (from NER) in the labeling editor. After this, the extracted entity will have two labels - one for NER and one for assertion. In the example below, the chunks heart disease, kidney disease, stroke etc., were extracted first using the NER label - Symptom (pink color) and then the assertion label - Absent (green color). Relation Extraction Creating relations with the Annotation Lab is very simple. First, click on any one labeled entity, then press the r key and click on the second labeled entity. You can add a label to the relation, change its direction or delete it using the contextual menu displayed next to the relation arrow or from the relation box. Cross page Annotation From version 2.8.0, Annotation Lab supports cross-page NER annotation for Text projects. It means that Annotators can annotate a chunk starting at the bottom of one page and finishing on the next page. This feature is also available for Relations. Previously, relations were created between chunks located on the same page. But now, relations can be created among tokens located on different pages. The way to do this is to first change the pagination settings to include the tokens to be linked on the same page, then create the relation annotation between the tokens and finally go back to the original pagination settings. The annotation is presented through connectors after updating the pagination. Visual NER Annotation Annotating text included in image documents (e.g., scanned documents) is a common use case in many verticals but comes with several challenges. With the Visual NER labeling config, we aim to ease the work of annotators by allowing them to select text from an image and assign the corresponding label to it. This feature is powered by Visual NLP library; hence a valid Visual NLP license is required to get access to it. Here is how we can use it: Upload a valid [Visual NLP](/docs/en/ocr) license. See how to do this here. Create a new project, specify a name for your project, add team members if necessary, and from the list of predefined templates (Default Project Configs) choose Visual NER Labeling under IMAGE content type. Update the configuration if necessary. This might be useful if you want to use other labels than the default ones. Click the Save Config button. While saving the project, a confirmation dialog is displayed to ask if you want to deploy the OCR pipeline. Select Yes from the confirmation dialog. Import the tasks you want to annotate (images or PDF documents). Start annotating text on top of the image by clicking on the text tokens, or by drawing bounding boxes on top of chunks or image areas. Export annotations in your preferred format. The entire process is illustrated below: Support for multi-page PDF documents When a valid Visual NLP license is available, Annotation Lab offers support for multi-page PDF annotation. We can import, annotate, and export multi-page PDF files easily. Users have two options for importing a new PDF file into the Visual NER project: Import PDF file from local storage. Add a link to the PDF file in the file attribute. After import, the task becomes available on the Tasks Page. The title of the new task is the name of the imported file. On the labeling page, the PDF viewer has pagination support so that annotators can annotate on the PDF document one page at a time. Users can also jump to a specific page in multi-page task, instead of passing through all pages to reach a target section of a PDF document. Support for multiple OCR servers Just like for Preannotation servers, Annotation Lab supports deployment of multiple OCR servers. If a user has uploaded a Visual NLP license, OCR inference is enabled. To work on a Visual NER project, users have to deploy at least one OCR server. Any OCR server can perform preannotation. To select the OCR server, users need to go to the Import page, click on the OCR Server button on the top-right corner and from the popup, choose one of the available OCR servers. If no suitable OCR server is present, you can create a new server by selecting the Create Server option and then clicking on the Deploy button.",
    "url": "/docs/en/alab/annotation",
    "relUrl": "/docs/en/alab/annotation"
  },
  "847": {
    "id": "847",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotation_audio.html",
    "relUrl": "/api/python/modules/sparknlp/annotation_audio.html"
  },
  "848": {
    "id": "848",
    "title": "Configurations",
    "content": "Simplified workflow Direct Submit Using the classical annotation workflow, when an annotator works on a task, a series of actions are necessary for creating a new annotation and submitting it as ground truth: Create the completion Save the completion Submit the completion Confirm submission Load next task This process is adapted for more complex workflows and large tasks. For simple projects with smaller tasks, Annotation Lab now offers a simplified workflow. Annotators can submit a completion with just one click. The Project Owner/Manager can activate this option from the Settings dialog (Customize Labels) in the Configuration step of the Setup page. Once enabled, annotators can see the submit button on the labeling page. A second option is available on the same dialog for Project Owner/Manager: Serve next task after completion submission. Once enabled, annotators can see the next task on the labeling page after submitting the completion for the current task. Note: Annotator can Save/Update completion using CTRL+Enter Annotator can Submit completion using ALT+Enter Accept Prediction When predictions are available for a task, Annotator can accept the predictions with just one click and navigate automatically to the next task. When users click on Accept Prediction, a new completion is created based on the prediction, then submitted as ground truth, and the next task in line (assigned to the current annotator/reviewer and with Incomplete or In Progress status) is automatically served. NOTE: Press backspace key (on windows) or delete key (on mac) to delete the selected relation from the labeling editor or use the delete action icon on the Relations widget. Labeling editor Settings The labeling editor offers some configurable features. For example, you can modify the editor’s layout, show or hide predictions, annotations, or the confidence panel, show or hide various controls and information. It is also possible to keep a label selected after creating a region, display labels on bounding boxes, polygons and other regions while labeling, and show line numbers for text labeling. Enable labeling hotkeys This option enables/disable the hotkeys assigned to taxonomy labels to use the hotkeys during the annotation process. Show hotkey tooltips This option shows/hides the hotkey and tooltip on the taxonomy label and the control buttons. Enable labeling hotkeys must be enabled for this option to work. Show labels inside the regions When you enable this option, the labels assigned to each annotated region are displayed on the respective region. Keep label selected after creating a region This option helps users quickly annotate sequences of the same label by keeping the label selected after the annotation of a region. With the option unchecked: With the option checked: Select regions after creating This option keeps the annotated region selected after annotation. In this way, it will be easier for users to quickly change the assigned label for the last selected region if necessary. Show line numbers for Text This option adds line numbers to the text content to annotate in the labeling editor. Label all occurrences of selected text When checked, this option allow users to annotate all occurences of a text in the current task in one step. Labeling editor Customizations The Labeling editor is highly customizable. Project Owners and Managers can change the layout of their projects based on their needs. Search filter for a large number of labels When a project has a large number of NER/Assertion labels in the taxonomy, the display of the taxonomy takes a lot of screen space, and it is difficult for annotators to navigate through all labels. To tackle this challenge, Annotation Lab supports search for labels in NER projects (an autocomplete search option). To add the search bar for NER Labels or Choices, use the Filter tag as shown in the following XML configuration. &lt;Filter /&gt; &lt;View&gt; *** enclose labels tags here *** &lt;/View&gt; &lt;View&gt; *** enclose text tags here *** &lt;/View&gt; Parameters: The following parameters/attributes can be used within the Filter tag. Param Type Default Description placeholder string Quick Filter Placeholder text for filter minlength number 3 Size of the filter style string   CSS style of the string hotkey string   Hotkey to use to focus on the filter text area Usage Example: &lt;Filter placeholder=&quot;Quick Filter&quot;/&gt; For obtaining the above display on a NER project, the config should look as follows: &lt;View&gt; &lt;Filter name=&quot;fl&quot; toName=&quot;label&quot; hotkey=&quot;shift+f&quot; minlength=&quot;1&quot; /&gt; &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;CARDINAL&quot; model=&quot;ner_onto_100&quot; background=&quot;#af906b&quot;/&gt; &lt;Label value=&quot;EVENT&quot; model=&quot;ner_onto_100&quot; background=&quot;#f384e1&quot;/&gt; ... &lt;Label value=&quot;LANGUAGE&quot; model=&quot;ner_onto_100&quot; background=&quot;#c0dad2&quot;/&gt; &lt;/Labels&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt; Notice how users can search for the desired label using the filter bar: Resizable label and text container While annotating longer text documents annotators may need to scroll to the top of the document for selecting the label to use, and then scroll down to create a label. Also, if the text is large, annotators have to scroll to a certain section because the textbox size is fixed. In those cases, the annotation experience can be improved by creating a scrollable labeling area and textbox area. To add the scroll bar, the View tag with a fixed height and overflow-y:scroll style property can be used as shown in the following XML config structure: &lt;View style=&quot;background:white; height: 100px; overflow-y:scroll; resize:vertical; position:sticky; top:0;&quot;&gt; *** enclose labels tags here *** &lt;/View&gt; &lt;View style=&quot;resize:vertical; margin-top:10px; max-height:400px; overflow-y:scroll;&quot;&gt; **** enclose text tags here** &lt;/View&gt; Once it has been added and saved to the Project Configuration, the scroll bar should be visible. Example Using the following Project Configuration &lt;View&gt; &lt;Filter name=&quot;fl&quot; toName=&quot;label&quot; hotkey=&quot;shift+f&quot; minlength=&quot;1&quot; /&gt; &lt;View style=&quot;background:white; height: 100px; overflow-y:scroll; resize:vertical; position:sticky; top:0;&quot;&gt; &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;CARDINAL&quot; model=&quot;ner_onto_100&quot; background=&quot;#af906b&quot;/&gt; &lt;Label value=&quot;EVENT&quot; model=&quot;ner_onto_100&quot; background=&quot;#f384e1&quot;/&gt; &lt;Label value=&quot;WORK_OF_ART&quot; model=&quot;ner_onto_100&quot; background=&quot;#0fbca4&quot;/&gt; ... &lt;Label value=&quot;LANGUAGE&quot; model=&quot;ner_onto_100&quot; background=&quot;#c0dad2&quot;/&gt; &lt;/Labels&gt; &lt;/View&gt; &lt;View style=&quot;resize:vertical; margin-top:10px; max-height:400px; overflow-y:scroll;&quot;&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;&gt;&lt;/Text&gt; &lt;/View&gt; &lt;/View&gt; we’ll obtain the output illustrated below: Comments on the Labeling Page Since version 4.10.0, NLP Lab offers enhanced comment feature for labeling pages, enabling users to easily add, update, and delete comments within labeling pages. This feature enhances the communication between the annotators, improves work efficiency and enhances productivity. In order to use this feature, there is a New Burger menu at the top right corner of the labeling page. The dropdown through this menu allows users to add, update, and delete comments. Tags from the Labeling Screen From version 4.10 onwards, NLP Lab introduces an enhanced tags feature for labeling pages. This addition offers users a convenient method to create, attach, and delete tags directly on the labeling page. It greatly enhances organization and boosts productivity by streamlining task management, granting users greater flexibility in classifying and monitoring their labeled data. Similar to the aforementioned comment feature, this can also be accessed from the burger menu at the top right corner of the labeling page. From the dropdown, select “Assign Tags”. Once the users select the tag/tags, they will be displayed against the tasks on the tasks page. Toggle Preview Window Label configuration editor and Preview Window covers 50/50 part of the screen. It can make editing larger XML configurations difficult. For a better editing experience, we can use the Toggle Preview Window button to have the editor use full screen width. Switch Role For users having multiple roles (Annotator/Reviewer/Manager) the labeling page can get confusing. Switch Role filter present on the top-right corner can help address this problem. This filter was introduced in Annotation Lab from version 2.6.0, previously refered to as View As filter. When selecting Annotator option, the view changes to facilitate annotating the task. Similar changes to the view applies when switching to Reviewer or Manager option. The selection persists even when the tab is closed or refreshed.",
    "url": "/docs/en/alab/annotation_configurations",
    "relUrl": "/docs/en/alab/annotation_configurations"
  },
  "849": {
    "id": "849",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotation_image.html",
    "relUrl": "/api/python/modules/sparknlp/annotation_image.html"
  },
  "850": {
    "id": "850",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/annotator_approach.html",
    "relUrl": "/api/python/modules/sparknlp/common/annotator_approach.html"
  },
  "851": {
    "id": "851",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/annotator_java_ml.html",
    "relUrl": "/api/python/modules/sparknlp/internal/annotator_java_ml.html"
  },
  "852": {
    "id": "852",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/annotator_model.html",
    "relUrl": "/api/python/modules/sparknlp/common/annotator_model.html"
  },
  "853": {
    "id": "853",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/annotator_properties.html",
    "relUrl": "/api/python/modules/sparknlp/common/annotator_properties.html"
  },
  "854": {
    "id": "854",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/annotator_transformer.html",
    "relUrl": "/api/python/modules/sparknlp/internal/annotator_transformer.html"
  },
  "855": {
    "id": "855",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/annotators.html",
    "relUrl": "/api/python/user_guide/annotators.html"
  },
  "856": {
    "id": "856",
    "title": "Text Annotators",
    "content": "How to read this section All annotators in Spark NLP share a common interface, this is: Annotation: Annotation(annotatorType, begin, end, result, meta-data, embeddings) AnnotatorType: some annotators share a type. This is not only figurative, but also tells about the structure of the metadata map in the Annotation. This is the one referred in the input and output of annotators. Inputs: Represents how many and which annotator types are expected in setInputCols(). These are column names of output of other annotators in the DataFrames. Output Represents the type of the output in the column setOutputCol(). There are two types of Annotators: Approach: AnnotatorApproach extend Estimators, which are meant to be trained through fit() Model: AnnotatorModel extend from Transformers, which are meant to transform DataFrames through transform() Model suffix is explicitly stated when the annotator is the result of a training process. Some annotators, such as Tokenizer are transformers, but do not contain the word Model since they are not trained annotators. Model annotators have a pretrained() on it’s static object, to retrieve the public pre-trained version of a model. pretrained(name, language, extra_location) -&gt; by default, pre-trained will bring a default model, sometimes we offer more than one model, in this case, you may have to use name, language or extra location to download them. Available Annotators Annotator Description Version BigTextMatcher Annotator to match exact phrases (by token) provided in a file against a Document. Opensource Chunk2Doc Converts a CHUNK type column back into DOCUMENT. Useful when trying to re-tokenize or do further analysis on a CHUNK result. Opensource ChunkEmbeddings This annotator utilizes WordEmbeddings, BertEmbeddings etc. to generate chunk embeddings from either Chunker, NGramGenerator, or NerConverter outputs. Opensource ChunkTokenizer Tokenizes and flattens extracted NER chunks. Opensource Chunker This annotator matches a pattern of part-of-speech tags in order to return meaningful phrases from document. Opensource ClassifierDL ClassifierDL for generic Multi-class Text Classification. Opensource ContextSpellChecker Implements a deep-learning based Noisy Channel Model Spell Algorithm. Opensource DateMatcher Matches standard date formats into a provided format. Opensource DependencyParser Unlabeled parser that finds a grammatical relation between two words in a sentence. Opensource Doc2Chunk Converts DOCUMENT type annotations into CHUNK type with the contents of a chunkCol. Opensource Doc2Vec Word2Vec model that creates vector representations of words in a text corpus. Opensource DocumentAssembler Prepares data into a format that is processable by Spark NLP. This is the entry point for every Spark NLP pipeline. Opensource DocumentNormalizer Annotator which normalizes raw text from tagged text, e.g. scraped web pages or xml documents, from document type columns into Sentence. Opensource EntityRuler Fits an Annotator to match exact strings or regex patterns provided in a file against a Document and assigns them an named entity. Opensource EmbeddingsFinisher Extracts embeddings from Annotations into a more easily usable form. Opensource Finisher Converts annotation results into a format that easier to use. It is useful to extract the results from Spark NLP Pipelines. Opensource GraphExtraction Extracts a dependency graph between entities. Opensource GraphFinisher Helper class to convert the knowledge graph from GraphExtraction into a generic format, such as RDF. Opensource ImageAssembler Prepares images read by Spark into a format that is processable by Spark NLP. Opensource LanguageDetectorDL Language Identification and Detection by using CNN and RNN architectures in TensorFlow. Opensource Lemmatizer Finds lemmas out of words with the objective of returning a base dictionary word. Opensource MultiClassifierDL Multi-label Text Classification. Opensource MultiDateMatcher Matches standard date formats into a provided format. Opensource MultiDocumentAssembler Prepares data into a format that is processable by Spark NLP. Opensource NGramGenerator A feature transformer that converts the input array of strings (annotatorType TOKEN) into an array of n-grams (annotatorType CHUNK). Opensource NerConverter Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label. Opensource NerCrf Extracts Named Entities based on a CRF Model. Opensource NerDL This Named Entity recognition annotator is a generic NER model based on Neural Networks. Opensource NerOverwriter Overwrites entities of specified strings. Opensource Normalizer Removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary. Opensource NorvigSweeting Spellchecker Retrieves tokens and makes corrections automatically if not found in an English dictionary. Opensource POSTagger (Part of speech tagger) Averaged Perceptron model to tag words part-of-speech. Opensource RecursiveTokenizer Tokenizes raw text recursively based on a handful of definable rules. Opensource RegexMatcher Uses rules to match a set of regular expressions and associate them with a provided identifier. Opensource RegexTokenizer A tokenizer that splits text by a regex pattern. Opensource SentenceDetector Annotator that detects sentence boundaries using regular expressions. Opensource SentenceDetectorDL Detects sentence boundaries using a deep learning approach. Opensource SentenceEmbeddings Converts the results from WordEmbeddings, BertEmbeddings, or ElmoEmbeddings into sentence or document embeddings by either summing up or averaging all the word embeddings in a sentence or a document (depending on the inputCols). Opensource SentimentDL Annotator for multi-class sentiment analysis. Opensource SentimentDetector Rule based sentiment detector, which calculates a score based on predefined keywords. Opensource Stemmer Returns hard-stems out of words with the objective of retrieving the meaningful part of the word. Opensource StopWordsCleaner This annotator takes a sequence of strings (e.g. the output of a Tokenizer, Normalizer, Lemmatizer, and Stemmer) and drops all the stop words from the input sequences. Opensource SymmetricDelete Spellchecker Symmetric Delete spelling correction algorithm. Opensource TextMatcher Matches exact phrases (by token) provided in a file against a Document. Opensource Token2Chunk Converts TOKEN type Annotations to CHUNK type. Opensource TokenAssembler This transformer reconstructs a DOCUMENT type annotation from tokens, usually after these have been normalized, lemmatized, normalized, spell checked, etc, in order to use this document annotation in further annotators. Opensource Tokenizer Tokenizes raw text into word pieces, tokens. Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs. Opensource TypedDependencyParser Labeled parser that finds a grammatical relation between two words in a sentence. Opensource ViveknSentiment Sentiment analyser inspired by the algorithm by Vivek Narayanan. Opensource WordEmbeddings Word Embeddings lookup annotator that maps tokens to vectors. Opensource Word2Vec Word2Vec model that creates vector representations of words in a text corpus. Opensource WordSegmenter Tokenizes non-english or non-whitespace separated texts. Opensource YakeKeywordExtraction Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction. Opensource Available Transformers Additionally, these transformers are available to generate embeddings. Transformer Description Version AlbertEmbeddings ALBERT: A Lite BERT for Self-supervised Learning of Language Representations Opensource AlbertForQuestionAnswering AlbertForQuestionAnswering can load ALBERT Models with a span classification head on top for extractive question-answering tasks like SQuAD. Opensource AlbertForTokenClassification AlbertForTokenClassification can load ALBERT Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. Opensource AlbertForSequenceClassification AlbertForSequenceClassification can load ALBERT Models with sequence classification/regression head on top e.g. for multi-class document classification tasks. Opensource BertEmbeddings Token-level embeddings using BERT. BERT (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture. Opensource BertForQuestionAnswering BertForQuestionAnswering can load Bert Models with a span classification head on top for extractive question-answering tasks like SQuAD. Opensource BertForSequenceClassification Bert Models with sequence classification/regression head on top. Opensource BertForTokenClassification BertForTokenClassification can load Bert Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. Opensource BertSentenceEmbeddings Sentence-level embeddings using BERT. BERT (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture. Opensource CamemBertEmbeddings CamemBert is based on Facebook’s RoBERTa model released in 2019. Opensource CamemBertForSequenceClassification amemBertForSequenceClassification can load CamemBERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. Opensource CamemBertForTokenClassification CamemBertForTokenClassification can load CamemBERT Models with a token classification head on top Opensource DeBertaEmbeddings DeBERTa builds on RoBERTa with disentangled attention and enhanced mask decoder training with half of the data used in RoBERTa. Opensource DeBertaForQuestionAnswering DeBertaForQuestionAnswering can load DeBERTa Models with a span classification head on top for extractive question-answering tasks like SQuAD. Opensource DistilBertEmbeddings DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. Opensource DistilBertForQuestionAnswering DistilBertForQuestionAnswering can load DistilBert Models with a span classification head on top for extractive question-answering tasks like SQuAD. Opensource DistilBertForSequenceClassification DistilBertForSequenceClassification can load DistilBERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. Opensource DistilBertForTokenClassification DistilBertForTokenClassification can load DistilBERT Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. Opensource ElmoEmbeddings Word embeddings from ELMo (Embeddings from Language Models), a language model trained on the 1 Billion Word Benchmark. Opensource GPT2Transformer GPT-2 is a large transformer-based language model with 1.5 billion parameters, trained on a dataset of 8 million web pages. Opensource HubertForCTC Hubert Model with a language modeling head on top for Connectionist Temporal Classification (CTC). Opensource LongformerEmbeddings Longformer is a BERT-like model started from the RoBERTa checkpoint and pretrained for MLM on long documents. Opensource LongformerForQuestionAnswering LongformerForQuestionAnswering can load Longformer Models with a span classification head on top for extractive question-answering tasks like SQuAD. Opensource LongformerForSequenceClassification LongformerForSequenceClassification can load Longformer Models with sequence classification/regression head on top e.g. for multi-class document classification tasks. Opensource LongformerForTokenClassification LongformerForTokenClassification can load Longformer Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. Opensource MarianTransformer Marian is an efficient, free Neural Machine Translation framework written in pure C++ with minimal dependencies. Opensource RoBertaEmbeddings RoBERTa: A Robustly Optimized BERT Pretraining Approach Opensource RoBertaForQuestionAnswering RoBertaForQuestionAnswering can load RoBERTa Models with a span classification head on top for extractive question-answering tasks like SQuAD. Opensource RoBertaForSequenceClassification RoBertaForSequenceClassification can load RoBERTa Models with sequence classification/regression head on top e.g. for multi-class document classification tasks. Opensource RoBertaForTokenClassification RoBertaForTokenClassification can load RoBERTa Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. Opensource RoBertaSentenceEmbeddings Sentence-level embeddings using RoBERTa. Opensource SpanBertCoref A coreference resolution model based on SpanBert. Opensource SwinForImageClassification SwinImageClassification is an image classifier based on Swin. Opensource T5Transformer T5 reconsiders all NLP tasks into a unified text-to-text-format where the input and output are always text strings, in contrast to BERT-style models that can only output either a class label or a span of the input. Opensource TapasForQuestionAnswering TapasForQuestionAnswering is an implementation of TaPas - a BERT-based model specifically designed for answering questions about tabular data. Opensource UniversalSentenceEncoder The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. Opensource ViTForImageClassification Vision Transformer (ViT) for image classification. Opensource Wav2Vec2ForCTC Wav2Vec2 Model with a language modeling head on top for Connectionist Temporal Classification (CTC). Opensource XlmRoBertaEmbeddings XlmRoBerta is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl Opensource XlmRoBertaForQuestionAnswering XlmRoBertaForQuestionAnswering can load XLM-RoBERTa Models with a span classification head on top for extractive question-answering tasks like SQuAD. Opensource XlmRoBertaForSequenceClassification XlmRoBertaForSequenceClassification can load XLM-RoBERTa Models with sequence classification/regression head on top e.g. for multi-class document classification tasks. Opensource XlmRoBertaForTokenClassification XlmRoBertaForTokenClassification can load XLM-RoBERTa Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. Opensource XlmRoBertaSentenceEmbeddings Sentence-level embeddings using XLM-RoBERTa. Opensource XlnetEmbeddings XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Opensource XlnetForTokenClassification XlnetForTokenClassification can load XLNet Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. Opensource XlnetForSequenceClassification XlnetForSequenceClassification can load XLNet Models with sequence classification/regression head on top e.g. for multi-class document classification tasks. Opensource ZeroShotNer ZeroShotNerModel implements zero shot named entity recognition by utilizing RoBERTa transformer models fine tuned on a question answering task. Opensource BigTextMatcher ModelApproach Annotator to match exact phrases (by token) provided in a file against a Document. A text file of predefined phrases must be provided with setStoragePath. In contrast to the normal TextMatcher, the BigTextMatcher is designed for large corpora. For extended examples of usage, see the BigTextMatcherTestSpec. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: BigTextMatcher Scala API: BigTextMatcher Source: BigTextMatcher Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # In this example, the entities file is of the form # # ... # dolore magna aliqua # lorem ipsum dolor. sit # laborum # ... # # where each line represents an entity phrase to be extracted. documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) data = spark.createDataFrame([[&quot;Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum&quot;]]).toDF(&quot;text&quot;) entityExtractor = BigTextMatcher() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setStoragePath(&quot;src/test/resources/entity-extractor/test-phrases.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) .setCaseSensitive(False) pipeline = Pipeline().setStages([documentAssembler, tokenizer, entityExtractor]) results = pipeline.fit(data).transform(data) results.selectExpr(&quot;explode(entity)&quot;).show(truncate=False) +--+ |col | +--+ |[chunk, 6, 24, dolore magna aliqua, [sentence -&gt; 0, chunk -&gt; 0], []]| |[chunk, 53, 59, laborum, [sentence -&gt; 0, chunk -&gt; 1], []] | +--+ // In this example, the entities file is of the form // // ... // dolore magna aliqua // lorem ipsum dolor. sit // laborum // ... // // where each line represents an entity phrase to be extracted. import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotator.Tokenizer import com.johnsnowlabs.nlp.annotator.BigTextMatcher import com.johnsnowlabs.nlp.util.io.ReadAs import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val data = Seq(&quot;Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum&quot;).toDF(&quot;text&quot;) val entityExtractor = new BigTextMatcher() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setStoragePath(&quot;src/test/resources/entity-extractor/test-phrases.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) .setCaseSensitive(false) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, entityExtractor)) val results = pipeline.fit(data).transform(data) results.selectExpr(&quot;explode(entity)&quot;).show(false) +--+ |col | +--+ |[chunk, 6, 24, dolore magna aliqua, [sentence -&gt; 0, chunk -&gt; 0], []]| |[chunk, 53, 59, laborum, [sentence -&gt; 0, chunk -&gt; 1], []] | +--+ Instantiated model of the BigTextMatcher. For usage and examples see the documentation of the main class. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: BigTextMatcherModel Scala API: BigTextMatcherModel Source: BigTextMatcherModel Chunk2Doc Converts a CHUNK type column back into DOCUMENT. Useful when trying to re-tokenize or do further analysis on a CHUNK result. Input Annotator Types: CHUNK Output Annotator Type: DOCUMENT Python API: Chunk2Doc Scala API: Chunk2Doc Source: Chunk2Doc Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline from sparknlp.pretrained import PretrainedPipeline # Location entities are extracted and converted back into `DOCUMENT` type for further processing data = spark.createDataFrame([[1, &quot;New York and New Jersey aren&#39;t that far apart actually.&quot;]]).toDF(&quot;id&quot;, &quot;text&quot;) # Extracts Named Entities amongst other things pipeline = PretrainedPipeline(&quot;explain_document_dl&quot;) chunkToDoc = Chunk2Doc().setInputCols(&quot;entities&quot;).setOutputCol(&quot;chunkConverted&quot;) explainResult = pipeline.transform(data) result = chunkToDoc.transform(explainResult) result.selectExpr(&quot;explode(chunkConverted)&quot;).show(truncate=False) ++ |col | ++ |[document, 0, 7, New York, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 0], []] | |[document, 13, 22, New Jersey, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 1], []]| ++ // Location entities are extracted and converted back into `DOCUMENT` type for further processing import spark.implicits._ import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline import com.johnsnowlabs.nlp.Chunk2Doc val data = Seq((1, &quot;New York and New Jersey aren&#39;t that far apart actually.&quot;)).toDF(&quot;id&quot;, &quot;text&quot;) // Extracts Named Entities amongst other things val pipeline = PretrainedPipeline(&quot;explain_document_dl&quot;) val chunkToDoc = new Chunk2Doc().setInputCols(&quot;entities&quot;).setOutputCol(&quot;chunkConverted&quot;) val explainResult = pipeline.transform(data) val result = chunkToDoc.transform(explainResult) result.selectExpr(&quot;explode(chunkConverted)&quot;).show(false) ++ |col | ++ |[document, 0, 7, New York, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 0], []] | |[document, 13, 22, New Jersey, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 1], []]| ++ ChunkEmbeddings This annotator utilizes WordEmbeddings, BertEmbeddings etc. to generate chunk embeddings from either Chunker, NGramGenerator, or NerConverter outputs. For extended examples of usage, see the Examples and the ChunkEmbeddingsTestSpec. Input Annotator Types: CHUNK, WORD_EMBEDDINGS Output Annotator Type: WORD_EMBEDDINGS Python API: ChunkEmbeddings Scala API: ChunkEmbeddings Source: ChunkEmbeddings Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # Extract the Embeddings from the NGrams documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) nGrams = NGramGenerator() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;chunk&quot;) .setN(2) embeddings = WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) # Convert the NGram chunks into Word Embeddings chunkEmbeddings = ChunkEmbeddings() .setInputCols([&quot;chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;chunk_embeddings&quot;) .setPoolingStrategy(&quot;AVERAGE&quot;) pipeline = Pipeline() .setStages([ documentAssembler, sentence, tokenizer, nGrams, embeddings, chunkEmbeddings ]) data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(chunk_embeddings) as result&quot;) .select(&quot;result.annotatorType&quot;, &quot;result.result&quot;, &quot;result.embeddings&quot;) .show(5, 80) ++-+--+ | annotatorType| result| embeddings| ++-+--+ |word_embeddings| This is|[-0.55661, 0.42829502, 0.86661, -0.409785, 0.06316501, 0.120775, -0.0732005, ...| |word_embeddings| is a|[-0.40674996, 0.22938299, 0.50597, -0.288195, 0.555655, 0.465145, 0.140118, 0...| |word_embeddings|a sentence|[0.17417, 0.095253006, -0.0530925, -0.218465, 0.714395, 0.79860497, 0.0129999...| |word_embeddings|sentence .|[0.139705, 0.177955, 0.1887775, -0.45545, 0.20030999, 0.461557, -0.07891501, ...| ++-+--+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.{NGramGenerator, Tokenizer} import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.embeddings.ChunkEmbeddings import org.apache.spark.ml.Pipeline // Extract the Embeddings from the NGrams val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val nGrams = new NGramGenerator() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;chunk&quot;) .setN(2) val embeddings = WordEmbeddingsModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(false) // Convert the NGram chunks into Word Embeddings val chunkEmbeddings = new ChunkEmbeddings() .setInputCols(&quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;chunk_embeddings&quot;) .setPoolingStrategy(&quot;AVERAGE&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentence, tokenizer, nGrams, embeddings, chunkEmbeddings )) val data = Seq(&quot;This is a sentence.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(chunk_embeddings) as result&quot;) .select(&quot;result.annotatorType&quot;, &quot;result.result&quot;, &quot;result.embeddings&quot;) .show(5, 80) ++-+--+ | annotatorType| result| embeddings| ++-+--+ |word_embeddings| This is|[-0.55661, 0.42829502, 0.86661, -0.409785, 0.06316501, 0.120775, -0.0732005, ...| |word_embeddings| is a|[-0.40674996, 0.22938299, 0.50597, -0.288195, 0.555655, 0.465145, 0.140118, 0...| |word_embeddings|a sentence|[0.17417, 0.095253006, -0.0530925, -0.218465, 0.714395, 0.79860497, 0.0129999...| |word_embeddings|sentence .|[0.139705, 0.177955, 0.1887775, -0.45545, 0.20030999, 0.461557, -0.07891501, ...| ++-+--+ ChunkTokenizer ModelApproach Tokenizes and flattens extracted NER chunks. The ChunkTokenizer will split the extracted NER CHUNK type Annotations and will create TOKEN type Annotations. The result is then flattened, resulting in a single array. For extended examples of usage, see the ChunkTokenizerTestSpec. Input Annotator Types: CHUNK Output Annotator Type: TOKEN Python API: ChunkTokenizer Scala API: ChunkTokenizer Source: ChunkTokenizer Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) entityExtractor = TextMatcher() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setEntities(&quot;src/test/resources/entity-extractor/test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) chunkTokenizer = ChunkTokenizer() .setInputCols([&quot;entity&quot;]) .setOutputCol(&quot;chunk_token&quot;) pipeline = Pipeline().setStages([ documentAssembler, sentenceDetector, tokenizer, entityExtractor, chunkTokenizer ]) data = spark.createDataFrame([[ &quot;Hello world, my name is Michael, I am an artist and I work at Benezar&quot;, &quot;Robert, an engineer from Farendell, graduated last year. The other one, Lucas, graduated last week.&quot; ]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;entity.result as entity&quot; , &quot;chunk_token.result as chunk_token&quot;).show(truncate=False) +--++ |entity |chunk_token | +--++ |[world, Michael, work at Benezar] |[world, Michael, work, at, Benezar] | |[engineer from Farendell, last year, last week]|[engineer, from, Farendell, last, year, last, week]| +--++ import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotators.{ChunkTokenizer, TextMatcher, Tokenizer} import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.util.io.ReadAs import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val entityExtractor = new TextMatcher() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setEntities(&quot;src/test/resources/entity-extractor/test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) val chunkTokenizer = new ChunkTokenizer() .setInputCols(&quot;entity&quot;) .setOutputCol(&quot;chunk_token&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, entityExtractor, chunkTokenizer )) val data = Seq( &quot;Hello world, my name is Michael, I am an artist and I work at Benezar&quot;, &quot;Robert, an engineer from Farendell, graduated last year. The other one, Lucas, graduated last week.&quot; ).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;entity.result as entity&quot; , &quot;chunk_token.result as chunk_token&quot;).show(false) +--++ |entity |chunk_token | +--++ |[world, Michael, work at Benezar] |[world, Michael, work, at, Benezar] | |[engineer from Farendell, last year, last week]|[engineer, from, Farendell, last, year, last, week]| +--++ Instantiated model of the ChunkTokenizer. For usage and examples see the documentation of the main class. Input Annotator Types: CHUNK Output Annotator Type: TOKEN Python API: ChunkTokenizerModel Scala API: ChunkTokenizerModel Source: ChunkTokenizerModel Chunker This annotator matches a pattern of part-of-speech tags in order to return meaningful phrases from document. Extracted part-of-speech tags are mapped onto the sentence, which can then be parsed by regular expressions. The part-of-speech tags are wrapped by angle brackets &lt;&gt; to be easily distinguishable in the text itself. This example sentence will result in the form: &quot;Peter Pipers employees are picking pecks of pickled peppers.&quot; &quot;&lt;NNP&gt;&lt;NNP&gt;&lt;NNS&gt;&lt;VBP&gt;&lt;VBG&gt;&lt;NNS&gt;&lt;IN&gt;&lt;JJ&gt;&lt;NNS&gt;&lt;.&gt;&quot; To then extract these tags, regexParsers need to be set with e.g.: val chunker = new Chunker() .setInputCols(&quot;sentence&quot;, &quot;pos&quot;) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;&lt;NNP&gt;+&quot;, &quot;&lt;NNS&gt;+&quot;)) When defining the regular expressions, tags enclosed in angle brackets are treated as groups, so here specifically &quot;&lt;NNP&gt;+&quot; means 1 or more nouns in succession. Additional patterns can also be set with addRegexParsers. For more extended examples see the Examples) and the ChunkerTestSpec. Input Annotator Types: DOCUMENT, POS Output Annotator Type: CHUNK Python API: Chunker Scala API: Chunker Source: Chunker Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) POSTag = PerceptronModel.pretrained() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) chunker = Chunker() .setInputCols(&quot;sentence&quot;, &quot;pos&quot;) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;&lt;NNP&gt;+&quot;, &quot;&lt;NNS&gt;+&quot;]) pipeline = Pipeline() .setStages([ documentAssembler, sentence, tokenizer, POSTag, chunker ]) data = spark.createDataFrame([[&quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(chunk) as result&quot;).show(truncate=False) +-+ |result | +-+ |[chunk, 0, 11, Peter Pipers, [sentence -&gt; 0, chunk -&gt; 0], []]| |[chunk, 13, 21, employees, [sentence -&gt; 0, chunk -&gt; 1], []] | |[chunk, 35, 39, pecks, [sentence -&gt; 0, chunk -&gt; 2], []] | |[chunk, 52, 58, peppers, [sentence -&gt; 0, chunk -&gt; 3], []] | +-+ import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotators.{Chunker, Tokenizer} import com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val POSTag = PerceptronModel.pretrained() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) val chunker = new Chunker() .setInputCols(&quot;sentence&quot;, &quot;pos&quot;) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;&lt;NNP&gt;+&quot;, &quot;&lt;NNS&gt;+&quot;)) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentence, tokenizer, POSTag, chunker )) val data = Seq(&quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(chunk) as result&quot;).show(false) +-+ |result | +-+ |[chunk, 0, 11, Peter Pipers, [sentence -&gt; 0, chunk -&gt; 0], []]| |[chunk, 13, 21, employees, [sentence -&gt; 0, chunk -&gt; 1], []] | |[chunk, 35, 39, pecks, [sentence -&gt; 0, chunk -&gt; 2], []] | |[chunk, 52, 58, peppers, [sentence -&gt; 0, chunk -&gt; 3], []] | +-+ ClassifierDL ModelApproach Trains a ClassifierDL for generic Multi-class Text Classification. ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications. The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to 100 classes. For instantiated/pretrained models, see ClassifierDLModel. Setting a test dataset to monitor model metrics can be done with .setTestDataset. The method expects a path to a parquet file containing a dataframe that has the same required columns as the training dataframe. The pre-processing steps for the training dataframe should also be applied to the test dataframe. The following example will show how to create the test dataset: val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val embeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val preProcessingPipeline = new Pipeline().setStages(Array(documentAssembler, embeddings)) val Array(train, test) = data.randomSplit(Array(0.8, 0.2)) preProcessingPipeline .fit(test) .transform(test) .write .mode(&quot;overwrite&quot;) .parquet(&quot;test_data&quot;) val classifier = new ClassifierDLApproach() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;category&quot;) .setLabelColumn(&quot;label&quot;) .setTestDataset(&quot;test_data&quot;) For extended examples of usage, see the Examples [1] [2] and the ClassifierDLTestSpec. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: CATEGORY Note: This annotator accepts a label column of a single item in either type of String, Int, Float, or Double. UniversalSentenceEncoder, BertSentenceEmbeddings, or SentenceEmbeddings can be used for the inputCol Python API: ClassifierDLApproach Scala API: ClassifierDLApproach Source: ClassifierDLApproach Show Example PythonScala # In this example, the training data `&quot;sentiment.csv&quot;` has the form of # # text,label # This movie is the best movie I have wached ever! In my opinion this movie can win an award.,0 # This was a terrible movie! The acting was bad really bad!,1 # ... # # Then traning can be done like so: import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline smallCorpus = spark.read.option(&quot;header&quot;,&quot;True&quot;).csv(&quot;src/test/resources/classifier/sentiment.csv&quot;) documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) useEmbeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) docClassifier = ClassifierDLApproach() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;category&quot;) .setLabelColumn(&quot;label&quot;) .setBatchSize(64) .setMaxEpochs(20) .setLr(5e-3) .setDropout(0.5) pipeline = Pipeline() .setStages( [ documentAssembler, useEmbeddings, docClassifier ] ) pipelineModel = pipeline.fit(smallCorpus) // In this example, the training data `&quot;sentiment.csv&quot;` has the form of // // text,label // This movie is the best movie I have wached ever! In my opinion this movie can win an award.,0 // This was a terrible movie! The acting was bad really bad!,1 // ... // // Then traning can be done like so: import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder import com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLApproach import org.apache.spark.ml.Pipeline val smallCorpus = spark.read.option(&quot;header&quot;,&quot;true&quot;).csv(&quot;src/test/resources/classifier/sentiment.csv&quot;) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val useEmbeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val docClassifier = new ClassifierDLApproach() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;category&quot;) .setLabelColumn(&quot;label&quot;) .setBatchSize(64) .setMaxEpochs(20) .setLr(5e-3f) .setDropout(0.5f) val pipeline = new Pipeline() .setStages( Array( documentAssembler, useEmbeddings, docClassifier ) ) val pipelineModel = pipeline.fit(smallCorpus) ClassifierDL for generic Multi-class Text Classification. ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications. The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to 100 classes. This is the instantiated model of the ClassifierDLApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val classifierDL = ClassifierDLModel.pretrained() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;classification&quot;) The default model is &quot;classifierdl_use_trec6&quot;, if no name is provided. It uses embeddings from the UniversalSentenceEncoder and is trained on the TREC-6 dataset. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples and the ClassifierDLTestSpec. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: CATEGORY Python API: ClassifierDLModel Scala API: ClassifierDLModel Source: ClassifierDLModel Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) useEmbeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) sarcasmDL = ClassifierDLModel.pretrained(&quot;classifierdl_use_sarcasm&quot;) .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;sarcasm&quot;) pipeline = Pipeline() .setStages([ documentAssembler, sentence, useEmbeddings, sarcasmDL ]) data = spark.createDataFrame([ [&quot;I&#39;m ready!&quot;], [&quot;If I could put into words how much I love waking up at 6 am on Mondays I would.&quot;] ]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(arrays_zip(sentence, sarcasm)) as out&quot;) .selectExpr(&quot;out.sentence.result as sentence&quot;, &quot;out.sarcasm.result as sarcasm&quot;) .show(truncate=False) +-+-+ |sentence |sarcasm| +-+-+ |I&#39;m ready! |normal | |If I could put into words how much I love waking up at 6 am on Mondays I would.|sarcasm| +-+-+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.SentenceDetector import com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel import com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val useEmbeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val sarcasmDL = ClassifierDLModel.pretrained(&quot;classifierdl_use_sarcasm&quot;) .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;sarcasm&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentence, useEmbeddings, sarcasmDL )) val data = Seq( &quot;I&#39;m ready!&quot;, &quot;If I could put into words how much I love waking up at 6 am on Mondays I would.&quot; ).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(arrays_zip(sentence, sarcasm)) as out&quot;) .selectExpr(&quot;out.sentence.result as sentence&quot;, &quot;out.sarcasm.result as sarcasm&quot;) .show(false) +-+-+ |sentence |sarcasm| +-+-+ |I&#39;m ready! |normal | |If I could put into words how much I love waking up at 6 am on Mondays I would.|sarcasm| +-+-+ ContextSpellChecker ModelApproach Trains a deep-learning based Noisy Channel Model Spell Algorithm. Correction candidates are extracted combining context information and word information. For instantiated/pretrained models, see ContextSpellCheckerModel. Spell Checking is a sequence to sequence mapping problem. Given an input sequence, potentially containing a certain number of errors, ContextSpellChecker will rank correction sequences according to three things: Different correction candidates for each word — word level. The surrounding text of each word, i.e. it’s context — sentence level. The relative cost of different correction candidates according to the edit operations at the character level it requires — subword level. For an in-depth explanation of the module see the article Applying Context Aware Spell Checking in Spark NLP. For extended examples of usage, see the article Training a Contextual Spell Checker for Italian Language, the Examples and the ContextSpellCheckerTestSpec. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: ContextSpellCheckerApproach Scala API: ContextSpellCheckerApproach Source: ContextSpellCheckerApproach Show Example PythonScala # For this example, we use the first Sherlock Holmes book as the training dataset. import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) spellChecker = ContextSpellCheckerApproach() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;corrected&quot;) .setWordMaxDistance(3) .setBatchSize(24) .setEpochs(8) .setLanguageModelClasses(1650) # dependant on vocabulary size # .addVocabClass(&quot;_NAME_&quot;, names) # Extra classes for correction could be added like this pipeline = Pipeline().setStages([ documentAssembler, tokenizer, spellChecker ]) path = &quot;sherlockholmes.txt&quot; dataset = spark.read.text(path) .toDF(&quot;text&quot;) pipelineModel = pipeline.fit(dataset) // For this example, we use the first Sherlock Holmes book as the training dataset. import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.spell.context.ContextSpellCheckerApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val spellChecker = new ContextSpellCheckerApproach() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;corrected&quot;) .setWordMaxDistance(3) .setBatchSize(24) .setEpochs(8) .setLanguageModelClasses(1650) // dependant on vocabulary size // .addVocabClass(&quot;_NAME_&quot;, names) // Extra classes for correction could be added like this val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, spellChecker )) val path = &quot;src/test/resources/spell/sherlockholmes.txt&quot; val dataset = spark.sparkContext.textFile(path) .toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(dataset) Implements a deep-learning based Noisy Channel Model Spell Algorithm. Correction candidates are extracted combining context information and word information. Spell Checking is a sequence to sequence mapping problem. Given an input sequence, potentially containing a certain number of errors, ContextSpellChecker will rank correction sequences according to three things: Different correction candidates for each word — word level. The surrounding text of each word, i.e. it’s context — sentence level. The relative cost of different correction candidates according to the edit operations at the character level it requires — subword level. For an in-depth explanation of the module see the article Applying Context Aware Spell Checking in Spark NLP. This is the instantiated model of the ContextSpellCheckerApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val spellChecker = ContextSpellCheckerModel.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;checked&quot;) The default model is &quot;spellcheck_dl&quot;, if no name is provided. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples and the ContextSpellCheckerTestSpec. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: ContextSpellCheckerModel Scala API: ContextSpellCheckerModel Source: ContextSpellCheckerModel DateMatcher Matches standard date formats into a provided format. Reads from different forms of date and time expressions and converts them to a provided date format. Extracts only one date per document. Use with sentence detector to find matches in each sentence. To extract multiple dates from a document, please use the MultiDateMatcher. Reads the following kind of dates: &quot;1978-01-28&quot;, &quot;1984/04/02,1/02/1980&quot;, &quot;2/28/79&quot;, &quot;The 31st of April in the year 2008&quot;, &quot;Fri, 21 Nov 1997&quot;, &quot;Jan 21, ‘97&quot;, &quot;Sun&quot;, &quot;Nov 21&quot;, &quot;jan 1st&quot;, &quot;next thursday&quot;, &quot;last wednesday&quot;, &quot;today&quot;, &quot;tomorrow&quot;, &quot;yesterday&quot;, &quot;next week&quot;, &quot;next month&quot;, &quot;next year&quot;, &quot;day after&quot;, &quot;the day before&quot;, &quot;0600h&quot;, &quot;06:00 hours&quot;, &quot;6pm&quot;, &quot;5:30 a.m.&quot;, &quot;at 5&quot;, &quot;12:59&quot;, &quot;23:59&quot;, &quot;1988/11/23 6pm&quot;, &quot;next week at 7.30&quot;, &quot;5 am tomorrow&quot; For example &quot;The 31st of April in the year 2008&quot; will be converted into 2008/04/31. Pretrained pipelines are available for this module, see Pipelines. For extended examples of usage, see the Examples and the DateMatcherTestSpec. Input Annotator Types: DOCUMENT Output Annotator Type: DATE Python API: DateMatcher Scala API: DateMatcher Source: DateMatcher Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) date = DateMatcher() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;date&quot;) .setAnchorDateYear(2020) .setAnchorDateMonth(1) .setAnchorDateDay(11) .setDateFormat(&quot;yyyy/MM/dd&quot;) pipeline = Pipeline().setStages([ documentAssembler, date ]) data = spark.createDataFrame([[&quot;Fri, 21 Nov 1997&quot;], [&quot;next week at 7.30&quot;], [&quot;see you a day after&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;date&quot;).show(truncate=False) +-+ |date | +-+ |[[date, 5, 15, 1997/11/21, [sentence -&gt; 0], []]] | |[[date, 0, 8, 2020/01/18, [sentence -&gt; 0], []]] | |[[date, 10, 18, 2020/01/12, [sentence -&gt; 0], []]]| +-+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.DateMatcher import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val date = new DateMatcher() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;date&quot;) .setAnchorDateYear(2020) .setAnchorDateMonth(1) .setAnchorDateDay(11) .setDateFormat(&quot;yyyy/MM/dd&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, date )) val data = Seq(&quot;Fri, 21 Nov 1997&quot;, &quot;next week at 7.30&quot;, &quot;see you a day after&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;date&quot;).show(false) +-+ |date | +-+ |[[date, 5, 15, 1997/11/21, [sentence -&gt; 0], []]] | |[[date, 0, 8, 2020/01/18, [sentence -&gt; 0], []]] | |[[date, 10, 18, 2020/01/12, [sentence -&gt; 0], []]]| +-+ DependencyParser ModelApproach Trains an unlabeled parser that finds a grammatical relations between two words in a sentence. For instantiated/pretrained models, see DependencyParserModel. Dependency parser provides information about word relationship. For example, dependency parsing can tell you what the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help you find precise answers to specific questions. The required training data can be set in two different ways (only one can be chosen for a particular model): Dependency treebank in the Penn Treebank format set with setDependencyTreeBank Dataset in the CoNLL-U format set with setConllU Apart from that, no additional training data is needed. See DependencyParserApproachTestSpec for further reference on how to use this API. Input Annotator Types: DOCUMENT, POS, TOKEN Output Annotator Type: DEPENDENCY Python API: DependencyParserApproach Scala API: DependencyParserApproach Source: DependencyParserApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) posTagger = PerceptronModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) dependencyParserApproach = DependencyParserApproach() .setInputCols(&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;) .setOutputCol(&quot;dependency&quot;) .setDependencyTreeBank(&quot;src/test/resources/parser/unlabeled/dependency_treebank&quot;) pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, posTagger, dependencyParserApproach ]) # Additional training data is not needed, the dependency parser relies on the dependency tree bank / CoNLL-U only. emptyDataSet = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(emptyDataSet) import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel import com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val posTagger = PerceptronModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) val dependencyParserApproach = new DependencyParserApproach() .setInputCols(&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;) .setOutputCol(&quot;dependency&quot;) .setDependencyTreeBank(&quot;src/test/resources/parser/unlabeled/dependency_treebank&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, posTagger, dependencyParserApproach )) // Additional training data is not needed, the dependency parser relies on the dependency tree bank / CoNLL-U only. val emptyDataSet = Seq.empty[String].toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(emptyDataSet) Unlabeled parser that finds a grammatical relation between two words in a sentence. Dependency parser provides information about word relationship. For example, dependency parsing can tell you what the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help you find precise answers to specific questions. This is the instantiated model of the DependencyParserApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val dependencyParserApproach = DependencyParserModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;) .setOutputCol(&quot;dependency&quot;) The default model is &quot;dependency_conllu&quot;, if no name is provided. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples and the DependencyParserApproachTestSpec. Input Annotator Types: [String]DOCUMENT, POS, TOKEN Output Annotator Type: DEPENDENCY Python API: DependencyParserModel Scala API: DependencyParserModel Source: DependencyParserModel Doc2Chunk Converts DOCUMENT type annotations into CHUNK type with the contents of a chunkCol. Chunk text must be contained within input DOCUMENT. May be either StringType or ArrayType[StringType] (using setIsArray). Useful for annotators that require a CHUNK type input. Input Annotator Types: DOCUMENT Output Annotator Type: CHUNK Python API: Doc2Chunk Scala API: Doc2Chunk Source: Doc2Chunk Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) chunkAssembler = Doc2Chunk() .setInputCols(&quot;document&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) .setIsArray(True) data = spark.createDataFrame([[ &quot;Spark NLP is an open-source text processing library for advanced natural language processing.&quot;, [&quot;Spark NLP&quot;, &quot;text processing library&quot;, &quot;natural language processing&quot;] ]]).toDF(&quot;text&quot;, &quot;target&quot;) pipeline = Pipeline().setStages([documentAssembler, chunkAssembler]).fit(data) result = pipeline.transform(data) result.selectExpr(&quot;chunk.result&quot;, &quot;chunk.annotatorType&quot;).show(truncate=False) +--++ |result |annotatorType | +--++ |[Spark NLP, text processing library, natural language processing]|[chunk, chunk, chunk]| +--++ import spark.implicits._ import com.johnsnowlabs.nlp.{Doc2Chunk, DocumentAssembler} import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val chunkAssembler = new Doc2Chunk() .setInputCols(&quot;document&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) .setIsArray(true) val data = Seq( (&quot;Spark NLP is an open-source text processing library for advanced natural language processing.&quot;, Seq(&quot;Spark NLP&quot;, &quot;text processing library&quot;, &quot;natural language processing&quot;)) ).toDF(&quot;text&quot;, &quot;target&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, chunkAssembler)).fit(data) val result = pipeline.transform(data) result.selectExpr(&quot;chunk.result&quot;, &quot;chunk.annotatorType&quot;).show(false) +--++ |result |annotatorType | +--++ |[Spark NLP, text processing library, natural language processing]|[chunk, chunk, chunk]| +--++ Doc2Vec ModelApproach Trains a Word2Vec model that creates vector representations of words in a text corpus. The algorithm first constructs a vocabulary from the corpus and then learns vector representation of words in the vocabulary. The vector representation can be used as features in natural language processing and machine learning algorithms. We use Word2Vec implemented in Spark ML. It uses skip-gram model in our implementation and a hierarchical softmax method to train the model. The variable names in the implementation match the original C implementation. For instantiated/pretrained models, see Doc2VecModel. Sources : For the original C implementation, see https://code.google.com/p/word2vec/ For the research paper, see Efficient Estimation of Word Representations in Vector Space and Distributed Representations of Words and Phrases and their Compositionality. Input Annotator Types: TOKEN Output Annotator Type: SENTENCE_EMBEDDINGS Python API: Doc2VecApproach Scala API: Doc2VecApproach Source: Doc2VecApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = Doc2VecApproach() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) pipeline = Pipeline() .setStages([ documentAssembler, tokenizer, embeddings ]) path = &quot;sherlockholmes.txt&quot; dataset = spark.read.text(path).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(dataset) import spark.implicits._ import com.johnsnowlabs.nlp.annotator.{Tokenizer, Doc2VecApproach} import com.johnsnowlabs.nlp.base.DocumentAssembler import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = new Doc2VecApproach() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, tokenizer, embeddings )) val path = &quot;src/test/resources/spell/sherlockholmes.txt&quot; val dataset = spark.sparkContext.textFile(path) .toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(dataset) Word2Vec model that creates vector representations of words in a text corpus. The algorithm first constructs a vocabulary from the corpus and then learns vector representation of words in the vocabulary. The vector representation can be used as features in natural language processing and machine learning algorithms. We use Word2Vec implemented in Spark ML. It uses skip-gram model in our implementation and a hierarchical softmax method to train the model. The variable names in the implementation match the original C implementation. This is the instantiated model of the Doc2VecApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val embeddings = Doc2VecModel.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) The default model is &quot;doc2vec_gigaword_300&quot;, if no name is provided. For available pretrained models please see the Models Hub. Sources : For the original C implementation, see https://code.google.com/p/word2vec/ For the research paper, see Efficient Estimation of Word Representations in Vector Space and Distributed Representations of Words and Phrases and their Compositionality. Input Annotator Types: TOKEN Output Annotator Type: SENTENCE_EMBEDDINGS Python API: Doc2VecModel Scala API: Doc2VecModel Source: Doc2VecModel Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = Doc2VecModel.pretrained() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) embeddingsFinisher = EmbeddingsFinisher() .setInputCols([&quot;embeddings&quot;]) .setOutputCols(&quot;finished_embeddings&quot;) .setOutputAsVector(True) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, embeddings, embeddingsFinisher ]) data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(1, 80) +--+ | result| +--+ |[0.06222493574023247,0.011579325422644615,0.009919632226228714,0.109361454844...| +--+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.{Tokenizer, Doc2VecModel} import com.johnsnowlabs.nlp.EmbeddingsFinisher import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = Doc2VecModel.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) val embeddingsFinisher = new EmbeddingsFinisher() .setInputCols(&quot;embeddings&quot;) .setOutputCols(&quot;finished_embeddings&quot;) .setOutputAsVector(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, embeddings, embeddingsFinisher )) val data = Seq(&quot;This is a sentence.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(1, 80) +--+ | result| +--+ |[0.06222493574023247,0.011579325422644615,0.009919632226228714,0.109361454844...| +--+ DocumentAssembler Prepares data into a format that is processable by Spark NLP. This is the entry point for every Spark NLP pipeline. The DocumentAssembler can read either a String column or an Array[String]. Additionally, setCleanupMode can be used to pre-process the text (Default: disabled). For possible options please refer the parameters section. For more extended examples on document pre-processing see the Examples. Input Annotator Types: NONE Output Annotator Type: DOCUMENT Python API: DocumentAssembler Scala API: DocumentAssembler Source: DocumentAssembler Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline data = spark.createDataFrame([[&quot;Spark NLP is an open-source text processing library.&quot;]]).toDF(&quot;text&quot;) documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) result = documentAssembler.transform(data) result.select(&quot;document&quot;).show(truncate=False) +-+ |document | +-+ |[[document, 0, 51, Spark NLP is an open-source text processing library., [sentence -&gt; 0], []]]| +-+ result.select(&quot;document&quot;).printSchema root |-- document: array (nullable = True) | |-- element: struct (containsNull = True) | | |-- annotatorType: string (nullable = True) | | |-- begin: integer (nullable = False) | | |-- end: integer (nullable = False) | | |-- result: string (nullable = True) | | |-- metadata: map (nullable = True) | | | |-- key: string | | | |-- value: string (valueContainsNull = True) | | |-- embeddings: array (nullable = True) | | | |-- element: float (containsNull = False) import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler val data = Seq(&quot;Spark NLP is an open-source text processing library.&quot;).toDF(&quot;text&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val result = documentAssembler.transform(data) result.select(&quot;document&quot;).show(false) +-+ |document | +-+ |[[document, 0, 51, Spark NLP is an open-source text processing library., [sentence -&gt; 0], []]]| +-+ result.select(&quot;document&quot;).printSchema root |-- document: array (nullable = true) | |-- element: struct (containsNull = true) | | |-- annotatorType: string (nullable = true) | | |-- begin: integer (nullable = false) | | |-- end: integer (nullable = false) | | |-- result: string (nullable = true) | | |-- metadata: map (nullable = true) | | | |-- key: string | | | |-- value: string (valueContainsNull = true) | | |-- embeddings: array (nullable = true) | | | |-- element: float (containsNull = false) DocumentNormalizer Annotator which normalizes raw text from tagged text, e.g. scraped web pages or xml documents, from document type columns into Sentence. Removes all dirty characters from text following one or more input regex patterns. Can apply not wanted character removal with a specific policy. Can apply lower case normalization. For extended examples of usage, see the Examples. Input Annotator Types: DOCUMENT Output Annotator Type: DOCUMENT Python API: DocumentNormalizer Scala API: DocumentNormalizer Source: DocumentNormalizer Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) cleanUpPatterns = [&quot;&lt;[^&gt;]&gt;&quot;] documentNormalizer = DocumentNormalizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;normalizedDocument&quot;) .setAction(&quot;clean&quot;) .setPatterns(cleanUpPatterns) .setReplacement(&quot; &quot;) .setPolicy(&quot;pretty_all&quot;) .setLowercase(True) pipeline = Pipeline().setStages([ documentAssembler, documentNormalizer ]) text = &quot;&quot;&quot; &lt;div id=&quot;theworldsgreatest&quot; class=&#39;my-right my-hide-small my-wide toptext&#39; style=&quot;font-family:&#39;Segoe UI&#39;,Arial,sans-serif&quot;&gt; THE WORLD&#39;S LARGEST WEB DEVELOPER SITE &lt;h1 style=&quot;font-size:300%;&quot;&gt;THE WORLD&#39;S LARGEST WEB DEVELOPER SITE&lt;/h1&gt; &lt;p style=&quot;font-size:160%;&quot;&gt;Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum..&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) result = pipelineModel.transform(data) result.selectExpr(&quot;normalizedDocument.result&quot;).show(truncate=False) +--+ |result | +--+ |[ the world&#39;s largest web developer site the world&#39;s largest web developer site lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..]| +--+ import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotator.DocumentNormalizer import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val cleanUpPatterns = Array(&quot;&lt;[^&gt;]&gt;&quot;) val documentNormalizer = new DocumentNormalizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;normalizedDocument&quot;) .setAction(&quot;clean&quot;) .setPatterns(cleanUpPatterns) .setReplacement(&quot; &quot;) .setPolicy(&quot;pretty_all&quot;) .setLowercase(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, documentNormalizer )) val text = &quot;&quot;&quot; &lt;div id=&quot;theworldsgreatest&quot; class=&#39;my-right my-hide-small my-wide toptext&#39; style=&quot;font-family:&#39;Segoe UI&#39;,Arial,sans-serif&quot;&gt; THE WORLD&#39;S LARGEST WEB DEVELOPER SITE &lt;h1 style=&quot;font-size:300%;&quot;&gt;THE WORLD&#39;S LARGEST WEB DEVELOPER SITE&lt;/h1&gt; &lt;p style=&quot;font-size:160%;&quot;&gt;Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum..&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&quot;&quot;&quot; val data = Seq(text).toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val result = pipelineModel.transform(data) result.selectExpr(&quot;normalizedDocument.result&quot;).show(truncate=false) +--+ |result | +--+ |[ the world&#39;s largest web developer site the world&#39;s largest web developer site lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..]| +--+ EmbeddingsFinisher Extracts embeddings from Annotations into a more easily usable form. This is useful for example: WordEmbeddings, BertEmbeddings, SentenceEmbeddings and ChunkEmbeddings. By using EmbeddingsFinisher you can easily transform your embeddings into array of floats or vectors which are compatible with Spark ML functions such as LDA, K-mean, Random Forest classifier or any other functions that require featureCol. For more extended examples see the Examples. Input Annotator Types: EMBEDDINGS Output Annotator Type: NONE Python API: EmbeddingsFinisher Scala API: EmbeddingsFinisher Source: EmbeddingsFinisher Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) normalizer = Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) stopwordsCleaner = StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) gloveEmbeddings = WordEmbeddingsModel.pretrained() .setInputCols(&quot;document&quot;, &quot;cleanTokens&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) embeddingsFinisher = EmbeddingsFinisher() .setInputCols(&quot;embeddings&quot;) .setOutputCols(&quot;finished_sentence_embeddings&quot;) .setOutputAsVector(True) .setCleanAnnotations(False) data = spark.createDataFrame([[&quot;Spark NLP is an open-source text processing library.&quot;]]) .toDF(&quot;text&quot;) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, normalizer, stopwordsCleaner, gloveEmbeddings, embeddingsFinisher ]).fit(data) result = pipeline.transform(data) resultWithSize = result.selectExpr(&quot;explode(finished_sentence_embeddings) as embeddings&quot;) resultWithSize.show(5, 80) +--+ | embeddings| +--+ |[0.1619900017976761,0.045552998781204224,-0.03229299932718277,-0.685609996318...| |[-0.42416998744010925,1.1378999948501587,-0.5717899799346924,-0.5078899860382...| |[0.08621499687433243,-0.15772999823093414,-0.06067200005054474,0.395359992980...| |[-0.4970499873161316,0.7164199948310852,0.40119001269340515,-0.05761000141501...| |[-0.08170200139284134,0.7159299850463867,-0.20677000284194946,0.0295659992843...| +--+ import spark.implicits._ import org.apache.spark.ml.Pipeline import com.johnsnowlabs.nlp.{DocumentAssembler, EmbeddingsFinisher} import com.johnsnowlabs.nlp.annotator.{Normalizer, StopWordsCleaner, Tokenizer, WordEmbeddingsModel} val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) val stopwordsCleaner = new StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val gloveEmbeddings = WordEmbeddingsModel.pretrained() .setInputCols(&quot;document&quot;, &quot;cleanTokens&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(false) val embeddingsFinisher = new EmbeddingsFinisher() .setInputCols(&quot;embeddings&quot;) .setOutputCols(&quot;finished_sentence_embeddings&quot;) .setOutputAsVector(true) .setCleanAnnotations(false) val data = Seq(&quot;Spark NLP is an open-source text processing library.&quot;) .toDF(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, normalizer, stopwordsCleaner, gloveEmbeddings, embeddingsFinisher )).fit(data) val result = pipeline.transform(data) val resultWithSize = result.selectExpr(&quot;explode(finished_sentence_embeddings)&quot;) .map { row =&gt; val vector = row.getAs[org.apache.spark.ml.linalg.DenseVector](0) (vector.size, vector) }.toDF(&quot;size&quot;, &quot;vector&quot;) resultWithSize.show(5, 80) +-+--+ |size| vector| +-+--+ | 100|[0.1619900017976761,0.045552998781204224,-0.03229299932718277,-0.685609996318...| | 100|[-0.42416998744010925,1.1378999948501587,-0.5717899799346924,-0.5078899860382...| | 100|[0.08621499687433243,-0.15772999823093414,-0.06067200005054474,0.395359992980...| | 100|[-0.4970499873161316,0.7164199948310852,0.40119001269340515,-0.05761000141501...| | 100|[-0.08170200139284134,0.7159299850463867,-0.20677000284194946,0.0295659992843...| +-+--+ EntityRuler ModelApproach Fits an Annotator to match exact strings or regex patterns provided in a file against a Document and assigns them an named entity. The definitions can contain any number of named entities. There are multiple ways and formats to set the extraction resource. It is possible to set it either as a “JSON”, “JSONL” or “CSV” file. A path to the file needs to be provided to setPatternsResource. The file format needs to be set as the “format” field in the option parameter map and depending on the file type, additional parameters might need to be set. To enable regex extraction, setEnablePatternRegex(true) needs to be called. If the file is in a JSON format, then the rule definitions need to be given in a list with the fields “id”, “label” and “patterns”: [ { &quot;id&quot;: &quot;person-regex&quot;, &quot;label&quot;: &quot;PERSON&quot;, &quot;patterns&quot;: [&quot; w+ s w+&quot;, &quot; w+- w+&quot;] }, { &quot;id&quot;: &quot;locations-words&quot;, &quot;label&quot;: &quot;LOCATION&quot;, &quot;patterns&quot;: [&quot;Winterfell&quot;] } ] The same fields also apply to a file in the JSONL format: {&quot;id&quot;: &quot;names-with-j&quot;, &quot;label&quot;: &quot;PERSON&quot;, &quot;patterns&quot;: [&quot;Jon&quot;, &quot;John&quot;, &quot;John Snow&quot;]} {&quot;id&quot;: &quot;names-with-s&quot;, &quot;label&quot;: &quot;PERSON&quot;, &quot;patterns&quot;: [&quot;Stark&quot;, &quot;Snow&quot;]} {&quot;id&quot;: &quot;names-with-e&quot;, &quot;label&quot;: &quot;PERSON&quot;, &quot;patterns&quot;: [&quot;Eddard&quot;, &quot;Eddard Stark&quot;]} In order to use a CSV file, an additional parameter “delimiter” needs to be set. In this case, the delimiter might be set by using .setPatternsResource(&quot;patterns.csv&quot;, ReadAs.TEXT, Map(&quot;format&quot;-&gt;&quot;csv&quot;, &quot;delimiter&quot; -&gt; &quot; |&quot;)) PERSON|Jon PERSON|John PERSON|John Snow LOCATION|Winterfell Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: EntityRulerApproach Scala API: EntityRulerApproach Source: EntityRulerApproach Show Example PythonScala # In this example, the entities file as the form of # # PERSON|Jon # PERSON|John # PERSON|John Snow # LOCATION|Winterfell # # where each line represents an entity and the associated string delimited by &quot;|&quot;. import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp.common import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) entityRuler = EntityRulerApproach() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;entities&quot;) .setPatternsResource( &quot;patterns.csv&quot;, ReadAs.TEXT, {&quot;format&quot;: &quot;csv&quot;, &quot;delimiter&quot;: &quot; |&quot;} ) .setEnablePatternRegex(True) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, entityRuler ]) data = spark.createDataFrame([[&quot;Jon Snow wants to be lord of Winterfell.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(entities)&quot;).show(truncate=False) +--+ |col | +--+ |[chunk, 0, 2, Jon, [entity -&gt; PERSON, sentence -&gt; 0], []] | |[chunk, 29, 38, Winterfell, [entity -&gt; LOCATION, sentence -&gt; 0], []]| +--+ // In this example, the entities file as the form of // // PERSON|Jon // PERSON|John // PERSON|John Snow // LOCATION|Winterfell // // where each line represents an entity and the associated string delimited by &quot;|&quot;. import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.er.EntityRulerApproach import com.johnsnowlabs.nlp.util.io.ReadAs import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val entityRuler = new EntityRulerApproach() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;entities&quot;) .setPatternsResource( &quot;src/test/resources/entity-ruler/patterns.csv&quot;, ReadAs.TEXT, {&quot;format&quot;: &quot;csv&quot;, &quot;delimiter&quot;: &quot;|&quot;)} ) .setEnablePatternRegex(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, entityRuler )) val data = Seq(&quot;Jon Snow wants to be lord of Winterfell.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(entities)&quot;).show(false) +--+ |col | +--+ |[chunk, 0, 2, Jon, [entity -&gt; PERSON, sentence -&gt; 0], []] | |[chunk, 29, 38, Winterfell, [entity -&gt; LOCATION, sentence -&gt; 0], []]| +--+ Instantiated model of the EntityRulerApproach. For usage and examples see the documentation of the main class. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: EntityRulerModel Scala API: EntityRulerModel Source: EntityRulerModel Finisher Converts annotation results into a format that easier to use. It is useful to extract the results from Spark NLP Pipelines. The Finisher outputs annotation(s) values into String. For more extended examples on document pre-processing see the Examples. Input Annotator Types: ANY Output Annotator Type: NONE Python API: Finisher Scala API: Finisher Source: Finisher Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline from sparknlp.pretrained import PretrainedPipeline data = spark.createDataFrame([[1, &quot;New York and New Jersey aren&#39;t that far apart actually.&quot;]]).toDF(&quot;id&quot;, &quot;text&quot;) # Extracts Named Entities amongst other things pipeline = PretrainedPipeline(&quot;explain_document_dl&quot;) finisher = Finisher().setInputCols(&quot;entities&quot;).setOutputCols(&quot;output&quot;) explainResult = pipeline.transform(data) explainResult.selectExpr(&quot;explode(entities)&quot;).show(truncate=False) ++ |entities | ++ |[[chunk, 0, 7, New York, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 0], []], [chunk, 13, 22, New Jersey, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 1], []]]| ++ result = finisher.transform(explainResult) result.select(&quot;output&quot;).show(truncate=False) +-+ |output | +-+ |[New York, New Jersey]| +-+ import spark.implicits._ import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline import com.johnsnowlabs.nlp.Finisher val data = Seq((1, &quot;New York and New Jersey aren&#39;t that far apart actually.&quot;)).toDF(&quot;id&quot;, &quot;text&quot;) // Extracts Named Entities amongst other things val pipeline = PretrainedPipeline(&quot;explain_document_dl&quot;) val finisher = new Finisher().setInputCols(&quot;entities&quot;).setOutputCols(&quot;output&quot;) val explainResult = pipeline.transform(data) explainResult.selectExpr(&quot;explode(entities)&quot;).show(false) ++ |entities | ++ |[[chunk, 0, 7, New York, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 0], []], [chunk, 13, 22, New Jersey, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 1], []]]| ++ val result = finisher.transform(explainResult) result.select(&quot;output&quot;).show(false) +-+ |output | +-+ |[New York, New Jersey]| +-+ GraphExtraction Extracts a dependency graph between entities. The GraphExtraction class takes e.g. extracted entities from a NerDLModel and creates a dependency tree which describes how the entities relate to each other. For that a triple store format is used. Nodes represent the entities and the edges represent the relations between those entities. The graph can then be used to find relevant relationships between words. Both the DependencyParserModel and TypedDependencyParserModel need to be present in the pipeline. There are two ways to set them: Both Annotators are present in the pipeline already. The dependencies are taken implicitly from these two Annotators. Setting setMergeEntities to true will download the default pretrained models for those two Annotators automatically. The specific models can also be set with setDependencyParserModel and setTypedDependencyParserModel: val graph_extraction = new GraphExtraction() .setInputCols(&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;) .setOutputCol(&quot;graph&quot;) .setRelationshipTypes(Array(&quot;prefer-LOC&quot;)) .setMergeEntities(true) //.setDependencyParserModel(Array(&quot;dependency_conllu&quot;, &quot;en&quot;, &quot;public/models&quot;)) //.setTypedDependencyParserModel(Array(&quot;dependency_typed_conllu&quot;, &quot;en&quot;, &quot;public/models&quot;)) To transform the resulting graph into a more generic form such as RDF, see the GraphFinisher. Input Annotator Types: DOCUMENT, TOKEN, NAMED_ENTITY Output Annotator Type: NODE Python API: GraphExtraction Scala API: GraphExtraction Source: GraphExtraction Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) nerTagger = NerDLModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) posTagger = PerceptronModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) dependencyParser = DependencyParserModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;]) .setOutputCol(&quot;dependency&quot;) typedDependencyParser = TypedDependencyParserModel.pretrained() .setInputCols([&quot;dependency&quot;, &quot;pos&quot;, &quot;token&quot;]) .setOutputCol(&quot;dependency_type&quot;) graph_extraction = GraphExtraction() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;graph&quot;) .setRelationshipTypes([&quot;prefer-LOC&quot;]) pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, embeddings, nerTagger, posTagger, dependencyParser, typedDependencyParser, graph_extraction ]) data = spark.createDataFrame([[&quot;You and John prefer the morning flight through Denver&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.select(&quot;graph&quot;).show(truncate=False) +--+ |graph | +--+ |13, 18, prefer, [relationship -&gt; prefer,LOC, path1 -&gt; prefer,nsubj,morning,flat,flight,flat,Denver], []| +--+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel import com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel import com.johnsnowlabs.nlp.annotators.parser.typdep.TypedDependencyParserModel import org.apache.spark.ml.Pipeline import com.johnsnowlabs.nlp.annotators.GraphExtraction val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = WordEmbeddingsModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) val nerTagger = NerDLModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) val posTagger = PerceptronModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) val dependencyParser = DependencyParserModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;) .setOutputCol(&quot;dependency&quot;) val typedDependencyParser = TypedDependencyParserModel.pretrained() .setInputCols(&quot;dependency&quot;, &quot;pos&quot;, &quot;token&quot;) .setOutputCol(&quot;dependency_type&quot;) val graph_extraction = new GraphExtraction() .setInputCols(&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;) .setOutputCol(&quot;graph&quot;) .setRelationshipTypes(Array(&quot;prefer-LOC&quot;)) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger, posTagger, dependencyParser, typedDependencyParser, graph_extraction )) val data = Seq(&quot;You and John prefer the morning flight through Denver&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.select(&quot;graph&quot;).show(false) +--+ |graph | +--+ |[[node, 13, 18, prefer, [relationship -&gt; prefer,LOC, path1 -&gt; prefer,nsubj,morning,flat,flight,flat,Denver], []]]| +--+ GraphFinisher Helper class to convert the knowledge graph from GraphExtraction into a generic format, such as RDF. Input Annotator Types: NONE Output Annotator Type: NONE Python API: GraphFinisher Scala API: GraphFinisher Source: GraphFinisher Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # This is a continuation of the example of # GraphExtraction. To see how the graph is extracted, see the # documentation of that class. graphFinisher = GraphFinisher() .setInputCol(&quot;graph&quot;) .setOutputCol(&quot;graph_finished&quot;) .setOutputAs[False] finishedResult = graphFinisher.transform(result) finishedResult.select(&quot;text&quot;, &quot;graph_finished&quot;).show(truncate=False) +--+--+ |text |graph_finished | +--+--+ |You and John prefer the morning flight through Denver|(morning,flat,flight), (flight,flat,Denver)| +--+--+ // This is a continuation of the example of // [[com.johnsnowlabs.nlp.annotators.GraphExtraction GraphExtraction]]. To see how the graph is extracted, see the // documentation of that class. import com.johnsnowlabs.nlp.GraphFinisher val graphFinisher = new GraphFinisher() .setInputCol(&quot;graph&quot;) .setOutputCol(&quot;graph_finished&quot;) .setOutputAsArray(false) val finishedResult = graphFinisher.transform(result) finishedResult.select(&quot;text&quot;, &quot;graph_finished&quot;).show(false) +--+--+ |text |graph_finished | +--+--+ |You and John prefer the morning flight through Denver|[[(prefer,nsubj,morning), (morning,flat,flight), (flight,flat,Denver)]]| +--+--+ ImageAssembler Prepares images read by Spark into a format that is processable by Spark NLP. This component is needed to process images. Input Annotator Types: NONE Output Annotator Type: IMAGE Python API: ImageAssembler Scala API: ImageAssembler Source: ImageAssembler Show Example PythonScala import sparknlp from sparknlp.base import * from pyspark.ml import Pipeline data = spark.read.format(&quot;image&quot;).load(&quot;./tmp/images/&quot;).toDF(&quot;image&quot;) imageAssembler = ImageAssembler().setInputCol(&quot;image&quot;).setOutputCol(&quot;image_assembler&quot;) result = imageAssembler.transform(data) result.select(&quot;image_assembler&quot;).show() result.select(&quot;image_assembler&quot;).printSchema() root |-- image_assembler: array (nullable = true) | |-- element: struct (containsNull = true) | | |-- annotatorType: string (nullable = true) | | |-- origin: string (nullable = true) | | |-- height: integer (nullable = true) | | |-- width: integer (nullable = true) | | |-- nChannels: integer (nullable = true) | | |-- mode: integer (nullable = true) | | |-- result: binary (nullable = true) | | |-- metadata: map (nullable = true) | | | |-- key: string | | | |-- value: string (valueContainsNull = true) import com.johnsnowlabs.nlp.ImageAssembler import org.apache.spark.ml.Pipeline val imageDF: DataFrame = spark.read .format(&quot;image&quot;) .option(&quot;dropInvalid&quot;, value = true) .load(&quot;src/test/resources/image/&quot;) val imageAssembler = new ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) val pipeline = new Pipeline().setStages(Array(imageAssembler)) val pipelineDF = pipeline.fit(imageDF).transform(imageDF) pipelineDF.printSchema() root |-- image_assembler: array (nullable = true) | |-- element: struct (containsNull = true) | | |-- annotatorType: string (nullable = true) | | |-- origin: string (nullable = true) | | |-- height: integer (nullable = false) | | |-- width: integer (nullable = false) | | |-- nChannels: integer (nullable = false) | | |-- mode: integer (nullable = false) | | |-- result: binary (nullable = true) | | |-- metadata: map (nullable = true) | | | |-- key: string | | | |-- value: string (valueContainsNull = true) LanguageDetectorDL Language Identification and Detection by using CNN and RNN architectures in TensorFlow. LanguageDetectorDL is an annotator that detects the language of documents or sentences depending on the inputCols. The models are trained on large datasets such as Wikipedia and Tatoeba. Depending on the language (how similar the characters are), the LanguageDetectorDL works best with text longer than 140 characters. The output is a language code in Wiki Code style. Pretrained models can be loaded with pretrained of the companion object: Val languageDetector = LanguageDetectorDL.pretrained() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;language&quot;) The default model is &quot;ld_wiki_tatoeba_cnn_21&quot;, default language is &quot;xx&quot; (meaning multi-lingual), if no values are provided. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples And the LanguageDetectorDLTestSpec. Input Annotator Types: DOCUMENT Output Annotator Type: LANGUAGE Python API: LanguageDetectorDL Scala API: LanguageDetectorDL Source: LanguageDetectorDL Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) languageDetector = LanguageDetectorDL.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;language&quot;) pipeline = Pipeline() .setStages([ documentAssembler, languageDetector ]) data = spark.createDataFrame([ [&quot;Spark NLP is an open-source text processing library for advanced natural language processing for the Python, Java and Scala programming languages.&quot;], [&quot;Spark NLP est une bibliothèque de traitement de texte open source pour le traitement avancé du langage naturel pour les langages de programmation Python, Java et Scala.&quot;], [&quot;Spark NLP ist eine Open-Source-Textverarbeitungsbibliothek für fortgeschrittene natürliche Sprachverarbeitung für die Programmiersprachen Python, Java und Scala.&quot;] ]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.select(&quot;language.result&quot;).show(truncate=False) ++ |result| ++ |[en] | |[fr] | |[de] | ++ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.ld.dl.LanguageDetectorDL import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val languageDetector = LanguageDetectorDL.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;language&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, languageDetector )) val data = Seq( &quot;Spark NLP is an open-source text processing library for advanced natural language processing for the Python, Java and Scala programming languages.&quot;, &quot;Spark NLP est une bibliothèque de traitement de texte open source pour le traitement avancé du langage naturel pour les langages de programmation Python, Java et Scala.&quot;, &quot;Spark NLP ist eine Open-Source-Textverarbeitungsbibliothek für fortgeschrittene natürliche Sprachverarbeitung für die Programmiersprachen Python, Java und Scala.&quot; ).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.select(&quot;language.result&quot;).show(false) ++ |result| ++ |[en] | |[fr] | |[de] | ++ Lemmatizer ModelApproach Class to find lemmas out of words with the objective of returning a base dictionary word. Retrieves the significant part of a word. A dictionary of predefined lemmas must be provided with setDictionary. The dictionary can be set as a delimited text file. Pretrained models can be loaded with LemmatizerModel.pretrained. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: Lemmatizer Scala API: Lemmatizer Source: Lemmatizer Show Example PythonScala # In this example, the lemma dictionary `lemmas_small.txt` has the form of # # ... # pick -&gt; pick picks picking picked # peck -&gt; peck pecking pecked pecks # pickle -&gt; pickle pickles pickled pickling # pepper -&gt; pepper peppers peppered peppering # ... # # where each key is delimited by `-&gt;` and values are delimited by ` t` import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) lemmatizer = Lemmatizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;lemma&quot;) .setDictionary(&quot;src/test/resources/lemma-corpus-small/lemmas_small.txt&quot;, &quot;-&gt;&quot;, &quot; t&quot;) pipeline = Pipeline() .setStages([ documentAssembler, sentenceDetector, tokenizer, lemmatizer ]) data = spark.createDataFrame([[&quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;]]) .toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;lemma.result&quot;).show(truncate=False) ++ |result | ++ |[Peter, Pipers, employees, are, pick, peck, of, pickle, pepper, .]| ++ // In this example, the lemma dictionary `lemmas_small.txt` has the form of // // ... // pick -&gt; pick picks picking picked // peck -&gt; peck pecking pecked pecks // pickle -&gt; pickle pickles pickled pickling // pepper -&gt; pepper peppers peppered peppering // ... // // where each key is delimited by `-&gt;` and values are delimited by ` t` import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotator.Tokenizer import com.johnsnowlabs.nlp.annotator.SentenceDetector import com.johnsnowlabs.nlp.annotators.Lemmatizer import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val lemmatizer = new Lemmatizer() .setInputCols(Array(&quot;token&quot;)) .setOutputCol(&quot;lemma&quot;) .setDictionary(&quot;src/test/resources/lemma-corpus-small/lemmas_small.txt&quot;, &quot;-&gt;&quot;, &quot; t&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentenceDetector, tokenizer, lemmatizer )) val data = Seq(&quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;) .toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;lemma.result&quot;).show(false) ++ |result | ++ |[Peter, Pipers, employees, are, pick, peck, of, pickle, pepper, .]| ++ Instantiated Model of the Lemmatizer. For usage and examples, please see the documentation of that class. For available pretrained models please see the Models Hub. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: LemmatizerModel Scala API: LemmatizerModel Source: LemmatizerModel MultiClassifierDL ModelApproach Trains a MultiClassifierDL for Multi-label Text Classification. MultiClassifierDL uses a Bidirectional GRU with a convolutional model that we have built inside TensorFlow and supports up to 100 classes. For instantiated/pretrained models, see MultiClassifierDLModel. The input to MultiClassifierDL are Sentence Embeddings such as the state-of-the-art UniversalSentenceEncoder, BertSentenceEmbeddings or SentenceEmbeddings. In machine learning, multi-label classification and the strongly related problem of multi-output classification are variants of the classification problem where multiple labels may be assigned to each instance. Multi-label classification is a generalization of multiclass classification, which is the single-label problem of categorizing instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many of the classes the instance can be assigned to. Formally, multi-label classification is the problem of finding a model that maps inputs x to binary vectors y (assigning a value of 0 or 1 for each element (label) in y). Setting a test dataset to monitor model metrics can be done with .setTestDataset. The method expects a path to a parquet file containing a dataframe that has the same required columns as the training dataframe. The pre-processing steps for the training dataframe should also be applied to the test dataframe. The following example will show how to create the test dataset: val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val embeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val preProcessingPipeline = new Pipeline().setStages(Array(documentAssembler, embeddings)) val Array(train, test) = data.randomSplit(Array(0.8, 0.2)) preProcessingPipeline .fit(test) .transform(test) .write .mode(&quot;overwrite&quot;) .parquet(&quot;test_data&quot;) val multiClassifier = new MultiClassifierDLApproach() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;category&quot;) .setLabelColumn(&quot;label&quot;) .setTestDataset(&quot;test_data&quot;) For extended examples of usage, see the Examples and the MultiClassifierDLTestSpec. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: CATEGORY Note: This annotator accepts a label column of a single item in either type of String, Int, Float, or Double. UniversalSentenceEncoder, BertSentenceEmbeddings, SentenceEmbeddings or other sentence based embeddings can be used for the inputCol Python API: MultiClassifierDLApproach Scala API: MultiClassifierDLApproach Source: MultiClassifierDLApproach Show Example PythonScala # In this example, the training data has the form # # +-+--+--+ # | id| text| labels| # +-+--+--+ # |ed58abb40640f983|PN NewsYou mean ... | [toxic]| # |a1237f726b5f5d89|Dude. Place the ...| [obscene, insult]| # |24b0d6c8733c2abe|Thanks - thanks ...| [insult]| # |8c4478fb239bcfc0|&quot; Gee, 5 minutes ...|[toxic, obscene, ...| # +-+--+--+ import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # Process training data to create text with associated array of labels trainDataset.printSchema() # root # |-- id: string (nullable = true) # |-- text: string (nullable = true) # |-- labels: array (nullable = true) # | |-- element: string (containsNull = true) # Then create pipeline for training documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) .setCleanupMode(&quot;shrink&quot;) embeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;embeddings&quot;) docClassifier = MultiClassifierDLApproach() .setInputCols(&quot;embeddings&quot;) .setOutputCol(&quot;category&quot;) .setLabelColumn(&quot;labels&quot;) .setBatchSize(128) .setMaxEpochs(10) .setLr(1e-3) .setThreshold(0.5) .setValidationSplit(0.1) pipeline = Pipeline() .setStages( [ documentAssembler, embeddings, docClassifier ] ) pipelineModel = pipeline.fit(trainDataset) // In this example, the training data has the form (Note: labels can be arbitrary) // // mr,ref // &quot;name[Alimentum], area[city centre], familyFriendly[no], near[Burger King]&quot;,Alimentum is an adult establish found in the city centre area near Burger King. // &quot;name[Alimentum], area[city centre], familyFriendly[yes]&quot;,Alimentum is a family-friendly place in the city centre. // ... // // It needs some pre-processing first, so the labels are of type `Array[String]`. This can be done like so: import spark.implicits._ import com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLApproach import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder import org.apache.spark.ml.Pipeline import org.apache.spark.sql.functions.{col, udf} // Process training data to create text with associated array of labels def splitAndTrim = udf { labels: String =&gt; labels.split(&quot;, &quot;).map(x=&gt;x.trim) } val smallCorpus = spark.read .option(&quot;header&quot;, true) .option(&quot;inferSchema&quot;, true) .option(&quot;mode&quot;, &quot;DROPMALFORMED&quot;) .csv(&quot;src/test/resources/classifier/e2e.csv&quot;) .withColumn(&quot;labels&quot;, splitAndTrim(col(&quot;mr&quot;))) .withColumn(&quot;text&quot;, col(&quot;ref&quot;)) .drop(&quot;mr&quot;) smallCorpus.printSchema() // root // |-- ref: string (nullable = true) // |-- labels: array (nullable = true) // | |-- element: string (containsNull = true) // Then create pipeline for training val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) .setCleanupMode(&quot;shrink&quot;) val embeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;embeddings&quot;) val docClassifier = new MultiClassifierDLApproach() .setInputCols(&quot;embeddings&quot;) .setOutputCol(&quot;category&quot;) .setLabelColumn(&quot;labels&quot;) .setBatchSize(128) .setMaxEpochs(10) .setLr(1e-3f) .setThreshold(0.5f) .setValidationSplit(0.1f) val pipeline = new Pipeline() .setStages( Array( documentAssembler, embeddings, docClassifier ) ) val pipelineModel = pipeline.fit(smallCorpus) MultiClassifierDL for Multi-label Text Classification. MultiClassifierDL Bidirectional GRU with Convolution model we have built inside TensorFlow and supports up to 100 classes. The input to MultiClassifierDL are Sentence Embeddings such as state-of-the-art UniversalSentenceEncoder, BertSentenceEmbeddings or SentenceEmbeddings. This is the instantiated model of the MultiClassifierDLApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val multiClassifier = MultiClassifierDLModel.pretrained() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;categories&quot;) The default model is &quot;multiclassifierdl_use_toxic&quot;, if no name is provided. It uses embeddings from the UniversalSentenceEncoder and classifies toxic comments. The data is based on the Jigsaw Toxic Comment Classification Challenge. For available pretrained models please see the Models Hub. In machine learning, multi-label classification and the strongly related problem of multi-output classification are variants of the classification problem where multiple labels may be assigned to each instance. Multi-label classification is a generalization of multiclass classification, which is the single-label problem of categorizing instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many of the classes the instance can be assigned to. Formally, multi-label classification is the problem of finding a model that maps inputs x to binary vectors y (assigning a value of 0 or 1 for each element (label) in y). For extended examples of usage, see the Examples and the MultiClassifierDLTestSpec. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: CATEGORY Python API: MultiClassifierDLModel Scala API: MultiClassifierDLModel Source: MultiClassifierDLModel Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) useEmbeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) multiClassifierDl = MultiClassifierDLModel.pretrained() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;classifications&quot;) pipeline = Pipeline() .setStages([ documentAssembler, useEmbeddings, multiClassifierDl ]) data = spark.createDataFrame([ [&quot;This is pretty good stuff!&quot;], [&quot;Wtf kind of crap is this&quot;] ]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.select(&quot;text&quot;, &quot;classifications.result&quot;).show(truncate=False) +--+-+ |text |result | +--+-+ |This is pretty good stuff!|[] | |Wtf kind of crap is this |[toxic, obscene]| +--+-+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLModel import com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val useEmbeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val multiClassifierDl = MultiClassifierDLModel.pretrained() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;classifications&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, useEmbeddings, multiClassifierDl )) val data = Seq( &quot;This is pretty good stuff!&quot;, &quot;Wtf kind of crap is this&quot; ).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.select(&quot;text&quot;, &quot;classifications.result&quot;).show(false) +--+-+ |text |result | +--+-+ |This is pretty good stuff!|[] | |Wtf kind of crap is this |[toxic, obscene]| +--+-+ MultiDateMatcher Matches standard date formats into a provided format. Reads the following kind of dates: &quot;1978-01-28&quot;, &quot;1984/04/02,1/02/1980&quot;, &quot;2/28/79&quot;, &quot;The 31st of April in the year 2008&quot;, &quot;Fri, 21 Nov 1997&quot;, &quot;Jan 21, ‘97&quot;, &quot;Sun&quot;, &quot;Nov 21&quot;, &quot;jan 1st&quot;, &quot;next thursday&quot;, &quot;last wednesday&quot;, &quot;today&quot;, &quot;tomorrow&quot;, &quot;yesterday&quot;, &quot;next week&quot;, &quot;next month&quot;, &quot;next year&quot;, &quot;day after&quot;, &quot;the day before&quot;, &quot;0600h&quot;, &quot;06:00 hours&quot;, &quot;6pm&quot;, &quot;5:30 a.m.&quot;, &quot;at 5&quot;, &quot;12:59&quot;, &quot;23:59&quot;, &quot;1988/11/23 6pm&quot;, &quot;next week at 7.30&quot;, &quot;5 am tomorrow&quot; For example &quot;The 31st of April in the year 2008&quot; will be converted into 2008/04/31. For extended examples of usage, see the Examples and the MultiDateMatcherTestSpec. Input Annotator Types: DOCUMENT Output Annotator Type: DATE Python API: MultiDateMatcher Scala API: MultiDateMatcher Source: MultiDateMatcher Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) date = MultiDateMatcher() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;date&quot;) .setAnchorDateYear(2020) .setAnchorDateMonth(1) .setAnchorDateDay(11) .setDateFormat(&quot;yyyy/MM/dd&quot;) pipeline = Pipeline().setStages([ documentAssembler, date ]) data = spark.createDataFrame([[&quot;I saw him yesterday and he told me that he will visit us next week&quot;]]) .toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(date) as dates&quot;).show(truncate=False) +--+ |dates | +--+ |[date, 57, 65, 2020/01/18, [sentence -&gt; 0], []]| |[date, 10, 18, 2020/01/10, [sentence -&gt; 0], []]| +--+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.MultiDateMatcher import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val date = new MultiDateMatcher() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;date&quot;) .setAnchorDateYear(2020) .setAnchorDateMonth(1) .setAnchorDateDay(11) .setDateFormat(&quot;yyyy/MM/dd&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, date )) val data = Seq(&quot;I saw him yesterday and he told me that he will visit us next week&quot;) .toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(date) as dates&quot;).show(false) +--+ |dates | +--+ |[date, 57, 65, 2020/01/18, [sentence -&gt; 0], []]| |[date, 10, 18, 2020/01/10, [sentence -&gt; 0], []]| +--+ MultiDocumentAssembler Prepares data into a format that is processable by Spark NLP. This is the entry point for every Spark NLP pipeline. The MultiDocumentAssembler can read either a String column or an Array[String]. Additionally, MultiDocumentAssembler.setCleanupMode can be used to pre-process the text (Default: disabled). For possible options please refer the parameters section. For more extended examples on document pre-processing see the Examples. Input Annotator Types: NONE Output Annotator Type: DOCUMENT Python API: MultiDocumentAssembler Scala API: MultiDocumentAssembler Source: MultiDocumentAssembler Show Example PythonScala import sparknlp from sparknlp.base import * from pyspark.ml import Pipeline data = spark.createDataFrame([[&quot;Spark NLP is an open-source text processing library.&quot;], [&quot;Spark NLP is a state-of-the-art Natural Language Processing library built on top of Apache Spark&quot;]]).toDF(&quot;text&quot;, &quot;text2&quot;) documentAssembler = MultiDocumentAssembler().setInputCols([&quot;text&quot;, &quot;text2&quot;]).setOutputCols([&quot;document1&quot;, &quot;document2&quot;]) result = documentAssembler.transform(data) result.select(&quot;document1&quot;).show(truncate=False) +-+ |document1 | +-+ |[[document, 0, 51, Spark NLP is an open-source text processing library., [sentence -&gt; 0], []]]| +-+ result.select(&quot;document1&quot;).printSchema() root |-- document: array (nullable = True) | |-- element: struct (containsNull = True) | | |-- annotatorType: string (nullable = True) | | |-- begin: integer (nullable = False) | | |-- end: integer (nullable = False) | | |-- result: string (nullable = True) | | |-- metadata: map (nullable = True) | | | |-- key: string | | | |-- value: string (valueContainsNull = True) | | |-- embeddings: array (nullable = True) | | | |-- element: float (containsNull = False) import spark.implicits._ import com.johnsnowlabs.nlp.MultiDocumentAssembler val data = Seq(&quot;Spark NLP is an open-source text processing library.&quot;).toDF(&quot;text&quot;) val multiDocumentAssembler = new MultiDocumentAssembler().setInputCols(&quot;text&quot;).setOutputCols(&quot;document&quot;) val result = multiDocumentAssembler.transform(data) result.select(&quot;document&quot;).show(false) +-+ |document | +-+ |[[document, 0, 51, Spark NLP is an open-source text processing library., [sentence -&gt; 0], []]]| +-+ result.select(&quot;document&quot;).printSchema root |-- document: array (nullable = true) | |-- element: struct (containsNull = true) | | |-- annotatorType: string (nullable = true) | | |-- begin: integer (nullable = false) | | |-- end: integer (nullable = false) | | |-- result: string (nullable = true) | | |-- metadata: map (nullable = true) | | | |-- key: string | | | |-- value: string (valueContainsNull = true) | | |-- embeddings: array (nullable = true) | | | |-- element: float (containsNull = false) NGramGenerator A feature transformer that converts the input array of strings (annotatorType TOKEN) into an array of n-grams (annotatorType CHUNK). Null values in the input array are ignored. It returns an array of n-grams where each n-gram is represented by a space-separated string of words. When the input is empty, an empty array is returned. When the input array length is less than n (number of elements per n-gram), no n-grams are returned. For more extended examples see the Examples and the NGramGeneratorTestSpec. Input Annotator Types: TOKEN Output Annotator Type: CHUNK Python API: NGramGenerator Scala API: NGramGenerator Source: NGramGenerator Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) nGrams = NGramGenerator() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;ngrams&quot;) .setN(2) pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, nGrams ]) data = spark.createDataFrame([[&quot;This is my sentence.&quot;]]).toDF(&quot;text&quot;) results = pipeline.fit(data).transform(data) results.selectExpr(&quot;explode(ngrams) as result&quot;).show(truncate=False) ++ |result | ++ |[chunk, 0, 6, This is, [sentence -&gt; 0, chunk -&gt; 0], []] | |[chunk, 5, 9, is my, [sentence -&gt; 0, chunk -&gt; 1], []] | |[chunk, 8, 18, my sentence, [sentence -&gt; 0, chunk -&gt; 2], []]| |[chunk, 11, 19, sentence ., [sentence -&gt; 0, chunk -&gt; 3], []]| ++ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.SentenceDetector import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.NGramGenerator import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val nGrams = new NGramGenerator() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;ngrams&quot;) .setN(2) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, nGrams )) val data = Seq(&quot;This is my sentence.&quot;).toDF(&quot;text&quot;) val results = pipeline.fit(data).transform(data) results.selectExpr(&quot;explode(ngrams) as result&quot;).show(false) ++ |result | ++ |[chunk, 0, 6, This is, [sentence -&gt; 0, chunk -&gt; 0], []] | |[chunk, 5, 9, is my, [sentence -&gt; 0, chunk -&gt; 1], []] | |[chunk, 8, 18, my sentence, [sentence -&gt; 0, chunk -&gt; 2], []]| |[chunk, 11, 19, sentence ., [sentence -&gt; 0, chunk -&gt; 3], []]| ++ NerConverter Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label. Results in CHUNK Annotation type. NER chunks can then be filtered by setting a whitelist with setWhiteList. Chunks with no associated entity (tagged “O”) are filtered. See also Inside–outside–beginning (tagging) for more information. Input Annotator Types: DOCUMENT, TOKEN, NAMED_ENTITY Output Annotator Type: CHUNK Python API: NerConverter Scala API: NerConverter Source: NerConverter Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # This is a continuation of the example of the NerDLModel. See that class # on how to extract the entities. # The output of the NerDLModel follows the Annotator schema and can be converted like so: # # result.selectExpr(&quot;explode(ner)&quot;).show(truncate=False) # +-+ # |col | # +-+ # |[named_entity, 0, 2, B-ORG, [word -&gt; U.N], []] | # |[named_entity, 3, 3, O, [word -&gt; .], []] | # |[named_entity, 5, 12, O, [word -&gt; official], []] | # |[named_entity, 14, 18, B-PER, [word -&gt; Ekeus], []] | # |[named_entity, 20, 24, O, [word -&gt; heads], []] | # |[named_entity, 26, 28, O, [word -&gt; for], []] | # |[named_entity, 30, 36, B-LOC, [word -&gt; Baghdad], []]| # |[named_entity, 37, 37, O, [word -&gt; .], []] | # +-+ # # After the converter is used: converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;entities&quot;) converter.transform(result).selectExpr(&quot;explode(entities)&quot;).show(truncate=False) ++ |col | ++ |[chunk, 0, 2, U.N, [entity -&gt; ORG, sentence -&gt; 0, chunk -&gt; 0], []] | |[chunk, 14, 18, Ekeus, [entity -&gt; PER, sentence -&gt; 0, chunk -&gt; 1], []] | |[chunk, 30, 36, Baghdad, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 2], []]| ++ // This is a continuation of the example of the [[com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel NerDLModel]]. See that class // on how to extract the entities. // The output of the NerDLModel follows the Annotator schema and can be converted like so: // // result.selectExpr(&quot;explode(ner)&quot;).show(false) // +-+ // |col | // +-+ // |[named_entity, 0, 2, B-ORG, [word -&gt; U.N], []] | // |[named_entity, 3, 3, O, [word -&gt; .], []] | // |[named_entity, 5, 12, O, [word -&gt; official], []] | // |[named_entity, 14, 18, B-PER, [word -&gt; Ekeus], []] | // |[named_entity, 20, 24, O, [word -&gt; heads], []] | // |[named_entity, 26, 28, O, [word -&gt; for], []] | // |[named_entity, 30, 36, B-LOC, [word -&gt; Baghdad], []]| // |[named_entity, 37, 37, O, [word -&gt; .], []] | // +-+ // // After the converter is used: val converter = new NerConverter() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;) .setOutputCol(&quot;entities&quot;) .setPreservePosition(false) converter.transform(result).selectExpr(&quot;explode(entities)&quot;).show(false) ++ |col | ++ |[chunk, 0, 2, U.N, [entity -&gt; ORG, sentence -&gt; 0, chunk -&gt; 0], []] | |[chunk, 14, 18, Ekeus, [entity -&gt; PER, sentence -&gt; 0, chunk -&gt; 1], []] | |[chunk, 30, 36, Baghdad, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 2], []]| ++ NerCrf ModelApproach Algorithm for training a Named Entity Recognition Model For instantiated/pretrained models, see NerCrfModel. This Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning algorithm. The training data should be a labeled Spark Dataset, e.g. CoNLL 2003 IOB with Annotation type columns. The data should have columns of type DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS and an additional label column of annotator type NAMED_ENTITY. Excluding the label, this can be done with for example a SentenceDetector, a Tokenizer and a PerceptronModel and a WordEmbeddingsModel (any word embeddings can be chosen, e.g. BertEmbeddings for BERT based embeddings). Optionally the user can provide an entity dictionary file with setExternalFeatures for better accuracy. For extended examples of usage, see the Examples and the NerCrfApproachTestSpec. Input Annotator Types: DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: NerCrfApproach Scala API: NerCrfApproach Source: NerCrfApproach Show Example PythonScala # This CoNLL dataset already includes the sentence, token, pos and label column with their respective annotator types. # If a custom dataset is used, these need to be defined. import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp.training import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) embeddings = WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) nerTagger = NerCrfApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;pos&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setMinEpochs(1) .setMaxEpochs(3) .setC0(34) .setL2(3.0) .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([ documentAssembler, embeddings, nerTagger ]) conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) // This CoNLL dataset already includes the sentence, token, pos and label column with their respective annotator types. // If a custom dataset is used, these need to be defined. import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotator.NerCrfApproach import com.johnsnowlabs.nlp.training.CoNLL import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val embeddings = WordEmbeddingsModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(false) val nerTagger = new NerCrfApproach() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;pos&quot;, &quot;embeddings&quot;) .setLabelColumn(&quot;label&quot;) .setMinEpochs(1) .setMaxEpochs(3) .setC0(34) .setL2(3.0) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, embeddings, nerTagger )) val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) Extracts Named Entities based on a CRF Model. This Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning algorithm. The data should have columns of type DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS. These can be extracted with for example a SentenceDetector, a Tokenizer and a PerceptronModel This is the instantiated model of the NerCrfApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val nerTagger = NerCrfModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;, &quot;pos&quot;) .setOutputCol(&quot;ner&quot; The default model is &quot;ner_crf&quot;, if no name is provided. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples. Input Annotator Types: DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: NerCrfModel Scala API: NerCrfModel Source: NerCrfModel NerDL ModelApproach This Named Entity recognition annotator allows to train generic NER model based on Neural Networks. The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets. For instantiated/pretrained models, see NerDLModel. The training data should be a labeled Spark Dataset, in the format of CoNLL 2003 IOB with Annotation type columns. The data should have columns of type DOCUMENT, TOKEN, WORD_EMBEDDINGS and an additional label column of annotator type NAMED_ENTITY. Excluding the label, this can be done with for example a SentenceDetector, a Tokenizer and a PerceptronModel and a WordEmbeddingsModel (any word embeddings can be chosen, e.g. BertEmbeddings for BERT based embeddings). Setting a test dataset to monitor model metrics can be done with .setTestDataset. The method expects a path to a parquet file containing a dataframe that has the same required columns as the training dataframe. The pre-processing steps for the training dataframe should also be applied to the test dataframe. The following example will show how to create the test dataset with a CoNLL dataset: val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val embeddings = WordEmbeddingsModel .pretrained() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) val preProcessingPipeline = new Pipeline().setStages(Array(documentAssembler, embeddings)) val conll = CoNLL() val Array(train, test) = conll .readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) .randomSplit(Array(0.8, 0.2)) preProcessingPipeline .fit(test) .transform(test) .write .mode(&quot;overwrite&quot;) .parquet(&quot;test_data&quot;) val nerTagger = new NerDLApproach() .setInputCols(&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setTestDataset(&quot;test_data&quot;) For extended examples of usage, see the Examples and the NerDLSpec. Input Annotator Types: DOCUMENT, TOKEN, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: NerDLApproach Scala API: NerDLApproach Source: NerDLApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp.training import * from pyspark.ml import Pipeline # First extract the prerequisites for the NerDLApproach documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = BertEmbeddings.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Then the training can start nerTagger = NerDLApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(1) .setRandomSeed(0) .setVerbose(0) pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, embeddings, nerTagger ]) # We use the text and labels from the CoNLL dataset conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.embeddings.BertEmbeddings import com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach import com.johnsnowlabs.nlp.training.CoNLL import org.apache.spark.ml.Pipeline // First extract the prerequisites for the NerDLApproach val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger = new NerDLApproach() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(1) .setRandomSeed(0) .setVerbose(0) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) // We use the text and labels from the CoNLL dataset val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) This Named Entity recognition annotator is a generic NER model based on Neural Networks. Neural Network architecture is Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets. This is the instantiated model of the NerDLApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val nerModel = NerDLModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) The default model is &quot;ner_dl&quot;, if no name is provided. For available pretrained models please see the Models Hub. Additionally, pretrained pipelines are available for this module, see Pipelines. Note that some pretrained models require specific types of embeddings, depending on which they were trained on. For example, the default model &quot;ner_dl&quot; requires the WordEmbeddings &quot;glove_100d&quot;. For extended examples of usage, see the Examples and the NerDLSpec. Input Annotator Types: DOCUMENT, TOKEN, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: NerDLModel Scala API: NerDLModel Source: NerDLModel NerOverwriter Overwrites entities of specified strings. The input for this Annotator have to be entities that are already extracted, Annotator type NAMED_ENTITY. The strings specified with setStopWords will have new entities assigned to, specified with setNewResult. Input Annotator Types: NAMED_ENTITY Output Annotator Type: NAMED_ENTITY Python API: NerOverwriter Scala API: NerOverwriter Source: NerOverwriter Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # First extract the prerequisite Entities documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;bert&quot;) nerTagger = NerDLModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;bert&quot;]) .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, embeddings, nerTagger ]) data = spark.createDataFrame([[&quot;Spark NLP Crosses Five Million Downloads, John Snow Labs Announces.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(ner)&quot;).show(truncate=False) # ++ # |col | # ++ # |[named_entity, 0, 4, B-ORG, [word -&gt; Spark], []] | # |[named_entity, 6, 8, I-ORG, [word -&gt; NLP], []] | # |[named_entity, 10, 16, O, [word -&gt; Crosses], []] | # |[named_entity, 18, 21, O, [word -&gt; Five], []] | # |[named_entity, 23, 29, O, [word -&gt; Million], []] | # |[named_entity, 31, 39, O, [word -&gt; Downloads], []] | # |[named_entity, 40, 40, O, [word -&gt; ,], []] | # |[named_entity, 42, 45, B-ORG, [word -&gt; John], []] | # |[named_entity, 47, 50, I-ORG, [word -&gt; Snow], []] | # |[named_entity, 52, 55, I-ORG, [word -&gt; Labs], []] | # |[named_entity, 57, 65, I-ORG, [word -&gt; Announces], []]| # |[named_entity, 66, 66, O, [word -&gt; .], []] | # ++ # The recognized entities can then be overwritten nerOverwriter = NerOverwriter() .setInputCols([&quot;ner&quot;]) .setOutputCol(&quot;ner_overwritten&quot;) .setStopWords([&quot;Million&quot;]) .setNewResult(&quot;B-CARDINAL&quot;) nerOverwriter.transform(result).selectExpr(&quot;explode(ner_overwritten)&quot;).show(truncate=False) ++ |col | ++ |[named_entity, 0, 4, B-ORG, [word -&gt; Spark], []] | |[named_entity, 6, 8, I-ORG, [word -&gt; NLP], []] | |[named_entity, 10, 16, O, [word -&gt; Crosses], []] | |[named_entity, 18, 21, O, [word -&gt; Five], []] | |[named_entity, 23, 29, B-CARDINAL, [word -&gt; Million], []]| |[named_entity, 31, 39, O, [word -&gt; Downloads], []] | |[named_entity, 40, 40, O, [word -&gt; ,], []] | |[named_entity, 42, 45, B-ORG, [word -&gt; John], []] | |[named_entity, 47, 50, I-ORG, [word -&gt; Snow], []] | |[named_entity, 52, 55, I-ORG, [word -&gt; Labs], []] | |[named_entity, 57, 65, I-ORG, [word -&gt; Announces], []] | |[named_entity, 66, 66, O, [word -&gt; .], []] | ++ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel import com.johnsnowlabs.nlp.annotators.ner.NerOverwriter import org.apache.spark.ml.Pipeline // First extract the prerequisite Entities val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = WordEmbeddingsModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;bert&quot;) val nerTagger = NerDLModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;bert&quot;) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) val data = Seq(&quot;Spark NLP Crosses Five Million Downloads, John Snow Labs Announces.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(ner)&quot;).show(false) / ++ |col | ++ |[named_entity, 0, 4, B-ORG, [word -&gt; Spark], []] | |[named_entity, 6, 8, I-ORG, [word -&gt; NLP], []] | |[named_entity, 10, 16, O, [word -&gt; Crosses], []] | |[named_entity, 18, 21, O, [word -&gt; Five], []] | |[named_entity, 23, 29, O, [word -&gt; Million], []] | |[named_entity, 31, 39, O, [word -&gt; Downloads], []] | |[named_entity, 40, 40, O, [word -&gt; ,], []] | |[named_entity, 42, 45, B-ORG, [word -&gt; John], []] | |[named_entity, 47, 50, I-ORG, [word -&gt; Snow], []] | |[named_entity, 52, 55, I-ORG, [word -&gt; Labs], []] | |[named_entity, 57, 65, I-ORG, [word -&gt; Announces], []]| |[named_entity, 66, 66, O, [word -&gt; .], []] | ++ / // The recognized entities can then be overwritten val nerOverwriter = new NerOverwriter() .setInputCols(&quot;ner&quot;) .setOutputCol(&quot;ner_overwritten&quot;) .setStopWords(Array(&quot;Million&quot;)) .setNewResult(&quot;B-CARDINAL&quot;) nerOverwriter.transform(result).selectExpr(&quot;explode(ner_overwritten)&quot;).show(false) ++ |col | ++ |[named_entity, 0, 4, B-ORG, [word -&gt; Spark], []] | |[named_entity, 6, 8, I-ORG, [word -&gt; NLP], []] | |[named_entity, 10, 16, O, [word -&gt; Crosses], []] | |[named_entity, 18, 21, O, [word -&gt; Five], []] | |[named_entity, 23, 29, B-CARDINAL, [word -&gt; Million], []]| |[named_entity, 31, 39, O, [word -&gt; Downloads], []] | |[named_entity, 40, 40, O, [word -&gt; ,], []] | |[named_entity, 42, 45, B-ORG, [word -&gt; John], []] | |[named_entity, 47, 50, I-ORG, [word -&gt; Snow], []] | |[named_entity, 52, 55, I-ORG, [word -&gt; Labs], []] | |[named_entity, 57, 65, I-ORG, [word -&gt; Announces], []] | |[named_entity, 66, 66, O, [word -&gt; .], []] | ++ Normalizer ModelApproach Annotator that cleans out tokens. Requires stems, hence tokens. Removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary For extended examples of usage, see the Examples. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: Normalizer Scala API: Normalizer Source: Normalizer Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) normalizer = Normalizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;normalized&quot;) .setLowercase(True) .setCleanupPatterns([&quot;&quot;&quot;[^ w d s]&quot;&quot;&quot;]) # remove punctuations (keep alphanumeric chars) # if we don&#39;t set CleanupPatterns, it will only keep alphabet letters ([^A-Za-z]) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, normalizer ]) data = spark.createDataFrame([[&quot;John and Peter are brothers. However they don&#39;t support each other that much.&quot;]]) .toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;normalized.result&quot;).show(truncate = False) +-+ |result | +-+ |[john, and, peter, are, brothers, however, they, dont, support, each, other, that, much]| +-+ import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotator.{Normalizer, Tokenizer} import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) .setLowercase(true) .setCleanupPatterns(Array(&quot;&quot;&quot;[^ w d s]&quot;&quot;&quot;)) // remove punctuations (keep alphanumeric chars) // if we don&#39;t set CleanupPatterns, it will only keep alphabet letters ([^A-Za-z]) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, normalizer )) val data = Seq(&quot;John and Peter are brothers. However they don&#39;t support each other that much.&quot;) .toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;normalized.result&quot;).show(truncate = false) +-+ |result | +-+ |[john, and, peter, are, brothers, however, they, dont, support, each, other, that, much]| +-+ Instantiated Model of the Normalizer. For usage and examples, please see the documentation of that class. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: NormalizerModel Scala API: NormalizerModel Source: NormalizerModel NorvigSweeting Spellchecker ModelApproach Trains annotator, that retrieves tokens and makes corrections automatically if not found in an English dictionary. The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster (than the standard approach with deletes + transposes + replaces + inserts) and language independent. A dictionary of correct spellings must be provided with setDictionary as a text file, where each word is parsed by a regex pattern. Inspired by Norvig model and SymSpell. For instantiated/pretrained models, see NorvigSweetingModel. For extended examples of usage, see the NorvigSweetingTestSpec. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: NorvigSweetingApproach Scala API: NorvigSweetingApproach Source: NorvigSweetingApproach Show Example PythonScala # In this example, the dictionary `&quot;words.txt&quot;` has the form of # # ... # gummy # gummic # gummier # gummiest # gummiferous # ... # # This dictionary is then set to be the basis of the spell checker. import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) spellChecker = NorvigSweetingApproach() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;spell&quot;) .setDictionary(&quot;src/test/resources/spell/words.txt&quot;) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, spellChecker ]) pipelineModel = pipeline.fit(trainingData) // In this example, the dictionary `&quot;words.txt&quot;` has the form of // // ... // gummy // gummic // gummier // gummiest // gummiferous // ... // // This dictionary is then set to be the basis of the spell checker. import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val spellChecker = new NorvigSweetingApproach() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;spell&quot;) .setDictionary(&quot;src/test/resources/spell/words.txt&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, spellChecker )) val pipelineModel = pipeline.fit(trainingData) This annotator retrieves tokens and makes corrections automatically if not found in an English dictionary. Inspired by Norvig model and SymSpell. The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster (than the standard approach with deletes + transposes + replaces + inserts) and language independent. This is the instantiated model of the NorvigSweetingApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val spellChecker = NorvigSweetingModel.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;spell&quot;) .setDoubleVariants(true) The default model is &quot;spellcheck_norvig&quot;, if no name is provided. For available pretrained models please see the Models Hub. For extended examples of see the NorvigSweetingTestSpec. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: NorvigSweetingModel Scala API: NorvigSweetingModel Source: NorvigSweetingModel POSTagger (Part of speech tagger) ModelApproach Trains an averaged Perceptron model to tag words part-of-speech. Sets a POS tag to each word within a sentence. For pretrained models please see the PerceptronModel. The training data needs to be in a Spark DataFrame, where the column needs to consist of Annotations of type POS. The Annotation needs to have member result set to the POS tag and have a &quot;word&quot; mapping to its word inside of member metadata. This DataFrame for training can easily created by the helper class POS. POS().readDataset(spark, datasetPath).selectExpr(&quot;explode(tags) as tags&quot;).show(false) ++ |tags | ++ |[pos, 0, 5, NNP, [word -&gt; Pierre], []] | |[pos, 7, 12, NNP, [word -&gt; Vinken], []] | |[pos, 14, 14, ,, [word -&gt; ,], []] | |[pos, 31, 34, MD, [word -&gt; will], []] | |[pos, 36, 39, VB, [word -&gt; join], []] | |[pos, 41, 43, DT, [word -&gt; the], []] | |[pos, 45, 49, NN, [word -&gt; board], []] | ... For extended examples of usage, see the Examples and PerceptronApproach tests. Input Annotator Types: TOKEN, DOCUMENT Output Annotator Type: POS Python API: PerceptronApproach Scala API: PerceptronApproach Source: PerceptronApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp.training import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) datasetPath = &quot;src/test/resources/anc-pos-corpus-small/test-training.txt&quot; trainingPerceptronDF = POS().readDataset(spark, datasetPath) trainedPos = PerceptronApproach() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) .setPosColumn(&quot;tags&quot;) .fit(trainingPerceptronDF) pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, trainedPos ]) data = spark.createDataFrame([[&quot;To be or not to be, is this the question?&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;pos.result&quot;).show(truncate=False) +--+ |result | +--+ |[NNP, NNP, CD, JJ, NNP, NNP, ,, MD, VB, DT, CD, .]| +--+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.SentenceDetector import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.training.POS import com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val datasetPath = &quot;src/test/resources/anc-pos-corpus-small/test-training.txt&quot; val trainingPerceptronDF = POS().readDataset(spark, datasetPath) val trainedPos = new PerceptronApproach() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) .setPosColumn(&quot;tags&quot;) .fit(trainingPerceptronDF) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, trainedPos )) val data = Seq(&quot;To be or not to be, is this the question?&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;pos.result&quot;).show(false) +--+ |result | +--+ |[NNP, NNP, CD, JJ, NNP, NNP, ,, MD, VB, DT, CD, .]| +--+ Averaged Perceptron model to tag words part-of-speech. Sets a POS tag to each word within a sentence. This is the instantiated model of the PerceptronApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val posTagger = PerceptronModel.pretrained() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) The default model is &quot;pos_anc&quot;, if no name is provided. For available pretrained models please see the Models Hub. Additionally, pretrained pipelines are available for this module, see Pipelines. For extended examples of usage, see the Examples. Input Annotator Types: TOKEN, DOCUMENT Output Annotator Type: POS Python API: PerceptronModel Scala API: PerceptronModel Source: PerceptronModel RecursiveTokenizer ModelApproach Tokenizes raw text recursively based on a handful of definable rules. Unlike the Tokenizer, the RecursiveTokenizer operates based on these array string parameters only: prefixes: Strings that will be split when found at the beginning of token. suffixes: Strings that will be split when found at the end of token. infixes: Strings that will be split when found at the middle of token. whitelist: Whitelist of strings not to split For extended examples of usage, see the Examples and the TokenizerTestSpec. Input Annotator Types: DOCUMENT Output Annotator Type: TOKEN Python API: RecursiveTokenizer Scala API: RecursiveTokenizer Source: RecursiveTokenizer Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = RecursiveTokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) pipeline = Pipeline().setStages([ documentAssembler, tokenizer ]) data = spark.createDataFrame([[&quot;One, after the Other, (and) again. PO, QAM,&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.select(&quot;token.result&quot;).show(truncate=False) ++ |result | ++ |[One, ,, after, the, Other, ,, (, and, ), again, ., PO, ,, QAM, ,]| ++ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.RecursiveTokenizer import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new RecursiveTokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer )) val data = Seq(&quot;One, after the Other, (and) again. PO, QAM,&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.select(&quot;token.result&quot;).show(false) ++ |result | ++ |[One, ,, after, the, Other, ,, (, and, ), again, ., PO, ,, QAM, ,]| ++ Instantiated model of the RecursiveTokenizer. For usage and examples see the documentation of the main class. Input Annotator Types: DOCUMENT Output Annotator Type: TOKEN Python API: RecursiveTokenizerModel Scala API: RecursiveTokenizerModel Source: RecursiveTokenizerModel RegexMatcher ModelApproach Uses rules to match a set of regular expressions and associate them with a provided identifier. A rule consists of a regex pattern and an identifier, delimited by a character of choice. An example could be &quot; d{4} / d d / d d,date&quot; which will match strings like &quot;1970/01/01&quot; to the identifier &quot;date&quot;. Rules must be provided by either setRules (followed by setDelimiter) or an external file. To use an external file, a dictionary of predefined regular expressions must be provided with setExternalRules. The dictionary can be set as a delimited text file. Pretrained pipelines are available for this module, see Pipelines. For extended examples of usage, see the Examples and the RegexMatcherTestSpec. Input Annotator Types: DOCUMENT Output Annotator Type: CHUNK Python API: RegexMatcher Scala API: RegexMatcher Source: RegexMatcher Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # In this example, the `rules.txt` has the form of # # the s w+, followed by &#39;the&#39; # ceremonies, ceremony # # where each regex is separated by the identifier by `&quot;,&quot;` documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentence = SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) regexMatcher = RegexMatcher() .setExternalRules(&quot;src/test/resources/regex-matcher/rules.txt&quot;, &quot;,&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;regex&quot;) .setStrategy(&quot;MATCH_ALL&quot;) pipeline = Pipeline().setStages([documentAssembler, sentence, regexMatcher]) data = spark.createDataFrame([[ &quot;My first sentence with the first rule. This is my second sentence with ceremonies rule.&quot; ]]).toDF(&quot;text&quot;) results = pipeline.fit(data).transform(data) results.selectExpr(&quot;explode(regex) as result&quot;).show(truncate=False) +--+ |result | +--+ |[chunk, 23, 31, the first, [identifier -&gt; followed by &#39;the&#39;, sentence -&gt; 0, chunk -&gt; 0], []]| |[chunk, 71, 80, ceremonies, [identifier -&gt; ceremony, sentence -&gt; 1, chunk -&gt; 0], []] | +--+ // In this example, the `rules.txt` has the form of // // the s w+, followed by &#39;the&#39; // ceremonies, ceremony // // where each regex is separated by the identifier by `&quot;,&quot;` import ResourceHelper.spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.SentenceDetector import com.johnsnowlabs.nlp.annotators.RegexMatcher import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val regexMatcher = new RegexMatcher() .setExternalRules(&quot;src/test/resources/regex-matcher/rules.txt&quot;, &quot;,&quot;) .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;regex&quot;) .setStrategy(&quot;MATCH_ALL&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, sentence, regexMatcher)) val data = Seq( &quot;My first sentence with the first rule. This is my second sentence with ceremonies rule.&quot; ).toDF(&quot;text&quot;) val results = pipeline.fit(data).transform(data) results.selectExpr(&quot;explode(regex) as result&quot;).show(false) +--+ |result | +--+ |[chunk, 23, 31, the first, [identifier -&gt; followed by &#39;the&#39;, sentence -&gt; 0, chunk -&gt; 0], []]| |[chunk, 71, 80, ceremonies, [identifier -&gt; ceremony, sentence -&gt; 1, chunk -&gt; 0], []] | +--+ Instantiated model of the RegexMatcher. For usage and examples see the documentation of the main class. Input Annotator Types: DOCUMENT Output Annotator Type: CHUNK Python API: RegexMatcherModel Scala API: RegexMatcherModel Source: RegexMatcherModel RegexTokenizer A tokenizer that splits text by a regex pattern. The pattern needs to be set with setPattern and this sets the delimiting pattern or how the tokens should be split. By default this pattern is s+ which means that tokens should be split by 1 or more whitespace characters. Input Annotator Types: DOCUMENT Output Annotator Type: TOKEN Python API: RegexTokenizer Scala API: RegexTokenizer Source: RegexTokenizer Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) regexTokenizer = RegexTokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;regexToken&quot;) .setToLowercase(True) .setPattern(&quot; s+&quot;) pipeline = Pipeline().setStages([ documentAssembler, regexTokenizer ]) data = spark.createDataFrame([[&quot;This is my first sentence. nThis is my second.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;regexToken.result&quot;).show(truncate=False) +-+ |result | +-+ |[this, is, my, first, sentence., this, is, my, second.]| +-+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.RegexTokenizer import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val regexTokenizer = new RegexTokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;regexToken&quot;) .setToLowercase(true) .setPattern(&quot; s+&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, regexTokenizer )) val data = Seq(&quot;This is my first sentence. nThis is my second.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;regexToken.result&quot;).show(false) +-+ |result | +-+ |[this, is, my, first, sentence., this, is, my, second.]| +-+ SentenceDetector Annotator that detects sentence boundaries using regular expressions. The following characters are checked as sentence boundaries: Lists (“(i), (ii)”, “(a), (b)”, “1., 2.”) Numbers Abbreviations Punctuations Multiple Periods Geo-Locations/Coordinates (“N°. 1026.253.553.”) Ellipsis (“…”) In-between punctuations Quotation marks Exclamation Points Basic Breakers (“.”, “;”) For the explicit regular expressions used for detection, refer to source of PragmaticContentFormatter. To add additional custom bounds, the parameter customBounds can be set with an array: val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) .setCustomBounds(Array(&quot; n n&quot;)) If only the custom bounds should be used, then the parameter useCustomBoundsOnly should be set to true. Each extracted sentence can be returned in an Array or exploded to separate rows, if explodeSentences is set to true. For extended examples of usage, see the Examples. Input Annotator Types: DOCUMENT Output Annotator Type: DOCUMENT Python API: SentenceDetector Scala API: SentenceDetector Source: SentenceDetector Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setCustomBounds([&quot; n n&quot;]) pipeline = Pipeline().setStages([ documentAssembler, sentence ]) data = spark.createDataFrame([[&quot;This is my first sentence. This my second. How about a third?&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(sentence) as sentences&quot;).show(truncate=False) ++ |sentences | ++ |[document, 0, 25, This is my first sentence., [sentence -&gt; 0], []]| |[document, 27, 41, This my second., [sentence -&gt; 1], []] | |[document, 43, 60, How about a third?, [sentence -&gt; 2], []] | ++ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.SentenceDetector import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) .setCustomBounds(Array(&quot; n n&quot;)) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence )) val data = Seq(&quot;This is my first sentence. This my second. How about a third?&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(sentence) as sentences&quot;).show(false) ++ |sentences | ++ |[document, 0, 25, This is my first sentence., [sentence -&gt; 0], []]| |[document, 27, 41, This my second., [sentence -&gt; 1], []] | |[document, 43, 60, How about a third?, [sentence -&gt; 2], []] | ++ SentenceDetectorDL ModelApproach Trains an annotator that detects sentence boundaries using a deep learning approach. For pretrained models see SentenceDetectorDLModel. Currently, only the CNN model is supported for training, but in the future the architecture of the model can be set with setModelArchitecture. The default model &quot;cnn&quot; is based on the paper Deep-EOS: General-Purpose Neural Networks for Sentence Boundary Detection (2020, Stefan Schweter, Sajawel Ahmed) using a CNN architecture. We also modified the original implementation a little bit to cover broken sentences and some impossible end of line chars. Each extracted sentence can be returned in an Array or exploded to separate rows, if explodeSentences is set to true. For extended examples of usage, see the Examples and the SentenceDetectorDLSpec. Input Annotator Types: DOCUMENT Output Annotator Type: DOCUMENT Python API: SentenceDetectorDLApproach Scala API: SentenceDetectorDLApproach Source: SentenceDetectorDLApproach Show Example PythonScala # The training process needs data, where each data point is a sentence. # In this example the `train.txt` file has the form of # # ... # Slightly more moderate language would make our present situation – namely the lack of progress – a little easier. # His political successors now have great responsibilities to history and to the heritage of values bequeathed to them by Nelson Mandela. # ... # # where each line is one sentence. # Training can then be started like so: import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline trainingData = spark.read.text(&quot;train.txt&quot;).toDF(&quot;text&quot;) documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLApproach() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) .setEpochsNumber(100) pipeline = Pipeline().setStages([documentAssembler, sentenceDetector]) model = pipeline.fit(trainingData) // The training process needs data, where each data point is a sentence. // In this example the `train.txt` file has the form of // // ... // Slightly more moderate language would make our present situation – namely the lack of progress – a little easier. // His political successors now have great responsibilities to history and to the heritage of values bequeathed to them by Nelson Mandela. // ... // // where each line is one sentence. // Training can then be started like so: import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.sentence_detector_dl.SentenceDetectorDLApproach import org.apache.spark.ml.Pipeline val trainingData = spark.read.text(&quot;train.txt&quot;).toDF(&quot;text&quot;) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetectorDLApproach() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentences&quot;) .setEpochsNumber(100) val pipeline = new Pipeline().setStages(Array(documentAssembler, sentenceDetector)) val model = pipeline.fit(trainingData) Annotator that detects sentence boundaries using a deep learning approach. Instantiated Model of the SentenceDetectorDLApproach. Detects sentence boundaries using a deep learning approach. Pretrained models can be loaded with pretrained of the companion object: val sentenceDL = SentenceDetectorDLModel.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentencesDL&quot;) The default model is &quot;sentence_detector_dl&quot;, if no name is provided. For available pretrained models please see the Models Hub. Each extracted sentence can be returned in an Array or exploded to separate rows, if explodeSentences is set to true. For extended examples of usage, see the Examples and the SentenceDetectorDLSpec. Input Annotator Types: DOCUMENT Output Annotator Type: DOCUMENT Python API: SentenceDetectorDLModel Scala API: SentenceDetectorDLModel Source: SentenceDetectorDLModel SentenceEmbeddings Converts the results from WordEmbeddings, BertEmbeddings, or ElmoEmbeddings into sentence or document embeddings by either summing up or averaging all the word embeddings in a sentence or a document (depending on the inputCols). This can be configured with setPoolingStrategy, which either be &quot;AVERAGE&quot; or &quot;SUM&quot;. For more extended examples see the Examples. and the SentenceEmbeddingsTestSpec. TIP: Here is how you can explode and convert these embeddings into Vectors or what’s known as Feature column so it can be used in Spark ML regression or clustering functions: PythonScala from org.apache.spark.ml.linal import Vector, Vectors from pyspark.sql.functions import udf # Let&#39;s create a UDF to take array of embeddings and output Vectors @udf(Vector) def convertToVectorUDF(matrix): return Vectors.dense(matrix.toArray.map(_.toDouble)) # Now let&#39;s explode the sentence_embeddings column and have a new feature column for Spark ML pipelineDF.select(explode(&quot;sentence_embeddings.embeddings&quot;).as(&quot;sentence_embedding&quot;)) .withColumn(&quot;features&quot;, convertToVectorUDF(&quot;sentence_embedding&quot;)) import org.apache.spark.ml.linalg.{Vector, Vectors} // Let&#39;s create a UDF to take array of embeddings and output Vectors val convertToVectorUDF = udf((matrix : Seq[Float]) =&gt; { Vectors.dense(matrix.toArray.map(_.toDouble)) }) // Now let&#39;s explode the sentence_embeddings column and have a new feature column for Spark ML pipelineDF.select(explode($&quot;sentence_embeddings.embeddings&quot;).as(&quot;sentence_embedding&quot;)) .withColumn(&quot;features&quot;, convertToVectorUDF($&quot;sentence_embedding&quot;)) Input Annotator Types: DOCUMENT, WORD_EMBEDDINGS Output Annotator Type: SENTENCE_EMBEDDINGS Note: If you choose document as your input for Tokenizer, WordEmbeddings/BertEmbeddings, and SentenceEmbeddings then it averages/sums all the embeddings into one array of embeddings. However, if you choose sentence as inputCols then for each sentence SentenceEmbeddings generates one array of embeddings. Python API: SentenceEmbeddings Scala API: SentenceEmbeddings Source: SentenceEmbeddings Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddingsModel.pretrained() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) embeddingsSentence = SentenceEmbeddings() .setInputCols([&quot;document&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) .setPoolingStrategy(&quot;AVERAGE&quot;) embeddingsFinisher = EmbeddingsFinisher() .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCols(&quot;finished_embeddings&quot;) .setOutputAsVector(True) .setCleanAnnotations(False) pipeline = Pipeline() .setStages([ documentAssembler, tokenizer, embeddings, embeddingsSentence, embeddingsFinisher ]) data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80) +--+ | result| +--+ |[-0.22093398869037628,0.25130119919776917,0.41810303926467896,-0.380883991718...| +--+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.embeddings.SentenceEmbeddings import com.johnsnowlabs.nlp.EmbeddingsFinisher import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = WordEmbeddingsModel.pretrained() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) val embeddingsSentence = new SentenceEmbeddings() .setInputCols(Array(&quot;document&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;sentence_embeddings&quot;) .setPoolingStrategy(&quot;AVERAGE&quot;) val embeddingsFinisher = new EmbeddingsFinisher() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCols(&quot;finished_embeddings&quot;) .setOutputAsVector(true) .setCleanAnnotations(false) val pipeline = new Pipeline() .setStages(Array( documentAssembler, tokenizer, embeddings, embeddingsSentence, embeddingsFinisher )) val data = Seq(&quot;This is a sentence.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80) +--+ | result| +--+ |[-0.22093398869037628,0.25130119919776917,0.41810303926467896,-0.380883991718...| +--+ SentimentDL ModelApproach Trains a SentimentDL, an annotator for multi-class sentiment analysis. In natural language processing, sentiment analysis is the task of classifying the affective state or subjective view of a text. A common example is if either a product review or tweet can be interpreted positively or negatively. For the instantiated/pretrained models, see SentimentDLModel. Notes: This annotator accepts a label column of a single item in either type of String, Int, Float, or Double. So positive sentiment can be expressed as either &quot;positive&quot; or 0, negative sentiment as &quot;negative&quot; or 1. UniversalSentenceEncoder, BertSentenceEmbeddings, SentenceEmbeddings or other sentence based embeddings can be used Setting a test dataset to monitor model metrics can be done with .setTestDataset. The method expects a path to a parquet file containing a dataframe that has the same required columns as the training dataframe. The pre-processing steps for the training dataframe should also be applied to the test dataframe. The following example will show how to create the test dataset: val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val embeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val preProcessingPipeline = new Pipeline().setStages(Array(documentAssembler, embeddings)) val Array(train, test) = data.randomSplit(Array(0.8, 0.2)) preProcessingPipeline .fit(test) .transform(test) .write .mode(&quot;overwrite&quot;) .parquet(&quot;test_data&quot;) val classifier = new SentimentDLApproach() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;sentiment&quot;) .setLabelColumn(&quot;label&quot;) .setTestDataset(&quot;test_data&quot;) For extended examples of usage, see the Examples and the SentimentDLTestSpec. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: CATEGORY Python API: SentimentDLApproach Scala API: SentimentDLApproach Source: SentimentDLApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # In this example, `sentiment.csv` is in the form # # text,label # This movie is the best movie I have watched ever! In my opinion this movie can win an award.,0 # This was a terrible movie! The acting was bad really bad!,1 # # The model can then be trained with smallCorpus = spark.read.option(&quot;header&quot;, &quot;True&quot;).csv(&quot;src/test/resources/classifier/sentiment.csv&quot;) documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) useEmbeddings = UniversalSentenceEncoder.pretrained() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) docClassifier = SentimentDLApproach() .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;sentiment&quot;) .setLabelColumn(&quot;label&quot;) .setBatchSize(32) .setMaxEpochs(1) .setLr(5e-3) .setDropout(0.5) pipeline = Pipeline() .setStages( [ documentAssembler, useEmbeddings, docClassifier ] ) pipelineModel = pipeline.fit(smallCorpus) // In this example, `sentiment.csv` is in the form // // text,label // This movie is the best movie I have watched ever! In my opinion this movie can win an award.,0 // This was a terrible movie! The acting was bad really bad!,1 // // The model can then be trained with import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.UniversalSentenceEncoder import com.johnsnowlabs.nlp.annotators.classifier.dl.{SentimentDLApproach, SentimentDLModel} import org.apache.spark.ml.Pipeline val smallCorpus = spark.read.option(&quot;header&quot;, &quot;true&quot;).csv(&quot;src/test/resources/classifier/sentiment.csv&quot;) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val useEmbeddings = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val docClassifier = new SentimentDLApproach() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;sentiment&quot;) .setLabelColumn(&quot;label&quot;) .setBatchSize(32) .setMaxEpochs(1) .setLr(5e-3f) .setDropout(0.5f) val pipeline = new Pipeline() .setStages( Array( documentAssembler, useEmbeddings, docClassifier ) ) val pipelineModel = pipeline.fit(smallCorpus) SentimentDL, an annotator for multi-class sentiment analysis. In natural language processing, sentiment analysis is the task of classifying the affective state or subjective view of a text. A common example is if either a product review or tweet can be interpreted positively or negatively. This is the instantiated model of the SentimentDLApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val sentiment = SentimentDLModel.pretrained() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;sentiment&quot;) The default model is &quot;sentimentdl_use_imdb&quot;, if no name is provided. It is english sentiment analysis trained on the IMDB dataset. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples and the SentimentDLTestSpec. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: CATEGORY Python API: SentimentDLModel Scala API: SentimentDLModel Source: SentimentDLModel SentimentDetector ModelApproach Trains a rule based sentiment detector, which calculates a score based on predefined keywords. A dictionary of predefined sentiment keywords must be provided with setDictionary, where each line is a word delimited to its class (either positive or negative). The dictionary can be set as a delimited text file. By default, the sentiment score will be assigned labels &quot;positive&quot; if the score is &gt;= 0, else &quot;negative&quot;. To retrieve the raw sentiment scores, enableScore needs to be set to true. For extended examples of usage, see the Examples and the SentimentTestSpec. Input Annotator Types: TOKEN, DOCUMENT Output Annotator Type: SENTIMENT Python API: SentimentDetector Scala API: SentimentDetector Source: SentimentDetector Show Example PythonScala # In this example, the dictionary `default-sentiment-dict.txt` has the form of # # ... # cool,positive # superb,positive # bad,negative # uninspired,negative # ... # # where each sentiment keyword is delimited by `&quot;,&quot;`. import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) lemmatizer = Lemmatizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;lemma&quot;) .setDictionary(&quot;lemmas_small.txt&quot;, &quot;-&gt;&quot;, &quot; t&quot;) sentimentDetector = SentimentDetector() .setInputCols([&quot;lemma&quot;, &quot;document&quot;]) .setOutputCol(&quot;sentimentScore&quot;) .setDictionary(&quot;default-sentiment-dict.txt&quot;, &quot;,&quot;, ReadAs.TEXT) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, lemmatizer, sentimentDetector, ]) data = spark.createDataFrame([ [&quot;The staff of the restaurant is nice&quot;], [&quot;I recommend others to avoid because it is too expensive&quot;] ]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;sentimentScore.result&quot;).show(truncate=False) +-+ # ++ for enableScore set to True |result | # |result| +-+ # ++ |[positive]| # |[1.0] | |[negative]| # |[-2.0]| +-+ # ++ // In this example, the dictionary `default-sentiment-dict.txt` has the form of // // ... // cool,positive // superb,positive // bad,negative // uninspired,negative // ... // // where each sentiment keyword is delimited by `&quot;,&quot;`. import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotator.Tokenizer import com.johnsnowlabs.nlp.annotators.Lemmatizer import com.johnsnowlabs.nlp.annotators.sda.pragmatic.SentimentDetector import com.johnsnowlabs.nlp.util.io.ReadAs import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val lemmatizer = new Lemmatizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;lemma&quot;) .setDictionary(&quot;src/test/resources/lemma-corpus-small/lemmas_small.txt&quot;, &quot;-&gt;&quot;, &quot; t&quot;) val sentimentDetector = new SentimentDetector() .setInputCols(&quot;lemma&quot;, &quot;document&quot;) .setOutputCol(&quot;sentimentScore&quot;) .setDictionary(&quot;src/test/resources/sentiment-corpus/default-sentiment-dict.txt&quot;, &quot;,&quot;, ReadAs.TEXT) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, lemmatizer, sentimentDetector, )) val data = Seq( &quot;The staff of the restaurant is nice&quot;, &quot;I recommend others to avoid because it is too expensive&quot; ).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;sentimentScore.result&quot;).show(false) +-+ // ++ for enableScore set to true |result | // |result| +-+ // ++ |[positive]| // |[1.0] | |[negative]| // |[-2.0]| +-+ // ++ Rule based sentiment detector, which calculates a score based on predefined keywords. This is the instantiated model of the SentimentDetector. For training your own model, please see the documentation of that class. A dictionary of predefined sentiment keywords must be provided with setDictionary, where each line is a word delimited to its class (either positive or negative). The dictionary can be set as a delimited text file. By default, the sentiment score will be assigned labels &quot;positive&quot; if the score is &gt;= 0, else &quot;negative&quot;. To retrieve the raw sentiment scores, enableScore needs to be set to true. For extended examples of usage, see the Examples and the SentimentTestSpec. Input Annotator Types: TOKEN, DOCUMENT Output Annotator Type: SENTIMENT Python API: SentimentDetectorModel Scala API: SentimentDetectorModel Source: SentimentDetectorModel Stemmer Returns hard-stems out of words with the objective of retrieving the meaningful part of the word. For extended examples of usage, see the Examples. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: Stemmer Scala API: Stemmer Source: Stemmer Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) stemmer = Stemmer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;stem&quot;) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, stemmer ]) data = spark.createDataFrame([[&quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;]]) .toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;stem.result&quot;).show(truncate = False) +-+ |result | +-+ |[peter, piper, employe, ar, pick, peck, of, pickl, pepper, .]| +-+ import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotator.{Stemmer, Tokenizer} import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val stemmer = new Stemmer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;stem&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stemmer )) val data = Seq(&quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;) .toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;stem.result&quot;).show(truncate = false) +-+ |result | +-+ |[peter, piper, employe, ar, pick, peck, of, pickl, pepper, .]| +-+ StopWordsCleaner This annotator takes a sequence of strings (e.g. the output of a Tokenizer, Normalizer, Lemmatizer, and Stemmer) and drops all the stop words from the input sequences. By default, it uses stop words from MLlibs StopWordsRemover. Stop words can also be defined by explicitly setting them with setStopWords(value: Array[String]) or loaded from pretrained models using pretrained of its companion object. val stopWords = StopWordsCleaner.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) // will load the default pretrained model `&quot;stopwords_en&quot;`. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples and StopWordsCleanerTestSpec. NOTE: If you need to setStopWords from a text file, you can first read and convert it into an array of string as follows. PythonScala # your stop words text file, each line is one stop word stopwords = sc.textFile(&quot;/tmp/stopwords/english.txt&quot;).collect() # simply use it in StopWordsCleaner stopWordsCleaner = StopWordsCleaner() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setStopWords(stopwords) .setCaseSensitive(False) # or you can use pretrained models for StopWordsCleaner stopWordsCleaner = StopWordsCleaner.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) // your stop words text file, each line is one stop word val stopwords = sc.textFile(&quot;/tmp/stopwords/english.txt&quot;).collect() // simply use it in StopWordsCleaner val stopWordsCleaner = new StopWordsCleaner() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setStopWords(stopwords) .setCaseSensitive(false) // or you can use pretrained models for StopWordsCleaner val stopWordsCleaner = StopWordsCleaner.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: StopWordsCleaner Scala API: StopWordsCleaner Source: StopWordsCleaner Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) stopWords = StopWordsCleaner() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) pipeline = Pipeline().setStages([ documentAssembler, sentenceDetector, tokenizer, stopWords ]) data = spark.createDataFrame([ [&quot;This is my first sentence. This is my second.&quot;], [&quot;This is my third sentence. This is my forth.&quot;] ]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;cleanTokens.result&quot;).show(truncate=False) +-+ |result | +-+ |[first, sentence, ., second, .]| |[third, sentence, ., forth, .] | +-+ import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotator.Tokenizer import com.johnsnowlabs.nlp.annotator.SentenceDetector import com.johnsnowlabs.nlp.annotators.StopWordsCleaner import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val stopWords = new StopWordsCleaner() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, stopWords )) val data = Seq( &quot;This is my first sentence. This is my second.&quot;, &quot;This is my third sentence. This is my forth.&quot; ).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;cleanTokens.result&quot;).show(false) +-+ |result | +-+ |[first, sentence, ., second, .]| |[third, sentence, ., forth, .] | +-+ SymmetricDelete Spellchecker ModelApproach Trains a Symmetric Delete spelling correction algorithm. Retrieves tokens and utilizes distance metrics to compute possible derived words. Inspired by SymSpell. For instantiated/pretrained models, see SymmetricDeleteModel. See SymmetricDeleteModelTestSpec for further reference. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: SymmetricDeleteApproach Scala API: SymmetricDeleteApproach Source: SymmetricDeleteApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # In this example, the dictionary `&quot;words.txt&quot;` has the form of # # ... # gummy # gummic # gummier # gummiest # gummiferous # ... # # This dictionary is then set to be the basis of the spell checker. documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) spellChecker = SymmetricDeleteApproach() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;spell&quot;) .setDictionary(&quot;src/test/resources/spell/words.txt&quot;) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, spellChecker ]) pipelineModel = pipeline.fit(trainingData) // In this example, the dictionary `&quot;words.txt&quot;` has the form of // // ... // gummy // gummic // gummier // gummiest // gummiferous // ... // // This dictionary is then set to be the basis of the spell checker. import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.spell.symmetric.SymmetricDeleteApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val spellChecker = new SymmetricDeleteApproach() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;spell&quot;) .setDictionary(&quot;src/test/resources/spell/words.txt&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, spellChecker )) val pipelineModel = pipeline.fit(trainingData) Symmetric Delete spelling correction algorithm. The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster (than the standard approach with deletes + transposes + replaces + inserts) and language independent. Inspired by SymSpell. Pretrained models can be loaded with pretrained of the companion object: val spell = SymmetricDeleteModel.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;spell&quot;) The default model is &quot;spellcheck_sd&quot;, if no name is provided. For available pretrained models please see the Models Hub. See SymmetricDeleteModelTestSpec for further reference. Input Annotator Types: TOKEN Output Annotator Type: TOKEN Python API: SymmetricDeleteModel Scala API: SymmetricDeleteModel Source: SymmetricDeleteModel TextMatcher ModelApproach Annotator to match exact phrases (by token) provided in a file against a Document. A text file of predefined phrases must be provided with setEntities. For extended examples of usage, see the Examples and the TextMatcherTestSpec. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: TextMatcher Scala API: TextMatcher Source: TextMatcher Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # In this example, the entities file is of the form # # ... # dolore magna aliqua # lorem ipsum dolor. sit # laborum # ... # # where each line represents an entity phrase to be extracted. documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) data = spark.createDataFrame([[&quot;Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum&quot;]]).toDF(&quot;text&quot;) entityExtractor = TextMatcher() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setEntities(&quot;src/test/resources/entity-extractor/test-phrases.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) .setCaseSensitive(False) pipeline = Pipeline().setStages([documentAssembler, tokenizer, entityExtractor]) results = pipeline.fit(data).transform(data) results.selectExpr(&quot;explode(entity) as result&quot;).show(truncate=False) ++ |result | ++ |[chunk, 6, 24, dolore magna aliqua, [entity -&gt; entity, sentence -&gt; 0, chunk -&gt; 0], []] | |[chunk, 27, 48, Lorem ipsum dolor. sit, [entity -&gt; entity, sentence -&gt; 0, chunk -&gt; 1], []]| |[chunk, 53, 59, laborum, [entity -&gt; entity, sentence -&gt; 0, chunk -&gt; 2], []] | ++ // In this example, the entities file is of the form // // ... // dolore magna aliqua // lorem ipsum dolor. sit // laborum // ... // // where each line represents an entity phrase to be extracted. import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotator.Tokenizer import com.johnsnowlabs.nlp.annotator.TextMatcher import com.johnsnowlabs.nlp.util.io.ReadAs import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val data = Seq(&quot;Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum&quot;).toDF(&quot;text&quot;) val entityExtractor = new TextMatcher() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setEntities(&quot;src/test/resources/entity-extractor/test-phrases.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) .setCaseSensitive(false) .setTokenizer(tokenizer.fit(data)) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, entityExtractor)) val results = pipeline.fit(data).transform(data) results.selectExpr(&quot;explode(entity) as result&quot;).show(false) ++ |result | ++ |[chunk, 6, 24, dolore magna aliqua, [entity -&gt; entity, sentence -&gt; 0, chunk -&gt; 0], []] | |[chunk, 27, 48, Lorem ipsum dolor. sit, [entity -&gt; entity, sentence -&gt; 0, chunk -&gt; 1], []]| |[chunk, 53, 59, laborum, [entity -&gt; entity, sentence -&gt; 0, chunk -&gt; 2], []] | ++ Instantiated model of the TextMatcher. For usage and examples see the documentation of the main class. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: TextMatcherModel Scala API: TextMatcherModel Source: TextMatcherModel Token2Chunk Converts TOKEN type Annotations to CHUNK type. This can be useful if a entities have been already extracted as TOKEN and following annotators require CHUNK types. Input Annotator Types: TOKEN Output Annotator Type: CHUNK Python API: Token2Chunk Scala API: Token2Chunk Source: Token2Chunk Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) token2chunk = Token2Chunk() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;chunk&quot;) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, token2chunk ]) data = spark.createDataFrame([[&quot;One Two Three Four&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(chunk) as result&quot;).show(truncate=False) ++ |result | ++ |[chunk, 0, 2, One, [sentence -&gt; 0], []] | |[chunk, 4, 6, Two, [sentence -&gt; 0], []] | |[chunk, 8, 12, Three, [sentence -&gt; 0], []]| |[chunk, 14, 17, Four, [sentence -&gt; 0], []]| ++ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.{Token2Chunk, Tokenizer} import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val token2chunk = new Token2Chunk() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;chunk&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, token2chunk )) val data = Seq(&quot;One Two Three Four&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(chunk) as result&quot;).show(false) ++ |result | ++ |[chunk, 0, 2, One, [sentence -&gt; 0], []] | |[chunk, 4, 6, Two, [sentence -&gt; 0], []] | |[chunk, 8, 12, Three, [sentence -&gt; 0], []]| |[chunk, 14, 17, Four, [sentence -&gt; 0], []]| ++ TokenAssembler This transformer reconstructs a DOCUMENT type annotation from tokens, usually after these have been normalized, lemmatized, normalized, spell checked, etc, in order to use this document annotation in further annotators. Requires DOCUMENT and TOKEN type annotations as input. For more extended examples on document pre-processing see the Examples. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: DOCUMENT Python API: TokenAssembler Scala API: TokenAssembler Source: TokenAssembler Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # First, the text is tokenized and cleaned documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;token&quot;) normalizer = Normalizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;normalized&quot;) .setLowercase(False) stopwordsCleaner = StopWordsCleaner() .setInputCols([&quot;normalized&quot;]) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) # Then the TokenAssembler turns the cleaned tokens into a `DOCUMENT` type structure. tokenAssembler = TokenAssembler() .setInputCols([&quot;sentences&quot;, &quot;cleanTokens&quot;]) .setOutputCol(&quot;cleanText&quot;) data = spark.createDataFrame([[&quot;Spark NLP is an open-source text processing library for advanced natural language processing.&quot;]]) .toDF(&quot;text&quot;) pipeline = Pipeline().setStages([ documentAssembler, sentenceDetector, tokenizer, normalizer, stopwordsCleaner, tokenAssembler ]).fit(data) result = pipeline.transform(data) result.select(&quot;cleanText&quot;).show(truncate=False) ++ |cleanText | ++ |0, 80, Spark NLP opensource text processing library advanced natural language processing, [sentence -&gt; 0], []| ++ import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotator.SentenceDetector import com.johnsnowlabs.nlp.annotator.Tokenizer import com.johnsnowlabs.nlp.annotator.{Normalizer, StopWordsCleaner} import com.johnsnowlabs.nlp.TokenAssembler import org.apache.spark.ml.Pipeline // First, the text is tokenized and cleaned val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) .setLowercase(false) val stopwordsCleaner = new StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) // Then the TokenAssembler turns the cleaned tokens into a `DOCUMENT` type structure. val tokenAssembler = new TokenAssembler() .setInputCols(&quot;sentences&quot;, &quot;cleanTokens&quot;) .setOutputCol(&quot;cleanText&quot;) val data = Seq(&quot;Spark NLP is an open-source text processing library for advanced natural language processing.&quot;) .toDF(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, normalizer, stopwordsCleaner, tokenAssembler )).fit(data) val result = pipeline.transform(data) result.select(&quot;cleanText&quot;).show(false) ++ |cleanText | ++ |[[document, 0, 80, Spark NLP opensource text processing library advanced natural language processing, [sentence -&gt; 0], []]]| ++ Tokenizer ModelApproach Tokenizes raw text in document type columns into TokenizedSentence . This class represents a non fitted tokenizer. Fitting it will cause the internal RuleFactory to construct the rules for tokenizing from the input configuration. Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs. For extended examples of usage see the Examples and Tokenizer test class Input Annotator Types: DOCUMENT Output Annotator Type: TOKEN Note: All these APIs receive regular expressions so please make sure that you escape special characters according to Java conventions. Python API: Tokenizer Scala API: Tokenizer Source: Tokenizer Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline data = spark.createDataFrame([[&quot;I&#39;d like to say we didn&#39;t expect that. Jane&#39;s boyfriend.&quot;]]).toDF(&quot;text&quot;) documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) tokenizer = Tokenizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;token&quot;).fit(data) pipeline = Pipeline().setStages([documentAssembler, tokenizer]).fit(data) result = pipeline.transform(data) result.selectExpr(&quot;token.result&quot;).show(truncate=False) +--+ |output | +--+ |[I&#39;d, like, to, say, we, didn&#39;t, expect, that, ., Jane&#39;s, boyfriend, .]| +--+ import spark.implicits._ import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import org.apache.spark.ml.Pipeline val data = Seq(&quot;I&#39;d like to say we didn&#39;t expect that. Jane&#39;s boyfriend.&quot;).toDF(&quot;text&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer().setInputCols(&quot;document&quot;).setOutputCol(&quot;token&quot;).fit(data) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer)).fit(data) val result = pipeline.transform(data) result.selectExpr(&quot;token.result&quot;).show(false) +--+ |output | +--+ |[I&#39;d, like, to, say, we, didn&#39;t, expect, that, ., Jane&#39;s, boyfriend, .]| +--+ Tokenizes raw text into word pieces, tokens. Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs. This class represents an already fitted Tokenizer model. See the main class Tokenizer for more examples of usage. Input Annotator Types: DOCUMENT //A Tokenizer could require only for now a SentenceDetector annotator Output Annotator Type: TOKEN Python API: TokenizerModel Scala API: TokenizerModel Source: TokenizerModel TypedDependencyParser ModelApproach Labeled parser that finds a grammatical relation between two words in a sentence. Its input is either a CoNLL2009 or ConllU dataset. For instantiated/pretrained models, see TypedDependencyParserModel. Dependency parsers provide information about word relationship. For example, dependency parsing can tell you what the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help you find precise answers to specific questions. The parser requires the dependant tokens beforehand with e.g. DependencyParser. The required training data can be set in two different ways (only one can be chosen for a particular model): Dataset in the CoNLL 2009 format set with setConll2009 Dataset in the CoNLL-U format set with setConllU Apart from that, no additional training data is needed. See TypedDependencyParserApproachTestSpec for further reference on this API. Input Annotator Types: TOKEN, POS, DEPENDENCY Output Annotator Type: LABELED_DEPENDENCY Python API: TypedDependencyParserApproach Scala API: TypedDependencyParserApproach Source: TypedDependencyParserApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) posTagger = PerceptronModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) dependencyParser = DependencyParserModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;]) .setOutputCol(&quot;dependency&quot;) typedDependencyParser = TypedDependencyParserApproach() .setInputCols([&quot;dependency&quot;, &quot;pos&quot;, &quot;token&quot;]) .setOutputCol(&quot;dependency_type&quot;) .setConllU(&quot;src/test/resources/parser/labeled/train_small.conllu.txt&quot;) .setNumberOfIterations(1) pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, posTagger, dependencyParser, typedDependencyParser ]) # Additional training data is not needed, the dependency parser relies on CoNLL-U only. emptyDataSet = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(emptyDataSet) import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel import com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel import com.johnsnowlabs.nlp.annotators.parser.typdep.TypedDependencyParserApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val posTagger = PerceptronModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) val dependencyParser = DependencyParserModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;) .setOutputCol(&quot;dependency&quot;) val typedDependencyParser = new TypedDependencyParserApproach() .setInputCols(&quot;dependency&quot;, &quot;pos&quot;, &quot;token&quot;) .setOutputCol(&quot;dependency_type&quot;) .setConllU(&quot;src/test/resources/parser/labeled/train_small.conllu.txt&quot;) .setNumberOfIterations(1) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, posTagger, dependencyParser, typedDependencyParser )) // Additional training data is not needed, the dependency parser relies on CoNLL-U only. val emptyDataSet = Seq.empty[String].toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(emptyDataSet) Labeled parser that finds a grammatical relation between two words in a sentence. Its input is either a CoNLL2009 or ConllU dataset. Dependency parsers provide information about word relationship. For example, dependency parsing can tell you what the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help you find precise answers to specific questions. The parser requires the dependant tokens beforehand with e.g. DependencyParser. Pretrained models can be loaded with pretrained of the companion object: val typedDependencyParser = TypedDependencyParserModel.pretrained() .setInputCols(&quot;dependency&quot;, &quot;pos&quot;, &quot;token&quot;) .setOutputCol(&quot;dependency_type&quot;) The default model is &quot;dependency_typed_conllu&quot;, if no name is provided. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples and the TypedDependencyModelTestSpec. Input Annotator Types: TOKEN, POS, DEPENDENCY Output Annotator Type: LABELED_DEPENDENCY Python API: TypedDependencyParserModel Scala API: TypedDependencyParserModel Source: TypedDependencyParserModel ViveknSentiment ModelApproach Trains a sentiment analyser inspired by the algorithm by Vivek Narayanan https://github.com/vivekn/sentiment/. The algorithm is based on the paper “Fast and accurate sentiment classification using an enhanced Naive Bayes model”. The analyzer requires sentence boundaries to give a score in context. Tokenization is needed to make sure tokens are within bounds. Transitivity requirements are also required. The training data needs to consist of a column for normalized text and a label column (either &quot;positive&quot; or &quot;negative&quot;). For extended examples of usage, see the Examples and the ViveknSentimentTestSpec. Input Annotator Types: TOKEN, DOCUMENT Output Annotator Type: SENTIMENT Python API: ViveknSentimentApproach Scala API: ViveknSentimentApproach Source: ViveknSentimentApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline document = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) token = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) normalizer = Normalizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;normal&quot;) vivekn = ViveknSentimentApproach() .setInputCols([&quot;document&quot;, &quot;normal&quot;]) .setSentimentCol(&quot;train_sentiment&quot;) .setOutputCol(&quot;result_sentiment&quot;) finisher = Finisher() .setInputCols([&quot;result_sentiment&quot;]) .setOutputCols(&quot;final_sentiment&quot;) pipeline = Pipeline().setStages([document, token, normalizer, vivekn, finisher]) training = spark.createDataFrame([ (&quot;I really liked this movie!&quot;, &quot;positive&quot;), (&quot;The cast was horrible&quot;, &quot;negative&quot;), (&quot;Never going to watch this again or recommend it to anyone&quot;, &quot;negative&quot;), (&quot;It&#39;s a waste of time&quot;, &quot;negative&quot;), (&quot;I loved the protagonist&quot;, &quot;positive&quot;), (&quot;The music was really really good&quot;, &quot;positive&quot;) ]).toDF(&quot;text&quot;, &quot;train_sentiment&quot;) pipelineModel = pipeline.fit(training) data = spark.createDataFrame([ [&quot;I recommend this movie&quot;], [&quot;Dont waste your time!!!&quot;] ]).toDF(&quot;text&quot;) result = pipelineModel.transform(data) result.select(&quot;final_sentiment&quot;).show(truncate=False) ++ |final_sentiment| ++ |[positive] | |[negative] | ++ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.Normalizer import com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentApproach import com.johnsnowlabs.nlp.Finisher import org.apache.spark.ml.Pipeline val document = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val token = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normal&quot;) val vivekn = new ViveknSentimentApproach() .setInputCols(&quot;document&quot;, &quot;normal&quot;) .setSentimentCol(&quot;train_sentiment&quot;) .setOutputCol(&quot;result_sentiment&quot;) val finisher = new Finisher() .setInputCols(&quot;result_sentiment&quot;) .setOutputCols(&quot;final_sentiment&quot;) val pipeline = new Pipeline().setStages(Array(document, token, normalizer, vivekn, finisher)) val training = Seq( (&quot;I really liked this movie!&quot;, &quot;positive&quot;), (&quot;The cast was horrible&quot;, &quot;negative&quot;), (&quot;Never going to watch this again or recommend it to anyone&quot;, &quot;negative&quot;), (&quot;It&#39;s a waste of time&quot;, &quot;negative&quot;), (&quot;I loved the protagonist&quot;, &quot;positive&quot;), (&quot;The music was really really good&quot;, &quot;positive&quot;) ).toDF(&quot;text&quot;, &quot;train_sentiment&quot;) val pipelineModel = pipeline.fit(training) val data = Seq( &quot;I recommend this movie&quot;, &quot;Dont waste your time!!!&quot; ).toDF(&quot;text&quot;) val result = pipelineModel.transform(data) result.select(&quot;final_sentiment&quot;).show(false) ++ |final_sentiment| ++ |[positive] | |[negative] | ++ Sentiment analyser inspired by the algorithm by Vivek Narayanan https://github.com/vivekn/sentiment/. The algorithm is based on the paper “Fast and accurate sentiment classification using an enhanced Naive Bayes model”. This is the instantiated model of the ViveknSentimentApproach. For training your own model, please see the documentation of that class. The analyzer requires sentence boundaries to give a score in context. Tokenization is needed to make sure tokens are within bounds. Transitivity requirements are also required. For extended examples of usage, see the Examples and the ViveknSentimentTestSpec. Input Annotator Types: TOKEN, DOCUMENT Output Annotator Type: SENTIMENT Python API: ViveknSentimentModel Scala API: ViveknSentimentModel Source: ViveknSentimentModel Word2Vec ModelApproach Trains a Word2Vec model that creates vector representations of words in a text corpus. The algorithm first constructs a vocabulary from the corpus and then learns vector representation of words in the vocabulary. The vector representation can be used as features in natural language processing and machine learning algorithms. We use Word2Vec implemented in Spark ML. It uses skip-gram model in our implementation and a hierarchical softmax method to train the model. The variable names in the implementation match the original C implementation. For instantiated/pretrained models, see Word2VecModel. Sources : For the original C implementation, see https://code.google.com/p/word2vec/ For the research paper, see Efficient Estimation of Word Representations in Vector Space and Distributed Representations of Words and Phrases and their Compositionality. Input Annotator Types: TOKEN Output Annotator Type: WORD_EMBEDDINGS Python API: Word2VecApproach Scala API: Word2VecApproach Source: Word2VecApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = Word2VecApproach() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) pipeline = Pipeline() .setStages([ documentAssembler, tokenizer, embeddings ]) path = &quot;sherlockholmes.txt&quot; dataset = spark.read.text(path).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(dataset) import spark.implicits._ import com.johnsnowlabs.nlp.annotator.{Tokenizer, Word2VecApproach} import com.johnsnowlabs.nlp.base.DocumentAssembler import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = new Word2VecApproach() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, tokenizer, embeddings )) val path = &quot;src/test/resources/spell/sherlockholmes.txt&quot; val dataset = spark.sparkContext.textFile(path) .toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(dataset) Word2Vec model that creates vector representations of words in a text corpus. The algorithm first constructs a vocabulary from the corpus and then learns vector representation of words in the vocabulary. The vector representation can be used as features in natural language processing and machine learning algorithms. We use Word2Vec implemented in Spark ML. It uses skip-gram model in our implementation and a hierarchical softmax method to train the model. The variable names in the implementation match the original C implementation. This is the instantiated model of the Word2VecApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val embeddings = Word2VecModel.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) The default model is &quot;word2vec_gigaword_300&quot;, if no name is provided. For available pretrained models please see the Models Hub. Sources : For the original C implementation, see https://code.google.com/p/word2vec/ For the research paper, see Efficient Estimation of Word Representations in Vector Space and Distributed Representations of Words and Phrases and their Compositionality. Input Annotator Types: TOKEN Output Annotator Type: WORD_EMBEDDINGS Python API: Word2VecModel Scala API: Word2VecModel Source: Word2VecModel Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = Word2VecModel.pretrained() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) embeddingsFinisher = EmbeddingsFinisher() .setInputCols([&quot;embeddings&quot;]) .setOutputCols(&quot;finished_embeddings&quot;) .setOutputAsVector(True) pipeline = Pipeline().setStages([ documentAssembler, tokenizer, embeddings, embeddingsFinisher ]) data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(1, 80) +--+ | result| +--+ |[0.06222493574023247,0.011579325422644615,0.009919632226228714,0.109361454844...| +--+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.{Tokenizer, Word2VecModel} import com.johnsnowlabs.nlp.EmbeddingsFinisher import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = Word2VecModel.pretrained() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) val embeddingsFinisher = new EmbeddingsFinisher() .setInputCols(&quot;embeddings&quot;) .setOutputCols(&quot;finished_embeddings&quot;) .setOutputAsVector(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, embeddings, embeddingsFinisher )) val data = Seq(&quot;This is a sentence.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(1, 80) +--+ | result| +--+ |[0.06222493574023247,0.011579325422644615,0.009919632226228714,0.109361454844...| +--+ WordEmbeddings ModelApproach Word Embeddings lookup annotator that maps tokens to vectors. For instantiated/pretrained models, see WordEmbeddingsModel. A custom token lookup dictionary for embeddings can be set with setStoragePath. Each line of the provided file needs to have a token, followed by their vector representation, delimited by a spaces. ... are 0.39658191506190343 0.630968081620067 0.5393722253731201 0.8428180123359783 were 0.7535235923631415 0.9699218875629833 0.10397182122983872 0.11833962569383116 stress 0.0492683418305907 0.9415954572751959 0.47624463167525755 0.16790967216778263 induced 0.1535748762292387 0.33498936903209897 0.9235178224122094 0.1158772920395934 ... If a token is not found in the dictionary, then the result will be a zero vector of the same dimension. Statistics about the rate of converted tokens, can be retrieved with[WordEmbeddingsModel.withCoverageColumn and WordEmbeddingsModel.overallCoverage. For extended examples of usage, see the Examples and the WordEmbeddingsTestSpec. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: WORD_EMBEDDINGS Python API: WordEmbeddings Scala API: WordEmbeddings Source: WordEmbeddings Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline # In this example, the file `random_embeddings_dim4.txt` has the form of the content above. documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddings() .setStoragePath(&quot;src/test/resources/random_embeddings_dim4.txt&quot;, ReadAs.TEXT) .setStorageRef(&quot;glove_4d&quot;) .setDimension(4) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) embeddingsFinisher = EmbeddingsFinisher() .setInputCols([&quot;embeddings&quot;]) .setOutputCols(&quot;finished_embeddings&quot;) .setOutputAsVector(True) .setCleanAnnotations(False) pipeline = Pipeline() .setStages([ documentAssembler, tokenizer, embeddings, embeddingsFinisher ]) data = spark.createDataFrame([[&quot;The patient was diagnosed with diabetes.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(truncate=False) +-+ |result | +-+ |[0.9439099431037903,0.4707513153553009,0.806300163269043,0.16176554560661316] | |[0.7966810464859009,0.5551124811172485,0.8861005902290344,0.28284206986427307] | |[0.025029370561242104,0.35177749395370483,0.052506182342767715,0.1887107789516449]| |[0.08617766946554184,0.8399239182472229,0.5395117998123169,0.7864698767662048] | |[0.6599600911140442,0.16109347343444824,0.6041093468666077,0.8913561105728149] | |[0.5955275893211365,0.01899011991918087,0.4397728443145752,0.8911281824111938] | |[0.9840458631515503,0.7599489092826843,0.9417727589607239,0.8624503016471863] | +-+ // In this example, the file `random_embeddings_dim4.txt` has the form of the content above. import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.embeddings.WordEmbeddings import com.johnsnowlabs.nlp.util.io.ReadAs import com.johnsnowlabs.nlp.EmbeddingsFinisher import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = new WordEmbeddings() .setStoragePath(&quot;src/test/resources/random_embeddings_dim4.txt&quot;, ReadAs.TEXT) .setStorageRef(&quot;glove_4d&quot;) .setDimension(4) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) val embeddingsFinisher = new EmbeddingsFinisher() .setInputCols(&quot;embeddings&quot;) .setOutputCols(&quot;finished_embeddings&quot;) .setOutputAsVector(true) .setCleanAnnotations(false) val pipeline = new Pipeline() .setStages(Array( documentAssembler, tokenizer, embeddings, embeddingsFinisher )) val data = Seq(&quot;The patient was diagnosed with diabetes.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(false) +-+ |result | +-+ |[0.9439099431037903,0.4707513153553009,0.806300163269043,0.16176554560661316] | |[0.7966810464859009,0.5551124811172485,0.8861005902290344,0.28284206986427307] | |[0.025029370561242104,0.35177749395370483,0.052506182342767715,0.1887107789516449]| |[0.08617766946554184,0.8399239182472229,0.5395117998123169,0.7864698767662048] | |[0.6599600911140442,0.16109347343444824,0.6041093468666077,0.8913561105728149] | |[0.5955275893211365,0.01899011991918087,0.4397728443145752,0.8911281824111938] | |[0.9840458631515503,0.7599489092826843,0.9417727589607239,0.8624503016471863] | +-+ Word Embeddings lookup annotator that maps tokens to vectors This is the instantiated model of WordEmbeddings. Pretrained models can be loaded with pretrained of the companion object: val embeddings = WordEmbeddingsModel.pretrained() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) The default model is &quot;glove_100d&quot;, if no name is provided. For available pretrained models please see the Models Hub. There are also two convenient functions to retrieve the embeddings coverage with respect to the transformed dataset: withCoverageColumn(dataset, embeddingsCol, outputCol): Adds a custom column with word coverage stats for the embedded field: (coveredWords, totalWords, coveragePercentage). This creates a new column with statistics for each row. val wordsCoverage = WordEmbeddingsModel.withCoverageColumn(resultDF, &quot;embeddings&quot;, &quot;cov_embeddings&quot;) wordsCoverage.select(&quot;text&quot;,&quot;cov_embeddings&quot;).show(false) +-+--+ |text |cov_embeddings| +-+--+ |This is a sentence.|[5, 5, 1.0] | +-+--+ overallCoverage(dataset, embeddingsCol): Calculates overall word coverage for the whole data in the embedded field. This returns a single coverage object considering all rows in the field. val wordsOverallCoverage = WordEmbeddingsModel.overallCoverage(wordsCoverage,&quot;embeddings&quot;).percentage 1.0 For extended examples of usage, see the Examples and the WordEmbeddingsTestSpec. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: WORD_EMBEDDINGS Python API: WordEmbeddingsModel Scala API: WordEmbeddingsModel Source: WordEmbeddingsModel WordSegmenter ModelApproach Trains a WordSegmenter which tokenizes non-english or non-whitespace separated texts. Many languages are not whitespace separated and their sentences are a concatenation of many symbols, like Korean, Japanese or Chinese. Without understanding the language, splitting the words into their corresponding tokens is impossible. The WordSegmenter is trained to understand these languages and split them into semantically correct parts. This annotator is based on the paper Chinese Word Segmentation as Character Tagging [1]. Word segmentation is treated as a tagging problem. Each character is be tagged as on of four different labels: LL (left boundary), RR (right boundary), MM (middle) and LR (word by itself). The label depends on the position of the word in the sentence. LL tagged words will combine with the word on the right. Likewise, RR tagged words combine with words on the left. MM tagged words are treated as the middle of the word and combine with either side. LR tagged words are words by themselves. Example (from [1], Example 3(a) (raw), 3(b) (tagged), 3(c) (translation)): 上海 计划 到 本 世纪 末 实现 人均 国内 生产 总值 五千 美元 上/LL 海/RR 计/LL 划/RR 到/LR 本/LR 世/LL 纪/RR 末/LR 实/LL 现/RR 人/LL 均/RR 国/LL 内/RR 生/LL 产/RR 总/LL 值/RR 五/LL 千/RR 美/LL 元/RR Shanghai plans to reach the goal of 5,000 dollars in per capita GDP by the end of the century. For instantiated/pretrained models, see WordSegmenterModel. To train your own model, a training dataset consisting of Part-Of-Speech tags is required. The data has to be loaded into a dataframe, where the column is an Annotation of type &quot;POS&quot;. This can be set with setPosColumn. Tip: The helper class POS might be useful to read training data into data frames. For extended examples of usage, see the Examples and the WordSegmenterTest. References: [1] Xue, Nianwen. “Chinese Word Segmentation as Character Tagging.” International Journal of Computational Linguistics &amp; Chinese Language Processing, Volume 8, Number 1, February 2003: Special Issue on Word Formation and Chinese Language Processing, 2003, pp. 29-48. ACLWeb, https://aclanthology.org/O03-4002. Input Annotator Types: DOCUMENT Output Annotator Type: TOKEN Python API: WordSegmenterApproach Scala API: WordSegmenterApproach Source: WordSegmenterApproach Show Example PythonScala # In this example, `&quot;chinese_train.utf8&quot;` is in the form of # # 十|LL 四|RR 不|LL 是|RR 四|LL 十|RR # # and is loaded with the `POS` class to create a dataframe of `&quot;POS&quot;` type Annotations. import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp.training import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) wordSegmenter = WordSegmenterApproach() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) .setPosColumn(&quot;tags&quot;) .setNIterations(5) pipeline = Pipeline().setStages([ documentAssembler, wordSegmenter ]) trainingDataSet = POS().readDataset( spark, &quot;src/test/resources/word-segmenter/chinese_train.utf8&quot; ) pipelineModel = pipeline.fit(trainingDataSet) // In this example, `&quot;chinese_train.utf8&quot;` is in the form of // // 十|LL 四|RR 不|LL 是|RR 四|LL 十|RR // // and is loaded with the `POS` class to create a dataframe of `&quot;POS&quot;` type Annotations. import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.ws.WordSegmenterApproach import com.johnsnowlabs.nlp.training.POS import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val wordSegmenter = new WordSegmenterApproach() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) .setPosColumn(&quot;tags&quot;) .setNIterations(5) val pipeline = new Pipeline().setStages(Array( documentAssembler, wordSegmenter )) val trainingDataSet = POS().readDataset( ResourceHelper.spark, &quot;src/test/resources/word-segmenter/chinese_train.utf8&quot; ) val pipelineModel = pipeline.fit(trainingDataSet) WordSegmenter which tokenizes non-english or non-whitespace separated texts. Many languages are not whitespace separated and their sentences are a concatenation of many symbols, like Korean, Japanese or Chinese. Without understanding the language, splitting the words into their corresponding tokens is impossible. The WordSegmenter is trained to understand these languages and plit them into semantically correct parts. This annotator is based on the paper Chinese Word Segmentation as Character Tagging. Word segmentation is treated as a tagging problem. Each character is be tagged as on of four different labels: LL (left boundary), RR (right boundary), MM (middle) and LR (word by itself). The label depends on the position of the word in the sentence. LL tagged words will combine with the word on the right. Likewise, RR tagged words combine with words on the left. MM tagged words are treated as the middle of the word and combine with either side. LR tagged words are words by themselves. Example (from [1], Example 3(a) (raw), 3(b) (tagged), 3(c) (translation)): 上海 计划 到 本 世纪 末 实现 人均 国内 生产 总值 五千 美元 上/LL 海/RR 计/LL 划/RR 到/LR 本/LR 世/LL 纪/RR 末/LR 实/LL 现/RR 人/LL 均/RR 国/LL 内/RR 生/LL 产/RR 总/LL 值/RR 五/LL 千/RR 美/LL 元/RR Shanghai plans to reach the goal of 5,000 dollars in per capita GDP by the end of the century. This is the instantiated model of the WordSegmenterApproach. For training your own model, please see the documentation of that class. Pretrained models can be loaded with pretrained of the companion object: val wordSegmenter = WordSegmenterModel.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;words_segmented&quot;) The default model is &quot;wordseg_pku&quot;, default language is &quot;zh&quot;, if no values are provided. For available pretrained models please see the Models Hub. For extended examples of usage, see the Examples and the WordSegmenterTest. References: [1] Xue, Nianwen. “Chinese Word Segmentation as Character Tagging.” International Journal of Computational Linguistics &amp; Chinese Language Processing, Volume 8, Number 1, February 2003: Special Issue on Word Formation and Chinese Language Processing, 2003, pp. 29-48. ACLWeb, https://aclanthology.org/O03-4002. Input Annotator Types: DOCUMENT Output Annotator Type: TOKEN Python API: WordSegmenterModel Scala API: WordSegmenterModel Source: WordSegmenterModel YakeKeywordExtraction Yake is an Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction algorithm. Extracting keywords from texts has become a challenge for individuals and organizations as the information grows in complexity and size. The need to automate this task so that text can be processed in a timely and adequate manner has led to the emergence of automatic keyword extraction tools. Yake is a novel feature-based system for multi-lingual keyword extraction, which supports texts of different sizes, domain or languages. Unlike other approaches, Yake does not rely on dictionaries nor thesauri, neither is trained against any corpora. Instead, it follows an unsupervised approach which builds upon features extracted from the text, making it thus applicable to documents written in different languages without the need for further knowledge. This can be beneficial for a large number of tasks and a plethora of situations where access to training corpora is either limited or restricted. The algorithm makes use of the position of a sentence and token. Therefore, to use the annotator, the text should be first sent through a Sentence Boundary Detector and then a tokenizer. Note that each keyword will be given a keyword score greater than 0 (The lower the score better the keyword). Therefore to filter the keywords, an upper bound for the score can be set with setThreshold. For extended examples of usage, see the Examples and the YakeTestSpec. Sources : Campos, R., Mangaravite, V., Pasquali, A., Jatowt, A., Jorge, A., Nunes, C. and Jatowt, A. (2020). YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences Journal. Elsevier, Vol 509, pp 257-289 Paper abstract: As the amount of generated information grows, reading and summarizing texts of large collections turns into a challenging task. Many documents do not come with descriptive terms, thus requiring humans to generate keywords on-the-fly. The need to automate this kind of task demands the development of keyword extraction systems with the ability to automatically identify keywords within the text. One approach is to resort to machine-learning algorithms. These, however, depend on large annotated text corpora, which are not always available. An alternative solution is to consider an unsupervised approach. In this article, we describe YAKE!, a light-weight unsupervised automatic keyword extraction method which rests on statistical text features extracted from single documents to select the most relevant keywords of a text. Our system does not need to be trained on a particular set of documents, nor does it depend on dictionaries, external corpora, text size, language, or domain. To demonstrate the merits and significance of YAKE!, we compare it against ten state-of-the-art unsupervised approaches and one supervised method. Experimental results carried out on top of twenty datasets show that YAKE! significantly outperforms other unsupervised methods on texts of different sizes, languages, and domains. Input Annotator Types: TOKEN Output Annotator Type: CHUNK Python API: YakeKeywordExtraction Scala API: YakeKeywordExtraction Source: YakeKeywordExtraction Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) token = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) .setContextChars([&quot;(&quot;, &quot;]&quot;, &quot;?&quot;, &quot;!&quot;, &quot;.&quot;, &quot;,&quot;]) keywords = YakeKeywordExtraction() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;keywords&quot;) .setThreshold(0.6) .setMinNGrams(2) .setNKeywords(10) pipeline = Pipeline().setStages([ documentAssembler, sentenceDetector, token, keywords ]) data = spark.createDataFrame([[ &quot;Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning competitions. Details about the transaction remain somewhat vague, but given that Google is hosting its Cloud Next conference in San Francisco this week, the official announcement could come as early as tomorrow. Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the acquisition is happening. Google itself declined &#39;to comment on rumors&#39;. Kaggle, which has about half a million data scientists on its platform, was founded by Goldbloom and Ben Hamner in 2010. The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, it has managed to stay well ahead of them by focusing on its specific niche. The service is basically the de facto home for running data science and machine learning competitions. With Kaggle, Google is buying one of the largest and most active communities for data scientists - and with that, it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow and other projects). Kaggle has a bit of a history with Google, too, but that&#39;s pretty recent. Earlier this month, Google and Kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. That competition had some deep integrations with the Google Cloud Platform, too. Our understanding is that Google will keep the service running - likely under its current name. While the acquisition is probably more about Kaggle&#39;s community than technology, Kaggle did build some interesting tools for hosting its competition and &#39;kernels&#39;, too. On Kaggle, kernels are basically the source code for analyzing data sets and developers can share this code on the platform (the company previously called them &#39;scripts&#39;). Like similar competition-centric sites, Kaggle also runs a job board, too. It&#39;s unclear what Google will do with that part of the service. According to Crunchbase, Kaggle raised $12.5 million (though PitchBook says it&#39;s $12.75) since its launch in 2010. Investors in Kaggle include Index Ventures, SV Angel, Max Levchin, NaRavikant, Google chie economist Hal Varian, Khosla Ventures and Yuri Milner&quot; ]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) # combine the result and score (contained in keywords.metadata) scores = result .selectExpr(&quot;explode(arrays_zip(keywords.result, keywords.metadata)) as resultTuples&quot;) .selectExpr(&quot;resultTuples[&#39;0&#39;] as keyword&quot;, &quot;resultTuples[&#39;1&#39;].score as score&quot;) # Order ascending, as lower scores means higher importance scores.orderBy(&quot;score&quot;).show(5, truncate = False) ++-+ |keyword |score | ++-+ |google cloud |0.32051516486864573| |google cloud platform|0.37786450577630676| |ceo anthony goldbloom|0.39922830978423146| |san francisco |0.40224744669493756| |anthony goldbloom |0.41584827825302534| ++-+ import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.{SentenceDetector, Tokenizer} import com.johnsnowlabs.nlp.annotators.keyword.yake.YakeKeywordExtraction import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val token = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) .setContextChars(Array(&quot;(&quot;, &quot;)&quot;, &quot;?&quot;, &quot;!&quot;, &quot;.&quot;, &quot;,&quot;)) val keywords = new YakeKeywordExtraction() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;keywords&quot;) .setThreshold(0.6f) .setMinNGrams(2) .setNKeywords(10) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, token, keywords )) val data = Seq( &quot;Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning competitions. Details about the transaction remain somewhat vague, but given that Google is hosting its Cloud Next conference in San Francisco this week, the official announcement could come as early as tomorrow. Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the acquisition is happening. Google itself declined &#39;to comment on rumors&#39;. Kaggle, which has about half a million data scientists on its platform, was founded by Goldbloom and Ben Hamner in 2010. The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, it has managed to stay well ahead of them by focusing on its specific niche. The service is basically the de facto home for running data science and machine learning competitions. With Kaggle, Google is buying one of the largest and most active communities for data scientists - and with that, it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow and other projects). Kaggle has a bit of a history with Google, too, but that&#39;s pretty recent. Earlier this month, Google and Kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. That competition had some deep integrations with the Google Cloud Platform, too. Our understanding is that Google will keep the service running - likely under its current name. While the acquisition is probably more about Kaggle&#39;s community than technology, Kaggle did build some interesting tools for hosting its competition and &#39;kernels&#39;, too. On Kaggle, kernels are basically the source code for analyzing data sets and developers can share this code on the platform (the company previously called them &#39;scripts&#39;). Like similar competition-centric sites, Kaggle also runs a job board, too. It&#39;s unclear what Google will do with that part of the service. According to Crunchbase, Kaggle raised $12.5 million (though PitchBook says it&#39;s $12.75) since its launch in 2010. Investors in Kaggle include Index Ventures, SV Angel, Max Levchin, Naval Ravikant, Google chief economist Hal Varian, Khosla Ventures and Yuri Milner&quot; ).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) // combine the result and score (contained in keywords.metadata) val scores = result .selectExpr(&quot;explode(arrays_zip(keywords.result, keywords.metadata)) as resultTuples&quot;) .select($&quot;resultTuples.0&quot; as &quot;keyword&quot;, $&quot;resultTuples.1.score&quot;) // Order ascending, as lower scores means higher importance scores.orderBy(&quot;score&quot;).show(5, truncate = false) ++-+ |keyword |score | ++-+ |google cloud |0.32051516486864573| |google cloud platform|0.37786450577630676| |ceo anthony goldbloom|0.39922830978423146| |san francisco |0.40224744669493756| |anthony goldbloom |0.41584827825302534| ++-+",
    "url": "/docs/en/annotators",
    "relUrl": "/docs/en/annotators"
  },
  "857": {
    "id": "857",
    "title": "API Integration",
    "content": "All features provided by the Annotation Lab via UI are also accessible via API. The complete API documentation is available on the SWAGGER page of the Annotation Lab. It is available under Settings &gt; API Integration. Concrete query examples are provided for each available endpoint. Example of creating a new project via API Get Client Secret Get CLIENT_ID and CLIENT_SECRET by following the steps illustrated in the video. Annotation Lab: Collect the Client Secret Call API endpoint For creating a new project via API you can use the following python script. import requests import json # URL to Annotation Lab API_URL = &quot;https://123.45.67.89&quot; # Add user credentials USERNAME = &quot;user&quot; PASSWORD = &quot;password&quot; # The above video shows how to get CLIENT_ID and CLIENT_SECRET CLIENT_ID = &quot;...&quot; CLIENT_SECRET = &quot;...&quot; PROJECT_NAME = &quot;sample_project&quot; IDENTITY_MANAGEMENT_URL = API_URL + &quot;/auth/&quot; IDENTITY_MANAGEMENT_REALM = &quot;master&quot; HEADERS = { &quot;Host&quot;: API_URL.replace(&quot;http://&quot;, &quot;&quot;).replace(&quot;https://&quot;, &quot;&quot;), &quot;Origin&quot;: API_URL, &quot;Content-Type&quot;: &quot;application/json&quot;, } def get_cookies(): url = f&quot;{IDENTITY_MANAGEMENT_URL}realms/{IDENTITY_MANAGEMENT_REALM}/protocol/openid-connect/token&quot; data = { &quot;grant_type&quot;: &quot;password&quot;, &quot;username&quot;: USERNAME, &quot;password&quot;: PASSWORD, &quot;client_id&quot;: CLIENT_ID, &quot;client_secret&quot;: CLIENT_SECRET, } auth_info = requests.post(url, data=data).json() cookies = { &quot;access_token&quot;: f&quot;Bearer {auth_info[&#39;access_token&#39;]}&quot;, &quot;refresh_token&quot;: auth_info[&quot;refresh_token&quot;], } return cookies def create_project(): # GET THIS FROM SWAGGER DOC url = f&quot;{API_URL}/api/projects/create&quot; data = { &quot;project_name&quot;: PROJECT_NAME, &quot;project_description&quot;: &quot;&quot;, &quot;project_sampling&quot;: &quot;uniform&quot;, &quot;project_instruction&quot;: &quot;&quot;, } r = requests.post( url, headers=HEADERS, data=json.dumps(data), cookies=get_cookies() ) return r create_project()",
    "url": "/docs/en/alab/api",
    "relUrl": "/docs/en/alab/api"
  },
  "858": {
    "id": "858",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/audio_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/audio_assembler.html"
  },
  "859": {
    "id": "859",
    "title": "Audit Trail",
    "content": "Annotation Lab is designed to handle Personal Identifying Information (PII) and Protected Health Information (PHI). It keeps a full audit trail for all created completions, where each entry is stored with an authenticated user and a timestamp. It is not possible for Annotators or Reviewers to delete any completions, and only Managers and Project Owners can remove tasks.",
    "url": "/docs/en/alab/audit_trail",
    "relUrl": "/docs/en/alab/audit_trail"
  },
  "860": {
    "id": "860",
    "title": "Helper functions",
    "content": "",
    "url": "/docs/en/auxiliary",
    "relUrl": "/docs/en/auxiliary"
  },
  "861": {
    "id": "861",
    "title": "Backup and Restore",
    "content": "Backup You can enable daily backups by adding several variables with --set option to helm command in annotationlab-updater.sh: backup.enable=true backup.files=true backup.s3_access_key=&quot;&lt;ACCESS_KEY&gt;&quot; backup.s3_secret_key=&quot;&lt;SECRET_KEY&gt;&quot; backup.s3_bucket_fullpath=&quot;&lt;FULL_PATH&gt;&quot; &lt;ACCESS_KEY&gt; - your access key for AWS S3 access &lt;SECRET_KEY&gt; - your secret key for AWS S3 access &lt;FULL_PATH&gt; - full path to your backup in s3 bucket (f.e. s3://example.com/path/to/my/backup/dir) Note: File backup is enabled by default. If you don’t need to backup files, you have to change backup.files=true to backup.files=false Configure Backup from the UI In 2.8.0 release, Annotation Lab added support for defining database and files backups via the UI. An admin user can view and edit the backup settings under the Settings menu. Users can select different backup periods and can specify a target S3 bucket for storing the backup files. New backups will be automatically generated and saved to the S3 bucket following the defined schedule. Restore Database To restore Annotation Lab from a backup you need a fresh installation of Annotation Lab. Install it using annotationlab-install.sh. Now, download the latest backup from your S3 bucket and move the archive to restore/database/ directory. Next, go to the restore/database/ directory and execute script restore_all_databases.sh with the name of your backup archive as the argument. For example: cd restore/database/ sudo ./restore_all_databases.sh 2022-04-14-annotationlab-all-databases.tar.xz Note: You need xz and bash installed to execute this script. This script works only with backups created by Annotation Lab backup system. Run this script with sudo command After database restore complete you can check logs in restore_log directory created by restore script. Files Download your files backup and move it to restore/files/ directory. Go to restore/files/ directory and execute script restore_files.sh with the name of your backup archive as the argument. For example: cd restore/files/ sudo ./restore_files.sh 2022-04-14-annotationlab-files.tar Note: You need bash installed to execute this script. This script works only with backups created by Annotation Lab backup system. Run this script with sudo command Reboot After restoring database and files, reboot Annotation Lab: sudo reboot",
    "url": "/docs/en/alab/backup_restore",
    "relUrl": "/docs/en/alab/backup_restore"
  },
  "862": {
    "id": "862",
    "title": "Developers Guideline",
    "content": "Cluster Speed Benchmarks NER (BiLSTM-CNN-Char Architecture) Benchmark Experiment Dataset : 1000 Clinical Texts from MTSamples Oncology Dataset, approx. 500 tokens per text. Driver : Standard_D4s_v3 - 16 GB Memory - 4 Cores Enable Autoscaling : False Cluster Mode : Standart Worker : Standard_D4s_v3 - 16 GB Memory - 4 Cores Standard_D4s_v2 - 28 GB Memory - 8 Cores Versions : Databricks Runtime Version : 8.3(Scala 2.12, Spark 3.1.1) spark-nlp Version: v3.2.3 spark-nlp-jsl Version : v3.2.3 Spark Version : v3.1.1 Spark NLP Pipeline : nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings_clinical, clinical_ner, ner_converter ]) NOTES : The first experiment with 5 different cluster configurations : ner_chunk as a column in Spark NLP Pipeline (ner_converter) output data frame, exploded (lazy evaluation) as ner_chunk and ner_label. Then results were written as parquet and delta formats. A second experiment with 2 different cluster configuration : Spark NLP Pipeline output data frame (except word_embeddings column) was written as parquet and delta formats. In the first experiment with the most basic driver node and worker (1 worker x 4 cores) configuration selection, it took 4.64 mins and 4.53 mins to write 4 partitioned data as parquet and delta formats respectively. With basic driver node and 8 workers (x8 cores) configuration selection, it took 40 seconds and 22 seconds to write 1000 partitioned data as parquet and delta formats respectively. In the second experiment with basic driver node and 4 workers (x 4 cores) configuration selection, it took 1.41 mins as parquet and 1.42 mins as delta format to write 16 partitioned (exploded results) data. Without explode it took 1.08 mins as parquet and 1.12 mins as delta format to write the data frame. Since given computation durations are highly dependent on different parameters including driver node and worker node configurations as well as partitions, results show that explode method increases duration %10-30 on chosen configurations. NER Benchmark Tables driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition NER timing NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_parquet 8 64 64 36 sec 1.14 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_deltalake 8 64 64 19 sec 1.13 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_parquet 8 64 100 21 sec 50 sec Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_deltalake 8 64 100 41 sec 51 sec Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_parquet 8 64 1000 40 sec 54 sec Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_deltalake 8 64 1000 22 sec 46 sec driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition duration NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 8 32 32 1.21 mins 2.05 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 8 32 32 55.8 sec 1.91 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 8 32 100 41 sec 1.64 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 8 32 100 48 sec 1.61 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 8 32 1000 1.36 min 1.83 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 8 32 1000 48 sec 1.70 mins driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition NER timing NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 10 1.4 mins 3.78 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 10 1.76 mins 3.93 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 16 1.41 mins 3.97 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 16 1.42 mins 3.82 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 32 1.36 mins 3.70 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 32 1.35 mins 3.65 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 100 1.21 mins 3.18 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 100 1.24 mins 3.15 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 1000 1.42 mins 3.51 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 1000 1.46 mins 3.48 mins driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition NER timing NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 2 8 10 2.82 mins 5.91 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 2 8 10 2.82 mins 5.99 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 2 8 100 2.27 mins 5.29 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 2 8 100 2.25 min 5.26 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 2 8 1000 2.65 mins 5.78 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 2 8 1000 2.7 mins 5.81 mins driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition NER timing NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 1 4 4 4.64 mins 13.97 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 1 4 4 4.53 mins 13.88 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 1 4 10 4.42 mins 14.13 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 1 4 10 4.55 mins 14.63 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 1 4 100 4.19 mins 14.68 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 1 4 100 4.18 mins 14.89 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 1 4 1000 5.01 mins 16.38 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 1 4 1000 4.99 mins 16.52 mins Clinical Bert For Token Classification Benchmark Experiment Dataset : 7537 Clinical Texts from PubMed Dataset Driver : Standard_DS3_v2 - 14GB Memory - 4 Cores Enable Autoscaling : True Cluster Mode : Standart Worker : Standard_DS3_v2 - 14GB Memory - 4 Cores Versions : Databricks Runtime Version : 10.0 (Apache Spark 3.2.0, Scala 2.12) spark-nlp Version: v3.4.0 spark-nlp-jsl Version : v3.4.0 Spark Version : v3.2.0 Spark NLP Pipeline : nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, ner_jsl_slim_tokenClassifier, ner_converter, finisher]) NOTES : In this experiment, the bert_token_classifier_ner_jsl_slim model was used to measure the inference time of clinical bert for token classification models in the databricks environment. In the first experiment, the data read from the parquet file is saved as parquet after processing. In the second experiment, the data read from the delta table was written to the delta table after it was processed. Bert For Token Classification Benchmark Table Repartition Time Read data from parquet 2 26.03 mins 64 10.84 mins 128 7.53 mins 1000 8.93 mins Read data from delta table 2 40.50 mins 64 11.84 mins 128 6.79 mins 1000 6.92 mins NER speed benchmarks across various Spark NLP and PySpark versions This experiment compares the ClinicalNER runtime for different versions of PySpark and Spark NLP. In this experiment, all reports went through the pipeline 10 times and repeated execution 5 times, so we ran each report 50 times and averaged it, %timeit -r 5 -n 10 run_model(spark, model). Driver : Standard Google Colab environment Spark NLP Pipeline : nlpPipeline = Pipeline( stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter ]) Dataset : File sizes: report_1: ~5.34kb report_2: ~8.51kb report_3: ~11.05kb report_4: ~15.67kb report_5: ~35.23kb   Spark NLP 4.0.0 (PySpark 3.1.2) Spark NLP 4.2.1 (PySpark 3.3.1) Spark NLP 4.2.1 (PySpark 3.1.2) Spark NLP 4.2.2 (PySpark 3.1.2) Spark NLP 4.2.2 (PySpark 3.3.1) Spark NLP 4.2.3 (PySpark 3.3.1) Spark NLP 4.2.3 (PySpark 3.1.2) report_1 2.36066 3.33056 2.23723 2.27243 2.11513 2.19655 2.23915 report_2 2.2179 3.31328 2.15578 2.23432 2.07259 2.07567 2.16776 report_3 2.77923 2.6134 2.69023 2.76358 2.55306 2.4424 2.72496 report_4 4.41064 4.07398 4.66656 4.59879 3.98586 3.92184 4.6145 report_5 9.54389 7.79465 9.25499 9.42764 8.02252 8.11318 9.46555 Results show that the different versions can have some variance in the execution time, but the difference is not too relevant.",
    "url": "/docs/en/benchmark",
    "relUrl": "/docs/en/benchmark"
  },
  "863": {
    "id": "863",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/bert_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/bert_embeddings.html"
  },
  "864": {
    "id": "864",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_question_answering.html"
  },
  "865": {
    "id": "865",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_sequence_classification.html"
  },
  "866": {
    "id": "866",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_token_classification.html"
  },
  "867": {
    "id": "867",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/bert_sentence_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/bert_sentence_embeddings.html"
  },
  "868": {
    "id": "868",
    "title": "Best Practices Using Pretrained Models Together",
    "content": "Entity Resolver Models and Features In the table below, all Entity Resolver models, their features, appropriate embeddings, and AUX info are illustrated. For instance, features of sbertresolve_ner_model_finder are under FEATURES column and it is trained using sbert_jsl_medium_uncased embeddings. Auxiliary info can be found under the AUX column if it is present. NOTE: This table is shared just to give you a rough idea about which pretrained models can be used together. You can get better or worse performance by playing out with different models. NO MODEL NAME FEATURES EMBEDDINGS LANGUAGE AUX 1 sbertresolve_ner_model_finder • Maps clinical entities (NER) to the most appropriate NER model• sbert_jsl_medium_uncased embeddings• Returns a list of pretrained NER models sbert_jsl_medium_uncased EN   2 sbiobertresolve_clinical_abbreviation_acronym • Maps  clinical abbreviations and acronyms to their meanings• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   3 sbiobertresolve_cpt • CPT Codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   4 sbiobertresolve_cpt_augmented • Augmented version of sbiobertresolve_cpt model• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   5 sbiobertresolve_cpt_procedures_augmented • Procedures to CPT Codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   6 sbiobertresolve_cpt_procedures_measurements_augmented • Procedure and Measurements to CPT Codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   7 sbiobertresolve_hcc_augmented • HCC Codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   8 sbiobertresolve_icd10cm • ICD-10-CM codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   9 sbertresolve_icd10gm • German ICD10-GM Codes• sent_bert_base_cased (DE) sent_bert_base_cased (DE) DE   10 sbiobertresolve_icd10cm_augmented • ICD-10-CM codes• sbiobert_base_cased_mli embeddings• Augmented version of sbiobertresolve_icd10cm model with synonyms, four times richer. sbiobert_base_cased_mli EN   11 sbiobertresolve_icd10cm_augmented_billable_hcc • ICD-10-CM codes• sbiobert_base_cased_mli embeddings• Provides HCC information of the codes in all_k_aux_labels column• This column can be divided to get further details: billable status - hcc status - hcc score. sbiobert_base_cased_mli EN HCC and Billable Information 12 sbiobertresolve_icd10cm_generalised • ICD-10-CM codes up to 3 Characters (general type of injury or disease)• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   13 sbiobertresolve_icd10cm_slim_billable_hcc • ICD-10-CM codes• sbiobert_base_cased_mli embeddings• Slim version (synonyms having low cosine similarity to unnormalized terms are dropped)• Provides  the official resolution text within the brackets• Provides  HCC information of the codes in all_k_aux_labels column.• This column can be divided to get further details: billable status - hcc status - hcc score. sbiobert_base_cased_mli EN HCC and Billable Information 14 sbertresolve_icd10cm_slim_billable_hcc_med • ICD-10-CM codes• sbert_jsl_medium_uncased embeddings• Slim version (synonyms having low cosine similarity to unnormalized terms are dropped)• Provides  the official resolution text within the brackets inside the metadata.• Provides  HCC information of the codes in all_k_aux_labels column• This column can be divided to get further details: billable status - hcc status - hcc score. sbert_jsl_medium_uncased EN HCC and Billable Information 15 sbiobertresolve_icd10cm_slim_normalized • ICD-10-CM codes• sbiobert_base_cased_mli embeddings• Slim version (synonyms having low cosine similarity to unnormalized terms are dropped)• Provides  the official resolution text within the brackets inside the metadata. sbiobert_base_cased_mli EN   16 sbiobertresolve_icd10pcs • ICD-10-PCS codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   17 sbiobertresolve_icdo • ICD-O Codes (International Classification of Diseases for Oncology code)• Provides topography codes and morphology codes comprising of Histology and Behavior codes in all_k_aux_labels columns• sbiobert_base_cased_mli embeddings• More granularity with respect to body parts sbiobert_base_cased_mli EN Topography codes, Morphology codes comprising of Histology and Behavior codes 18 sbiobertresolve_icdo_base • ICD-O Codes (International Classification of Diseases for Oncology code)• Provides topography codes and morphology codes comprising of Histology and Behavior codes in all_k_aux_labels columns• sbiobert_base_cased_mli embeddings• More granularity with respect to body parts sbiobert_base_cased_mli EN Topography codes, Morphology codes comprising of Histology and Behavior codes 19 sbiobertresolve_icdo_augmented • ICD-O Codes (International Classification of Diseases for Oncology code)• Provides topography codes and morphology codes comprising of Histology and Behavior codes in all_k_aux_labels columns• sbiobert_base_cased_mli embeddings• More granularity with respect to body parts• Augmented using the site information coming from ICD10 and synonyms coming from SNOMED vocabularies. sbiobert_base_cased_mli EN Topography codes, Morphology codes comprising of Histology and Behavior codes 20 sbiobertresolve_rxnorm • RxNorm Codes for Drugs/ Ingredients• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   21 sbiobertresolve_rxnorm_augmented • RxNorm Codes for Drugs/ Ingredients• sbiobert_base_cased_mli  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Augmented version of sbiobertresolve_rxnorm model sbiobert_base_cased_mli EN Concept classes of the drugs 22 sbiobertresolve_rxnorm_augmented_cased • RxNorm Codes for Drugs/ Ingredients• sbiobert_base_cased_mli  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Cased (unlowered) concept names• Augmented version of sbiobertresolve_rxnorm model sbiobert_base_cased_mli EN Concept classes of the drugs 23 sbiobertresolve_rxnorm_disposition • RxNorm Codes for Drugs/ Ingredients• sbiobert_base_cased_mli  embeddings• Provides dispositions of the RxNorm codes in all_k_aux_labels column. sbiobert_base_cased_mli EN Provides dispositions of the RxNorm codes in all_k_aux_labels column. 24 sbertresolve_rxnorm_disposition • Medication entities (like drugs/ingredients) to RxNorm codes• Provides the dispositions of the codes in all_k_aux_labels column• sbert_jsl_medium_uncased embeddings (light) sbert_jsl_medium_uncased EN Disposition Information 25 sbiobertresolve_jsl_rxnorm_augmented • RxNorm Codes for Drugs/ Ingredients• sbiobert_jsl_rxnorm_cased  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Augmented version of sbiobertresolve_rxnorm model sbiobert_jsl_rxnorm_cased EN Concept classes of the drugs 26 sbluebertresolve_rxnorm_augmented_uncased • RxNorm Codes for Drugs/ Ingredients• sbluebert_base_uncased_mli  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Augmented version of sbiobertresolve_rxnorm model sbluebert_base_uncased_mli EN Concept classes of the drugs 27 sbertresolve_jsl_rxnorm_augmented_med • RxNorm Codes for Drugs/ Ingredients• sbert_jsl_medium_rxnorm_uncased  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Augmented version of sbiobertresolve_rxnorm model sbert_jsl_medium_rxnorm_uncased EN Concept classes of the drugs 28 sbiobertresolve_rxcui • RxCUI Codes• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   29 sbluebertresolve_loinc • LOINC Codes• sbluebert_base_uncased_mli  embeddings sbluebert_base_uncased_mli EN   30 sbiobertresolve_loinc • LOINC Codes• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   31 sbiobertresolve_loinc_augmented • LOINC Codes• sbiobert_base_cased_mli  embeddings• Augmented version of sbiobertresolve_loinc sbiobert_base_cased_mli EN   32 sbiobertresolve_loinc_cased • LOINC Codes• sbiobert_base_cased_mli  embeddings• Cased (unlowered) concept names• Augmented version of sbiobertresolve_loinc sbiobert_base_cased_mli EN   33 sbluebertresolve_loinc_uncased • LOINC Codes• sbluebert_base_uncased_mli  embeddings• Uncased (lowercased) concept names• Augmented version of sbiobertresolve_loinc sbluebert_base_uncased_mli EN   34 sbiobertresolve_mesh • MeSH Codes• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   35 sbiobertresolve_ndc • NDC Codes• sbiobert_base_cased_mli  embeddings• If a drug has more than one NDC code, it returns all other codes in the all_k_aux_label column sbiobert_base_cased_mli EN If drugs have multiple NDC code, it returns all other codes in the all_k_aux_label column 36 sbiobertresolve_hcpcs • HCPCS Codes• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN Domain Information 37 sbiobertresolve_HPO • Maps phenotypic abnormalities encountered in human diseases to Human Phenotype Ontology (HPO)• Provides associated codes from the following vocabularies for each HPO code: - MeSH (Medical Subject Headings)- SNOMED- UMLS (Unified Medical Language System ) - ORPHA (international reference resource for information on rare diseases and orphan drugs) - OMIM (Online Mendelian Inheritance in Man) in all_k_aux_labels column sbiobert_base_cased_mli EN SNOMED, MeSH, UMLS, ORPHA, OMIM Codes 38 sbiobertresolve_snomed_auxConcepts • SNOMED Codes• sbiobert_base_cased_mli  embeddings• Capable of extracting Morph Abnormality, Procedure, Substance, Physical Object, and Body Structure concepts of Snomed codes sbiobert_base_cased_mli EN   39 sbiobertresolve_snomed_auxConcepts_int • SNOMED Codes (INT Version)• sbiobert_base_cased_mli  embeddings• Capable of extracting Morph Abnormality, Procedure, Substance, Physical Object, and Body Structure concepts of Snomed codes sbiobert_base_cased_mli EN   40 sbiobertresolve_snomed_bodyStructure • SNOMED Codes for body structure• sbiobert_base_cased_mli  embeddings• Anatomical structures to body structure SNOMED codes sbiobert_base_cased_mli EN   41 sbertresolve_snomed_bodyStructure_med • SNOMED Codes for body structure• sbert_jsl_medium_uncased  embeddings• Anatomical structures to body structure SNOMED codes sbert_jsl_medium_uncased EN   42 sbiobertresolve_snomed_drug • SNOMED Codes (drug version)• sbiobert_base_cased_mli  embeddings• Drug entities to SNOMED codes sbiobert_base_cased_mli EN   43 sbiobertresolve_snomed_findings • SNOMED Codes (CT version)• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   44 sbiobertresolve_snomed_findings_int • SNOMED Codes (INT version)• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   45 sbiobertresolve_snomed_findings_aux_concepts • SNOMED Codes• sbiobert_base_cased_mli  embeddings• Capable of extracting Morph Abnormality, Procedure, Substance, Physical Object, and Body Structure concepts of Snomed codes• Both Aux and CT versions together sbiobert_base_cased_mli EN   46 sbiobertresolve_snomed_procedures_measurements • SNOMED Codes for procedure and measurements• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   47 sbiobertresolve_clinical_snomed_procedures_measurements • SNOMED Codes for procedure and measurements• sbiobert_base_cased_mli  embeddings sent_biobert_clinical_base_cased EN   48 sbertresolve_snomed_conditions • Conditions to SNOMED Codes• sbert_jsl_medium_uncased embeddings sbert_jsl_medium_uncased EN   49 robertaresolve_snomed • Spanish SNOMED Codes• Roberta Clinical Word Embeddings (roberta_base_biomedical_es)• averaged with SentenceEmbeddings. roberta_base_biomedical_es ES   50 sbertresolve_snomed • German SNOMED Codes• sent_bert_base_cased (DE) sent_bert_base_cased (DE) DE   51 sbiobertresolve_umls_clinical_drugs • UMLS CUI Codes for Clinical Drugs• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   52 sbiobertresolve_umls_disease_syndrome • UMLS CUI Codes for Disease and Syndrom entities• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   53 sbiobertresolve_umls_drug_substance • UMLS CUI Codes for Drug and Substance entities• sbiobert_base_cased_mli  embeddings• Clinical Drugs, Pharmacologic Substance, Antibiotic, Hazardous or Poisonous Substance to UMLS CUI Codes sbiobert_base_cased_mli EN   54 sbiobertresolve_umls_findings • UMLS CUI Codes for clinical entities and concepts• sbiobert_base_cased_mli  embeddings• 4 major categories of UMLS CUI codes sbiobert_base_cased_mli EN   55 sbiobertresolve_umls_major_concepts • UMLS CUI Codes for clinical entities and concepts• sbiobert_base_cased_mli  embeddings• 4 major categories (Clinical Findings, Medical Devices, Anatomical Structures, and Injuries &amp; Poisoning terms) of UMLS CUI codes sbiobert_base_cased_mli EN               Entity Resolver Model and NER Model Pairs In the table below, you can find Entity Resolver models as well as its appropriate NER models and labels, that can return optimal results. For instance, sbiobertresolve_hcc_augmented resolver model must be used with sbiobert_base_cased_mli as embeddings, ner_clinical as NER model, PROBLEM set in setWhiteList(). NOTE: This table is shared just to give you a rough idea about which pretrained models can be used together. You can get better or worse performance by playing out with different models. ENTITY RESOLVER MODEL SENTENCE EMBEDDINGS NER MODEL NER MODEL WHITELIST LABEL MERGE CHUNKS (ChunkMergeApproach) sbiobertresolve_HPO sbiobert_base_cased_mli ner_human_phenotype_gene_clinical No need to set whiteList sbiobertresolve_cpt_procedures_measurements_augmented sbiobert_base_cased_mli ner_jsl Procedure Merge ner_jsl and ner_measurements_clinical model chunks ner_measurements_clinical Measurements sbiobertresolve_hcc_augmented sbiobert_base_cased_mli ner_clinical PROBLEM sbiobertresolve_hcpcs sbiobert_base_cased_mli ner_jsl Procedure sbiobertresolve_icd10cm_augmented_billable_hcc sbiobert_base_cased_mli ner_clinical PROBLEM sbiobertresolve_icd10cm_generalised sbiobert_base_cased_mli ner_clinical PROBLEM sbiobertresolve_icd10pcs sbiobert_base_cased_mli ner_jsl Procedure sbiobertresolve_icdo_base sbiobert_base_cased_mli ner_jsl Oncological sbiobertresolve_loinc_augmented sbiobert_base_cased_mli ner_jsl TestBMIHDLLDLMedical_DeviceTemperatureTotal_CholesterolTriglyceridesBlood_Pressure sbiobertresolve_mesh sbiobert_base_cased_mli ner_clinical No need to set whiteList sbiobertresolve_rxcui sbiobert_base_cased_mli ner_posology DRUG sbiobertresolve_rxnorm_augmented sbiobert_base_cased_mli ner_posology DRUG sbiobertresolve_rxnorm_disposition sbiobert_base_cased_mli ner_posology DRUG sbiobertresolve_snomed_bodyStructure sbiobert_base_cased_mli ner_jsl Disease_Syndrome_DisorderExternal_body_part_or_region Merge ner_jsl and ner_anatomy_coarse model chunks ner_anatomy_coarse No need to set whiteList sbiobertresolve_snomed_procedures_measurements sbiobert_base_cased_mli ner_jsl ProcedureTestBMIHDLLDLTemperatureTotal_CholesterolTriglyceridesBlood_Pressure Merge ner_jsl and ner_measurements_clinical model chunks ner_measurements_clinical Measurements sbiobertresolve_snomed_findings sbiobert_base_cased_mli ner_clinical No need to set whiteList sbiobertresolve_umls_disease_syndrome sbiobert_base_cased_mli ner_jsl Cerebrovascular_DiseaseCommunicable_DiseaseDiabetesDisease_Syndrome_DisorderHeart_DiseaseHyperlipidemiaHypertensionInjury_or_PoisoningKidney_DiseaseObesityOncologicalOverweightPsychological_ConditionSymptomVS_FindingImagingFindingsEKG_Findings sbiobertresolve_umls_clinical_drugs sbiobert_base_cased_mli ner_posology DRUG sbiobertresolve_umls_major_concepts sbiobert_base_cased_mli ner_jsl Cerebrovascular_DiseaseCommunicable_DiseaseDiabetesDisease_Syndrome_DisorderHeart_DiseaseHyperlipidemiaHypertensionInjury_or_PoisoningKidney_DiseaseMedical-DeviceObesityOncologicalOverweightPsychological_ConditionSymptomVS_FindingImagingFindingsEKG_Findings sbiobertresolve_ndc sbiobert_base_cased_mli ner_posology_greedy DRUG Relation Extraction Models and Relation Pairs Table In the table below, available Relation Extraction models, its labels, optimal NER model, and meaningful relation pairs are illustrated. For instance, re_bodypart_proceduretest RE model returns (0,1) labels (binary), works optimally with ner_jsl NER model, and outputs relation pairs under the RE PAIRS column. NOTE: This table is shared just to give you a rough idea about which pretrained models can be used together. You can get better or worse performance by playing out with different models. NO RE MODEL RE MODEL LABELS NER MODEL RE PAIRS 1 re_bodypart_proceduretest 0,1 ner_jsl [“external_body_part_or_region-test”, ”test-external_body_part_or_region”,“internal_organ_or_component-test”,“test-internal_organ_or_component”,“external_body_part_or_region-procedure”,“procedure-external_body_part_or_region”,“procedure-internal_organ_or_component”,“internal_organ_or_component-procedure”] 2 re_ade_clinical 0,1 ner_ade_clinical [“ade-drug”, ”drug-ade”] 3 redl_chemprot_biobert CPR:1, CPR:2, CPR:3, CPR:4, CPR:5, CPR:6, CPR:7, CPR:8, CPR:9, CPR:10 ner_chemprot_clinical [“No need to set pairs.”] 4 re_human_phenotype_gene_clinical 0,1 ner_human_phenotype_gene_clinical [“No need to set pairs.”] 5 re_bodypart_directions 0,1 ner_jsl [“direction-external_body_part_or_region”,“external_body_part_or_region-direction”,“direction-internal_organ_or_component”,“internal_organ_or_component-direction”] 6 re_bodypart_problem 0,1 ner_jsl [“internal_organ_or_component-cerebrovascular_disease”, “cerebrovascular_disease-internal_organ_or_component”,“internal_organ_or_component-communicable_disease”, “communicable_disease-internal_organ_or_component”,“internal_organ_or_component-diabetes”, “diabetes-internal_organ_or_component”,“internal_organ_or_component-disease_syndrome_disorder”, “disease_syndrome_disorder-internal_organ_or_component”,“internal_organ_or_component-ekg_findings”, “ekg_findings-internal_organ_or_component”,“internal_organ_or_component-heart_disease”, “heart_disease-internal_organ_or_component”,“internal_organ_or_component-hyperlipidemia”, “hyperlipidemia-internal_organ_or_component”,“internal_organ_or_component-hypertension”, “hypertension-internal_organ_or_component”,“internal_organ_or_component-imagingfindings”, “imagingfindings-internal_organ_or_component”,“internal_organ_or_component-injury_or_poisoning”, “injury_or_poisoning-internal_organ_or_component”,“internal_organ_or_component-kidney_disease”, “kidney_disease-internal_organ_or_component”,“internal_organ_or_component-oncological”, “oncological-internal_organ_or_component”,“internal_organ_or_component-psychological_condition”, “psychological_condition-internal_organ_or_component”,“internal_organ_or_component-symptom”, “symptom-internal_organ_or_component”,“internal_organ_or_component-vs_finding”, “vs_finding-internal_organ_or_component”,“external_body_part_or_region-communicable_disease”, “communicable_disease-external_body_part_or_region”,“external_body_part_or_region-diabetes”, “diabetes-external_body_part_or_region”,“external_body_part_or_region-disease_syndrome_disorder”, “disease_syndrome_disorder-external_body_part_or_region”,“external_body_part_or_region-hypertension”, “hypertension-external_body_part_or_region”,“external_body_part_or_region-imagingfindings”, “imagingfindings-external_body_part_or_region”,“external_body_part_or_region-injury_or_poisoning”, “injury_or_poisoning-external_body_part_or_region”,“external_body_part_or_region-obesity”, “obesity-external_body_part_or_region”,“external_body_part_or_region-oncological”, “oncological-external_body_part_or_region”,“external_body_part_or_region-overweight”, “overweight-external_body_part_or_region”,“external_body_part_or_region-symptom”, “symptom-external_body_part_or_region”,“external_body_part_or_region-vs_finding”, “vs_finding-external_body_part_or_region”] 7 re_drug_drug_interaction_clinical DDI-advise, DDI-effect, DDI-mechanism, DDI-int, DDI-false ner_posology [“drug-drug”] 8 re_clinical TrIP, TrWP, TrCP, TrAP, TrAP, TeRP, TeCP, PIP ner_clinical [“No need to set pairs.”] 9 re_temporal_events_clinical AFTER, BEFORE, OVERLAP ner_events_clinical [“No need to set pairs.”] 10 re_temporal_events_enriched_clinical BEFORE, AFTER, SIMULTANEOUS, BEGUN_BY, ENDED_BY, DURING, BEFORE_OVERLAP ner_events_clinical [“No need to set pairs.”] 11 re_test_problem_finding 0,1 ner_jsl [“test-cerebrovascular_disease”, “cerebrovascular_disease-test”,“test-communicable_disease”, “communicable_disease-test”,“test-diabetes”, “diabetes-test”,“test-disease_syndrome_disorder”, “disease_syndrome_disorder-test”,“test-heart_disease”, “heart_disease-test”,“test-hyperlipidemia”, “hyperlipidemia-test”,“test-hypertension”, “hypertension-test”,“test-injury_or_poisoning”, “injury_or_poisoning-test”,“test-kidney_disease”, “kidney_disease-test”,“test-obesity”, “obesity-test”,“test-oncological”, “oncological-test”,“test-psychological_condition”, “psychological_condition-test”,“test-symptom”, “symptom-test”,“ekg_findings-disease_syndrome_disorder”, “disease_syndrome_disorder-ekg_findings”,“ekg_findings-heart_disease”, “heart_disease-ekg_findings”,“ekg_findings-symptom”, “symptom-ekg_findings”,“imagingfindings-cerebrovascular_disease”, “cerebrovascular_disease-imagingfindings”,“imagingfindings-communicable_disease”, “communicable_disease-imagingfindings”,“imagingfindings-disease_syndrome_disorder”, “disease_syndrome_disorder-imagingfindings”,“imagingfindings-heart_disease”, “heart_disease-imagingfindings”,“imagingfindings-hyperlipidemia”, “hyperlipidemia-imagingfindings”,“imagingfindings-hypertension”, “hypertension-imagingfindings”,“imagingfindings-injury_or_poisoning”, “injury_or_poisoning-imagingfindings”,“imagingfindings-kidney_disease”, “kidney_disease-imagingfindings”,“imagingfindings-oncological”, “oncological-imagingfindings”,“imagingfindings-psychological_condition”, “psychological_condition-imagingfindings”,“imagingfindings-symptom”, “symptom-imagingfindings”,“vs_finding-cerebrovascular_disease”, “cerebrovascular_disease-vs_finding”,“vs_finding-communicable_disease”, “communicable_disease-vs_finding”,“vs_finding-diabetes”, “diabetes-vs_finding”,“vs_finding-disease_syndrome_disorder”, “disease_syndrome_disorder-vs_finding”,“vs_finding-heart_disease”, “heart_disease-vs_finding”,“vs_finding-hyperlipidemia”, “hyperlipidemia-vs_finding”,“vs_finding-hypertension”, “hypertension-vs_finding”,“vs_finding-injury_or_poisoning”, “injury_or_poisoning-vs_finding”,“vs_finding-kidney_disease”, “kidney_disease-vs_finding”,“vs_finding-obesity”, “obesity-vs_finding”,“vs_finding-oncological”, “oncological-vs_finding”,“vs_finding-overweight”, “overweight-vs_finding”,“vs_finding-psychological_condition”, “psychological_condition-vs_finding”,“vs_finding-symptom”, “symptom-vs_finding”] 12 re_test_result_date is_finding_of, is_result_of, is_date_of, O ner_jsl [“test-test_result”, “test_result-test”,“test-date”, “date-test”,“test-imagingfindings”, “imagingfindings-test”,“test-ekg_findings”, “ekg_findings-test”,“date-test_result”, “test_result-date”,“date-imagingfindings”, “imagingfindings-date”,“date-ekg_findings”, “ekg_findings-date”] 13 re_date_clinical 0,1 ner_jsl [“date-admission_discharge”, “admission_discharge-date”,“date-alcohol”, “alcohol-date”,“date-allergen”, “allergen-date”,“date-bmi”, “bmi-date”,“date-birth_entity”, “birth_entity-date”,“date-blood_pressure”, “blood_pressure-date”,“date-cerebrovascular_disease”, “cerebrovascular_disease-date”,“date-clinical_dept”, “clinical_dept-date”,“date-communicable_disease”, “communicable_disease-date”,“date-death_entity”, “death_entity-date”,“date-diabetes”, “diabetes-date”,“date-diet”, “diet-date”,“date-disease_syndrome_disorder”, “disease_syndrome_disorder-date”,“date-drug_brandname”, “drug_brandname-date”,“date-drug_ingredient”, “drug_ingredient-date”,“date-ekg_findings”, “ekg_findings-date”,“date-external_body_part_or_region”, “external_body_part_or_region-date”,“date-fetus_newborn”, “fetus_newborn-date”,“date-hdl”, “hdl-date”,“date-heart_disease”, “heart_disease-date”,“date-height”, “height-date”,“date-hyperlipidemia”, “hyperlipidemia-date”,“date-hypertension”, “hypertension-date”,“date-imagingfindings”, “imagingfindings-date”,“date-imaging_technique”, “imaging_technique-date”,“date-injury_or_poisoning”, “injury_or_poisoning-date”,“date-internal_organ_or_component”, “internal_organ_or_component-date”,“date-kidney_disease”, “kidney_disease-date”,“date-ldl”, “ldl-date”,“date-modifier”, “modifier-date”,“date-o2_saturation”, “o2_saturation-date”,“date-obesity”, “obesity-date”,“date-oncological”, “oncological-date”,“date-overweight”, “overweight-date”,“date-oxygen_therapy”, “oxygen_therapy-date”,“date-pregnancy”, “pregnancy-date”,“date-procedure”, “procedure-date”,“date-psychological_condition”, “psychological_condition-date”,“date-pulse”, “pulse-date”,“date-respiration”, “respiration-date”,“date-smoking”, “smoking-date”,“date-substance”, “substance-date”,“date-substance_quantity”, “substance_quantity-date”,“date-symptom”, “symptom-date”,“date-temperature”, “temperature-date”,“date-test”, “test-date”,“date-test_result”, “test_result-date”,“date-total_cholesterol”, “total_cholesterol-date”,“date-treatment”, “treatment-date”,“date-triglycerides”, “triglycerides-date”,“date-vs_finding”, “vs_finding-date”,“date-vaccine”, “vaccine-date”,“date-vital_signs_header”, “vital_signs_header-date”,“date-weight”, “weight-date”,“time-admission_discharge”, “admission_discharge-time”,“time-alcohol”, “alcohol-time”,“time-allergen”, “allergen-time”,“time-bmi”, “bmi-time”,“time-birth_entity”, “birth_entity-time”,“time-blood_pressure”, “blood_pressure-time”,“time-cerebrovascular_disease”, “cerebrovascular_disease-time”,“time-clinical_dept”, “clinical_dept-time”,“time-communicable_disease”, “communicable_disease-time”,“time-death_entity”, “death_entity-time”,“time-diabetes”, “diabetes-time”,“time-diet”, “diet-time”,“time-disease_syndrome_disorder”, “disease_syndrome_disorder-time”,“time-drug_brandname”, “drug_brandname-time”,“time-drug_ingredient”, “drug_ingredient-time”,“time-ekg_findings”, “ekg_findings-time”,“time-external_body_part_or_region”, “external_body_part_or_region-time”,“time-fetus_newborn”, “fetus_newborn-time”,“time-hdl”, “hdl-time”,“time-heart_disease”, “heart_disease-time”,“time-height”, “height-time”,“time-hyperlipidemia”, “hyperlipidemia-time”,“time-hypertension”, “hypertension-time”,“time-imagingfindings”, “imagingfindings-time”,“time-imaging_technique”, “imaging_technique-time”,“time-injury_or_poisoning”, “injury_or_poisoning-time”,“time-internal_organ_or_component”, “internal_organ_or_component-time”,“time-kidney_disease”, “kidney_disease-time”,“time-ldl”, “ldl-time”,“time-modifier”, “modifier-time”,“time-o2_saturation”, “o2_saturation-time”,“time-obesity”, “obesity-time”,“time-oncological”, “oncological-time”,“time-overweight”, “overweight-time”,“time-oxygen_therapy”, “oxygen_therapy-time”,“time-pregnancy”, “pregnancy-time”,“time-procedure”, “procedure-time”,“time-psychological_condition”, “psychological_condition-time”,“time-pulse”, “pulse-time”,“time-respiration”, “respiration-time”,“time-smoking”, “smoking-time”,“time-substance”, “substance-time”,“time-substance_quantity”, “substance_quantity-time”,“time-symptom”, “symptom-time”,“time-temperature”, “temperature-time”,“time-test”, “test-time”,“time-test_result”, “test_result-time”,“time-total_cholesterol”, “total_cholesterol-time”,“time-treatment”, “treatment-time”,“time-triglycerides”, “triglycerides-time”,“time-vs_finding”, “vs_finding-time”,“time-vaccine”, “vaccine-time”,“time-vital_signs_header”, “vital_signs_header-time”,“time-weight”, “weight-time”,“relativedate-admission_discharge”, “admission_discharge-relativedate”,“relativedate-alcohol”, “alcohol-relativedate”,“relativedate-allergen”, “allergen-relativedate”,“relativedate-bmi”, “bmi-relativedate”,“relativedate-birth_entity”, “birth_entity-relativedate”,“relativedate-blood_pressure”, “blood_pressure-relativedate”,“relativedate-cerebrovascular_disease”, “cerebrovascular_disease-relativedate”,“relativedate-clinical_dept”, “clinical_dept-relativedate”,“relativedate-communicable_disease”, “communicable_disease-relativedate”,“relativedate-death_entity”, “death_entity-relativedate”,“relativedate-diabetes”, “diabetes-relativedate”,“relativedate-diet”, “diet-relativedate”,“relativedate-disease_syndrome_disorder”, “disease_syndrome_disorder-relativedate”,“relativedate-drug_brandname”, “drug_brandname-relativedate”,“relativedate-drug_ingredient”, “drug_ingredient-relativedate”,“relativedate-ekg_findings”, “ekg_findings-relativedate”,“relativedate-external_body_part_or_region”, “external_body_part_or_region-relativedate”,“relativedate-fetus_newborn”, “fetus_newborn-relativedate”,“relativedate-hdl”, “hdl-relativedate”,“relativedate-heart_disease”, “heart_disease-relativedate”,“relativedate-height”, “height-relativedate”,“relativedate-hyperlipidemia”, “hyperlipidemia-relativedate”,“relativedate-hypertension”, “hypertension-relativedate”,“relativedate-imagingfindings”, “imagingfindings-relativedate”,“relativedate-imaging_technique”, “imaging_technique-relativedate”,“relativedate-injury_or_poisoning”, “injury_or_poisoning-relativedate”,“relativedate-internal_organ_or_component”, “internal_organ_or_component-relativedate”,“relativedate-kidney_disease”, “kidney_disease-relativedate”,“relativedate-ldl”, “ldl-relativedate”,“relativedate-modifier”, “modifier-relativedate”,“relativedate-o2_saturation”, “o2_saturation-relativedate”,“relativedate-obesity”, “obesity-relativedate”,“relativedate-oncological”, “oncological-relativedate”,“relativedate-overweight”, “overweight-relativedate”,“relativedate-oxygen_therapy”, “oxygen_therapy-relativedate”,“relativedate-pregnancy”, “pregnancy-relativedate”,“relativedate-procedure”, “procedure-relativedate”,“relativedate-psychological_condition”, “psychological_condition-relativedate”,“relativedate-pulse”, “pulse-relativedate”,“relativedate-respiration”, “respiration-relativedate”,“relativedate-smoking”, “smoking-relativedate”,“relativedate-substance”, “substance-relativedate”,“relativedate-substance_quantity”, “substance_quantity-relativedate”,“relativedate-symptom”, “symptom-relativedate”,“relativedate-temperature”, “temperature-relativedate”,“relativedate-test”, “test-relativedate”,“relativedate-test_result”, “test_result-relativedate”,“relativedate-total_cholesterol”, “total_cholesterol-relativedate”,“relativedate-treatment”, “treatment-relativedate”,“relativedate-triglycerides”, “triglycerides-relativedate”,“relativedate-vs_finding”, “vs_finding-relativedate”,“relativedate-vaccine”, “vaccine-relativedate”,“relativedate-vital_signs_header”, “vital_signs_header-relativedate”,“relativedate-weight”, “weight-relativedate”,“relativetime-admission_discharge”, “admission_discharge-relativetime”,“relativetime-alcohol”, “alcohol-relativetime”,“relativetime-allergen”, “allergen-relativetime”,“relativetime-bmi”, “bmi-relativetime”,“relativetime-birth_entity”, “birth_entity-relativetime”,“relativetime-blood_pressure”, “blood_pressure-relativetime”,“relativetime-cerebrovascular_disease”, “cerebrovascular_disease-relativetime”,“relativetime-clinical_dept”, “clinical_dept-relativetime”,“relativetime-communicable_disease”, “communicable_disease-relativetime”,“relativetime-death_entity”, “death_entity-relativetime”,“relativetime-diabetes”, “diabetes-relativetime”,“relativetime-diet”, “diet-relativetime”,“relativetime-disease_syndrome_disorder”, “disease_syndrome_disorder-relativetime”,“relativetime-drug_brandname”, “drug_brandname-relativetime”,“relativetime-drug_ingredient”, “drug_ingredient-relativetime”,“relativetime-ekg_findings”, “ekg_findings-relativetime”,“relativetime-external_body_part_or_region”, “external_body_part_or_region-relativetime”,“relativetime-fetus_newborn”, “fetus_newborn-relativetime”,“relativetime-hdl”, “hdl-relativetime”,“relativetime-heart_disease”, “heart_disease-relativetime”,“relativetime-height”, “height-relativetime”,“relativetime-hyperlipidemia”, “hyperlipidemia-relativetime”,“relativetime-hypertension”, “hypertension-relativetime”,“relativetime-imagingfindings”, “imagingfindings-relativetime”,“relativetime-imaging_technique”, “imaging_technique-relativetime”,“relativetime-injury_or_poisoning”, “injury_or_poisoning-relativetime”,“relativetime-internal_organ_or_component”, “internal_organ_or_component-relativetime”,“relativetime-kidney_disease”, “kidney_disease-relativetime”,“relativetime-ldl”, “ldl-relativetime”,“relativetime-modifier”, “modifier-relativetime”,“relativetime-o2_saturation”, “o2_saturation-relativetime”,“relativetime-obesity”, “obesity-relativetime”,“relativetime-oncological”, “oncological-relativetime”,“relativetime-overweight”, “overweight-relativetime”,“relativetime-oxygen_therapy”, “oxygen_therapy-relativetime”,“relativetime-pregnancy”, “pregnancy-relativetime”,“relativetime-procedure”, “procedure-relativetime”,“relativetime-psychological_condition”, “psychological_condition-relativetime”,“relativetime-pulse”, “pulse-relativetime”,“relativetime-respiration”, “respiration-relativetime”,“relativetime-smoking”, “smoking-relativetime”,“relativetime-substance”, “substance-relativetime”,“relativetime-substance_quantity”, “substance_quantity-relativetime”,“relativetime-symptom”, “symptom-relativetime”,“relativetime-temperature”, “temperature-relativetime”,“relativetime-test”, “test-relativetime”,“relativetime-test_result”, “test_result-relativetime”,“relativetime-total_cholesterol”, “total_cholesterol-relativetime”,“relativetime-treatment”, “treatment-relativetime”,“relativetime-triglycerides”, “triglycerides-relativetime”,“relativetime-vs_finding”, “vs_finding-relativetime”,“relativetime-vaccine”, “vaccine-relativetime”,“relativetime-vital_signs_header”, “vital_signs_header-relativetime”,“relativetime-weight”, “weight-relativetime”] 14 redl_drugprot_biobert  INHIBITOR, DIRECT-REGULATOR, SUBSTRATE, ACTIVATOR, INDIRECT-UPREGULATOR, INDIRECT-DOWNREGULATOR, ANTAGONIST, PRODUCT-OF, PART-OF, AGONIST ner_drugprot_clinical [“checmical-gene”, “chemical-gene_and_chemical”, “gene_and_chemical-gene”] 15 re_drugprot_clinical  INHIBITOR, DIRECT-REGULATOR, SUBSTRATE, ACTIVATOR, INDIRECT-UPREGULATOR, INDIRECT-DOWNREGULATOR, ANTAGONIST, PRODUCT-OF, PART-OF, AGONIST ner_drugprot_clinical [“checmical-gene”, “chemical-gene_and_chemical”, “gene_and_chemical-gene”] 16 redl_nihss_biobert Has_Value, 0 ner_nihss [“No need to set pairs.”]",
    "url": "/docs/en/best_practices_pretrained_models",
    "relUrl": "/docs/en/best_practices_pretrained_models"
  },
  "869": {
    "id": "869",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/big_text_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/big_text_matcher.html"
  },
  "870": {
    "id": "870",
    "title": "License Management",
    "content": "By default, the Annotation Lab allows access to community pre-trained models and embeddings. Those are available on the Models Hub page. To gain access to licensed resources (e.g. pre-trained models and embeddings) admin user can import a license (Healthcare, Finance, Legal, or Visual NLP) which will activate additional features: Access to licensed models for pre-annotation Access to healthcare, finance, and legal embeddings Access to rules Access to optimized annotators Access to training custom models using licensed embeddings The admin user can upload a Spark NLP license JSON file by visiting the License page. The license is generated by the John Snow Labs license server and is available on my.johnsnowlabs.com. Once a valid license is uploaded, all the licensed (Healthcare, Finance, Legal, and Visual NLP) models and embeddings become available for download. The License page shows the history of license uploads with detailed information like License Info, Status, Renewal Date, and License Secrets. Support for Floating Licenses Annotation Lab supports floating licenses with different scopes (ocr: training, ocr: inference, healthcare: inference, healthcare: training, finance: inference, finance: training, legal: inference, legal: training). Depending on the scope of the available license, users can perform model training and/or deploy pre-annotation servers. Licenses are a must for training Healthcare, Finance, and Legal models and deploying these models as pre-annotation servers. Floating licenses can be acquired on self-service via my.johnsnowlabs.com. One floating license is bound to only one server (pre-annotation server, OCR server, training job) at a time. To run multiple model training jobs and/or pre-annotations servers, users must provide multiple floating licenses. Annotation Lab supports either floating licenses or air-gapped licenses. Mixing floating and air-gapped licenses on the same Annotation Lab instance is not allowed. In-App Trial License Generation Version 4.10 offers an updated License page layout that streamlines the process of obtaining a trial license. This updated design enables users to initiate a trial license request directly from the License page, thereby eliminating the need for external page navigation. This enhanced workflow incorporates a new “Get License” tab, while maintaining the status quo of the Import License and Existing Licenses tabs. To obtain a trial license, users are required to fill out the form on the “Get License” tab, providing their organizational email. Once the form is submitted, a validation link is sent to the provided email address, and the trial license is automatically imported to the NLP Lab when the link is clicked, making it readily available for use. Usage of NLP Licenses The number of available floating licenses can influence the creation of multiple training and pre-annotation servers. For example, to deploy 5 pre-annotation servers using Spark NLP for Healthcare models or embeddings, across 5 different projects, you will need 5 floating licenses. Since one floating license can only be used for one server, it is not possible to deploy a pre-annotation server and then trigger training from the same project when only one license is available. In this case, the pre-annotation server has to be deleted first, and then the training can be started. Those restrictions do not apply when using Spark NLP models and embeddings.",
    "url": "/docs/en/alab/byol",
    "relUrl": "/docs/en/alab/byol"
  },
  "871": {
    "id": "871",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/camembert_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/camembert_embeddings.html"
  },
  "872": {
    "id": "872",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_question_answering.html"
  },
  "873": {
    "id": "873",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification.html"
  },
  "874": {
    "id": "874",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_token_classification.html"
  },
  "875": {
    "id": "875",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/chunk2_doc.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/chunk2_doc.html"
  },
  "876": {
    "id": "876",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/chunk_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/chunk_embeddings.html"
  },
  "877": {
    "id": "877",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/token/chunk_tokenizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/token/chunk_tokenizer.html"
  },
  "878": {
    "id": "878",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/chunker.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/chunker.html"
  },
  "879": {
    "id": "879",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/classifier_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/classifier_dl.html"
  },
  "880": {
    "id": "880",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/param/classifier_encoder.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/param/classifier_encoder.html"
  },
  "881": {
    "id": "881",
    "title": "Classify Documents - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/classify_documents",
    "relUrl": "/classify_documents"
  },
  "882": {
    "id": "882",
    "title": "Classify Financial Documents - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/classify_financial_documents",
    "relUrl": "/classify_financial_documents"
  },
  "883": {
    "id": "883",
    "title": "Cluster Management",
    "content": "Management of Preannotation and Training Servers Annotation Lab gives users the ability to view the list of all active servers. Any user can access the Clusters page by navigating to Settings &gt; Clusters. This page provides the following details. A summary of the status/limitations of the current infrastructure to run Spark NLP for Healthcare training jobs and/or pre-annotation servers. Ability to delete a server and free up resources when required, so that another training job and/or pre-annotation server can be started. Shows details of the server Server Name: The name of server that can help identify it while running pre-annotation or importing files. License Used/Scope: The license that is being used in the server and its scope. Usage: Let the user know the usage of the server. A server can be used for pre-annotation, training, or OCR. Status: Status of training and pre-annotation servers. Deployed By: The user who deployed the server. This information might be useful for contacting the user who deployed a server before deleting it. Deployed At: Shows when the server was deployed. By default, only 1 server can be initialized for either pre-annotation or training even if there are multiple licenses present. To enable more than 1 servers to be initialized update the below configuration parameter in annotationlab-updater.sh script inside the artifacts folder and then re-run it. model_server.count=&lt;NUMBER_OF_SERVER_TO_INITIALIZE&gt; airflow.model_server.count=&lt;NUMBER_OF_SERVER_TO_INITIALIZE&gt; To run the script: sudo ./annotationlab-updater.sh Status of Training and Preannotation Server A new column, status, is added to the Clusters page that gives the status of training and pre-annotation servers. The available pre-annotation server statuses are: Idle Busy Stopped Users can visualize which servers are busy and which are idle. It is very useful information when the user intends to deploy a new server in replacement of an idle one. In this situation, the user can delete an idle server and deploy another pre-annotation/ training server. This information is also available on the pre-annotation popup when the user selects the deployed server to use for pre-annotation. Also, if any issues are encountered during server initialization, those are displayed on the tooltip accessible via mouse-over. Depending on the issue, changes might be required in the infrastructure settings, and the user will have to manually redeploy the training/pre-annotation server.",
    "url": "/docs/en/alab/cluster_management",
    "relUrl": "/docs/en/alab/cluster_management"
  },
  "884": {
    "id": "884",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/logging/comet.html",
    "relUrl": "/api/python/modules/sparknlp/logging/comet.html"
  },
  "885": {
    "id": "885",
    "title": "Quick Start",
    "content": "Load &amp; Predict 1 liner The johnsnowlabs library provides 2 simple methods with which most NLP tasks can be solved while achieving state-of-the-art results. The load and predict method. when building a load&amp;predict based model you will follow these steps: Pick a model/pipeline/component you want to create from the Namespace Call the model = nlp.load(component) method which will return an auto-completed pipeline Call model.predict(&#39;that was easy&#39;) on some String input These 3 steps can be boiled down to just 1 line from johnsnowlabs import nlp nlp.load(&#39;sentiment&#39;).predict(&#39;How does this witchcraft work?&#39;) nlp.load() defines 18 components types usable in 1-liners, some can be prefixed with .train for training models Any of the actions for the component types can be passed as a string to nlp.load() and will return you the default model for that component type for the English language. You can further specify your model selection by placing a ‘.’ behind your component selection. After the ‘.’ you can specify the model you want via specifying a dataset or model version. See the Models Hub, the Components Namespace and The load function for more infos. Component type nlp.load() base Named Entity Recognition(NER) nlp.load(&#39;ner&#39;) Part of Speech (POS) nlp.load(&#39;pos&#39;) Classifiers nlp.load(&#39;classify&#39;) Word embeddings nlp.load(&#39;embed&#39;) Sentence embeddings nlp.load(&#39;embed_sentence&#39;) Chunk embeddings nlp.load(&#39;embed_chunk&#39;) Labeled dependency parsers nlp.load(&#39;dep&#39;) Unlabeled dependency parsers nlp.load(&#39;dep.untyped&#39;) Legitimatizes nlp.load(&#39;lemma&#39;) Matchers nlp.load(&#39;match&#39;) Normalizers nlp.load(&#39;norm&#39;) Sentence detectors nlp.load(&#39;sentence_detector&#39;) Chunkers nlp.load(&#39;chunk&#39;) Spell checkers nlp.load(&#39;spell&#39;) Stemmers nlp.load(&#39;stem&#39;) Stopwords cleaners nlp.load(&#39;stopwords&#39;) Cleaner nlp.load(&#39;clean&#39;) N-Grams nlp.load(&#39;ngram&#39;) Tokenizers nlp.load(&#39;tokenize&#39;) Annotator &amp; PretrainedPipeline based pipelines You can create Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the nlp module. nlp.PretrainedPipeline(&#39;pipe_name&#39;) gives access to Pretrained Pipelines from johnsnowlabs import nlp from pprint import pprint nlp.start() explain_document_pipeline = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;) annotations = explain_document_pipeline.annotate(&quot;We are very happy about SparkNLP&quot;) pprint(annotations) OUTPUT: { &#39;stem&#39;: [&#39;we&#39;, &#39;ar&#39;, &#39;veri&#39;, &#39;happi&#39;, &#39;about&#39;, &#39;sparknlp&#39;], &#39;checked&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;lemma&#39;: [&#39;We&#39;, &#39;be&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;document&#39;: [&#39;We are very happy about SparkNLP&#39;], &#39;pos&#39;: [&#39;PRP&#39;, &#39;VBP&#39;, &#39;RB&#39;, &#39;JJ&#39;, &#39;IN&#39;, &#39;NNP&#39;], &#39;token&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;sentence&#39;: [&#39;We are very happy about SparkNLP&#39;] } Custom Pipes Alternatively you can compose Annotators into a pipeline which offers the highest degree of customization from johnsnowlabs import nlp spark = nlp.start(nlp=False) pipe = nlp.Pipeline(stages= [ nlp.DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;doc&#39;), nlp.Tokenizer().setInputCols(&#39;doc&#39;).setOutputCol(&#39;tok&#39;) ]) spark_df = spark.createDataFrame([[&#39;Hello NLP World&#39;]]).toDF(&quot;text&quot;) pipe.fit(spark_df).transform(spark_df).show()",
    "url": "/docs/en/jsl/concepts",
    "relUrl": "/docs/en/jsl/concepts"
  },
  "886": {
    "id": "886",
    "title": "General Concepts",
    "content": "Concepts Spark ML provides a set of Machine Learning applications that can be build using two main components: Estimators and Transformers. The Estimators have a method called fit() which secures and trains a piece of data to such application. The Transformer is generally the result of a fitting process and applies changes to the the target dataset. These components have been embedded to be applicable to Spark NLP. Pipelines are a mechanism for combining multiple estimators and transformers in a single workflow. They allow multiple chained transformations along a Machine Learning task. For more information please refer to Spark ML library. Annotation The basic result of a Spark NLP operation is an annotation. It’s structure includes: annotatorType: the type of annotator that generated the current annotation begin: the begin of the matched content relative to raw-text end: the end of the matched content relative to raw-text result: the main output of the annotation metadata: content of matched result and additional information embeddings: (new in 2.0) contains vector mappings if required This object is automatically generated by annotators after a transform process. No manual work is required. However, it is important to clearly understand the structure of an annotation to be able too efficiently use it. Annotators Annotators are the spearhead of NLP functions in Spark NLP. There are two forms of annotators: Annotator Approaches: are those who represent a Spark ML Estimator and require a training stage. They have a function called fit(data) which trains a model based on some data. They produce the second type of annotator which is an annotator model or transformer. Annotator Models: are spark models or transformers, meaning they have a transform(data) function. This function takes as input a dataframe to which it adds a new column containing the result of the current annotation. All transformers are additive, meaning they append to current data, never replace or delete previous information. Both forms of annotators can be included in a Pipeline. All annotators included in a Pipeline will be automatically executed in the defined order and will transform the data accordingly. A Pipeline is turned into a PipelineModel after the fit() stage. The Pipeline can be saved to disk and re-loaded at any time. Common Functions setInputCols(column_names): Takes a list of column names of annotations required by this annotator. Those are generated by the annotators which precede the current annotator in the pipeline. setOutputCol(column_name): Defines the name of the column containing the result of the current annotator. Use this name as an input for other annotators down the pipeline requiring the outputs generated by the current annotator. Quickly annotate some text You can run these examples using Python or Scala. The easiest way to run the python examples is by starting a pyspark jupyter notebook including the spark-nlp package: $ java -version # should be Java 8 (Oracle or OpenJDK) $ conda create -n sparknlp python=3.7 -y $ conda activate sparknlp # spark-nlp by default is based on pyspark 3.x $ pip install spark-nlp==4.3.2 pyspark==3.3.1 jupyter $ jupyter notebook Explain Document ML Spark NLP offers a variety of pretrained pipelines that will help you get started, and get a sense of how the library works. We are constantly working on improving the available content. You can checkout a demo application of the Explain Document ML pipeline here: View Demo Downloading and using a pretrained pipeline Explain Document ML (explain_document_ml) is a pretrained pipeline that does a little bit of everything NLP related. Let’s try it out in scala. Note that the first time you run the below code it might take longer since it downloads the pretrained pipeline from our servers! PythonScala import sparknlp sparknlp.start() from sparknlp.pretrained import PretrainedPipeline explain_document_pipeline = PretrainedPipeline(&quot;explain_document_ml&quot;) annotations = explain_document_pipeline.annotate(&quot;We are very happy about SparkNLP&quot;) print(annotations) OUTPUT: { &#39;stem&#39;: [&#39;we&#39;, &#39;ar&#39;, &#39;veri&#39;, &#39;happi&#39;, &#39;about&#39;, &#39;sparknlp&#39;], &#39;checked&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;lemma&#39;: [&#39;We&#39;, &#39;be&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;document&#39;: [&#39;We are very happy about SparkNLP&#39;], &#39;pos&#39;: [&#39;PRP&#39;, &#39;VBP&#39;, &#39;RB&#39;, &#39;JJ&#39;, &#39;IN&#39;, &#39;NNP&#39;], &#39;token&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;sentence&#39;: [&#39;We are very happy about SparkNLP&#39;] } import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline val explainDocumentPipeline = PretrainedPipeline(&quot;explain_document_ml&quot;) OUTPUT: explain_document_ml download started this may take some time. Approximate size to download 9.4 MB Download done! Loading the resource. explain_document_pipeline: com.johnsnowlabs.nlp.pretrained.PretrainedPipeline = PretrainedPipeline(explain_document_ml,en,public/models) val annotations = explainDocumentPipeline.annotate(&quot;We are very happy about SparkNLP&quot;) println(annotations) OUTPUT: Map( stem -&gt; List(we, ar, veri, happi, about, sparknlp), checked -&gt; List(We, are, very, happy, about, SparkNLP), lemma -&gt; List(We, be, very, happy, about, SparkNLP), document -&gt; List(We are very happy about SparkNLP), pos -&gt; ArrayBuffer(PRP, VBP, RB, JJ, IN, NNP), token -&gt; List(We, are, very, happy, about, SparkNLP), sentence -&gt; List(We are very happy about SparkNLP) ) As you can see the explain_document_ml is able to annotate any “document” providing as output a list of stems, check-spelling, lemmas, part of speech tags, tokens and sentence boundary detection and all this “out-of-the-box”!. Using a pretrained pipeline with spark dataframes You can also use the pipeline with a spark dataframe. You just need to create first a spark dataframe with a column named “text” that will work as the input for the pipeline and then use the .transform() method to run the pipeline over that dataframe and store the outputs of the different components in a spark dataframe. Remember than when starting jupyter notebook from pyspark or when running the spark-shell for scala, a Spark Session is started in the background by default within the namespace ‘scala’. PythonScala import sparknlp sparknlp.start() sentences = [ [&#39;Hello, this is an example sentence&#39;], [&#39;And this is a second sentence.&#39;] ] # spark is the Spark Session automatically started by pyspark. data = spark.createDataFrame(sentences).toDF(&quot;text&quot;) # Download the pretrained pipeline from Johnsnowlab&#39;s servers explain_document_pipeline = PretrainedPipeline(&quot;explain_document_ml&quot;) OUTPUT: explain_document_ml download started this may take some time. Approx size to download 9.4 MB [OK!] # Transform &#39;data&#39; and store output in a new &#39;annotations_df&#39; dataframe annotations_df = explain_document_pipeline.transform(data) # Show the results annotations_df.show() OUTPUT: +--+--+--+--+--+--+--+--+ | text| document| sentence| token| checked| lemma| stem| pos| +--+--+--+--+--+--+--+--+ |Hello, this is an...|[[document, 0, 33...|[[document, 0, 33...|[[token, 0, 4, He...|[[token, 0, 4, He...|[[token, 0, 4, He...|[[token, 0, 4, he...|[[pos, 0, 4, UH, ...| |And this is a sec...|[[document, 0, 29...|[[document, 0, 29...|[[token, 0, 2, An...|[[token, 0, 2, An...|[[token, 0, 2, An...|[[token, 0, 2, an...|[[pos, 0, 2, CC, ...| +--+--+--+--+--+--+--+--+ val data = Seq( &quot;Hello, this is an example sentence&quot;, &quot;And this is a second sentence&quot;) .toDF(&quot;text&quot;) data.show(truncate=false) OUTPUT: ++ |text | ++ |Hello, this is an example set | |And this is a second sentence.| ++ val explainDocumentPipeline = PretrainedPipeline(&quot;explain_document_ml&quot;) val annotations_df = explainDocumentPipeline.transform(data) annotations_df.show() OUTPUT: +--+--+--+--+--+--+--+--+ | text| document| sentence| token| checked| lemma| stem| pos| +--+--+--+--+--+--+--+--+ |Hello, this is an...|[[document, 0, 33...|[[document, 0, 33...|[[token, 0, 4, He...|[[token, 0, 4, He...|[[token, 0, 4, He...|[[token, 0, 4, he...|[[pos, 0, 4, UH, ...| |And this is a sec...|[[document, 0, 29...|[[document, 0, 29...|[[token, 0, 2, An...|[[token, 0, 2, An...|[[token, 0, 2, An...|[[token, 0, 2, an...|[[pos, 0, 2, CC, ...| +--+--+--+--+--+--+--+--+ Manipulating pipelines The output of the previous DataFrame was in terms of Annotation objects. This output is not really comfortable to deal with, as you can see by running the code: PythonScala annotations_df.select(&quot;token&quot;).show(truncate=False) OUTPUT: +--+ |token | +--+ |[[token, 0, 4, Hello, [sentence -&gt; 0], [], []], [token, 5, 5, ,, [sentence -&gt; 0], [], []], [token, 7, 10, this, [sentence -&gt; 0], [], []], [token, 12, 13, is, [sentence -&gt; 0], [], []], [token, 15, 16, an, [sentence -&gt; 0], [], []], [token, 18, 24, example, [sentence -&gt; 0], [], []], [token, 26, 33, sentence, [sentence -&gt; 0], [], []]]| |[[token, 0, 2, And, [sentence -&gt; 0], [], []], [token, 4, 7, this, [sentence -&gt; 0], [], []], [token, 9, 10, is, [sentence -&gt; 0], [], []], [token, 12, 12, a, [sentence -&gt; 0], [], []], [token, 14, 19, second, [sentence -&gt; 0], [], []], [token, 21, 28, sentence, [sentence -&gt; 0], [], []], [token, 29, 29, ., [sentence -&gt; 0], [], []]] | +--+ annotations_df.select(&quot;token&quot;).show(truncate=false) OUTPUT: +--+ |token | +--+ |[[token, 0, 4, Hello, [sentence -&gt; 0], [], []], [token, 5, 5, ,, [sentence -&gt; 0], [], []], [token, 7, 10, this, [sentence -&gt; 0], [], []], [token, 12, 13, is, [sentence -&gt; 0], [], []], [token, 15, 16, an, [sentence -&gt; 0], [], []], [token, 18, 24, example, [sentence -&gt; 0], [], []], [token, 26, 33, sentence, [sentence -&gt; 0], [], []]]| |[[token, 0, 2, And, [sentence -&gt; 0], [], []], [token, 4, 7, this, [sentence -&gt; 0], [], []], [token, 9, 10, is, [sentence -&gt; 0], [], []], [token, 12, 12, a, [sentence -&gt; 0], [], []], [token, 14, 19, second, [sentence -&gt; 0], [], []], [token, 21, 28, sentence, [sentence -&gt; 0], [], []], [token, 29, 29, ., [sentence -&gt; 0], [], []]] | +--+ What if we want to deal with just the resulting annotations? We can use the Finisher annotator, retrieve the Explain Document ML pipeline, and add them together in a Spark ML Pipeline. Remember that pretrained pipelines expect the input column to be named “text”. PythonScala from sparknlp import Finisher from pyspark.ml import Pipeline from sparknlp.pretrained import PretrainedPipeline finisher = Finisher().setInputCols([&quot;token&quot;, &quot;lemmas&quot;, &quot;pos&quot;]) explain_pipeline_model = PretrainedPipeline(&quot;explain_document_ml&quot;).model pipeline = Pipeline() .setStages([ explain_pipeline_model, finisher ]) sentences = [ [&#39;Hello, this is an example sentence&#39;], [&#39;And this is a second sentence.&#39;] ] data = spark.createDataFrame(sentences).toDF(&quot;text&quot;) model = pipeline.fit(data) annotations_finished_df = model.transform(data) annotations_finished_df.select(&#39;finished_token&#39;).show(truncate=False) OUTPUT: +-+ |finished_token | +-+ |[Hello, ,, this, is, an, example, sentence]| |[And, this, is, a, second, sentence, .] | +-+ scala&gt; import com.johnsnowlabs.nlp.Finisher scala&gt; import org.apache.spark.ml.Pipeline scala&gt; val finisher = new Finisher().setInputCols(&quot;token&quot;, &quot;lemma&quot;, &quot;pos&quot;) scala&gt; val explainPipelineModel = PretrainedPipeline(&quot;explain_document_ml&quot;).model scala&gt; val pipeline = new Pipeline(). setStages(Array( explainPipelineModel, finisher )) scala&gt; val data = Seq( &quot;Hello, this is an example sentence&quot;, &quot;And this is a second sentence&quot;) .toDF(&quot;text&quot;) scala&gt; val model = pipeline.fit(data) scala&gt; val annotations_df = model.transform(data) scala&gt; annotations_df.select(&quot;finished_token&quot;).show(truncate=false) OUTPUT: +-+ |finished_token | +-+ |[Hello, ,, this, is, an, example, sentence]| |[And, this, is, a, second, sentence, .] | +-+ Setup your own pipeline Annotator types Every annotator has a type. Those annotators that share a type, can be used interchangeably, meaning you could use any of them when needed. For example, when a token type annotator is required by another annotator, such as a sentiment analysis annotator, you can either provide a normalized token or a lemma, as both are of type token. Necessary imports Since version 1.5.0 we are making necessary imports easy to reach, base._ will include general Spark NLP transformers and concepts, while annotator._ will include all annotators that we currently provide. We also need Spark ML pipelines. PythonScala from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline import com.johnsnowlabs.nlp.base._ import com.johnsnowlabs.nlp.annotator._ import org.apache.spark.ml.Pipeline DocumentAssembler: Getting data in In order to get through the NLP process, we need to get raw data annotated. There is a special transformer that does this for us: the DocumentAssembler, it creates the first annotation of type Document which may be used by annotators down the road. PythonScala documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val documentAssembler = new DocumentAssembler(). setInputCol(&quot;text&quot;). setOutputCol(&quot;document&quot;) Sentence detection and tokenization In this quick example, we now proceed to identify the sentences in the input document. SentenceDetector requires a Document annotation, which is provided by the DocumentAssembler output, and it’s itself a Document type token. The Tokenizer requires a Document annotation type. That means it works both with DocumentAssembler or SentenceDetector output. In the following example we use the sentence output. PythonScala sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;Sentence&quot;) regexTokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) val sentenceDetector = new SentenceDetector(). setInputCols(Array(&quot;document&quot;)). setOutputCol(&quot;sentence&quot;) val regexTokenizer = new Tokenizer(). setInputCols(Array(&quot;sentence&quot;)). setOutputCol(&quot;token&quot;) Spark NLP also includes another special transformer, called Finisher to show tokens in a human language. finisher = Finisher() .setInputCols([&quot;token&quot;]) .setCleanAnnotations(False) val finisher = new Finisher(). setInputCols(&quot;token&quot;). setCleanAnnotations(false) Finisher: Getting data out At the end of each pipeline or any stage that was done by Spark NLP, you may want to get results out whether onto another pipeline or simply write them on disk. The Finisher annotator helps you to clean the metadata (if it’s set to true) and output the results into an array: PythonScala finisher = Finisher() .setInputCols([&quot;token&quot;]) .setIncludeMetadata(True) val finisher = new Finisher() .setInputCols(&quot;token&quot;) .setIncludeMetadata(true) If you need to have a flattened DataFrame (each sub-array in a new column) from any annotations other than struct type columns, you can use explode function from Spark SQL. You can also use Apache Spark functions (SQL) to manipulate the output DataFrame in any way you need. Here we combine the tokens and NER results together: import pyspark.sql.functions as F df.withColumn(&quot;tmp&quot;, F.explode(&quot;chunk&quot;)).select(&quot;tmp.*&quot;) finisher.withColumn(&quot;newCol&quot;, explode(arrays_zip($&quot;finished_token&quot;, $&quot;finished_ner&quot;))) import org.apache.spark.sql.functions._ df.withColumn(&quot;tmp&quot;, explode(col(&quot;chunk&quot;))).select(&quot;tmp.*&quot;) Using Spark ML Pipeline Now we want to put all this together and retrieve the results, we use a Pipeline for this. We use the same data in fit() that we will use in transform since none of the pipeline stages have a training stage. PythonScala pipeline = Pipeline() .setStages([ documentAssembler, sentenceDetector, regexTokenizer, finisher ]) OUTPUT: +-+ |finished_token | +-+ |[hello, ,, this, is, an, example, sentence]| +-+ val pipeline = new Pipeline(). setStages(Array( documentAssembler, sentenceDetector, regexTokenizer, finisher )) val data = Seq(&quot;hello, this is an example sentence&quot;).toDF(&quot;text&quot;) val annotations = pipeline. fit(data). transform(data).toDF(&quot;text&quot;)) annotations.select(&quot;finished_token&quot;).show(truncate=false) OUTPUT: +-+ |finished_token | +-+ |[hello, ,, this, is, an, example, sentence]| +-+ Using Spark NLP’s LightPipeline LightPipeline is a Spark NLP specific Pipeline class equivalent to Spark ML Pipeline. The difference is that it’s execution does not hold to Spark principles, instead it computes everything locally (but in parallel) in order to achieve fast results when dealing with small amounts of data. This means, we do not input a Spark Dataframe, but a string or an Array of strings instead, to be annotated. To create Light Pipelines, you need to input an already trained (fit) Spark ML Pipeline. It’s transform() stage is converted into annotate() instead. PythonScala from sparknlp.base import LightPipeline explain_document_pipeline = PretrainedPipeline(&quot;explain_document_ml&quot;) lightPipeline = LightPipeline(explain_document_pipeline.model) OUTPUT: explain_document_ml download started this may take some time. Approx size to download 9.4 MB [OK!] lightPipeline.annotate(&quot;Hello world, please annotate my text&quot;) OUTPUT: {&#39;stem&#39;: [&#39;hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;pleas&#39;, &#39;annot&#39;, &#39;my&#39;, &#39;text&#39;], &#39;checked&#39;: [&#39;Hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;please&#39;, &#39;annotate&#39;, &#39;my&#39;, &#39;text&#39;], &#39;lemma&#39;: [&#39;Hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;please&#39;, &#39;annotate&#39;, &#39;i&#39;, &#39;text&#39;], &#39;document&#39;: [&#39;Hello world, please annotate my text&#39;], &#39;pos&#39;: [&#39;UH&#39;, &#39;NN&#39;, &#39;,&#39;, &#39;VB&#39;, &#39;NN&#39;, &#39;PRP$&#39;, &#39;NN&#39;], &#39;token&#39;: [&#39;Hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;please&#39;, &#39;annotate&#39;, &#39;my&#39;, &#39;text&#39;], &#39;sentence&#39;: [&#39;Hello world, please annotate my text&#39;]} import com.johnsnowlabs.nlp.base._ val explainDocumentPipeline = PretrainedPipeline(&quot;explain_document_ml&quot;) val lightPipeline = new LightPipeline(explainDocumentPipeline.model) lightPipeline.annotate(&quot;Hello world, please annotate my text&quot;) OUTPUT: Map[String,Seq[String]] = Map( stem -&gt; List(hello, world, ,, pleas, annot, my, text), checked -&gt; List(Hello, world, ,, please, annotate, my, tex), lemma -&gt; List(Hello, world, ,, please, annotate, i, text), document -&gt; List(Hello world, please annotate my text), pos -&gt; ArrayBuffer(UH, NN, ,, VB, NN, PRP$, NN), token -&gt; List(Hello, world, ,, please, annotate, my, text), sentence -&gt; List(Hello world, please annotate my text) ) Training annotators Training methodology Training your own annotators is a key concept when dealing with real life scenarios. Any of the annotators provided above, such as pretrained pipelines and models, can be applied out-of-the-box to a specific use case, but better results are obtained when they are fine-tuned to your specific use-case. Dealing with real life problems ofter requires training your own models. In Spark NLP, we support three ways of training a custom annotator: Train from a dataset. Most annotators are capable of training from a dataset passed to fit() method just as Spark ML does. Annotators that use the suffix Approach are such trainable annotators. Training from fit() is the standard behavior in Spark ML. Annotators have different schema requirements for training. Check the reference to see what are the requirements of each annotators. Training from an external source: Some of our annotators train from an external file or folder passed to the annotator as a param. You will see such ones as setCorpus() or setDictionary() param setter methods, allowing you to configure the input to use. You can set Spark NLP to read them as Spark datasets or LINE_BY_LINE which is usually faster for small files. Last but not least, some of our annotators are Deep Learning based. These models may be trained with the standard AnnotatorApproach API just like any other annotator. For more advanced users, we also allow importing your own graphs or even training from Python and converting them into an AnnotatorModel. Spark NLP Imports base includes general Spark NLP transformers and concepts, annotator includes all annotators that we currently provide, embeddings includes word embedding annotators. Example: PythonScala from sparknlp.base import * from sparknlp.annotator import * from sparknlp.embeddings import * import com.johnsnowlabs.nlp.base._ import com.johnsnowlabs.nlp.annotator._ Spark ML Pipelines SparkML Pipelines are a uniform structure that helps creating and tuning practical machine learning pipelines. Spark NLP integrates with them seamlessly so it is important to have this concept handy. Once a Pipeline is trained with fit(), it becomes a PipelineModel Example: PythonScala from pyspark.ml import Pipeline pipeline = Pipeline().setStages([...]) import org.apache.spark.ml.Pipeline new Pipeline().setStages(Array(...)) LightPipeline LightPipelines are Spark ML pipelines converted into a single machine but multithreaded task, becoming more than 10x times faster for smaller amounts of data (small is relative, but 50k sentences is roughly a good maximum). To use them, simply plug in a trained (fitted) pipeline. Example: PythonScala from sparknlp.base import LightPipeline LightPipeline(someTrainedPipeline).annotate(someStringOrArray) import com.johnsnowlabs.nlp.LightPipeline new LightPipeline(somePipelineModel).annotate(someStringOrArray)) Functions: annotate(string or string[]): returns dictionary list of annotation results fullAnnotate(string or string[]): returns dictionary list of entire annotations content For more details please refer to Using Spark NLP’s LightPipelines. RecursivePipeline Recursive pipelines are SparkNLP specific pipelines that allow a Spark ML Pipeline to know about itself on every Pipeline Stage task, allowing annotators to utilize this same pipeline against external resources to process them in the same way the user decides. Only some of our annotators take advantage of this. RecursivePipeline behaves exactly the same as normal Spark ML pipelines, so they can be used with the same intention. Example: PythonScala from sparknlp.annotator import * recursivePipeline = RecursivePipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, lemmatizer, finisher ]) import com.johnsnowlabs.nlp.RecursivePipeline val recursivePipeline = new RecursivePipeline() .setStages(Array( documentAssembler, sentenceDetector, tokenizer, lemmatizer, finisher )) Params and Features Annotator parameters SparkML uses ML Params to store pipeline parameter maps. In SparkNLP, we also use Features, which are a way to store parameter maps that are larger than just a string or a boolean. These features are serialized as either Parquet or RDD objects, allowing much faster and scalable annotator information. Features are also broadcasted among executors for better performance.",
    "url": "/docs/en/concepts",
    "relUrl": "/docs/en/concepts"
  },
  "887": {
    "id": "887",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/conll.html",
    "relUrl": "/api/python/modules/sparknlp/training/conll.html"
  },
  "888": {
    "id": "888",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/conllu.html",
    "relUrl": "/api/python/modules/sparknlp/training/conllu.html"
  },
  "889": {
    "id": "889",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/spell_check/context_spell_checker.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/spell_check/context_spell_checker.html"
  },
  "890": {
    "id": "890",
    "title": "Contribute",
    "content": "Refer to our GitHub page to take a look at the GH Issues, as the project is yet small. You can create in there your own issues to either work on them yourself or simply propose them. Feel free to clone the repository locally and submit pull requests so we can review them and work together. feedback, ideas and bug reports testing and development training and testing nlp corpora documentation and research Help is always welcome, for any further questions, contact nlp@johnsnowlabs.com. Your own annotator model Creating your first annotator transformer should not be hard, here are a few guidelines to get you started. Lets assume we want a wrapper annotator, which puts a character surrounding tokens provided by a Tokenizer WordWrapper uid is utilized for transformer serialization, AnnotatorModel[MyAnnotator] will contain the common annotator logic We need to use standard constructor for java and python compatibility class WordWrapper(override val uid: String) extends AnnotatorModel[WordWrapper] { def this() = this(Identifiable.randomUID(&quot;WORD_WRAPPER&quot;)) } Annotator attributes This annotator is not flexible if we don’t provide parameters import com.johnsnowlabs.nlp.AnnotatorType._ override val annotatorType: AnnotatorType = TOKEN override val requiredAnnotatorTypes: Array[AnnotatorType] = Array[AnnotatorType](TOKEN) Annotator parameters This annotator is not flexible if we don’t provide parameters protected val character: Param[String] = new Param(this, &quot;character&quot;, &quot;this is the character used to wrap a token&quot;) def setCharacter(value: String): this.type = set(pattern, value) def getCharacter: String = $(pattern) setDefault(character, &quot;@&quot;) Annotator logic Here is how we act, annotations will automatically provide our required annotations We generally use annotatorType for metadata keys override def annotate(annotations: Seq[Annotation]): Seq[Annotation] = { annotations.map(annotation =&gt; { Annotation( annotatorType, annotation.begin, annotation.end, Map(annotatorType -&gt; $(character) + annotation.result + $(character)) }) }",
    "url": "/contribute",
    "relUrl": "/contribute"
  },
  "891": {
    "id": "891",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/custom_pipelines.html",
    "relUrl": "/api/python/user_guide/custom_pipelines.html"
  },
  "892": {
    "id": "892",
    "title": "Databricks Solution Accelerators",
    "content": "",
    "url": "/databricks_solution_accelerators",
    "relUrl": "/databricks_solution_accelerators"
  },
  "893": {
    "id": "893",
    "title": "Utilities for Databricks",
    "content": "Endpoint Creation You can Query&amp;Deploy John Snow Labs models with 1 line of code as Databricks Model Serve Endpoints. Data is passed to the predict() function and predictions are shaped accordingly. You must create endpoints from a Databricks cluster created by nlp.install. See Cluster Creation Notebook and Databricks Endpoint Tutorial Notebook # You need `mlflow_by_johnsnowlabs` installed until next mlflow is released ! pip install mlflow_by_johnsnowlabs from johnsnowlabs import nlp nlp.query_and_deploy_if_missing(&#39;bert&#39;,&#39;My String to embed&#39;) nlp.query_and_deploy_if_missing has the following parameters related to deploying your model: Parameter Description model Model to be deployed as endpoint which is converted into NluPipelines, supported classes are: String Reference to NLU Pipeline name like ‘bert’, NLUPipeline, List[Annotator], Pipeline, LightPipeline, PretrainedPipeline, PipelineModel, query str or list of strings or raw json string. If raw json, is_json_query must be True is_json_query if True, query is treated as raw json string base_name Name-Prefix for all resources created (Endpoints, Models, etc). If using non nlu referenced based models, you must specify this. re_create_endpoint if False, endpoint creation is skipped if one already exists. If True, it will delete existing endpoint if it exists re_create_model if False, model creation is skipped if one already exists. If True, model will be re-logged again, bumping the current version by 2 workload_size one of Small, Medium, Large. gpu True/False to load GPU-optimized jars or CPU-optimized jars in the container new_run if True, mlflow will start a new run before logging the model db_host the databricks host URL. If not specified, the DATABRICKS_HOST environment variable is used db_token the databricks Access Token. If not specified, the DATABRICKS_TOKEN environment variable is used block_until_deployed if True, this function will block until the endpoint is created nlp.query_and_deploy_if_missing has the following parameters related to querying your model, which are forwarded to the model.predict() call: Parameter Description output_level One of token, chunk, sentence, relation, document to shape outputs positions Set True/False to include or exclude character index position of predictions metadata Set True/False to include additional metadata drop_irrelevant_cols Set True/False to drop irrelevant columns get_embeddings Set True/False to include embedding or not keep_stranger_features Set True/False to return columns not named “text”, ‘image” or “file_type” from your input data multithread Set True/False to use multi-Threading for inference. Auto-inferred if not set nlp.query_and_deploy_if_missing checks the following Env vars Env Var Name Description HEALTHCARE_SECRET Automatically set on your cluster if you run nlp.install() VISUAL_SECRET Automatically set if you run. nlp.install(..., visual=True). You can only spawn visual endpoint from a cluster created by nlp.install(..., visual=True) JOHNSNOWLABS_LICENSE_JSON JSON content of your john snow labs licensed to use for endpoints. Should be airgap license Submit a Task with nlp.run_in_databricks Easily run Python code in a Databricks cluster, using the John Snow Labs library. The fastest way to test this out, is to create a cluster with nlp.install() and then use nlp.run_in_databricks to start a task. # Execute a Raw Python string as script on Databricks from johnsnowlabs import * script = &quot;&quot;&quot; import nlu print(nlu.load(&#39;sentiment&#39;).predict(&#39;That was easy!&#39;))&quot;&quot;&quot; cluster_id = nlp.install(json_license_path=my_license, databricks_host=my_host,databricks_token=my_token) nlp.run_in_databricks(script, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;Python Code String Example&#39;) This will start a Job Run which you can view in the Workflows tab And after a while you can see the results Run a Python Function in Databricks Define a function, which will be written to a local file, copied to HDFS and executed by the Databricks cluster. def my_function(): import nlu medical_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .&quot;&quot;&quot; df = nlu.load(&#39;en.med_ner.diseases&#39;).predict(medical_text) for c in df.columns: print(df[c]) # my_function will run on databricks nlp.run_in_databricks(my_function, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;Function test&#39;) This example will print all columns of the resulting dataframe which contains emdical NER predictions. Run a Raw Python Code String in Databricks Provide a string which must be valid Python Syntax. It will be written to string, copied to HDFS and executed by the Databricks Cluster. script = &quot;&quot;&quot; import nlu print(nlu.load(&#39;sentiment&#39;).predict(&#39;That was easy!&#39;))&quot;&quot;&quot; nlp.run_in_databricks(script, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;Python Code String Example&#39;) Run a Python Script in Databricks Provide the path to a script on your machine. It will be copied to the Databricks HDFS and executed as task. nlp.run_in_databricks(&#39;path/to/my/script.py&#39;, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;Script test &#39;) Run a Python Module in Databricks Provide a module accessible to the john snow labs library. It’s content’s will be written to a local file, copied to HDFS and executed by the databricks cluster. import johnsnowlabs.auto_install.health_checks.nlp_test as nlp_test nlp.run_in_databricks(nlp_test, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;nlp_test&#39;)",
    "url": "/docs/en/jsl/databricks-utils",
    "relUrl": "/docs/en/jsl/databricks-utils"
  },
  "894": {
    "id": "894",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/date2_chunk.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/date2_chunk.html"
  },
  "895": {
    "id": "895",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/date_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/date_matcher.html"
  },
  "896": {
    "id": "896",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/deberta_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/deberta_embeddings.html"
  },
  "897": {
    "id": "897",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_question_answering.html"
  },
  "898": {
    "id": "898",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification.html"
  },
  "899": {
    "id": "899",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_token_classification.html"
  },
  "900": {
    "id": "900",
    "title": "De-Identification - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/deidentification",
    "relUrl": "/deidentification"
  },
  "901": {
    "id": "901",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/demos",
    "relUrl": "/demos"
  },
  "902": {
    "id": "902",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/dependency/dependency_parser.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/dependency/dependency_parser.html"
  },
  "903": {
    "id": "903",
    "title": "Detect Sentiment & Emotion - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/detect_sentiment_emotion",
    "relUrl": "/detect_sentiment_emotion"
  },
  "904": {
    "id": "904",
    "title": "Developers Guideline",
    "content": "",
    "url": "/docs/en/developers",
    "relUrl": "/docs/en/developers"
  },
  "905": {
    "id": "905",
    "title": "Diagnoses & Procedures - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/diagnoses_procedures",
    "relUrl": "/diagnoses_procedures"
  },
  "906": {
    "id": "906",
    "title": "Spark NLP Display",
    "content": "Getting started Spark NLP Display is an open-source python library for visualizing the annotations generated with Spark NLP. It currently offers out-of-the-box suport for the following types of annotations: Dependency Parser Named Entity Recognition Entity Resolution Relation Extraction Assertion Status The ability to quickly visualize the entities/relations/assertion statuses, etc. generated using Spark NLP is a very useful feature for speeding up the development process as well as for understanding the obtained results. Getting all of this in a one liner is extremelly convenient especially when running Jupyter notebooks which offers full support for html visualizations. The visualisation classes work with the outputs returned by both Pipeline.transform() function and LightPipeline.fullAnnotate(). Install Spark NLP Display You can install the Spark NLP Display library via pip by using: pip install spark-nlp-display A complete guideline on how to use the Spark NLP Display library is available here. Visualize a dependency tree For visualizing a dependency trees generated with DependencyParserApproach you can use the following code. from sparknlp_display import DependencyParserVisualizer dependency_vis = DependencyParserVisualizer() dependency_vis.display(pipeline_result[0], #should be the results of a single example, not the complete dataframe. pos_col = &#39;pos&#39;, #specify the pos column dependency_col = &#39;dependency&#39;, #specify the dependency column dependency_type_col = &#39;dependency_type&#39; #specify the dependency type column ) The following image gives an example of html output that is obtained for a test sentence: Visualize extracted named entities The NerVisualizer highlights the named entities that are identified by Spark NLP and also displays their labels as decorations on top of the analyzed text. The colors assigned to the predicted labels can be configured to fit the particular needs of the application. from sparknlp_display import NerVisualizer ner_vis = NerVisualizer() ner_vis.display(pipeline_result[0], #should be the results of a single example, not the complete dataframe label_col=&#39;entities&#39;, #specify the entity column document_col=&#39;document&#39; #specify the document column (default: &#39;document&#39;) labels=[&#39;PER&#39;] #only allow these labels to be displayed. (default: [] - all labels will be displayed) ) ## To set custom label colors: ner_vis.set_label_colors({&#39;LOC&#39;:&#39;#800080&#39;, &#39;PER&#39;:&#39;#77b5fe&#39;}) #set label colors by specifying hex codes The following image gives an example of html output that is obtained for a couple of test sentences: Visualize relations The RelationExtractionVisualizer can be used to visualize the relations predicted by Spark NLP. The two entities involved in a relation will be highlighted and their label will be displayed. Also a directed and labeled arc(line) will be used to connect the two entities. from sparknlp_display import RelationExtractionVisualizer re_vis = RelationExtractionVisualizer() re_vis.display(pipeline_result[0], #should be the results of a single example, not the complete dataframe relation_col = &#39;relations&#39;, #specify relations column document_col = &#39;document&#39;, #specify document column show_relations=True #display relation names on arrows (default: True) ) The following image gives an example of html output that is obtained for a couple of test sentences: Visualize assertion status The AssertionVisualizer is a special type of NerVisualizer that also displays on top of the labeled entities the assertion status that was infered by a Spark NLP model. from sparknlp_display import AssertionVisualizer assertion_vis = AssertionVisualizer() assertion_vis.display(pipeline_result[0], label_col = &#39;entities&#39;, #specify the ner result column assertion_col = &#39;assertion&#39; #specify assertion column document_col = &#39;document&#39; #specify the document column (default: &#39;document&#39;) ) ## To set custom label colors: assertion_vis.set_label_colors({&#39;TREATMENT&#39;:&#39;#008080&#39;, &#39;problem&#39;:&#39;#800080&#39;}) #set label colors by specifying hex codes The following image gives an example of html output that is obtained for a couple of test sentences: Visualize entity resolution Entity resolution refers to the normalization of named entities predicted by Spark NLP with respect to standard terminologies such as ICD-10, SNOMED, RxNorm etc. You can read more about the available entity resolvers here. The EntityResolverVisualizer will automatically display on top of the NER label the standard code (ICD10 CM, PCS, ICDO; CPT) that corresponds to that entity as well as the short description of the code. If no resolution code could be identified a regular NER-type of visualization will be displayed. from sparknlp_display import EntityResolverVisualizer er_vis = EntityResolverVisualizer() er_vis.display(pipeline_result[0], #should be the results of a single example, not the complete dataframe label_col=&#39;entities&#39;, #specify the ner result column resolution_col = &#39;resolution&#39; document_col=&#39;document&#39; #specify the document column (default: &#39;document&#39;) ) ## To set custom label colors: er_vis.set_label_colors({&#39;TREATMENT&#39;:&#39;#800080&#39;, &#39;PROBLEM&#39;:&#39;#77b5fe&#39;}) #set label colors by specifying hex codes The following image gives an example of html output that is obtained for a couple of test sentences:",
    "url": "/docs/en/display",
    "relUrl": "/docs/en/display"
  },
  "907": {
    "id": "907",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/distil_bert_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/distil_bert_embeddings.html"
  },
  "908": {
    "id": "908",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering.html"
  },
  "909": {
    "id": "909",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification.html"
  },
  "910": {
    "id": "910",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification.html"
  },
  "911": {
    "id": "911",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/doc2_chunk.html",
    "relUrl": "/api/python/modules/sparknlp/base/doc2_chunk.html"
  },
  "912": {
    "id": "912",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/doc2vec.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/doc2vec.html"
  },
  "913": {
    "id": "913",
    "title": "John Snow Labs - NLP Documentation",
    "content": "",
    "url": "/docs",
    "relUrl": "/docs"
  },
  "914": {
    "id": "914",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/document_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/document_assembler.html"
  },
  "915": {
    "id": "915",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/document_normalizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/document_normalizer.html"
  },
  "916": {
    "id": "916",
    "title": "Drugs & Adverse Events - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/drug_adverse_events",
    "relUrl": "/drug_adverse_events"
  },
  "917": {
    "id": "917",
    "title": "East Asian Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/east_asian_languages",
    "relUrl": "/east_asian_languages"
  },
  "918": {
    "id": "918",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/elmo_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/elmo_embeddings.html"
  },
  "919": {
    "id": "919",
    "title": "Embeddings",
    "content": "All the embeddings available in the Annotation Lab are listed on this page. General information about the embeddings like the name, version, source, and date of upload/download is available. Like models, any compatible embeddings can be downloaded from NLP Models Hub. By default, glove_100d, bert_base_cased, tfhub_use embeddings are included in every fresh installation of Annotation Lab. Custom Embeddings Upload Custom embeddings can be uploaded using the Upload button present in the top right corner of the page. Note: The embeddings to upload need to be Spark NLP compatible.",
    "url": "/docs/en/alab/embeddings",
    "relUrl": "/docs/en/alab/embeddings"
  },
  "920": {
    "id": "920",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/embeddings_finisher.html",
    "relUrl": "/api/python/modules/sparknlp/base/embeddings_finisher.html"
  },
  "921": {
    "id": "921",
    "title": "Enhance Low-Quality Images - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/enhance_low_quality_images",
    "relUrl": "/enhance_low_quality_images"
  },
  "922": {
    "id": "922",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/er/entity_ruler.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/er/entity_ruler.html"
  },
  "923": {
    "id": "923",
    "title": "European Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/european_languages",
    "relUrl": "/european_languages"
  },
  "924": {
    "id": "924",
    "title": "Evaluation",
    "content": "Spark NLP Evaluation This module includes tools to evaluate the accuracy of annotators and visualize the parameters used on training. It includes specific metrics for each annotator and its training time. The results will display on the console or to an MLflow tracking UI. Just with a simple import you can start using eval module. Check how to setup MLflow UI See here on eval folder if you want to check specific running examples. Example: PythonScala from sparknlp_jsl.eval import * import com.johnsnowlabs.nlp.eval._ Evaluating Norvig Spell Checker You can evaluate this spell checker either by training an annotator or by using a pretrained model. spark: Spark session. trainFile: A corpus of documents with correctly spell words. testFile: A corpus of documents with misspells words. groundTruthFile: The same corpus used on testFile but with correctly spell words. Train File Example: Any document that you prefer with correctly spell words. Test File Example: My siter go to Munich. Ground Truth File Example: My sister goes to Munich. Example for annotator: PythonScala spell = NorvigSweetingApproach() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;checked&quot;) .setDictionary(dictionary_file) norvigSpellEvaluation = NorvigSpellEvaluation(spark, test_file, ground_truth_file) norvigSpellEvaluation.computeAccuracyAnnotator(train_file, spell) val spell = new NorvigSweetingApproach() .setInputCols(Array(&quot;token&quot;)) .setOutputCol(&quot;checked&quot;) .setDictionary(dictionary_file) val norvigSpellEvaluation = new NorvigSpellEvaluation(spark, testFile, groundTruthFile) norvigSpellEvaluation.computeAccuracyAnnotator(trainFile, spell) Example for pretrained model: PythonScala spell = NorvigSweetingModel.pretrained() norvigSpellEvaluation = NorvigSpellEvaluation(spark, test_file, ground_truth_file) norvigSpellEvaluation.computeAccuracyModel(spell) val spell = NorvigSweetingModel.pretrained() val norvigSpellEvaluation = new NorvigSpellEvaluation(spark, testFile, groundTruthFile) norvigSpellEvaluation.computeAccuracyModel(spell) Evaluating Symmetric Spell Checker You can evaluate this spell checker either by training an annotator or by using a pretrained model. spark: Spark session trainFile: A corpus of documents with correctly spell words. testFile: A corpus of documents with misspells words. groundTruthFile: The same corpus used on testFile but with correctly spell words. Train File Example: Any document that you prefer with correctly spell words. Test File Example: My siter go to Munich. Ground Truth File Example: My sister goes to Munich. Example for annotator: PythonScala spell = SymmetricDeleteApproach() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;checked&quot;) .setDictionary(dictionary_file) symSpellEvaluation = SymSpellEvaluation(spark, test_file, ground_truth_file) symSpellEvaluation.computeAccuracyAnnotator(train_file, spell) val spell = new SymmetricDeleteApproach() .setInputCols(Array(&quot;token&quot;)) .setOutputCol(&quot;checked&quot;) val symSpellEvaluation = new SymSpellEvaluation(spark, testFile, groundTruthFile) symSpellEvaluation.computeAccuracyAnnotator(trainFile, spell) Example for pretrained model: PythonScala spell = SymmetricDeleteModel.pretrained() symSpellEvaluation = NorvigSpellEvaluation(spark, test_file, ground_truth_file) symSpellEvaluation.computeAccuracyModel(spell) val spell = SymmetricDeleteModel.pretrained() val symSpellEvaluation = new SymSpellEvaluation(spark, testFile, groundTruthFile) symSpellEvaluation.computeAccuracyModel(spell) Evaluating NER DL You can evaluate NER DL when training an annotator. spark: Spark session. trainFile: Files with labeled NER entities for training. testFile: Files with labeled NER entities for testing. These files are used to evaluate the model. So, it’s used for prediction and the labels as ground truth. tagLevel: The granularity of tagging when measuring accuracy on entities. Set “IOB” to include inside and beginning, empty to ignore it. For example to display accuracy for entity I-PER and B-PER set “IOB” whereas just for entity PER set it as an empty string. Example: PythonScala embeddings = WordEmbeddings() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setEmbeddingsSource(&quot;glove.6B.100d.txt&quot;, 100, &quot;TEXT&quot;) ner_approach = NerDLApproach() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(10) .setRandomSeed(0) nerDLEvaluation = NerDLEvaluation(spark, test_File, tag_level) nerDLEvaluation.computeAccuracyAnnotator(train_file, ner_approach, embeddings) val embeddings = new WordEmbeddings() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setEmbeddingsSource(&quot;glove.6B.100d.txt&quot;, 100, WordEmbeddingsFormat.TEXT) val nerApproach = new NerDLApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(10) .setRandomSeed(0) val nerDLEvaluation = new NerDLEvaluation(spark, testFile, tagLevel) nerDLEvaluation.computeAccuracyAnnotator(trainFile, nerApproach, embeddings) Example for pretrained model: PythonScala ner_dl = NerDLModel.pretrained() nerDlEvaluation = NerDLEvaluation(spark, test_File, tag_level) nerDlEvaluation.computeAccuracyModel(ner_dl) val nerDl = NerDLModel.pretrained() val nerDlEvaluation = NerDLEvaluation(spark, testFile, tagLevel) nerDlEvaluation.computeAccuracyModel(nerDl) Evaluating NER CRF You can evaluate NER CRF when training an annotator. spark: Spark session. trainFile: Files with labeled NER entities for training. testFile: Files with labeled NER entities for testing. These files are used to evaluate the model. So, it’s used for prediction and the labels as ground truth. format: The granularity of tagging when measuring accuracy on entities. Set “IOB” to include inside and beginning, empty to ignore it. For example to display accuracy for entity I-PER and B-PER set “IOB” whereas just for entity PER set it as an empty string. Example: PythonScala embeddings = WordEmbeddings() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setEmbeddingsSource(&quot;glove.6B.100d.txt&quot;, 100, &quot;TEXT&quot;) ner_approach = NerCrfApproach() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;pos&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(10) .setRandomSeed(0) nerCrfEvaluation = NerCrfEvaluation(spark, test_File, tag_level) nerCrfEvaluation.computeAccuracyAnnotator(train_file, ner_approach, embeddings) val embeddings = new WordEmbeddings() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setEmbeddingsSource(&quot;./glove.6B.100d.txt &quot;, 100, WordEmbeddingsFormat.TEXT) .setCaseSensitive(true) val nerTagger = new NerCrfApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;pos&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(10) val nerCrfEvaluation = new NerCrfEvaluation(testFile, format) nerCrfEvaluation.computeAccuracyAnnotator(trainFile, nerTagger, embeddings) Example for pretrained model: PythonScala ner_crf = NerCrfModel.pretrained() nerCrfEvaluation = NerCrfEvaluation(spark, test_File, tag_level) nerCrfEvaluation.computeAccuracyModel(ner_crf) nerCrf = NerCrfModel.pretrained() nerCrfEvaluation = NerCrfEvaluation(spark, testFile, tagLevel) nerCrfEvaluation.computeAccuracyModel(nerCrf) Evaluating POS Tagger You can evaluate POS either by training an annotator or by using a pretrained model. spark: Spark session. trainFile: A labeled POS file see and example here. testFile: A CoNLL-U format file. Example for annotator: PythonScala pos_tagger = PerceptronApproach() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) .setNIterations(2) posEvaluation = POSEvaluation(spark, test_file) posEvaluation.computeAccuracyAnnotator(train_file, pos_tagger) val posTagger = new PerceptronApproach() .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;pos&quot;) .setNIterations(2) val posEvaluation = new POSEvaluation(spark, testFile) posEvaluation.computeAccuracyAnnotator(trainFile, posTagger)",
    "url": "/docs/en/evaluation",
    "relUrl": "/docs/en/evaluation"
  },
  "925": {
    "id": "925",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/param/evaluation_dl_params.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/param/evaluation_dl_params.html"
  },
  "926": {
    "id": "926",
    "title": "1-liners reference",
    "content": "Usage examples of nlp.load() The following examples demonstrate how to use nlu’s load api accompanied by the outputs generated by it. It enables loading any model or pipeline in one line You need to pass one NLU reference to the load method. You can also pass multiple whitespace separated references. You can find all NLU references here Named Entity Recognition (NER) 18 class NER ONTO example Predicts the following 18 NER classes from the ONTO dataset : Type Description PERSON People, including fictional like Harry Potter NORP Nationalities or religious or political groups like the Germans FAC Buildings, airports, highways, bridges, etc. like New York Airport ORG Companies, agencies, institutions, etc. like Microsoft GPE Countries, cities, states. like Germany LOC Non-GPE locations, mountain ranges, bodies of water. Like the Sahara desert PRODUCT Objects, vehicles, foods, etc. (Not services.) like playstation EVENT Named hurricanes, battles, wars, sports events, etc. like hurricane Katrina WORK_OF_ART Titles of books, songs, etc. Like Mona Lisa LAW Named documents made into laws. Like : Declaration of Independence LANGUAGE Any named language. Like Turkish DATE Absolute or relative dates or periods. Like every second friday TIME Times smaller than a day. Like every minute PERCENT Percentage, including ”%“. Like 55% of workers enjoy their work MONEY Monetary values, including unit. Like 50$ for those pants QUANTITY Measurements, as of weight or distance. Like this person weights 50kg ORDINAL “first”, “second”, etc. Like David placed first in the tournament CARDINAL Numerals that do not fall under another type. Like hundreds of models are avaiable in NLU nlp.load(&#39;ner&#39;).predict(&#39;Angela Merkel from Germany and the American Donald Trump dont share many opinions&#39;) embeddings ner_tag entities [[-0.563759982585907, 0.26958999037742615, 0.3… PER Angela Merkel [[-0.563759982585907, 0.26958999037742615, 0.3… GPE Germany [[-0.563759982585907, 0.26958999037742615, 0.3… NORP American [[-0.563759982585907, 0.26958999037742615, 0.3… PER Donald Trump Named Entity Recognition (NER) 5 Class NER CONLL example Predicts the following NER classes from the CONLL dataset : Tag Description B-PER A person like Jim or Joe B-ORG An organisation like Microsoft or PETA B-LOC A location like Germany B-MISC Anything else like Playstation O Everything that is not an entity. nlp.load(&#39;ner.conll&#39;).predict(&#39;Angela Merkel from Germany and the American Donald Trump dont share many opinions&#39;) embeddings ner_tag entities [[-0.563759982585907, 0.26958999037742615, 0.3… PER Angela Merkel [[-0.563759982585907, 0.26958999037742615, 0.3… LOC Germany [[-0.563759982585907, 0.26958999037742615, 0.3… MISC American [[-0.563759982585907, 0.26958999037742615, 0.3… PER Donald Trump Part of speech (POS) POS Classifies each token with one of the following tags Part of Speech example Tag Description Example CC Coordinating conjunction This batch of mushroom stew is savory and delicious CD Cardinal number Here are five coins DT Determiner The bunny went home EX Existential there There is a storm coming FW Foreign word I’m having a déjà vu IN Preposition or subordinating conjunction He is cleverer than I am JJ Adjective She wore a beautiful dress JJR Adjective, comparative My house is bigger than yours JJS Adjective, superlative I am the shortest person in my family LS List item marker A number of things need to be considered before starting a business , such as premises , finance , product demand , staffing and access to customers MD Modal You must stop when the traffic lights turn red NN Noun, singular or mass The dog likes to run NNS Noun, plural The cars are fast NNP Proper noun, singular I ordered the chair from Amazon NNPS Proper noun, plural We visted the Kennedys PDT Predeterminer Both the children had a toy POS Possessive ending I built the dog’s house PRP Personal pronoun You need to stop PRP$ Possessive pronoun Remember not to judge a book by its cover RB Adverb The dog barks loudly RBR Adverb, comparative Could you sing more quietly please? RBS Adverb, superlative Everyone in the race ran fast, but John ran the fastest of all RP Particle He ate up all his dinner SYM Symbol What are you doing ? TO to Please send it back to me UH Interjection Wow! You look gorgeous VB Verb, base form We play soccer VBD Verb, past tense I worked at a restaurant VBG Verb, gerund or present participle Smoking kills people VBN Verb, past participle She has done her homework VBP Verb, non-3rd person singular present You flit from place to place VBZ Verb, 3rd person singular present He never calls me WDT Wh-determiner The store honored the complaints, which were less than 25 days old WP Wh-pronoun Who can help me? WP$ Possessive wh-pronoun Whose fault is it? WRB Wh-adverb Where are you going? nlp.load(&#39;pos&#39;).predict(&#39;Part of speech assigns each token in a sentence a grammatical label&#39;) token pos Part NN of IN speech NN assigns NNS each DT token NN in IN a DT sentence NN a DT grammatical JJ label NN Emotion Classifier Emotion Classifier example Classifies text as one of 4 categories (joy, fear, surprise, sadness) nlp.load(&#39;emotion&#39;).predict(&#39;I love NLU!&#39;) sentence_embeddings emotion_confidence sentence emotion [0.027570432052016258, -0.052647676318883896, …] 0.976017 I love NLU! joy Sentiment Classifier Sentiment Classifier Example Classifies binary sentiment for every sentence, either positive or negative. nlp.load(&#39;sentiment&#39;).predict(&quot;I hate this guy Sami&quot;) sentiment_confidence sentence sentiment checked 0.5778 I hate this guy Sami negative [I, hate, this, guy, Sami] Question Classifier 50 class 50 Class Questions Classifier example Classifies between 50 different types of questions trained on the Trec50 dataset When setting predict(meta=True) nlu will output the probabilities for all other 49 question classes. The classes are the following : Abbreviation question classes: Class Definition abb abbreviation exp expression abbreviated Entities question classes: Class Definition animal animals body organs of body color colors creative inventions, books and other creative pieces currency currency names dis .med. diseases and medicine event events food food instrument musical instrument lang languages letter letters like a-z other other entities plant plants product products religion religions sport sports substance elements and substances symbol symbols and signs technique techniques and methods term equivalent terms vehicle vehicles word words with a special property Description and abstract concepts question classes: Class Definition definition definition of sth. description description of sth. manner manner of an action reason reasons Human being question classes: Class Definition group a group or organization of persons ind an individual title title of a person description description of a person Location question classes: Class Definition city cities country countries mountain mountains other other locations state states Numeric question classes: Class Definition code postcodes or other codes count number of sth. date dates distance linear measures money prices order ranks other other numbers period the lasting time of sth. percent fractions speed speed temp temperature size size, area and volume weight weight nlp.load(&#39;en.classify.trec50&#39;).predict(&#39;How expensive is the Watch?&#39;) sentence_embeddings question_confidence sentence question [0.051809534430503845, 0.03128402680158615, -0…] 0.919436 How expensive is the watch? NUM_count Fake News Classifier Fake News Classifier example nlp.load(&#39;en.classify.fakenews&#39;).predict(&#39;Unicorns have been sighted on Mars!&#39;) sentence_embeddings fake_confidence sentence fake [-0.01756167598068714, 0.015006818808615208, -…] 1.000000 Unicorns have been sighted on Mars! FAKE Cyberbullying Classifier Cyberbullying Classifier example Classifies sexism and racism nlp.load(&#39;en.classify.cyberbullying&#39;).predict(&#39;Women belong in the kitchen.&#39;) # sorry we really don&#39;t mean it sentence_embeddings cyberbullying_confidence sentence cyberbullying [-0.054944973438978195, -0.022223370149731636,…] 0.999998 Women belong in the kitchen. sexism Spam Classifier Spam Classifier example nlp.load(&#39;en.classify.spam&#39;).predict(&#39;Please sign up for this FREE membership it costs $$NO MONEY$$ just your mobile number!&#39;) sentence_embeddings spam_confidence sentence spam [0.008322705514729023, 0.009957313537597656, 0…] 1.000000 Please sign up for this FREE membership it cos… spam Sarcasm Classifier Sarcasm Classifier example nlp.load(&#39;en.classify.sarcasm&#39;).predict(&#39;gotta love the teachers who give exams on the day after halloween&#39;) sentence_embeddings sarcasm_confidence sentence sarcasm [-0.03146284446120262, 0.04071342945098877, 0….] 0.999985 gotta love the teachers who give exams on the… sarcasm IMDB Movie Sentiment Classifier Movie Review Sentiment Classifier example nlp.load(&#39;en.sentiment.imdb&#39;).predict(&#39;The Matrix was a pretty good movie&#39;) document sentence_embeddings sentiment_negative sentiment_negative sentiment_positive sentiment The Matrix was a pretty good movie [[0.04629608988761902, -0.020867452025413513, … ] [2.7235753918830596e-07] [2.7235753918830596e-07] [0.9999997615814209] [positive] Twitter Sentiment Classifier Twitter Sentiment Classifier Example nlp.load(&#39;en.sentiment.twitter&#39;).predict(&#39;@elonmusk Tesla stock price is too high imo&#39;) document sentence_embeddings sentiment_negative sentiment_negative sentiment_positive sentiment @elonmusk Tesla stock price is too high imo [[0.08604438602924347, 0.04703635722398758, -0…] [1.0] [1.0] [1.692714735043349e-36] [negative] Language Classifier Languages Classifier example Classifies the following 20 languages : Bulgarian, Czech, German, Greek, English, Spanish, Finnish, French, Croatian, Hungarian, Italy, Norwegian, Polish, Portuguese, Romanian, Russian, Slovak, Swedish, Turkish, and Ukrainian nlp.load(&#39;lang&#39;).predict([&#39;NLU is an open-source text processing library for advanced natural language processing for the Python.&#39;,&#39;NLU est une bibliothèque de traitement de texte open source pour le traitement avancé du langage naturel pour les langages de programmation Python.&#39;]) language_confidence document language 0.985407 NLU is an open-source text processing library …] en 0.999822 NLU est une bibliothèque de traitement de text…] fr E2E Classifier E2E Classifier example This is a multi class classifier trained on the E2E dataset for Natural language generation nlp.load(&#39;e2e&#39;).predict(&#39;E2E is a dataset for training generative models&#39;) sentence_embeddings e2e e2e_confidence sentence [0.021445205435156822, -0.039284929633140564, …,] customer rating[high] 0.703248 E2E is a dataset for training generative models None name[The Waterman] 0.703248 None None eatType[restaurant] 0.703248 None None priceRange[£20-25] 0.703248 None None familyFriendly[no] 0.703248 None None familyFriendly[yes] 0.703248 None Toxic Classifier Toxic Text Classifier example nlp.load(&#39;en.classify.toxic&#39;).predict(&#39;You are to stupid&#39;) toxic_confidence toxic sentence_embeddings document 0.978273 [toxic,insult] [[-0.03398505970835686, 0.0007853527786210179,…,] You are to stupid YAKE Unsupervised Keyword Extractor YAKE Keyword Extraction Example nlp.load(&#39;yake&#39;).predict(&quot;NLU is a Python Library for beginners and experts in NLP&quot;) keywords_score_confidence keywords sentence 0.454232 [nlu, nlp, python library] NLU is a Python Library for beginners and expe… Word Embeddings Bert BERT Word Embeddings example nlp.load(&#39;bert&#39;).predict(&#39;NLU offers the latest embeddings in one line &#39;) token bert_embeddings NLU [0.3253086805343628, -0.574441134929657, -0.08…] offers [-0.6660361886024475, -0.1494743824005127, -0…] the [-0.6587662696838379, 0.3323703110218048, 0.16…] latest [0.7552685737609863, 0.17207926511764526, 1.35…] embeddings [-0.09838500618934631, -1.1448147296905518, -1…] in [-0.4635896384716034, 0.38369956612586975, 0.0…] one [0.26821616291999817, 0.7025910019874573, 0.15…] line [-0.31930840015411377, -0.48271292448043823, 0…] Word Embeddings Biobert BIOBERT Word Embeddings example Bert model pretrained on Bio dataset nlp.load(&#39;biobert&#39;).predict(&#39;Biobert was pretrained on a medical dataset&#39;) token biobert_embeddings NLU [0.3253086805343628, -0.574441134929657, -0.08…] offers [-0.6660361886024475, -0.1494743824005127, -0…] the [-0.6587662696838379, 0.3323703110218048, 0.16…] latest [0.7552685737609863, 0.17207926511764526, 1.35…] embeddings [-0.09838500618934631, -1.1448147296905518, -1…] in [-0.4635896384716034, 0.38369956612586975, 0.0…] one [0.26821616291999817, 0.7025910019874573, 0.15…] line [-0.31930840015411377, -0.48271292448043823, 0…] Word Embeddings Covidbert COVIDBERT Word Embeddings Bert model pretrained on COVID dataset nlp.load(&#39;covidbert&#39;).predict(&#39;Albert uses a collection of many berts to generate embeddings&#39;) token covid_embeddings He [-1.0551927089691162, -1.534174919128418, 1.29…,] was [-0.14796507358551025, -1.3928604125976562, 0….,] suprised [1.0647121667861938, -0.3664901852607727, 0.54…,] by [-0.15271103382110596, -0.6812090277671814, -0…,] the [-0.45744237303733826, -1.4266574382781982, -0…,] diversity [-0.05339818447828293, -0.5118572115898132, 0….,] of [-0.2971905767917633, -1.0936176776885986, -0….,] NLU [-0.9573594331741333, -0.18001675605773926, -1…,] Word Embeddings Albert ALBERT Word Embeddings examle nlp.load(&#39;albert&#39;).predict(&#39;Albert uses a collection of many berts to generate embeddings&#39;) token albert_embeddings Albert [-0.08257609605789185, -0.8017427325248718, 1…] uses [0.8256351947784424, -1.5144840478897095, 0.90…] a [-0.22089454531669617, -0.24295514822006226, 3…] collection [-0.2136894017457962, -0.8225528597831726, -0…] of [1.7623294591903687, -1.113651156425476, 0.800…] many [0.6415284872055054, -0.04533941298723221, 1.9…] berts [-0.5591965317726135, -1.1773797273635864, -0…] to [1.0956681966781616, -1.4180747270584106, -0.2…] generate [-0.6759272813796997, -1.3546931743621826, 1.6…] embeddings [-0.0035803020000457764, -0.35928264260292053,…] Electra Embeddings ELECTRA Word Embeddings example nlp.load(&#39;electra&#39;).predict(&#39;He was suprised by the diversity of NLU&#39;) token electra_embeddings He [0.29674115777015686, -0.21371933817863464, -0…,] was [-0.4278327524662018, -0.5352768898010254, -0….,] suprised [-0.3090559244155884, 0.8737565279006958, -1.0…,] by [-0.07821277529001236, 0.13081523776054382, 0….,] the [0.5462881922721863, 0.0683358758687973, -0.41…,] diversity [0.1381239891052246, 0.2956242859363556, 0.250…,] of [-0.5667567253112793, -0.3955455720424652, -0….,] NLU [0.5597224831581116, -0.703249454498291, -1.08…,] Word Embeddings Elmo ELMO Word Embeddings example nlp.load(&#39;elmo&#39;).predict(&#39;Elmo was trained on Left to right masked to learn its embeddings&#39;) token elmo_embeddings Elmo [0.6083735227584839, 0.20089012384414673, 0.42…] was [0.2980785369873047, -0.07382500916719437, -0…] trained [-0.39923471212387085, 0.17155063152313232, 0…] on [0.04337821900844574, 0.1392083466053009, -0.4…] Left [0.4468783736228943, -0.623046875, 0.771505534…] to [-0.18209676444530487, 0.03812692314386368, 0…] right [0.23305709660053253, -0.6459438800811768, 0.5…] masked [-0.7243442535400391, 0.10247116535902023, 0.1…] to [-0.18209676444530487, 0.03812692314386368, 0…] learn [1.2942464351654053, 0.7376189231872559, -0.58…] its [0.055951207876205444, 0.19218483567237854, -0…] embeddings [-1.31377112865448, 0.7727609872817993, 0.6748…] Word Embeddings Xlnet XLNET Word Embeddings example nlp.load(&#39;xlnet&#39;).predict(&#39;XLNET computes contextualized word representations using combination of Autoregressive Language Model and Permutation Language Model&#39;) token xlnet_embeddings XLNET [-0.02719488926231861, -1.7693557739257812, -0…] computes [-1.8262947797775269, 0.8455266356468201, 0.57…] contextualized [2.8446314334869385, -0.3564329445362091, -2.1…] word [-0.6143839359283447, -1.7368144989013672, -0…] representations [-0.30445945262908936, -1.2129613161087036, 0…] using [0.07423821836709976, -0.02561005763709545, -0…] combination [-0.5387097597122192, -1.1827564239501953, 0.5…] of [-1.403516411781311, 0.3108177185058594, -0.32…] Autoregressive [-1.0869172811508179, 0.7135171890258789, -0.2…] Language [-0.33215752243995667, -1.4108021259307861, -0…] Model [-1.6097160577774048, -0.2548254430294037, 0.0…] and [0.7884324789047241, -1.507911205291748, 0.677…] Permutation [0.6049966812133789, -0.157279372215271, -0.06…] Language [-0.33215752243995667, -1.4108021259307861, -0…] Model [-1.6097160577774048, -0.2548254430294037, 0.0…] Word Embeddings Glove GLOVE Word Embeddings example nlp.load(&#39;glove&#39;).predict(&#39;Glove embeddings are generated by aggregating global word-word co-occurrence matrix from a corpus&#39;) token glove_embeddings Glove [0.3677999973297119, 0.37073999643325806, 0.32…] embeddings [0.732479989528656, 0.3734700083732605, 0.0188…] are [-0.5153300166130066, 0.8318600058555603, 0.22…] generated [-0.35510000586509705, 0.6115900278091431, 0.4…] by [-0.20874999463558197, -0.11739999800920486, 0…] aggregating [-0.5133699774742126, 0.04489300027489662, 0.1…] global [0.24281999468803406, 0.6170300245285034, 0.66…] word-word [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …] co-occurrence [0.16384999454021454, -0.3178800046443939, 0.1…] matrix [-0.2663800120353699, 0.4449099898338318, 0.32…] from [0.30730998516082764, 0.24737000465393066, 0.6…] a [-0.2708599865436554, 0.04400600120425224, -0…] corpus [0.39937999844551086, 0.15894000232219696, -0…] Multiple Token Embeddings at once Compare 6 Embeddings at once with NLU and T-SNE example #This takes around 10GB RAM, watch out! nlp.load(&#39;bert albert electra elmo xlnet use glove&#39;).predict(&#39;Get all of them at once! Watch your RAM tough!&#39;) xlnet_embeddings use_embeddings elmo_embeddings electra_embeddings glove_embeddings sentence albert_embeddings biobert_embeddings bert_embeddings [[-0.003953204490244389, -1.5821468830108643, …,] [-0.019299551844596863, -0.04762779921293259, …,] [[0.04002974182367325, -0.43536433577537537, -…,] [[0.19559216499328613, -0.46693214774131775, -…,] [[0.1443299949169159, 0.4395099878311157, 0.58…,] Get all of them at once, watch your RAM tough! [[-0.4743960201740265, -0.581386387348175, 0.7…,] [[-0.00012563914060592651, -1.372296929359436,…,] [[-0.7687976360321045, 0.8489367961883545, -0….,] Bert Sentence Embeddings BERT Sentence Embeddings example sentence bert_sentence_embeddings He was suprised by the diversity of NLU [-1.0726687908172607, 0.4481312036514282, -0.0…,] Electra Sentence Embeddings ELECTRA Sentence Embeddings example nlp.load(&#39;embed_sentence.electra&#39;).predict(&#39;He was suprised by the diversity of NLU&#39;) sentence electra_sentence_embeddings He was suprised by the diversity of NLU [0.005376118700951338, 0.18036000430583954, -0…,] Sentence Embeddings Use USE Sentence Embeddings example nlp.load(&#39;use&#39;).predict(&#39;USE is designed to encode whole sentences and documents into vectors that can be used for text classification, semantic similarity, clustering or oder NLP tasks&#39;) sentence use_embeddings USE is designed to encode whole sentences and …] [0.03302069380879402, -0.004255455918610096, -…] Spell Checking Spell checking example nlp.load(&#39;spell&#39;).predict(&#39;I liek pentut buttr ant jely&#39;) token checked I I liek like peantut pentut buttr buttr and and jelli jely Dependency Parsing Unlabeled Untyped Dependency Parsing example nlp.load(&#39;dep.untyped&#39;).predict(&#39;Untyped Dependencies represent a grammatical tree structure.md&#39;) token pos dependency Untyped NNP ROOT Dependencies NNP represent represent VBD Untyped a DT structure grammatical JJ structure tree NN structure structure NN represent Dependency Parsing Labeled Typed Dependency Parsing example nlp.load(&#39;dep&#39;).predict(&#39;Typed Dependencies represent a grammatical tree structure.md where every edge has a label&#39;) token pos dependency labled_dependency Typed NNP ROOT root Dependencies NNP represent nsubj represent VBD Typed parataxis a DT structure nsubj grammatical JJ structure amod tree NN structure flat structure NN represent nsubj where WRB structure mark every DT edge nsubj edge NN where nsubj has VBZ ROOT root a DT label nsubj label NN has nsubj Tokenization Tokenization example nlp.load(&#39;tokenize&#39;).predict(&#39;Each word and symbol in a sentence will generate token.&#39;) token Each word and symbol will generate a token . Stemmer Stemmer example nlp.load(&#39;stem&#39;).predict(&#39;NLU can get you the stem of a word&#39;) token stem NLU nlu can can get get you you the the stem stem of of a a word word Stopwords Removal Stopwords Removal example nlp.load(&#39;stopwords&#39;).predict(&#39;I want you to remove stopwords from this sentence please&#39;) token cleanTokens I remove want stopwords you sentence to None remove None stopwords None from None this None sentence None please None Lemmatization Lemmatization example nlp.load(&#39;lemma&#39;).predict(&#39;Lemmatizing generates a less noisy version of the inputted tokens&#39;) token lemma Lemmatizing Lemmatizing generates generate a a less less noisy noisy version version of of the the inputted input tokens token Normalizers Normalizing example nlp.load(&#39;norm&#39;).predict(&#39;@CKL_IT says that #normalizers are pretty useful to clean #structured_strings in #NLU like tweets&#39;) normalized token CKLIT @CKL_IT says says that that normalizers #normalizers are are pretty pretty useful useful to to clean clean structuredstrings #structured_strings in in NLU #NLU like like tweets tweets NGrams NGrams example nlp.load(&#39;ngram&#39;).predict(&#39;Wht a wondful day!&#39;) document ngrams pos To be or not to be [To, be, or, not, to, be, To be, be or, or not…] [TO, VB, CC, RB, TO, VB] Date Matching Date Matching example nlp.load(&#39;match.datetime&#39;).predict(&#39;In the years 2000/01/01 to 2010/01/01 a lot of things happened&#39;) document date In the years 2000/01/01 to 2010/01/01 a lot of things happened [2000/01/01, 2001/01/01] Entity Chunking Checkout see here for all possible POS labels or Splits text into rows based on matched grammatical entities. Entity Chunking Example # First we load the pipeline pipe = nlp.load(&#39;match.chunks&#39;) # Now we print the info to see at which index which com,ponent is and what parameters we can configure on them pipe.generate_class_metadata_table() # Lets set our Chunker to only match NN pipe[&#39;default_chunker&#39;].setRegexParsers([&#39;&lt;NN&gt;+&#39;, &#39;&lt;JJ&gt;+&#39;]) # Now we can predict with the configured pipeline pipe.predict(&quot;Jim and Joe went to the big blue market next to the town hall&quot;) # the outputs of component_list.print_info() The following parameters are configurable for this NLU pipeline (You can copy paste the examples) : &gt;&gt;&gt; component_list[&#39;document_assembler&#39;] has settable params: component_list[&#39;document_assembler&#39;].setCleanupMode(&#39;disabled&#39;) | Info: possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full | Currently set to : disabled &gt;&gt;&gt; component_list[&#39;sentence_detector&#39;] has settable params: component_list[&#39;sentence_detector&#39;].setCustomBounds([]) | Info: characters used to explicitly mark sentence bounds | Currently set to : [] component_list[&#39;sentence_detector&#39;].setDetectLists(True) | Info: whether detect lists during sentence detection | Currently set to : True component_list[&#39;sentence_detector&#39;].setExplodeSentences(False) | Info: whether to explode each sentence into a different row, for better parallelization. Defaults to false. | Currently set to : False component_list[&#39;sentence_detector&#39;].setMaxLength(99999) | Info: Set the maximum allowed length for each sentence | Currently set to : 99999 component_list[&#39;sentence_detector&#39;].setMinLength(0) | Info: Set the minimum allowed length for each sentence. | Currently set to : 0 component_list[&#39;sentence_detector&#39;].setUseAbbreviations(True) | Info: whether to apply abbreviations at sentence detection | Currently set to : True component_list[&#39;sentence_detector&#39;].setUseCustomBoundsOnly(False) | Info: Only utilize custom bounds in sentence detection | Currently set to : False &gt;&gt;&gt; component_list[&#39;regex_matcher&#39;] has settable params: component_list[&#39;regex_matcher&#39;].setCaseSensitiveExceptions(True) | Info: Whether to care for case sensitiveness in exceptions | Currently set to : True component_list[&#39;regex_matcher&#39;].setTargetPattern(&#39; S+&#39;) | Info: pattern to grab from text as token candidates. Defaults S+ | Currently set to : S+ component_list[&#39;regex_matcher&#39;].setMaxLength(99999) | Info: Set the maximum allowed length for each token | Currently set to : 99999 component_list[&#39;regex_matcher&#39;].setMinLength(0) | Info: Set the minimum allowed length for each token | Currently set to : 0 &gt;&gt;&gt; component_list[&#39;sentiment_dl&#39;] has settable params: &gt;&gt;&gt; component_list[&#39;default_chunker&#39;] has settable params: component_list[&#39;default_chunker&#39;].setRegexParsers([&#39;&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;+&#39;]) | Info: an array of grammar based chunk parsers | Currently set to : [&#39;&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;+&#39;] chunk pos market [NNP, CC, NNP, VBD, TO, DT, JJ, JJ, NN, JJ, TO… town hall [NNP, CC, NNP, VBD, TO, DT, JJ, JJ, NN, JJ, TO… big blue [NNP, CC, NNP, VBD, TO, DT, JJ, JJ, NN, JJ, TO… next [NNP, CC, NNP, VBD, TO, DT, JJ, JJ, NN, JJ, TO… Sentence Detection Sentence Detection example nlp.load(&#39;sentence_detector&#39;).predict(&#39;NLU can detect things. Like beginning and endings of sentences. It can also do much more!&#39;, output_level =&#39;sentence&#39;) sentence word_embeddings pos ner NLU can detect things. [[0.4970400035381317, -0.013454999774694443, 0…] [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN… ] [O, O, O, O, O, B-sent, O, O, O, O, O, O, B-se…] Like beginning and endings of sentences. [[0.4970400035381317, -0.013454999774694443, 0…] [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN…] [O, O, O, O, O, B-sent, O, O, O, O, O, O, B-se…] It can also do much more! [[0.4970400035381317, -0.013454999774694443, 0…] [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN…] [O, O, O, O, O, B-sent, O, O, O, O, O, O, B-se…] Document Normalization Document Normalizer example The DocumentNormalizer extracts content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters pipe = nlp.load(&#39;norm_document&#39;) data = &#39;&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;&#39; df = pipe.predict(data,output_level=&#39;document&#39;) df text normalized_text &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; Example This is an example of a simple HTML page with one paragraph. Word Segmenter Word Segmenter Example The WordSegmenter segments languages without any rule-based tokenization such as Chinese, Japanese, or Korean pipe = nlp.load(&#39;ja.segment_words&#39;) # japanese for &#39;Donald Trump and Angela Merkel dont share many opinions&#39; ja_data = [&#39;ドナルド・トランプとアンゲラ・メルケルは多くの意見を共有していません&#39;] df = pipe.predict(ja_data, output_level=&#39;token&#39;) df token ドナルド ・ トランプ と アンゲラ ・ メルケル は 多く の 意見 を 共有 し て い ませ ん Translation Translation example You can translate between more than 192 Languages pairs with the Marian Models You need to specify the language your data is in as start_language and the language you want to translate to as target_language. The language references must be ISO language codes nlp.load(&#39;xx.&lt;start_language&gt;.translate_to.&lt;target_language&gt;&#39;) Translate Turkish to English: nlp.load(&#39;xx.tr.translate_to.fr&#39;) Translate English to French: nlp.load(&#39;xx.en.translate_to.fr&#39;) Translate French to Hebrew: nlp.load(&#39;xx.en.translate_to.fr&#39;) translate_pipe = nlp.load(&#39;xx.en.translate_to.de&#39;) df = translate_pipe.predict(&#39;Billy likes to go to the mall every sunday&#39;) df sentence translation Billy likes to go to the mall every sunday Billy geht gerne jeden Sonntag ins Einkaufszentrum Automatic Speech Recognition (ASR) with HuBERT ASR Demo Notebook Recognize speech in Audio files with HuBERT # Let&#39;s download an audio file !wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/audio/samples/wavs/ngm_12484_01067234848.wav FILE_PATH = &quot;ngm_12484_01067234848.wav&quot; asr_df = nlp.load(&#39;en.speech2text.hubert&#39;).predict(&#39;ngm_12484_01067234848.wav&#39;) asr_df text PEOPLE WHO DIED WHILE LIVING IN OTHER PLACES Automatic Speech Recognition (ASR) with Wav2Vec2 ASR Tutorial Notebook Recognize speech in Audio files with HuBERT # Let&#39;s download an audio file !wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/audio/samples/wavs/ngm_12484_01067234848.wav FILE_PATH = &quot;ngm_12484_01067234848.wav&quot; asr_df = nlp.load(&#39;en.speech2text.wav2vec2.v2_base_960h&#39;).predict(&#39;ngm_12484_01067234848.wav&#39;) asr_df text PEOPLE WHO DIED WHILE LIVING IN OTHER PLACES Table Question Answering (TAPAS) TAPS Tutorial Notebook Table Question Answering on Pandas DataFrames powered by TAPAS: Weakly Supervised Table Parsing via Pre-training First we need a pandas dataframe on for which we want to ask questions. The so called “context” import pandas as pd context_df = pd.DataFrame({ &#39;name&#39;:[&#39;Donald Trump&#39;,&#39;Elon Musk&#39;], &#39;money&#39;: [&#39;$100,000,000&#39;,&#39;$20,000,000,000,000&#39;], &#39;married&#39;: [&#39;yes&#39;,&#39;no&#39;], &#39;age&#39; : [&#39;75&#39;,&#39;55&#39;] }) context_df Then we create an array of questions questions = [ &quot;Who earns less than 200,000,000?&quot;, &quot;Who earns more than 200,000,000?&quot;, &quot;Who earns 100,000,000?&quot;, &quot;How much money has Donald Trump?&quot;, &quot;Who is the youngest?&quot;, ] questions Now Combine the data, pass it to NLU and get answers for your questions import nlu # Now we combine both to a tuple and we are done! We can now pass this to the .predict() method tapas_data = (context_df, questions) # Lets load a TAPAS QA model and predict on (context,question). # It will give us an aswer for every question in the questions array, based on the context in context_df answers = nlu.load(&#39;en.answer_question.tapas.wtq.large_finetuned&#39;).predict(tapas_data) answers sentence tapas_qa_UNIQUE_aggregation tapas_qa_UNIQUE_answer tapas_qa_UNIQUE_cell_positions tapas_qa_UNIQUE_cell_scores tapas_qa_UNIQUE_origin_question Who earns less than 200,000,000? NONE Donald Trump [0, 0] 1 Who earns less than 200,000,000? Who earns more than 200,000,000? NONE Elon Musk [0, 1] 1 Who earns more than 200,000,000? Who earns 100,000,000? NONE Donald Trump [0, 0] 1 Who earns 100,000,000? How much money has Donald Trump? SUM SUM($100,000,000) [1, 0] 1 How much money has Donald Trump? Who is the youngest? NONE Elon Musk [0, 1] 1 Who is the youngest? Image Classification (VIT) Image Classification Tutorial Notebook Image Classifier Based on VIT Lets download a folder of images and predict on it !wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/images.zip import shutil shutil.unpack_archive(&quot;images.zip&quot;, &quot;images&quot;, &quot;zip&quot;) ! ls /content/images/images/ Once we have image data its easy to label it, we just pass the folder with images to nlu.predict() and NLU will return a pandas DF with one row per image detected nlu.load(&#39;en.classify_image.base_patch16_224&#39;).predict(&#39;/content/images/images&#39;) Image Classification (ConvNext) Image Classification Tutorial Notebook Image Classifier Based on ConvNext Lets download a folder of images and predict on it !wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/images.zip import shutil shutil.unpack_archive(&quot;images.zip&quot;, &quot;images&quot;, &quot;zip&quot;) ! ls /content/images/images/ Once we have image data its easy to label it, we just pass the folder with images to nlu.predict() and NLU will return a pandas DF with one row per image detected nlu.load(&#39;en.classify_image.convnext.tiny&#39;).predict(&#39;/content/images/images&#39;) Image Classification (SWIN) Image Classification Tutorial Notebook Image Classifier Based on SWIN Lets download a folder of images and predict on it !wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/images.zip import shutil shutil.unpack_archive(&quot;images.zip&quot;, &quot;images&quot;, &quot;zip&quot;) ! ls /content/images/images/ Once we have image data its easy to label it, we just pass the folder with images to nlu.predict() and NLU will return a pandas DF with one row per image detected nlu.load(&#39;en.classify_image.swin.tiny&#39;).predict(&#39;/content/images/images&#39;) T5 Example of every T5 task Overview of every task available with T5 The T5 model is trained on various datasets for 17 different tasks which fall into 8 categories. Text summarization Question answering Translation Sentiment analysis Natural Language inference Coreference resolution Sentence Completion Word sense disambiguation Every T5 Task with explanation: Task Name Explanation 1.CoLA Classify if a sentence is gramaticaly correct 2.RTE Classify whether if a statement can be deducted from a sentence 3.MNLI Classify for a hypothesis and premise whether they contradict or contradict each other or neither of both (3 class). 4.MRPC Classify whether a pair of sentences is a re-phrasing of each other (semantically equivalent) 5.QNLI Classify whether the answer to a question can be deducted from an answer candidate. 6.QQP Classify whether a pair of questions is a re-phrasing of each other (semantically equivalent) 7.SST2 Classify the sentiment of a sentence as positive or negative 8.STSB Classify the sentiment of a sentence on a scale from 1 to 5 (21 Sentiment classes) 9.CB Classify for a premise and a hypothesis whether they contradict each other or not (binary). 10.COPA Classify for a question, premise, and 2 choices which choice the correct choice is (binary). 11.MultiRc Classify for a question, a paragraph of text, and an answer candidate, if the answer is correct (binary), 12.WiC Classify for a pair of sentences and a disambigous word if the word has the same meaning in both sentences. 13.WSC/DPR Predict for an ambiguous pronoun in a sentence what it is referring to. 14.Summarization Summarize text into a shorter representation. 15.SQuAD Answer a question for a given context. 16.WMT1. Translate English to German 17.WMT2. Translate English to French 18.WMT3. Translate English to Romanian Every T5 Task example notebook to see how to use every T5 Task. T5 Open and Closed Book question answering notebook Text Summarization Summarization example Summarizes a paragraph into a shorter version with the same semantic meaning, based on Text summarization # Set the task on T5 pipe = nlp.load(&#39;summarize&#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; The belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . &#39;&#39;&#39;, &#39;&#39;&#39; Calculus, originally called infinitesimal calculus or &quot;the calculus of infinitesimals&quot;, is the mathematical study of continuous change, in the same way that geometry is the study of shape and algebra is the study of generalizations of arithmetic operations. It has two major branches, differential calculus and integral calculus; the former concerns instantaneous rates of change, and the slopes of curves, while integral calculus concerns accumulation of quantities, and areas under or between curves. These two branches are related to each other by the fundamental theorem of calculus, and they make use of the fundamental notions of convergence of infinite sequences and infinite series to a well-defined limit.[1] Infinitesimal calculus was developed independently in the late 17th century by Isaac Newton and Gottfried Wilhelm Leibniz.[2][3] Today, calculus has widespread uses in science, engineering, and economics.[4] In mathematics education, calculus denotes courses of elementary mathematical analysis, which are mainly devoted to the study of functions and limits. The word calculus (plural calculi) is a Latin word, meaning originally &quot;small pebble&quot; (this meaning is kept in medicine – see Calculus (medicine)). Because such pebbles were used for calculation, the meaning of the word has evolved and today usually means a method of computation. It is therefore used for naming specific methods of calculation and related theories, such as propositional calculus, Ricci calculus, calculus of variations, lambda calculus, and process calculus.&#39;&#39;&#39; ] #Predict on text data with T5 pipe.predict(data) Predicted summary Text manchester united face newcastle in the premier league on wednesday . louis van gaal’s side currently sit two points clear of liverpool in fourth . the belgian duo took to the dance floor on monday night with some friends . the belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . Binary Sentence similarity/ Paraphrasing Binary sentence similarity example Classify whether one sentence is a re-phrasing or similar to another sentence This is a sub-task of GLUE and based on MRPC - Binary Paraphrasing/ sentence similarity classification t5 = nlp.load(&#39;en.t5.base&#39;) # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;mrpc &#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , &quot; Rumsfeld said . sentence2: Rather , the US acted because the administration saw &quot; existing evidence in a new light , through the prism of our experience on September 11 &quot; &#39;&#39;&#39; , &#39;&#39;&#39; sentence1: I like to eat peanutbutter for breakfast sentence2: I like to play football. &#39;&#39;&#39; ] #Predict on text data with T5 t5.predict(data) Sentence1 Sentence2 prediction We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , “ Rumsfeld said . Rather , the US acted because the administration saw “ existing evidence in a new light , through the prism of our experience on September 11 “ . equivalent I like to eat peanutbutter for breakfast I like to play football not_equivalent How to configure T5 task for MRPC and pre-process text .setTask(&#39;mrpc sentence1:) and prefix second sentence with sentence2: Example pre-processed input for T5 MRPC - Binary Paraphrasing/ sentence similarity mrpc sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , &quot; Rumsfeld said . sentence2: Rather , the US acted because the administration saw &quot; existing evidence in a new light , through the prism of our experience on September 11&quot;, Regressive Sentence similarity/ Paraphrasing Measures how similar two sentences are on a scale from 0 to 5 with 21 classes representing a regressive label. This is a sub-task of GLUE and based onSTSB - Regressive semantic sentence similarity . t5 = nlp.load(&#39;en.t5.base&#39;) # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;stsb &#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; sentence1: What attributes would have made you highly desirable in ancient Rome? sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?&#39; &#39;&#39;&#39; , &#39;&#39;&#39; sentence1: What was it like in Ancient rome? sentence2: What was Ancient rome like? &#39;&#39;&#39;, &#39;&#39;&#39; sentence1: What was live like as a King in Ancient Rome?? sentence2: What was Ancient rome like? &#39;&#39;&#39; ] #Predict on text data with T5 t5.predict(data) Sentence1 Sentence2 prediction What attributes would have made you highly desirable in ancient Rome? How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER? 0 What was it like in Ancient rome? What was Ancient rome like? 5.0 What was live like as a King in Ancient Rome?? What is it like to live in Rome? 3.2 How to configure T5 task for stsb and pre-process text .setTask(&#39;stsb sentence1:) and prefix second sentence with sentence2: Example pre-processed input for T5 STSB - Regressive semantic sentence similarity stsb sentence1: What attributes would have made you highly desirable in ancient Rome? sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?&#39;, Grammar Checking Grammar checking with T5 example) Judges if a sentence is grammatically acceptable. Based on CoLA - Binary Grammatical Sentence acceptability classification pipe = nlp.load(&#39;grammar_correctness&#39;) # Set the task on T5 pipe[&#39;t5&#39;].setTask(&#39;cola sentence: &#39;) # define Data data = [&#39;Anna and Mike is going skiing and they is liked is&#39;,&#39;Anna and Mike like to dance&#39;] #Predict on text data with T5 pipe.predict(data) sentence prediction Anna and Mike is going skiing and they is liked is unacceptable Anna and Mike like to dance acceptable Bart Transformer Bart Transformer tutorial Bart is based on transformer architecture and is designed to handle a wide range of natural language processing tasks such as text generation, summarization, and machine translation. Based on BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer model = nlu.load(&#39;en.seq2seq.distilbart_cnn_12_6&#39;) # Set the task on T5 model[&#39;bart_transformer&#39;].setTask(&quot;summarize: &quot;) model[&#39;bart_transformer&#39;].setMaxOutputLength(200) # define Data data = &#39;&#39;&#39;LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won&#39;t cast a spell on him. Daniel Radcliffe as Harry Potter in &quot;Harry Potter and the Order of the Phoenix&quot; To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. &quot;I don&#39;t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,&quot; he told an Australian interviewer earlier this month. &quot;I don&#39;t think I&#39;ll be particularly extravagant. &quot;The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.&quot; At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film &quot;Hostel: Part II,&quot; currently six places below his number one movie on the UK box office chart. Details of how he&#39;ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. &quot;I&#39;ll definitely have some sort of party,&quot; he said in an interview. &quot;Hopefully none of you will be reading about it.&quot; Radcliffe&#39;s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. &quot;People are always looking to say &#39;kid star goes off the rails,&#39;&quot; he told reporters last month. &quot;But I try very hard not to go that way because it would be too easy for them.&quot; His latest outing as the boy wizard in &quot;Harry Potter and the Order of the Phoenix&quot; is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. Watch I-Reporter give her review of Potter&#39;s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called &quot;My Boy Jack,&quot; about author Rudyard Kipling and his son, due for release later this year. He will also appear in &quot;December Boys,&quot; an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer&#39;s &quot;Equus.&quot; Meanwhile, he is braced for even closer media scrutiny now that he&#39;s legally an adult: &quot;I just think I&#39;m going to be more sort of fair game,&quot; he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.&#39;&#39;&#39; #Predict on text data with T5 df = model.predict(data) text generated LONDON, England (Reuters) – Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won’t cast a spell on him. Daniel Radcliffe as Harry Potter in “Harry Potter and the Order of the Phoenix” To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. “I don’t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,” he told an Australian interviewer earlier this month. “I don’t think I’ll be particularly extravagant. “The things I like buying are things that cost about 10 pounds – books and CDs and DVDs.” At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film “Hostel: Part II,” currently six places below his number one movie on the UK box office chart. Details of how he’ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. “I’ll definitely have some sort of party,” he said in an interview. “Hopefully none of you will be reading about it.” Radcliffe’s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. “People are always looking to say ‘kid star goes off the rails,’” he told reporters last month. “But I try very hard not to go that way because it would be too easy for them.” His latest outing as the boy wizard in “Harry Potter and the Order of the Phoenix” is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. Watch I-Reporter give her review of Potter’s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called “My Boy Jack,” about author Rudyard Kipling and his son, due for release later this year. He will also appear in “December Boys,” an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer’s “Equus.” Meanwhile, he is braced for even closer media scrutiny now that he’s legally an adult: “I just think I’m going to be more sort of fair game,” he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed. Daniel Radcliffe gains access to a reported � 20 million $ 41 . 1 million fortune . Harry Potter star Daniel Radcliffe turns 18 on Monday . Radcliffe insists the money won’t cast a spell on him . Open book question answering T5 Open and Closed Book question answering tutorial You can imagine an open book question similar to an examen where you are allowed to bring in text documents or cheat sheets that help you answer questions in an examen. Kinda like bringing a history book to an history examen. In T5&#39;s terms, this means the model is given a question and an additional piece of textual information or so called context. This enables the T5 model to answer questions on textual datasets like medical records,newsarticles , wiki-databases , stories and movie scripts , product descriptions, ‘legal documents’ and many more. You can answer open book question in 1 line of code, leveraging the latest NLU release and Google’s T5. All it takes is : nlp.load(&#39;answer_question&#39;).predict(&quot;&quot;&quot; Where did Jebe die? context: Ghenkis Khan recalled Subtai back to Mongolia soon afterwards, and Jebe died on the road back to Samarkand&quot;&quot;&quot;) &gt;&gt;&gt; Output: Samarkand Example for answering medical questions based on medical context question =&#39;&#39;&#39; What does increased oxygen concentrations in the patient’s lungs displace? context: Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment. &#39;&#39;&#39; #Predict on text data with T5 nlp.load(&#39;answer_question&#39;).predict(question) &gt;&gt;&gt; Output: carbon monoxide Take a look at this example on a recent news article snippet : question1 = &#39;Who is Jack ma?&#39; question2 = &#39;Who is founder of Alibaba Group?&#39; question3 = &#39;When did Jack Ma re-appear?&#39; question4 = &#39;How did Alibaba stocks react?&#39; question5 = &#39;Whom did Jack Ma meet?&#39; question6 = &#39;Who did Jack Ma hide from?&#39; # from https://www.bbc.com/news/business-55728338 news_article_snippet = &quot;&quot;&quot; context: Alibaba Group founder Jack Ma has made his first appearance since Chinese regulators cracked down on his business empire. His absence had fuelled speculation over his whereabouts amid increasing official scrutiny of his businesses. The billionaire met 100 rural teachers in China via a video meeting on Wednesday, according to local government media. Alibaba shares surged 5% on Hong Kong&#39;s stock exchange on the news. &quot;&quot;&quot; # join question with context, works with Pandas DF aswell! questions = [ question1+ news_article_snippet, question2+ news_article_snippet, question3+ news_article_snippet, question4+ news_article_snippet, question5+ news_article_snippet, question6+ news_article_snippet,] nlp.load(&#39;answer_question&#39;).predict(questions) This will output a Pandas Dataframe similar to this : Answer Question Alibaba Group founder Who is Jack ma? Jack Ma Who is founder of Alibaba Group? Wednesday When did Jack Ma re-appear? surged 5% How did Alibaba stocks react? 100 rural teachers Whom did Jack Ma meet? Chinese regulators Who did Jack Ma hide from? Closed book question answering T5 Open and Closed Book question answering tutorial A closed book question is the exact opposite of a open book question. In an examen scenario, you are only allowed to use what you have memorized in your brain and nothing else. In T5&#39;s terms this means that T5 can only use it’s stored weights to answer a question and is given no aditional context. T5 was pre-trained on the C4 dataset which contains petabytes of web crawling data collected over the last 8 years, including Wikipedia in every language. This gives T5 the broad knowledge of the internet stored in it’s weights to answer various closed book questions You can answer closed book question in 1 line of code, leveraging the latest NLU release and Google’s T5. You need to pass one string to NLU, which starts which a question and is followed by a context: tag and then the actual context contents. All it takes is : nlp.load(&#39;en.t5&#39;).predict(&#39;Who is president of Nigeria?&#39;) &gt;&gt;&gt; Muhammadu Buhari nlp.load(&#39;en.t5&#39;).predict(&#39;What is the most spoken language in India?&#39;) &gt;&gt;&gt; Hindi nlp.load(&#39;en.t5&#39;).predict(&#39;What is the capital of Germany?&#39;) &gt;&gt;&gt; Berlin",
    "url": "/docs/en/jsl/examples",
    "relUrl": "/docs/en/jsl/examples"
  },
  "927": {
    "id": "927",
    "title": "Examples",
    "content": "Showcasing notebooks and codes of how to use Spark NLP in Python and Scala. Python Setup $ java -version # should be Java 8 (Oracle or OpenJDK) $ conda create -n sparknlp python=3.7 -y $ conda activate sparknlp $ pip install spark-nlp==4.3.2 pyspark==3.3.1 Google Colab Notebook Google Colab is perhaps the easiest way to get started with spark-nlp. It requires no installation or setup other than having a Google account. Run the following code in Google Colab notebook and start using spark-nlp right away. # This is only to setup PySpark and Spark NLP on Colab !wget https://setup.johnsnowlabs.com/colab.sh -O - | bash This script comes with the two options to define pyspark and spark-nlp versions via options: # -p is for pyspark # -s is for spark-nlp # by default they are set to the latest !bash colab.sh -p 3.2.3 -s 4.3.2 Spark NLP quick start on Google Colab is a live demo on Google Colab that performs named entity recognitions and sentiment analysis by using Spark NLP pretrained pipelines. Kaggle Kernel Run the following code in Kaggle Kernel and start using spark-nlp right away. # Let&#39;s setup Kaggle for Spark NLP and PySpark !wget https://setup.johnsnowlabs.com/kaggle.sh -O - | bash Notebooks Tutorials and articles Jupyter Notebooks",
    "url": "/docs/en/examples",
    "relUrl": "/docs/en/examples"
  },
  "928": {
    "id": "928",
    "title": "Examples",
    "content": "Usage examples of nlp.load() The following examples demonstrate how to use nlu’s load api accompanied by the outputs generated by it. It enables loading any model or pipeline in one line You need to pass one NLU reference to the load method. You can also pass multiple whitespace separated references. You can find all NLU references here Medical Named Entity Recognition (NER) Medical NER tutorial notebook NLU provided a separate and highly tuned medical NER models for various Healthcare domains. These medical NER models are trained to extract various medical named entities. data =&quot;&quot;&quot;The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days.&quot;&quot;&quot; df = nlp.load(&#39;med_ner.jsl.wip.clinical en.resolve_chunk.cpt_clinical&#39;).predict(data) entities@clinical_results meta_entities@clinical_entity meta_entities@clinical_confidence chunk_resolution_results meta_chunk_resolution_all_k_aux_labels meta_chunk_resolution_target_text meta_chunk_resolution_distance meta_chunk_resolution_confidence meta_chunk_resolution_all_k_results meta_chunk_resolution_all_k_distances meta_chunk_resolution_all_k_cosine_distances 5-month-old Age 0.9982 49496   5-month-old 15.0536 1 49496 15.0536 0.5153 infant Age 0.9999 49492   infant 6.7093 1 49492 6.7093 0.3702 Monday RelativeDate 0.9983 59857   Monday 12.6501 1 59857 12.6501 0.5324 cold Symptom 0.7517 50547   cold 2.6313 1 50547 2.6313 0.4492 cough Symptom 0.9969 32215   cough 3.5559 1 32215 3.5559 0.4847 runny nose Symptom 0.7796 60281   runny nose 3.3286 1 60281 3.3286 0.3959 for 2 days Duration 0.5479 35390   for 2 days 2.3929 1 35390 2.3929 0.22 See the Models Hub for all avaiable Entity Resolution Models Zero-Shot NER Zero-Shot NER Tutorial Notebook Based on John Snow Labs Enterprise-NLP ZeroShotNerModel Zero shot models excel at generalization, meaning that the model can accurately predict entities in very different data sets without the need to fine tune the model or train from scratch for each different domain. Even though a model trained to solve a specific problem can achieve better accuracy than a zero-shot model in this specific task, it probably won’t be useful in a different task. That is where zero-shot models shows its usefulness by being able to achieve good results in various domains. Usage: We just need to load the zero-shot NER model and configure a set of entity definitions. # load zero-shot ner model enterprise_zero_shot_ner = nlp.load(&#39;en.zero_shot.ner_roberta&#39;) # Configure entity definitions enterprise_zero_shot_ner[&#39;zero_shot_ner&#39;].setEntityDefinitions( { &quot;PROBLEM&quot;: [ &quot;What is the disease?&quot;, &quot;What is his symptom?&quot;, &quot;What is her disease?&quot;, &quot;What is his disease?&quot;, &quot;What is the problem?&quot;, &quot;What does a patient suffer&quot;, &quot;What was the reason that the patient is admitted to the clinic?&quot;, ], &quot;DRUG&quot;: [ &quot;Which drug?&quot;, &quot;Which is the drug?&quot;, &quot;What is the drug?&quot;, &quot;Which drug does he use?&quot;, &quot;Which drug does she use?&quot;, &quot;Which drug do I use?&quot;, &quot;Which drug is prescribed for a symptom?&quot;, ], &quot;ADMISSION_DATE&quot;: [&quot;When did patient admitted to a clinic?&quot;], &quot;PATIENT_AGE&quot;: [ &quot;How old is the patient?&quot;, &quot;What is the gae of the patient?&quot;, ], } ) Then we can already use this pipeline to predict labels # Predict entities df = enterprise_zero_shot_ner.predict( [ &quot;The doctor pescribed Majezik for my severe headache.&quot;, &quot;The patient was admitted to the hospital for his colon cancer.&quot;, &quot;27 years old patient was admitted to clinic on Sep 1st by Dr.&quot;+ &quot;X for a right-sided pleural effusion for thoracentesis.&quot;, ] ) df document entities_zero_shot entities_zero_shot_class entities_zero_shot_confidence entities_zero_shot_origin_chunk entities_zero_shot_origin_sentence The doctor pescribed Majezik for my severe headache. Majezik DRUG 0.646716 0 0 The doctor pescribed Majezik for my severe headache. severe headache PROBLEM 0.552635 1 0 The patient was admitted to the hospital for his colon cancer. colon cancer PROBLEM 0.88985 0 0 27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis. 27 years old PATIENT_AGE 0.694308 0 0 27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis. Sep 1st ADMISSION_DATE 0.956461 1 0 27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis. a right-sided pleural effusion for thoracentesis PROBLEM 0.500266 2 0 Entity Resolution (for sentences) Entity Resolution tutorial notebook Classify each sentence extracted by a sentence detector into one of C resolvable classes. These classes usually are international disease , medicine , or procedure codes based on ICD standards. data = [&quot;&quot;&quot;He has a starvation ketosis but nothing found for significant for dry oral mucosa&quot;&quot;&quot;] nlp.load(&#39;med_ner.jsl.wip.clinical resolve.icd10pcs&#39;).predict(data) sentence_results sentence_resolution_results entities@clinical_results meta_entities@clinical_entity meta_entities@clinical_confidence The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. DU12BBZ [‘5-month-old’, ‘infant’, ‘Monday’, ‘cold’, ‘cough’, ‘runny nose’, ‘for 2 days’, ‘Mom’, ‘she’, ‘fever’, ‘Her’, ‘she’, ‘spitting up a lot’] [‘Age’, ‘Age’, ‘RelativeDate’, ‘Symptom’, ‘Symptom’, ‘Symptom’, ‘Duration’, ‘Gender’, ‘Gender’, ‘VS_Finding’, ‘Gender’, ‘Gender’, ‘Symptom’] [‘0.9982’, ‘0.9999’, ‘0.9983’, ‘0.7517’, ‘0.9969’, ‘0.7796’, ‘0.5479’, ‘0.9427’, ‘0.9994’, ‘0.9975’, ‘0.9996’, ‘0.9985’, ‘0.30217502’] Mom states she had no fever. F00ZNQZ [‘5-month-old’, ‘infant’, ‘Monday’, ‘cold’, ‘cough’, ‘runny nose’, ‘for 2 days’, ‘Mom’, ‘she’, ‘fever’, ‘Her’, ‘she’, ‘spitting up a lot’] [‘Age’, ‘Age’, ‘RelativeDate’, ‘Symptom’, ‘Symptom’, ‘Symptom’, ‘Duration’, ‘Gender’, ‘Gender’, ‘VS_Finding’, ‘Gender’, ‘Gender’, ‘Symptom’] [‘0.9982’, ‘0.9999’, ‘0.9983’, ‘0.7517’, ‘0.9969’, ‘0.7796’, ‘0.5479’, ‘0.9427’, ‘0.9994’, ‘0.9975’, ‘0.9996’, ‘0.9985’, ‘0.30217502’] Her appetite was good but she was spitting up a lot. F08Z3YZ [‘5-month-old’, ‘infant’, ‘Monday’, ‘cold’, ‘cough’, ‘runny nose’, ‘for 2 days’, ‘Mom’, ‘she’, ‘fever’, ‘Her’, ‘she’, ‘spitting up a lot’] [‘Age’, ‘Age’, ‘RelativeDate’, ‘Symptom’, ‘Symptom’, ‘Symptom’, ‘Duration’, ‘Gender’, ‘Gender’, ‘VS_Finding’, ‘Gender’, ‘Gender’, ‘Symptom’] [‘0.9982’, ‘0.9999’, ‘0.9983’, ‘0.7517’, ‘0.9969’, ‘0.7796’, ‘0.5479’, ‘0.9427’, ‘0.9994’, ‘0.9975’, ‘0.9996’, ‘0.9985’, ‘0.30217502’] See the Models Hub for all avaiable Entity Resolution Models Relation Extraction Relation Extraction tutorial notebook Classify for pairs of entities what kind of relation exists between them. It classifies for every named entity , which type of relationship exists to the other entities. More precisely, internally the relation extractor classifies every pair of entities into one out of C potential relation classes. There could be no relation between a pair of entities or there could a relation, which is specified by ` the predicted relation label` . You can specify predict(data,output_level=&#39;relation to have one row per classified relation in your resulting dataframe. Depending on what models are loaded in your pipe, NLU infers output_level=relation automatically and configures to that, unless specified otherwise. See the Models Hub for all avaiable Relation Extractor Models data = &#39;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&#39; df = nlp.load(&#39;en.med_ner.jsl.wip.clinical.greedy en.relation&#39;).predict(data) document_results relation_results meta_relation_entity1 meta_relation_entity2 meta_relation_chunk1 meta_relation_chunk2 meta_relation_confidence entities@greedy_results meta_entities@greedy_entity meta_entities@greedy_confidence MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Disease_Syndrome_Disorder MRI infarction 0.900999 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Direction MRI upper 0.947945 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Internal_organ_or_component MRI brain stem 0.654686 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Direction MRI left 0.944728 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Internal_organ_or_component MRI cerebellum 0.683124 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Direction MRI right 0.96001 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Internal_organ_or_component MRI basil ganglia 0.958023 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Direction infarction upper 0.986427 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Internal_organ_or_component infarction brain stem 0.872217 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Direction infarction left 0.983788 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Internal_organ_or_component infarction cerebellum 0.974557 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Direction infarction right 0.981092 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Internal_organ_or_component infarction basil ganglia 0.968148 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 1 Direction Internal_organ_or_component upper brain stem 0.999582 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Direction upper left 0.98803 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Internal_organ_or_component upper cerebellum 0.990115 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Direction upper right 0.989708 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Internal_organ_or_component upper basil ganglia 0.971543 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Direction brain stem left 0.768312 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 1 Internal_organ_or_component Internal_organ_or_component brain stem cerebellum 0.504254 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Direction brain stem right 0.939806 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Internal_organ_or_component brain stem basil ganglia 0.944104 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 1 Direction Internal_organ_or_component left cerebellum 0.999842 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Direction left right 0.99164 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Internal_organ_or_component left basil ganglia 0.985331 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Direction cerebellum right 0.986705 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Internal_organ_or_component cerebellum basil ganglia 0.975779 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 1 Direction Internal_organ_or_component right basil ganglia 0.999613 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] Assertion Assertion tutorial notebook Assert for each entity the status into one out of C classes. These classes usually are : hypothetical, present, absent, possible, conditional, associated_with_someone_else. data = &quot;He has a starvation ketosis but nothing found for significant for dry oral mucosa&quot; assert_df = nlp.load(&#39;en.med_ner.clinical en.assert &#39;).predict(data) | entities@clinical_results | meta_entities@clinical_entity | meta_entities@clinical_confidence | assertion_results | meta_assertion_confidence | |:—————————-|:——————————–|————————————:|:——————–|—————————-:| | a starvation ketosis | PROBLEM | 0.932233 | present | 0.9938 | | dry oral mucosa | PROBLEM | 0.797567 | present | 0.9997 | See the Models Hub for all avaiable Assertion Models De-Identification De-Identification tutorial notebook Detect sensitive information in a string and replace the sensitive data with anonymized labels data= &#39;DR Johnson administerd to the patient Peter Parker last week 30 MG of penicilin on Friday 25. March 1999&#39; df = nlp.load(&#39;de_identify&#39;).predict(data) deidentified_results entities@ner_results meta_entities@ner_entity [‘DR administerd to the patient last week 30 MG of penicilin on Friday 25.&#39;, &#39; March &#39;] Johnson PER [‘DR administerd to the patient last week 30 MG of penicilin on Friday 25.&#39;, &#39; March &#39;] Peter Parker PER See the Models Hub for all avaiable De-Identification Models Drug Normalizer Drug Normalizer tutorial notebook Normalize raw text from clinical documents, e.g. scraped web pages or xml document. Removes all dirty characters from text following one or more input regex patterns. Can apply non wanted character removal which a specific policy. Can apply lower case normalization. Parameters are lowercase: whether to convert strings to lowercase. Default is False. policy: rule to remove patterns from text. Valid policy values are: all abbreviations, dosages Defaults is all. abbreviation policy used to expend common drugs abbreviations, dosages policy used to convert drugs dosages and values to the standard form (see examples bellow). data = [&quot;Agnogenic one half cup&quot;,&quot;adalimumab 54.5 + 43.2 gm&quot;,&quot;aspirin 10 meq/ 5 ml oral sol&quot;,&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec&quot;,&quot;Sodium Chloride/Potassium Chloride 13bag&quot;] nlp.load(&#39;norm_drugs&#39;).predict(data) drug_norm text Agnogenic 0.5 oral solution Agnogenic one half cup adalimumab 97700 mg adalimumab 54.5 + 43.2 gm aspirin 2 meq/ml oral solution aspirin 10 meq/ 5 ml oral sol interferon alfa - 2b 10000000 unt ( 1 ml ) injection interferon alfa-2b 10 million unit ( 1 ml ) injec Sodium Chloride / Potassium Chloride 13 bag Sodium Chloride/Potassium Chloride 13bag Text Generator Text Generation tutorial notebook Given a few tokens as an intro, it can generate human-like, conceptually meaningful texts up to 512 tokens given an input text (max 1024 tokens). data - [&#39;Covid 19 is&#39;] df = nlu.load(&#39;en.text_generator.biomedical_biogpt_base&#39;).predict(data) text generated Covid 19 is Covid 19 is a pandemic that has affected the world economy and health. The World Health Organization ( WHO ) has declared the pandemic a global emergency. See the Models Hub for all available Text Generation Models Rule based NER with Context Matcher Rule based NER with context matching tutorial notebook Define a rule based NER algorithm by providing Regex Patterns and resolution mappings. The confidence value is computed using a heuristic approach based on how many matches it has. A dictionary can be provided with setDictionary to map extracted entities to a unified representation. The first column of the dictionary file should be the representation with following columns the possible matches. import nlu import json # Define helper functions to write NER rules to file &quot;&quot;&quot;Generate json with dict contexts at target path&quot;&quot;&quot; def dump_dict_to_json_file(dict, path): with open(path, &#39;w&#39;) as f: json.dump(dict, f) &quot;&quot;&quot;Dump raw text file &quot;&quot;&quot; def dump_file_to_csv(data,path): with open(path, &#39;w&#39;) as f:f.write(data) sample_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting. Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Twenty days ago. Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . At birth the typical boy is growing slightly faster than the typical girl, but the velocities become equal at about seven months, and then the girl grows faster until four years. From then until adolescence no differences in velocity can be detected. 21-02-2020 21/04/2020 &quot;&quot;&quot; # Define Gender NER matching rules gender_rules = { &quot;entity&quot;: &quot;Gender&quot;, &quot;ruleScope&quot;: &quot;sentence&quot;, &quot;completeMatchRegex&quot;: &quot;true&quot; } # Define dict data in csv format gender_data = &#39;&#39;&#39;male,man,male,boy,gentleman,he,him female,woman,female,girl,lady,old-lady,she,her neutral,neutral&#39;&#39;&#39; # Dump configs to file dump_dict_to_json_file(gender_data, &#39;gender.csv&#39;) dump_dict_to_json_file(gender_rules, &#39;gender.json&#39;) gender_NER_pipe = nlp.load(&#39;match.context&#39;) gender_NER_pipe.print_info() gender_NER_pipe[&#39;context_matcher&#39;].setJsonPath(&#39;gender.json&#39;) gender_NER_pipe[&#39;context_matcher&#39;].setDictionary(&#39;gender.csv&#39;, options={&quot;delimiter&quot;:&quot;,&quot;}) gender_NER_pipe.predict(sample_text) context_match context_match_confidence female 0.13 she 0.13 she 0.13 she 0.13 she 0.13 boy 0.13 girl 0.13 girl 0.13 Context Matcher Parameters You can define the following parameters in your rules.json file to define the entities to be matched Parameter Type Description entity str The name of this rule regex Optional[str] Regex Pattern to extract candidates contextLength Optional[int] defines the maximum distance a prefix and suffix words can be away from the word to match,whereas context are words that must be immediately after or before the word to match prefix Optional[List[str]] Words preceding the regex match, that are at most contextLength characters aways regexPrefix Optional[str] RegexPattern of words preceding the regex match, that are at most contextLength characters aways suffix Optional[List[str]] Words following the regex match, that are at most contextLength characters aways regexSuffix Optional[str] RegexPattern of words following the regex match, that are at most contextLength distance aways context Optional[List[str]] list of words that must be immediatly before/after a match contextException Optional[List[str]] ?? List of words that may not be immediatly before/after a match exceptionDistance Optional[int] Distance exceptions must be away from a match regexContextException Optional[str] Regex Pattern of exceptions that may not be within exceptionDistance range of the match matchScope Optional[str] Either token or sub-token to match on character basis completeMatchRegex Optional[str] Wether to use complete or partial matching, either &quot;true&quot; or &quot;false&quot; ruleScope str currently only sentence supported Authorize access to licensed features and install healthcare dependencies You need a set of credentials to access the licensed healthcare features. You can grab one here Automatically Authorize Google Colab via JSON file By default, nlu checks /content/spark_nlp_for_healthcare.json on google colabe enviroments for a spark_nlp_for_healthcare.json file that you recieve via E-mail from us. If you upload the spark_nlp_for_healthcare.json file to the standard colab directory, nlp.load() will automatically find it and authorize your enviroment. Authorize anywhere via providing via JSON file You can specify the location of your spark_nlp_for_healthcare.json like this : path = &#39;/path/to/spark_nlp_for_healthcare.json&#39; nlp.auth(path).load(&#39;licensed_model&#39;).predict(data) Authorize via providing String parameters import nlu SPARK_NLP_LICENSE = &#39;YOUR_SECRETS&#39; AWS_ACCESS_KEY_ID = &#39;YOUR_SECRETS&#39; AWS_SECRET_ACCESS_KEY = &#39;YOUR_SECRETS&#39; JSL_SECRET = &#39;YOUR_SECRETS&#39; nlp.auth(SPARK_NLP_LICENSE,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,JSL_SECRET)",
    "url": "/docs/en/jsl/examples_hc",
    "relUrl": "/docs/en/jsl/examples_hc"
  },
  "929": {
    "id": "929",
    "title": "Explore Medical LLM - Medical Large Language Models Demos & Notebooks",
    "content": "",
    "url": "/explore_medical_llm",
    "relUrl": "/explore_medical_llm"
  },
  "930": {
    "id": "930",
    "title": "Annotations Export",
    "content": "Annotations can be exported in various format for storage and later use. You can export the annotations applied to the tasks of any project by going to the Tasks page and clicking on the Export button on the top-right corner of this page. You will be navigated to the Export page and from there you can select the format and configure the export options to export the annotations to a file/s. Supported Formats for Text Projects The completions and predictions are stored in a database for fast search and access. Completions and predictions can be exported into the formats described below. JSON You can export the manual annotations (completions) and automatic annotations (predictions) to JSON format using the JSON option on the Export page. An example of JSON export file is shown below: [ { &quot;completions&quot;: [ { &quot;created_username&quot;: &quot;eric&quot;, &quot;created_ago&quot;: &quot;2022-10-29T14:42:50.867Z&quot;, &quot;lead_time&quot;: 82, &quot;result&quot;: [ { &quot;value&quot;: { &quot;start&quot;: 175, &quot;end&quot;: 187, &quot;text&quot;: &quot;tuberculosis&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.9524 }, &quot;id&quot;: &quot;zgam2AbdmY&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 213, &quot;end&quot;: 239, &quot;text&quot;: &quot;Mycobacterium tuberculosis&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.904775 }, &quot;id&quot;: &quot;1v76SqlWtj&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 385, &quot;end&quot;: 394, &quot;text&quot;: &quot;pneumonia&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.91655 }, &quot;id&quot;: &quot;CURKae4Eca&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 436, &quot;end&quot;: 449, &quot;text&quot;: &quot;Streptococcus&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9157500000000001 }, &quot;id&quot;: &quot;cM5BvAsZL4&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 454, &quot;end&quot;: 465, &quot;text&quot;: &quot;Pseudomonas&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.91495 }, &quot;id&quot;: &quot;KGOLhb8OPV&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 532, &quot;end&quot;: 540, &quot;text&quot;: &quot;Shigella&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.91655 }, &quot;id&quot;: &quot;JCIhVQTDZl&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 542, &quot;end&quot;: 555, &quot;text&quot;: &quot;Campylobacter&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9163 }, &quot;id&quot;: &quot;CkxrbwvFzb&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 561, &quot;end&quot;: 571, &quot;text&quot;: &quot;Salmonella&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9164000000000001 }, &quot;id&quot;: &quot;c6ev6McH4Z&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 623, &quot;end&quot;: 630, &quot;text&quot;: &quot;tetanus&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.97 }, &quot;id&quot;: &quot;9ZmEaJnqKG&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 632, &quot;end&quot;: 645, &quot;text&quot;: &quot;typhoid fever&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.976675 }, &quot;id&quot;: &quot;Uo5CWzdd1S&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 647, &quot;end&quot;: 657, &quot;text&quot;: &quot;diphtheria&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.9737 }, &quot;id&quot;: &quot;7nc71jXT3P&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 659, &quot;end&quot;: 667, &quot;text&quot;: &quot;syphilis&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.97355 }, &quot;id&quot;: &quot;nIKfsOWNyE&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 673, &quot;end&quot;: 689, &quot;text&quot;: &quot;Hansen&#39;s disease&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.899025 }, &quot;id&quot;: &quot;SyuVYMn7ax&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 30, &quot;end&quot;: 38, &quot;text&quot;: &quot;bacteria&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 1 }, &quot;id&quot;: &quot;lq7qtJj1yX&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 98, &quot;end&quot;: 106, &quot;text&quot;: &quot;bacteria&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 1 }, &quot;id&quot;: &quot;kxaB_gMstN&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; } ], &quot;honeypot&quot;: true, &quot;copied_from&quot;: &quot;prediction: 11001&quot;, &quot;id&quot;: 11001, &quot;confidence_range&quot;: [ 0, 1 ], &quot;copy&quot;: true, &quot;cid&quot;: &quot;11001&quot;, &quot;data_type&quot;: &quot;prediction&quot;, &quot;updated_at&quot;: &quot;2022-10-29T15:13:03.445569Z&quot;, &quot;updated_by&quot;: &quot;eric&quot;, &quot;submitted_at&quot;: &quot;2022-10-30T20:57:54.303&quot; }, { &quot;created_username&quot;: &quot;jenny&quot;, &quot;created_ago&quot;: &quot;2022-10-29T15:03:51.669Z&quot;, &quot;lead_time&quot;: 0, &quot;result&quot;: [ { &quot;value&quot;: { &quot;start&quot;: 175, &quot;end&quot;: 187, &quot;text&quot;: &quot;tuberculosis&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.9524 }, &quot;id&quot;: &quot;zgam2AbdmY&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 213, &quot;end&quot;: 239, &quot;text&quot;: &quot;Mycobacterium tuberculosis&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.904775 }, &quot;id&quot;: &quot;1v76SqlWtj&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 385, &quot;end&quot;: 394, &quot;text&quot;: &quot;pneumonia&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.91655 }, &quot;id&quot;: &quot;CURKae4Eca&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 436, &quot;end&quot;: 449, &quot;text&quot;: &quot;Streptococcus&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9157500000000001 }, &quot;id&quot;: &quot;cM5BvAsZL4&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 454, &quot;end&quot;: 465, &quot;text&quot;: &quot;Pseudomonas&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.91495 }, &quot;id&quot;: &quot;KGOLhb8OPV&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 532, &quot;end&quot;: 540, &quot;text&quot;: &quot;Shigella&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.91655 }, &quot;id&quot;: &quot;JCIhVQTDZl&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 542, &quot;end&quot;: 555, &quot;text&quot;: &quot;Campylobacter&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9163 }, &quot;id&quot;: &quot;CkxrbwvFzb&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 561, &quot;end&quot;: 571, &quot;text&quot;: &quot;Salmonella&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9164000000000001 }, &quot;id&quot;: &quot;c6ev6McH4Z&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 623, &quot;end&quot;: 630, &quot;text&quot;: &quot;tetanus&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.97 }, &quot;id&quot;: &quot;9ZmEaJnqKG&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 632, &quot;end&quot;: 645, &quot;text&quot;: &quot;typhoid fever&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.976675 }, &quot;id&quot;: &quot;Uo5CWzdd1S&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 647, &quot;end&quot;: 657, &quot;text&quot;: &quot;diphtheria&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.9737 }, &quot;id&quot;: &quot;7nc71jXT3P&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 659, &quot;end&quot;: 667, &quot;text&quot;: &quot;syphilis&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.97355 }, &quot;id&quot;: &quot;nIKfsOWNyE&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 673, &quot;end&quot;: 689, &quot;text&quot;: &quot;Hansen&#39;s disease&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.899025 }, &quot;id&quot;: &quot;SyuVYMn7ax&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; } ], &quot;honeypot&quot;: true, &quot;confidence_range&quot;: [ 0, 1 ], &quot;submitted_at&quot;: &quot;2022-10-29T20:48:51.669&quot;, &quot;id&quot;: 11002 } ], &quot;predictions&quot;: [ { &quot;created_username&quot;: &quot;SparkNLP Pre-annotation&quot;, &quot;result&quot;: [ { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;zgam2AbdmY&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 187, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 175, &quot;text&quot;: &quot;tuberculosis&quot;, &quot;confidence&quot;: &quot;0.9524&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;1v76SqlWtj&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 239, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 213, &quot;text&quot;: &quot;Mycobacterium tuberculosis&quot;, &quot;confidence&quot;: &quot;0.904775&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;CURKae4Eca&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 394, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 385, &quot;text&quot;: &quot;pneumonia&quot;, &quot;confidence&quot;: &quot;0.91655&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;cM5BvAsZL4&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 449, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 436, &quot;text&quot;: &quot;Streptococcus&quot;, &quot;confidence&quot;: &quot;0.9157500000000001&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;KGOLhb8OPV&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 465, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 454, &quot;text&quot;: &quot;Pseudomonas&quot;, &quot;confidence&quot;: &quot;0.91495&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;JCIhVQTDZl&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 540, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 532, &quot;text&quot;: &quot;Shigella&quot;, &quot;confidence&quot;: &quot;0.91655&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;CkxrbwvFzb&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 555, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 542, &quot;text&quot;: &quot;Campylobacter&quot;, &quot;confidence&quot;: &quot;0.9163&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;c6ev6McH4Z&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 571, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 561, &quot;text&quot;: &quot;Salmonella&quot;, &quot;confidence&quot;: &quot;0.9164000000000001&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;9ZmEaJnqKG&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 630, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 623, &quot;text&quot;: &quot;tetanus&quot;, &quot;confidence&quot;: &quot;0.97&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;Uo5CWzdd1S&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 645, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 632, &quot;text&quot;: &quot;typhoid fever&quot;, &quot;confidence&quot;: &quot;0.976675&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;7nc71jXT3P&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 657, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 647, &quot;text&quot;: &quot;diphtheria&quot;, &quot;confidence&quot;: &quot;0.9737&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;nIKfsOWNyE&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 667, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 659, &quot;text&quot;: &quot;syphilis&quot;, &quot;confidence&quot;: &quot;0.97355&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;SyuVYMn7ax&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 689, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 673, &quot;text&quot;: &quot;Hansen&#39;s disease&quot;, &quot;confidence&quot;: &quot;0.899025&quot; } } ], &quot;created_ago&quot;: &quot;2022-10-29T14:07:58.553246Z&quot;, &quot;id&quot;: 11001 } ], &quot;created_at&quot;: &quot;2022-10-29 14:07:12&quot;, &quot;created_by&quot;: &quot;admin&quot;, &quot;data&quot;: { &quot;text&quot;: &quot;Although the vast majority of bacteria are harmless or beneficial to one&#39;s body, a few pathogenic bacteria can cause infectious diseases. The most common bacterial disease is tuberculosis, caused by the bacterium Mycobacterium tuberculosis, which affects about 2 million people mostly in sub-Saharan Africa. Pathogenic bacteria contribute to other globally important diseases, such as pneumonia, which can be caused by bacteria such as Streptococcus and Pseudomonas, and foodborne illnesses, which can be caused by bacteria such as Shigella, Campylobacter, and Salmonella. Pathogenic bacteria also cause infections such as tetanus, typhoid fever, diphtheria, syphilis, and Hansen&#39;s disease. They typically range between 1 and 5 micrometers in length.&quot;, &quot;title&quot;: &quot;cord19-11.txt&quot; }, &quot;id&quot;: 11 } ] Below are some explanations related to the structure of the JSON export file. The export represents a list/array of task, containing completions and/or predictions. Each task in the list has the following main elements: TASK: A task can have 0 or several completions and 0 or several predictions. { &quot;completions&quot;: [COMPLETION1, COMPLETION2, ...], &quot;predictions&quot;: [PREDICTION1, PREDICTION2, ...], &quot;created_at&quot;: &quot;2022-07-04 06:17:26&quot;, &quot;created_by&quot;: &quot;admin&quot;, &quot;data&quot;: { &quot;text&quot;: &lt;sample_text&gt;&quot; }, &quot;id&quot;: 1 } completions: list of completions (manual annotations) predictions: list of predictions (annotations generated by spark-nlp model(s)) created_by: time stamp representing the creation time for a task created_by: the user who created the task data: input data on which the annotations/preannotation are defined (text/image/audio etc) id: task ID COMPLETION/PREDICTION: Completions and predictions have the following structure: { &quot;created_username&quot;: &quot;collaborate&quot;, &quot;created_ago&quot;: &quot;2022-07-04T06:18:39.720155Z&quot;, &quot;lead_time&quot;: 11, &quot;result&quot;: [RESULT1, RESULT2, RESULT3, ....], &quot;honeypot&quot;: true, &quot;id&quot;: 1001, &quot;updated_at&quot;: &quot;2022-07-04T06:18:49.037150Z&quot;, &quot;updated_by&quot;: &quot;collaborate&quot;, } created_username: user who created the annotation created_ago: timestamp of when the annotation was created lead_time: time taken (in seconds) to create this annotation (valid for manual completion only) result: list of annotated labels honeypot: boolean value to set/unset ground truth id: completion/prediction ID updated_at: timestamp of when the annotation was last updated updated_by: user who updated the annotation Each completion/prediction contains one or several results which can be seen as individual annotations. RESULT: The structure of the RESULT dictionary differs according to the project configuration: 1. NER: { &quot;value&quot;: { &quot;start&quot;: 17, &quot;end&quot;: 25, &quot;text&quot;: &quot;pleasant&quot;, &quot;labels&quot;: [ &quot;FAC&quot; ], &quot;confidence&quot;: 1 }, &quot;id&quot;: &quot;iJOo_XgIao&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; } value: start: start index of the annotated chunk end: end index of the annotated chunk text: annotated chunk labels: associated label confidence: confidence score (1 for manual annotation and a value between 0 and 1 for predicted annotations) id: id of annotation (used while creating relations between entities) from_name/to_name: this attribute is set according to the project config: from_name -&gt; name attribute of the Labels tag to_name -&gt; toName attribute of the Labels tag &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; type: type of the annotation (labels, choices, relations etc.) 2. Classification: { &quot;value&quot;: { &quot;choices&quot;: [ &quot;sadness&quot; ], &quot;confidence&quot;: 1 }, &quot;id&quot;: &quot;VyY-OHe_lf&quot;, &quot;from_name&quot;: &quot;surprise&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;choices&quot; } value: choices: the options/choises selected by users confidence: confidence score (1 for manual annotation and between 0 and 1 for predicted annotation) id: id of annotation from_name/to_name: this field is set according to the project config: `from_name` -&gt; name attribute of the Choice tag `to_name` -&gt; toName attribute of the Choice tag &lt;Choices name=&quot;surprise&quot; toName=&quot;text&quot; choice=&quot;single&quot;&gt; type: type of the annotation (labels, choices, relations etc) 3. Relations: The information below is added in the RESULT section: { &quot;from_id&quot;: &quot;ucfP3c4xWg&quot;, &quot;to_id&quot;: &quot;IlWac4TdFx&quot;, &quot;type&quot;: &quot;relation&quot;, &quot;direction&quot;: &quot;right&quot;, &quot;confidence&quot;: 1 } from_id/to_id: IDs of the related annotations type: type of the annotation (labels, choices, relations etc) direction: direction for the relation. The accepted values are right and left. Submitted annotation: When a completion is submitted, it has a submitted timestamp on the COMPLETION dictionary (refer to the above json example): &quot;submitted_at&quot;: &quot;2022-07-04T12:03:48.824&quot; Reviewed annotation: When a completion is reviewed, the following information is added to the COMPLETION dictionary: &quot;review_status&quot;: { &quot;approved&quot;: true, &quot;comment&quot;: &quot;Looks good!&quot;, &quot;reviewer&quot;: &quot;Mauro&quot;, &quot;reviewed_at&quot;: &quot;2022-07-04T06:19:31.897Z&quot; } approved: boolean value (true -&gt; approved and false -&gt; rejected) comment: text comment manually defined by the reviewer reviewer: user who reviewed the completion reviewed_at: review timestamp Copied Annotation: When an annotation is copied/cloned from a specific completion/prediction, the COMPLETION dictionary contains the copied_from filed: &quot;copied_from&quot;: &quot;prediction: 4001&quot; CSV Results are stored in a comma-separated tabular file with column names specified by “from_name” and “to_name” values. TSV Results are stored in a tab-separated tabular file with column names specified by “from_name” and “to_name” values. CoNLL2003 The CoNLL export feature generates a single output file, containing all available completions for all the tasks in the project. The resulting file has the following format: -DOCSTART- -X- O Sample -X- _ O Type -X- _ O Medical -X- _ O Specialty: -X- _ O Endocrinology -X- _ O Sample -X- _ O Name: -X- _ O Diabetes -X- _ B-Diagnosis Mellitus -X- _ I-Diagnosis Followup -X- _ O Description: -X- _ O Return -X- _ O visit -X- _ O to -X- _ O the -X- _ O endocrine -X- _ O clinic -X- _ O for -X- _ O followup -X- _ O management -X- _ O of -X- _ O type -X- _ O 1 -X- _ O diabetes -X- _ O mellitus -X- _ O Plan -X- _ O today -X- _ O is -X- _ O to -X- _ O make -X- _ O adjustments -X- _ O to -X- _ O her -X- _ O pump -X- _ O based -X- _ O on -X- _ O a -X- _ O total -X- _ O daily -X- _ B-FREQUENCY dose -X- _ O of -X- _ O 90 -X- _ O units -X- _ O of -X- _ O insulin -X- _ O … Users can specify if only starred completions should be included in the output file by checking the Only ground truth option before generating the export. Supported Formats for Visual NER Projects The process of annotations export from Visual NER projects is similar to that of text projects. When exporting the Visual NER annotations users have two additional formats available: COCO and VOC. For Visual NER projects, the image documents annotated as part of each task are included in the project export archive under the images folder. COCO The COCO format is a specific JSON structure dictating how labels and metadata are saved for an image dataset. It is a large-scale object detection, segmentation, and captioning dataset. Exporting in COCO format is available for Visual NER projects only. Below is a sample format: { &quot;images&quot;: [ { &quot;width&quot;: 6.588235294117647, &quot;height&quot;: 0.9396786905122766, &quot;id&quot;: 0, &quot;file_name&quot;: [ &quot;/images/19/0160023239a-1655481445_0.png&quot;, &quot;/images/19/0160023239a-1655481445_1.png&quot; ] } ], &quot;categories&quot;: [ { &quot;id&quot;: 0, &quot;name&quot;: &quot;OGSContractNumber&quot;, &quot;supercategory&quot;: &quot;OGSContractNumber&quot; }, { &quot;id&quot;: 1, &quot;name&quot;: &quot;Contractor&quot;, &quot;supercategory&quot;: &quot;Contractor&quot; }, { &quot;id&quot;: 2, &quot;name&quot;: &quot;FederalID&quot;, &quot;supercategory&quot;: &quot;FederalID&quot; }, { &quot;id&quot;: 3, &quot;name&quot;: &quot;VendorID&quot;, &quot;supercategory&quot;: &quot;VendorID&quot; }, { &quot;id&quot;: 4, &quot;name&quot;: &quot;Title&quot;, &quot;supercategory&quot;: &quot;Title&quot; }, { &quot;id&quot;: 5, &quot;name&quot;: &quot;AwardNumber&quot;, &quot;supercategory&quot;: &quot;AwardNumber&quot; }, { &quot;id&quot;: 6, &quot;name&quot;: &quot;ContractPeriod&quot;, &quot;supercategory&quot;: &quot;ContractPeriod&quot; }, { &quot;id&quot;: 7, &quot;name&quot;: &quot;BidOpeningDate&quot;, &quot;supercategory&quot;: &quot;BidOpeningDate&quot; }, { &quot;id&quot;: 8, &quot;name&quot;: &quot;DateOfIssue&quot;, &quot;supercategory&quot;: &quot;DateOfIssue&quot; }, { &quot;id&quot;: 9, &quot;name&quot;: &quot;SpecificationReference&quot;, &quot;supercategory&quot;: &quot;SpecificationReference&quot; }, { &quot;id&quot;: 10, &quot;name&quot;: &quot;GroupNumber&quot;, &quot;supercategory&quot;: &quot;GroupNumber&quot; } ], &quot;annotations&quot;: [ { &quot;id&quot;: 0, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69434&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 1, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69435&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 2, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69436&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 3, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 1, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Cream-O-Land Dairies, LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 4, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 1, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Hudson Valley Fresh Dairy, LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 5, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 1, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Upstate Niagara Inc.&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 6, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;223629742&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 7, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;461053272&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 8, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;160845625&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 9, &quot;image_id&quot;: 0, &quot;category_id&quot;: 3, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;1100070111&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 10, &quot;image_id&quot;: 0, &quot;category_id&quot;: 3, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;1100212977&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 11, &quot;image_id&quot;: 0, &quot;category_id&quot;: 3, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;1000014941&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 12, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Cream-O-Land - LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 13, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69434&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 14, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Hudson Valley Fresh Dairy, LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 15, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69435&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 16, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69436&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 17, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Upstate Niagara Cooperative, Inc.&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 18, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;; Upstate Niagara Cooperative,&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 19, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69436&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 20, &quot;image_id&quot;: 0, &quot;category_id&quot;: 4, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Milk, Fluid (Statewide)&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 21, &quot;image_id&quot;: 0, &quot;category_id&quot;: 5, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;23239&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 22, &quot;image_id&quot;: 0, &quot;category_id&quot;: 6, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 2, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;September 21, 2021 Through September 20, 2026&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 23, &quot;image_id&quot;: 0, &quot;category_id&quot;: 7, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;June 10, 2021&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 24, &quot;image_id&quot;: 0, &quot;category_id&quot;: 8, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;September 14, 2021&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 27, &quot;image_id&quot;: 0, &quot;category_id&quot;: 10, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Group&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 29, &quot;image_id&quot;: 0, &quot;category_id&quot;: 4, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Milk, Fluid (Statewide)&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 30, &quot;image_id&quot;: 0, &quot;category_id&quot;: 5, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;23239&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 31, &quot;image_id&quot;: 0, &quot;category_id&quot;: 6, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 2, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;September 21, 2021 Through September 20, 2026&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 32, &quot;image_id&quot;: 0, &quot;category_id&quot;: 6, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;June 10, 2021&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 33, &quot;image_id&quot;: 0, &quot;category_id&quot;: 6, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;September 14, 2021&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 34, &quot;image_id&quot;: 0, &quot;category_id&quot;: 5, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;23239&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 35, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69434&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 36, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 1, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Cream-O-Land Dairies, LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 38, &quot;image_id&quot;: 0, &quot;category_id&quot;: 3, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;1100070111&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 39, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69435&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 41, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;461053272&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 43, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69436&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 45, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;160845625&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 47, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Cream-O-Land&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 49, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69434&quot;, &quot;pageNumber&quot;: 2 } ], &quot;info&quot;: { &quot;year&quot;: 2022, &quot;version&quot;: &quot;1.0&quot;, &quot;contributor&quot;: &quot;Annotation Lab Converter&quot; } } Pascal VOC XML Pascal Visual Object Classes(VOC) is an XML file that contains the image details, bounding box details, classes, pose, truncated, and other data. For each image of the task there will be an XML annotation file. Exporting in VOC format is available for Visual NER projects only. Below is a sample format: &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;annotation&gt; &lt;folder&gt;images&lt;/folder&gt; &lt;filename&gt;0160023239a-1655481445_0.png&lt;/filename&gt; &lt;source&gt; &lt;database&gt;ALABDB&lt;/database&gt; &lt;/source&gt; &lt;owner&gt; &lt;name&gt;AnnotationLab&lt;/name&gt; &lt;/owner&gt; &lt;size&gt; &lt;width&gt;2550&lt;/width&gt; &lt;height&gt;3299&lt;/height&gt; &lt;depth&gt;1&lt;/depth&gt; &lt;/size&gt; &lt;segmented&gt;0&lt;/segmented&gt; &lt;object&gt; &lt;name&gt;Title&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;1305&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1780&lt;/xmax&gt; &lt;ymax&gt;703&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;AwardNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;973&lt;/xmin&gt; &lt;ymin&gt;791&lt;/ymin&gt; &lt;xmax&gt;1099&lt;/xmax&gt; &lt;ymax&gt;834&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;ContractPeriod&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;903&lt;/ymin&gt; &lt;xmax&gt;2038&lt;/xmax&gt; &lt;ymax&gt;946&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;BidOpeningDate&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;1013&lt;/ymin&gt; &lt;xmax&gt;1263&lt;/xmax&gt; &lt;ymax&gt;1054&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;DateOfIssue&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;1124&lt;/ymin&gt; &lt;xmax&gt;1393&lt;/xmax&gt; &lt;ymax&gt;1166&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;SpecificationReference&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;973&lt;/xmin&gt; &lt;ymin&gt;1235&lt;/ymin&gt; &lt;xmax&gt;1729&lt;/xmax&gt; &lt;ymax&gt;1277&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;GroupNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1248&lt;/xmax&gt; &lt;ymax&gt;702&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;GroupNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1108&lt;/xmax&gt; &lt;ymax&gt;702&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;AwardNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;1125&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1248&lt;/xmax&gt; &lt;ymax&gt;694&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;Title&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;1304&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1780&lt;/xmax&gt; &lt;ymax&gt;703&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;AwardNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;791&lt;/ymin&gt; &lt;xmax&gt;1097&lt;/xmax&gt; &lt;ymax&gt;825&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;ContractPeriod&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;902&lt;/ymin&gt; &lt;xmax&gt;2038&lt;/xmax&gt; &lt;ymax&gt;945&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;ContractPeriod&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;1013&lt;/ymin&gt; &lt;xmax&gt;1264&lt;/xmax&gt; &lt;ymax&gt;1054&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;ContractPeriod&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;1124&lt;/ymin&gt; &lt;xmax&gt;1393&lt;/xmax&gt; &lt;ymax&gt;1166&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;AwardNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;791&lt;/xmin&gt; &lt;ymin&gt;2246&lt;/ymin&gt; &lt;xmax&gt;903&lt;/xmax&gt; &lt;ymax&gt;2276&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;/annotation&gt; Export Options Filter Exported Annotations by Task This filter allows users to select annotations based on the task (NER, Classification, Assertion, Relation Extraction) Select Annotations to Include In the Export This filter can be used to select available labels, classes, assertion labels, or relations. Tags Only allow export of tasks having the specified tags. Only Ground Truth If this option is enabled then only the tasks having ground truth in the completion will be exported. Exclude tasks without Completions Previous versions of the Annotation Lab only allowed the export of tasks that contained completions. From version 2.8.0 on, the tasks without any completions can be exported as this can be necessary for cloning projects. In the case where only tasks with completions are required in the export, users can enable the Exclude tasks without Completions option on the Export page. Integration with Amazon S3 for tasks and projects export NLP Lab 5.2 offers seamless integration with Amazon Simple Storage Service. Users can now effortlessly export annotated tasks and projects directly to a given S3 bucket. This enhancement simplifies data management and ensures a smooth transition from annotation to model training and deployment. In previous versions, exported tasks were sent to the local workstation, but now it is possible to store annotated tasks and project backups securely in an S3 bucket. When triggering export, a new popup window will prompt the user to choose the target destination. By default, the “Local Export” tab is selected. This means that when the user clicks on the export button, target files will be downloaded to the local workstation. For those who prefer the convenience and reliability of cloud storage, it is now possible to select the “S3 Export” tab - enter Amazon S3 credentials, and export tasks and projects directly to the specified S3 bucket path. S3 credentials can be stored by the NLP Lab for future use. Improved HIPAA compliance with disabled exports to local storage Another new feature NLP Lab 5.2 offers is the option to restrict the export for more control over tasks and projects. Exporting tasks and projects to the local workstation can be disabled by admin users when dealing with sensitive data. This encourages users to adopt the more versatile and secure option of exporting data to Amazon S3. Disable Local Export: System administrators can now manage export settings from the system settings page. By enabling the “Disable Local Export” option, the export to a local workstation for all projects is turned off. Selective Export Exceptions: Administrators have the flexibility to specify projects that can still use local export if needed. To do this, click on the “Add Project” button from the Exceptions widget and search for the projects to add to the exceptions list. S3 Bucket Export: With the “Disable Local Export” option activated, users can only export tasks and projects to Amazon S3 bucket paths. This ensures the protection of sensitive data that will be stored securely in the cloud. By introducing these export enhancements, NLP Lab 5.2.0 empowers organizations to streamline their data management processes while maintaining flexibility and control over export options. Users can continue to export specific projects to their local workstations if required, while others can benefit from the reliability and accessibility of exporting to Amazon S3 buckets.",
    "url": "/docs/en/alab/export",
    "relUrl": "/docs/en/alab/export"
  },
  "931": {
    "id": "931",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/extended_java_wrapper.html",
    "relUrl": "/api/python/modules/sparknlp/internal/extended_java_wrapper.html"
  },
  "932": {
    "id": "932",
    "title": "Extract handwritten texts - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/extract_handwritten_texts",
    "relUrl": "/extract_handwritten_texts"
  },
  "933": {
    "id": "933",
    "title": "Extract Tables - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/extract_tables",
    "relUrl": "/extract_tables"
  },
  "934": {
    "id": "934",
    "title": "Extract Text from Documents - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/extract_text_from_documents",
    "relUrl": "/extract_text_from_documents"
  },
  "935": {
    "id": "935",
    "title": "Finance Models - Medical Large Language Models Demos & Notebooks",
    "content": "",
    "url": "/finance_models",
    "relUrl": "/finance_models"
  },
  "936": {
    "id": "936",
    "title": "Normalization & Data Augmentation - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_company_normalization",
    "relUrl": "/financial_company_normalization"
  },
  "937": {
    "id": "937",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/financial_deidentification",
    "relUrl": "/financial_deidentification"
  },
  "938": {
    "id": "938",
    "title": "Financial Document Splitting - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_document_splitting",
    "relUrl": "/financial_document_splitting"
  },
  "939": {
    "id": "939",
    "title": "Financial Document Understanding - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_document_understanding",
    "relUrl": "/financial_document_understanding"
  },
  "940": {
    "id": "940",
    "title": "Recognize Financial Entities - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_entity_recognition",
    "relUrl": "/financial_entity_recognition"
  },
  "941": {
    "id": "941",
    "title": "Finance Question Answering in Financial NLP - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_question_answering",
    "relUrl": "/financial_question_answering"
  },
  "942": {
    "id": "942",
    "title": "Extract Financial Relationships - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_relation_extraction",
    "relUrl": "/financial_relation_extraction"
  },
  "943": {
    "id": "943",
    "title": "Finance NLP Release Notes",
    "content": "Releases log         1.0.0 1.1.0 1.2.0 1.3.0 1.4.0 1.5.0 1.6.0 1.7.0 1.8.0 1.9.0     Slack - Join #finance channel",
    "url": "/docs/en/financial_release_notes",
    "relUrl": "/docs/en/financial_release_notes"
  },
  "944": {
    "id": "944",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/financial_table_extraction",
    "relUrl": "/financial_table_extraction"
  },
  "945": {
    "id": "945",
    "title": "Version Compatibility",
    "content": "Legal NLP runs on top of johnsnowlabs library (former nlu). Please find technical documentation about how to install it here. All our models are backwards compatible, which means it will be safe for you to always use the last version of johnsnowlabs. If you are curious about which version of Spark NLP, Visual NLP or Clinical NLP are included in the last johnsnowlabs versions, please check here Finance NLP is also supported in Annotation Lab from Alab 4.2.3 version on!",
    "url": "/docs/en/financial_version_compatibility",
    "relUrl": "/docs/en/financial_version_compatibility"
  },
  "946": {
    "id": "946",
    "title": "Financial Visual Document Classification - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_visual_document_classification",
    "relUrl": "/financial_visual_document_classification"
  },
  "947": {
    "id": "947",
    "title": "Find Biomedical Entities - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/find_biomedical_entities",
    "relUrl": "/find_biomedical_entities"
  },
  "948": {
    "id": "948",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/finisher.html",
    "relUrl": "/api/python/modules/sparknlp/base/finisher.html"
  },
  "949": {
    "id": "949",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$$EachAnnotations.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$$EachAnnotations.html"
  },
  "950": {
    "id": "950",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$$ExplodeAnnotations.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$$ExplodeAnnotations.html"
  },
  "951": {
    "id": "951",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$$FilterAnnotations.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$$FilterAnnotations.html"
  },
  "952": {
    "id": "952",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$$MapAnnotations.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$$MapAnnotations.html"
  },
  "953": {
    "id": "953",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$.html"
  },
  "954": {
    "id": "954",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/functions.html",
    "relUrl": "/api/python/modules/sparknlp/functions.html"
  },
  "955": {
    "id": "955",
    "title": "",
    "content": "",
    "url": "/api/python/genindex.html",
    "relUrl": "/api/python/genindex.html"
  },
  "956": {
    "id": "956",
    "title": "German - Medical NLP Demos & Notebooks",
    "content": "",
    "url": "/german",
    "relUrl": "/german"
  },
  "957": {
    "id": "957",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/seq2seq/gpt2_transformer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/seq2seq/gpt2_transformer.html"
  },
  "958": {
    "id": "958",
    "title": "Tensorflow Graph",
    "content": "NER DL uses Char CNNs - BiLSTM - CRF Neural Network architecture. Spark NLP defines this architecture through a Tensorflow graph, which requires the following parameters: Tags Embeddings Dimension Number of Chars Spark NLP infers these values from the training dataset used in NerDLApproach annotator and tries to load the graph embedded on spark-nlp package. Currently, Spark NLP has graphs for the most common combination of tags, embeddings, and number of chars values: Tags Embeddings Dimension 10 100 10 200 10 300 10 768 10 1024 25 300 All of these graphs use an LSTM of size 128 and number of chars 100 In case, your train dataset has a different number of tags, embeddings dimension, number of chars and LSTM size combinations shown in the table above, NerDLApproach will raise an IllegalArgumentException exception during runtime with the message below: Graph [parameter] should be [value]: Could not find a suitable tensorflow graph for embeddings dim: [value] tags: [value] nChars: [value]. Check https://nlp.johnsnowlabs.com/docs/en/graph for instructions to generate the required graph. To overcome this exception message we have to follow these steps: Clone spark-nlp github repo Run python file create_models with number of tags, embeddings dimension and number of char values mentioned on your exception message error. cd spark-nlp/python/tensorflow export PYTHONPATH=lib/ner python ner/create_models.py [number_of_tags] [embeddings_dimension] [number_of_chars] [output_path] This will generate a graph on the directory defined on `output_path argument. Retry training with NerDLApproach annotator but this time use the parameter setGraphFolder with the path of your graph. Note: Make sure that you have Python 3 and Tensorflow 1.15.0 installed on your system since create_models requires those versions to generate the graph successfully. Note: We also have a notebook in the same directory if you prefer Jupyter notebook to cerate your custom graph (create_models.ipynb).",
    "url": "/docs/en/graph",
    "relUrl": "/docs/en/graph"
  },
  "959": {
    "id": "959",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/graph_extraction.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/graph_extraction.html"
  },
  "960": {
    "id": "960",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/graph_finisher.html",
    "relUrl": "/api/python/modules/sparknlp/base/graph_finisher.html"
  },
  "961": {
    "id": "961",
    "title": "Hardware Acceleration",
    "content": "",
    "url": "/docs/en/hardware_acceleration",
    "relUrl": "/docs/en/hardware_acceleration"
  },
  "962": {
    "id": "962",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/has_recursive_fit.html",
    "relUrl": "/api/python/modules/sparknlp/base/has_recursive_fit.html"
  },
  "963": {
    "id": "963",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/has_recursive_transform.html",
    "relUrl": "/api/python/modules/sparknlp/base/has_recursive_transform.html"
  },
  "964": {
    "id": "964",
    "title": "NLP Libraries Integration",
    "content": "Healthcare NLP provides an easy to use module for interacting with Annotation Lab with minimal code. In this section, you can find the instructions for performing specific operations using the annotation lab module of the Healthcare NLP library. You can execute these instructions in a python notebook (Jupyter, Colab, Kaggle, etc.). Before running the instructions described in the following sub-sections, some initial environment setup needs to be performed in order to configure the Healthcare NLP library and start a Spark session. NOTE: For using this integration a Healthcare, Finance and/or Legal NLP License key is requirend. If you do not have one, you can get it here. import json import os from google.colab import files license_keys = files.upload() with open(list(license_keys.keys())[0]) as f: license_keys = json.load(f) # Defining license key-value pairs as local variables locals().update(license_keys) # Adding license key-value pairs to environment variables os.environ.update(license_keys) NOTE: The license upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving jsl_keys.json to jsl_keys (2).json # Installing pyspark and spark-nlp ! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION # Installing Spark NLP Healthcare ! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION --extra-index-url https://pypi.johnsnowlabs.com/$SECRET # Installing Spark NLP Display Library for visualization ! pip install -q spark-nlp-display |████████████████████████████████| 212.4 MB 51 kB/s |████████████████████████████████| 616 kB 56.5 MB/s |████████████████████████████████| 198 kB 52.8 MB/s Building wheel for pyspark (setup.py) ... done |████████████████████████████████| 206 kB 2.9 MB/s |████████████████████████████████| 95 kB 2.4 MB/s |████████████████████████████████| 66 kB 4.9 MB/s |████████████████████████████████| 1.6 MB 44.7 MB/s import pandas as pd import requests import json from zipfile import ZipFile from io import BytesIO import os from pyspark.ml import Pipeline,PipelineModel from pyspark.sql import SparkSession from pyspark.sql import functions as F from sparknlp.annotator import * from sparknlp_jsl.annotator import * from sparknlp.base import * import sparknlp_jsl import sparknlp import warnings warnings.filterwarnings(&#39;ignore&#39;) params = {&quot;spark.driver.memory&quot;:&quot;16G&quot;, &quot;spark.kryoserializer.buffer.max&quot;:&quot;2000M&quot;, &quot;spark.driver.maxResultSize&quot;:&quot;2000M&quot;} print(&quot;Spark NLP Version :&quot;, sparknlp.version()) print(&quot;Spark NLP_JSL Version :&quot;, sparknlp_jsl.version()) spark = sparknlp_jsl.start(license_keys[&#39;SECRET&#39;],params=params) spark Spark NLP Version : 4.1.0 Spark NLP_JSL Version : 4.1.0 SparkSession - in-memory SparkContext Spark UI Version v3.1.2 Master local[*] AppName Spark NLP Licensed Using already exported JSON to generate training data - No Annotation Lab Credentials Required # import the module from sparknlp_jsl.alab import AnnotationLab alab = AnnotationLab() # downloading demo json !wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Annotation_Lab/data/alab_demo.json --2022-09-29 18:47:21-- https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Annotation_Lab/data/alab_demo.json Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 66538 (65K) [text/plain] Saving to: ‘alab_demo.json’ alab_demo.json 100%[===================&gt;] 64.98K --.-KB/s in 0.01s 2022-09-29 18:47:21 (5.43 MB/s) - ‘alab_demo.json’ saved [66538/66538] Generating training data for different models No Annotation Lab Credentials Required. Only the exported JSON is used. Classification Model The following snippet shows how to generate data for training a classification model. alab.get_classification_data( # required: path to Annotation Lab JSON export input_json_path=&#39;alab_demo.json&#39;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth=True ) Processing 14 annotation(s). Output:   task_id task_title text class 0 2 Note 2 The patient is a 5-month-old infant who presen… [Female] 1 3 Note 3 The patient is a 21-day-old male here for 2 da… [Male] 2 1 Note 1 On 18/08 patient declares she has a headache s… [Female] NER Model The JSON export must be converted into a CoNLL format suitable for training an NER model. alab.get_conll_data( # required: Spark session with spark-nlp-jsl jar spark=spark, # required: path to Annotation Lab JSON export input_json_path=&quot;alab_demo.json&quot;, # required: name of the CoNLL file to save output_name=&quot;conll_demo&quot;, # optional: path for CoNLL file saving directory, defaults to &#39;exported_conll&#39; save_dir=&quot;exported_conll&quot;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth=True, # optional: labels to exclude from CoNLL; these are all assertion labels and irrelevant NER labels, # defaults to empty list excluded_labels=[&#39;ABSENT&#39;], # optional: set a pattern to use regex tokenizer, defaults to regular tokenizer if pattern not defined regex_pattern=&quot; s+|(?=[-.:;*+,$&amp;% [ ]])|(?&lt;=[-.:;*+,$&amp;% [ ]])&quot; # optional: list of Annotation Lab task IDs to exclude from CoNLL, defaults to empty list # excluded_task_ids = [2, 3] # optional: list of Annotation Lab task titles to exclude from CoNLL, defaults to None # excluded_task_titles = [&#39;Note 1&#39;] ) sentence_detector_dl_healthcare download started this may take some time. Approximate size to download 367.3 KB [OK!] pos_clinical download started this may take some time. Approximate size to download 1.5 MB [OK!] Spark NLP LightPipeline is created sentence_detector_dl_healthcare download started this may take some time. Approximate size to download 367.3 KB [OK!] Spark NLP LightPipeline is created Attempting to process: Task ID# 1 Task ID# 1 is included Attempting to process: Task ID# 2 Task ID# 2 is included Attempting to process: Task ID# 3 Task ID# 3 is included Saved in location: exported_conll/conll_demo.conll Printing first 30 lines of CoNLL for inspection: [&#39;-DOCSTART- -X- -1- O n n&#39;, &#39;On II II O n&#39;, &#39;18/08 MC MC B-DATE n&#39;, &#39;patient NN NN O n&#39;, &#39;declares NNS NNS O n&#39;, &#39;she PN PN O n&#39;, &#39;has VHZ VHZ O n&#39;, &#39;a DD DD O n&#39;, &#39;headache NN NN B-PROBLEM n&#39;, &#39;since CS CS O n&#39;, &#39;06/08 MC MC B-DATE n&#39;, &#39;, NN NN O n&#39;, &#39;needs VVZ VVZ O n&#39;, &#39;to TO TO O n&#39;, &#39;get VVI VVI O n&#39;, &#39;a DD DD O n&#39;, &#39;head NN NN B-TEST n&#39;, &#39;CT NN NN I-TEST n&#39;, &#39;, NN NN O n&#39;, &#39;and CC CC O n&#39;, &#39;appears VVZ VVZ O n&#39;, &#39;anxious JJ JJ B-PROBLEM n&#39;, &#39;when CS CS O n&#39;, &#39;she PN PN O n&#39;, &#39;walks RR RR O n&#39;, &#39;fast JJ JJ O n&#39;, &#39;. NN NN O n&#39;, &#39;No NN NN O n&#39;, &#39;alopecia NN NN B-PROBLEM n&#39;, &#39;noted VVNJ VVNJ O n&#39;] Assertion Model The JSON export is converted into a dataframe, suitable for training an assertion model. alab.get_assertion_data( # required: SparkSession with spark-nlp-jsl jar spark=spark, # required: path to Annotation Lab JSON export input_json_path = &#39;alab_demo.json&#39;, # required: annotated assertion labels to train on assertion_labels = [&#39;ABSENT&#39;], # required: relevant NER labels that are assigned assertion labels relevant_ner_labels = [&#39;PROBLEM&#39;, &#39;TREATMENT&#39;], # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth = True, # optional: assertion label to assign to entities that have no assertion labels, defaults to None unannotated_label = &#39;PRESENT&#39;, # optional: set a pattern to use regex tokenizer, defaults to regular tokenizer if pattern not defined regex_pattern = &quot; s+|(?=[-.:;*+,$&amp;% [ ]])|(?&lt;=[-.:;*+,$&amp;% [ ]])&quot;, # optional: set the strategy to control the number of occurrences of the unannotated assertion label # in the output dataframe, options are &#39;weighted&#39; or &#39;counts&#39;, &#39;weighted&#39; allows to sample using a # fraction, &#39;counts&#39; allows to sample using absolute counts, defaults to None unannotated_label_strategy = &#39;weighted&#39;, # optional: dictionary in the format {&#39;ENTITY_LABEL&#39;: sample_weight_or_counts} to control the number of # occurrences of the unannotated assertion label in the output dataframe, where &#39;ENTITY_LABEL&#39; are the # NER labels that are assigned the unannotated assertion label, and sample_weight_or_counts should be # between 0 and 1 if `unannotated_label_strategy` is &#39;weighted&#39; or between 0 and the max number of # occurrences of that NER label if `unannotated_label_strategy` is &#39;counts&#39; unannotated_label_strategy_dict = {&#39;PROBLEM&#39;: 0.5, &#39;TREATMENT&#39;: 0.5}, # optional: list of Annotation Lab task IDs to exclude from output dataframe, defaults to None # excluded_task_ids = [2, 3] # optional: list of Annotation Lab task titles to exclude from output dataframe, defaults to None # excluded_task_titles = [&#39;Note 1&#39;] ) sentence_detector_dl_healthcare download started this may take some time. Approximate size to download 367.3 KB [OK!] Spark NLP LightPipeline is created Processing Task ID# 2 Processing Task ID# 3 Processing Task ID# 1 Output:   task_id title text target ner_label label start end 0 1 Note 1 On 18/08 patient declares she has a headache s… headache PROBLEM PRESENT 7 7 1 1 Note 1 On 18/08 patient declares she has a headache s… alopecia PROBLEM ABSENT 27 27 2 1 Note 1 On 18/08 patient declares she has a headache s… pain PROBLEM ABSENT 32 32 3 2 Note 2 Mom states she had no fever. fever PROBLEM ABSENT 5 5 4 2 Note 2 She had no difficulty breathing and her cough … difficulty breathing PROBLEM ABSENT 3 4 5 2 Note 2 She had no difficulty breathing and her cough … cough PROBLEM PRESENT 7 7 6 2 Note 2 She had no difficulty breathing and her cough … dry PROBLEM PRESENT 11 11 7 2 Note 2 She had no difficulty breathing and her cough … hacky PROBLEM PRESENT 13 13 8 2 Note 2 At that time, physical exam showed no signs of… flu PROBLEM ABSENT 10 10 9 3 Note 3 The patient is a 21-day-old male here for 2 da… congestion PROBLEM PRESENT 15 15 10 3 Note 3 The patient is a 21-day-old male here for 2 da… suctioning yellow discharge TREATMENT PRESENT 23 25 11 3 Note 3 The patient is a 21-day-old male here for 2 da… perioral cyanosis PROBLEM ABSENT 47 48 12 3 Note 3 One day ago, mom also noticed a tactile temper… tactile temperature PROBLEM PRESENT 8 9 Relation Extraction Model The JSON export is converted into a dataframe suitable for training a relation extraction model. alab.get_relation_extraction_data( # required: Spark session with spark-nlp-jsl jar spark=spark, # required: path to Annotation Lab JSON export input_json_path=&#39;alab_demo.json&#39;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth=True, # optional: set to True to assign a relation label between entities where no relation was annotated, # defaults to False negative_relations=True, # optional: all assertion labels that were annotated in the Annotation Lab, defaults to None assertion_labels=[&#39;ABSENT&#39;], # optional: plausible pairs of entities for relations, separated by a &#39;-&#39;, use the same casing as the # annotations, include only one relation direction, defaults to all possible pairs of annotated entities relation_pairs=[&#39;DATE-PROBLEM&#39;,&#39;TREATMENT-PROBLEM&#39;,&#39;TEST-PROBLEM&#39;], # optional: set the strategy to control the number of occurrences of the negative relation label # in the output dataframe, options are &#39;weighted&#39; or &#39;counts&#39;, &#39;weighted&#39; allows to sample using a # fraction, &#39;counts&#39; allows to sample using absolute counts, defaults to None negative_relation_strategy=&#39;weighted&#39;, # optional: dictionary in the format {&#39;ENTITY1-ENTITY2&#39;: sample_weight_or_counts} to control the number of # occurrences of negative relations in the output dataframe for each entity pair, where &#39;ENTITY1-ENTITY2&#39; # represent the pairs of entities for relations separated by a `-` (include only one relation direction), # and sample_weight_or_counts should be between 0 and 1 if `negative_relation_strategy` is &#39;weighted&#39; or # between 0 and the max number of occurrences of negative relations if `negative_relation_strategy` is # &#39;counts&#39;, defaults to None negative_relation_strategy_dict = {&#39;DATE-PROBLEM&#39;: 0.1, &#39;TREATMENT-PROBLEM&#39;: 0.5, &#39;TEST-PROBLEM&#39;: 0.2}, # optional: list of Annotation Lab task IDs to exclude from output dataframe, defaults to None # excluded_task_ids = [2, 3] # optional: list of Annotation Lab task titles to exclude from output dataframe, defaults to None # excluded_task_titles = [&#39;Note 1&#39;] ) Successfully processed relations for task: Task ID# 2 Successfully processed relations for task: Task ID# 3 Successfully processed relations for task: Task ID# 1 Total tasks processed: 3 Total annotated relations processed: 10 sentence_detector_dl_healthcare download started this may take some time. Approximate size to download 367.3 KB [OK!] Successfully processed NER labels for: Task ID# 2 Successfully processed NER labels for: Task ID# 3 Successfully processed NER labels for: Task ID# 1 Total tasks processed: 3 Total annotated NER labels processed: 28 Output:   task_id title sentence firstCharEnt1 firstCharEnt2 lastCharEnt1 lastCharEnt2 chunk1 chunk2 label1 label2 rel 0 1 Note 1 On 18/08 patient declares she has a headache s… 36 51 44 56 headache 06/08 PROBLEM DATE is_date_of 1 1 Note 1 On 18/08 patient declares she has a headache s… 36 73 44 80 headache head CT PROBLEM TEST is_test_of 2 1 Note 1 On 18/08 patient declares she has a headache s… 51 156 56 160 06/08 pain DATE PROBLEM O 3 1 Note 1 On 18/08 patient declares she has a headache s… 73 126 80 134 head CT alopecia TEST PROBLEM O 4 2 Note 2 At that time, physical exam showed no signs of… 14 47 27 50 physical exam flu TEST PROBLEM is_test_of 5 2 Note 2 The patient is a 5-month-old infant who presen… 63 76 68 80 Feb 8 cold DATE PROBLEM is_date_of 6 2 Note 2 The patient is a 5-month-old infant who presen… 63 82 68 87 Feb 8 cough DATE PROBLEM is_date_of 7 2 Note 2 The patient is a 5-month-old infant who presen… 63 93 68 103 Feb 8 runny nose DATE PROBLEM is_date_of 8 2 Note 2 The patient is a 5-month-old infant who presen… 82 110 87 115 cough Feb 2 PROBLEM DATE O 9 3 Note 3 One day ago, mom also noticed a tactile temper… 32 73 51 80 tactile temperature Tylenol PROBLEM TREATMENT is_treatment_of 10 3 Note 3 The patient is a 21-day-old male here for 2 da… 52 69 62 77 congestion Nov 8/15 PROBLEM DATE is_date_of 11 3 Note 3 The patient is a 21-day-old male here for 2 da… 52 93 62 120 congestion suctioning yellow discharge PROBLEM TREATMENT is_treatment_of 12 3 Note 3 The patient is a 21-day-old male here for 2 da… 93 244 120 261 suctioning yellow discharge perioral cyanosis TREATMENT PROBLEM O 13 3 Note 3 The patient is a 21-day-old male here for 2 da… 93 265 120 276 suctioning yellow discharge retractions TREATMENT PROBLEM O 14 3 Note 3 The patient is a 21-day-old male here for 2 da… 173 217 196 225 mild breathing problems Nov 9/15 PROBLEM DATE is_date_of Generate Pre-annotations using Spark NLP pipelines No Annotation Lab credentials are required. The first step is to define the Healthcare NLP pipeline. The same procedure can be followed for Legal and Finance NLP pipelines. document = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&#39;document&#39;]) .setOutputCol(&#39;sentence&#39;) .setCustomBounds([&#39; n&#39;]) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel().pretrained(&#39;embeddings_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &#39;token&#39;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&#39;ner_jsl&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) assertion_model = AssertionDLModel().pretrained(&#39;assertion_dl&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &#39;embeddings&#39;]) .setOutputCol(&quot;assertion_res&quot;) pos_tagger = PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;pos_tags&quot;, &quot;token&quot;]) .setOutputCol(&quot;dependencies&quot;) relation_clinical = RelationExtractionModel.pretrained(&#39;re_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunk&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations_clinical&quot;) .setRelationPairs([&#39;procedure-disease_syndrome_disorder&#39;, &#39;test-oncological&#39;, &#39;test-disease_syndrome_disorder&#39;, &#39;external_body_part_or_region-procedure&#39;, &#39;oncological-external_body_part_or_region&#39;, &#39;oncological-procedure&#39;]) .setMaxSyntacticDistance(0) relation_pos = RelationExtractionModel.pretrained(&#39;posology_re&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunk&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations_pos&quot;) .setRelationPairs([&#39;drug_ingredient-drug_brandname&#39;, &#39;drug_ingredient-dosage&#39;, &#39;drug_ingredient-strength&#39;, &#39;drug_ingredient-route&#39;]) .setMaxSyntacticDistance(0) ner_pipeline = Pipeline( stages = [ document, sentence, tokenizer, word_embeddings, ner_model, converter, assertion_model, pos_tagger, dependency_parser, relation_clinical, relation_pos ]) empty_data = spark.createDataFrame([[&#39;&#39;]]).toDF(&quot;text&quot;) pipeline_model = ner_pipeline.fit(empty_data) lmodel = LightPipeline(pipeline_model) embeddings_clinical download started this may take some time. Approximate size to download 1.6 GB [OK!] ner_jsl download started this may take some time. [OK!] assertion_dl download started this may take some time. [OK!] pos_clinical download started this may take some time. Approximate size to download 1.5 MB [OK!] dependency_conllu download started this may take some time. Approximate size to download 16.7 MB [OK!] re_clinical download started this may take some time. Approximate size to download 6 MB [OK!] Run on sample tasks txt1 = &quot;The patient is a 21-day-old male here for 2 days of congestion since Nov 8/15 - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild breathing problems while feeding since Nov 9/15 (without signs of perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol.&quot; txt2 = &quot;The patient is a 5-month-old infant who presented initially on Feb 8 with a cold, cough, and runny nose since Feb 2. Mom states she had no fever. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed no signs of flu.&quot; task_list = [txt1, txt2] results = lmodel.fullAnnotate(task_list) # full pipeline: # results = pipeline_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: task_list}))).collect() Generate pre-annotation JSON using pipeline results pre_annotations, summary = alab.generate_preannotations( # required: list of results. all_results = results, # requied: output column name of &#39;DocumentAssembler&#39; stage - to get original document string. document_column = &#39;document&#39;, # required: column name(s) of ner model(s). Note: multiple NER models can be used, but make sure their results don&#39;t overrlap. # Or use &#39;ChunkMergeApproach&#39; to combine results from multiple NER models. ner_columns = [&#39;ner_chunk&#39;], # optional: column name(s) of assertion model(s). Note: multiple assertion models can be used, but make sure their results don&#39;t overrlap. assertion_columns = [&#39;assertion_res&#39;], # optional: column name(s) of relation extraction model(s). Note: multiple relation extraction models can be used, but make sure their results don&#39;t overrlap. relations_columns = [&#39;relations_clinical&#39;, &#39;relations_pos&#39;], # optional: This can be defined to identify which pipeline/user/model was used to get predictions. # Default: &#39;model&#39; user_name = &#39;model&#39;, # optional: Option to assign custom titles to tasks. By default, tasks will be titled as &#39;task_#&#39; titles_list = [], # optional: If there are already tasks in project, then this id offset can be used to make sure default titles &#39;task_#&#39; do not overlap. # While upload a batch after the first one, this can be set to number of tasks currently present in the project # This number would be added to each tasks&#39;s ID and title. id_offset=0 ) Processing 2 Annotations. The Generated JSON can be uploaded to Annotation Lab to particular project directly via UI or via API. pre_annotations [{&#39;predictions&#39;: [{&#39;created_username&#39;: &#39;model&#39;, &#39;result&#39;: [{&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;YCtU7EDvme&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 27, &#39;labels&#39;: [&#39;Age&#39;], &#39;start&#39;: 17, &#39;text&#39;: &#39;21-day-old&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;xqbYIUPhhB&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 32, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 28, &#39;text&#39;: &#39;male&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;7GYr3DFbAs&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 48, &#39;labels&#39;: [&#39;Duration&#39;], &#39;start&#39;: 38, &#39;text&#39;: &#39;for 2 days&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;akBx3N0Gy2&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 62, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 52, &#39;text&#39;: &#39;congestion&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;TJKowx9hR2&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 77, &#39;labels&#39;: [&#39;Date&#39;], &#39;start&#39;: 69, &#39;text&#39;: &#39;Nov 8/15&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;UuWHo6pGz8&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 83, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 80, &#39;text&#39;: &#39;mom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;qIgnDgSJw6&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 110, &#39;labels&#39;: [&#39;Modifier&#39;], &#39;start&#39;: 104, &#39;text&#39;: &#39;yellow&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;DkE8rIoKVg&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 120, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 111, &#39;text&#39;: &#39;discharge&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;RBjrHSa1sj&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 145, &#39;labels&#39;: [&#39;External_body_part_or_region&#39;], &#39;start&#39;: 140, &#39;text&#39;: &#39;nares&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;yHEPWvrk9s&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 155, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 152, &#39;text&#39;: &#39;she&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;dbeel0WXqw&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 177, &#39;labels&#39;: [&#39;Modifier&#39;], &#39;start&#39;: 173, &#39;text&#39;: &#39;mild&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;cFJwsYMe2k&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 210, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 178, &#39;text&#39;: &#39;breathing problems while feeding&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;PhiSDTDXlV&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 225, &#39;labels&#39;: [&#39;Date&#39;], &#39;start&#39;: 217, &#39;text&#39;: &#39;Nov 9/15&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;lsGep4SLRn&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 261, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 244, &#39;text&#39;: &#39;perioral cyanosis&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;WiTJIGOZ9Z&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 276, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 265, &#39;text&#39;: &#39;retractions&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;omIdHl5z74&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 290, &#39;labels&#39;: [&#39;RelativeDate&#39;], &#39;start&#39;: 279, &#39;text&#39;: &#39;One day ago&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;CqDclquhmD&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 295, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 292, &#39;text&#39;: &#39;mom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;u8Q3GTVzZh&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 359, &#39;labels&#39;: [&#39;Drug_BrandName&#39;], &#39;start&#39;: 352, &#39;text&#39;: &#39;Tylenol&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;i2JLPQOUxv&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 27, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 17, &#39;text&#39;: &#39;Age&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;QShr4s6bpg&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 32, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 28, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;800DYq0quS&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 48, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 38, &#39;text&#39;: &#39;Duration&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;ns3P70kktN&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 62, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 52, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;tQOdI1ANUO&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 77, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 69, &#39;text&#39;: &#39;Date&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;oEwYVnyi2A&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 83, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 80, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;PkCkXQEIFN&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 110, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 104, &#39;text&#39;: &#39;Modifier&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;m9Bz8CzaXd&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 120, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 111, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;GBIhXo8nks&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 145, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 140, &#39;text&#39;: &#39;External_body_part_or_region&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;CDVDDIwVrl&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 155, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 152, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;CHPuFoT9iK&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 177, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 173, &#39;text&#39;: &#39;Modifier&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;eS4vXGth7v&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 210, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 178, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;2nDgfsoGZ7&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 225, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 217, &#39;text&#39;: &#39;Date&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;dhYC0U4sKG&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 261, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 244, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;TKN6DIP2ua&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 276, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 265, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;7X9EwULTA1&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 290, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 279, &#39;text&#39;: &#39;RelativeDate&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;UIFKYTDKcm&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 295, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 292, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;U6TqOYf3Ez&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 359, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 352, &#39;text&#39;: &#39;Drug_BrandName&#39;}}]}], &#39;data&#39;: {&#39;title&#39;: &#39;task_0&#39;, &#39;text&#39;: &quot;The patient is a 21-day-old male here for 2 days of congestion since Nov 8/15 - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild breathing problems while feeding since Nov 9/15 (without signs of perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol.&quot;}, &#39;id&#39;: 0}, {&#39;predictions&#39;: [{&#39;created_username&#39;: &#39;model&#39;, &#39;result&#39;: [{&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;qd28OkdmDO&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 28, &#39;labels&#39;: [&#39;Age&#39;], &#39;start&#39;: 17, &#39;text&#39;: &#39;5-month-old&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;UIZm8wCy3c&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 35, &#39;labels&#39;: [&#39;Age&#39;], &#39;start&#39;: 29, &#39;text&#39;: &#39;infant&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;KpMv4PIy21&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 68, &#39;labels&#39;: [&#39;Date&#39;], &#39;start&#39;: 63, &#39;text&#39;: &#39;Feb 8&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;Uyj3awC8jp&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 80, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 76, &#39;text&#39;: &#39;cold&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;Dt3xtm1l5A&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 87, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 82, &#39;text&#39;: &#39;cough&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;bp9yUFAUaE&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 103, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 93, &#39;text&#39;: &#39;runny nose&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;QhuFKxwFVk&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 113, &#39;labels&#39;: [&#39;Date&#39;], &#39;start&#39;: 110, &#39;text&#39;: &#39;Feb&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;m9ikgaeJMY&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 120, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 117, &#39;text&#39;: &#39;Mom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;QXhhDJ6CXn&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 131, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 128, &#39;text&#39;: &#39;she&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;YUCHE7GcHB&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 144, &#39;labels&#39;: [&#39;VS_Finding&#39;], &#39;start&#39;: 139, &#39;text&#39;: &#39;fever&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;xbphfajGY1&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 149, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 146, &#39;text&#39;: &#39;She&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;xN5GuZpeUw&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 177, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 157, &#39;text&#39;: &#39;difficulty breathing&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;VK9lAjcVNy&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 185, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 182, &#39;text&#39;: &#39;her&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;dqiohcfX4G&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 191, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 186, &#39;text&#39;: &#39;cough&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;18bjvjxuDL&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 212, &#39;labels&#39;: [&#39;Modifier&#39;], &#39;start&#39;: 209, &#39;text&#39;: &#39;dry&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;BB90sIXIYZ&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 274, &#39;labels&#39;: [&#39;Disease_Syndrome_Disorder&#39;], &#39;start&#39;: 271, &#39;text&#39;: &#39;flu&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;sAL9AHWvOa&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 28, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 17, &#39;text&#39;: &#39;Age&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;vyio7vnpmS&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 35, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 29, &#39;text&#39;: &#39;Age&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;r6T6e8WmO9&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 68, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 63, &#39;text&#39;: &#39;Date&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;3SdFeft6ya&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 80, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 76, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;0iyfhRx1nl&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 87, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 82, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;pqJFZRu8Zu&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 103, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 93, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;zRa9noedl5&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 113, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 110, &#39;text&#39;: &#39;Date&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;RJ8MHb5Css&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 120, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 117, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;sbtQpMnkxH&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 131, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 128, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;K0yEKeG7GR&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 144, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 139, &#39;text&#39;: &#39;VS_Finding&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;V4fTVAh4Ro&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 149, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 146, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;1K1NUt9mcU&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 177, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 157, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;kXl3bnMSqM&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 185, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 182, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;spqjsrISZg&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 191, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 186, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;EcrKDs2yyH&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 212, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 209, &#39;text&#39;: &#39;Modifier&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;FHYcyz14aj&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 274, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 271, &#39;text&#39;: &#39;Disease_Syndrome_Disorder&#39;}}]}], &#39;data&#39;: {&#39;title&#39;: &#39;task_1&#39;, &#39;text&#39;: &#39;The patient is a 5-month-old infant who presented initially on Feb 8 with a cold, cough, and runny nose since Feb 2. Mom states she had no fever. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed no signs of flu.&#39;}, &#39;id&#39;: 1}] An annotation summary is also generated that can be used to setup and configure a new project. { &#39;ner_labels&#39;: [ &#39;Age&#39;, &#39;VS_Finding&#39;, &#39;Gender&#39;, &#39;Modifier&#39;, &#39;Duration&#39;, &#39;RelativeDate&#39;, &#39;Symptom&#39;, &#39;Date&#39;, &#39;External_body_part_or_region&#39;, &#39;Disease_Syndrome_Disorder&#39;, &#39;Drug_BrandName&#39; ], &#39;assertion_labels&#39;: [&#39;present&#39;, &#39;absent&#39;], &#39;re_labels&#39;: [] } Interacting with Annotation Lab Credentials are required for the following actions. Set Credentials alab = AnnotationLab() username=&#39;&#39; password=&#39;&#39; client_secret=&quot;&quot; annotationlab_url=&quot;&quot; alab.set_credentials( # required: username username=username, # required: password password=password, # required: secret for you Annotation Lab instance (every Annotation Lab installation has a different secret) client_secret=client_secret, # required: http(s) url for you annotation lab annotationlab_url=annotationlab_url ) Get All visible projects alab.get_all_projects() Operation completed successfully. Response code: 200 {&#39;has_next&#39;: False, &#39;has_prev&#39;: False, &#39;items&#39;: [{&#39;creation_date&#39;: &#39;Thu, 29 Sep 2022 18:01:07 GMT&#39;, &#39;group_color&#39;: None, &#39;group_id&#39;: None, &#39;group_name&#39;: None, &#39;owner&#39;: &#39;hasham&#39;, &#39;owner_id&#39;: &#39;ba60df4b-7192-47ca-aa92-759fa577a617&#39;, &#39;project_description&#39;: &#39;&#39;, &#39;project_id&#39;: 1129, &#39;project_members&#39;: [&#39;hasham&#39;], &#39;project_name&#39;: &#39;alab_demo&#39;, &#39;resource_id&#39;: &#39;1dabaac8-54a0-4c52-a876-8c01f42b44e7&#39;, &#39;total_tasks&#39;: 2}, {&#39;creation_date&#39;: &#39;Tue, 27 Sep 2022 03:12:18 GMT&#39;, &#39;group_color&#39;: None, &#39;group_id&#39;: None, &#39;group_name&#39;: None, &#39;owner&#39;: &#39;hasham&#39;, &#39;owner_id&#39;: &#39;ba60df4b-7192-47ca-aa92-759fa577a617&#39;, &#39;project_description&#39;: &#39;&#39;, &#39;project_id&#39;: 1117, &#39;project_members&#39;: [&#39;hasham&#39;], &#39;project_name&#39;: &#39;testing101&#39;, &#39;resource_id&#39;: &#39;b1388775-9a3b-436e-b1cc-ea36bab44699&#39;, &#39;total_tasks&#39;: 9}, {&#39;creation_date&#39;: &#39;Fri, 06 Nov 2020 12:08:02 GMT&#39;, &#39;group_color&#39;: &#39;#dbdf2e&#39;, &#39;group_id&#39;: 10, &#39;group_name&#39;: &#39;MT_Samples&#39;, &#39;owner&#39;: &#39;mauro&#39;, &#39;owner_id&#39;: &#39;7b6048c8-f923-46e4-9011-2c749e3c2c93&#39;, &#39;project_description&#39;: &#39;&#39;, &#39;project_id&#39;: 126, &#39;project_members&#39;: [], &#39;project_name&#39;: &#39;PathologyReports&#39;, &#39;resource_id&#39;: &#39;7ed36c55-db19-48e0-bc56-4b2114f9a251&#39;, &#39;total_tasks&#39;: 97}], &#39;iter_pages&#39;: [1], &#39;next_num&#39;: None, &#39;prev_num&#39;: None, &#39;total_count&#39;: 3} Create a new project alab.create_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: other details about project. Default: Empty string project_description=&#39;&#39;, # optional: Sampling option of tasks. Default: random project_sampling=&#39;&#39;, # optional: Annotation Guidelines of project project_instruction=&#39;&#39; ) Operation completed successfully. Response code: 201 {&#39;project_name&#39;: &#39;alab_demo&#39;} Delete a project alab.delete_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: confirmation for deletion. Default: False - will ask for confirmation. If set to true, will delete directly. confirm=False ) Deleting Project. Press &quot;Y&quot; to confirm.y Operation completed successfully. Response code: 200 {&#39;message&#39;: &#39;Project successfully Deleted!&#39;} Set / Edit configuration of a project ## First, recreate a project alab.create_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: other details about project. Default: Empty string project_description=&#39;&#39;, # optional: Sampling option of tasks. Default: random project_sampling=&#39;&#39;, # optional: Annotation Guidelines of project project_instruction=&#39;&#39; ) Operation completed successfully. Response code: 201 {&#39;project_name&#39;: &#39;alab_demo&#39;} Set Configuration - First Time ## set configuration - first time alab.set_project_config( # required: name of project project_name = &#39;alab_demo&#39;, # optional: labels of classes for classification tasks classification_labels=[&#39;Male&#39;, &#39;Female&#39;], # optional: labels of classes for classification tasks ner_labels=[&#39;Age&#39;, &#39;Symptom&#39;, &#39;Procedure&#39;, &#39;BodyPart&#39;], # optional: labels of classes for classification tasks assertion_labels=[&#39;absent&#39;, &#39;family_history&#39;, &#39;someone_else&#39;], # optional: labels of classes for classification tasks relations_labels=[&#39;is_related&#39;] ) Operation completed successfully. Response code: 201 {&#39;messages&#39;: [{&#39;message&#39;: &#39;Project config saved.&#39;, &#39;success&#39;: True}]} Edit Configuration - add classes and labels ## Note: At least one type of labels should be provided. ## Note: to define relation labels, NER labels should be provided. alab.set_project_config( # required: name of project project_name = &#39;alab_demo&#39;, # optional: labels of classes for classification tasks classification_labels=[&#39;Male&#39;, &#39;Female&#39;, &#39;Unknown&#39;], # optional: labels of classes for classification tasks ner_labels=[&#39;Age&#39;, &#39;Symptom&#39;, &#39;Procedure&#39;, &#39;BodyPart&#39;, &#39;Test&#39;, &#39;Drug&#39;], # optional: labels of classes for classification tasks assertion_labels=[&#39;absent&#39;, &#39;family_history&#39;, &#39;someone_else&#39;], # optional: labels of classes for classification tasks relations_labels=[&#39;is_related&#39;, &#39;is_reactioni_of&#39;] ) Operation completed successfully. Response code: 201 {&#39;messages&#39;: [{&#39;message&#39;: &#39;Project config saved.&#39;, &#39;success&#39;: True}]} Set Configuration using summary generated at the pre-annotation step alab.set_project_config( # required: name of project project_name = &#39;alab_demo&#39;, # optional: labels of classes for classification tasks classification_labels=[&#39;Male&#39;, &#39;Female&#39;, &#39;Unknown&#39;], # optional: labels of classes for classification tasks ner_labels=summary[&#39;ner_labels&#39;], # optional: labels of classes for classification tasks assertion_labels=summary[&#39;assertion_labels&#39;], # optional: labels of classes for classification tasks relations_labels=[&#39;is_related&#39;, &#39;is_reactioni_of&#39;] ) Operation completed successfully. Response code: 201 {&#39;messages&#39;: [{&#39;message&#39;: &#39;Project config saved.&#39;, &#39;success&#39;: True}]} Get configuration of any project alab.get_project_config( # required: name of project project_name = &#39;alab_demo&#39; ) Operation completed successfully. Response code: 200 {&#39;analytics_permission&#39;: {}, &#39;annotators&#39;: [&#39;hasham&#39;], &#39;config&#39;: {&#39;allow_delete_completions&#39;: True, &#39;debug&#39;: False, &#39;editor&#39;: {&#39;debug&#39;: False}, &#39;enable_predictions_button&#39;: True, &#39;input_path&#39;: None, &#39;instruction&#39;: &#39;&#39;, &#39;ml_backends&#39;: [], &#39;output_dir&#39;: &#39;completions&#39;, &#39;port&#39;: 8200, &#39;sampling&#39;: &#39;uniform&#39;, &#39;templates_dir&#39;: &#39;examples&#39;, &#39;title&#39;: &#39;alab_demo&#39;}, &#39;created_version&#39;: &#39;4.0.1&#39;, &#39;creation_date&#39;: &#39;Thu, 29 Sep 2022 18:46:02 GMT&#39;, &#39;evaluation_info&#39;: None, &#39;group_id&#39;: None, &#39;isVisualNER&#39;: None, &#39;label_config&#39;: &#39;&#39;, &#39;labels&#39;: [&#39;Age&#39;, &#39;VS_Finding&#39;, &#39;Gender&#39;, &#39;Modifier&#39;, &#39;Duration&#39;, &#39;RelativeDate&#39;, &#39;Symptom&#39;, &#39;Date&#39;, &#39;External_body_part_or_region&#39;, &#39;Disease_Syndrome_Disorder&#39;, &#39;Drug_BrandName&#39;, &#39;present&#39;, &#39;absent&#39;], &#39;model_types&#39;: [{&#39;choices&#39;: [&#39;sentiment&#39;], &#39;name&#39;: &#39;classification&#39;}, {&#39;name&#39;: &#39;ner&#39;}, {&#39;name&#39;: &#39;assertion&#39;}], &#39;ocr_info&#39;: None, &#39;owner&#39;: {&#39;id&#39;: &#39;ba60df4b-7192-47ca-aa92-759fa577a617&#39;, &#39;username&#39;: &#39;hasham&#39;}, &#39;project_description&#39;: &#39;&#39;, &#39;project_id&#39;: 1130, &#39;project_name&#39;: &#39;alab_demo&#39;, &#39;resource_id&#39;: &#39;e8e17001-a25b-4a92-b419-88948d917647&#39;, &#39;tasks_count&#39;: 0, &#39;team_members_order&#39;: [&#39;hasham&#39;]} Upload tasks to a project # Define a list of tasks/string to upload txt1 = &quot;The patient is a 21-day-old male here for 2 days of congestion since Nov 8/15 - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild breathing problems while feeding since Nov 9/15 (without signs of perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol.&quot; txt2 = &quot;The patient is a 5-month-old infant who presented initially on Feb 8 with a cold, cough, and runny nose since Feb 2. Mom states she had no fever. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed no signs of flu.&quot; task_list = [txt1, txt2] alab.upload_tasks( # required: name of project to upload tasks to project_name=&#39;alab_demo&#39;, # required: list of examples / tasks as string (One string is one task). task_list=task_list, # optional: Option to assign custom titles to tasks. By default, tasks will be titled as &#39;task_#&#39; title_list = [], # optional: If there are already tasks in project, then this id offset can be used to make sure default titles &#39;task_#&#39; do not overlap. # While upload a batch after the first one, this can be set to number of tasks currently present in the project # This number would be added to each tasks&#39;s ID and title. id_offset=0 ) Uploading 2 task(s). Operation completed successfully. Response code: 201 {&#39;completion_count&#39;: 0, &#39;duration&#39;: 0.11868953704833984, &#39;failed_count&#39;: 0, &#39;ignored_count&#39;: 0, &#39;prediction_count&#39;: 0, &#39;task_count&#39;: 2, &#39;task_ids&#39;: [1, 2], &#39;task_title_warning&#39;: 0, &#39;updated_count&#39;: 0} Delete tasks of a project alab.delete_tasks( # required: name of project to upload tasks to project_name=&#39;alab_demo&#39;, # required: list of ids of tasks. # note: you can get task ids from the above step. Look for &#39;task_ids&#39; key. task_ids=[1, 2], # optional: confirmation for deletion. Default: False - will ask for confirmation. If set to true, will delete directly. confirm=False ) Deleting 2 task(s). Press &quot;Y&quot; to confirm.y Operation completed successfully. Response code: 200 {&#39;message&#39;: &#39;Task(s) successfully deleted!&#39;} Upload pre-annotations to Annotation Lab You can get the data for pre_annotations from this section. alab.upload_preannotations( # required: name of project to upload annotations to project_name = &#39;alab_demo&#39;, # required: preannotation JSON preannotations = pre_annotations ) Uploading 2 preannotation(s). Operation completed successfully. Response code: 201 {&#39;completion_count&#39;: 0, &#39;duration&#39;: 0.14992427825927734, &#39;failed_count&#39;: 0, &#39;ignored_count&#39;: 0, &#39;prediction_count&#39;: 2, &#39;task_count&#39;: 2, &#39;task_ids&#39;: [1, 2], &#39;task_title_warning&#39;: 0, &#39;updated_count&#39;: 0}",
    "url": "/docs/en/alab/healthcare",
    "relUrl": "/docs/en/alab/healthcare"
  },
  "965": {
    "id": "965",
    "title": "Risk Adjustments Score Calculation",
    "content": "Our Risk Adjustment Score implementation uses the Hierarchical Condition Category (HCC) Risk Adjustment model from the Centers for Medicare &amp; Medicaid Service (CMS). HCC groups similar conditions in terms of healthcare costs and similarities in the diagnosis, and the model uses any ICD code that has a corresponging HCC category in the computation, discarding other ICD codes. This module supports versions 22, 23, and 24 of the CMS-HCC risk adjustment model and needs the following parameters in order to calculate the risk score: ICD Codes (Obtained by, e.g., our pretrained model sbiobertresolve_icd10cm_augmented_billable_hcc from theSentenceEntityResolverModel annotator) Age (Obtained by, e.g., our pretrained model ner_jsl from theNerModel annotator) Gender (Obtained by, e.g., our pretrained model classifierdl_gender_biobert from theClassifierDLModel annotator) The eligibility segment of the patient (information from the health plan provider) The original reason for entitlement (information from the health plan provider) If the patient is in Medicaid or not (information from the health plan provider) Available softwares and profiles As mentioned, we implemented versions 22, 23, and 24 of the CMS-HCC software, and have the following profiles: Version 22 Year 2017 Year 2018 Year 2019 Year 2020 Year 2021 Year 2022 Version 23 Year 2018 Year 2019 Version 24 Year 2017 Year 2018 Year 2019 Year 2020 Year 2021 Year 2022 Usage The module can perform the computations given a data frame containing the required information (Age, Gender, ICD codes, eligibility segment, the original reason for entitlement, and if the patient is in Medicaid or not). For example, given the dataset df: +--++--+-++--+-+--+-+ | filename|Age| icd10_code|Extracted_Entities_vs_ICD_Codes|Gender|eligibility|orec|medicaid| DOB| +--++--+-++--+-+--+-+ |mt_note_03.txt| 66|[C499, C499, D618...| [{leiomyosarcoma,...| F| CND| 1| false|1956-05-30| |mt_note_01.txt| 59| [C801]| [{cancer, C801}]| F| CFA| 0| true|1961-10-12| |mt_note_10.txt| 16| [C6960, C6960]| [{Rhabdomyosarcom...| M| CFA| 2| false|2006-02-14| |mt_note_08.txt| 66| [C459, C800]| [{malignant mesot...| F| CND| 1| true|1956-03-17| |mt_note_09.txt| 19| [D5702, K5505]| [{Sickle cell cri...| M| CPA| 3| true|2003-06-11| |mt_note_05.txt| 57|[C5092, C5091, C5...| [{Breast Cancer, ...| F| CPA| 3| true|1963-08-12| |mt_note_06.txt| 63| [F319, F319]| [{type 1 bipolar ...| F| CFA| 0| false|1959-07-24| +--++--+-++--+-+--+-+ Where column orec means original reason for entitlement and DOB means date of birth (can also be used to compute age). You can use any of the available profiles to compute the scores (in the example, we use version 24, year 2020): from johnsnowlabs import medical # Creates the risk profile df = df.withColumn( &quot;hcc_profile&quot;, medical.profileV24Y20( df.icd10_code, df.Age, df.Gender, df.eligibility, df.orec, df.medicaid ), ) # Extract relevant information df = ( df.withColumn(&quot;risk_score&quot;, df.hcc_profile.getItem(&quot;risk_score&quot;)) .withColumn(&quot;hcc_lst&quot;, df.hcc_profile.getItem(&quot;hcc_lst&quot;)) .withColumn(&quot;parameters&quot;, df.hcc_profile.getItem(&quot;parameters&quot;)) .withColumn(&quot;details&quot;, df.hcc_profile.getItem(&quot;details&quot;)) ) df.select( &quot;filename&quot;, &quot;risk_score&quot;, &quot;icd10_code&quot;, &quot;Age&quot;, &quot;Gender&quot;, &quot;eligibility&quot;, &quot;orec&quot;, &quot;medicaid&quot;, ).show(truncate=False) +--+-++++--+-+--+ filename |risk_score|icd10_code |Age|Gender|eligibility|orec|medicaid| +--+-++++--+-+--+ mt_note_01.txt|0.158 |[C801] |59 |F |CFA |0 |true | mt_note_03.txt|1.03 |[C499, C499, D6181, M069, C801] |66 |F |CND |1 |false | mt_note_05.txt|2.991 |[C5092, C5091, C779, C5092, C800, G20, C5092]|57 |F |CPA |3 |true | mt_note_06.txt|0.299 |[F319] |63 |F |CFA |0 |true | mt_note_08.txt|2.714 |[C459, C800] |66 |F |CND |1 |false | mt_note_09.txt|1.234 |[D5702, K5505] |19 |F |CPA |3 |true | +--+-++++--+-+--+ For more details and usage examples, check the notebook Medicare Risk Adjustment notebook from our Spark NLP Workshop repository.",
    "url": "/docs/en/healthcare_risk_adjustments_score_calculation",
    "relUrl": "/docs/en/healthcare_risk_adjustments_score_calculation"
  },
  "966": {
    "id": "966",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/helpers.html",
    "relUrl": "/api/python/user_guide/helpers.html"
  },
  "967": {
    "id": "967",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/audio/hubert_for_ctc.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/audio/hubert_for_ctc.html"
  },
  "968": {
    "id": "968",
    "title": "Identify & Translate Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/identify_translate_languages",
    "relUrl": "/identify_translate_languages"
  },
  "969": {
    "id": "969",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/image_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/image_assembler.html"
  },
  "970": {
    "id": "970",
    "title": "Import Documents",
    "content": "Once a new project is created and its configuration is saved, the user is redirected to the Import page. Here the user has multiple options for importing tasks. Users can import the accepted file formats in multiple ways. They can drag and drop the file(s) to the upload box, select the file from the file explorer, provide the URL of the file in JSON format, or import it directly from the S3 bucket. To import from Amazon S3 bucket the user needs to provide the necessary connection details (credentials, access keys, and S3 bucket path). All documents present in the specified path, are then imported as tasks in the current project. Plain text file When you upload a plain text file, only one task will be created which will contain the entire data in the input file. This is an update from earlier versions of Annotation Lab when the input text file was split by the new line character and one task was created for each line. Json file For bulk importing a list of documents you can use the json import option. The expected format is illustrated in the image below. It consists of a list of dictionaries, each with 2 keys-values pairs (“text” and “title”). [{&quot;text&quot;: &quot;Task text content.&quot;, &quot;title&quot;:&quot;Task title&quot;}] CSV, TSV file When CSV / TSV formatted text file is used, column names are interpreted as task data keys: Task text content, Task title this is a first task, Colon Cancer.txt this is a second task, Breast radiation therapy.txt Import annotated tasks When importing tasks that already contain annotations (e.g. exported from another project, with predictions generated by pre-trained models) the user has the option to overwrite completions/predictions or to skip the tasks that are already imported into the project. NOTE: When importing tasks from different projects with the purpose of combining them in one project, users should take care of the overlaps existing between tasks IDs. Annotation Lab will simply overwrite tasks with the same ID. Dynamic Task Pagination The support for pagination offered by earlier versions of the Annotation Lab involved the use of the &lt;pagebreak&gt; tag. A document pre-processing step was necessary for adding/changing the page breaks and those involved extra effort from the part of the users. Annotation Lab 2.8.0 introduces a paradigm change for pagination. Going forward, pagination is dynamic and can be configured according to the user’s needs and preferences from the Labeling page. Annotators or reviewers can now choose the number of words to include on a single page from a predefined list of values or can add the desired counts. A new settings option has been added to prevent splitting a sentence into two different pages.",
    "url": "/docs/en/alab/import",
    "relUrl": "/docs/en/alab/import"
  },
  "971": {
    "id": "971",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/",
    "relUrl": "/api/com/johnsnowlabs/collections/"
  },
  "972": {
    "id": "972",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/",
    "relUrl": "/api/com/johnsnowlabs/storage/"
  },
  "973": {
    "id": "973",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/"
  },
  "974": {
    "id": "974",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/"
  },
  "975": {
    "id": "975",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/"
  },
  "976": {
    "id": "976",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/"
  },
  "977": {
    "id": "977",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/"
  },
  "978": {
    "id": "978",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/"
  },
  "979": {
    "id": "979",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/"
  },
  "980": {
    "id": "980",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/"
  },
  "981": {
    "id": "981",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/"
  },
  "982": {
    "id": "982",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/"
  },
  "983": {
    "id": "983",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/"
  },
  "984": {
    "id": "984",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/"
  },
  "985": {
    "id": "985",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/"
  },
  "986": {
    "id": "986",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/"
  },
  "987": {
    "id": "987",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/util/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/util/"
  },
  "988": {
    "id": "988",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/"
  },
  "989": {
    "id": "989",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/"
  },
  "990": {
    "id": "990",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/"
  },
  "991": {
    "id": "991",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/"
  },
  "992": {
    "id": "992",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/"
  },
  "993": {
    "id": "993",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/"
  },
  "994": {
    "id": "994",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/"
  },
  "995": {
    "id": "995",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/"
  },
  "996": {
    "id": "996",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/"
  },
  "997": {
    "id": "997",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/"
  },
  "998": {
    "id": "998",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/"
  },
  "999": {
    "id": "999",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/"
  },
  "1000": {
    "id": "1000",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/"
  },
  "1001": {
    "id": "1001",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/"
  },
  "1002": {
    "id": "1002",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/"
  },
  "1003": {
    "id": "1003",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/"
  },
  "1004": {
    "id": "1004",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/"
  },
  "1005": {
    "id": "1005",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/"
  },
  "1006": {
    "id": "1006",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/"
  },
  "1007": {
    "id": "1007",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/"
  },
  "1008": {
    "id": "1008",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/"
  },
  "1009": {
    "id": "1009",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/"
  },
  "1010": {
    "id": "1010",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/"
  },
  "1011": {
    "id": "1011",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/"
  },
  "1012": {
    "id": "1012",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/"
  },
  "1013": {
    "id": "1013",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/"
  },
  "1014": {
    "id": "1014",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/"
  },
  "1015": {
    "id": "1015",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/"
  },
  "1016": {
    "id": "1016",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/"
  },
  "1017": {
    "id": "1017",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/"
  },
  "1018": {
    "id": "1018",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/"
  },
  "1019": {
    "id": "1019",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/"
  },
  "1020": {
    "id": "1020",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/"
  },
  "1021": {
    "id": "1021",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/"
  },
  "1022": {
    "id": "1022",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/"
  },
  "1023": {
    "id": "1023",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/recursive/",
    "relUrl": "/api/com/johnsnowlabs/nlp/recursive/"
  },
  "1024": {
    "id": "1024",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/"
  },
  "1025": {
    "id": "1025",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/",
    "relUrl": "/api/com/johnsnowlabs/nlp/"
  },
  "1026": {
    "id": "1026",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/",
    "relUrl": "/api/com/johnsnowlabs/client/aws/"
  },
  "1027": {
    "id": "1027",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/gcp/",
    "relUrl": "/api/com/johnsnowlabs/client/gcp/"
  },
  "1028": {
    "id": "1028",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/",
    "relUrl": "/api/com/johnsnowlabs/client/"
  },
  "1029": {
    "id": "1029",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/spark/",
    "relUrl": "/api/com/johnsnowlabs/util/spark/"
  },
  "1030": {
    "id": "1030",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/",
    "relUrl": "/api/com/johnsnowlabs/util/"
  },
  "1031": {
    "id": "1031",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/"
  },
  "1032": {
    "id": "1032",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/ai/",
    "relUrl": "/api/com/johnsnowlabs/ml/ai/"
  },
  "1033": {
    "id": "1033",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/util/",
    "relUrl": "/api/com/johnsnowlabs/ml/util/"
  },
  "1034": {
    "id": "1034",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/"
  },
  "1035": {
    "id": "1035",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/"
  },
  "1036": {
    "id": "1036",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/"
  },
  "1037": {
    "id": "1037",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/",
    "relUrl": "/api/com/johnsnowlabs/ml/"
  },
  "1038": {
    "id": "1038",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/",
    "relUrl": "/api/com/johnsnowlabs/"
  },
  "1039": {
    "id": "1039",
    "title": "",
    "content": "",
    "url": "/api/com/",
    "relUrl": "/api/com/"
  },
  "1040": {
    "id": "1040",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/logging/comet/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/logging/comet/"
  },
  "1041": {
    "id": "1041",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/logging/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/logging/"
  },
  "1042": {
    "id": "1042",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotation_image/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotation_image/"
  },
  "1043": {
    "id": "1043",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/pos/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/pos/"
  },
  "1044": {
    "id": "1044",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/pub_tator/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/pub_tator/"
  },
  "1045": {
    "id": "1045",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/spacy_to_annotation/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/spacy_to_annotation/"
  },
  "1046": {
    "id": "1046",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/conllu/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/conllu/"
  },
  "1047": {
    "id": "1047",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/conll/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/conll/"
  },
  "1048": {
    "id": "1048",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/tfgraphs/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/tfgraphs/"
  },
  "1049": {
    "id": "1049",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/"
  },
  "1050": {
    "id": "1050",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotation_audio/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotation_audio/"
  },
  "1051": {
    "id": "1051",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/extended_java_wrapper/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/extended_java_wrapper/"
  },
  "1052": {
    "id": "1052",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/recursive/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/recursive/"
  },
  "1053": {
    "id": "1053",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/annotator_java_ml/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/annotator_java_ml/"
  },
  "1054": {
    "id": "1054",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/annotator_transformer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/annotator_transformer/"
  },
  "1055": {
    "id": "1055",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/params_getters_setters/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/params_getters_setters/"
  },
  "1056": {
    "id": "1056",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/"
  },
  "1057": {
    "id": "1057",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/upload_to_hub/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/upload_to_hub/"
  },
  "1058": {
    "id": "1058",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/util/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/util/"
  },
  "1059": {
    "id": "1059",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/functions/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/functions/"
  },
  "1060": {
    "id": "1060",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/pretrained/resource_downloader/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/pretrained/resource_downloader/"
  },
  "1061": {
    "id": "1061",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/pretrained/utils/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/pretrained/utils/"
  },
  "1062": {
    "id": "1062",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/pretrained/pretrained_pipeline/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/pretrained/pretrained_pipeline/"
  },
  "1063": {
    "id": "1063",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/pretrained/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/pretrained/"
  },
  "1064": {
    "id": "1064",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotation/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotation/"
  },
  "1065": {
    "id": "1065",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/normalizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/normalizer/"
  },
  "1066": {
    "id": "1066",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/"
  },
  "1067": {
    "id": "1067",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/"
  },
  "1068": {
    "id": "1068",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/cv/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/cv/"
  },
  "1069": {
    "id": "1069",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector/"
  },
  "1070": {
    "id": "1070",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/"
  },
  "1071": {
    "id": "1071",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentence/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentence/"
  },
  "1072": {
    "id": "1072",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/chunker/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/chunker/"
  },
  "1073": {
    "id": "1073",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/"
  },
  "1074": {
    "id": "1074",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/"
  },
  "1075": {
    "id": "1075",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/"
  },
  "1076": {
    "id": "1076",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/"
  },
  "1077": {
    "id": "1077",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/pos/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/pos/"
  },
  "1078": {
    "id": "1078",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/"
  },
  "1079": {
    "id": "1079",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/"
  },
  "1080": {
    "id": "1080",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/text_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/text_matcher/"
  },
  "1081": {
    "id": "1081",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/regex_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/regex_matcher/"
  },
  "1082": {
    "id": "1082",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/date_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/date_matcher/"
  },
  "1083": {
    "id": "1083",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/"
  },
  "1084": {
    "id": "1084",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/"
  },
  "1085": {
    "id": "1085",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/keyword_extraction/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/keyword_extraction/"
  },
  "1086": {
    "id": "1086",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/param/classifier_encoder/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/param/classifier_encoder/"
  },
  "1087": {
    "id": "1087",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/"
  },
  "1088": {
    "id": "1088",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/param/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/param/"
  },
  "1089": {
    "id": "1089",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/lemmatizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/lemmatizer/"
  },
  "1090": {
    "id": "1090",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/chunk2_doc/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/chunk2_doc/"
  },
  "1091": {
    "id": "1091",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/"
  },
  "1092": {
    "id": "1092",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/"
  },
  "1093": {
    "id": "1093",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/audio/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/audio/"
  },
  "1094": {
    "id": "1094",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/"
  },
  "1095": {
    "id": "1095",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/"
  },
  "1096": {
    "id": "1096",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/"
  },
  "1097": {
    "id": "1097",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/"
  },
  "1098": {
    "id": "1098",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/"
  },
  "1099": {
    "id": "1099",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ws/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ws/"
  },
  "1100": {
    "id": "1100",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/date2_chunk/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/date2_chunk/"
  },
  "1101": {
    "id": "1101",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/graph_extraction/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/graph_extraction/"
  },
  "1102": {
    "id": "1102",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/"
  },
  "1103": {
    "id": "1103",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/"
  },
  "1104": {
    "id": "1104",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_overwriter/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_overwriter/"
  },
  "1105": {
    "id": "1105",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/"
  },
  "1106": {
    "id": "1106",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_converter/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_converter/"
  },
  "1107": {
    "id": "1107",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_approach/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_approach/"
  },
  "1108": {
    "id": "1108",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/"
  },
  "1109": {
    "id": "1109",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/stop_words_cleaner/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/stop_words_cleaner/"
  },
  "1110": {
    "id": "1110",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/n_gram_generator/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/n_gram_generator/"
  },
  "1111": {
    "id": "1111",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/stemmer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/stemmer/"
  },
  "1112": {
    "id": "1112",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/"
  },
  "1113": {
    "id": "1113",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/"
  },
  "1114": {
    "id": "1114",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/"
  },
  "1115": {
    "id": "1115",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/"
  },
  "1116": {
    "id": "1116",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/"
  },
  "1117": {
    "id": "1117",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/"
  },
  "1118": {
    "id": "1118",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/"
  },
  "1119": {
    "id": "1119",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/"
  },
  "1120": {
    "id": "1120",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/"
  },
  "1121": {
    "id": "1121",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/"
  },
  "1122": {
    "id": "1122",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/"
  },
  "1123": {
    "id": "1123",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/"
  },
  "1124": {
    "id": "1124",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/"
  },
  "1125": {
    "id": "1125",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/"
  },
  "1126": {
    "id": "1126",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/"
  },
  "1127": {
    "id": "1127",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/"
  },
  "1128": {
    "id": "1128",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/"
  },
  "1129": {
    "id": "1129",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/"
  },
  "1130": {
    "id": "1130",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/"
  },
  "1131": {
    "id": "1131",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/"
  },
  "1132": {
    "id": "1132",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/"
  },
  "1133": {
    "id": "1133",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/"
  },
  "1134": {
    "id": "1134",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/"
  },
  "1135": {
    "id": "1135",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/"
  },
  "1136": {
    "id": "1136",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/"
  },
  "1137": {
    "id": "1137",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/"
  },
  "1138": {
    "id": "1138",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/"
  },
  "1139": {
    "id": "1139",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/"
  },
  "1140": {
    "id": "1140",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/"
  },
  "1141": {
    "id": "1141",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/"
  },
  "1142": {
    "id": "1142",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/"
  },
  "1143": {
    "id": "1143",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/document_normalizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/document_normalizer/"
  },
  "1144": {
    "id": "1144",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/"
  },
  "1145": {
    "id": "1145",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ld_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ld_dl/"
  },
  "1146": {
    "id": "1146",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/"
  },
  "1147": {
    "id": "1147",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/tokenizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/tokenizer/"
  },
  "1148": {
    "id": "1148",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/"
  },
  "1149": {
    "id": "1149",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/regex_tokenizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/regex_tokenizer/"
  },
  "1150": {
    "id": "1150",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/"
  },
  "1151": {
    "id": "1151",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/"
  },
  "1152": {
    "id": "1152",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/er/entity_ruler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/er/entity_ruler/"
  },
  "1153": {
    "id": "1153",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/er/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/er/"
  },
  "1154": {
    "id": "1154",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/"
  },
  "1155": {
    "id": "1155",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/"
  },
  "1156": {
    "id": "1156",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/dependency/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/dependency/"
  },
  "1157": {
    "id": "1157",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/coref/spanbert_coref/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/coref/spanbert_coref/"
  },
  "1158": {
    "id": "1158",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/coref/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/coref/"
  },
  "1159": {
    "id": "1159",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/"
  },
  "1160": {
    "id": "1160",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/"
  },
  "1161": {
    "id": "1161",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/"
  },
  "1162": {
    "id": "1162",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/"
  },
  "1163": {
    "id": "1163",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/"
  },
  "1164": {
    "id": "1164",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/"
  },
  "1165": {
    "id": "1165",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/"
  },
  "1166": {
    "id": "1166",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/"
  },
  "1167": {
    "id": "1167",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/"
  },
  "1168": {
    "id": "1168",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/"
  },
  "1169": {
    "id": "1169",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/"
  },
  "1170": {
    "id": "1170",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/"
  },
  "1171": {
    "id": "1171",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/"
  },
  "1172": {
    "id": "1172",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/"
  },
  "1173": {
    "id": "1173",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/"
  },
  "1174": {
    "id": "1174",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/"
  },
  "1175": {
    "id": "1175",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/"
  },
  "1176": {
    "id": "1176",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/"
  },
  "1177": {
    "id": "1177",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/"
  },
  "1178": {
    "id": "1178",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/"
  },
  "1179": {
    "id": "1179",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/"
  },
  "1180": {
    "id": "1180",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/"
  },
  "1181": {
    "id": "1181",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/"
  },
  "1182": {
    "id": "1182",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/"
  },
  "1183": {
    "id": "1183",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/"
  },
  "1184": {
    "id": "1184",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/document_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/document_assembler/"
  },
  "1185": {
    "id": "1185",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/has_recursive_transform/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/has_recursive_transform/"
  },
  "1186": {
    "id": "1186",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/table_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/table_assembler/"
  },
  "1187": {
    "id": "1187",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/finisher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/finisher/"
  },
  "1188": {
    "id": "1188",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/has_recursive_fit/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/has_recursive_fit/"
  },
  "1189": {
    "id": "1189",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/light_pipeline/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/light_pipeline/"
  },
  "1190": {
    "id": "1190",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/image_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/image_assembler/"
  },
  "1191": {
    "id": "1191",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/doc2_chunk/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/doc2_chunk/"
  },
  "1192": {
    "id": "1192",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/embeddings_finisher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/embeddings_finisher/"
  },
  "1193": {
    "id": "1193",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/audio_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/audio_assembler/"
  },
  "1194": {
    "id": "1194",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/graph_finisher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/graph_finisher/"
  },
  "1195": {
    "id": "1195",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/multi_document_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/multi_document_assembler/"
  },
  "1196": {
    "id": "1196",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/token_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/token_assembler/"
  },
  "1197": {
    "id": "1197",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/recursive_pipeline/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/recursive_pipeline/"
  },
  "1198": {
    "id": "1198",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/token2_chunk/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/token2_chunk/"
  },
  "1199": {
    "id": "1199",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/"
  },
  "1200": {
    "id": "1200",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/annotator_properties/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/annotator_properties/"
  },
  "1201": {
    "id": "1201",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/storage/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/storage/"
  },
  "1202": {
    "id": "1202",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/annotator_approach/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/annotator_approach/"
  },
  "1203": {
    "id": "1203",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/read_as/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/read_as/"
  },
  "1204": {
    "id": "1204",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/annotator_model/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/annotator_model/"
  },
  "1205": {
    "id": "1205",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/recursive_annotator_approach/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/recursive_annotator_approach/"
  },
  "1206": {
    "id": "1206",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/utils/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/utils/"
  },
  "1207": {
    "id": "1207",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/annotator_type/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/annotator_type/"
  },
  "1208": {
    "id": "1208",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/properties/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/properties/"
  },
  "1209": {
    "id": "1209",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/coverage_result/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/coverage_result/"
  },
  "1210": {
    "id": "1210",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/"
  },
  "1211": {
    "id": "1211",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/"
  },
  "1212": {
    "id": "1212",
    "title": "",
    "content": "",
    "url": "/api/python/reference/",
    "relUrl": "/api/python/reference/"
  },
  "1213": {
    "id": "1213",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/",
    "relUrl": "/api/python/user_guide/"
  },
  "1214": {
    "id": "1214",
    "title": "",
    "content": "",
    "url": "/api/python/third_party/",
    "relUrl": "/api/python/third_party/"
  },
  "1215": {
    "id": "1215",
    "title": "",
    "content": "",
    "url": "/api/python/modules/",
    "relUrl": "/api/python/modules/"
  },
  "1216": {
    "id": "1216",
    "title": "",
    "content": "",
    "url": "/api/python/getting_started/",
    "relUrl": "/api/python/getting_started/"
  },
  "1217": {
    "id": "1217",
    "title": "",
    "content": "",
    "url": "/api/python/",
    "relUrl": "/api/python/"
  },
  "1218": {
    "id": "1218",
    "title": "",
    "content": "",
    "url": "/api/",
    "relUrl": "/api/"
  },
  "1219": {
    "id": "1219",
    "title": "John Snow Labs <span>State of the Art Natural Language Processing in Python</span>",
    "content": "",
    "url": "/",
    "relUrl": "/"
  },
  "1220": {
    "id": "1220",
    "title": "Infer Meaning & Intent - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/infer_meaning_intent",
    "relUrl": "/infer_meaning_intent"
  },
  "1221": {
    "id": "1221",
    "title": "Infrastructure Configuration",
    "content": "The admin user can now define the infrastructure configurations for the prediction and training tasks. Resource allocation for Training and Preannotation Annotation Lab gives users the ability to change the configuration for the training and pre-annotation processes. This is done from the Settings &gt; Infrastructure page. The settings can be edited by admin user and they are read-only for the other users. The Infrastructure page consists of three sections namely Resource For Training, Resource For Preannotation Server, Resources for Prenotation Pipeline. Resources Inclusion: Memory Limit – Represents the maximum memory size to allocate for the training/pre-annotation processes. CPU Limit – Specifies this maximum number of CPUs to use by the training/pre-annotation server. Note: If the specified configurations exceed the available resources, the server will not start.",
    "url": "/docs/en/alab/infrastructure",
    "relUrl": "/docs/en/alab/infrastructure"
  },
  "1222": {
    "id": "1222",
    "title": "Installation",
    "content": "Type of installation Dedicated Server AWS Marketplace Azure Marketplace EKS deployment AKS deployment AirGap Environment OpenShift Dedicated Server Install NLP Lab (Annotation Lab) on a dedicated server to reduce the likelihood of conflicts or unexpected behavior. Fresh install To install NLP Lab run the following command: wget https://setup.johnsnowlabs.com/annotationlab/install.sh -O - | sudo bash -s $VERSION Replace $VERSION in the above one liners with the version you want to install. For installing the latest available version of the NLP Lab use: wget https://setup.johnsnowlabs.com/annotationlab/install.sh -O - | sudo bash -s -- Upgrade To upgrade your NLP Lab installation to a newer version, run the following command on a terminal: wget https://setup.johnsnowlabs.com/annotationlab/upgrade.sh -O - | sudo bash -s $VERSION Replace $VERSION in the above one liners with the version you want to upgrade to. For upgrading to the latest version of the NLP Lab, use: wget https://setup.johnsnowlabs.com/annotationlab/upgrade.sh -O - | sudo bash -s -- NOTE: The install/upgrade script displays the login credentials for the admin user on the terminal. After running the install/upgrade script, the NLP Lab is available at http://INSTANCE_IP or https://INSTANCE_IP We have an aesthetically pleasing Sign-In Page with a section highlighting the key features of NLP Lab using animated GIFs. AWS Marketplace The NLP Lab needs to be installed on a virtual machine. One of the most straight forward method is an installation from AWS Marketplace (also available on Azure). There is no fee for the NLP Lab. However, you still have to pay for the underlying AWS EC2 instance (not Free Tier Eligible). Visit the product page on AWS Marketplace and follow the instructions on the video below to subscribe and deploy. Deploy NLP Lab via AWS Marketplace Secure access to NLP Lab on AWS When installed via the AWS Marketplace, NLP Lab has a private IP address and listens on an unsecured HTTP port. You can ask your DevOps department to incorporate the resource to your standard procedures to access from the internet in a secure manner. Alternatively, a Cloud Formation script is available that can be used to create a front end proxy (CloudFront, ELB, and auxiliary Lambda Function). Those resources are Free Tier Eligible. Create the AWS Cloud Formation Script in YAML format: vi cloudformation_https.yaml AWSTemplateFormatVersion: &#39;2010-09-09&#39; Metadata: License: Apache-2.0 Description: &#39;AWS CloudFormation To access NLP Lab via https: Create an Amazon EC2 instance running the NLP Lab Amazon Linux AMI. Once the NLP Lab instance is created, provide instance hostname as input. This Cloudfromation Creates Cloudfront. You can use Cloudfront Domain URL to access NLP Lab via https protocol. &#39; Parameters: NLPlabInstanceHostName: Description: HostName of the NLP Lab InstanceID Type: String ConstraintDescription: HostName of the NLP Lab InstanceID Resources: CloudFront: Type: AWS::CloudFront::Distribution Properties: DistributionConfig: Enabled: True DefaultCacheBehavior: AllowedMethods: - DELETE - GET - HEAD - OPTIONS - PATCH - POST - PUT DefaultTTL: 0 MaxTTL: 0 MinTTL: 0 Compress: True ForwardedValues: QueryString: true Headers: - &#39;*&#39; Cookies: Forward: all TargetOriginId: EC2CustomOrigin ViewerProtocolPolicy: redirect-to-https Origins: - DomainName: !Ref NLPlabInstanceHostName Id: EC2CustomOrigin CustomOriginConfig: HTTPPort: &#39;80&#39; OriginProtocolPolicy: http-only Outputs: CloudfrontURL: Description: Cloudfront URL to access NLP Lab Value: !Join [&quot;&quot;, [&#39;https://&#39;, !GetAtt [CloudFront, DomainName]]] Click Create a stack, “Upload a template file”. Give the Stack a name and enter the NLP Lab instance Hostname(from the EC2 console) as a parameter. Next -&gt; Next -&gt; Acknowledge that AWS CloudFormation might create IAM resources. -&gt; Submit. Wait a few minutes until all resources are created. Once created, go do the Outputs tab and click on the NLP Lab URL. You may need to refresh the view. Now, to access the NLP Lab, you go to the CloudFront URL and log in with username “admin” and password equal to the EC2 Instance ID noted earlier. Azure Marketplace Visit the product page on Azure Marketplace and follow the instructions on the video below to subscribe and deploy. Deploy NLP Lab via Azure Marketplace EKS deployment Create NodeGroup for a given cluster eksctl create nodegroup --config-file eks-nodegroup.yaml kind: ClusterConfig apiVersion: eksctl.io/v1alpha5 metadata: name: &lt;cluster-name&gt; region: &lt;region&gt; version: &quot;1.21&quot; availabilityZones: - &lt;zone-1&gt; - &lt;zone-2&gt; vpc: id: &quot;&lt;vpc-id&gt;&quot; subnets: private: us-east-1d: id: &quot;&lt;subnet-id&quot; us-east-1f: id: &quot;&lt;subent-id&gt;&quot; securityGroup: &quot;&lt;security-group&gt;&quot; iam: withOIDC: true managedNodeGroups: - name: alab-workers instanceType: m5.large desiredCapacity: 3 VolumeSize: 50 VolumeType: gp2 privateNetworking: true ssh: publicKeyPath: &lt;path/to/id_rsa_pub&gt; eksctl utils associate-iam-oidc-provider --region=us-east-1 --cluster=&lt;cluster-name&gt; --approve Create an EFS as shared storage. EFS stands for Elastic File System and is a scalable storage solution that can be used for general purpose workloads. curl -S https://raw.githubusercontent.com/kubernetes-sigs/aws-efs-csi-driver/v1.2.0/docs/iam-policy-example.json -o iam-policy.json aws iam create-policy --policy-name EFSCSIControllerIAMPolicy --policy-document file://iam-policy.json eksctl create iamserviceaccount --cluster=&lt;cluster&gt; --region &lt;AWS Region&gt; --namespace=kube-system --name=efs-csi-controller-sa --override-existing-serviceaccounts --attach-policy-arn=arn:aws:iam::&lt;AWS account ID&gt;:policy/EFSCSIControllerIAMPolicy --approve helm repo add aws-efs-csi-driver https://kubernetes-sigs.github.io/aws-efs-csi-driver helm repo update helm upgrade -i aws-efs-csi-driver aws-efs-csi-driver/aws-efs-csi-driver --namespace kube-system --set image.repository=602401143452.dkr.ecr.us-east-1.amazonaws.com/eks/aws-efs-csi-driver --set controller.serviceAccount.create=false --set controller.serviceAccount.name=efs-csi-controller-sa Create storageClass.yaml cat &lt;&lt;EOF &gt; storageClass.yaml kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: efs-sc provisioner: efs.csi.aws.com parameters: provisioningMode: efs-ap fileSystemId: &lt;EFS file system ID&gt; directoryPerms: &quot;700&quot; EOF kubectl apply -f storageClass.yaml Edit annotationlab-installer.sh inside artifact folder as follows: helm install annotationlab annotationlab-${ANNOTATIONLAB_VERSION}.tgz --set image.tag=${ANNOTATIONLAB_VERSION} --set model_server.count=1 --set ingress.enabled=true --set networkPolicy.enabled=true --set networkPolicy.enabled=true --set extraNetworkPolicies=&#39;- namespaceSelector: matchLabels: kubernetes.io/metadata.name: kube-system podSelector: matchLabels: app.kubernetes.io/name: traefik app.kubernetes.io/instance: traefik&#39; --set keycloak.postgresql.networkPolicy.enabled=true --set sharedData.storageClass=efs-sc --set airflow.postgresql.networkPolicy.enabled=true --set postgresql.networkPolicy.enabled=true --set airflow.networkPolicies.enabled=true --set ingress.defaultBackend=true --set ingress.uploadLimitInMegabytes=16 --set &#39;ingress.hosts[0].host=domain.tld&#39; --set airflow.model_server.count=1 --set airflow.redis.password=$(bash -c &quot;echo ${password_gen_string}&quot;) --set configuration.FLASK_SECRET_KEY=$(bash -c &quot;echo ${password_gen_string}&quot;) --set configuration.KEYCLOAK_CLIENT_SECRET_KEY=$(bash -c &quot;echo ${uuid_gen_string}&quot;) --set postgresql.postgresqlPassword=$(bash -c &quot;echo ${password_gen_string}&quot;) --set keycloak.postgresql.postgresqlPassword=$(bash -c &quot;echo ${password_gen_string}&quot;) --set keycloak.secrets.admincreds.stringData.user=admin --set keycloak.secrets.admincreds.stringData.password=$(bash -c &quot;echo ${password_gen_string}&quot;) Run annotationlab-installer.sh script ./artifacts/annotationlab-installer.sh Install ingress Controller helm repo add nginx-stable https://helm.nginx.com/stable helm repo update helm install my-release nginx-stable/nginx-ingress Apply ingress.yaml cat &lt;&lt;EOF &gt; ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx meta.helm.sh/release-name: annotationlab meta.helm.sh/release-namespace: default name: annotationlab spec: defaultBackend: service: name: annotationlab port: name: http rules: - host: domain.tld http: paths: - backend: service: name: annotationlab port: name: http path: / pathType: ImplementationSpecific - backend: service: name: annotationlab-keyclo-http port: name: http path: /auth pathType: ImplementationSpecific EOF kubectl apply -f ingress.yaml AKS deployment To deploy NLP Lab on Azure Kubernetes Service (AKS) a Kubernetes cluster needs to be created in Microsoft Azure. Login to your Azure Portal and search for Kubernetes services. On the Kubernetes services page click on the Create dropdown and select Create a Kubernetes cluster. On the Create Kubernetes cluster page, select the resource group and provide the name you want to give to the cluster. You can keep the rest of the fields to default values and click on Review + create. Click on Create button to start the deployment process. Once the deployment is completed, click on Go to resource button. On the newly created resource page, click on Connect button. You will be shown a list of commands to run on the Cloud Shell or Azure CLI to connect to this resource. We will execute them successively in the following steps. Run the following commands to connect to Azure Kubernetes Service. az account set --subscription &lt;subscription-id&gt; NOTE: Replace with your account&#39;s subscription id. az aks get-credentials --resource-group &lt;resource-group-name&gt; --name &lt;cluster-name&gt; NOTE: Replace and with what you selected in Step 3. Check to see if azurefile or azuredisk storage class is present by running the following command: kubectl get storageclass Later in the helm script we need to update the value of sharedData.storageClass with the respective storage class. Go to the artifact directory and from there edit the annotationlab-installer.sh script. helm install annotationlab annotationlab-${ANNOTATIONLAB_VERSION}.tgz --set image.tag=${ANNOTATIONLAB_VERSION} --set model_server.count=1 --set ingress.enabled=true --set networkPolicy.enabled=true --set networkPolicy.enabled=true --set extraNetworkPolicies=&#39;- namespaceSelector: matchLabels: kubernetes.io/metadata.name: kube-system podSelector: matchLabels: app.kubernetes.io/name: traefik app.kubernetes.io/instance: traefik&#39; --set keycloak.postgresql.networkPolicy.enabled=true --set sharedData.storageClass=azurefile --set airflow.postgresql.networkPolicy.enabled=true --set postgresql.networkPolicy.enabled=true --set airflow.networkPolicies.enabled=true --set ingress.defaultBackend=true --set ingress.uploadLimitInMegabytes=16 --set &#39;ingress.hosts[0].host=domain.tld&#39; --set airflow.model_server.count=1 --set airflow.redis.password=$(bash -c &quot;echo ${password_gen_string}&quot;) --set configuration.FLASK_SECRET_KEY=$(bash -c &quot;echo ${password_gen_string}&quot;) --set configuration.KEYCLOAK_CLIENT_SECRET_KEY=$(bash -c &quot;echo ${uuid_gen_string}&quot;) --set postgresql.postgresqlPassword=$(bash -c &quot;echo ${password_gen_string}&quot;) --set keycloak.postgresql.postgresqlPassword=$(bash -c &quot;echo ${password_gen_string}&quot;) --set keycloak.secrets.admincreds.stringData.user=admin --set keycloak.secrets.admincreds.stringData.password=$(bash -c &quot;echo ${password_gen_string}&quot;) Execute the annotationlab-installer.sh script to run the NLP Lab installation. ./annotationlab-installer.sh Verify if the installation was successful. kubectl get pods Install ingress controller. This will be required for load-balancing purpose. helm repo add nginx-stable https://helm.nginx.com/stable helm repo update helm install my-release nginx-stable/nginx-ingress Create a YAML configuration file named ingress.yaml with the following configuration apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx meta.helm.sh/release-name: annotationlab meta.helm.sh/release-namespace: default name: annotationlab spec: defaultBackend: service: name: annotationlab port: name: http rules: - host: domain.tld http: paths: - backend: service: name: annotationlab port: name: http path: / pathType: ImplementationSpecific - backend: service: name: annotationlab-keyclo-http port: name: http path: /auth pathType: ImplementationSpecific Apply the ingress.yaml by running the following command kubectl apply -f ingress.yaml AirGap Environment Get Artifact Run the following command on a terminal to fetch the compressed artifact (tarball) of the NLP Lab. wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/annotationlab/annotationlab-$VERSION.tar.gz Extract the tarball and the change directory to the extracted folder (artifacts): tar -xzf annotationlab-$VERSION.tar.gz cd artifacts Replace $VERSION with the version you want to download and install. Fresh Install Run the installer script annotationlab-installer.sh with sudo privileges. $ sudo su $ ./annotationlab-installer.sh Upgrade Run the upgrade script annotationlab-updater.sh with sudo privileges. $ sudo su $ ./annotationlab-updater.sh OpenShift Annotation Lab can also be installed using the operator framework on an OpenShift cluster. The Annotation Lab operator can be found under the OperatorHub. Find and select The OperatorHub has a large list of operators that can be installed into your cluster. Search for Annotation Lab operator under AI/Machine Learning category and select it. Install Some basic information about this operator is provided on the navigation panel that opens after selecting Annotation Lab on the previous step. NOTE: Make sure you have defined shared storage such as efs/nfs/cephfs prior to installing the Annotation Lab Operator. Click on the Install button located on the top-left corner of this panel to start the installation process. After successful installation of the Annotation Lab operator, you can access it by navigating to the Installed Operators page. Create Instance Next step is to create a cluster instance of the Annotation Lab. For this, select the Annotation Lab operator under the Installed Operators page and then switch to Annotationlab tab. On this section, click on Create Annotationlab button to spawn a new instance of Annotation Lab. Define shared Storage Class Update the storageClass property in the YAML configuration to define the storage class to one of efs, nfs, or cephfs depending upon what storage you set up before Annotation Lab operator installation. Define domain name Update the host property in the YAML configuration to define the required domain name to use instead of the default hostname annotationlab as shown in the image below. Click on Create button once you have made all the necessary changes. This will also set up all the necessary resources to run the instance in addition to standing up the services themselves. View Resources After the instance is successfully created we can visit its page to view all the resources as well as supporting resources like the secrets, configuration maps, etc that were created. Now, we can access the Annotation Lab from the provided domain name or also from the location defined for this service under the Networking &gt; Routes page Work over proxy Custom CA certificate You can provide a custom CA certificate chain to be included into the deployment. To do it add --set-file custom_cacert=./cachain.pem options to helm install/upgrade command inside annotationlab-installer.sh and annotationlab-updater.sh files. cachain.pem must include a certificate in the following format: --BEGIN CERTIFICATE-- .... --END CERTIFICATE-- Proxy env variables You can provide a proxy to use for external communications. To do that add `--set proxy.http=[protocol://]&lt;host&gt;[:port]`, `--set proxy.https=[protocol://]&lt;host&gt;[:port]`, `--set proxy.no=&lt;comma-separated list of hosts/domains&gt;` commands inside annotationlab-installer.sh and annotationlab-updater.sh files. Recommended Configurations System requirements You can install Annotation Lab on a Ubuntu 20+ machine. Port requirements Annotation Lab expects ports 443 and 80 to be open by default. Server requirements The minimal required configuration is 32GB RAM, 8 Core CPU, 512 SSD. The ideal configuration in case model training and preannotations are required on a large number of tasks is 64 GiB, 16 Core CPU, 2TB HDD, 512 SSD. Web browser support Annotation Lab is tested with the latest version of Google Chrome and is expected to work in the latest versions of: Google Chrome Apple Safari Mozilla Firefox",
    "url": "/docs/en/alab/install",
    "relUrl": "/docs/en/alab/install"
  },
  "1223": {
    "id": "1223",
    "title": "Installation",
    "content": "To install the johnsnowlabs Python library and all of John Snow Labs open source libraries, just run pip install johnsnowlabs To quickly test the installation, you can run in your Shell: python -c &quot;from johnsnowlabs import nlp;print(nlp.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;))&quot; or in Python: from johnsnowlabs import nlp nlp.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;) when using Annotator based pipelines, use nlp.start() to start up your session from johnsnowlabs import nlp nlp.start() pipe = nlp.Pipeline(stages= [ nlp.DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;doc&#39;), nlp.Tokenizer().setInputCols(&#39;doc&#39;).setOutputCol(&#39;tok&#39;) ]) nlp.to_nlu_pipe(pipe).predict(&#39;That was easy&#39;) for alternative installation options see Custom Installation",
    "url": "/docs/en/jsl/install",
    "relUrl": "/docs/en/jsl/install"
  },
  "1224": {
    "id": "1224",
    "title": "Installation",
    "content": "Spark NLP Cheatsheet # Install Spark NLP from PyPI pip install spark-nlp==4.3.2 # Install Spark NLP from Anacodna/Conda conda install -c johnsnowlabs spark-nlp # Load Spark NLP with Spark Shell spark-shell --packages com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.2 # Load Spark NLP with PySpark pyspark --packages com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.2 # Load Spark NLP with Spark Submit spark-submit --packages com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.2 # Load Spark NLP as external JAR after compiling and building Spark NLP by `sbt assembly` spark-shell --jars spark-nlp-assembly-4.3.2.jar Python Spark NLP supports Python 3.6.x and above depending on your major PySpark version. Quick Install Let’s create a new Conda environment to manage all the dependencies there. You can use Python Virtual Environment if you prefer or not have any environment. $ java -version # should be Java 8 (Oracle or OpenJDK) $ conda create -n sparknlp python=3.8 -y $ conda activate sparknlp $ pip install spark-nlp==4.3.2 pyspark==3.3.1 Of course you will need to have jupyter installed in your system: pip install jupyter Now you should be ready to create a jupyter notebook running from terminal: jupyter notebook Start Spark NLP Session from python If you need to manually start SparkSession because you have other configurations and sparknlp.start() is not including them, you can manually start the SparkSession: spark = SparkSession.builder .appName(&quot;Spark NLP&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;,&quot;16G&quot;) .config(&quot;spark.driver.maxResultSize&quot;, &quot;0&quot;) .config(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;) .config(&quot;spark.jars.packages&quot;, &quot;com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.2&quot;) .getOrCreate() Scala and Java Maven spark-nlp on Apache Spark 3.0.x, 3.1.x, 3.2.x, and 3.3.x: &lt;!-- https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp --&gt; &lt;dependency&gt; &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt; &lt;artifactId&gt;spark-nlp_2.12&lt;/artifactId&gt; &lt;version&gt;4.3.2&lt;/version&gt; &lt;/dependency&gt; spark-nlp-gpu: &lt;!-- https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp-gpu --&gt; &lt;dependency&gt; &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt; &lt;artifactId&gt;spark-nlp-gpu_2.12&lt;/artifactId&gt; &lt;version&gt;4.3.2&lt;/version&gt; &lt;/dependency&gt; spark-nlp-m1: &lt;!-- https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp-m1 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt; &lt;artifactId&gt;spark-nlp-m1_2.12&lt;/artifactId&gt; &lt;version&gt;4.3.2&lt;/version&gt; &lt;/dependency&gt; spark-nlp-aarch64: &lt;!-- https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp-aarch64 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt; &lt;artifactId&gt;spark-nlp-aarch64_2.12&lt;/artifactId&gt; &lt;version&gt;4.3.2&lt;/version&gt; &lt;/dependency&gt; SBT spark-nlp on Apache Spark 3.0.x, 3.1.x, 3.2.x, and 3.3.x: // https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp libraryDependencies += &quot;com.johnsnowlabs.nlp&quot; %% &quot;spark-nlp&quot; % &quot;4.3.2&quot; spark-nlp-gpu: // https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp-gpu libraryDependencies += &quot;com.johnsnowlabs.nlp&quot; %% &quot;spark-nlp-gpu&quot; % &quot;4.3.2&quot; spark-nlp-m1: // https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp-m1 libraryDependencies += &quot;com.johnsnowlabs.nlp&quot; %% &quot;spark-nlp-m1&quot; % &quot;4.3.2&quot; spark-nlp-aarch64: // https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp-aarch64 libraryDependencies += &quot;com.johnsnowlabs.nlp&quot; %% &quot;spark-nlp-aarch64&quot; % &quot;4.3.2&quot; Maven Central: https://mvnrepository.com/artifact/com.johnsnowlabs.nlp If you are interested, there is a simple SBT project for Spark NLP to guide you on how to use it in your projects Spark NLP SBT Starter Installation for M1 Macs Starting from version 4.0.0, Spark NLP has experimental support for M1 macs. Note that at the moment, only the standard variant of the M1 is supported. Other variants (e.g. M1 Pro/Max/Ultra, M2) will most likely not work. Make sure the following prerequisites are met: An M1 compiled java version needs to be installed. For example to install the Zulu Java 11 JDK head to Download Azul JDKs and install that java version. To check if the installed java environment is running natively on arm64 and not rosetta, you can run the following commands in your shell: johnsnow@m1mac ~ % cat $(which java) | file - /dev/stdin: Mach-O 64-bit executable arm64 The environment variable JAVA_HOME should also be set to this java version. You can check this by running echo $JAVA_HOME in your terminal. If it is not set, you can set it by adding export JAVA_HOME=$(/usr/libexec/java_home) to your ~/.zshrc file. If you are planning to use Annotators or Pipelines that use the RocksDB library (for example WordEmbeddings, TextMatcher or explain_document_dl_en Pipeline respectively) with spark-submit, then a workaround is required to get it working. See M1 RocksDB workaround for spark-submit with Spark version &gt;= 3.2.0. M1 RocksDB workaround for spark-submit with Spark version &gt;= 3.2.0 Starting from Spark version 3.2.0, Spark includes their own version of the RocksDB dependency. Unfortunately, this is an older version of RocksDB does not include the necessary binaries of M1. To work around this issue, the default packaged RocksDB jar has to be removed from the Spark distribution. For example, if you downloaded Spark version 3.2.0 from the official archives, you will find the following folders in the directory of Spark: $ ls bin conf data examples jars kubernetes LICENSE licenses NOTICE python R README.md RELEASE sbin yarn To check for the RocksDB jar, you can run $ ls jars | grep rocksdb rocksdbjni-6.20.3.jar to find the jar you have to remove. After removing the jar, the pipelines should work as expected. Scala and Java for M1 Adding Spark NLP to your Scala or Java project is easy: Simply change to dependency coordinates to spark-nlp-m1 and add the dependency to your project. How to do this is mentioned above: Scala And Java So for example for Spark NLP with Apache Spark 3.0.x and 3.1.x you will end up with maven coordinates like these: &lt;!-- https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp-m1 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.johnsnowlabs.nlp&lt;/groupId&gt; &lt;artifactId&gt;spark-nlp-m1_2.12&lt;/artifactId&gt; &lt;version&gt;4.3.2&lt;/version&gt; &lt;/dependency&gt; or in case of sbt: // https://mvnrepository.com/artifact/com.johnsnowlabs.nlp/spark-nlp libraryDependencies += &quot;com.johnsnowlabs.nlp&quot; %% &quot;spark-nlp-m1&quot; % &quot;4.3.2&quot; If everything went well, you can now start Spark NLP with the m1 flag set to true: import com.johnsnowlabs.nlp.SparkNLP val spark = SparkNLP.start(m1 = true) Python for M1 First, make sure you have a recent Python 3 installation. johnsnow@m1mac ~ % python3 --version Python 3.9.13 Then we can install the dependency as described in the Python section. It is also recommended to use a virtual environment for this. If everything went well, you can now start Spark NLP with the m1 flag set to True: import sparknlp spark = sparknlp.start(m1=True) Installation for Linux Aarch64 Systems Starting from version 4.3.2, Spark NLP supports Linux systems running on an aarch64 processor architecture. The necessary dependencies have been built on Ubuntu 16.04, so a recent system with an environment of at least that will be needed. Check the Python section and the Scala And Java section on to install Spark NLP for your system. Starting Spark NLP Spark NLP needs to be started with the aarch64 flag set to true: For Scala: import com.johnsnowlabs.nlp.SparkNLP val spark = SparkNLP.start(aarch64 = true) For Python: import sparknlp spark = sparknlp.start(aarch64=True) Google Colab Notebook Google Colab is perhaps the easiest way to get started with spark-nlp. It requires no installation or setup other than having a Google account. Run the following code in Google Colab notebook and start using spark-nlp right away. # This is only to setup PySpark and Spark NLP on Colab !wget https://setup.johnsnowlabs.com/colab.sh -O - | bash This script comes with the two options to define pyspark and spark-nlp versions via options: # -p is for pyspark # -s is for spark-nlp # by default they are set to the latest !wget https://setup.johnsnowlabs.com/colab.sh -O - | bash /dev/stdin -p 3.2.3 -s 4.3.2 Spark NLP quick start on Google Colab is a live demo on Google Colab that performs named entity recognitions and sentiment analysis by using Spark NLP pretrained pipelines. Kaggle Kernel Run the following code in Kaggle Kernel and start using spark-nlp right away. # Let&#39;s setup Kaggle for Spark NLP and PySpark !wget https://setup.johnsnowlabs.com/kaggle.sh -O - | bash Spark NLP quick start on Kaggle Kernel is a live demo on Kaggle Kernel that performs named entity recognitions by using Spark NLP pretrained pipeline. Databricks Support Spark NLP 4.3.2 has been tested and is compatible with the following runtimes: CPU: 7.3 7.3 ML 9.1 9.1 ML 10.1 10.1 ML 10.2 10.2 ML 10.3 10.3 ML 10.4 10.4 ML 10.5 10.5 ML 11.0 11.0 ML 11.1 11.1 ML 11.2 11.2 ML 11.3 11.3 ML 12.0 12.0 ML 12.1 12.1 ML 12.2 12.2 ML GPU: 9.1 ML &amp; GPU 10.1 ML &amp; GPU 10.2 ML &amp; GPU 10.3 ML &amp; GPU 10.4 ML &amp; GPU 10.5 ML &amp; GPU 11.0 ML &amp; GPU 11.1 ML &amp; GPU 11.2 ML &amp; GPU 11.3 ML &amp; GPU 12.0 ML &amp; GPU 12.1 ML &amp; GPU 12.2 ML &amp; GPU NOTE: Spark NLP 4.0.x is based on TensorFlow 2.7.x which is compatible with CUDA11 and cuDNN 8.0.2. The only Databricks runtimes supporting CUDA 11 are 9.x and above as listed under GPU. Install Spark NLP on Databricks Create a cluster if you don’t have one already On a new cluster or existing one you need to add the following to the Advanced Options -&gt; Spark tab: spark.kryoserializer.buffer.max 2000M spark.serializer org.apache.spark.serializer.KryoSerializer In Libraries tab inside your cluster you need to follow these steps: 3.1. Install New -&gt; PyPI -&gt; spark-nlp -&gt; Install 3.2. Install New -&gt; Maven -&gt; Coordinates -&gt; com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.2 -&gt; Install Now you can attach your notebook to the cluster and use Spark NLP! NOTE: Databrick’s runtimes support different Apache Spark major releases. Please make sure you choose the correct Spark NLP Maven pacakge name (Maven Coordinate) for your runtime from our Packages Cheatsheet Databricks Notebooks You can view all the Databricks notebooks from this address: https://johnsnowlabs.github.io/spark-nlp-workshop/databricks/index.html Note: You can import these notebooks by using their URLs. EMR Support Spark NLP 4.3.2 has been tested and is compatible with the following EMR releases: emr-6.2.0 emr-6.3.0 emr-6.3.1 emr-6.4.0 emr-6.5.0 emr-6.6.0 emr-6.7.0 emr-6.8.0 emr-6.9.0 emr-6.10.0 Full list of Amazon EMR 6.x releases NOTE: The EMR 6.1.0 and 6.1.1 are not supported. How to create EMR cluster via CLI To lanuch EMR cluster with Apache Spark/PySpark and Spark NLP correctly you need to have bootstrap and software configuration. A sample of your bootstrap script #!/bin/bash set -x -e echo -e &#39;export PYSPARK_PYTHON=/usr/bin/python3 export HADOOP_CONF_DIR=/etc/hadoop/conf export SPARK_JARS_DIR=/usr/lib/spark/jars export SPARK_HOME=/usr/lib/spark&#39; &gt;&gt; $HOME/.bashrc &amp;&amp; source $HOME/.bashrc sudo python3 -m pip install awscli boto spark-nlp set +x exit 0 A sample of your software configuration in JSON on S3 (must be public access): [{ &quot;Classification&quot;: &quot;spark-env&quot;, &quot;Configurations&quot;: [{ &quot;Classification&quot;: &quot;export&quot;, &quot;Properties&quot;: { &quot;PYSPARK_PYTHON&quot;: &quot;/usr/bin/python3&quot; } }] }, { &quot;Classification&quot;: &quot;spark-defaults&quot;, &quot;Properties&quot;: { &quot;spark.yarn.stagingDir&quot;: &quot;hdfs:///tmp&quot;, &quot;spark.yarn.preserve.staging.files&quot;: &quot;true&quot;, &quot;spark.kryoserializer.buffer.max&quot;: &quot;2000M&quot;, &quot;spark.serializer&quot;: &quot;org.apache.spark.serializer.KryoSerializer&quot;, &quot;spark.driver.maxResultSize&quot;: &quot;0&quot;, &quot;spark.jars.packages&quot;: &quot;com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.2&quot; } } ] A sample of AWS CLI to launch EMR cluster: aws emr create-cluster --name &quot;Spark NLP 4.3.2&quot; --release-label emr-6.2.0 --applications Name=Hadoop Name=Spark Name=Hive --instance-type m4.4xlarge --instance-count 3 --use-default-roles --log-uri &quot;s3://&lt;S3_BUCKET&gt;/&quot; --bootstrap-actions Path=s3://&lt;S3_BUCKET&gt;/emr-bootstrap.sh,Name=custome --configurations &quot;https://&lt;public_access&gt;/sparknlp-config.json&quot; --ec2-attributes KeyName=&lt;your_ssh_key&gt;,EmrManagedMasterSecurityGroup=&lt;security_group_with_ssh&gt;,EmrManagedSlaveSecurityGroup=&lt;security_group_with_ssh&gt; --profile &lt;aws_profile_credentials&gt; GCP Dataproc Support Create a cluster if you don’t have one already as follows. At gcloud shell: gcloud services enable dataproc.googleapis.com compute.googleapis.com storage-component.googleapis.com bigquery.googleapis.com bigquerystorage.googleapis.com REGION=&lt;region&gt; BUCKET_NAME=&lt;bucket_name&gt; gsutil mb -c standard -l ${REGION} gs://${BUCKET_NAME} REGION=&lt;region&gt; ZONE=&lt;zone&gt; CLUSTER_NAME=&lt;cluster_name&gt; BUCKET_NAME=&lt;bucket_name&gt; You can set image-version, master-machine-type, worker-machine-type, master-boot-disk-size, worker-boot-disk-size, num-workers as your needs. If you use the previous image-version from 2.0, you should also add ANACONDA to optional-components. And, you should enable gateway. gcloud dataproc clusters create ${CLUSTER_NAME} --region=${REGION} --zone=${ZONE} --image-version=2.0 --master-machine-type=n1-standard-4 --worker-machine-type=n1-standard-2 --master-boot-disk-size=128GB --worker-boot-disk-size=128GB --num-workers=2 --bucket=${BUCKET_NAME} --optional-components=JUPYTER --enable-component-gateway --metadata &#39;PIP_PACKAGES=spark-nlp spark-nlp-display google-cloud-bigquery google-cloud-storage&#39; --initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh On an existing one, you need to install spark-nlp and spark-nlp-display packages from PyPI. Now, you can attach your notebook to the cluster and use the Spark NLP! Amazon Linux 2 Support # Update Package List &amp; Install Required Packages sudo yum update sudo yum install -y amazon-linux-extras sudo yum -y install python3-pip # Create Python virtual environment and activate it: python3 -m venv .sparknlp-env source .sparknlp-env/bin/activate Check JAVA version: For Sparknlp versions above 3.x, please use JAVA-11 Checking Java versions installed on your machine: sudo alternatives --config java You can pick the index number (I am using java-8 as default - index 2): If you dont have java-11 or java-8 in you system, you can easily install via: sudo yum install java-1.8.0-openjdk Now, we can start installing the required libraries: pip install pyspark==3.3.1 pip install spark-nlp Docker Support For having Spark NLP, PySpark, Jupyter, and other ML/DL dependencies as a Docker image you can use the following template: #Download base image ubuntu 18.04 FROM ubuntu:18.04 ENV NB_USER jovyan ENV NB_UID 1000 ENV HOME /home/${NB_USER} ENV PYSPARK_PYTHON=python3 ENV PYSPARK_DRIVER_PYTHON=python3 RUN apt-get update &amp;&amp; apt-get install -y tar wget bash rsync gcc libfreetype6-dev libhdf5-serial-dev libpng-dev libzmq3-dev python3 python3-dev python3-pip unzip pkg-config software-properties-common graphviz RUN adduser --disabled-password --gecos &quot;Default user&quot; --uid ${NB_UID} ${NB_USER} # Install OpenJDK-8 RUN apt-get update &amp;&amp; apt-get install -y openjdk-8-jdk &amp;&amp; apt-get install -y ant &amp;&amp; apt-get clean; # Fix certificate issues RUN apt-get update &amp;&amp; apt-get install ca-certificates-java &amp;&amp; apt-get clean &amp;&amp; update-ca-certificates -f; # Setup JAVA_HOME -- useful for docker commandline ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64/ RUN export JAVA_HOME RUN echo &quot;export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/&quot; &gt;&gt; ~/.bashrc RUN apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* RUN pip3 install --upgrade pip # You only need pyspark and spark-nlp paclages to use Spark NLP # The rest of the PyPI packages are here as examples RUN pip3 install --no-cache-dir pyspark spark-nlp==3.2.3 notebook==5.* numpy pandas mlflow Keras scikit-spark scikit-learn scipy matplotlib pydot tensorflow==2.4.1 graphviz # Make sure the contents of our repo are in ${HOME} RUN mkdir -p /home/jovyan/tutorials RUN mkdir -p /home/jovyan/jupyter COPY data ${HOME}/data COPY jupyter ${HOME}/jupyter COPY tutorials ${HOME}/tutorials RUN jupyter notebook --generate-config COPY jupyter_notebook_config.json /home/jovyan/.jupyter/jupyter_notebook_config.json USER root RUN chown -R ${NB_UID} ${HOME} USER ${NB_USER} WORKDIR ${HOME} # Specify the default command to run CMD [&quot;jupyter&quot;, &quot;notebook&quot;, &quot;--ip&quot;, &quot;0.0.0.0&quot;] Finally, use jupyter_notebook_config.json for the password: { &quot;NotebookApp&quot;: { &quot;password&quot;: &quot;sha1:65adaa6ffb9c:36df1c2086ef294276da703667d1b8ff38f92614&quot; } } Windows Support In order to fully take advantage of Spark NLP on Windows (8 or 10), you need to setup/install Apache Spark, Apache Hadoop, Java and a Pyton environment correctly by following the following instructions: https://github.com/JohnSnowLabs/spark-nlp/discussions/1022 How to correctly install Spark NLP on Windows Follow the below steps to set up Spark NLP with Spark 3.2.3: Download Adopt OpenJDK 1.8 Make sure it is 64-bit Make sure you install it in the root of your main drive C: java. During installation after changing the path, select setting Path Download the pre-compiled Hadoop binaries winutils.exe, hadoop.dll and put it in a folder called C: hadoop bin from https://github.com/cdarlint/winutils/tree/master/hadoop-3.2.0/bin Note: The version above is for Spark 3.2.3, which was built for Hadoop 3.2.0. You might have to change the hadoop version in the link, depending on which Spark version you are using. Download Apache Spark 3.2.3 and extract it to C: spark. Set/add environment variables for HADOOP_HOME to C: hadoop and SPARK_HOME to C: spark. Add %HADOOP_HOME% bin and %SPARK_HOME% bin to the PATH environment variable. Install Microsoft Visual C++ 2010 Redistributed Package (x64). Create folders C: tmp and C: tmp hive If you encounter issues with permissions to these folders, you might need to change the permissions by running the following commands: %HADOOP_HOME% bin winutils.exe chmod 777 /tmp/hive %HADOOP_HOME% bin winutils.exe chmod 777 /tmp/ Requisites for PySpark We recommend using conda to manage your Python environment on Windows. Download Miniconda for Python 3.8 See Quick Install on how to set up a conda environment with Spark NLP. The following environment variables need to be set: PYSPARK_PYTHON=python Optionally, if you want to use the Jupyter Notebook runtime of Spark: first install it in the environment with conda install notebook then set PYSPARK_DRIVER_PYTHON=jupyter, PYSPARK_DRIVER_PYTHON_OPTS=notebook The environment variables can either be directly set in windows, or if only the conda env will be used, with conda env config vars set PYSPARK_PYTHON=python. After setting the variable with conda, you need to deactivate and re-activate the environment. Now you can use the downloaded binary by navigating to %SPARK_HOME% bin and running Either create a conda env for python 3.6, install pyspark==3.3.1 spark-nlp numpy and use Jupyter/python console, or in the same conda env you can go to spark bin for pyspark –packages com.johnsnowlabs.nlp:spark-nlp_2.12:4.3.2. Offline Spark NLP library and all the pre-trained models/pipelines can be used entirely offline with no access to the Internet. If you are behind a proxy or a firewall with no access to the Maven repository (to download packages) or/and no access to S3 (to automatically download models and pipelines), you can simply follow the instructions to have Spark NLP without any limitations offline: Instead of using the Maven package, you need to load our Fat JAR Instead of using PretrainedPipeline for pretrained pipelines or the .pretrained() function to download pretrained models, you will need to manually download your pipeline/model from Models Hub, extract it, and load it. Example of SparkSession with Fat JAR to have Spark NLP offline: spark = SparkSession.builder .appName(&quot;Spark NLP&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;,&quot;16G&quot;) .config(&quot;spark.driver.maxResultSize&quot;, &quot;0&quot;) .config(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;) .config(&quot;spark.jars&quot;, &quot;/tmp/spark-nlp-assembly-4.3.2.jar&quot;) .getOrCreate() You can download provided Fat JARs from each release notes, please pay attention to pick the one that suits your environment depending on the device (CPU/GPU) and Apache Spark version (3.x) If you are local, you can load the Fat JAR from your local FileSystem, however, if you are in a cluster setup you need to put the Fat JAR on a distributed FileSystem such as HDFS, DBFS, S3, etc. (i.e., hdfs:///tmp/spark-nlp-assembly-4.3.2.jar) Example of using pretrained Models and Pipelines in offline: # instead of using pretrained() for online: # french_pos = PerceptronModel.pretrained(&quot;pos_ud_gsd&quot;, lang=&quot;fr&quot;) # you download this model, extract it, and use .load french_pos = PerceptronModel.load(&quot;/tmp/pos_ud_gsd_fr_2.0.2_2.4_1556531457346/&quot;) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) # example for pipelines # instead of using PretrainedPipeline # pipeline = PretrainedPipeline(&#39;explain_document_dl&#39;, lang=&#39;en&#39;) # you download this pipeline, extract it, and use PipelineModel PipelineModel.load(&quot;/tmp/explain_document_dl_en_2.0.2_2.4_1556530585689/&quot;) Since you are downloading and loading models/pipelines manually, this means Spark NLP is not downloading the most recent and compatible models/pipelines for you. Choosing the right model/pipeline is on you If you are local, you can load the model/pipeline from your local FileSystem, however, if you are in a cluster setup you need to put the model/pipeline on a distributed FileSystem such as HDFS, DBFS, S3, etc. (i.e., hdfs:///tmp/explain_document_dl_en_2.0.2_2.4_1556530585689/)",
    "url": "/docs/en/install",
    "relUrl": "/docs/en/install"
  },
  "1225": {
    "id": "1225",
    "title": "Install NLP Libraries",
    "content": "Spark NLP For installing Spark NLP on your infrastructure please follow the instructions detailed here. Spark NLP for Healthcare For installing Spark NLP for Healthcare please follow the instructions detailed here. Spark OCR For installing Spark OCR please follow the instructions detailed here.",
    "url": "/docs/en/install_NLP_libraries",
    "relUrl": "/docs/en/install_NLP_libraries"
  },
  "1226": {
    "id": "1226",
    "title": "Installation",
    "content": "To install the johnsnowlabs Python library and all of John Snow Labs open source libraries, just run pip install johnsnowlabs This installs Spark-NLP, NLU , Spark-NLP-Display , Pyspark and other open source sub-dependencies. To quickly test the installation, you can run in your Shell: python -c &quot;from johnsnowlabs import *;print(nlu.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;))&quot; or in Python: from johnsnowlabs import * nlp.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;) The quickest way to get access to licensed libraries like Finance NLP, Legal NLP, Healthcare NLP or Visual NLP is to run the following in python: from johnsnowlabs import * nlp.install() This will display a Browser Window Pop Up or show a Clickable Button with Pop Up. Click on the Authorize button to allow the library to connect to your account on my.JohnSnowLabs.com and access you licenses. This will enable the installation and use of all licensed products for which you have a valid license. Make sure to Restart your Notebook after installation. Colab Button Where the Pop-Up leads you to: After clicking Authorize: Additional Requirements Make sure you have Java 8 installed, for setup instructions see How to install Java 8 for Windows/Linux/Mac? Windows Users must additionally follow every step precisely defined in How to correctly install Spark NLP for Windows? Install Licensed Libraries The following is a more detailed overview of the alternative installation methods and parameters you can use. The parameters of nlp.install()parameters fall into 3 categories: Authorization Flow Choice &amp; Auth Flow Tweaks Installation Targets such as Airgap Offline, Databricks, new Pytho Venv, Currently running Python Enviroment, or target Python Environment Installation process tweaks List all of your accessible Licenses You can use nlp.list_remote_licenses() to list all available licenses in your my.johnsnowlabs.com/ account and nlp.list_local_licenses() to list all locally cached licenses. Authorization Flows overview The johnsnowlabs library gives you multiple methods to authorize and provide your license when installing licensed libraries. Once access to your license is provided, it is cached locally ~/.johnsnowlabs/licenses and re-used when calling nlp.start() and nlp.install(), so you don’t need to authorize again. Only 1 licenses can be provided and will be cached during authorization flows. If you have multiple licenses you can re-run an authorization method and use the local_license_number and remote_license_number parameter choose between licenses you have access to. Licenses are locally numbered in order they have been provided, for more info see License Caching. Auth Flow Method Description Python nlp.install() usage Browser Based Login (OAuth) Localhost Browser window will pop up, where you can give access to your license. Use remote_license_number parameter to choose between licenses. Use remote_license_number parameter to choose between licenses nlp.install() Browser Based Login (OAuth) on Google Colab A button is displayed in your notebook, click it and visit new page to give access to your license. Use remote_license_number parameter to choose between licenses nlp.install() Access Token Vist my.johnsnowlabs.com to extract a token which you can provide to enable license access. See Access Token Example for more details nlp.install(access_token=my_token) License JSON file path Define JSON license file with keys defined by License Variable Overview and provide file path nlp.install(json_license_path=path) Auto-Detect License JSON file from os.getcwd() os.getcwd() directory is scanned for a .json file containing license keys defined by License Variable Overview nlp.install() Auto-Detect OS Environment Variables Environment Variables are scanned for license variables defined by License Variable Overview nlp.install() Auto-Detect Cached License in ~/.johnsnowlabs/licenses If you already have provided a license previously, it is cached in ~/.johnsnowlabs/licenses and automatically loaded. Use local_license_number parameter to choose between licenses if you have multiple nlp.install() Manually specify license data Set each license value as python parameter, defined by License Variable Overview nlp.install(hc_license=hc_license enterprise_nlp_secret=enterprise_nlp_secret ocr_secret=ocr_secret ocr_license=ocr_license aws_access_key=aws_access_key aws_key_id=aws_key_id) Optional Auth Flow Parameters Use these parameters to configure the preferred authorization flow. Parameter description browser_login Enable or disable browser based login and pop up if no license is provided or automatically detected. Defaults to True. force_browser_login If a cached license if found, no browser pop up occurs. Set True to force the browser pop up, so that you can download different license, if you have several ones. local_license_number Specify the license number when loading a cached license from jsl home and multiple licenses have been cached. Defaults to 0 which will use the very first license every provided to the johnsnowlabs library. remote_license_number Specify the license number to use with OAuth based approaches. Defaults to 0 which will use your first license from my.johnsnowlabs.com. store_in_jsl_home By default license data and Jars/Wheels are stored in JSL home directory. This enables nlp.start() and nlp.install() to re-use your information and you don’t have to specify on every run. Set to False to disable this caching behaviour. only_refresh_credentials Set to True if you don’t want to install anything and just need to refresh or index a new license. Defaults to False. Optional Installation Target Parameters Use these parameters to configure where to install the libraries. Parameter description python_exec_path Specify path to a python executable into whose environment the libraries will be installed. Defaults to the current executing Python process, i.e. sys.executable and it’s pip module is used for setup. venv_creation_path Specify path to a folder, in which a fresh venv will be created with all libraries. Using this parameter ignores the python_exec_path parameter, since the newly created venv’s python executable is used for setup. offline_zip_dir Specify path to a folder in which 3 sub-folders are created, py_installs, java_installs with corrosponding Wheels/Jars/Tars and licenses. It will additionallly be zipped. Install to Databricks with access Token See Databricks Documentation for extracting a token which you can provide to databricks access, see Databricks Install Section for more details. Optional Installation Process Parameters Use the following parameters to configure what should be installed. Parameter description install_optional By default install all open source libraries if missing. Set the False to disable. install_licensed By default installs all licensed libraries you have access to if they are missing. Set to False to disable. include_dependencies Defaults to True which installs all depeendencies. If set to False pip will be executed with the --no-deps argument under the hood. product Specify product to install. By default installs everything you have access to. only_download_jars By default all libraries are installed to the current environment via pip. Set to False to disable installing Python dependencies and only download jars to the John Snow Labs home directory. hardware_target Specify hardware install type, either cpu, gpu, apple_silicon, or aarch . Defaults to cpu. If you have a GPU and want to leverage CUDA, set gpu. If you are an Apple M1 or Arch user choose the corresponding types. py_install_type Specify Python installation type to use, either tar.gz or whl, defaults to whl. refresh_install Delete any cached files before installing by removing John Snow Labs home folder. This will delete your locally cached licenses. Automatic Databricks Installation Use any of the databricks auth flows to enable the johnsnowlabs library to automatically install all open source and licensed features into a Databricks cluster. You additionally must use one of the John Snow Labs License Authorization Flows to give access to your John Snow Labs license,which will be installed to your Databricks cluster. A John Snow Labs Home directory is constructed in the distributed Databricks File System/dbfs/johnsnowlabs which has all Jars, Wheels and License Information to run all features in a Databricks cluster. Databricks Auth Flow Method Description Python nlp.install() usage Access Token See Databricks Documentation for extracting a token which you can provide to databricks access, see Databricks Install Section for details nlp.install(databricks_cluster_id=my_cluster_id, databricks_host=my_databricks_host, databricks_token=my_access_databricks_token) Where to find your Databricks Access Token: Databricks Cluster Creation Parameters You can set the following parameters on the nlp.install() function to define properties of the cluster which will be created. See Databricks Cluster Creation for a detailed description of all parameters. Cluster creation Parameter Default Value block_till_cluster_ready True num_workers 1 cluster_name John-Snow-Labs-Databricks-Auto-Cluster🚀 node_type_id i3.xlarge driver_node_type_id i3.xlarge spark_env_vars None autotermination_minutes 60 spark_version 10.5.x-scala2.12 spark_conf None auto_scale None aws_attributes None ssh_public_keys None custom_tags None cluster_log_conf None enable_elastic_disk None cluster_source None instance_pool_id None headers None The created cluster License Variables Names for JSON and OS variables The following variable names are checked when using a JSON or environment variables based approach for installing licensed features or when using nlp.start() . You can find all of your license information on https://my.johnsnowlabs.com/subscriptions AWS_ACCESS_KEY_ID : Assigned to you by John Snow Labs. Must be defined. AWS_SECRET_ACCESS_KEY : Assigned to you by John Snow Labs. Must be defined. HC_SECRET : The secret for a version of the enterprise NLP engine library. Changes between releases. Can be omitted if you don’t have access to enterprise nlp. HC_LICENSE : Your license for the medical features. Can be omitted if you don’t have a medical license. OCR_SECRET : The secret for a version of the Visual NLP (Spark OCR) library. Changes between releases. Can be omitted if you don’t have a Visual NLP (Spark OCR) license. OCR_LICENSE : Your license for the Visual NLP (Spark OCR) features. Can be omitted if you don’t have a Visual NLP (Spark OCR) license. JSL_LEGAL_LICENSE: Your license for Legal NLP Features JSL_FINANCE_LICENSE Your license for Finance NLP Features NOTE: Instead of JSL_LEGAL_LICENSE, HC_LICENSE and JSL_FINANCE_LICENSE you may have 1 generic SPARK_NLP_LICENSE. Installation Examples Via Auto Detection &amp; Browser Login All default search locations are searched, if any credentials are found they will be used. If no credentials are auto-detected, a Browser Window will pop up, asking to authorize access to https://my.johnsnowlabs.com/ In Google Colab, a clickable button will appear, which will make a window pop up where you can authorize access to https://my.johnsnowlabs.com/. nlp.install() Via Access Token Get your License Token from My John Snow Labs nlp.install(access_token=&#39;secret&#39;) Where you find the license Via Json Secrets file Path to a JSON containing secrets, see License Variable Names for more details. nlp.install(json_file_path=&#39;my/secret.json&#39;) Via Manually defining Secrets Manually specify all secrets. Some of these can be omitted, see License Variable Names for more details. nlp.install( hc_license=&#39;Your HC License&#39;, fin_license=&#39;Your FIN License&#39;, leg_license=&#39;Your LEG License&#39;, enterprise_nlp_secret=&#39;Your NLP Secret&#39;, ocr_secret=&#39;Your OCR Secret&#39;, ocr_license=&#39;Your OCR License&#39;, aws_access_key=&#39;Your Access Key&#39;, aws_key_id=&#39;Your Key ID&#39;, ) Into Current Python Process Uses sys.executable by default, i.e. the Python that is currently running the program. nlp.install() Into Custom Python Env Using specific python executable, which is not the currently running python. Will use the provided python’s executable pip module to install libraries. nlp.install(python_exec_path=&#39;my/python.exe&#39;) Into freshly created venv Create a new Venv using the currently executing Pythons Venv Module. nlp.install(venv_creation_path=&#39;path/to/where/my/new/venv/will/be&#39;) Into Airgap/Offline Installation (Automatic) Create a Zip with all Jars/Wheels/Licenses you need to run all libraries in an offline environment. Step1: nlp.install(offline_zip_dir=&#39;path/to/where/my/zip/will/be&#39;) Step2: Transfer the zip file securely to your offline environment and unzip it. One option is the unix scp command. scp /to/where/my/zip/will/be/john_snow_labs.zip 123.145.231.001:443/remote/directroy Step3: Then from the remote machine shell unzip with: # Unzip all files to ~/johnsowlabs unzip remote/directory/jsl.zip -d ~/johnsowlabs Step4 (option1): Install the wheels via jsl: # If you unzipped to ~/johnsowlabs, then just update this setting before running and nlp.install() handles the rest for you! from johnsnowlabs import * nlp.settings.jsl_root = &#39;~/johnsowlabs&#39; # Make sure you have Java 8 installed! nlp.install() Step4 (option2): Install the wheels via pip: # Assuming you unzipped to ~/johnsnowlabs, you can install all wheels like this pip install ~/johnsnowlabs/py_installs/*.whl Step5: Test your installation Via shell: python -c &quot;from johnsnowlabs import *;print(nlu.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;))&quot; or in Python: from johnsnowlabs import * nlp.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;) Into Airgap/Offline Manual Download all files yourself from the URLs printed by nlp.install(). You will have to folly the Automatic Instructions starting from step (2) of the automatic installation. I.e. provide the files somehow on your offline machine. # Print all URLs to files you need to provide on your host machine nlp.install(offline=True) Into a freshly created Databricks cluster automatically To install in databricks you must provide your accessToken and hostUrl. You can provide the secrets to the install function with any of the methods listed above, i.e. using access_token , browser, json_file, or manually defining secrets Your can get it from: # Create a new Cluster with Spark NLP and all licensed libraries ready to go: nlp.install(databricks_host=&#39;https://your_host.cloud.databricks.com&#39;, databricks_token = &#39;dbapi_token123&#39;,) Into Existing Databricks cluster Manual If you do not wish to use the recommended automatic installation but instead want to install manually you must install the johnsnowlabs_for_databricks pypi package instead of johnsnowlabs via the UI or any method of your choice. License Management &amp; Caching Storage of License Data and License Search behaviour The John Snow Labs library caches license data in ~/.johnsnowlabs/licenses whenever a new one is provided . After having provided license data once, you don’t need to specify it again since the cached licensed will be used. Use the local_license_number and remote_license_number parameters to switch between multiple licenses. Note: Locally cached licenses are numbered in the order they have been provided, starting at 0. remote_license_number=0 might not be the same as local_license_number=0. Use the following functions to see all your avaiable licenses. List all available licenses This shows you all licenses for your account in https://my.johnsnowlabs.com/. Use this to decide which license number to install when installing via browser or access token. nlp.list_remote_licenses() List all locally cached licenses Use this to decide which license number to use when using nlp.start() or nlp.install() to specify which local license you want to load. nlp.list_local_licenses() License Search precedence If there are multiples possible sources for licenses, the following order takes precedence: Manually provided license data by defining all license parameters. Browser/ Access Token. Os environment Variables for any var names that match up with secret names. /content/*.json for any json file smaller than 1 MB. current_working_dir/*.json for any json smaller than 1 MB. ~/.johnsnowlabs/licenses for any licenses. JSON files are scanned if they have any keys that match up with names of secrets. Name of the json file does not matter, file just needs to end with .json. Upgrade Flow Step 1: Upgrade the johnsnowlabs library. pip install johnsnowlabs --upgrade Step 2: Run install again, while using one Authorization Flows. nlp.install() The John Snow Labs Teams are working early to push out new Releases and Features each week! Simply run pip install johnsnowlabs --upgrade to get the latest open source libraries updated. Once the johnsnowlabs library is upgraded, it will detect any out-dated libraries any inform you that you can upgrade them by running nlp.install() again. You must run one of the Authorization Flows again, to gian access to the latest enterprise libraries. Next Steps &amp; Frequently Asked Questions How to setup Java 8 Setup Java 8 on Windows Setup Java 8 on Linux Setup Java 8 on Mac Join our Slack channel Join our channel, to ask for help and share your feedback. Developers and users can help each other get started here. NLU Slack Where to go next If you want to get your hands dirty with any of the features check out the NLU examples page, or Licensed Annotators Overview Detailed information about Johnsnowlabs Libraries APIs, concepts, components and more can be found on the following pages : Starting a Spark Session John Snow Labs Library usage and import Overview The NLU load function The NLU predict function The NLU components spellbook NLU Notebooks",
    "url": "/docs/en/jsl/install_advanced",
    "relUrl": "/docs/en/jsl/install_advanced"
  },
  "1227": {
    "id": "1227",
    "title": "Installation",
    "content": "To install the johnsnowlabs Python library and all of John Snow Labs licensed libraries, just run run in your shell pip install johnsnowlabs run in a Python Shell from johnsnowlabs import * nlp.install() This will display a Browser Window Pop Up or show a Clickable Button with Pop Up. Click on the Authorize button to allow the library to connect to your account on my.JohnSnowLabs.com and access you licenses. This will enable the installation and use of all licensed products for which you have a valid license. Colab Button: Where the Pop-Up leads you to: After clicking Authorize: To quickly test your installation, run in a Python shell for alternative installation options see Custom Installation",
    "url": "/docs/en/jsl/install_licensed_quick",
    "relUrl": "/docs/en/jsl/install_licensed_quick"
  },
  "1228": {
    "id": "1228",
    "title": "Installation",
    "content": "Deploy using Docker For deploying NLP Server on your instance run the following command. docker run --pull=always -p 5000:5000 johnsnowlabs/nlp-server:latest This will check if the latest docker image is available on your local machine and if not it will automatically download and run it. If you want to keep downloaded models between restarts of the docker image, you can mount a volume. mkdir /var/cache_pretrained chown 1000:1000 /var/cache_pretrained docker run --pull=always -v /var/cache_pretrained:/home/johnsnowlabs/cache_pretrained -p 5000:5000 johnsnowlabs/nlp-server:latest Deploy using AWS Marketplace NLP Server on AWS Marketplace provides one of the fastest and easiest ways to get up and running on Amazon Web Services (AWS). NLP Server is available through AWS Marketplace free of charge. However, to use licensed spells in NLP Server, you need to buy our license from here. You can get NLP Server on AWS Marketplace from this URL. Follow the seven steps instructions or the video tutorial given below to learn how to deploy NLP Server using AWS Marketplace. Make sure you have a valid AWS account and log in to the AWS Marketplace using your credentials. Deploy NLP Server via AWS Marketplace 1.Click on Continue to subscribe button for creating a subscription to the NLP Server product. The software is free of charge. 2.Read the subscription EULA and click on Accept terms button if you want to continue. 3.In a couple of seconds the subscription becomes active. Once it is active you see this screen. 4.Go to AWS Marketplace &gt; Manage subscriptions and click on the Launch new instance button corresponding to the NLP Server subscription. This will redirect you to the following screen. Click on Continue to launch through EC2 button. 5.From the available options select the instance type you want to use for the deployment. Then click on Review and Lauch button. 6.Select an existing key pair or create a new one. This ensures a secured connection to the instance. If you create a new key make sure that you download and safely store it for future usage. Click on the Launch button. 7.While the instance is starting you will see this screen. Then the instance will appear on your EC2 Instances list. The NLP Server can now be accessed via a web browser at https://PUBLIC_EC2_IP. API documentation is also available at https://PUBLIC_EC2_IP/docs. Deploy using Azure Marketplace NLP Server on Azure Marketplace provides one of the fastest and easiest ways to get up and running on Microsoft Azure. NLP Server is available through Azure Marketplace free of charge. However, to use licensed spells in NLP Server, you need to buy our license from here. You can get NLP Server on Azure Marketplace from this URL. Follow the video tutorial given below to learn how to deploy NLP Server using Azure Marketplace. Deploy NLP Server using Azure Marketplace",
    "url": "/docs/en/nlp_server/installation",
    "relUrl": "/docs/en/nlp_server/installation"
  },
  "1229": {
    "id": "1229",
    "title": "John Snow Labs Configurations",
    "content": "Installed Library Version Settings Each version of the John Snow Labs library comes with a hardcoded set of versions for very of product of the John Snow Labs company. It will not accept library secrets which correspond to versions do not match the settings. This essentially prevents you from installing outdated or new but not deeply tested libraries, or from shooting yourself in the foot you might say. You can work around this protection mechanism, by configuring nlp.settings.enforce_versions=False. This will ignore bad secret versions. from johnsnowlabs import * nlp.settings.enforce_versions=False nlp.install(secret=&#39;1.2.3-My.Custom.or.Outdated.Secret&#39;) John Snow Labs Home Cache Folder The John Snow Labs library maintains a home folder in ~/.johnsnowlabs which contains all your Licenses, Jars for Java and Wheels for Python to install and run any feature. Additionally, each directory has an info.json file, telling you more about Spark compatibility, Hardware Targets and versions of the files. ~/.johnsnowlabs/ ├─ licenses/ │ ├─ info.json │ ├─ license1.json │ ├─ license2.json ├─ java_installs/ │ ├─ info.json │ ├─ app1.jar │ ├─ app2.jar ├─ py_installs/ │ ├─ info.json │ ├─ app1.tar.gz │ ├─ app2.tar.gz ├─ info.json",
    "url": "/docs/en/jsl/john-snow-labs-home",
    "relUrl": "/docs/en/jsl/john-snow-labs-home"
  },
  "1230": {
    "id": "1230",
    "title": "John Snow labs Usage & Overview",
    "content": "The John Snow Labs Python library gives you a clean and easy way to structure your Python projects. The very first line of a project should be: from johnsnowlabs import * This imports all licensed and open source Python modules installed from other John Snow Labs Products, as well as many handy utility imports. The following Functions, Classes and Modules will available in the global namespace The nlp Module nlp module with classes and methods from Spark NLP like nlp.BertForSequenceClassification and nlp.map_annotations() nlp.AnnotatorName via Spark NLP Annotators and Transformers i.e. nlp.BertForSequenceClassification Spark NLP Helper Functions i.e. nlp.map_annotations() nlp.F via import pyspark.sql.functions as F under the hood nlp.T via import pyspark.sql.types as T under the hood nlp.SQL via import pyspark.sql as SQL under the hood nlp.ML via from pyspark import ml as ML under the hood To see all the imports see the source The jsl Module jsl module with the following methods nlp.install() for installing John Snow Labs libraries and managing your licenses, more info here nlp.load() for predicting with any the 10k+ pretrained models in 1 line of code or training new ones, using the nlu.load() method under the hood nlp.start() for starting a Spark Session with access to features, more info here nlp.viz() for visualizing predictions with any of the 10k+ pretrained models using nlu.viz() under the hood nlp.viz_streamlit() and other `nlp.viz_streamlit_xyz for using any of the 10k+ pretrained models in 0 lines of code with an interactive Streamlit GUI and re-usable and stackable Streamlit Components nlp.to_pretty_df() for predicting on raw strings getting a nicely structures Pandas DF from a Spark Pipeline using nlu.to_pretty_df() under the hood The viz Module viz module with classes from Spark NLP Display viz.NerVisualizer for visualizing prediction outputs of Ner based Spark Pipelines viz.DependencyParserVisualizer for visualizing prediction outputs of DependencyParser based Spark Pipelines viz.RelationExtractionVisualizer for visualizing prediction outputs of RelationExtraction based Spark Pipelines viz.EntityResolverVisualizer for visualizing prediction outputs of EntityResolver based Spark Pipelines viz.AssertionVisualizer for visualizing prediction outputs of Assertion based Spark Pipelines The ocr Module ocr module with annotator classes and methods from Spark OCR like ocr.VisualDocumentClassifier and `ocr.helpful_method() Pipeline Components i.e. ocr.ImageToPdf Table Recognizers i.e. ocr.ImageTableDetector Visual Document Understanding i.e. ocr.VisualDocumentClassifier Object detectors i.e. ocr.ImageHandwrittenDetector Enums, Structures and helpers i.e. ocr.Color To see all the imports see the source The medical Module medical module with annotator classes and methods from Spark NLP for Medicine like medical.RelationExtractionDL and medical.profile() Medical Annotators , i.e. medical.DeIdentification Training Methods i.e. medical.AnnotationToolJsonReader Evaluation Methods, i.e. medical.NerDLEvaluation NOTE: Any class which has Medical in its name is available, but the Medical prefix has been omitted. I.e. medical.NerModel maps to sparknlp_jsl.annotator.MedicalNerModel This is achieved via from sparknlp_jsl.annotator import MedicalNerModel as NerModel under the hood. To see all the imports see the source The legal Module legal module with annotator classes and methods from Spark NLP for Legal like legal.RelationExtractionDL and legal.profile() Legal Annotators , i.e. legal.DeIdentification Training Methods i.e. legal.AnnotationToolJsonReader Evaluation Methods, i.e. legal.NerDLEvaluation NOTE: Any class which has Legal in its name is available, but the Legal prefix has been omitted. I.e. legal.NerModel maps to sparknlp_jsl.annotator.LegalNerModel This is achieved via from sparknlp_jsl.annotator import LegalNerModel as NerModel under the hood. To see all the imports see the source The finance Module finance module with annotator classes and methods from Spark NLP for Finance like finance.RelationExtractionDL and finance.profile() Finance Annotators , i.e. finance.DeIdentification Training Methods i.e. finance.AnnotationToolJsonReader Evaluation Methods, i.e. finance.NerDLEvaluation NOTE: Any class which has Finance in its name is available, but the Finance prefix has been omitted. I.e. finance.NerModel maps to sparknlp_jsl.annotator.FinanceNerModel This is achieved via from sparknlp_jsl.annotator import FinanceNerModel as NerModel under the hood. To see all the imports see the source",
    "url": "/docs/en/jsl/import-structure",
    "relUrl": "/docs/en/jsl/import-structure"
  },
  "1231": {
    "id": "1231",
    "title": "John Snow Labs Release Notes",
    "content": "See Github Releases for detailed information on Release History and Features. 5.0.8 Release date: 11-09-2023 The John Snow Labs 5.0.5 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 5.0.0 Enterprise NLP 5.0.2 Finance NLP 1.X.X Legal NLP 1.X.X NLU 5.0.1 Spark-NLP-Display 4.4 Spark-NLP 5.0.2 Pyspark 3.1.2 5.0.7 Release date: 3-09-2023 The John Snow Labs 5.0.5 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 5.0.0 Enterprise NLP 5.0.2 Finance NLP 1.X.X Legal NLP 1.X.X NLU 5.0.0 Spark-NLP-Display 4.4 Spark-NLP 5.0.2 Pyspark 3.1.2 5.0.6 Release date: 3-09-2023 The John Snow Labs 5.0.5 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 5.0.0 Enterprise NLP 5.0.2 Finance NLP 1.X.X Legal NLP 1.X.X NLU 5.0.0 Spark-NLP-Display 4.4 Spark-NLP 5.0.2 Pyspark 3.1.2 5.0.4 Release date: 25-08-2023 The John Snow Labs 5.0.5 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 5.0.0 Enterprise NLP 5.0.2 Finance NLP 1.X.X Legal NLP 1.X.X NLU 5.0.0 Spark-NLP-Display 4.4 Spark-NLP 5.0.2 Pyspark 3.1.2 5.0.4 Release date: 24-08-2023 The John Snow Labs 5.0.4 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 5.0.0 Enterprise NLP 5.0.2 Finance NLP 1.X.X Legal NLP 1.X.X NLU 5.0.0 Spark-NLP-Display 4.4 Spark-NLP 5.0.2 Pyspark 3.1.2 5.0.1 Release date: 02-08-2023 The John Snow Labs 5.0.1 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.4 Enterprise NLP 5.0.1 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.2 Spark-NLP-Display 4.4 Spark-NLP 5.0.1 Pyspark 3.1.2 5.0.0 Release date: 13-07-2023 The John Snow Labs 5.0.0 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.3 Enterprise NLP 5.0.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.2 Spark-NLP-Display 4.4 Spark-NLP 5.0.0 Pyspark 3.1.2 4.4.11 Release date: 11-07-2023 The John Snow Labs 4.4.11 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.3 Enterprise NLP 4.4.4 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.2 Spark-NLP-Display 4.4 Spark-NLP 4.4.4 Pyspark 3.1.2 4.4.10 Release date: 04-07-2023 The John Snow Labs 4.4.10 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.3 Enterprise NLP 4.4.4 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.2 Spark-NLP-Display 4.4 Spark-NLP 4.4.4 Pyspark 3.1.2 4.4.9 Release date: 04-07-2023 The John Snow Labs 4.4.9 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.3 Enterprise NLP 4.4.4 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.2 Spark-NLP-Display 4.4 Spark-NLP 4.4.1 Pyspark 3.1.2 4.4.8 Release date: 14-06-2023 The John Snow Labs 4.4.8 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.2 Enterprise NLP 4.4.3 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.2 Spark-NLP-Display 4.1 Spark-NLP 4.4.1 Pyspark 3.1.2 4.4.7 Release date: 06-06-2023 The John Snow Labs 4.4.7 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.2 Enterprise NLP 4.4.3 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.1 Spark-NLP-Display 4.1 Spark-NLP 4.4.1 Pyspark 3.1.2 4.4.6 Release date: 28-05-2023 The John Snow Labs 4.4.6 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.1 Enterprise NLP 4.4.2 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.0 Spark-NLP-Display 4.1 Spark-NLP 4.4.1 Pyspark 3.1.2 create_jsl_home_if_missing parameter added to nlp.start() which can be set to False to disable the creation of the ~/.johnsnowlabs directory. This is useful when jars are provided directly via jar_paths parameter. Dynamic Wheel resolution for spark nlp, enabling you to set settings.nlp_version=’4.4.2’ and it will automatically use the appropriate jars and wheels when starting a session or building an envirornment. Bump Enterprise NLP version to 4.4.2 Bump OCR version to 4.4.1 Fixed erronous handling of enterprise-secrets which have &lt;VERSION&gt;.&lt;PR-NUM&gt;.&lt;COMMIT_HASH&gt; pattern, 4.4.5 Release date: 03-05-2023 The John Snow Labs 4.4.5 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.0 Enterprise NLP 4.4.1 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.0 Spark-NLP-Display 4.1 Spark-NLP 4.4.1 Pyspark 3.1.2 4.4.4 Release date: 26-04-2023 The John Snow Labs 4.4.4 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.0 Enterprise NLP 4.4.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.0 Spark-NLP-Display 4.1 Spark-NLP 4.4.1 Pyspark 3.1.2 4.4.3 Release date: 26-04-2023 The John Snow Labs 4.4.3 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.0 Enterprise NLP 4.4.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.0 Spark-NLP-Display 4.1 Spark-NLP 4.4.1 Pyspark 3.1.2 4.4.2 Release date: 18-04-2023 The John Snow Labs 4.4.2 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.4.0 Enterprise NLP 4.4.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.0 Spark-NLP-Display 4.1 Spark-NLP 4.4.0 Pyspark 3.1.2 4.4.1 Release date: 13-04-2023 The John Snow Labs 4.4.1 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.3 Enterprise NLP 4.4.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.0 Spark-NLP-Display 4.1 Spark-NLP 4.4.0 Pyspark 3.1.2 4.4.0 Release date: 12-04-2023 The John Snow Labs 4.4.0 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.3 Enterprise NLP 4.4.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.0 Spark-NLP-Display 4.1 Spark-NLP 4.4.0 Pyspark 3.1.2 4.3.5 Release date: 25-03-2023 The John Snow Labs 4.3.5 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.3 Enterprise NLP 4.3.2 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.0 Spark-NLP-Display 4.1 Spark-NLP 4.3.2 Pyspark 3.1.2 4.3.4 Release date: 20-03-2023 The John Snow Labs 4.3.4 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.3 Enterprise NLP 4.3.1 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.2.0 Spark-NLP-Display 4.1 Spark-NLP 4.3.2 Pyspark 3.1.2 4.3.3 Release date: 23-02-2023 The John Snow Labs 4.3.3 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.1 Enterprise NLP 4.3.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc6 Spark-NLP-Display 4.1 Spark-NLP 4.3.0 Pyspark 3.1.2 4.3.2 Release date: 21-02-2023 The John Snow Labs 4.3.2 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.3.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc6 Spark-NLP-Display 4.1 Spark-NLP 4.3.0 Pyspark 3.1.2 4.3.1 Release date: 14-02-2023 The John Snow Labs 4.3.1 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.3.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc5 Spark-NLP-Display 4.1 Spark-NLP 4.3.0 Pyspark 3.1.2 4.3.0 Release date: 14-02-2023 The John Snow Labs 4.3.0 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.3.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.3.0 Pyspark 3.1.2 4.2.9 Release date: 01-02-2023 The John Snow Labs 4.2.9 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.2.8 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.8 Pyspark 3.1.2 4.2.8 Release date: 29-01-2023 The John Snow Labs 4.2.8 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.2.8 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.8 Pyspark 3.1.2 4.2.5 Release date: 27-12-2022 The John Snow Labs 4.2.5 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.2.4 Enterprise NLP 4.2.4 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.4 Pyspark 3.1.2 4.2.4 Release date: 21-12-2022 The John Snow Labs 4.2.4 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.2.1 Enterprise NLP 4.2.4 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.4 Pyspark 3.1.2 4.2.3 Release date: 02-12-2022 The John Snow Labs 4.2.3 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.2.1 Enterprise NLP 4.2.3 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.4 Pyspark 3.1.2 4.2.2 Release date: 17-10-2022 The John Snow Labs 4.2.2 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.2.0 Enterprise NLP 4.2.2 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.2 Pyspark 3.1.2 4.2.1 Release date: 10-10-2022 The John Snow Labs 4.2.1 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.1.0 Enterprise NLP 4.2.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.1 Pyspark 3.1.2 4.2.0 Release date: 06-10-2022 The John Snow Labs 4.2.0 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.0.0 Enterprise NLP 4.2.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.0 Pyspark 3.1.2",
    "url": "/docs/en/jsl/jsl-release-notes",
    "relUrl": "/docs/en/jsl/jsl-release-notes"
  },
  "1232": {
    "id": "1232",
    "title": "Labs, Tests, and Vitals - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/labs_tests_and_vitals",
    "relUrl": "/labs_tests_and_vitals"
  },
  "1233": {
    "id": "1233",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ld_dl/language_detector_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ld_dl/language_detector_dl.html"
  },
  "1234": {
    "id": "1234",
    "title": "African Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/languages_africa",
    "relUrl": "/languages_africa"
  },
  "1235": {
    "id": "1235",
    "title": "Languages of India - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/languages_india",
    "relUrl": "/languages_india"
  },
  "1236": {
    "id": "1236",
    "title": "",
    "content": "",
    "url": "/latest.html",
    "relUrl": "/latest.html"
  },
  "1237": {
    "id": "1237",
    "title": "Learn",
    "content": "Introductions to Spark NLP Videos State of the Art Natural Language Processing at Scale. David Talby - April 13, 2020 Spark NLP: State of the art natural language processing at scale. David Talby - 4 Jun 2020 What is Spark NLP. John Snow Labs - 30 Jul 2019 Apache Spark NLP Extending Spark ML to Deliver Fast, Scalable, and Unified Natural Language Process. David Talby - 6 May 2019 Natural Language Understanding at Scale with Spark Native NLP, Spark ML &amp;TensorFlow with Alex Thomas. Alex Thomas - 26 Oct 2017 Articles Introducing the Natural Language Processing Library for Apache SparkDavid Talby - October 19, 2017 Improving Clinical Document Understanding on COVID-19 Research with Spark NLPVeysel Kocaman, David Talby - 7 December, 2020 Topic Modelling with PySpark and Spark NLPMaria Obedkova - May 29, 2020 Installing Spark NLP and Spark OCR in air-gapped networks (offline mode)Veysel Kocaman - May 04, 2020 Cleaning and extracting text from HTML/XML documents by using Spark NLPStefano Lori - Jan 13, 2020 A Google Colab Notebook Introducing Spark NLPVeysel Kocaman - September, 2020 State-of-the-art Natural Language Processing at ScaleDavid Talby - April 13, 2020 How to Wrap Your Head Around Spark NLPMustafa Aytuğ Kaya - August 25, 2020 5 Reasons Why Spark NLP Is The Most Widely Used Library In EnterprisesAmbika Choudhury - May 28, 2019 My Experience with SparkNLP Workshop &amp; CertificationAngelina Maria Leigh - August 17, 2020 Out of the box Spark NLP models in actionDia Trambitas - August 14, 2020 Get started with Machine Learning in Java using Spark NLPWill Price - August 27, 2020 SPARK NLP 3: MASSIVE SPEEDUPS &amp; THE LATEST COMPUTE PLATFORMSMaziyar Panahi - March 25, 2021 SPARK NLP 2.7: 720+ NEW MODELS &amp; PIPELINES FOR 192 LANGUAGES!David Talby - January 05, 2021 Python’s NLU Library Videos &quot;Python&#39;s NLU library: 1,000+ Models, 200+ Languages, 1 Line of Code&quot; by: Christian Kasim Loan - 18 June 2021 John Snow Labs NLU: Become a Data Science Superhero with One Line of Python code. Christian Kasim Loan - November, 2020 Articles 1 line to GLOVE Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to XLNET Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to ALBERT Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to COVIDBERT Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to ELECTRA Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to BioBERT Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 Line of Code, 350 + NLP Models with John Snow Labs’ NLU in PythonChristian Kasim Loan - September 21, 2020 Easy sentence similarity with BERT Sentence Embeddings using John Snow Labs NLUChristian Kasim Loan - November 20, 2020 Training Deep Learning NLP Classifier TutorialChristian Kasim Loan - November 20, 2020 1 Python Line for ELMo Word Embeddings and t-SNE plots with John Snow Labs’ NLUChristian Kasim Loan - October 24, 2020 1 line of Python code for BERT, ALBERT, ELMO, ELECTRA, XLNET, GLOVE, Part of Speech with NLU and t-SNEChristian Kasim Loan - September 21, 2020 1 line to BERT Word Embeddings with NLU in PythonChristian Kasim Loan - September 21, 2020 Question answering, intent classification, aspect based ner, and new multilingual models in python’s NLU libraryChristian Kasim Loan - February 12, 2021 Intent and action classification, analyze chinese news and crypto market, 200+ languages &amp; answer questions with NLU 1.1.3Christian Kasim Loan - March 02, 2021 Hindi wordembeddings, bengali named entity recognition, 30+ new models, analyze crypto news with NLU 1.1.2Christian Kasim Loan - February 18, 2021 Named Entity Recognition Videos State-of-the-art Clinical Named Entity Recognition in Spark NLP Workshop - Veysel Kocaman Train your own NerDL. John Snow Labs - 7 Oct 2019 Articles State-of-the-art named entity recognition with BERTVeysel Kocaman - February 26th, 2020 State-of-the-art Named Entity Recognition in Spark NLPVeysel Kocaman Spark NLP in action: intelligent, high-accuracy fact extraction from long financial documentsSaif Addin Ellafi - May 5, 2020 Named Entity Recognition (NER) with BERT in Spark NLPVeysel Kocaman - Mar 4, 2020 Document Classification Videos Spark NLP in Action: Learning to read Life Science research - Saif Addin Ellafi. Saif Addin Ellafi - 1 Aug 2018 State of the art emotion and sentiment analysis with Spark NLP (Data science Salon). Dia Trambitas - December 1, 2020 Articles GloVe, ELMo &amp; BERT. A guide to state-of-the-art text classification using Spark NLP Ryan Burke - March 16, 2021 Distributed Topic Modelling using Spark NLP and Spark MLLib(LDA)Satish Silveri - June 11, 2020 Text Classification in Spark NLP with Bert and Universal Sentence EncodersVeysel Kocaman - April 12, 2020 Classification of Unstructured Documents into the Environmental, Social &amp; Governance (ESG) TaxonomyAlina Petukhova - May, 2020 Using Spark NLP to build a drug discovery knowledge graph for COVID-19Vishnu Vettrivel, Alexander Thomas - October 8, 2020 Build Text Categorization Model with Spark NLPSatish Silveri - Jul 8 2020 Topic Modelling with PySpark and Spark NLPMaria Obedkova - May 29 2020 Spark NLP Tasks &amp; Pipelines Videos Spark NLP Annotators, Annotations and Pipelines. John Snow Labs - 23 Oct 2019 Your first Spark NLP Pipeline. John Snow Labs - 23 Oct 2019 Natural Language Understanding at Scale with Spark NLP | DSS 2020. Veysel Kocaman - December 12, 2020 Articles Cleaning and extracting text from HTML/XML documents by using Spark NLPStefano Lori - January 13 2021 NER model with ELMo Embeddings in 5 minutes in Spark-NLPChristian Kasim Loan - Jule 2020 Applying Context Aware Spell Checking in Spark NLPAlberto Andreotti - May 2020 Spark nlp 2.5 delivers state-of-the-art accuracy for spell checking and sentiment analysisIda Lucente - May 12, 2020 Spark NLP 2.4: More Accurate NER, OCR, and Entity ResolutionIda Lucente - February 14, 2020 Introduction to Spark NLP: Foundations and Basic Components (Part-I)Veysel Kocaman - Sep 29, 2019 Introducing Spark NLP: Why would we need another NLP library (Part-I)Veysel Kocaman - October 22, 2019 Introducing Spark NLP: basic components and underlying technologies (Part-III)Veysel Kocaman - December 2, 2019 Explain document DL – Spark NLP pretrained pipelineVeysel Kocaman - January 15, 2020 Spark NLP Walkthrough, powered by TensorFlowSaif Addin Ellafi - Nov 19, 2018 Natural Language Processing with PySpark and Spark-NLPAllison Honold - Feb 5, 2020 Spark NLP for Healthcare Videos Advancing the State of the Art in Applied Natural Language Processing | Healthcare NLP Summit 2021. David Talby - 21 Apr 2021 How to Apply State-of-the-Art Natural Language Processing in Healthcare. David Talby - 15 Sep 2020 Advanced Natural Language Processing with Apache Spark NLP. David Talby - 20 Aug 2020 Applying State-of-the-art Natural Language Processing for Personalized Healthcare. David Talby - April 13, 2020 State-of-the-art Natural Language Processing at Scale. David Talby - April 13, 2020 Apache SPARK NLP: Extending SPARK ML to Deliver Fast, Scalable &amp; Unified Natural Language Processing. David Talby - June 04, 2018 State of the Art Natural Language Processing at Scale. David Talby - June 04, 2018 Spark NLP in Action: Learning to read Life Science research. Saif Addin Ellafi - May 28, 2018 Natural Language Understanding at Scale with Spark-Native NLP, Spark ML, and TensorFlow. Alexander Thomas - October 14, 2018 Apache Spark NLP for Healthcare: Lessons Learned Building Real-World Healthcare AI Systems. Veysel Kocaman - 9 Jul 2020 SNOMED entity resolver. John Snow Labs - 31 Jul 2020 NLP and its applications in Healthcare. Veysel Kocaman - 17 May 2020 Lessons Learned Building Real-World Healthcare AI Systems. Veysel Kocaman - April 13, 2020 Application of Spark NLP for Development of Multi-Modal Prediction Model from EHR | Healthcare NLP. Sutanay Choudhury - 14 Apr 2021 Best Practices in Improving NLP Accuracy for Clinical Use Cases I Healthcare NLP Summit 2021. Rajesh Chamarthi, Veysel Kocaman - 15 Apr 2021 Articles Contextual Parser: Increased Flexibility Extracting Entities in Spark NLPLuca Martial - Feb 09 2022 Named Entity Recognition for Healthcare with SparkNLP NerDL and NerCRFMaggie Yilmaz - Jul 20 2020 Roche automates knowledge extraction from pathology reports with Spark NLPCase Study Spark NLP in action: Improving patient flow forecastingCase Study Using Spark NLP to Enable Real-World Evidence (RWE) and Clinical Decision Support in OncologyVeysel Kocaman - April 13, 2020 Applying State-of-the-art Natural Language Processing for Personalized HealthcareDavid Talby - April 13, 2020 Automated Mapping of Clinical Entities from Natural Language Text to Medical TerminologiesAndrés Fernández - April 29 2020 Contextual Parser in Spark NLP: Extracting Medical Entities ContextuallyAlina Petukhova - May 28 2020 Deep6 accelerates clinical trial recruitment with Spark NLPCase Study SelectData uses AI to better understand home health patientsCase Study Explain Clinical Document Spark NLP Pretrained PipelineVeysel Kocaman - January 20, 2020 Introducing Spark NLP: State of the art NLP Package (Part-II)Veysel Kocaman - January 20, 2020 Automated Adverse Drug Event (ADE) Detection from Text in Spark NLP with BioBertVeysel Kocaman - Octover 4, 2020 Normalize drug names and dosage units with spark NLPDavid Cecchini - February 23, 2021 Spark NLP for healthcare 2.7.3 with biobert extraction models, higher accuracy, de-identification, new radiology ner model &amp; moreVeysel Kocaman - February 09, 2021 Spark OCR &amp; De-Identification Videos Maximizing Text Recognition Accuracy with Image Transformers in Spark OCR. Mykola Melnyk - June 24, 2020 Accurate de-identification, obfuscation, and editing of scanned medical documents and images. Alina Petukhova - August 19, 2020 Accurate De-Identification of Structured &amp; Unstructured Medical Data at Scale. Julio Bonis - March 18, 2020 Articles A Unified CV, OCR &amp; NLP Model Pipeline for Document Understanding at DocuSignPatrick Beukema, Michael Chertushkin - October 6, 2020 Scaling High-Accuracy Text Extraction from Images using Spark OCR on DatabricksMikola Melnyk - July 2, 2020 Spark NLP at Scale Videos Turbocharging State-of-the-art Natural Language Processing on Ray. David Talby - October 3, 2020 Articles Big Data Analysis of Meetup Events using Spark NLP, Kafka and Vegas VisualizationAndrei Deuşteanu - August 25, 2020 Setup Spark NLP on Databricks in 2 Minutes and get the taste of scalable NLPChristian Kasim Loan - May 25, 2020 Real-time trending topic detection using Spark NLP, Kafka and Vegas VisualizationValentina Crisan - Oct 15, 2020 Mueller Report for Nerds! Spark meets NLP with TensorFlow and BERTMaziyar Panahi - May 1, 2019 Spark in Docker in Kubernetes: A Practical Approach for Scalable NLPJürgen Schmidl - Jan 18 2020 Running Spark NLP in Docker Container for Named Entity Recognition and Other NLP FeaturesYuefeng Zhang - Jun 5 2020 Annotation Lab Videos Accelerating Clinical Data Abstraction and Real-World Data Curation with Active Learning, Dia Trambitas - Apr 15, 2021 MLOPS Veysel &amp; Dia. Dia Trambitas, Veysel Kocaman - July 16, 2020 Best Practices &amp; Tools for Accurate Document Annotation and Data Abstraction. Dia Trambitas - May 27, 2020 Articles John Snow Labs’ data annotator &amp; active learning for human-in-the-loop AI is now included with all subscriptionsIda Lucente - May 26, 2020 Auto NLP: Pretrain, Tune &amp; Deploy State-of-the-art Models Without CodingDia Trambitas - October 6, 2020 Lesson Learned annotating training data for healthcare NLP projectsRebecca Leung, Marianne Mak - October 8, 2020 Task review workflows in the annotation labDia Trambitas - March 08, 2021 The annotation lab 1.1 is here with improvements to speed, accuracy, and productivityIda Lucente - January 20, 2021 Tips and tricks on how to annotate assertion in clinical textsMauro Nievas Offidani - November 24, 2020 Spark NLP Benchmarks Articles Biomedical Named Entity Recognition at ScaleVeysel Kocaman, David Talby - November 12, 2020 NLP Industry Survey Analysis: the industry landscape of natural language use cases in 2020Paco Nathan - October 6, 2020 Comparing the Functionality of Open Source Natural Language Processing LibrariesMaziyar Panahi and David Talby - April 7, 2019 SpaCy or Spark NLP — A Benchmarking ComparisonMustafa Aytuğ Kaya - Aug 27, 2020 Comparing production-grade NLP libraries: Training Spark-NLP and spaCy pipelinesSaif Addin Ellafi - February 28, 2018 Comparing production-grade NLP libraries: Running Spark-NLP and spaCy pipelinesSaif Addin Ellafi - February 28, 2018 Comparing production-grade NLP libraries: Accuracy, performance, and scalabilitySaif Addin Ellafi - February 28, 2018 Spark NLP Awards Articles John Snow Labs is healthcare tech outlook’s 2020 healthcare analytics provider of the yearIda Lucente - July 14, 2020 John Snow Labs wins the 2020 artificial intelligence excellence awardIda Lucente - April 27, 2020 John Snow Labs is named ‘2019 ai platform of the yearIda Lucente - August 14, 2019 Spark NLP is the world’s most widely used nlp library by enterprise practitionersIda Lucente - May 6, 2019 John Snow Labs’ spark nlp wins “most significant open source project” at the strata data awardsIda Lucente April 1 - 2019 John Snow Labs named “artificial intelligence solution provider of the year” by cio reviewIda Lucente - February 7, 2019",
    "url": "/learnold",
    "relUrl": "/learnold"
  },
  "1238": {
    "id": "1238",
    "title": "The NLP Learning Hub",
    "content": "The Technology Spark NLP Healthcare NLP Spark OCR NLP Lab Auto NLP Multimodal AI The Technology in Action Medical AI Applications Finance AI Applications De-Identification Multilingual NLP NLP on Databricks Industry Trends AI in Healthcare No-Code AI Responsible NLP Data Philanthropy Announcements Awards",
    "url": "/learn",
    "relUrl": "/learn"
  },
  "1239": {
    "id": "1239",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/legal_assertion_status",
    "relUrl": "/legal_assertion_status"
  },
  "1240": {
    "id": "1240",
    "title": "Normalization & Data Augmentation - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_company_normalization",
    "relUrl": "/legal_company_normalization"
  },
  "1241": {
    "id": "1241",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/legal_deidentification",
    "relUrl": "/legal_deidentification"
  },
  "1242": {
    "id": "1242",
    "title": "Legal Document Understanding - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_document_understanding",
    "relUrl": "/legal_document_understanding"
  },
  "1243": {
    "id": "1243",
    "title": "Recognize Legal Entities - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_entity_recognition",
    "relUrl": "/legal_entity_recognition"
  },
  "1244": {
    "id": "1244",
    "title": "Legal Models - Medical Large Language Models Demos & Notebooks",
    "content": "",
    "url": "/legal_models",
    "relUrl": "/legal_models"
  },
  "1245": {
    "id": "1245",
    "title": "Legal Question Answering in Legal NLP - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_question_answering",
    "relUrl": "/legal_question_answering"
  },
  "1246": {
    "id": "1246",
    "title": "Extract Legal Relationships - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_relation_extraction",
    "relUrl": "/legal_relation_extraction"
  },
  "1247": {
    "id": "1247",
    "title": "Legal NLP Release Notes",
    "content": "Releases log         1.0.0 1.1.0 1.2.0 1.3.0 1.4.0 1.5.0 1.6.0 1.7.0 1.8.0 1.9.0     Slack - Join #legal channel",
    "url": "/docs/en/legal_release_notes",
    "relUrl": "/docs/en/legal_release_notes"
  },
  "1248": {
    "id": "1248",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/legal_table_extraction",
    "relUrl": "/legal_table_extraction"
  },
  "1249": {
    "id": "1249",
    "title": "Classify Legal Texts - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_text_classification",
    "relUrl": "/legal_text_classification"
  },
  "1250": {
    "id": "1250",
    "title": "Text Summarization - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_text_summarization",
    "relUrl": "/legal_text_summarization"
  },
  "1251": {
    "id": "1251",
    "title": "Version Compatibility",
    "content": "Legal NLP runs on top of johnsnowlabs library (former nlu). Please find technical documentation about how to install it here. All our models are backwards compatible, which means it will be safe for you to always use the last version of johnsnowlabs. If you are curious about which version of Spark NLP, Visual NLP or Clinical NLP are included in the last johnsnowlabs versions, please check here Legal NLP is also supported in Annotation Lab from Alab 4.2.3 version on!",
    "url": "/docs/en/legal_version_compatibility",
    "relUrl": "/docs/en/legal_version_compatibility"
  },
  "1252": {
    "id": "1252",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/lemmatizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/lemmatizer.html"
  },
  "1253": {
    "id": "1253",
    "title": "Enterprise Spark NLP",
    "content": "PythonScalaNLU spark-nlp-jsljohnsnowlabs ... pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;sentence&quot;]) .setOutputCol(&quot;pos&quot;) pos_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, pos]) light_pipeline = LightPipeline(pos_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))) result = light_pipeline.fullAnnotate(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) ... pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;sentence&quot;]) .setOutputCol(&quot;pos&quot;) pos_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, pos]) light_pipeline = LightPipeline(pos_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))) result = light_pipeline.fullAnnotate(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) val pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;token&quot;,&quot;sentence&quot;) .setOutputCol(&quot;pos&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, pos)) val data = Seq(&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) import nlu nlu.load(&quot;en.pos.clinical&quot;).predict(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) Getting started We call Enterprise Spark NLP libraries to all the commercial NLP libraries, including Healthcare NLP (former Spark NLP for Healthcare), Finance, Legal NLP, among others. This excludes Visual NLP (former Spark OCR), which has its own documentation page, available here. If you don’t have an Enterprise Spark NLP subscription yet, you can ask for a free trial by clicking on the Try Free button and following the instructions provides in the video below. Try Free 30-day free trials for the John Snow Labs NLP libraries can be obtained via AWS and Azure markeplaces. To get a free trial please subscribe to one of the pay-as-you-go products: John Snow Labs NLP Libraries - AWS Marketplace John Snow Labs NLP Libraries - Azure Marketplace Note: It is important to note that every AWS/Azure account is limited to one 30-day free trial period for John Snow Labs NLP Libraries, and users are responsible for verifying the status of any past trials before subscribing and being charged for usage. Enterprise Spark NLP libraries provides healthcare-specific annotators, pipelines, models, and embeddings for: Entity recognition Entity Linking Entity normalization Assertion Status Detection De-identification Relation Extraction Spell checking &amp; correction and much more!",
    "url": "/docs/en/license_getting_started",
    "relUrl": "/docs/en/license_getting_started"
  },
  "1254": {
    "id": "1254",
    "title": "License Management & Caching",
    "content": "Storage of License Data and License Search behaviour The John Snow Labs library caches license data in ~/.johnsnowlabs/licenses whenever a new one is provided . After having provided license data once, you don’t need to specify it again since the cached licensed will be used. Use the local_license_number and remote_license_number parameters to switch between multiple licenses. Note: Locally cached licenses are numbered in the order they have been provided, starting at 0. remote_license_number=0 might not be the same as local_license_number=0. Use the following functions to see all your avaiable licenses. List all available licenses This shows you all licenses for your account in https://my.johnsnowlabs.com/ . Use this to decide which license number to install when installing via browser or access token. nlp.list_remote_licenses() List all locally cached licenses Use this to decide which license number to use when using nlp.start() or nlp.install() to specify which local license you want to load. nlp.list_local_licenses() License Search precedence If there are multiples possible sources for licenses, the following order takes precedence: Manually provided license data by defining all license parameters. Browser/ Access Token. Os environment Variables for any var names that match up with secret names. /content/*.json for any json file smaller than 1 MB. current_working_dir/*.json for any json smaller than 1 MB. ~/.johnsnowlabs/licenses for any licenses. JSON files are scanned if they have any keys that match up with names of secrets. Name of the json file does not matter, file just needs to end with .json.",
    "url": "/docs/en/jsl/license_management",
    "relUrl": "/docs/en/jsl/license_management"
  },
  "1255": {
    "id": "1255",
    "title": "Enterprise NLP Annotators",
    "content": "A Spark NLP Enterprise license includes access to unique annotators. At the Spark NLP Workshop you can see different types of annotators in action. By clicking on any annotator, you will see different sections: The Approach, or class to train models. The Model, to infer using pretrained models. Also, for most of the annotators, you will find examples for the different enterprise libraries: Healthcare NLP Finance NLP Legal NLP Check out the Spark NLP Annotators page for more information on how to read this page. Available Annotators Annotators Description AssertionDL AssertionDL is a deep Learning based approach used to extract Assertion Status from extracted entities and text. AssertionFilterer Filters entities coming from ASSERTION type annotations and returns the CHUNKS. AssertionLogReg Logistic Regression is used to extract Assertion Status from extracted entities and text. Chunk2Token A feature transformer that converts the input array of strings (annotatorType CHUNK) into an array of chunk-based tokens (annotatorType TOKEN). ChunkEntityResolver Returns a normalized entity for a particular trained ontology / curated dataset (e.g. clinical ICD-10, RxNorm, SNOMED; financial SEC’s EDGAR database, etc). ChunkFilterer Filters entities coming from CHUNK annotations. ChunkKeyPhraseExtraction Uses Bert Sentence Embeddings to determine the most relevant key phrases describing a text. ChunkMerge Merges entities coming from different CHUNK annotations. ContextualParser Extracts entity from a document based on user defined rules. DeIdentification Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS. DocumentLogRegClassifier Classifies documents with a Logarithmic Regression algorithm. DrugNormalizer Annotator which normalizes raw text from documents, e.g. scraped web pages or xml documents FeaturesAssembler Collects features from different columns. GenericClassifier Creates a generic single-label classifier which uses pre-generated Tensorflow graphs. IOBTagger Merges token tags and NER labels from chunks in the specified format. NerChunker Extracts phrases that fits into a known pattern using the NER tags. NerConverterInternal Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label. NerDisambiguator Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB). MedicalNer This Named Entity recognition annotator is a generic NER model based on Neural Networks.. QuestionAnswering GPT-based model for answering questions given a context. RENerChunksFilter Filters and outputs combinations of relations between extracted entities, for further processing. ReIdentification Reidentifies obfuscated entities by DeIdentification. RelationExtraction Extracts and classifies instances of relations between named entities. RelationExtractionDL Extracts and classifies instances of relations between named entities. SentenceEntityResolver Returns the normalized entity for a particular trained ontology / curated dataset (e.g. clinical ICD-10, RxNorm, SNOMED; financial SEC’s EDGAR database, etc) based on sentence embeddings. Summarizer Helps to quickly summarize complex medical information. TextGenerator Uses the basic BioGPT model to perform various tasks related to medical text abstraction. TFGraphBuilder Creates Tensorflow graphs. AnnotationMerger Model Merge annotations from different pipeline steps that have the same annotation type into a unified annotation. Possible annotations that can be merged include: document (e.g., output of DocumentAssembler annotator) token (e.g., output of Tokenizer annotator) word_embeddings (e.g., output of WordEmbeddingsModel annotator) sentence_embeddings (e.g., output of BertSentenceEmbeddings annotator) category (e.g., output of RelationExtractionModel annotator) date (e.g., output of DateMatcher annotator) sentiment (e.g., output of SentimentDLModel annotator) pos (e.g., output of PerceptronModel annotator) chunk (e.g., output of NerConverter annotator) named_entity (e.g., output of NerDLModel annotator) regex (e.g., output of RegexTokenizer annotator) dependency (e.g., output of DependencyParserModel annotator) language (e.g., output of LanguageDetectorDL annotator) keyword (e.g., output of YakeModel annotator) Input Annotator Types: ANY Output Annotator Type: ANY Python API: AnnotationMerger Scala API: AnnotationMerger Show Example PythonScala Medical # Create the pipeline with two RE models documenter = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) pos_ner_tagger = MedicalNerModel() .pretrained(&quot;ner_posology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ner_pos&quot;) pos_ner_chunker = NerConverterInternal() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_pos&quot;]) .setOutputCol(&quot;pos_ner_chunks&quot;) dependency_parser = DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) pos_reModel = RelationExtractionModel() .pretrained(&quot;posology_re&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;pos_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;pos_relations&quot;) .setMaxSyntacticDistance(4) ade_ner_tagger = MedicalNerModel.pretrained(&quot;ner_ade_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ade_ner_tags&quot;) ade_ner_chunker = NerConverterInternal() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ade_ner_tags&quot;]) .setOutputCol(&quot;ade_ner_chunks&quot;) ade_reModel = RelationExtractionModel() .pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ade_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;ade_relations&quot;) .setMaxSyntacticDistance(10) .setRelationPairs([&quot;drug-ade, ade-drug&quot;]) annotation_merger = AnnotationMerger() .setInputCols(&quot;ade_relations&quot;, &quot;pos_relations&quot;) .setInputType(&quot;category&quot;) .setOutputCol(&quot;all_relations&quot;) merger_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, pos_ner_tagger, pos_ner_chunker, dependency_parser, pos_reModel, ade_ner_tagger, ade_ner_chunker, ade_reModel, annotation_merger ]) empty_df= spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) merger_model= merger_pipeline.fit(empty_df) # Show example result text = &quot;&quot;&quot; The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.. &quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) result = merger_model.transform(data) result.show() +--+--+--+--+--+--+--+--+--+--+--+--+--+--+ text| document| sentences| tokens| embeddings| pos_tags| ner_pos| pos_ner_chunks| dependencies| pos_relations| ade_ner_tags| ade_ner_chunks| ade_relations| all_relations| +--+--+--+--+--+--+--+--+--+--+--+--+--+--+ The patient was ...|[{document, 0, 26...|[{document, 1, 95...|[{token, 1, 3, Th...|[{word_embeddings...|[{pos, 1, 3, DD, ...|[{named_entity, 1...|[{chunk, 28, 33, ...|[{dependency, 1, ...|[{category, 28, 4...|[{named_entity, 1...|[{chunk, 38, 45, ...|[{category, 134, ...|[{category, 134, ...| +--+--+--+--+--+--+--+--+--+--+--+--+--+--+ AssertionChunkConverter Model This annotator creates a CHUNK column with metadata useful for training an Assertion Status Detection model (see AssertionDL). In some cases, there may be issues while creating the chunk column when using token indices that can lead to loss of data to train assertion status models. The AssertionChunkConverter annotator uses both begin and end indices of the tokens as input to add a more robust metadata to the chunk column in a way that improves the reliability of the indices and avoid loss of data. NOTE: Chunk begin and end indices in the assertion status model training dataframe can be populated using the new version of ALAB module. Input Annotator Types: TOKEN Output Annotator Type: CHUNK Python API: AssertionChunkConverter Scala API: AssertionChunkConverter Show Example PythonScala Medical data = spark.createDataFrame( [ [ &quot;An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized.&quot;, &quot;Minnie&quot;, 57, 64, ], [ &quot;After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation &quot;, &quot;PCP&quot;, 31, 34, ], ] ).toDF(&quot;text&quot;, &quot;target&quot;, &quot;char_begin&quot;, &quot;char_end&quot;) document_assembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = ( SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) ) tokenizer = Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;tokens&quot;) converter = ( AssertionChunkConverter() .setInputCols(&quot;tokens&quot;) .setChunkTextCol(&quot;target&quot;) .setChunkBeginCol(&quot;char_begin&quot;) .setChunkEndCol(&quot;char_end&quot;) .setOutputTokenBeginCol(&quot;token_begin&quot;) .setOutputTokenEndCol(&quot;token_end&quot;) .setOutputCol(&quot;chunk&quot;) ) pipeline = Pipeline().setStages( [document_assembler, sentenceDetector, tokenizer, converter] ) results = pipeline.fit(data).transform(data) results.selectExpr( &quot;target&quot;, &quot;char_begin&quot;, &quot;char_end&quot;, &quot;token_begin&quot;, &quot;token_end&quot;, &quot;tokens[token_begin].result&quot;, &quot;tokens[token_end].result&quot;, &quot;target&quot;, &quot;chunk&quot;, ).show(truncate=False) ++-+--+--++--+++-+ |target|char_begin|char_end|token_begin|token_end|tokens[token_begin].result|tokens[token_end].result|target|chunk | ++-+--+--++--+++-+ |Minnie|57 |64 |10 |10 |Minnie |Minnie |Minnie|[{chunk, 57, 62, Minnie, {sentence -&gt; 0}, []}]| |PCP |31 |34 |5 |5 |PCP |PCP |PCP |[{chunk, 31, 33, PCP, {sentence -&gt; 0}, []}] | ++-+--+--++--+++-+ AssertionDL ModelApproach AssertionDL is a deep Learning based approach used to extract Assertion Status from extracted entities and text. AssertionDLModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type annotator inputs, which can be obtained by e.g a DocumentAssembler, NerConverter and WordEmbeddingsModel. The result is an assertion status annotation for each recognized entity. Possible values include “present”, “absent”, “hypothetical”, “conditional”, “associated_with_other_person” etc. For pretrained models please see the Models Hub for available models. Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionDLModel Scala API: AssertionDLModel Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define pipeline stages to extract NER chunks first data = spark.createDataFrame([ [&quot;Patient with severe fever and sore throat&quot;], [&quot;Patient shows no stomach pain&quot;], [&quot;She was maintained on an epidural and PCA for pain control.&quot;]]).toDF(&quot;text&quot;) documentAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setOutputCol(&quot;embeddings&quot;) nerModel = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) # Then a pretrained AssertionDLModel is used to extract the assertion status clinicalAssertion = medical.AssertionDLModel.pretrained(&quot;assertion_dl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion ]) assertionModel = assertionPipeline.fit(data) # Show results result = assertionModel.transform(data) result.selectExpr(&quot;ner_chunk.result&quot;, &quot;assertion.result&quot;).show(3, truncate=False) +--+--+ |result |result | +--+--+ |[severe fever, sore throat] |[present, present] | |[stomach pain] |[absent] | |[an epidural, PCA, pain control]|[present, present, hypothetical]| +--+--+ from johnsnowlabs import * data = spark.createDataFrame([[&quot;Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc.&quot;]]).toDF(&quot;text&quot;) document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = finance.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) assertion = finance.AssertionDLModel.pretrained(&quot;finassertion_competitors&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, assertion ]) assertionModel = pipeline.fit(data) # Show results result = assertionModel.transform(data) result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.metadata, result.assertion.result)).alias(&quot;cols&quot;)) .select(F.expr(&quot;cols[&#39;1&#39;][&#39;sentence&#39;]&quot;).alias(&quot;sent_id&quot;), F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;1&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;), F.expr(&quot;cols[&#39;2&#39;]&quot;).alias(&quot;assertion&quot;)).show(truncate=False) +-+++-+ |sent_id|chunk |ner_label|assertion | +-+++-+ |0 |McAfee LLC |ORG |COMPETITOR| |0 |Broadcom Inc|ORG |COMPETITOR| +-+++-+ from johnsnowlabs import * data = spark.createDataFrame([[&quot;This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc.&quot;]]).toDF(&quot;text&quot;) document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings_ner = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings_ner&quot;) ner_model = legal.NerModel.pretrained(&#39;legner_contract_doc_parties&#39;, &#39;en&#39;, &#39;legal/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings_ner&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;DOC&quot;, &quot;EFFDATE&quot;, &quot;PARTY&quot;]) embeddings_ass = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings_ass&quot;) assertion = legal.AssertionDLModel.pretrained(&quot;legassertion_time&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings_ass&quot;]) .setOutputCol(&quot;assertion&quot;) nlpPipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings_ner, ner_model, ner_converter, embeddings_ass, assertion ]) assertionModel = nlpPipeline.fit(data) # Show results result = assertionModel.transform(data) result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.begin, result.ner_chunk.end, result.ner_chunk.metadata, result.assertion.result)).alias(&quot;cols&quot;)) .select(F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;1&#39;]&quot;).alias(&quot;begin&quot;), F.expr(&quot;cols[&#39;2&#39;]&quot;).alias(&quot;end&quot;), F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;), F.expr(&quot;cols[&#39;4&#39;]&quot;).alias(&quot;assertion&quot;)).show(truncate=False) +-+--++++ |chunk |begin|end|ner_label|assertion| +-+--++++ |Intellectual Property Agreement|11 |41 |DOC |PRESENT | |Amazon Inc |51 |60 |PARTY |PRESENT | |Atlantic Inc |67 |78 |PARTY |PRESENT | +-+--++++ MedicalFinanceLegal from johnsnowlabs import * // Define pipeline stages to extract NER chunks first val data = Seq( &quot;Patient with severe fever and sore throat&quot;, &quot;Patient shows no stomach pain&quot;, &quot;She was maintained on an epidural and PCA for pain control.&quot;).toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)).setOutputCol(&quot;embeddings&quot;) val nerModel = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)).setOutputCol(&quot;ner_chunk&quot;) // Then a pretrained AssertionDLModel is used to extract the assertion status val clinicalAssertion = medical.AssertionDLModel.pretrained(&quot;assertion_dl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion )) val assertionModel = assertionPipeline.fit(data) // Show results val result = assertionModel.transform(data) result.selectExpr(&quot;ner_chunk.result&quot;, &quot;assertion.result&quot;).show(3, truncate=false) +--+--+ |result |result | +--+--+ |[severe fever, sore throat] |[present, present] | |[stomach pain] |[absent] | |[an epidural, PCA, pain control]|[present, present, hypothetical]| +--+--+ from johnsnowlabs import * val data = Seq(&quot;Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc.&quot;).toDF(&quot;text&quot;) val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new finance.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val assertion = finance.AssertionDLModel.pretrained(&quot;finassertion_competitors&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, assertion ) val assertionModel = pipeline.fit(data) from johnsnowlabs import * val data = Seq(&quot;This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc.&quot;).toDF(&quot;text&quot;) val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings_ner = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings_ner&quot;) val ner_model = legal.NerModel.pretrained(&#39;legner_contract_doc_parties&#39;, &#39;en&#39;, &#39;legal/models&#39;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings_ner&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(Array(&quot;DOC&quot;, &quot;EFFDATE&quot;, &quot;PARTY&quot;)) val embeddings_ass = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings_ass&quot;) val assertion = legal.AssertionDLModel.pretrained(&quot;legassertion_time&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings_ass&quot;)) .setOutputCol(&quot;assertion&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, embeddings_ner, ner_model, ner_converter, embeddings_ass, assertion ) val assertionModel = pipeline.fit(data) Trains AssertionDL, a deep Learning based approach used to extract Assertion Status from extracted entities and text. Contains all the methods for training an AssertionDLModel. For pretrained models please use AssertionDLModel and see the Models Hub for available models. Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionDLApproach Scala API: AssertionDLApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. document = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) chunk = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;chunk&quot;) token = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Define AssertionDLApproach with parameters and start training assertionStatus = medical.AssertionDLApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setDropout(0.012) .setLearningRate(0.015) .setEpochs(1) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setMaxSentLen(250) trainingPipeline = Pipeline().setStages([ document, chunk, token, embeddings, assertionStatus ]) assertionModel = trainingPipeline.fit(data) assertionResults = assertionModel.transform(data).cache() from johnsnowlabs import * # First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. document = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) chunk = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;chunk&quot;) token = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Define AssertionDLApproach with parameters and start training assertionStatus = finance.AssertionDLApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setDropout(0.012) .setLearningRate(0.015) .setEpochs(1) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setMaxSentLen(250) trainingPipeline = Pipeline().setStages([ document, chunk, token, embeddings, assertionStatus ]) assertionModel = trainingPipeline.fit(data) assertionResults = assertionModel.transform(data).cache() from johnsnowlabs import * # First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. document = nlp.DocumentAssembler() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;document&quot;) chunk = nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;doc_chunk&quot;) token = nlp.Tokenizer() .setInputCols([&#39;document&#39;]) .setOutputCol(&#39;token&#39;) roberta_embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setMaxSentenceLength(512) # Define AssertionDLApproach with parameters and start training assertionStatus = legal.AssertionDLApproach() .setLabelCol(&quot;assertion_label&quot;) .setInputCols(&quot;document&quot;, &quot;doc_chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setLearningRate(0.001) .setEpochs(2) .setStartCol(&quot;tkn_start&quot;) .setEndCol(&quot;tkn_end&quot;) .setMaxSentLen(1200) .setEnableOutputLogs(True) .setOutputLogsPath(&#39;training_logs/&#39;) .setGraphFolder(graph_folder) .setGraphFile(f&quot;{graph_folder}/assertion_graph.pb&quot;) .setTestDataset(path=&quot;test_data.parquet&quot;, read_as=&#39;SPARK&#39;, options={&#39;format&#39;: &#39;parquet&#39;}) .setScopeWindow(scope_window) #.setValidationSplit(0.2) #.setDropout(0.1) trainingPipeline = Pipeline().setStages([ document, chunk, token, roberta_embeddings, assertionStatus ]) assertionModel = trainingPipeline.fit(data) assertionResults = assertionModel.transform(data).cache() MedicalFinanceLegal from johnsnowlabs import * // First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. val document = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val chunk = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;chunk&quot;) val token = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Define AssertionDLApproach with parameters and start training val assertionStatus = new medical.AssertionDLApproach() .setLabelCol(&quot;label&quot;) .setInputCols(&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setDropout(0.012f) .setLearningRate(0.015f) .setEpochs(1) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setMaxSentLen(250) val trainingPipeline = new Pipeline().setStages(Array( document, chunk, token, embeddings, assertionStatus )) val assertionModel = trainingPipeline.fit(data) val assertionResults = assertionModel.transform(data).cache() from johnsnowlabs import * // First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. val document = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val chunk = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;chunk&quot;) val token = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Define AssertionDLApproach with parameters and start training val assertionStatus = new finance.AssertionDLApproach() .setLabelCol(&quot;label&quot;) .setInputCols(&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setDropout(0.012f) .setLearningRate(0.015f) .setEpochs(1) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setMaxSentLen(250) val trainingPipeline = new Pipeline().setStages(Array( document, chunk, token, embeddings, assertionStatus )) val assertionModel = trainingPipeline.fit(data) val assertionResults = assertionModel.transform(data).cache() from johnsnowlabs import * val document = new nlp.DocumentAssembler() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;document&quot;) val chunk = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;doc_chunk&quot;) .setChunkCol(&quot;chunk&quot;) .setStartCol(&quot;tkn_start&quot;) .setStartColByTokenIndex(True) .setFailOnMissing(False) .setLowerCase(False) val token = new nlp.Tokenizer() .setInputCols([&#39;document&#39;]) .setOutputCol(&#39;token&#39;) val roberta_embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setMaxSentenceLength(512) # Define AssertionDLApproach with parameters and start training val assertionStatus = new legal.AssertionDLApproach() .setLabelCol(&quot;assertion_label&quot;) .setInputCols(&quot;document&quot;, &quot;doc_chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setLearningRate(0.001) .setEpochs(2) .setStartCol(&quot;tkn_start&quot;) .setEndCol(&quot;tkn_end&quot;) .setMaxSentLen(1200) .setEnableOutputLogs(True) .setOutputLogsPath(&#39;training_logs/&#39;) .setGraphFolder(graph_folder) .setGraphFile(f&quot;{graph_folder}/assertion_graph.pb&quot;) .setTestDataset(path=&quot;test_data.parquet&quot;, read_as=&#39;SPARK&#39;, options={&#39;format&#39;: &#39;parquet&#39;}) .setScopeWindow(scope_window) #.setValidationSplit(0.2) #.setDropout(0.1) val trainingPipeline = new Pipeline().setStages(Array( document, chunk, token, roberta_embeddings, assertionStatus )) val assertionModel = trainingPipeline.fit(data) val assertionResults = assertionModel.transform(data).cache() AssertionFilterer Model Filters entities coming from ASSERTION type annotations and returns the CHUNKS. Filters can be set via a white list on the extracted chunk, the assertion or a regular expression. White list for assertion is enabled by default. To use chunk white list, criteria has to be set to &quot;isin&quot;. For regex, criteria has to be set to &quot;regex&quot;. Input Annotator Types: DOCUMENT, CHUNK, ASSERTION Output Annotator Type: CHUNK Python API: AssertionFilterer Scala API: AssertionFilterer Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # To see how the assertions are extracted, see the example for AssertionDLModel. # Define an extra step where the assertions are filtered assertionFilterer = medical.AssertionFilterer() .setInputCols([&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList([&quot;present&quot;]) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer ]) assertionModel = assertionPipeline.fit(data) result = assertionModel.transform(data) # Show results: result.selectExpr(&quot;ner_chunk.result&quot;, &quot;assertion.result&quot;).show(3, truncate=False) +--+--+ |result |result | +--+--+ |[severe fever, sore throat] |[present, present] | |[stomach pain] |[absent] | |[an epidural, PCA, pain control]|[present, present, hypothetical]| +--+--+ result.select(&quot;filtered.result&quot;).show(3, truncate=False) ++ |result | ++ |[severe fever, sore throat]| |[] | |[an epidural, PCA] | ++ from johnsnowlabs import * # To see how the assertions are extracted, see the example for AssertionDLModel. # Define an extra step where the assertions are filtered assertionFilterer = finance.AssertionFilterer() .setInputCols([&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList([&quot;present&quot;]) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer ]) assertionModel = assertionPipeline.fit(data) result = assertionModel.transform(data) from johnsnowlabs import * # To see how the assertions are extracted, see the example for AssertionDLModel. # Define an extra step where the assertions are filtered assertionFilterer = legal.AssertionFilterer() .setInputCols([&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList([&quot;present&quot;]) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer ]) assertionModel = assertionPipeline.fit(data) result = assertionModel.transform(data) MedicalFinanceLegal from johnsnowlabs import * // To see how the assertions are extracted, see the example for // [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]]. // Define an extra step where the assertions are filtered val assertionFilterer = new medical.AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList(&quot;present&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer )) val assertionModel = assertionPipeline.fit(data) val result = assertionModel.transform(data) // Show results: // // result.selectExpr(&quot;ner_chunk.result&quot;, &quot;assertion.result&quot;).show(3, truncate=false) // +--+--+ // |result |result | // +--+--+ // |[severe fever, sore throat] |[present, present] | // |[stomach pain] |[absent] | // |[an epidural, PCA, pain control]|[present, present, hypothetical]| // +--+--+ // result.select(&quot;filtered.result&quot;).show(3, truncate=false) // ++ // |result | // ++ // |[severe fever, sore throat]| // |[] | // |[an epidural, PCA] | // ++ // from johnsnowlabs import * // To see how the assertions are extracted, see the example for // [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]]. // Define an extra step where the assertions are filtered val assertionFilterer = new legal.AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList(&quot;present&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer )) val assertionModel = assertionPipeline.fit(data) val result = assertionModel.transform(data) from johnsnowlabs import * // To see how the assertions are extracted, see the example for // [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]]. // Define an extra step where the assertions are filtered val assertionFilterer = new legal.AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList(&quot;present&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer )) val assertionModel = assertionPipeline.fit(data) val result = assertionModel.transform(data) AssertionLogReg ModelApproach This is a main class in AssertionLogReg family. Logarithmic Regression is used to extract Assertion Status from extracted entities and text. AssertionLogRegModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type annotator inputs, which can be obtained by e.g a DocumentAssembler, NerConverter and WordEmbeddingsModel. The result is an assertion status annotation for each recognized entity. Possible values are &quot;Negated&quot;, &quot;Affirmed&quot; and &quot;Historical&quot;. Unlike the DL Model, this class does not extend AnnotatorModel. Instead it extends the RawAnnotator, that’s why the main point of interest is method transform(). At the moment there are no pretrained models available for this class. Please refer to AssertionLogRegApproach to train your own model. Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionLogRegModel Scala API: AssertionLogRegModel Trains a classification method, which uses the Logarithmic Regression Algorithm. It is used to extract Assertion Status from extracted entities and text. Contains all the methods for training a AssertionLogRegModel, together with trainWithChunk, trainWithStartEnd. Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionLogRegApproach Scala API: AssertionLogRegApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Training with Glove Embeddings # First define pipeline stages to extract embeddings and text chunks documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(False) chunkAssembler = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) # Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. assertion = medical.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion ]) assertionModel = assertionPipeline.fit(dataset) from johnsnowlabs import * # Training with Glove Embeddings # First define pipeline stages to extract embeddings and text chunks documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(False) chunkAssembler = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) # Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. assertion = finance.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion ]) assertionModel = assertionPipeline.fit(dataset) from johnsnowlabs import * # Training with Glove Embeddings # First define pipeline stages to extract embeddings and text chunks documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(False) chunkAssembler = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) # Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. assertion = legal.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion ]) assertionModel = assertionPipeline.fit(dataset) MedicalFinanceLegal from johnsnowlabs import * // Training with Glove Embeddings // First define pipeline stages to extract embeddings and text chunks val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(false) val chunkAssembler = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) // Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. val assertion = new medical.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols(Array(&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion )) val assertionModel = assertionPipeline.fit(dataset) from johnsnowlabs import * // Training with Glove Embeddings // First define pipeline stages to extract embeddings and text chunks val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(false) val chunkAssembler = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) // Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. val assertion = new finance.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols(Array(&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion )) val assertionModel = assertionPipeline.fit(dataset) from johnsnowlabs import * // Training with Glove Embeddings // First define pipeline stages to extract embeddings and text chunks val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(false) val chunkAssembler = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) // Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. val assertion = new legal.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols(Array(&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion )) val assertionModel = assertionPipeline.fit(dataset) BertSentenceChunkEmbeddings Model This annotator allows aggregating sentence embeddings with ner chunk embeddings to get specific and more accurate resolution codes. It works by averaging sentence and chunk embeddings add contextual information in the embedding value. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model. The setChunkWeight parameter can be used to control the influence of surrounding context. For more information and examples of BertSentenceChunkEmbeddings annotator, you can check the Spark NLP Workshop, and in special, the notebook 24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb. Input Annotator Types: DOCUMENT, CHUNK Output Annotator Type: SENTENCE_EMBEDDINGS Python API: BertSentenceChunkEmbeddings Scala API: BertSentenceChunkEmbeddings Show Example PythonScala Medical # Define the pipeline document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = medical.NerModel.pretrained(&quot;ner_abbreviation_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = medical.NerConverterInternal() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&#39;ABBR&#39;]) sentence_chunk_embeddings = medical.BertSentenceChunkEmbeddings.pretrained(&quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) .setChunkWeight(0.5) .setCaseSensitive(True) abbr_resolver = medical.SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_clinical_abbreviation_acronym&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;abbr_meaning&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) resolver_pipeline = Pipeline( stages = [ document_assembler, tokenizer, word_embeddings, clinical_ner, ner_converter, sentence_chunk_embeddings, abbr_resolver ]) # Example results sample_text = [ &quot;&quot;&quot;The patient admitted from the IR for aggressive irrigation of the Miami pouch. DISCHARGE DIAGNOSES: 1. A 58-year-old female with a history of stage 2 squamous cell carcinoma of the cervix status post total pelvic exenteration in 1991.&quot;&quot;&quot;, &quot;&quot;&quot;Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA: Laboratory tests include a CBC which is normal. Blood Type: AB positive. Rubella: Immune. VDRL: Nonreactive. Hepatitis C surface antigen: Negative. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet.&quot;&quot;&quot;] from pyspark.sql.types import StringType, IntegerType df = spark.createDataFrame(sample_text, StringType()).toDF(&#39;text&#39;) df.show(truncate = 100) +-+ | text| +-+ |The patient admitted from the IR for aggressive irrigation of the Miami pouch. DISCHARGE DIAGNOSE...| |Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA...| +-+ Medical val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;tokens&quot;) val wordEmbeddings = BertEmbeddings .pretrained(&quot;biobert_pubmed_base_cased&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;word_embeddings&quot;) val nerModel = MedicalNerModel .pretrained(&quot;ner_clinical_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;tokens&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val nerConverter = new NerConverter() .setInputCols(&quot;sentence&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunk&quot;) val sentenceChunkEmbeddings = BertSentenceChunkEmbeddings .pretrained(&quot;sbluebert_base_uncased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;sentence_chunk_embeddings&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentenceDetector, tokenizer, wordEmbeddings, nerModel, nerConverter, sentenceChunkEmbeddings)) val sampleText = &quot;Her Diabetes has become type 2 in the last year with her Diabetes.&quot; + &quot; He complains of swelling in his right forearm.&quot; val testDataset = Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(emptyDataset).transform(testDataset) result .selectExpr(&quot;explode(sentence_chunk_embeddings) AS s&quot;) .selectExpr(&quot;s.result&quot;, &quot;slice(s.embeddings, 1, 5) AS averageEmbedding&quot;) .show(truncate=false) +--+--+ | result| averageEmbedding| +--+--+ |Her Diabetes |[-0.31995273, -0.04710883, -0.28973156, -0.1294758, 0.12481072] | |type 2 |[-0.027161136, -0.24613449, -0.0949309, 0.1825444, -0.2252143] | |her Diabetes |[-0.31995273, -0.04710883, -0.28973156, -0.1294758, 0.12481072] | |swelling in his right forearm|[-0.45139068, 0.12400375, -0.0075617577, -0.90806055, 0.12871636]| +--+--+ Chunk2Token Model A feature transformer that converts the input array of strings (annotatorType CHUNK) into an array of chunk-based tokens (annotatorType TOKEN). When the input is empty, an empty array is returned. This Annotator is specially convenient when using NGramGenerator annotations as inputs to WordEmbeddingsModels Input Annotator Types: CHUNK Output Annotator Type: TOKEN Scala API: Chunk2Token Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define a pipeline for generating n-grams data = spark.createDataFrame([[&quot;A 63-year-old man presents to the hospital ...&quot;]]).toDF(&quot;text&quot;) document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) token = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) ngrammer = nlp.NGramGenerator() .setN(2) .setEnableCumulative(False) .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) # Stage to convert n-gram CHUNKS to TOKEN type chunk2Token = medical.Chunk2Token().setInputCols([&quot;ngrams&quot;]).setOutputCol(&quot;ngram_tokens&quot;) trainingPipeline = Pipeline(stages=[document, sentenceDetector, token, ngrammer, chunk2Token]).fit(data) result = trainingPipeline.transform(data).cache() result.selectExpr(&quot;explode(ngram_tokens)&quot;).show(5, False) +-+ |col | +-+ |{token, 3, 15, A_63-year-old, {sentence -&gt; 0, chunk -&gt; 0}, []} | |{token, 5, 19, 63-year-old_man, {sentence -&gt; 0, chunk -&gt; 1}, []}| |{token, 17, 28, man_presents, {sentence -&gt; 0, chunk -&gt; 2}, []} | |{token, 21, 31, presents_to, {sentence -&gt; 0, chunk -&gt; 3}, []} | |{token, 30, 35, to_the, {sentence -&gt; 0, chunk -&gt; 4}, []} | +-+ from johnsnowlabs import * # Define a pipeline for generating n-grams document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) token = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) ngrammer = nlp.NGramGenerator() .setN(2) .setEnableCumulative(False) .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) # Stage to convert n-gram CHUNKS to TOKEN type chunk2Token = finance.Chunk2Token().setInputCols([&quot;ngrams&quot;]).setOutputCol(&quot;ngram_tokens&quot;) trainingPipeline = Pipeline(stages=[document, sentenceDetector, token, ngrammer, chunk2Token]) from johnsnowlabs import * # Define a pipeline for generating n-grams document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) token = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) ngrammer = nlp.NGramGenerator() .setN(2) .setEnableCumulative(False) .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) # Stage to convert n-gram CHUNKS to TOKEN type chunk2Token = legal.Chunk2Token().setInputCols([&quot;ngrams&quot;]).setOutputCol(&quot;ngram_tokens&quot;) trainingPipeline = Pipeline(stages=[document, sentenceDetector, token, ngrammer, chunk2Token]) MedicalFinanceLegal from johnsnowlabs import * // Define a pipeline for generating n-grams val data = Seq((&quot;A 63-year-old man presents to the hospital ...&quot;)).toDF(&quot;text&quot;) val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val token = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val ngrammer = new nlp.NGramGenerator() .setN(2) .setEnableCumulative(false) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) // Stage to convert n-gram CHUNKS to TOKEN type val chunk2Token = new medical.Chunk2Token().setInputCols(&quot;ngrams&quot;).setOutputCol(&quot;ngram_tokens&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, sentenceDetector, token, ngrammer, chunk2Token)).fit(data) val result = trainingPipeline.transform(data).cache() result.selectExpr(&quot;explode(ngram_tokens)&quot;).show(5, false) +-+ |col | +-+ |{token, 3, 15, A_63-year-old, {sentence -&gt; 0, chunk -&gt; 0}, []} | |{token, 5, 19, 63-year-old_man, {sentence -&gt; 0, chunk -&gt; 1}, []}| |{token, 17, 28, man_presents, {sentence -&gt; 0, chunk -&gt; 2}, []} | |{token, 21, 31, presents_to, {sentence -&gt; 0, chunk -&gt; 3}, []} | |{token, 30, 35, to_the, {sentence -&gt; 0, chunk -&gt; 4}, []} | +-+ from johnsnowlabs import * // Define a pipeline for generating n-grams val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val token = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val ngrammer = new nlp.NGramGenerator() .setN(2) .setEnableCumulative(false) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) // Stage to convert n-gram CHUNKS to TOKEN type val chunk2Token = new finance.Chunk2Token().setInputCols(&quot;ngrams&quot;).setOutputCol(&quot;ngram_tokens&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, sentenceDetector, token, ngrammer, chunk2Token)) from johnsnowlabs import * // Define a pipeline for generating n-grams val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val token = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val ngrammer = new nlp.NGramGenerator() .setN(2) .setEnableCumulative(false) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) // Stage to convert n-gram CHUNKS to TOKEN type val chunk2Token = new legal.Chunk2Token().setInputCols(&quot;ngrams&quot;).setOutputCol(&quot;ngram_tokens&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, sentenceDetector, token, ngrammer, chunk2Token)) ChunkConverter Model Convert chunks from RegexMatcher to chunks with a entity in the metadata. This annotator is important when the user wants to merge entities identified by NER models together with rules-based matching used by the RegexMathcer annotator. In the following steps of the pipeline, all the identified entities can be treated in a unified field. Input Annotator Types: DOCUMENT, CHUNK Output Annotator Type: CHUNK Python API: ChunkConverter Scala API: ChunkConverter Show Example PythonScala Medical # Creating the pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_clinical_large&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) ner_converter= NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) regex_matcher = RegexMatcher() .setInputCols(&#39;document&#39;) .setStrategy(&quot;MATCH_ALL&quot;) .setOutputCol(&quot;regex_matches&quot;) .setExternalRules(path=&#39;file:/dbfs/regex_rules.txt&#39;, delimiter=&#39;,&#39;) chunkConverter = ChunkConverter() .setInputCols(&quot;regex_matches&quot;) .setOutputCol(&quot;regex_chunk&quot;) merger= ChunkMergeApproach() .setInputCols([&quot;regex_chunk&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;merged_chunks&quot;) .setMergeOverlapping(True) .setChunkPrecedence(&quot;field&quot;) pipeline= Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, ner_model, ner_converter, regex_matcher, chunkConverter, merger ]) empty_df= spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model= pipeline.fit(empty_df) lp_model = LightPipeline(model) results = lp_model.fullAnnotate(sample_text)[0] # Displaying the results chunk= [] merge= [] for result in list(results[&quot;merged_chunks&quot;]): merge.append(result.metadata[&quot;entity&quot;]) chunk.append(result.result) df_merge = pd.DataFrame({&quot;chunk&quot;: chunk, &quot;merged_entity&quot;: merge}) df_merge | chunk | merged_entity | |--:|:| | POSTOPERATIVE DIAGNOSIS: | SECTION_HEADER | | Cervical lymphadenopathy | PROBLEM | | PROCEDURE: | SECTION_HEADER | | Excisional biopsy of right cervical lymph node | TEST | | ANESTHESIA: | SECTION_HEADER | | General endotracheal anesthesia | TREATMENT | | Right cervical lymph node | PROBLEM | | EBL: | SECTION_HEADER | | COMPLICATIONS: | SECTION_HEADER | | FINDINGS: | SECTION_HEADER | | Enlarged level 2 lymph node | PROBLEM | | ... | | Medical val sampleDataset = ResourceHelper.spark.createDataFrame(Seq( (1, &quot;My first sentence with the first rule. This is my second sentence with ceremonies rule.&quot;) )).toDF(&quot;id&quot;, &quot;text&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val regexMatcher = new RegexMatcher() .setExternalRules(ExternalResource(&quot;src/test/resources/regex-matcher/rules.txt&quot;, ReadAs.TEXT, Map(&quot;delimiter&quot; -&gt; &quot;,&quot;))) .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;regex&quot;) .setStrategy(strategy) val chunkConverter = new ChunkConverter().setInputCols(&quot;regex&quot;).setOutputCol(&quot;chunk&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, sentence, regexMatcher,chunkConverter)) val results = pipeline.fit(sampleDataset).transform(sampleDataset) results.select(&quot;chunk&quot;).show(truncate = false) ++ |col | ++ |[chunk, 23, 31, the first, [identifier -&gt; NAME, sentence -&gt; 0, chunk -&gt; 0, entity -&gt; NAME], []] | |[chunk, 71, 80, ceremonies, [identifier -&gt; NAME, sentence -&gt; 1, chunk -&gt; 0, entity -&gt; NAME], []]| ++ ChunkEntityResolver ModelApproach Returns a normalized entity for a particular trained ontology / curated dataset (e.g. ICD-10, RxNorm, SNOMED etc). For available pretrained models please see the Models Hub. Input Annotator Types: TOKEN, WORD_EMBEDDINGS Output Annotator Type: ENTITY Scala API: ChunkEntityResolverModel Show Example PythonScala Medical from johnsnowlabs import * # Using pretrained models for SNOMED # First the prior steps of the pipeline are defined. # Output of types TOKEN and WORD_EMBEDDINGS are needed. data = spark.createDataFrame([[&quot;A 63-year-old man presents to the hospital ...&quot;]]).toDF(&quot;text&quot;) docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) icdo_ner = medical.NerModel.pretrained(&quot;ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;icdo_ner&quot;) icdo_chunk = nlp.NerConverter().setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;icdo_ner&quot;]).setOutputCol(&quot;icdo_chunk&quot;).setWhiteList([&quot;Cancer&quot;]) icdo_chunk_embeddings = nlp.ChunkEmbeddings() .setInputCols([&quot;icdo_chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;icdo_chunk_embeddings&quot;) icdo_chunk_resolver = medical.ChunkEntityResolverModel.pretrained(&quot;chunkresolve_icdo_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;icdo_chunk_embeddings&quot;]) .setOutputCol(&quot;tm_icdo_code&quot;) clinical_ner = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ner_chunk_tokenizer = nlp.ChunkTokenizer() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;ner_token&quot;) ner_chunk_embeddings = nlp.ChunkEmbeddings() .setInputCols([&quot;ner_chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner_chunk_embeddings&quot;) # Definition of the SNOMED Resolution ner_snomed_resolver = medical.ChunkEntityResolverModel.pretrained(&quot;chunkresolve_snomed_findings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_token&quot;,&quot;ner_chunk_embeddings&quot;]).setOutputCol(&quot;snomed_result&quot;) pipelineFull = Pipeline().setStages([ docAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, ner_chunk_embeddings, ner_chunk_tokenizer, ner_snomed_resolver, icdo_ner, icdo_chunk, icdo_chunk_embeddings, icdo_chunk_resolver ]) pipelineModelFull = pipelineFull.fit(data) result = pipelineModelFull.transform(data).cache() # Show results result.selectExpr(&quot;explode(snomed_result)&quot;) .selectExpr( &quot;col.metadata.target_text&quot;, &quot;col.metadata.resolved_text&quot;, &quot;col.metadata.confidence&quot;, &quot;col.metadata.all_k_results&quot;, &quot;col.metadata.all_k_resolutions&quot;) .filter($&quot;confidence&quot; &gt; 0.2).show(5) +--+--+-+--+--+ | target_text| resolved_text|confidence| all_k_results| all_k_resolutions| +--+--+-+--+--+ |hypercholesterolemia|Hypercholesterolemia| 0.2524|13644009:::267432...|Hypercholesterole...| | CBC| Neocyte| 0.4980|259680000:::11573...|Neocyte:::Blood g...| | CD38| Hypoviscosity| 0.2560|47872005:::370970...|Hypoviscosity:::E...| | platelets| Increased platelets| 0.5267|6631009:::2596800...|Increased platele...| | CD38| Hypoviscosity| 0.2560|47872005:::370970...|Hypoviscosity:::E...| +--+--+-+--+--+ Medical from johnsnowlabs import * // Using pretrained models for SNOMED // First the prior steps of the pipeline are defined. // Output of types TOKEN and WORD_EMBEDDINGS are needed. val data = Seq((&quot;A 63-year-old man presents to the hospital ...&quot;)).toDF(&quot;text&quot;) val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;word_embeddings&quot;) val icdo_ner = medical.NerModel.pretrained(&quot;ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;icdo_ner&quot;) val icdo_chunk = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;icdo_ner&quot;)).setOutputCol(&quot;icdo_chunk&quot;).setWhiteList(&quot;Cancer&quot;) val icdo_chunk_embeddings = new nlp.ChunkEmbeddings() .setInputCols(Array(&quot;icdo_chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;icdo_chunk_embeddings&quot;) val icdo_chunk_resolver = medical.ChunkEntityResolverModel.pretrained(&quot;chunkresolve_icdo_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;token&quot;,&quot;icdo_chunk_embeddings&quot;)) .setOutputCol(&quot;tm_icdo_code&quot;) val clinical_ner = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val ner_chunk_tokenizer = new nlp.ChunkTokenizer() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_token&quot;) val ner_chunk_embeddings = new nlp.ChunkEmbeddings() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;ner_chunk_embeddings&quot;) // Definition of the SNOMED Resolution val ner_snomed_resolver = medical.ChunkEntityResolverModel.pretrained(&quot;chunkresolve_snomed_findings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;ner_token&quot;,&quot;ner_chunk_embeddings&quot;)).setOutputCol(&quot;snomed_result&quot;) val pipelineFull = new Pipeline().setStages(Array( docAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, ner_chunk_embeddings, ner_chunk_tokenizer, ner_snomed_resolver, icdo_ner, icdo_chunk, icdo_chunk_embeddings, icdo_chunk_resolver )) val pipelineModelFull = pipelineFull.fit(data) val result = pipelineModelFull.transform(data).cache() // Show results // // result.selectExpr(&quot;explode(snomed_result)&quot;) // .selectExpr( // &quot;col.metadata.target_text&quot;, // &quot;col.metadata.resolved_text&quot;, // &quot;col.metadata.confidence&quot;, // &quot;col.metadata.all_k_results&quot;, // &quot;col.metadata.all_k_resolutions&quot;) // .filter($&quot;confidence&quot; &gt; 0.2).show(5) // +--+--+-+--+--+ // | target_text| resolved_text|confidence| all_k_results| all_k_resolutions| // +--+--+-+--+--+ // |hypercholesterolemia|Hypercholesterolemia| 0.2524|13644009:::267432...|Hypercholesterole...| // | CBC| Neocyte| 0.4980|259680000:::11573...|Neocyte:::Blood g...| // | CD38| Hypoviscosity| 0.2560|47872005:::370970...|Hypoviscosity:::E...| // | platelets| Increased platelets| 0.5267|6631009:::2596800...|Increased platele...| // | CD38| Hypoviscosity| 0.2560|47872005:::370970...|Hypoviscosity:::E...| // +--+--+-+--+--+ // Contains all the parameters and methods to train a ChunkEntityResolverModel. It transform a dataset with two Input Annotations of types TOKEN and WORD_EMBEDDINGS, coming from e.g. ChunkTokenizer and ChunkEmbeddings Annotators and returns the normalized entity for a particular trained ontology / curated dataset. (e.g. ICD-10, RxNorm, SNOMED etc.) To use pretrained models please use ChunkEntityResolverModel and see the Models Hub for available models. Input Annotator Types: TOKEN, WORD_EMBEDDINGS Output Annotator Type: ENTITY Scala API: ChunkEntityResolverApproach Show Example PythonScala Medical from johnsnowlabs import * # Training a SNOMED model # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data # and their labels. document = nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) chunk = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;chunk&quot;) token = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_healthcare_100d&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) chunkEmb = nlp.ChunkEmbeddings() .setInputCols([&quot;chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;chunk_embeddings&quot;) snomedTrainingPipeline = Pipeline().setStages([ document, chunk, token, embeddings, chunkEmb ]) snomedTrainingModel = snomedTrainingPipeline.fit(data) snomedData = snomedTrainingModel.transform(data).cache() # Then the Resolver can be trained with snomedExtractor = medical.ChunkEntityResolverApproach() .setInputCols([&quot;token&quot;, &quot;chunk_embeddings&quot;]) .setOutputCol(&quot;recognized&quot;) .setNeighbours(1000) .setAlternatives(25) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setEnableWmd(True).setEnableTfidf(True).setEnableJaccard(True) .setEnableSorensenDice(True).setEnableJaroWinkler(True).setEnableLevenshtein(True) .setDistanceWeights([1, 2, 2, 1, 1, 1]) .setAllDistancesMetadata(True) .setPoolingStrategy(&quot;MAX&quot;) .setThreshold(1e32) model = snomedExtractor.fit(snomedData) Medical from johnsnowlabs import * // Training a SNOMED model // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data // and their labels. val document = new nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val chunk = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;chunk&quot;) val token = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_healthcare_100d&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val chunkEmb = new nlp.ChunkEmbeddings() .setInputCols(Array(&quot;chunk&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;chunk_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( document, chunk, token, embeddings, chunkEmb )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val snomedExtractor = new medical.ChunkEntityResolverApproach() .setInputCols(Array(&quot;token&quot;, &quot;chunk_embeddings&quot;)) .setOutputCol(&quot;recognized&quot;) .setNeighbours(1000) .setAlternatives(25) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setEnableWmd(true).setEnableTfidf(true).setEnableJaccard(true) .setEnableSorensenDice(true).setEnableJaroWinkler(true).setEnableLevenshtein(true) .setDistanceWeights(Array(1, 2, 2, 1, 1, 1)) .setAllDistancesMetadata(true) .setPoolingStrategy(&quot;MAX&quot;) .setThreshold(1e32) val model = snomedExtractor.fit(snomedData) ChunkFilterer Model Filters entities coming from CHUNK annotations. Filters can be set via a white list of terms or a regular expression. White list criteria is enabled by default. To use regex, criteria has to be set to regex. Input Annotator Types: DOCUMENT,CHUNK Output Annotator Type: CHUNK Python API: ChunkFilterer Scala API: ChunkFilterer Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Filtering POS tags # First pipeline stages to extract the POS tags are defined data = spark.createDataFrame([[&quot;Has a past history of gastroenteritis and stomach pain, however patient ...&quot;]]).toDF(&quot;text&quot;) docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) posTagger = nlp.PerceptronModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) chunker = nlp.Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) # Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. chunkerFilter = medical.ChunkFilterer() .setInputCols([&quot;sentence&quot;,&quot;chunk&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList([&quot;gastroenteritis&quot;]) pipeline = Pipeline(stages=[ docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter]) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(chunk)&quot;).show(truncate=False) ++ |col | ++ |{chunk, 11, 17, history, {sentence -&gt; 0, chunk -&gt; 0}, []} | |{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []} | |{chunk, 42, 53, stomach pain, {sentence -&gt; 0, chunk -&gt; 2}, []} | |{chunk, 64, 70, patient, {sentence -&gt; 0, chunk -&gt; 3}, []} | |{chunk, 81, 110, stomach pain now.We don&#39;t care, {sentence -&gt; 0, chunk -&gt; 4}, []}| |{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []} | ++ result.selectExpr(&quot;explode(filtered)&quot;).show(truncate=False) +-+ |col | +-+ |{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []} | |{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}| +-+ from johnsnowlabs import * # Filtering POS tags # First pipeline stages to extract the POS tags are defined docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) posTagger = nlp.PerceptronModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) chunker = nlp.Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) # Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. chunkerFilter = finance.ChunkFilterer() .setInputCols([&quot;sentence&quot;,&quot;chunk&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList([&quot;gastroenteritis&quot;]) pipeline = Pipeline(stages=[ docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter]) result = pipeline.fit(data).transform(data) from johnsnowlabs import * # Filtering POS tags # First pipeline stages to extract the POS tags are defined docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) posTagger = nlp.PerceptronModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) chunker = nlp.Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) # Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. chunkerFilter = legal.ChunkFilterer() .setInputCols([&quot;sentence&quot;,&quot;chunk&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList([&quot;gastroenteritis&quot;]) pipeline = Pipeline(stages=[ docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter]) result = pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * // Filtering POS tags // First pipeline stages to extract the POS tags are defined val data = Seq(&quot;Has a past history of gastroenteritis and stomach pain, however patient ...&quot;).toDF(&quot;text&quot;) val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val posTagger = nlp.PerceptronModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;pos&quot;) val chunker = new nlp.Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) // Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. val chunkerFilter = new medical.ChunkFilterer() .setInputCols(Array(&quot;sentence&quot;,&quot;chunk&quot;)) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList(&quot;gastroenteritis&quot;) val pipeline = new Pipeline().setStages(Array( docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter)) result.selectExpr(&quot;explode(chunk)&quot;).show(truncate=false) ++ |col | ++ |{chunk, 11, 17, history, {sentence -&gt; 0, chunk -&gt; 0}, []} | |{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []} | |{chunk, 42, 53, stomach pain, {sentence -&gt; 0, chunk -&gt; 2}, []} | |{chunk, 64, 70, patient, {sentence -&gt; 0, chunk -&gt; 3}, []} | |{chunk, 81, 110, stomach pain now.We don&#39;t care, {sentence -&gt; 0, chunk -&gt; 4}, []}| |{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []} | ++ result.selectExpr(&quot;explode(filtered)&quot;).show(truncate=false) +-+ |col | +-+ |{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []} | |{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}| +-+ from johnsnowlabs import * val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val posTagger = nlp.PerceptronModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;pos&quot;) val chunker = new nlp.Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) // Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. val chunkerFilter = new finance.ChunkFilterer() .setInputCols(Array(&quot;sentence&quot;,&quot;chunk&quot;)) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList(&quot;gastroenteritis&quot;) val pipeline = new Pipeline().setStages(Array( docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter)) from johnsnowlabs import * val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val posTagger = nlp.PerceptronModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;pos&quot;) val chunker = new nlp.Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) // Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. val chunkerFilter = new legal.ChunkFilterer() .setInputCols(Array(&quot;sentence&quot;,&quot;chunk&quot;)) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList(&quot;gastroenteritis&quot;) val pipeline = new Pipeline().setStages(Array( docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter)) ChunkKeyPhraseExtraction Model Chunk KeyPhrase Extraction uses Bert Sentence Embeddings to determine the most relevant key phrases describing a text. The input to the model consists of chunk annotations and sentence or document annotation. The model compares the chunks against the corresponding sentences/documents and selects the chunks which are most representative of the broader text context (i.e. the document or the sentence they belong to). The key phrases candidates (i.e. the input chunks) can be generated in various ways, e.g. by NGramGenerator, TextMatcher or NerConverter. The model operates either at sentence (selecting the most descriptive chunks from the sentence they belong to) or at document level. In the latter case, the key phrases are selected to represent all the input document annotations. This model is a subclass of [[BertSentenceEmbeddings]] and shares all parameters with it. It can load any pretrained BertSentenceEmbeddings model. Available models can be found at the Models Hub. Input Annotator Types: DOCUMENT, CHUNK Output Annotator Type: CHUNK Python API: ChunkKeyPhraseExtraction Scala API: ChunkKeyPhraseExtraction Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;tokens&quot;) embeddings = nlp.WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_tagger = medical.NerModel() .pretrained(&quot;ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ner_converter = nlp.NerConverter() .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;) .setOutputCol(&quot;ner_chunks&quot;) key_phrase_extractor = medical.ChunkKeyPhraseExtraction .pretrained() .setTopN(1) .setDocumentLevelProcessing(False) .setDivergence(0.4) .setInputCols([&quot;sentences&quot;, &quot;ner_chunks&quot;]) .setOutputCol(&quot;ner_chunk_key_phrases&quot;) pipeline = sparknlp.base.Pipeline() .setStages([documenter, sentencer, tokenizer, embeddings, ner_tagger, ner_converter, key_phrase_extractor]) data = spark.createDataFrame([[&quot;Her Diabetes has become type 2 in the last year with her Diabetes.He complains of swelling in his right forearm.&quot;]]).toDF(&quot;text&quot;) results = pipeline.fit(data).transform(data) results .selectExpr(&quot;explode(ner_chunk_key_phrases) AS key_phrase&quot;) .selectExpr( &quot;key_phrase.result&quot;, &quot;key_phrase.metadata.entity&quot;, &quot;key_phrase.metadata.DocumentSimilarity&quot;, &quot;key_phrase.metadata.MMRScore&quot;) .show(truncate=False) +--++-+ |result |DocumentSimilarity|MMRScore | +--++-+ |gestational diabetes mellitus|0.7391447825527298|0.44348688715422274| |28-year-old |0.4366776288430703|0.13577881610104517| |type two diabetes mellitus |0.7323921930094919|0.085800103824974 | +--++-+ from johnsnowlabs import * documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;tokens&quot;) embeddings = nlp.WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunks&quot;) key_phrase_extractor = finance.ChunkKeyPhraseExtraction .pretrained() .setTopN(1) .setDocumentLevelProcessing(False) .setDivergence(0.4) .setInputCols([&quot;sentences&quot;, &quot;ner_chunks&quot;]) .setOutputCol(&quot;ner_chunk_key_phrases&quot;) pipeline = sparknlp.base.Pipeline() .setStages([documenter, sentencer, tokenizer, embeddings, ner_model, ner_converter, key_phrase_extractor]) from johnsnowlabs import * documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;tokens&quot;) embeddings = nlp.WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunks&quot;) key_phrase_extractor = legal.ChunkKeyPhraseExtraction .pretrained() .setTopN(1) .setDocumentLevelProcessing(False) .setDivergence(0.4) .setInputCols([&quot;sentences&quot;, &quot;ner_chunks&quot;]) .setOutputCol(&quot;ner_chunk_key_phrases&quot;) pipeline = sparknlp.base.Pipeline() .setStages([documenter, sentencer, tokenizer, embeddings, ner_model, ner_converter, key_phrase_extractor]) MedicalFinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val stopWordsCleaner = nlp.StopWordsCleaner.pretrained() .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;clean_tokens&quot;) .setCaseSensitive(false) val nGrams = new nlp.NGramGenerator() .setInputCols(Array(&quot;clean_tokens&quot;)) .setOutputCol(&quot;ngrams&quot;) .setN(3) val chunkKeyPhraseExtractor = medical.ChunkKeyPhraseExtraction .pretrained() .setTopN(2) .setDivergence(0.7f) .setInputCols(Array(&quot;document&quot;, &quot;ngrams&quot;)) .setOutputCol(&quot;key_phrases&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stopWordsCleaner, nGrams, chunkKeyPhraseExtractor)) val sampleText = &quot;Her Diabetes has become type 2 in the last year with her Diabetes.&quot; + &quot; He complains of swelling in his right forearm.&quot; val testDataset = Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(emptyDataset).transform(testDataset) result .selectExpr(&quot;explode(key_phrases) AS key_phrase&quot;) .selectExpr( &quot;key_phrase.result&quot;, &quot;key_phrase.metadata.DocumentSimilarity&quot;, &quot;key_phrase.metadata.MMRScore&quot;) .show(truncate=false) +--+-++ |result |DocumentSimilarity |MMRScore | +--+-++ |complains swelling forearm|0.6325718954229369 |0.1897715761677257| |type 2 year |0.40181028931546364|-0.189501077108947| +--+-++ from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val stopWordsCleaner = nlp.StopWordsCleaner.pretrained() .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;clean_tokens&quot;) .setCaseSensitive(false) val nGrams = new nlp.NGramGenerator() .setInputCols(Array(&quot;clean_tokens&quot;)) .setOutputCol(&quot;ngrams&quot;) .setN(3) val chunkKeyPhraseExtractor = finance.ChunkKeyPhraseExtraction .pretrained() .setTopN(2) .setDivergence(0.7f) .setInputCols(Array(&quot;document&quot;, &quot;ngrams&quot;)) .setOutputCol(&quot;key_phrases&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stopWordsCleaner, nGrams, chunkKeyPhraseExtractor)) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val stopWordsCleaner = nlp.StopWordsCleaner.pretrained() .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;clean_tokens&quot;) .setCaseSensitive(false) val nGrams = new nlp.NGramGenerator() .setInputCols(Array(&quot;clean_tokens&quot;)) .setOutputCol(&quot;ngrams&quot;) .setN(3) val chunkKeyPhraseExtractor = legal.ChunkKeyPhraseExtraction .pretrained() .setTopN(2) .setDivergence(0.7f) .setInputCols(Array(&quot;document&quot;, &quot;ngrams&quot;)) .setOutputCol(&quot;key_phrases&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stopWordsCleaner, nGrams, chunkKeyPhraseExtractor)) ChunkMapper ModelApproach We can use ChunkMapper to map entities with their associated code/reference based on pre-defined dictionaries. This is the AnnotatorModel of the ChunkMapper, which can be used to access pretrained models with the .pretrained() or .load() methods. To train a new model, check the documentation of the ChunkMapperApproach annotator. The annotator also allows using fuzzy matching, which can take into consideration parts of the tokens tha can map even when word order is different, char ngrams that can map even when thre are typos, and using fuzzy distance metric (Jaccard, Levenshtein, etc.). Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook Healthcare Chunk Mapping. Input Annotator Types: CHUNK Output Annotator Type: LABEL_DEPENDENCY Python API: ChunkMapperModel Scala API: ChunkMapperModel Show Example PythonScala Medical # Use `rxnorm_mapper` pretrained model to map entities with their corresponding RxNorm codes. document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;rxnorm&quot;) .setRels([&quot;rxnorm_code&quot;]) mapper_pipeline = Pipeline().setStages([document_assembler, chunkerMapper]) empty_df = spark.createDataFrame([[&#39;&#39;]]).toDF(&#39;text&#39;) mapper_model = mapper_pipeline.fit(empty_df) mapper_lp = LightPipeline(mapper_model) mapper_lp.fullAnnotate(&quot;metformin&quot;) [{&#39;ner_chunk&#39;: [Annotation(document, 0, 8, metformin, {})], &#39;rxnorm&#39;: [Annotation(labeled_dependency, 0, 8, 6809, {&#39;entity&#39;: &#39;metformin&#39;, &#39;relation&#39;: &#39;rxnorm_code&#39;, &#39;all_relations&#39;: &#39;&#39;})]}] Medical val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) val chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;rxnorm&quot;) .setRels([&quot;rxnorm_code&quot;]) mapper_pipeline = Pipeline().setStages([document_assembler, chunkerMapper]) empty_df = spark.createDataFrame([[&#39;&#39;]]).toDF(&#39;text&#39;) mapper_model = mapper_pipeline.fit(empty_df) mapper_lp = LightPipeline(mapper_model) mapper_lp.fullAnnotate(&quot;metformin&quot;) [{&#39;ner_chunk&#39;: [Annotation(document, 0, 8, metformin, {})], &#39;rxnorm&#39;: [Annotation(labeled_dependency, 0, 8, 6809, {&#39;entity&#39;: &#39;metformin&#39;, &#39;relation&#39;: &#39;rxnorm_code&#39;, &#39;all_relations&#39;: &#39;&#39;})]}] We can use ChunkMapper to map entities with their associated code/reference based on pre-defined dictionaries. This is the AnnotatorApproach of the ChunkMapper, which can be used to train ChunkMapper models by giving a custom mapping dictionary. To use pretriained models, check the documentation of the ChunkMapperModel annotator. The annotator also allows using fuzzy matching, which can take into consideration parts of the tokens tha can map even when word order is different, char ngrams that can map even when thre are typos, and using fuzzy distance metric (Jaccard, Levenshtein, etc.). Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook Healthcare Chunk Mapping. Input Annotator Types: CHUNK Output Annotator Type: LABEL_DEPENDENCY Python API: ChunkMapperApproach Scala API: ChunkMapperApproach Show Example PythonScala Medical # First, create a dictionay in JSON format following this schema: import json data_set= { &quot;mappings&quot;: [ { &quot;key&quot;: &quot;metformin&quot;, &quot;relations&quot;: [ { &quot;key&quot;: &quot;action&quot;, &quot;values&quot; : [&quot;hypoglycemic&quot;, &quot;Drugs Used In Diabetes&quot;] }, { &quot;key&quot;: &quot;treatment&quot;, &quot;values&quot; : [&quot;diabetes&quot;, &quot;t2dm&quot;] }] }] } with open(&#39;sample_drug.json&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f: json.dump(data_set, f, ensure_ascii=False, indent=4) # Create a pipeline document_assembler = DocumentAssembler() .setInputCol(&#39;text&#39;) .setOutputCol(&#39;document&#39;) sentence_detector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) #NER model to detect drug in the text clinical_ner = MedicalNerModel.pretrained(&quot;ner_posology_small&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) .setLabelCasing(&quot;upper&quot;) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;DRUG&quot;]) chunkerMapper = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;sample_drug.json&quot;) .setRels([&quot;action&quot;]) #or treatment pipeline = Pipeline( stages=[ document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunkerMapper, ] ) # Train the model text = [&quot;The patient was given 1 unit of metformin daily.&quot;] test_data = spark.createDataFrame([text]).toDF(&quot;text&quot;) model = pipeline.fit(test_data) ChunkMapperFilterer Model ChunkMapperFilterer is an annotator to be used after ChunkMapper that allows to filter chunks based on the results of the mapping, whether it was successful or failed. Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook Healthcare Chunk Mapping. Input Annotator Types: CHUNK, LABEL_DEPENDENCY Output Annotator Type: CHUNK Python API: ChunkMapperFilterer Scala API: ChunkMapperFilterer Show Example PythonScala Medical document_assembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentence_detector = ( SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) ) tokenizer = Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) word_embeddings = ( WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ) ner_model = ( MedicalNerModel.pretrained(&quot;ner_posology_greedy&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ) ner_converter = ( NerConverter().setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;).setOutputCol(&quot;chunk&quot;) ) chunkerMapper = ( ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;chunk&quot;]) .setOutputCol(&quot;RxNorm_Mapper&quot;) .setRel(&quot;rxnorm_code&quot;) ) cfModel = ( ChunkMapperFilterer() .setInputCols([&quot;chunk&quot;, &quot;RxNorm_Mapper&quot;]) .setOutputCol(&quot;chunks_fail&quot;) .setReturnCriteria(&quot;fail&quot;) ) chunk2doc = Chunk2Doc().setInputCols(&quot;chunks_fail&quot;).setOutputCol(&quot;doc_chunk&quot;) sbert_embedder = ( BertSentenceEmbeddings.pretrained( &quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols([&quot;doc_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) .setCaseSensitive(False) ) resolver = ( SentenceEntityResolverModel.pretrained( &quot;sbiobertresolve_rxnorm_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols([&quot;chunks_fail&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;resolver_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ) resolverMerger = ( ResolverMerger() .setInputCols([&quot;resolver_code&quot;, &quot;RxNorm_Mapper&quot;]) .setOutputCol(&quot;RxNorm&quot;) ) mapper_pipeline = Pipeline( stages=[ document_assembler, sentence_detector, tokenizer, word_embeddings, ner_model, ner_converter, chunkerMapper, chunkerMapper, cfModel, chunk2doc, sbert_embedder, resolver, resolverMerger, ] ) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = mapper_pipeline.fit(empty_data) samples = [ [&quot;The patient was given Adapin 10 MG, coumadn 5 mg&quot;], [&quot;The patient was given Avandia 4 mg, Tegretol, zitiga&quot;], ] result = model.transform(spark.createDataFrame(samples).toDF(&quot;text&quot;)) result.selectExpr( &quot;chunk.result as chunk&quot;, &quot;RxNorm_Mapper.result as RxNorm_Mapper&quot;, &quot;chunks_fail.result as chunks_fail&quot;, &quot;resolver_code.result as resolver_code&quot;, &quot;RxNorm.result as RxNorm&quot;, ).show(truncate=False) +--+-+--+-++ chunk |RxNorm_Mapper |chunks_fail |resolver_code|RxNorm | +--+-+--+-++ [Adapin 10 MG, coumadn 5 mg] |[1000049, NONE] |[coumadn 5 mg]|[200883] |[1000049, 200883] | [Avandia 4 mg, Tegretol, zitiga]|[261242, 203029, NONE]|[zitiga] |[220989] |[261242, 203029, 220989]| +--+-+--+-++ ChunkMerge ModelApproach Merges entities coming from different CHUNK annotations Input Annotator Types: CHUNK, CHUNK Output Annotator Type: CHUNK Python API: ChunkMergeModel Scala API: ChunkMergeModel Merges two chunk columns coming from two annotators(NER, ContextualParser or any other annotator producing chunks). The merger of the two chunk columns is made by selecting one chunk from one of the columns according to certain criteria. The decision on which chunk to select is made according to the chunk indices in the source document. (chunks with longer lengths and highest information will be kept from each source) Labels can be changed by setReplaceDictResource. Input Annotator Types: CHUNK, CHUNK Output Annotator Type: CHUNK Python API: ChunkMergeApproach Scala API: ChunkMergeApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define a pipeline with 2 different NER models with a ChunkMergeApproach at the end data = spark.createDataFrame([[&quot;A 63-year-old man presents to the hospital ...&quot;]]).toDF(&quot;text&quot;) pipeline = Pipeline(stages=[ nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;), nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;), nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;), nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setOutputCol(&quot;embs&quot;), medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;jsl_ner&quot;), nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;]).setOutputCol(&quot;jsl_ner_chunk&quot;), medical.NerModel.pretrained(&quot;ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;bionlp_ner&quot;), nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;bionlp_ner&quot;]) .setOutputCol(&quot;bionlp_ner_chunk&quot;), medical.ChunkMergeApproach().setInputCols([&quot;jsl_ner_chunk&quot;, &quot;bionlp_ner_chunk&quot;]).setOutputCol(&quot;merged_chunk&quot;) ]) # Show results result = pipeline.fit(data).transform(data).cache() result.selectExpr(&quot;explode(merged_chunk) as a&quot;) .selectExpr(&quot;a.begin&quot;,&quot;a.end&quot;,&quot;a.result as chunk&quot;,&quot;a.metadata.entity as entity&quot;) .show(5, False) +--++--++ |begin|end|chunk |entity | +--++--++ |5 |15 |63-year-old|Age | |17 |19 |man |Gender | |64 |72 |recurrent |Modifier | |98 |107|cellulitis |Diagnosis| |110 |119|pneumonias |Diagnosis| +--++--++ from johnsnowlabs import * data = spark.createDataFrame([[&quot;Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon&quot;]]).toDF(&quot;text&quot;) documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) fin_ner = finance.NerModel.pretrained(&#39;finner_deid&#39;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = finance.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; ner_finner = finance.NerModel.pretrained(&quot;finner_org_per_role_date&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;bert_embeddings&quot;]) .setOutputCol(&quot;ner_finner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter_finner = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_finner&quot;]) .setOutputCol(&quot;ner_finner_chunk&quot;) .setWhiteList([&#39;ROLE&#39;]) # Just use &quot;ROLE&quot; entity from this NER chunk_merge = finance.ChunkMergeApproach() .setInputCols(&quot;ner_finner_chunk&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, bert_embeddings, fin_ner, ner_converter, ner_finner, ner_converter_finner, chunk_merge]) # Show results result = nlpPipeline.fit(data).transform(data).cache() result.select(F.explode(F.arrays_zip(result.deid_merged_chunk.result, result.deid_merged_chunk.metadata)).alias(&quot;cols&quot;)) .select(F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;1&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;)).show(truncate=False) +++ |chunk |ner_label| +++ |Jeffrey Preston Bezos|PERSON | |founder |ROLE | |CEO |ROLE | |Amazon |PARTY | +++ from johnsnowlabs import * data = spark.createDataFrame([[&quot;ENTIRE AGREEMENT. This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. 2THEMART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99 Date: 6/11/99 &quot;]]).toDF(&quot;text&quot;) documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = legal.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) ner_signers = legal.NerModel.pretrained(&quot;legner_signers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_signers&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter_signers = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_signers&quot;]) .setOutputCol(&quot;ner_signer_chunk&quot;) chunk_merge = legal.ChunkMergeApproach() .setInputCols(&quot;ner_signer_chunk&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter, ner_signers, ner_converter_signers, chunk_merge]) # Show results result = nlpPipeline.fit(data).transform(data).cache() result.select(F.explode(F.arrays_zip(result.deid_merged_chunk.result, result.deid_merged_chunk.metadata)).alias(&quot;cols&quot;)) .select(F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;1&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;)).show(truncate=False) +--+--+ |chunk |ner_label | +--+--+ |ENTIRE AGREEMENT |DOC | |INC |PARTY | |J. Magliarditi |SIGNING_PERSON| |Bajaj |SIGNING_PERSON| |Dominic J. Magliarditi |SIGNING_PERSON| |Sanjay Bajaj |SIGNING_PERSON| |President |SIGNING_TITLE | |VP Business Development|SIGNING_TITLE | +--+--+ MedicalFinanceLegal from johnsnowlabs import * // Define a pipeline with 2 different NER models with a ChunkMergeApproach at the end val data = Seq((&quot;A 63-year-old man presents to the hospital ...&quot;)).toDF(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array( new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;), new nlp.SentenceDetector().setInputCol(&quot;document&quot;).setOutputCol(&quot;sentence&quot;), new nlp.Tokenizer().setInputCol(&quot;sentence&quot;).setOutputCol(&quot;token&quot;), nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)).setOutputCol(&quot;embs&quot;), medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;jsl_ner&quot;), new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;)).setOutputCol(&quot;jsl_ner_chunk&quot;), medical.NerModel.pretrained(&quot;ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;bionlp_ner&quot;), new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;bionlp_ner&quot;)) .setOutputCol(&quot;bionlp_ner_chunk&quot;), new medical.ChunkMergeApproach().setInputCols(Array(&quot;jsl_ner_chunk&quot;, &quot;bionlp_ner_chunk&quot;)).setOutputCol(&quot;merged_chunk&quot;) )) // Show results val result = pipeline.fit(data).transform(data).cache() result.selectExpr(&quot;explode(merged_chunk) as a&quot;) .selectExpr(&quot;a.begin&quot;,&quot;a.end&quot;,&quot;a.result as chunk&quot;,&quot;a.metadata.entity as entity&quot;) .show(5, false) +--++--++ |begin|end|chunk |entity | +--++--++ |5 |15 |63-year-old|Age | |17 |19 |man |Gender | |64 |72 |recurrent |Modifier | |98 |107|cellulitis |Diagnosis| |110 |119|pneumonias |Diagnosis| +--++--++ from johnsnowlabs import * val data = Seq((&quot;Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon&quot;)).toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCol(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;bert_embeddings&quot;) val fin_ner = finance.NerModel.pretrained(&#39;finner_deid&#39;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter = finance.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; val ner_finner = finance.NerModel.pretrained(&quot;finner_org_per_role_date&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;bert_embeddings&quot;)) .setOutputCol(&quot;ner_finner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter_finner = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_finner&quot;)) .setOutputCol(&quot;ner_finner_chunk&quot;) .setWhiteList([&#39;ROLE&#39;]) # Just use &quot;ROLE&quot; entity from this NER val chunk_merge = new finance.ChunkMergeApproach() .setInputCols(Array(&quot;ner_finner_chunk&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;deid_merged_chunk&quot;) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, bert_embeddings, fin_ner, ner_converter, ner_finner, ner_converter_finner, chunk_merge)) val model = nlpPipeline.fit(data) from johnsnowlabs import * val data = Seq((&quot;ENTIRE AGREEMENT. This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. 2THEMART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99 Date: 6/11/99 &quot;)).toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCol(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter = new legal.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) val ner_signers = legal.NerModel.pretrained(&quot;legner_signers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_signers&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter_signers = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_signers&quot;)) .setOutputCol(&quot;ner_signer_chunk&quot;) val chunk_merge = new legal.ChunkMergeApproach() .setInputCols(Array(&quot;ner_signer_chunk&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;deid_merged_chunk&quot;) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter, ner_signers, ner_converter_signers, chunk_merge)) val model = nlpPipeline.fit(data) ChunkSentenceSplitter Model ChunkSentenceSplitter annotator can split the documents into chunks according to separators given as CHUNK columns. It is useful when you need to perform different models or analysis in different sections of your document (for example, for different headers, clauses, items, etc.). The given separator chunk can be the output from, for example, RegexMatcher or NerModel. For detailed usage of this annotator, visit this notebook from our Spark NLP Workshop. Input Annotator Types: DOCUMENT, CHUNK Output Annotator Type: DOCUMENT Python API: ChunkSentenceSplitter Scala API: ChunkSentenceSplitter Show Example PythonScala Medical # Defining the pipeline documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) tokenizer = Tokenizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;token&quot;) tokenClassifier = ( MedicalBertForTokenClassifier.pretrained( &quot;bert_token_classifier_ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ) ner_converter = ( NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;Header&quot;]) ) chunkSentenceSplitter = ( ChunkSentenceSplitter() .setInputCols(&quot;document&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;paragraphs&quot;) .setGroupBySentences(False) ) pipeline = Pipeline( stages=[ documentAssembler, tokenizer, tokenClassifier, ner_converter, chunkSentenceSplitter, ] ) empty_df = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) pipeline_model = pipeline.fit(empty_df) sentences = [ [ &quot;&quot;&quot;ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelioma. PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma. REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface. &quot;&quot;&quot; ] ] df = spark.createDataFrame(sentences).toDF(&quot;text&quot;) paragraphs = pipeline_model.transform(df) paragraphs.selectExpr(&quot;explode(paragraphs) as result&quot;).selectExpr(&quot;result.result&quot;,&quot;result.metadata.entity&quot;, &quot;result.metadata.splitter_chunk&quot;).show(truncate=80) +--++-+ | result|entity| splitter_chunk| +--++-+ |ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelio...|Header|ADMISSION DIAGNOSIS| |PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma....|Header|PRINCIPAL DIAGNOSIS| |REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered thr...|Header| REVIEW OF SYSTEMS| +--++-+ Medical val data = Seq(text,text).toDS.toDF(&quot;text&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;doc&quot;) val regexMatcher = new RegexMatcher().setInputCols(&quot;doc&quot;).setOutputCol(&quot;chunks&quot;).setExternalRules(&quot;src/test/resources/chunker/title_regex.txt&quot;,&quot;,&quot;) val chunkSentenceSplitter = new ChunkSentenceSplitter().setInputCols(&quot;chunks&quot;,&quot;doc&quot;).setOutputCol(&quot;paragraphs&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler,regexMatcher,chunkSentenceSplitter)) val result = pipeline.fit(data).transform(data).select(&quot;paragraphs&quot;) result.show(truncate = false) ContextualParser ModelApproach Extracts entity from a document based on user defined rules. Rule matching is based on a RegexMatcher defined in a JSON file. In this file, regex is defined that you want to match along with the information that will output on metadata field. To instantiate a model, see ContextualParserApproach and its accompanied example. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: ContextualParserModel Scala API: ContextualParserModel Creates a model, that extracts entity from a document based on user defined rules. Rule matching is based on a RegexMatcher defined in a JSON file. It is set through the parameter setJsonPath() In this JSON file, regex is defined that you want to match along with the information that will output on metadata field. Additionally, a dictionary can be provided with setDictionary to map extracted entities to a unified representation. The first column of the dictionary file should be the representation with following columns the possible matches. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: ContextualParserApproach Scala API: ContextualParserApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # An example JSON file `regex_token.json` can look like this: # # { # &quot;entity&quot;: &quot;Stage&quot;, # &quot;ruleScope&quot;: &quot;sentence&quot;, # &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, # &quot;matchScope&quot;: &quot;token&quot; # } # # Which means to extract the stage code on a sentence level. # An example pipeline could then be defined like this # Pipeline could then be defined like this documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) # Define the parser (json file needs to be provided) data = spark.createDataFrame([[&quot;A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... &quot;]]).toDF(&quot;text&quot;) contextualParser = medical.ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(True) .setContextMatch(False) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, contextualParser ]) result = pipeline.fit(data).transform(data) # Show Results result.selectExpr(&quot;explode(entity)&quot;).show(5, truncate=False) +-+ |col | +-+ |{chunk, 32, 39, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []} | |{chunk, 49, 50, T5, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []} | |{chunk, 148, 156, cT4bcN2M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 1}, []}| |{chunk, 189, 194, T?N3M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 2}, []} | |{chunk, 316, 323, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 3}, []} | +-+ from johnsnowlabs import * # An example JSON file `regex_token.json` can look like this: # # { # &quot;entity&quot;: &quot;Stage&quot;, # &quot;ruleScope&quot;: &quot;sentence&quot;, # &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, # &quot;matchScope&quot;: &quot;token&quot; # } # # Which means to extract the stage code on a sentence level. # An example pipeline could then be defined like this # Pipeline could then be defined like this documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) # Define the parser (json file needs to be provided) contextualParser = finance.ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(True) .setContextMatch(False) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, contextualParser ]) from johnsnowlabs import * # An example JSON file `regex_token.json` can look like this: # # { # &quot;entity&quot;: &quot;Stage&quot;, # &quot;ruleScope&quot;: &quot;sentence&quot;, # &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, # &quot;matchScope&quot;: &quot;token&quot; # } # # Which means to extract the stage code on a sentence level. # An example pipeline could then be defined like this # Pipeline could then be defined like this documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) # Define the parser (json file needs to be provided) contextualParser = legal.ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(True) .setContextMatch(False) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, contextualParser ]) MedicalFinanceLegal from johnsnowlabs import * // An example JSON file `regex_token.json` can look like this: // // { // &quot;entity&quot;: &quot;Stage&quot;, // &quot;ruleScope&quot;: &quot;sentence&quot;, // &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, // &quot;matchScope&quot;: &quot;token&quot; // } // // Which means to extract the stage code on a sentence level. // An example pipeline could then be defined like this val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) // Define the parser (json file needs to be provided) val data = Seq(&quot;A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... &quot;).toDF(&quot;text&quot;) val contextualParser = new medical.ContextualParserApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(true) .setContextMatch(false) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, contextualParser )) val result = pipeline.fit(data).transform(data) // Show Results // // result.selectExpr(&quot;explode(entity)&quot;).show(5, truncate=false) // +-+ // |col | // +-+ // |{chunk, 32, 39, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []} | // |{chunk, 49, 50, T5, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []} | // |{chunk, 148, 156, cT4bcN2M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 1}, []}| // |{chunk, 189, 194, T?N3M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 2}, []} | // |{chunk, 316, 323, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 3}, []} | // +-+ // from johnsnowlabs import * // An example JSON file `regex_token.json` can look like this: // // { // &quot;entity&quot;: &quot;Stage&quot;, // &quot;ruleScope&quot;: &quot;sentence&quot;, // &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, // &quot;matchScope&quot;: &quot;token&quot; // } // // Which means to extract the stage code on a sentence level. // An example pipeline could then be defined like this val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) // Define the parser (json file needs to be provided) val data = Seq(&quot;A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... &quot;).toDF(&quot;text&quot;) val contextualParser = new finance.ContextualParserApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(true) .setContextMatch(false) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, contextualParser )) from johnsnowlabs import * // An example JSON file `regex_token.json` can look like this: // // { // &quot;entity&quot;: &quot;Stage&quot;, // &quot;ruleScope&quot;: &quot;sentence&quot;, // &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, // &quot;matchScope&quot;: &quot;token&quot; // } // // Which means to extract the stage code on a sentence level. // An example pipeline could then be defined like this val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) // Define the parser (json file needs to be provided) val data = Seq(&quot;A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... &quot;).toDF(&quot;text&quot;) val contextualParser = new legal.ContextualParserApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(true) .setContextMatch(false) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, contextualParser )) DateNormalizer Model This annotator transforms date mentions to a common standard format: YYYY/MM/DD. It is useful when using data from different sources, some times from different countries that has different formats to represent dates. For the relative dates (next year, past month, etc.), you can define an achor date to create the normalized date by setting the parameters anchorDateYear, anchorDateMonth, and anchorDateDay. The resultant chunk date will contain a metada indicating whether the normalization was successful or not (True / False). Input Annotator Types: CHUNK Output Annotator Type: CHUNK Python API: DateNormalizer Scala API: DateNormalizer Show Example PythonScala Medical from pyspark.sql.types import StringType dates = [ &quot;08/02/2018&quot;, &quot;11/2018&quot;, &quot;11/01/2018&quot;, &quot;12Mar2021&quot;, &quot;Jan 30, 2018&quot;, &quot;13.04.1999&quot;, &quot;3April 2020&quot;, &quot;next monday&quot;, &quot;today&quot;, &quot;next week&quot;, ] df = spark.createDataFrame(dates, StringType()).toDF(&quot;original_date&quot;) document_assembler = ( DocumentAssembler().setInputCol(&quot;original_date&quot;).setOutputCol(&quot;document&quot;) ) doc2chunk = Doc2Chunk().setInputCols(&quot;document&quot;).setOutputCol(&quot;date_chunk&quot;) date_normalizer = ( DateNormalizer() .setInputCols(&quot;date_chunk&quot;) .setOutputCol(&quot;date&quot;) .setAnchorDateYear(2000) .setAnchorDateMonth(3) .setAnchorDateDay(15) ) pipeline = Pipeline(stages=[document_assembler, doc2chunk, date_normalizer]) result = pipeline.fit(df).transform(df) result.selectExpr( &quot;date.result as normalized_date&quot;, &quot;original_date&quot;, &quot;date.metadata[0].normalized as metadata&quot;, ).show() ++-+--+ |normalized_date|original_date|metadata| ++-+--+ | [2018/08/02]| 08/02/2018| true| | [2018/11/DD]| 11/2018| true| | [2018/11/01]| 11/01/2018| true| | [2021/03/12]| 12Mar2021| true| | [2018/01/30]| Jan 30, 2018| true| | [1999/04/13]| 13.04.1999| true| | [2020/04/03]| 3April 2020| true| | [2000/03/20]| next monday| true| | [2000/03/15]| today| true| | [2000/03/22]| next week| true| ++-+--+ Medical val df = Seq((&quot;08/02/2018&quot;),(&quot;11/2018&quot;),(&quot;11/01/2018&quot;),(&quot;next monday&quot;),(&quot;today&quot;),(&quot;next week&quot;)).toDF(&quot;original_date&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;original_date&quot;).setOutputCol(&quot;document&quot;) val chunksDF = documentAssembler .transform(df) .mapAnnotationsCol[Seq[Annotation]](&quot;document&quot;, &quot;chunk_date&quot;, CHUNK, (aa:Seq[Annotation]) =&gt; aa.map( ann =&gt; ann.copy(annotatorType = CHUNK))) val dateNormalizerModel = new DateNormalizer() .setInputCols(&quot;chunk_date&quot;) .setOutputCol(&quot;date&quot;) .setAnchorDateDay(15) .setAnchorDateMonth(3) .setAnchorDateYear(2000) val dateDf = dateNormalizerModel.transform(chunksDF) dateDf.select(&quot;chunk_date.result&quot;,&quot;text&quot;).show() +-+-+ | result|original_date| +-+-+ | [08/02/2018]| 08/02/2018| | [11/2018]| 11/2018| | [11/01/2018]| 11/01/2018| |[next monday]| next monday| | [today]| today| | [next week]| next week| +-+-+ DeIdentification ModelApproach Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS. To create a configured DeIdentificationModel, please see the example of DeIdentification. Input Annotator Types: DOCUMENT, TOKEN, CHUNK Output Annotator Type: DOCUMENT Python API: DeIdentificationModel Scala API: DeIdentificationModel Show Example PythonScala FinanceLegal from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) fin_ner = finance.NerModel.pretrained(&#39;finner_deid&#39;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = finance.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; ner_finner = finance.NerModel.pretrained(&quot;finner_org_per_role_date&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;bert_embeddings&quot;]) .setOutputCol(&quot;ner_finner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter_finner = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_finner&quot;]) .setOutputCol(&quot;ner_finner_chunk&quot;) .setWhiteList([&#39;ROLE&#39;]) # Just use &quot;ROLE&quot; entity from this NER chunk_merge = finance.ChunkMergeApproach() .setInputCols(&quot;ner_finner_chunk&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) deidentification = finance.DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;deid_merged_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;mask&quot;) .setIgnoreRegex(True) # Pipeline data = spark.createDataFrame([ [&quot;Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon&quot;] ]).toDF(&quot;text&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, bert_embeddings, fin_ner, ner_converter, ner_finner, ner_converter_finner, chunk_merge, deidentification]) result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = legal.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) ner_signers = legal.NerModel.pretrained(&quot;legner_signers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_signers&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter_signers = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_signers&quot;]) .setOutputCol(&quot;ner_signer_chunk&quot;) chunk_merge = legal.ChunkMergeApproach() .setInputCols(&quot;ner_signer_chunk&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) deidentification = legal.DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;deid_merged_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;mask&quot;) .setIgnoreRegex(True) # Pipeline data = spark.createDataFrame([ [&quot;ENTIRE AGREEMENT. This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. 2THEMART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99 Date: 6/11/99 &quot;] ]).toDF(&quot;text&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter, ner_signers, ner_converter_signers, chunk_merge, deidentification]) result = nlpPipeline.fit(data).transform(data) FinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;bert_embeddings&quot;) val fin_ner = finance.NerModel.pretrained(&#39;finner_deid&#39;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter = finance.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; val ner_finner = finance.NerModel.pretrained(&quot;finner_org_per_role_date&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;bert_embeddings&quot;)) .setOutputCol(&quot;ner_finner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter_finner = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_finner&quot;)) .setOutputCol(&quot;ner_finner_chunk&quot;) .setWhiteList([&#39;ROLE&#39;]) # Just use &quot;ROLE&quot; entity from this NER val chunk_merge = new finance.ChunkMergeApproach() .setInputCols(Array(&quot;ner_finner_chunk&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;deid_merged_chunk&quot;) val deidentification = new finance.DeIdentification() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;deid_merged_chunk&quot;)) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;mask&quot;) .setIgnoreRegex(True) # Pipeline val data = Seq(&quot;Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon&quot;).toDF(&quot;text&quot;) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, bert_embeddings, fin_ner, ner_converter, ner_finner, ner_converter_finner, chunk_merge, deidentification)) val result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter = new legal.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) val ner_signers = legal.NerModel.pretrained(&quot;legner_signers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_signers&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter_signers = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_signers&quot;)) .setOutputCol(&quot;ner_signer_chunk&quot;) val chunk_merge = new legal.ChunkMergeApproach() .setInputCols(Array(&quot;ner_signer_chunk&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;deid_merged_chunk&quot;) val deidentification = new legal.DeIdentification() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;deid_merged_chunk&quot;)) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;mask&quot;) .setIgnoreRegex(True) # Pipeline val data = Seq(&quot;ENTIRE AGREEMENT. This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. 2THEMART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99 Date: 6/11/99 &quot;).toDF(&quot;text&quot;) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter, ner_signers, ner_converter_signers, chunk_merge, deidentification)) val result = nlpPipeline.fit(data).transform(data) Contains all the methods for training a DeIdentificationModel model. This module can obfuscate or mask the entities that contains personal information. These can be set with a file of regex patterns with setRegexPatternsDictionary, where each line is a mapping of entity to regex. DATE d{4} AID d{6,7} Additionally, obfuscation strings can be defined with setObfuscateRefFile, where each line is a mapping of string to entity. The format and seperator can be speficied with setRefFileFormat and setRefSep. Dr. Gregory House#DOCTOR 01010101#MEDICALRECORD Ideally this annotator works in conjunction with Demographic Named EntityRecognizers that can be trained either using TextMatchers, RegexMatchers, DateMatchers, NerCRFs or NerDLs Input Annotator Types: DOCUMENT, TOKEN, CHUNK Output Annotator Type: DOCUMENT Python API: DeIdentification Scala API: DeIdentification Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(True) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Ner entities clinical_sensitive_entities = medical.NerModel .pretrained(&quot;ner_deid_enriched&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = medical.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) # Deidentification deIdentification = medical.DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) # file with custom regex pattern for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) # file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) # Pipeline data = spark.createDataFrame([ [&quot;# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.&quot;] ]).toDF(&quot;text&quot;) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, clinical_sensitive_entities, nerConverter, deIdentification ]) result = pipeline.fit(data).transform(data) # Show Results result.select(&quot;dei.result&quot;).show(truncate = False) +--+ |result | +--+ |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]| +--+ from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(True) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Ner entities ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_con&quot;) # Deidentification deIdentification = finance.DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) # file with custom regex pattern for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) # file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) # Pipeline pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, deIdentification ]) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(True) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Ner entities ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_con&quot;) # Deidentification deIdentification = legal.DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) # file with custom regex pattern for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) # file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) # Pipeline pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, deIdentification ]) MedicalFinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(true) val tokenizer = new nlp.Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Ner entities val clinical_sensitive_entities = medical.NerModel.pretrained(&quot;ner_deid_enriched&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_con&quot;) // Deidentification val deIdentification = new medical.DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) // file with custom regex patterns for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) // file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(true) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) // Pipeline val data = Seq( &quot;# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.&quot; ).toDF(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, clinical_sensitive_entities, nerConverter, deIdentification )) val result = pipeline.fit(data).transform(data) result.select(&quot;dei.result&quot;).show(truncate = false) // Show Results // // result.select(&quot;dei.result&quot;).show(truncate = false) // +--+ // |result | // +--+ // |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]| // +--+ // from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(true) val tokenizer = new nlp.Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Ner entities val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_con&quot;) // Deidentification val deIdentification = new finance.DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) // file with custom regex patterns for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) // file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(true) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) // Pipeline val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, deIdentification )) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(true) val tokenizer = new nlp.Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Ner entities val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_con&quot;) // Deidentification val deIdentification = new legal.DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) // file with custom regex patterns for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) // file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(true) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) // Pipeline val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, deIdentification )) Doc2ChunkInternal Model Converts DOCUMENT, TOKEN typed annotations into CHUNK type with the contents of a chunkCol. Chunk text must be contained within input DOCUMENT. May be either StringType or ArrayType[StringType] (using setIsArray). Useful for annotators that require a CHUNK type input. For more extended examples on document pre-processing see the Spark NLP Workshop. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: Doc2ChunkInternal Scala API: Doc2ChunkInternal Show Example PythonScala Medical import sparknlp from sparknlp.base import * from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) tokenizer = Tokenizer().setInputCol(&quot;document&quot;).setOutputCol(&quot;token&quot;) chunkAssembler = ( Doc2ChunkInternal() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) .setIsArray(True) ) data = spark.createDataFrame( [ [ &quot;Spark NLP is an open-source text processing library for advanced natural language processing.&quot;, [&quot;Spark NLP&quot;, &quot;text processing library&quot;, &quot;natural language processing&quot;], ] ] ).toDF(&quot;text&quot;, &quot;target&quot;) pipeline = ( Pipeline().setStages([documentAssembler, tokenizer, chunkAssembler]).fit(data) ) result = pipeline.transform(data) result.selectExpr(&quot;chunk.result&quot;, &quot;chunk.annotatorType&quot;).show(truncate=False) +--++ |result |annotatorType | +--++ |[Spark NLP, text processing library, natural language processing]|[chunk, chunk, chunk]| +--++ DocumentHashCoder Model This annotator can replace dates in a column of DOCUMENT type according with the hash code of any other column. It uses the hash of the specified column and creates a new document column containing the day shift information. In sequence, the DeIdentification annotator deidentifies the document with the shifted date information. If the specified column contains strings that can be parsed to integers, use those numbers to make the shift in the data accordingly. Input Annotator Types: DOCUMENT Output Annotator Type: DOCUMENT Python API: DocumentHashCoder Scala API: DocumentHashCoder Show Example PythonScala Medical import pandas as pd data = pd.DataFrame( {&#39;patientID&#39; : [&#39;A001&#39;, &#39;A001&#39;, &#39;A003&#39;, &#39;A003&#39;], &#39;text&#39; : [&#39;Chris Brown was discharged on 10/02/2022&#39;, &#39;Mark White was discharged on 10/04/2022&#39;, &#39;John was discharged on 15/03/2022&#39;, &#39;John Moore was discharged on 15/12/2022&#39; ], &#39;dateshift&#39; : [&#39;10&#39;, &#39;10&#39;, &#39;30&#39;, &#39;30&#39;] } ) my_input_df = spark.createDataFrame(data) documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) documentHasher = DocumentHashCoder() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;document2&quot;) .setDateShiftColumn(&quot;dateshift&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document2&quot;]) .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document2&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel .pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document2&quot;,&quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&quot;document2&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;document2&quot;]) .setOutputCol(&quot;deid_text&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setLanguage(&quot;en&quot;) .setObfuscateRefSource(&#39;faker&#39;) .setUseShifDays(True) pipeline_col = Pipeline().setStages([ documentAssembler, documentHasher, tokenizer, embeddings, clinical_ner, ner_converter, de_identification ]) empty_data = spark.createDataFrame([[&quot;&quot;, &quot;&quot;, &quot;&quot;]]).toDF(&quot;patientID&quot;,&quot;text&quot;, &quot;dateshift&quot;) pipeline_col_model = pipeline_col.fit(empty_data) output = pipeline_col_model.transform(my_input_df) output.select(&#39;text&#39;, &#39;dateshift&#39;, &#39;deid_text.result&#39;).show(truncate = False) +-++-+ text |dateshift|result | +-++-+ Chris Brown was discharged on 10/02/2022|10 |[Ellender Manual was discharged on 20/02/2022]| Mark White was discharged on 10/04/2022 |10 |[Errol Bang was discharged on 20/04/2022] | John was discharged on 15/03/2022 |30 |[Ariel Null was discharged on 14/04/2022] | John Moore was discharged on 15/12/2022 |30 |[Jean Cotton was discharged on 14/01/2023] | +-++-+ DocumentLogRegClassifier ModelApproach Classifies documents with a Logarithmic Regression algorithm. Currently there are no pretrained models available. Please see DocumentLogRegClassifierApproach to train your own model. Please check out the Models Hub for available models in the future. Input Annotator Types: TOKEN Output Annotator Type: CATEGORY Python API: DocumentLogRegClassifierModel Scala API: DocumentLogRegClassifierModel Trains a model to classify documents with a Logarithmic Regression algorithm. Training data requires columns for text and their label. The result is a trained DocumentLogRegClassifierModel. Input Annotator Types: TOKEN Output Annotator Type: CATEGORY Python API: DocumentLogRegClassifierApproach Scala API: DocumentLogRegClassifierApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define pipeline stages to prepare the data document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) normalizer = nlp.Normalizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;normalized&quot;) stopwords_cleaner = nlp.StopWordsCleaner() .setInputCols([&quot;normalized&quot;]) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) stemmer = nlp.Stemmer() .setInputCols([&quot;cleanTokens&quot;]) .setOutputCol(&quot;stem&quot;) # Define the document classifier and fit training data to it logreg = medical.DocumentLogRegClassifierApproach() .setInputCols([&quot;stem&quot;]) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) pipeline = Pipeline(stages=[ document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg ]) model = pipeline.fit(trainingData) from johnsnowlabs import * # Define pipeline stages to prepare the data document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) normalizer = nlp.Normalizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;normalized&quot;) stopwords_cleaner = nlp.StopWordsCleaner() .setInputCols([&quot;normalized&quot;]) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) stemmer = nlp.Stemmer() .setInputCols([&quot;cleanTokens&quot;]) .setOutputCol(&quot;stem&quot;) # Define the document classifier and fit training data to it logreg = finance.DocumentLogRegClassifierApproach() .setInputCols([&quot;stem&quot;]) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) pipeline = Pipeline(stages=[ document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg ]) model = pipeline.fit(trainingData) from johnsnowlabs import * # Define pipeline stages to prepare the data document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) normalizer = nlp.Normalizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;normalized&quot;) stopwords_cleaner = nlp.StopWordsCleaner() .setInputCols([&quot;normalized&quot;]) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) stemmer = nlp.Stemmer() .setInputCols([&quot;cleanTokens&quot;]) .setOutputCol(&quot;stem&quot;) # Define the document classifier and fit training data to it logreg = legal.DocumentLogRegClassifierApproach() .setInputCols([&quot;stem&quot;]) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) pipeline = Pipeline(stages=[ document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg ]) model = pipeline.fit(trainingData) MedicalFinanceLegal from johnsnowlabs import * // Define pipeline stages to prepare the data val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new nlp.Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) val stopwords_cleaner = new nlp.StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val stemmer = new nlp.Stemmer() .setInputCols(&quot;cleanTokens&quot;) .setOutputCol(&quot;stem&quot;) // Define the document classifier and fit training data to it val logreg = new medical.DocumentLogRegClassifierApproach() .setInputCols(&quot;stem&quot;) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg )) val model = pipeline.fit(trainingData) from johnsnowlabs import * // Define pipeline stages to prepare the data val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new nlp.Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) val stopwords_cleaner = new nlp.StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val stemmer = new nlp.Stemmer() .setInputCols(&quot;cleanTokens&quot;) .setOutputCol(&quot;stem&quot;) // Define the document classifier and fit training data to it val logreg = new finance.DocumentLogRegClassifierApproach() .setInputCols(&quot;stem&quot;) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg )) val model = pipeline.fit(trainingData) from johnsnowlabs import * // Define pipeline stages to prepare the data val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new nlp.Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) val stopwords_cleaner = new nlp.StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val stemmer = new nlp.Stemmer() .setInputCols(&quot;cleanTokens&quot;) .setOutputCol(&quot;stem&quot;) // Define the document classifier and fit training data to it val logreg = new legal.DocumentLogRegClassifierApproach() .setInputCols(&quot;stem&quot;) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg )) val model = pipeline.fit(trainingData) DrugNormalizer Model Annotator which normalizes raw text from clinical documents, e.g. scraped web pages or xml documents, from document type columns into Sentence. Removes all dirty characters from text following one or more input regex patterns. Can apply non wanted character removal which a specific policy. Can apply lower case normalization. See Spark NLP Workshop for more examples of usage. Input Annotator Types: DOCUMENT Output Annotator Type: DOCUMENT Python API: DrugNormalizer Scala API: DrugNormalizer Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * data = spark.createDataFrame([ [&quot;Sodium Chloride/Potassium Chloride 13bag&quot;], [&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec&quot;], [&quot;aspirin 10 meq/ 5 ml oral sol&quot;] ]).toDF(&quot;text&quot;) document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) drugNormalizer = medical.DrugNormalizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;document_normalized&quot;) trainingPipeline = Pipeline(stages=[document, drugNormalizer]) result = trainingPipeline.fit(data).transform(data) result.selectExpr(&quot;explode(document_normalized.result) as normalized_text&quot;).show(truncate=False) +-+ |normalized_text | +-+ |Sodium Chloride / Potassium Chloride 13 bag | |interferon alfa - 2b 10000000 unt ( 1 ml ) injection| |aspirin 2 meq/ml oral solution | +-+ from johnsnowlabs import * document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) drugNormalizer = finance.DrugNormalizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;document_normalized&quot;) trainingPipeline = Pipeline(stages=[document, drugNormalizer]) from johnsnowlabs import * document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) drugNormalizer = legal.DrugNormalizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;document_normalized&quot;) trainingPipeline = Pipeline(stages=[document, drugNormalizer]) MedicalFinanceLegal from johnsnowlabs import * val data = Seq( (&quot;Sodium Chloride/Potassium Chloride 13bag&quot;), (&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec&quot;), (&quot;aspirin 10 meq/ 5 ml oral sol&quot;) ).toDF(&quot;text&quot;) val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val drugNormalizer = new medical.DrugNormalizer().setInputCols(&quot;document&quot;).setOutputCol(&quot;document_normalized&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, drugNormalizer)) val result = trainingPipeline.fit(data).transform(data) result.selectExpr(&quot;explode(document_normalized.result) as normalized_text&quot;).show(false) +-+ |normalized_text | +-+ |Sodium Chloride / Potassium Chloride 13 bag | |interferon alfa - 2b 10000000 unt ( 1 ml ) injection| |aspirin 2 meq/ml oral solution | +-+ from johnsnowlabs import * val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val drugNormalizer = new finance.DrugNormalizer().setInputCols(&quot;document&quot;).setOutputCol(&quot;document_normalized&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, drugNormalizer)) from johnsnowlabs import * val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val drugNormalizer = new legal.DrugNormalizer().setInputCols(&quot;document&quot;).setOutputCol(&quot;document_normalized&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, drugNormalizer)) EntityChunkEmbeddings Model Weighted average embeddings of multiple named entities chunk annotations. Entity Chunk Embeddings uses BERT Sentence embeddings to compute a weighted average vector represention of related entity chunks. The input the model consists of chunks of recognized named entities. One or more entities are selected as target entities and for each of them a list of related entities is specified (if empty, all other entities are assumed to be related). The model looks for chunks of the target entities and then tries to pair each target entity (e.g. DRUG) with other related entities (e.g. DOSAGE, STRENGTH, FORM, etc). The criterion for pairing a target entity with another related entity is that they appear in the same sentence and the maximal syntactic distance is below a predefined threshold. The relationship between target and related entities is one-to-many, meaning that if there multiple instances of the same target entity (e.g.) within a sentence, the model will map a related entity (e.g. DOSAGE) to at most one of the instances of the target entity. For example, if there is a sentence “The patient was given 125 mg of paracetamol and metformin”, the model will pair “125 mg” to “paracetamol”, but not to “metformin”. The output of the model is an average embeddings of the chunks of each of the target entities and their related entities. It is possible to specify a particular weight for each entity type. An entity can be defined both as target a entity and as a related entity for some other target entity. For example, we may want to compute the embeddings of SYMPTOMs and their related entities, as well as the embeddings of DRUGs and their related entities, one of each is also SYMPTOM. In such cases, it is possible to use the TARGET_ENTITY:RELATED_ENTITY notation to specify the weight of an related entity (e.g. “DRUG:SYMPTOM” to set the weight of SYMPTOM when it appears as an related entity to target entity DRUG). The relative weights of entities for particular entity chunk embeddings are available in the annotations metadata. This model is a subclass of BertSentenceEmbeddings and shares all parameters with it. It can load any pretrained BertSentenceEmbeddings model. The default model is &quot;sbiobert_base_cased_mli&quot; from clinical/models. Other available models can be found at Models Hub. Input Annotator Types: DEPENDENCY, CHUNK Output Annotator Type: SENTENCE_EMBEDDINGS Python API: EntityChunkEmbeddingsModel Scala API: EntityChunkEmbeddingsModel Show Example PythonScala Medical import sparknlp from sparknlp.base import * from sparknlp_jsl.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline documenter = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) sentence_detector = SentenceDetector() .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;sentences&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) embeddings = WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel() .pretrained(&quot;ner_posology_large&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal() .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunks&quot;) pos_tager = PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) drug_chunk_embeddings = EntityChunkEmbeddings() .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;drug_chunk_embeddings&quot;) .setMaxSyntacticDistance(3) .setTargetEntities({&quot;DRUG&quot;: []}) .setEntityWeights({&quot;DRUG&quot;: 0.8, &quot;STRENGTH&quot;: 0.2, &quot;DOSAGE&quot;: 0.2, &quot;FORM&quot;: 0.5}) sampleData = &quot;The parient was given metformin 125 mg, 250 mg of coumadin and then one pill paracetamol&quot; data = SparkContextForTest.spark.createDataFrame([[sampleData]]).toDF(&quot;text&quot;) pipeline = Pipeline().setStages([ documenter, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, pos_tager, dependency_parser, drug_chunk_embeddings]) results = pipeline.fit(data).transform(data) results = results .selectExpr(&quot;explode(drug_chunk_embeddings) AS drug_chunk&quot;) .selectExpr(&quot;drug_chunk.result&quot;, &quot;slice(drug_chunk.embeddings, 1, 5) AS drug_embedding&quot;) .cache() results.show(truncate=False) +--+--+ | result| drug_embedding&quot;| +--+--+ |metformin 125 mg |[-0.267413, 0.07614058, -0.5620966, 0.83838946, 0.8911504] | |250 mg coumadin |[0.22319649, -0.07094894, -0.6885556, 0.79176235, 0.82672405] | |one pill paracetamol |[-0.10939768, -0.29242, -0.3574444, 0.3981813, 0.79609615] | +--+--+ Medical import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.SentenceDetector import com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel import com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel import com.johnsnowlabs.nlp.annotators.ner.{MedicalNerModel, NerConverterInternal} import com.johnsnowlabs.nlp.annotators.embeddings.EntityChunkEmbeddings import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;tokens&quot;) val wordEmbeddings = WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;word_embeddings&quot;) val nerModel = MedicalNerModel .pretrained(&quot;ner_posology_large&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;tokens&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val nerConverter = new NerConverterInternal() .setInputCols(&quot;sentence&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunk&quot;) val posTager = PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;) .setOutputCol(&quot;pos_tags&quot;) val dependencyParser = DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val drugChunkEmbeddings = EntityChunkEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;drug_chunk_embeddings&quot;) .setMaxSyntacticDistance(3) .setTargetEntities(Map(&quot;DRUG&quot; -&gt; List())) .setEntityWeights(Map[String, Float](&quot;DRUG&quot; -&gt; 0.8f, &quot;STRENGTH&quot; -&gt; 0.2f, &quot;DOSAGE&quot; -&gt; 0.2f, &quot;FORM&quot; -&gt; 0.5f)) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentenceDetector, tokenizer, wordEmbeddings, nerModel, nerConverter, posTager, dependencyParser, drugChunkEmbeddings)) val sampleText = &quot;The patient was given metformin 125 mg, 250 mg of coumadin and then one pill paracetamol.&quot; val testDataset = Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(emptyDataset).transform(testDataset) result .selectExpr(&quot;explode(drug_chunk_embeddings) AS drug_chunk&quot;) .selectExpr(&quot;drug_chunk.result&quot;, &quot;slice(drug_chunk.embeddings, 1, 5) AS drugEmbedding&quot;) .show(truncate=false) +--+--+ | result| drugEmbedding| +--+--+ |metformin 125 mg |[-0.267413, 0.07614058, -0.5620966, 0.83838946, 0.8911504] | |250 mg coumadin |[0.22319649, -0.07094894, -0.6885556, 0.79176235, 0.82672405] | |one pill paracetamol |[-0.10939768, -0.29242, -0.3574444, 0.3981813, 0.79609615] | +--+-+ FeaturesAssembler Approach The FeaturesAssembler is used to collect features from different columns. It can collect features from single value columns (anything which can be cast to a float, if casts fails then the value is set to 0), array columns or SparkNLP annotations (if the annotation is an embedding, it takes the embedding, otherwise tries to cast the result field). The output of the transformer is a FEATURE_VECTOR annotation (the numeric vector is in the embeddings field). Input Annotator Types: NONE Output Annotator Type: &quot;feature_vector&quot; Python API: FeaturesAssembler Scala API: FeaturesAssembler Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * features_asm = medical.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = medical.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setLearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline(stages=[ features_asm, gen_clf ]) clf_model = pipeline.fit(data) from johnsnowlabs import * features_asm = finance.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = finance.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setLearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline(stages=[ features_asm, gen_clf ]) clf_model = pipeline.fit(data) from johnsnowlabs import * features_asm = legal.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = legal.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setLearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline(stages=[ features_asm, gen_clf ]) clf_model = pipeline.fit(data) MedicalFinanceLegal from johnsnowlabs import * val features_asm = new medical.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new medical.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) from johnsnowlabs import * val features_asm = new finance.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new finance.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) from johnsnowlabs import * val features_asm = new legal.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new legal.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) GenericClassifier ModelApproach Creates a generic single-label classifier which uses pre-generated Tensorflow graphs. The model operates on FEATURE_VECTOR annotations which can be produced using FeatureAssembler. Requires the FeaturesAssembler to create the input. Input Annotator Types: FEATURE_VECTOR Output Annotator Type: CATEGORY Python API: GenericClassifierModel Scala API: GenericClassifierModel Trains a TensorFlow model for generic classification of feature vectors. It takes FEATURE_VECTOR annotations from FeaturesAssembler as input, classifies them and outputs CATEGORY annotations. Please see the Parameters section for required training parameters. For a more extensive example please see the Spark NLP Workshop. Input Annotator Types: FEATURE_VECTOR Output Annotator Type: CATEGORY Python API: GenericClassifierApproach Scala API: GenericClassifierApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * features_asm = medical.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = medical.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline().setStages([ features_asm, gen_clf ]) clf_model = pipeline.fit(data) from johnsnowlabs import * features_asm = finance.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = finance.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline().setStages([ features_asm, gen_clf ]) clf_model = pipeline.fit(data) from johnsnowlabs import * features_asm = legal.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = legal.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline().setStages([ features_asm, gen_clf ]) clf_model = pipeline.fit(data) MedicalFinanceLegal from johnsnowlabs import * val features_asm = new medical.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new medical.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) from johnsnowlabs import * val features_asm = new finance.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new finance.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) from johnsnowlabs import * val features_asm = new legal.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new legal.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) IOBTagger Model Merges token tags and NER labels from chunks in the specified format. For example output columns as inputs from NerConverter and Tokenizer can be used to merge. Input Annotator Types: TOKEN, CHUNK Output Annotator Type: NAMED_ENTITY Python API: IOBTagger Scala API: IOBTagger Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Pipeline stages are defined where NER is done. NER is converted to chunks. data = spark.createDataFrame([[&quot;A 63-year-old man presents to the hospital ...&quot;]]).toDF(&quot;text&quot;) docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;]).setOutputCol(&quot;embs&quot;) nerModel = medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) # Define the IOB tagger, which needs tokens and chunks as input. Show results. iobTagger = medical.IOBTagger().setInputCols([&quot;token&quot;, &quot;ner_chunk&quot;]).setOutputCol(&quot;ner_label&quot;) pipeline = Pipeline(stages=[docAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, iobTagger]) result.selectExpr(&quot;explode(ner_label) as a&quot;) .selectExpr(&quot;a.begin&quot;,&quot;a.end&quot;,&quot;a.result as chunk&quot;,&quot;a.metadata.word as word&quot;) .where(&quot;chunk!=&#39;O&#39;&quot;).show(5, False) +--++--+--+ |begin|end|chunk |word | +--++--+--+ |5 |15 |B-Age |63-year-old| |17 |19 |B-Gender |man | |64 |72 |B-Modifier |recurrent | |98 |107|B-Diagnosis|cellulitis | |110 |119|B-Diagnosis|pneumonias | +--++--+--+ from johnsnowlabs import * # Pipeline stages are defined where NER is done. NER is converted to chunks. docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;]).setOutputCol(&quot;embs&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) # Define the IOB tagger, which needs tokens and chunks as input. Show results. iobTagger = finance.IOBTagger().setInputCols([&quot;token&quot;, &quot;ner_chunk&quot;]).setOutputCol(&quot;ner_label&quot;) pipeline = Pipeline(stages=[docAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, iobTagger]) from johnsnowlabs import * # Pipeline stages are defined where NER is done. NER is converted to chunks. docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;]).setOutputCol(&quot;embs&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) # Define the IOB tagger, which needs tokens and chunks as input. Show results. iobTagger = legal.IOBTagger().setInputCols([&quot;token&quot;, &quot;ner_chunk&quot;]).setOutputCol(&quot;ner_label&quot;) pipeline = Pipeline(stages=[docAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, iobTagger]) MedicalFinanceLegal from johnsnowlabs import * // Pipeline stages are defined where NER is done. NER is converted to chunks. val data = Seq((&quot;A 63-year-old man presents to the hospital ...&quot;)).toDF(&quot;text&quot;) val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)).setOutputCol(&quot;embs&quot;) val nerModel = medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)).setOutputCol(&quot;ner_chunk&quot;) // Define the IOB tagger, which needs tokens and chunks as input. Show results. val iobTagger = new medical.IOBTagger().setInputCols(Array(&quot;token&quot;, &quot;ner_chunk&quot;)).setOutputCol(&quot;ner_label&quot;) val pipeline = new Pipeline().setStages(Array(docAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, iobTagger)) result.selectExpr(&quot;explode(ner_label) as a&quot;) .selectExpr(&quot;a.begin&quot;,&quot;a.end&quot;,&quot;a.result as chunk&quot;,&quot;a.metadata.word as word&quot;) .where(&quot;chunk!=&#39;O&#39;&quot;).show(5, false) +--++--+--+ |begin|end|chunk |word | +--++--+--+ |5 |15 |B-Age |63-year-old| |17 |19 |B-Gender |man | |64 |72 |B-Modifier |recurrent | |98 |107|B-Diagnosis|cellulitis | |110 |119|B-Diagnosis|pneumonias | +--++--+--+ from johnsnowlabs import * // Pipeline stages are defined where NER is done. NER is converted to chunks. val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)).setOutputCol(&quot;embs&quot;) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)).setOutputCol(&quot;ner_chunk&quot;) // Define the IOB tagger, which needs tokens and chunks as input. Show results. val iobTagger = new legal.IOBTagger().setInputCols(Array(&quot;token&quot;, &quot;ner_chunk&quot;)).setOutputCol(&quot;ner_label&quot;) val pipeline = new Pipeline().setStages(Array(docAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, iobTagger)) from johnsnowlabs import * // Pipeline stages are defined where NER is done. NER is converted to chunks. val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)).setOutputCol(&quot;embs&quot;) val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)).setOutputCol(&quot;ner_chunk&quot;) // Define the IOB tagger, which needs tokens and chunks as input. Show results. val iobTagger = new legal.IOBTagger().setInputCols(Array(&quot;token&quot;, &quot;ner_chunk&quot;)).setOutputCol(&quot;ner_label&quot;) val pipeline = new Pipeline().setStages(Array(docAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, iobTagger)) NerChunker Model Extracts phrases that fits into a known pattern using the NER tags. Useful for entity groups with neighboring tokens when there is no pretrained NER model to address certain issues. A Regex needs to be provided to extract the tokens between entities. Input Annotator Types: DOCUMENT, NAMED_ENTITY Output Annotator Type: CHUNK Python API: NerChunker Scala API: NerChunker Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Defining pipeline stages for NER data= spark.createDataFrame([[&quot;She has cystic cyst on her kidney.&quot;]]).toDF(&quot;text&quot;) documentAssembler= nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector= nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) tokenizer= nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) ner = medical.NerModel.pretrained(&quot;ner_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) .setIncludeConfidence(True) # Define the NerChunker to combine to chunks chunker = medical.NerChunker() .setInputCols([&quot;sentence&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers([&quot;&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;&quot;]) pipeline= Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner, chunker ]) result = pipeline.fit(data).transform(data) # Show results: result.selectExpr(&quot;explode(arrays_zip(ner.metadata , ner.result))&quot;) .selectExpr(&quot;col[&#39;0&#39;].word as word&quot; , &quot;col[&#39;1&#39;] as ner&quot;).show(truncate=False) ++--+ |word |ner | ++--+ |She |O | |has |O | |cystic|B-ImagingFindings| |cyst |I-ImagingFindings| |on |O | |her |O | |kidney|B-BodyPart | |. |O | ++--+ result.select(&quot;ner_chunk.result&quot;).show(truncate=False) ++ |result | ++ |[cystic cyst on her kidney]| ++ from johnsnowlabs import * # Defining pipeline stages for NER documentAssembler= nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector= nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) tokenizer= nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) # Define the NerChunker to combine to chunks chunker = finance.NerChunker() .setInputCols([&quot;sentence&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers([&quot;&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;&quot;]) pipeline= Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, chunker ]) from johnsnowlabs import * # Defining pipeline stages for NER documentAssembler= nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector= nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) tokenizer= nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) # Define the NerChunker to combine to chunks chunker = legal.NerChunker() .setInputCols([&quot;sentence&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers([&quot;&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;&quot;]) pipeline= Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, chunker ]) MedicalFinanceLegal from johnsnowlabs import * // Defining pipeline stages for NER val data= Seq(&quot;She has cystic cyst on her kidney.&quot;).toDF(&quot;text&quot;) val documentAssembler=new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector=new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) val tokenizer=new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) val ner = medical.NerModel.pretrained(&quot;ner_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) .setIncludeConfidence(True) // Define the NerChunker to combine to chunks val chunker = new medical.NerChunker() .setInputCols(Array(&quot;sentence&quot;,&quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers(Array(&quot;&lt;ImagingFindings&gt;.&lt;BodyPart&gt;&quot;)) val pipeline=new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner, chunker )) val result = pipeline.fit(data).transform(data) // Show results: // // result.selectExpr(&quot;explode(arrays_zip(ner.metadata , ner.result))&quot;) // .selectExpr(&quot;col[&#39;0&#39;].word as word&quot; , &quot;col[&#39;1&#39;] as ner&quot;).show(truncate=false) // ++--+ // |word |ner | // ++--+ // |She |O | // |has |O | // |cystic|B-ImagingFindings| // |cyst |I-ImagingFindings| // |on |O | // |her |O | // |kidney|B-BodyPart | // |. |O | // ++--+ // result.select(&quot;ner_chunk.result&quot;).show(truncate=false) // ++ // |result | // ++ // |[cystic cyst on her kidney]| // ++ // from johnsnowlabs import * // Defining pipeline stages for NER val documentAssembler=new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector=new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) val tokenizer=new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) // Define the NerChunker to combine to chunks val chunker = new finance.NerChunker() .setInputCols(Array(&quot;sentence&quot;,&quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers(Array(&quot;&lt;ImagingFindings&gt;.&lt;BodyPart&gt;&quot;)) val pipeline=new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, chunker )) from johnsnowlabs import * // Defining pipeline stages for NER val documentAssembler=new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector=new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) val tokenizer=new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) // Define the NerChunker to combine to chunks val chunker = new legal.NerChunker() .setInputCols(Array(&quot;sentence&quot;,&quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers(Array(&quot;&lt;ImagingFindings&gt;.&lt;BodyPart&gt;&quot;)) val pipeline=new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, chunker )) NerConverterInternal Model Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label. Chunks with no associated entity (tagged “O”) are filtered out. This licensed annotator adds extra functionality to the open-source version by adding the following parameters: blackList, greedyMode, threshold, and ignoreStopWords that are not available in the NerConverter annotator. See also Inside–outside–beginning (tagging) for more information. Input Annotator Types: DOCUMENT, TOKEN, NAMED_ENTITY Output Annotator Type: CHUNK Python API: NerConverterInternal Scala API: NerConverterInternal Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) jsl_ner = medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;jsl_ner&quot;) jsl_ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;]) .setOutputCol(&quot;jsl_ner_chunk&quot;) jsl_ner_converter_internal = medical.NerConverterInternal() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;jsl_ner&quot;]) .setOutputCol(&quot;replaced_ner_chunk&quot;) .setReplaceDictResource(&quot;replace_dict.csv&quot;,&quot;text&quot;, {&quot;delimiter&quot;:&quot;,&quot;}) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, jsl_ner, jsl_ner_converter, jsl_ner_converter_internal ]) result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) #.setCustomBounds([&quot; n n&quot;]) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) fin_ner = finance.NerModel.pretrained(&quot;finner_deid&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = finance.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, fin_ner, ner_converter]) result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) #.setCustomBounds([&quot; n n&quot;]) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = legal.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) # &quot;ALIAS&quot; are secondary names of companies, so let&#39;s extract them also as PARTY nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter]) result = nlpPipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val jsl_ner = medical.NerModel .pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;jsl_ner&quot;) val jsl_ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;)) .setOutputCol(&quot;jsl_ner_chunk&quot;) val jsl_ner_converter_internal = new medical.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;)) .setOutputCol(&quot;replaced_ner_chunk&quot;) .setReplaceDictResource(&quot;replace_dict.csv&quot;,&quot;text&quot;, {&quot;delimiter&quot;:&quot;,&quot;}) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, jsl_ner, jsl_ner_converter, jsl_ner_converter_internal )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings .pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val fin_ner = finance.NerModel .pretrained(&quot;finner_deid&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new finance.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, fin_ner, ner_converter )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings .pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val legal_ner = legal.NerModel .pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new legal.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter )) val result = pipeline.fit(data).transform(data) NerDisambiguator ModelApproach Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs), mentions, or surface forms. Instantiated / pretrained model of the NerDisambiguator. Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs), mentions, or surface forms. Input Annotator Types: CHUNK, SENTENCE_EMBEDDINGS Output Annotator Type: DISAMBIGUATION Python API: NerDisambiguatorModel Scala API: NerDisambiguatorModel Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs), mentions, or surface forms. The model needs extracted CHUNKS and SENTENCE_EMBEDDINGS type input from e.g. SentenceEmbeddings and NerConverter. Input Annotator Types: CHUNK, SENTENCE_EMBEDDINGS Output Annotator Type: DISAMBIGUATION Python API: NerDisambiguator Scala API: NerDisambiguator Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. data = spark.createDataFrame([[&quot;The show also had a contestant named Donald Trump who later defeated Christina Aguilera ...&quot;]]) .toDF(&quot;text&quot;) documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) sentence_embeddings = nlp.SentenceEmbeddings() .setInputCols([&quot;sentence&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) ner_model = nlp.NerDLModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;PER&quot;]) # Then the extracted entities can be disambiguated. disambiguator = medical.NerDisambiguator() .setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator]) model = nlpPipeline.fit(data) result = model.transform(data) # Show results result.selectExpr(&quot;explode(disambiguation)&quot;) .selectExpr(&quot;col.metadata.chunk as chunk&quot;, &quot;col.result as result&quot;).show(5, False) +++ |chunk |result | +++ |Donald Trump |http:#en.wikipedia.org/?curid=4848272, http:#en.wikipedia.org/?curid=31698421, http:#en.wikipedia.org/?curid=55907961 | |Christina Aguilera|http:#en.wikipedia.org/?curid=144171, http:#en.wikipedia.org/?curid=6636454 | +++ from johnsnowlabs import * # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) sentence_embeddings = nlp.SentenceEmbeddings() .setInputCols([&quot;sentence&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;PER&quot;]) # Then the extracted entities can be disambiguated. disambiguator = finance.NerDisambiguator() #.setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator]) from johnsnowlabs import * # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) sentence_embeddings = nlp.SentenceEmbeddings() .setInputCols([&quot;sentence&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;PER&quot;]) # Then the extracted entities can be disambiguated. disambiguator = legal.NerDisambiguator() #.setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator]) MedicalFinanceLegal from johnsnowlabs import * // Extracting Person identities // First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. val data = Seq(&quot;The show also had a contestant named Donald Trump who later defeated Christina Aguilera ...&quot;) .toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val sentence_embeddings = new nlp.SentenceEmbeddings() .setInputCols(Array(&quot;sentence&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;sentence_embeddings&quot;) val ner_model = nlp.NerDLModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(&quot;PER&quot;) // Then the extracted entities can be disambiguated. val disambiguator = new medical.NerDisambiguator() .setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator)) val model = nlpPipeline.fit(data) val result = model.transform(data) // Show results // // result.selectExpr(&quot;explode(disambiguation)&quot;) // .selectExpr(&quot;col.metadata.chunk as chunk&quot;, &quot;col.result as result&quot;).show(5, false) // +++ // |chunk |result | // +++ // |Donald Trump |https://en.wikipedia.org/?curid=4848272, https://en.wikipedia.org/?curid=31698421, https://en.wikipedia.org/?curid=55907961| // |Christina Aguilera|https://en.wikipedia.org/?curid=144171, https://en.wikipedia.org/?curid=6636454 | // +++ // from johnsnowlabs import * // Extracting Person identities // First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. val data = Seq(&quot;The show also had a contestant named Donald Trump who later defeated Christina Aguilera ...&quot;) .toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val sentence_embeddings = new nlp.SentenceEmbeddings() .setInputCols(Array(&quot;sentence&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;sentence_embeddings&quot;) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(&quot;PER&quot;) // Then the extracted entities can be disambiguated. val disambiguator = new finance.NerDisambiguator() #.setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator)) from johnsnowlabs import * // Extracting Person identities // First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. val data = Seq(&quot;The show also had a contestant named Donald Trump who later defeated Christina Aguilera ...&quot;) .toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val sentence_embeddings = new nlp.SentenceEmbeddings() .setInputCols(Array(&quot;sentence&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;sentence_embeddings&quot;) val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(&quot;PER&quot;) // Then the extracted entities can be disambiguated. val disambiguator = new legal.NerDisambiguator() #.setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator)) NerModel ModelApproach This Named Entity recognition annotator is a generic NER model based on Neural Networks. Pretrained models can be loaded with pretrained of the companion object: val nerModel = nlp.NerDLModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) The default model is &quot;ner_clinical&quot;, if no name is provided. For available pretrained models please see the Models Hub. Additionally, pretrained pipelines are available for this module, see Pipelines. Note that some pretrained models require specific types of embeddings, depending on which they were trained on. For example, the default model &quot;ner_dl&quot; requires the WordEmbeddings &quot;ner_clinical&quot;. For extended examples of usage, see the Spark NLP Workshop (sections starting with Training a Clinical NER) Input Annotator Types: DOCUMENT, TOKEN, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: MedicalNerModel Scala API: MedicalNerModel Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) jsl_ner = medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;jsl_ner&quot;) jsl_ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;]) .setOutputCol(&quot;jsl_ner_chunk&quot;) jsl_ner_pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, jsl_ner, jsl_ner_converter]) result = jsl_ner_pipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_headers&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter]) result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_headers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter]) result = nlpPipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val jsl_ner = medical.NerModel .pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;jsl_ner&quot;) val jsl_ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;)) .setOutputCol(&quot;jsl_ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, jsl_ner, jsl_ner_converter )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings .pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = finance.NerModel .pretrained(&quot;finner_headers&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings .pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = legal.NerModel .pretrained(&quot;legner_headers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter )) val result = pipeline.fit(data).transform(data) This Named Entity recognition annotator allows to train generic NER model based on Neural Networks. The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets. For instantiated/pretrained models, see NerDLModel. The training data should be a labeled Spark Dataset, in the format of CoNLL 2003 IOB with Annotation type columns. The data should have columns of type DOCUMENT, TOKEN, WORD_EMBEDDINGS and an additional label column of annotator type NAMED_ENTITY. Excluding the label, this can be done with for example a SentenceDetector, a Tokenizer and a WordEmbeddingsModel with clinical embeddings (any clinical word embeddings can be chosen). For extended examples of usage, see the Spark NLP Workshop (sections starting with Training a Clinical NER) Input Annotator Types: DOCUMENT, TOKEN, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: MedicalNerApproach Scala API: MedicalNerApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # First extract the prerequisites for the NerDLApproach documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) clinical_embeddings = nlp.WordEmbeddingsModel.pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Then the training can start nerTagger = medical.NerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(2) .setBatchSize(64) .setRandomSeed(0) .setVerbose(1) .setValidationSplit(0.2) .setEvaluationLogExtended(True) .setEnableOutputLogs(True) .setIncludeConfidence(True) .setOutputLogsPath(&#39;ner_logs&#39;) .setGraphFolder(&#39;medical_ner_graphs&#39;) .setEnableMemoryOptimizer(True) #&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, clinical_embeddings, nerTagger ]) # We use the text and labels from the CoNLL dataset conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) from johnsnowlabs import * # First extract the prerequisites for the NerDLApproach documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) clinical_embeddings = nlp.WordEmbeddingsModel.pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Then the training can start nerTagger = finance.NerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(2) .setBatchSize(64) .setRandomSeed(0) .setVerbose(1) .setValidationSplit(0.2) .setEvaluationLogExtended(True) .setEnableOutputLogs(True) .setIncludeConfidence(True) .setOutputLogsPath(&#39;ner_logs&#39;) .setGraphFolder(&#39;medical_ner_graphs&#39;) .setEnableMemoryOptimizer(True) #&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, clinical_embeddings, nerTagger ]) from johnsnowlabs import * # First extract the prerequisites for the NerDLApproach documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) clinical_embeddings = nlp.WordEmbeddingsModel.pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Then the training can start nerTagger = legal.NerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(2) .setBatchSize(64) .setRandomSeed(0) .setVerbose(1) .setValidationSplit(0.2) .setEvaluationLogExtended(True) .setEnableOutputLogs(True) .setIncludeConfidence(True) .setOutputLogsPath(&#39;ner_logs&#39;) .setGraphFolder(&#39;medical_ner_graphs&#39;) .setEnableMemoryOptimizer(True) #&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, clinical_embeddings, nerTagger ]) MedicalFinanceLegal from johnsnowlabs import * // First extract the prerequisites for the NerDLApproach val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new medical.NerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) // We use the text and labels from the CoNLL dataset val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) from johnsnowlabs import * // First extract the prerequisites for the NerDLApproach val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new finance.NerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) from johnsnowlabs import * // First extract the prerequisites for the NerDLApproach val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new legal.NerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) QuestionAnswering Model QuestionAnswering is a GPT-based model for answering questions given a context. Unlike span-based models, it generates the answers to the questions, rather than selecting phrases from the given context. The model is capable of answering various types of questions, including yes-no or full-text ones. Types of questions are supported: &quot;short&quot; (producing yes/no/maybe) answers and &quot;long&quot; (full answers). Available models can be found at the Models Hub. For more extended examples on the document, pre-processing see the Spark NLP Workshop. Input Annotator Types: DOCUMENT, DOCUMENT Output Annotator Type: CHUNK Python API: MedicalQuestionAnswering Scala API: MedicalQuestionAnswering Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * document_assembler = nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) med_qa = medical.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; pipeline = nlp.Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; data = spark.createDataFrame( [ [long_question, paper_abstract, &quot;long&quot;], [yes_no_question, paper_abstract, &quot;short&quot;], ] ).toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;long&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;short&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) from johnsnowlabs import * document_assembler = nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) med_qa = finance.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; pipeline = nlp.Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; data = spark.createDataFrame( [ [long_question, paper_abstract, &quot;long&quot;], [yes_no_question, paper_abstract, &quot;short&quot;], ] ).toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;long&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;short&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) from johnsnowlabs import * document_assembler = nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) med_qa = legal.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; pipeline = nlp.Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; data = spark.createDataFrame( [ [long_question, paper_abstract, &quot;long&quot;], [yes_no_question, paper_abstract, &quot;short&quot;], ] ).toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;long&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;short&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) MedicalFinanceLegal from johnsnowlabs import * val document_assembler = new nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) val med_qa = medical.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_qa)) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; val data = Seq( (long_question, paper_abstract, &quot;long&quot; ), (yes_no_question, paper_abstract, &quot;short&quot;)) .toDS.toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) val med_qa = finance.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_qa)) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; val data = Seq( (long_question, paper_abstract, &quot;long&quot; ), (yes_no_question, paper_abstract, &quot;short&quot;)) .toDS.toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) val med_qa = legal.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_qa)) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; val data = Seq( (long_question, paper_abstract, &quot;long&quot; ), (yes_no_question, paper_abstract, &quot;short&quot;)) .toDS.toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) val result = pipeline.fit(data).transform(data) RENerChunksFilter Model Filters entities’ dependency relations. The annotator filters desired relation pairs (defined by the parameter realtionPairs), and store those on the output column. Filtering the possible relations can be useful to perform additional analysis for a specific use case (e.g., checking adverse drug reactions and drug realations), which can be the input for further analysis using a pretrained RelationExtractionDLModel. For example, the ner_clinical NER model can identify PROBLEM, TEST, and TREATMENT entities. By using the RENerChunksFilter, one can filter only the relations between PROBLEM and TREATMENT entities only, removing any relation between the other entities, to further analyze the associations between clinical problems and treatments. Input Annotator Types: CHUNK, DEPENDENCY Output Annotator Type: CHUNK Python API: RENerChunksFilter Scala API: RENerChunksFilter Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define pipeline stages to extract entities documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) clinical_ner_tagger = medical.NerModel.pretrained(&quot;jsl_ner_wip_greedy_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ner_chunker = nlp.NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;]) .setOutputCol(&quot;ner_chunks&quot;) # Define the relation pairs and the filter relationPairs = [ &quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot; ] re_ner_chunk_filter = medical.RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;internal_organ_or_component-direction&quot;]) trained_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_ner_chunk_filter ]) data = spark.createDataFrame([[&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;]]).toDF(&quot;text&quot;) result = trained_pipeline.fit(data).transform(data) # Show results result.selectExpr(&quot;explode(re_ner_chunks) as re_chunks&quot;) .selectExpr(&quot;re_chunks.begin&quot;, &quot;re_chunks.result&quot;, &quot;re_chunks.metadata.entity&quot;, &quot;re_chunks.metadata.paired_to&quot;) .show(6, truncate=False) +--+-+++ |begin|result |entity |paired_to| +--+-+++ |35 |upper |Direction |41 | |41 |brain stem |Internal_organ_or_component|35 | |35 |upper |Direction |59 | |59 |cerebellum |Internal_organ_or_component|35 | |35 |upper |Direction |81 | |81 |basil ganglia|Internal_organ_or_component|35 | +--+-+++ from johnsnowlabs import * # Define pipeline stages to extract entities documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_chunker = nlp.NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunks&quot;) # Define the relation pairs and the filter relationPairs = [ &quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot; ] re_ner_chunk_filter = finance.RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;internal_organ_or_component-direction&quot;]) trained_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, dependency_parser, ner_model, ner_chunker, re_ner_chunk_filter ]) from johnsnowlabs import * # Define pipeline stages to extract entities documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embedding&quot;]) .setOutputCol(&quot;ner&quot;) ner_chunker = nlp.NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunks&quot;) # Define the relation pairs and the filter relationPairs = [ &quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot; ] re_ner_chunk_filter = legal.RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;internal_organ_or_component-direction&quot;]) trained_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, dependency_parser, ner_model, ner_chunker, re_ner_chunk_filter ]) MedicalFinanceLegal from johnsnowlabs import * // Define pipeline stages to extract entities val documenter = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentencer = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) val words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;pos_tags&quot;) val dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val clinical_ner_tagger = medical.NerModel.pretrained(&quot;jsl_ner_wip_greedy_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_tags&quot;) val ner_chunker = new nlp.NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;)) .setOutputCol(&quot;ner_chunks&quot;) // Define the relation pairs and the filter val relationPairs = Array(&quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot;) val re_ner_chunk_filter = new medical.RENerChunksFilter() .setInputCols(Array(&quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs(Array(&quot;internal_organ_or_component-direction&quot;)) val trained_pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_ner_chunk_filter )) val data = Seq(&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;).toDF(&quot;text&quot;) val result = trained_pipeline.fit(data).transform(data) // Show results // // result.selectExpr(&quot;explode(re_ner_chunks) as re_chunks&quot;) // .selectExpr(&quot;re_chunks.begin&quot;, &quot;re_chunks.result&quot;, &quot;re_chunks.metadata.entity&quot;, &quot;re_chunks.metadata.paired_to&quot;) // .show(6, truncate=false) // +--+-+++ // |begin|result |entity |paired_to| // +--+-+++ // |35 |upper |Direction |41 | // |41 |brain stem |Internal_organ_or_component|35 | // |35 |upper |Direction |59 | // |59 |cerebellum |Internal_organ_or_component|35 | // |35 |upper |Direction |81 | // |81 |basil ganglia|Internal_organ_or_component|35 | // +--+-+++ // from johnsnowlabs import * // Define pipeline stages to extract entities val documenter = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentencer = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) val words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;pos_tags&quot;) val dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_chunker = new nlp.NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunks&quot;) // Define the relation pairs and the filter val relationPairs = Array(&quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot;) val re_ner_chunk_filter = new finance.RENerChunksFilter() .setInputCols(Array(&quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs(Array(&quot;internal_organ_or_component-direction&quot;)) val trained_pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, dependency_parser, ner_model, ner_chunker, re_ner_chunk_filter )) from johnsnowlabs import * // Define pipeline stages to extract entities val documenter = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentencer = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) val words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;pos_tags&quot;) val dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embedding&quot;)) .setOutputCol(&quot;ner&quot;) val ner_chunker = new nlp.NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunks&quot;) // Define the relation pairs and the filter val relationPairs = Array(&quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot;) val re_ner_chunk_filter = new legal.RENerChunksFilter() .setInputCols(Array(&quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs(Array(&quot;internal_organ_or_component-direction&quot;)) val trained_pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, dependency_parser, ner_model, ner_chunker, re_ner_chunk_filter )) ReIdentification Model Reidentifies obfuscated entities by DeIdentification. This annotator requires the outputs from the deidentification as input. Input columns need to be the deidentified document and the deidentification mappings set with DeIdentification.setMappingsColumn. To see how the entities are deidentified, please refer to the example of that class. Input Annotator Types: DOCUMENT,CHUNK Output Annotator Type: DOCUMENT Python API: ReIdentification Scala API: ReIdentification Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define the reidentification stage and transform the deidentified documents reideintification = medical.ReIdentification() .setInputCols([&quot;dei&quot;, &quot;protectedEntities&quot;]) .setOutputCol(&quot;reid&quot;) .transform(result) # Show results result.select(&quot;dei.result&quot;).show(truncate = False) +--+ |result | +--+ |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]| +--+ reideintification.selectExpr(&quot;explode(reid.result)&quot;).show(truncate=False) +--+ |col | +--+ |# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.| +--+ from johnsnowlabs import * # Define the reidentification stage and transform the deidentified documents reideintification = finance.ReIdentification() .setInputCols([&quot;aux&quot;, &quot;deidentified&quot;]) .setOutputCol(&quot;original&quot;) .transform(result) from johnsnowlabs import * # Define the reidentification stage and transform the deidentified documents reideintification = legal.ReIdentification() .setInputCols([&quot;aux&quot;, &quot;deidentified&quot;]) .setOutputCol(&quot;original&quot;) .transform(result) MedicalFinanceLegal from johnsnowlabs import * // Define the reidentification stage and transform the deidentified documents val reideintification = new medical.ReIdentification() .setInputCols(Array(&quot;dei&quot;, &quot;protectedEntities&quot;)) .setOutputCol(&quot;reid&quot;) .transform(result) // Show results // // result.select(&quot;dei.result&quot;).show(truncate = false) // +--+ // |result | // +--+ // |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]| // +--+ // reideintification.selectExpr(&quot;explode(reid.result)&quot;).show(false) // +--+ // |col | // +--+ // |# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.| // +--+ // from johnsnowlabs import * // Define the reidentification stage and transform the deidentified documents val reideintification = new finance.ReIdentification() .setInputCols(Array(&quot;aux&quot;, &quot;deidentified&quot;)) .setOutputCol(&quot;original&quot;) .transform(result) from johnsnowlabs import * // Define the reidentification stage and transform the deidentified documents val reideintification = new legal.ReIdentification() .setInputCols(Array(&quot;aux&quot;, &quot;deidentified&quot;)) .setOutputCol(&quot;original&quot;) .transform(result) RelationExtraction ModelApproach Extracts and classifies instances of relations between named entities. For pretrained models please see the Models Hub for available models. Input Annotator Types: WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY Output Annotator Type: CATEGORY Python API: RelationExtractionModel Scala API: RelationExtractionModel Show Example PythonScala Medical from johnsnowlabs import * # Relation Extraction between body parts # Define pipeline stages to extract entities documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) clinical_ner_tagger = medical.NerModel.pretrained(&quot;jsl_ner_wip_greedy_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ner_chunker = nlp.NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;]) .setOutputCol(&quot;ner_chunks&quot;) # Define the relations that are to be extracted relationPairs = [ &quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot; ] re_model = medical.RelationExtractionModel.pretrained(&quot;re_bodypart_directions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationPairs(relationPairs) .setMaxSyntacticDistance(4) .setPredictionThreshold(0.9) pipeline = Pipeline().setStages([ documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_model ]) data = spark.createDataFrame([[&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) # Show results # result.selectExpr(&quot;explode(relations) as relations&quot;) .select( &quot;relations.metadata.chunk1&quot;, &quot;relations.metadata.entity1&quot;, &quot;relations.metadata.chunk2&quot;, &quot;relations.metadata.entity2&quot;, &quot;relations.result&quot; ) .where(&quot;result != 0&quot;) .show(truncate=False) # Show results result.selectExpr(&quot;explode(relations) as relations&quot;) .select( &quot;relations.metadata.chunk1&quot;, &quot;relations.metadata.entity1&quot;, &quot;relations.metadata.chunk2&quot;, &quot;relations.metadata.entity2&quot;, &quot;relations.result&quot; ).where(&quot;result != 0&quot;) .show(truncate=False) +++-+++ |chunk1|entity1 |chunk2 |entity2 |result| +++-+++ |upper |Direction|brain stem |Internal_organ_or_component|1 | |left |Direction|cerebellum |Internal_organ_or_component|1 | |right |Direction|basil ganglia|Internal_organ_or_component|1 | +++-+++ Medical from johnsnowlabs import * // Relation Extraction between body parts // Define pipeline stages to extract entities val documenter = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentencer = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) val words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;pos_tags&quot;) val dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val clinical_ner_tagger = medical.NerModel.pretrained(&quot;jsl_ner_wip_greedy_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_tags&quot;) val ner_chunker = new nlp.NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;)) .setOutputCol(&quot;ner_chunks&quot;) // Define the relations that are to be extracted val relationPairs = Array(&quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot;) val re_model = medical.RelationExtractionModel.pretrained(&quot;re_bodypart_directions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;relations&quot;) .setRelationPairs(relationPairs) .setMaxSyntacticDistance(4) .setPredictionThreshold(0.9f) val pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_model )) val data = Seq(&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) // Show results // // result.selectExpr(&quot;explode(relations) as relations&quot;) // .select( // &quot;relations.metadata.chunk1&quot;, // &quot;relations.metadata.entity1&quot;, // &quot;relations.metadata.chunk2&quot;, // &quot;relations.metadata.entity2&quot;, // &quot;relations.result&quot; // ) // .where(&quot;result != 0&quot;) // .show(truncate=false) // +++-+++ // |chunk1|entity1 |chunk2 |entity2 |result| // +++-+++ // |upper |Direction|brain stem |Internal_organ_or_component|1 | // |left |Direction|cerebellum |Internal_organ_or_component|1 | // |right |Direction|basil ganglia|Internal_organ_or_component|1 | // +++-+++ // Trains a TensorFlow model for relation extraction. To train a custom relation extraction model, you need to first creat a Tensorflow graph using either the TfGraphBuilder annotator or the tf_graph module. Then, set the path to the Tensorflow graph using the method .setModelFile(&quot;path/to/tensorflow_graph.pb&quot;). If the parameter relationDirectionCol is set, the model will be trained using the direction information (see the parameter decription for details). Otherwise, the model won’t have direction between the relation of the entities. After training a model (using the .fit() method), the resulting object is of class RelationExtractionModel. Input Annotator Types: WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY Output Annotator Type: NONE Python API: RelationExtractionApproach Scala API: RelationExtractionApproach Show Example PythonScala Medical from johnsnowlabs import * # Defining pipeline stages to extract entities first documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;tokens&quot;) embedder = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) posTagger = nlp.PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;posTags&quot;) nerTagger = nlp.MedicalNerModel .pretrained(&quot;ner_events_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) nerConverter = nlp.NerConverter() .setInputCols([&quot;document&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;]) .setOutputCol(&quot;nerChunks&quot;) depencyParser = nlp.DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;document&quot;, &quot;posTags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) # Then define `RelationExtractionApproach` and training parameters re = medical.RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;posTags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations_t&quot;) .setLabelColumn(&quot;target_rel&quot;) .setEpochsNumber(300) .setBatchSize(200) .setLearningRate(0.001) .setModelFile(&quot;path/to/graph_file.pb&quot;) .setFixImbalance(True) .setValidationSplit(0.05) .setFromEntity(&quot;from_begin&quot;, &quot;from_end&quot;, &quot;from_label&quot;) .setToEntity(&quot;to_begin&quot;, &quot;to_end&quot;, &quot;to_label&quot;) finisher = nlp.Finisher() .setInputCols([&quot;relations_t&quot;]) .setOutputCols([&quot;relations&quot;]) .setCleanAnnotations(False) .setValueSplitSymbol(&quot;,&quot;) .setAnnotationSplitSymbol(&quot;,&quot;) .setOutputAsArray(False) # Define complete pipeline and start training pipeline = Pipeline(stages=[ documentAssembler, tokenizer, embedder, posTagger, nerTagger, nerConverter, depencyParser, re, finisher]) model = pipeline.fit(trainData) Medical from johnsnowlabs import * // Defining pipeline stages to extract entities first val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val embedder = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val posTagger = nlp.PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;posTags&quot;) val nerTagger = medical.NerModel .pretrained(&quot;ner_events_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_tags&quot;) val nerConverter = new nlp.NerConverter() .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;)) .setOutputCol(&quot;nerChunks&quot;) val depencyParser = nlp.DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;posTags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) // Then define `RelationExtractionApproach` and training parameters val re = new medical.RelationExtractionApproach() .setInputCols(Array(&quot;embeddings&quot;, &quot;posTags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;relations_t&quot;) .setLabelColumn(&quot;target_rel&quot;) .setEpochsNumber(300) .setBatchSize(200) .setlearningRate(0.001f) .setModelFile(&quot;path/to/graph_file.pb&quot;) .setFixImbalance(true) .setValidationSplit(0.05f) .setFromEntity(&quot;from_begin&quot;, &quot;from_end&quot;, &quot;from_label&quot;) .setToEntity(&quot;to_begin&quot;, &quot;to_end&quot;, &quot;to_label&quot;) val finisher = new nlp.Finisher() .setInputCols(Array(&quot;relations_t&quot;)) .setOutputCols(Array(&quot;relations&quot;)) .setCleanAnnotations(false) .setValueSplitSymbol(&quot;,&quot;) .setAnnotationSplitSymbol(&quot;,&quot;) .setOutputAsArray(false) // Define complete pipeline and start training val pipeline = new Pipeline() .setStages(Array( documentAssembler, tokenizer, embedder, posTagger, nerTagger, nerConverter, depencyParser, re, finisher)) val model = pipeline.fit(trainData) RelationExtractionDL Model Extracts and classifies instances of relations between named entities. In contrast with RelationExtractionModel, RelationExtractionDLModel is based on BERT. For pretrained models please see the Models Hub for available models. Input Annotator Types: CHUNK, DOCUMENT Output Annotator Type: CATEGORY Python API: RelationExtractionDLModel Scala API: RelationExtractionDLModel Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Relation Extraction between body parts # This is a continuation of the RENerChunksFilter example. See that class on how to extract the relation chunks. # Define the extraction model re_ner_chunk_filter = medical.RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;internal_organ_or_component-direction&quot;]) re_model = medical.RelationExtractionDLModel.pretrained(&quot;redl_bodypart_direction_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setPredictionThreshold(0.5) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) trained_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_ner_chunk_filter, re_model ]) data = spark.createDataFrame([[&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;]]).toDF(&quot;text&quot;) result = trained_pipeline.fit(data).transform(data) # Show results result.selectExpr(&quot;explode(relations) as relations&quot;) .select( &quot;relations.metadata.chunk1&quot;, &quot;relations.metadata.entity1&quot;, &quot;relations.metadata.chunk2&quot;, &quot;relations.metadata.entity2&quot;, &quot;relations.result&quot; ) .where(&quot;result != 0&quot;) .show(truncate=False) +++-+++ |chunk1|entity1 |chunk2 |entity2 |result| +++-+++ |upper |Direction|brain stem |Internal_organ_or_component|1 | |left |Direction|cerebellum |Internal_organ_or_component|1 | |right |Direction|basil ganglia|Internal_organ_or_component|1 | +++-+++ from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_org&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner_org&quot;]) .setOutputCol(&quot;ner_chunk_org&quot;) token_classifier = nlp.DeBertaForTokenClassification.pretrained(&quot;deberta_v3_base_token_classifier_ontonotes&quot;, &quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;ner_date&quot;) .setCaseSensitive(True) .setMaxSentenceLength(512) ner_converter_date = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner_date&quot;]) .setOutputCol(&quot;ner_chunk_date&quot;) .setWhiteList([&quot;DATE&quot;]) chunk_merger = finance.ChunkMergeApproach() .setInputCols(&quot;ner_chunk_org&quot;, &quot;ner_chunk_date&quot;) .setOutputCol(&#39;ner_chunk&#39;) re_model = finance.RelationExtractionDLModel.pretrained(&quot;finre_acquisitions_subsidiaries&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setPredictionThreshold(0.3) .setInputCols([&quot;ner_chunk&quot;, &quot;document&quot;]) .setOutputCol(&quot;relations&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, token_classifier, ner_converter_date, chunk_merger, re_model ]) result = pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setMaxSentenceLength(512) ner_model = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) re_model = legal.RelationExtractionDLModel.pretrained(&quot;legre_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setPredictionThreshold(0.5) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;relations&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, re_model ]) result = pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * // Relation Extraction between body parts // This is a continuation of the [[RENerChunksFilter]] example. See that class on how to extract the relation chunks. // Define the extraction model val re_ner_chunk_filter = new medical.RENerChunksFilter() .setInputCols(&quot;ner_chunks&quot;, &quot;dependencies&quot;) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs(Array(&quot;internal_organ_or_component-direction&quot;)) val re_model = medical.RelationExtractionDLModel.pretrained(&quot;redl_bodypart_direction_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setPredictionThreshold(0.5f) .setInputCols(&quot;re_ner_chunks&quot;, &quot;sentences&quot;) .setOutputCol(&quot;relations&quot;) val trained_pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_ner_chunk_filter, re_model )) val data = Seq(&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;).toDF(&quot;text&quot;) val result = trained_pipeline.fit(data).transform(data) // Show results // // result.selectExpr(&quot;explode(relations) as relations&quot;) // .select( // &quot;relations.metadata.chunk1&quot;, // &quot;relations.metadata.entity1&quot;, // &quot;relations.metadata.chunk2&quot;, // &quot;relations.metadata.entity2&quot;, // &quot;relations.result&quot; // ) // .where(&quot;result != 0&quot;) // .show(truncate=false) // +++-+++ // |chunk1|entity1 |chunk2 |entity2 |result| // +++-+++ // |upper |Direction|brain stem |Internal_organ_or_component|1 | // |left |Direction|cerebellum |Internal_organ_or_component|1 | // |right |Direction|basil ganglia|Internal_organ_or_component|1 | // +++-+++ // from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings .pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = finance.NerModel .pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner_org&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_org&quot;)) .setOutputCol(&quot;ner_chunk_org&quot;) val token_classifier = nlp.DeBertaForTokenClassification .pretrained(&quot;deberta_v3_base_token_classifier_ontonotes&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;ner_date&quot;) .setCaseSensitive(True) .setMaxSentenceLength(512) val ner_converter_date = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_date&quot;)) .setOutputCol(&quot;ner_chunk_date&quot;) .setWhiteList(Array(&quot;DATE&quot;)) val chunk_merger = new finance.ChunkMergeApproach() .setInputCols(&quot;ner_chunk_org&quot;, &quot;ner_chunk_date&quot;) .setOutputCol(&#39;ner_chunk&#39;) val re_model = finance.RelationExtractionDLModel .pretrained(&quot;finre_acquisitions_subsidiaries&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setPredictionThreshold(0.3) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;document&quot;)) .setOutputCol(&quot;relations&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, token_classifier, ner_converter_date, chunk_merger, re_model )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings .pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setMaxSentenceLength(512) val ner_model = legal.NerModel .pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val re_model = legal.RelationExtractionDLModel .pretrained(&quot;legre_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setPredictionThreshold(0.5) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;relations&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, re_model )) val result = pipeline.fit(data).transform(data) SentenceEntityResolver ModelApproach The model transforms a dataset with Input Annotation type SENTENCE_EMBEDDINGS, coming from e.g. BertSentenceEmbeddings and returns the normalized entity for a particular trained ontology / curated dataset (e.g. ICD-10, RxNorm, SNOMED etc.). For a list of pretrained models, please see the Models Hub. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: ENTITY Python API: SentenceEntityResolverModel Scala API: SentenceEntityResolverModel Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Resolving CPT # First define pipeline stages to extract entities documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) clinical_ner = medical.NerModel.pretrained(&quot;jsl_ner_wip_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;Test&quot;,&quot;Procedure&quot;]) c2doc = nlp.Chunk2Doc() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = nlp.BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) # Then the resolver is defined on the extracted entities and sentence embeddings cpt_resolver = medical.SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_cpt_procedures_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;cpt_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) sbert_pipeline_cpt = Pipeline().setStages([ documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, c2doc, sbert_embedder, cpt_resolver]) sbert_outputs = sbert_pipeline_cpt.fit(data_ner).transform(data) # Show results # # sbert_outputs # .select(&quot;explode(arrays_zip(ner_chunk.result ,ner_chunk.metadata, cpt_code.result, cpt_code.metadata, ner_chunk.begin, ner_chunk.end)) as cpt_code&quot;) # .selectExpr( # &quot;cpt_code[&#39;0&#39;] as chunk&quot;, # &quot;cpt_code[&#39;1&#39;].entity as entity&quot;, # &quot;cpt_code[&#39;2&#39;] as code&quot;, # &quot;cpt_code[&#39;3&#39;].confidence as confidence&quot;, # &quot;cpt_code[&#39;3&#39;].all_k_resolutions as all_k_resolutions&quot;, # &quot;cpt_code[&#39;3&#39;].all_k_results as all_k_results&quot; # ).show(5) # +--++--+-+--+--+ # | chunk| entity| code|confidence| all_k_resolutions| all_k_codes| # +--++--+-+--+--+ # | heart cath|Procedure|93566| 0.1180|CCA - Cardiac cat...|93566:::62319:::9...| # |selective coronar...| Test|93460| 0.1000|Coronary angiogra...|93460:::93458:::9...| # |common femoral an...| Test|35884| 0.1808|Femoral artery by...|35884:::35883:::3...| # | StarClose closure|Procedure|33305| 0.1197|Heart closure:::H...|33305:::33300:::3...| # | stress test| Test|93351| 0.2795|Cardiovascular st...|93351:::94621:::9...| # +--++--+-+--+--+ # from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) chunk2doc = nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) sentence_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_edgar_company_name&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;text&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, chunk2doc, sentence_embeddings, resolver ]) result = pipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) chunk2doc = nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) sentence_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) resolver = legal.SentenceEntityResolverModel.pretrained(&quot;legel_edgar_company_name&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;text&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, chunk2doc, sentence_embeddings, resolver ]) result = pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * // Resolving CPT // First define pipeline stages to extract entities val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val clinical_ner = medical.NerModel.pretrained(&quot;jsl_ner_wip_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(&quot;Test&quot;,&quot;Procedure&quot;) val c2doc = new nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) val sbert_embedder = nlp.BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sbert_embeddings&quot;) // Then the resolver is defined on the extracted entities and sentence embeddings val cpt_resolver = medical.SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_cpt_procedures_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sbert_embeddings&quot;)) .setOutputCol(&quot;cpt_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) val sbert_pipeline_cpt = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, c2doc, sbert_embedder, cpt_resolver)) // Show results // // sbert_outputs // .select(&quot;explode(arrays_zip(ner_chunk.result ,ner_chunk.metadata, cpt_code.result, cpt_code.metadata, ner_chunk.begin, ner_chunk.end)) as cpt_code&quot;) // .selectExpr( // &quot;cpt_code[&#39;0&#39;] as chunk&quot;, // &quot;cpt_code[&#39;1&#39;].entity as entity&quot;, // &quot;cpt_code[&#39;2&#39;] as code&quot;, // &quot;cpt_code[&#39;3&#39;].confidence as confidence&quot;, // &quot;cpt_code[&#39;3&#39;].all_k_resolutions as all_k_resolutions&quot;, // &quot;cpt_code[&#39;3&#39;].all_k_results as all_k_results&quot; // ).show(5) // +--++--+-+--+--+ // | chunk| entity| code|confidence| all_k_resolutions| all_k_codes| // +--++--+-+--+--+ // | heart cath|Procedure|93566| 0.1180|CCA - Cardiac cat...|93566:::62319:::9...| // |selective coronar...| Test|93460| 0.1000|Coronary angiogra...|93460:::93458:::9...| // |common femoral an...| Test|35884| 0.1808|Femoral artery by...|35884:::35883:::3...| // | StarClose closure|Procedure|33305| 0.1197|Heart closure:::H...|33305:::33300:::3...| // | stress test| Test|93351| 0.2795|Cardiovascular st...|93351:::94621:::9...| // +--++--+-+--+--+ // from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings .pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = finance.NerModel .pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val chunk2doc = new nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) val sentence_embeddings = nlp.UniversalSentenceEncoder .pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val resolver = finance.SentenceEntityResolverModel .pretrained(&quot;finel_edgar_company_name&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;text&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, chunk2doc, sentence_embeddings, resolver )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings .pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = legal.NerModel .pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val chunk2doc = new nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) val sentence_embeddings = nlp.UniversalSentenceEncoder .pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val resolver = legal.SentenceEntityResolverModel .pretrained(&quot;legel_edgar_company_name&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;text&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, chunk2doc, sentence_embeddings, resolver )) val result = pipeline.fit(data).transform(data) Trains a SentenceEntityResolverModel that maps sentence embeddings to entities in a knowledge base. To train a custom model, you need to provide a dataset with the following columns: label: Entity name chunk: Occurrence of the entity in the text, without standartization sentence_embeddings: Sentence embeddings from, e.g., the BertSentenceEmbeddings annotator. Optionally, you can also provide the following columns: aux_label: Auxiliary label which maps resolved entities to additional labels. If you have ground truth of the knowledge base entities, setting this column will help the model to learn better. You can find pretrained Sentence Embeddings (using BERT or other architecgture) in the NLP Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;_. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: ENTITY Python API: SentenceEntityResolverApproach Scala API: SentenceEntityResolverApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import nlp, medical # Training a SNOMED resolution model using BERT sentence embeddings # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) snomedTrainingPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, bertEmbeddings ]) snomedTrainingModel = snomedTrainingPipeline.fit(data) snomedData = snomedTrainingModel.transform(data).cache() # Then the Resolver can be trained with bertExtractor = medical.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols([&quot;bert_embeddings&quot;]) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(False) snomedModel = bertExtractor.fit(snomedData) from johnsnowlabs import nlp, finance # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_large_cased&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) preprocessing_pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, bertEmbeddings ]) preprocessing_model = preprocessing_pipeline.fit(data) processed_data = preprocessing_model.transform(data).cache() # Then the Resolver can be trained with bertExtractor = finance.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols([&quot;bert_embeddings&quot;]) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(False) model = bertExtractor.fit(processed_data) from johnsnowlabs import nlp, legal # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_uncased_legal&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) preprocessing_pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, bertEmbeddings ]) data_preprocessing_model = preprocessing_pipeline.fit(data) processed_data = data_preprocessing_model.transform(data).cache() # Then the Resolver can be trained with bertExtractor = legal.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols([&quot;bert_embeddings&quot;]) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(False) model = bertExtractor.fit(processed_data) MedicalFinanceLegal from johnsnowlabs import * // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new medical.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData) from johnsnowlabs import * // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new finance.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData) from johnsnowlabs import * // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new legal.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData) Summarizer Model Summarizer annotator that uses a generative deep learning model to create summaries of medical texts given clinical contexts. This annotator helps to quickly summarize complex medical information. Available models can be found at the Models Hub. For more extended examples on document pre-processing see the Spark NLP Workshop Input Annotator Types: DOCUMENT Output Annotator Type: CHUNK Python API: MedicalSummarizer Scala API: MedicalSummarizer Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_summarizer = medical.Summarizer .pretrained(&quot;summarizer_generic_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxTextLength(512) .setMaxNewTokens(512) .setDoSample(True) .setRefineSummary(True) .setRefineSummaryTargetLength(100) .setRefineMaxAttempts(3) .setRefineChunkSize(512) pipeline = nlp.Pipeline(stages=[document_assembler, med_summarizer]) text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_summarizer = finance.Summarizer .pretrained(&quot;summarizer_generic_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(100) .setMaxTextLength(1024) .setDoSample(True) .setRefineSummary(True) .setRefineSummaryTargetLength(100) .setRefineMaxAttempts(3) .setRefineChunkSize(512) pipeline = nlp.Pipeline(stages=[document_assembler, med_summarizer]) text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_summarizer = legal.Summarizer .pretrained(&quot;summarizer_generic_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxTextLength(512) .setMaxNewTokens(512) .setDoSample(True) .setRefineSummary(True) .setRefineSummaryTargetLength(100) .setRefineMaxAttempts(3) .setRefineChunkSize(512) pipeline = nlp.Pipeline(stages=[document_assembler, med_summarizer]) text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_summarizer = medical.Summarizer.pretrained(&quot;summarizer_generic_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxTextLength(512) .setMaxNewTokens(512) .setDoSample(true) .setRefineSummary(true) .setRefineSummaryTargetLength(100) .setRefineMaxAttempts(3) .setRefineChunkSize(512) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_summarizer)) val text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; val data = Seq(text).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_summarizer = finance.Summarizer.pretrained(&quot;summarizer_generic_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxTextLength(512) .setMaxNewTokens(512) .setDoSample(True) .setRefineSummary(True) .setRefineSummaryTargetLength(100) .setRefineMaxAttempts(3) .setRefineChunkSize(512) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_summarizer)) val text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; val data = Seq(text).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_summarizer = legal.Summarizer.pretrained(&quot;summarizer_generic_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxTextLength(512) .setMaxNewTokens(512) .setDoSample(true) .setRefineSummary(true) .setRefineSummaryTargetLength(100) .setRefineMaxAttempts(3) .setRefineChunkSize(512) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_summarizer)) val text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; val data = Seq(text).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) TFGraphBuilder ModelApproach This annotator creates Tensorflow graphs. This class is used to build a TensorFlow graph from a given model name and a set of input columns. For more information and examples of TFGraphBuilder annotator, you can check the Spark NLP Workshop, and in special, the notebook 17.0.Graph_builder_for_DL_models.ipynb. Input Annotator Types: The setInputCols parameter is changing based on the setModelName parameter. Output Annotator Type: There is no output file. The setGraphFile function creates a file with a .pb extension and saves it there. Python API: AssertionChunkConverter Scala API: AssertionChunkConverter Show Example PythonScala Medical graph_folder = &quot;graph/graphs_100d&quot; graph_name = &quot;re_graph&quot; re_graph_builder = medical.TFGraphBuilder() .setModelName(&quot;relation_extraction&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setLabelColumn(&quot;rel&quot;) .setGraphFolder(graph_folder) .setGraphFile(f&quot;{graph_name}.pb&quot;) .setHiddenLayers([300, 200]) .setHiddenAct(&quot;relu&quot;) .setHiddenActL2(True) .setHiddenWeightsL2(False) .setBatchNorm(False) Input Annotator Types: `` Output Annotator Type: `` TextGenerator Model TextGenerator uses the basic BioGPT model to perform various tasks related to medical text abstraction. With this annotator, a user can provide a prompt and context and instruct the system to perform a specific task, such as explaining why a patient may have a particular disease or paraphrasing the context more directly. In addition, this annotator can create a clinical note for a cancer patient using the given keywords or write medical texts based on introductory sentences. The BioGPT model is trained on large volumes of medical data allowing it to identify and extract the most relevant information from the text provided. Available models can be found at the Models Hub. For more extended examples on document pre-processing see the Spark NLP Workshop. Input Annotator Types: DOCUMENT Output Annotator Type: CHUNK Python API: MedicalTextGenerator Scala API: MedicalTextGenerator Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_text_generator = medical.TextGenerator .pretrained(&quot;medical_text_generator&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(True) .setTopK(3) .setRandomSeed(42) pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator ]) data = spark.createDataFrame([ [&quot;Covid 19 is&quot;], [&quot;The most common cause of stomach pain is&quot;] ]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_text_generator = finance.TextGenerator .pretrained(&quot;medical_text_generator&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(True) .setTopK(3) .setRandomSeed(42) pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator ]) data = spark.createDataFrame([ [&quot;Covid 19 is&quot;], [&quot;The most common cause of stomach pain is&quot;] ]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_text_generator = legal.TextGenerator .pretrained(&quot;medical_text_generator&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(True) .setTopK(3) .setRandomSeed(42) pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator ]) data = spark.createDataFrame([ [&quot;Covid 19 is&quot;], [&quot;The most common cause of stomach pain is&quot;] ]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_text_generator = medical.TextGenerator .pretrained(&quot;medical_text_generator&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(true) .setTopK(3) .setRandomSeed(42) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_text_generator )) val data = Seq(Array( &quot;Covid 19 is&quot;, &quot;The most common cause of stomach pain is&quot;)).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_text_generator = finance.TextGenerator .pretrained(&quot;medical_text_generator&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(true) .setTopK(3) .setRandomSeed(42) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_text_generator )) val data = Seq(Array( &quot;Covid 19 is&quot;, &quot;The most common cause of stomach pain is&quot;)).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_text_generator = legal.TextGenerator .pretrained(&quot;medical_text_generator&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(true) .setTopK(3) .setRandomSeed(42) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_text_generator )) val data = Seq(Array( &quot;Covid 19 is&quot;, &quot;The most common cause of stomach pain is&quot;)).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) ZeroShotNerModel Model This is a zero shot named entity recognition based on RoBertaForQuestionAnswering. Zero shot models excel at generalization, meaning that the model can accurately predict entities in very different data sets without the need to fine tune the model or train from scratch for each different domain. Even though a model trained to solve a specific problem can achieve better accuracy than a zero-shot model in this specific task, it probably won’t be be useful in a different task. That is where zero-shot models shows its usefulness by being able to achieve good results in many different scenarions. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: NAMED_ENTITY Python API: ZeroShotNerModel Scala API: ZeroShotNerModel Show Example PythonScala MedicalFinanceLegal documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = ( SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) ) tokenizer = Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) zero_shot_ner = ( ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setEntityDefinitions( { &quot;PROBLEM&quot;: [ &quot;What is the disease?&quot;, &quot;What is his symptom?&quot;, &quot;What is her disease?&quot;, &quot;What is his disease?&quot;, &quot;What is the problem?&quot;, &quot;What does a patient suffer&quot;, &quot;What was the reason that the patient is admitted to the clinic?&quot;, ], &quot;DRUG&quot;: [ &quot;Which drug?&quot;, &quot;Which is the drug?&quot;, &quot;What is the drug?&quot;, &quot;Which drug does he use?&quot;, &quot;Which drug does she use?&quot;, &quot;Which drug do I use?&quot;, &quot;Which drug is prescribed for a symptom?&quot;, ], &quot;ADMISSION_DATE&quot;: [&quot;When did patient admitted to a clinic?&quot;], &quot;PATIENT_AGE&quot;: [ &quot;How old is the patient?&quot;, &quot;What is the gae of the patient?&quot;, ], } ) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setPredictionThreshold(0.1) ) # default 0.01 ner_converter = ( sparknlp.annotators.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) pipeline = Pipeline( stages=[ documentAssembler, sentenceDetector, tokenizer, zero_shot_ner, ner_converter, ] ) zero_shot_ner_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) text_list = [ &quot;The doctor pescribed Majezik for my severe headache.&quot;, &quot;The patient was admitted to the hospital for his colon cancer.&quot;, &quot;27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis.&quot;, ] data = spark.createDataFrame(text_list, StringType()).toDF(&quot;text&quot;) results = zero_shot_ner_model.transform(data) results.select( F.explode( F.arrays_zip( results.token.result, results.zero_shot_ner.result, results.zero_shot_ner.metadata, results.zero_shot_ner.begin, results.zero_shot_ner.end, ) ).alias(&quot;cols&quot;) ).select( F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;token&quot;), F.expr(&quot;cols[&#39;1&#39;]&quot;).alias(&quot;ner_label&quot;), F.expr(&quot;cols[&#39;2&#39;][&#39;sentence&#39;]&quot;).alias(&quot;sentence&quot;), F.expr(&quot;cols[&#39;3&#39;]&quot;).alias(&quot;begin&quot;), F.expr(&quot;cols[&#39;4&#39;]&quot;).alias(&quot;end&quot;), F.expr(&quot;cols[&#39;2&#39;][&#39;confidence&#39;]&quot;).alias(&quot;confidence&quot;), ).show( 50, truncate=100 ) +-+-+--+--++-+ token| ner_label|sentence|begin|end|confidence| +-+-+--+--++-+ The| O| 0| 0| 2| null| doctor| O| 0| 4| 9| null| pescribed| O| 0| 11| 19| null| Majezik| B-DRUG| 0| 21| 27| 0.6467137| for| O| 0| 29| 31| null| my| O| 0| 33| 34| null| severe| B-PROBLEM| 0| 36| 41|0.55263567| headache| I-PROBLEM| 0| 43| 50|0.55263567| .| O| 0| 51| 51| null| The| O| 0| 0| 2| null| patient| O| 0| 4| 10| null| was| O| 0| 12| 14| null| admitted| O| 0| 16| 23| null| to| O| 0| 25| 26| null| the| O| 0| 28| 30| null| hospital| O| 0| 32| 39| null| for| O| 0| 41| 43| null| his| O| 0| 45| 47| null| colon| B-PROBLEM| 0| 49| 53| 0.8898501| cancer| I-PROBLEM| 0| 55| 60| 0.8898501| .| O| 0| 61| 61| null| 27| B-PATIENT_AGE| 0| 0| 1| 0.6943086| years| I-PATIENT_AGE| 0| 3| 7| 0.6943086| old| I-PATIENT_AGE| 0| 9| 11| 0.6943086| patient| O| 0| 13| 19| null| was| O| 0| 21| 23| null| admitted| O| 0| 25| 32| null| to| O| 0| 34| 35| null| clinic| O| 0| 37| 42| null| on| O| 0| 44| 45| null| Sep|B-ADMISSION_DATE| 0| 47| 49|0.95646083| 1st|I-ADMISSION_DATE| 0| 51| 53|0.95646083| by| O| 0| 55| 56| null| Dr| O| 0| 58| 59| null| .| O| 0| 60| 60| null| X| O| 0| 62| 62| null| for| O| 0| 64| 66| null| a| B-PROBLEM| 0| 68| 68|0.50026655| right-sided| I-PROBLEM| 0| 70| 80|0.50026655| pleural| I-PROBLEM| 0| 82| 88|0.50026655| effusion| I-PROBLEM| 0| 90| 97|0.50026655| for| I-PROBLEM| 0| 99|101|0.50026655| thoracentesis| I-PROBLEM| 0| 103|115|0.50026655| .| O| 0| 116|116| null| +-+-+--+--++-+ document_assembler = ( nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) ) sentence_detector = ( nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) ) tokenizer = nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) zero_shot_ner = ( finance.ZeroShotNerModel.pretrained( &quot;finner_roberta_zeroshot&quot;, &quot;en&quot;, &quot;finance/models&quot; ) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;DATE&quot;: [ &quot;When was the company acquisition?&quot;, &quot;When was the company purchase agreement?&quot;, ], &quot;ORG&quot;: [&quot;Which company was acquired?&quot;], &quot;PRODUCT&quot;: [&quot;Which product?&quot;], &quot;PROFIT_INCREASE&quot;: [&quot;How much has the gross profit increased?&quot;], &quot;REVENUES_DECLINED&quot;: [&quot;How much has the revenues declined?&quot;], &quot;OPERATING_LOSS_2020&quot;: [&quot;Which was the operating loss in 2020&quot;], &quot;OPERATING_LOSS_2019&quot;: [&quot;Which was the operating loss in 2019&quot;], } ) ) ner_converter = ( nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) pipeline = nlp.Pipeline( stages=[ document_assembler, sentence_detector, tokenizer, zero_shot_ner, ner_converter, ] ) from pyspark.sql.types import StringType sample_text = [ &quot;In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.&quot;, &quot;In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.&quot;, &quot;While our gross profit margin increased to 81.4% in 2020 from 63.1% in 2019, our revenues declined approximately 27% in 2020 as compared to 2019.&quot;, &quot;We reported an operating loss of approximately $8,048,581 million in 2020 as compared to an operating loss of $7,738,193 in 2019.&quot;, ] p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) res = p_model.transform(spark.createDataFrame(sample_text, StringType()).toDF(&quot;text&quot;)) res.select( F.explode( F.arrays_zip( res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata, ) ).alias(&quot;cols&quot;) ).select( F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;) ).filter( &quot;ner_label!=&#39;O&#39;&quot; ).show( truncate=False ) ++-+ |chunk |ner_label | ++-+ |March 2012 |DATE | |Vertro |ORG | |ALOT |PRODUCT | |February 2017 |DATE | |NetSeer |ORG | |81.4% |PROFIT_INCREASE | |27% |REVENUES_DECLINED | |$8,048,581 million|OPERATING_LOSS_2020| |$7,738,193 |OPERATING_LOSS_2019| |2019 |DATE | ++-+ documentAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentence = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) zero_shot_ner = ( legal.ZeroShotNerModel.pretrained(&quot;legner_roberta_zeroshot&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;DATE&quot;: [ &quot;When was the company acquisition?&quot;, &quot;When was the company purchase agreement?&quot;, &quot;When was the agreement?&quot;, ], &quot;ORG&quot;: [&quot;Which company?&quot;], &quot;STATE&quot;: [&quot;Which state?&quot;], &quot;AGREEMENT&quot;: [&quot;What kind of agreement?&quot;], &quot;LICENSE&quot;: [&quot;What kind of license?&quot;], &quot;LICENSE_RECIPIENT&quot;: [&quot;To whom the license is granted?&quot;], } ) ) nerconverter = ( nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) pipeline = nlp.Pipeline( stages=[ documentAssembler, sentence, tokenizer, zero_shot_ner, nerconverter, ] ) from pyspark.sql.types import StructType, StructField, StringType sample_text = [ &quot;In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.&quot;, &quot;In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.&quot;, &quot;This INTELLECTUAL PROPERTY AGREEMENT, dated as of December 31, 2018 (the &#39;Effective Date&#39;) is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (&#39;Seller&#39;) and AFI Licensing LLC, a Delaware company (the &#39;Licensee&#39;)&quot;, &quot;The Company hereby grants to Seller a perpetual, non- exclusive, royalty-free license&quot;, ] p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) res = p_model.transform(spark.createDataFrame(sample_text, StringType()).toDF(&quot;text&quot;)) res.select( F.explode( F.arrays_zip( res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata, ) ).alias(&quot;cols&quot;) ).select( F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;) ).filter( &quot;ner_label!=&#39;O&#39;&quot; ).show( truncate=False ) +-+--+ |chunk |ner_label | +-+--+ |March 2012 |DATE | |Vertro, Inc |ORG | |February 2017 |DATE | |asset purchase agreement |AGREEMENT | |NetSeer |ORG | |INTELLECTUAL PROPERTY |AGREEMENT | |December 31, 2018 |DATE | |Armstrong Flooring |LICENSE_RECIPIENT| |Delaware |STATE | |AFI Licensing LLC, a Delaware company|LICENSE_RECIPIENT| |Seller |LICENSE_RECIPIENT| |perpetual |LICENSE | |non- exclusive |LICENSE | |royalty-free |LICENSE | +-+--+ FinanceLegal val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentences&quot;) val zeroShotNer = ZeroShotNerModel .pretrained() .setEntityDefinitions( Map( &quot;NAME&quot; -&gt; Array(&quot;What is his name?&quot;, &quot;What is her name?&quot;), &quot;CITY&quot; -&gt; Array(&quot;Which city?&quot;))) .setPredictionThreshold(0.01f) .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;zero_shot_ner&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentenceDetector, zeroShotNer)) val model = pipeline.fit(Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;)) val results = model.transform( Seq(&quot;Clara often travels between New York and Paris.&quot;).toDS.toDF(&quot;text&quot;)) results .selectExpr(&quot;document&quot;, &quot;explode(zero_shot_ner) AS entity&quot;) .select( col(&quot;entity.result&quot;), col(&quot;entity.metadata.word&quot;), col(&quot;entity.metadata.sentence&quot;), col(&quot;entity.begin&quot;), col(&quot;entity.end&quot;), col(&quot;entity.metadata.confidence&quot;), col(&quot;entity.metadata.question&quot;)) .show(truncate=false) ++--+--+--++-++ |result|word |sentence|begin|end|confidence|question | ++--+--+--++-++ |B-CITY|Paris|0 |41 |45 |0.78655756|Which is the city?| |B-CITY|New |0 |28 |30 |0.29346612|Which city? | |I-CITY|York |0 |32 |35 |0.29346612|Which city? | ++--+--+--++-++ val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentences&quot;) val zeroShotNer = ZeroShotNerModel .pretrained() .setEntityDefinitions( Map( &quot;NAME&quot; -&gt; Array(&quot;What is his name?&quot;, &quot;What is her name?&quot;), &quot;CITY&quot; -&gt; Array(&quot;Which city?&quot;))) .setPredictionThreshold(0.01f) .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;zero_shot_ner&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentenceDetector, zeroShotNer)) val model = pipeline.fit(Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;)) val results = model.transform( Seq(&quot;Clara often travels between New York and Paris.&quot;).toDS.toDF(&quot;text&quot;)) results .selectExpr(&quot;document&quot;, &quot;explode(zero_shot_ner) AS entity&quot;) .select( col(&quot;entity.result&quot;), col(&quot;entity.metadata.word&quot;), col(&quot;entity.metadata.sentence&quot;), col(&quot;entity.begin&quot;), col(&quot;entity.end&quot;), col(&quot;entity.metadata.confidence&quot;), col(&quot;entity.metadata.question&quot;)) .show(truncate=false) ++--+--+--++-++ |result|word |sentence|begin|end|confidence|question | ++--+--+--++-++ |B-CITY|Paris|0 |41 |45 |0.78655756|Which is the city?| |B-CITY|New |0 |28 |30 |0.29346612|Which city? | |I-CITY|York |0 |32 |35 |0.29346612|Which city? | ++--+--+--++-++ ZeroShotRelationExtractionModel Model ZeroShotRelationExtractionModel implements zero-shot binary relations extraction by utilizing BERT transformer models trained on the NLI (Natural Language Inference) task. The model inputs consists of documents/sentences and paired NER chunks, usually obtained by RENerChunksFilter. The definitions of relations which are extracted is given by a dictionary structures, specifying a set of statements regarding the relationship of named entities. These statements are automatically appended to each document in the dataset and the NLI model is used to determine whether a particular relationship between entities. For available pretrained models please see the NLP Models Hub. Input Annotator Types: CHUNK, DOCUMENT Output Annotator Type: CATEGORY Python API: ZeroShotRelationExtractionModel Scala API: ZeroShotRelationExtractionModel Show Example PythonScala MedicalFinanceLegal documenter = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentencer = ( SentenceDetectorDLModel.pretrained( &quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) ) tokenizer = Tokenizer().setInputCols([&quot;sentences&quot;]).setOutputCol(&quot;tokens&quot;) words_embedder = ( WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ) ner_clinical = ( MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_clinical&quot;) ) ner_clinical_converter = ( NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_clinical&quot;]) .setOutputCol(&quot;ner_clinical_chunks&quot;) .setWhiteList([&quot;PROBLEM&quot;, &quot;TEST&quot;]) ) # PROBLEM-TEST-TREATMENT ner_posology = ( MedicalNerModel.pretrained(&quot;ner_posology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_posology&quot;) ) ner_posology_converter = ( NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_posology&quot;]) .setOutputCol(&quot;ner_posology_chunks&quot;) .setWhiteList([&quot;DRUG&quot;]) ) # DRUG-FREQUENCY-DOSAGE-DURATION-FORM-ROUTE-STRENGTH chunk_merger = ( ChunkMergeApproach() .setInputCols(&quot;ner_clinical_chunks&quot;, &quot;ner_posology_chunks&quot;) .setOutputCol(&quot;merged_ner_chunks&quot;) ) ## ZERO-SHOT RE Starting... pos_tagger = ( PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) ) dependency_parser = ( DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;document&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) ) re_ner_chunk_filter = ( RENerChunksFilter() .setRelationPairs([&quot;problem-test&quot;, &quot;problem-drug&quot;]) .setMaxSyntacticDistance(4) .setDocLevelRelations(False) .setInputCols([&quot;merged_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) ) re_model = ( ZeroShotRelationExtractionModel.pretrained( &quot;re_zeroshot_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationalCategories( { &quot;ADE&quot;: [&quot;{DRUG} causes {PROBLEM}.&quot;], &quot;IMPROVE&quot;: [&quot;{DRUG} improves {PROBLEM}.&quot;, &quot;{DRUG} cures {PROBLEM}.&quot;], &quot;REVEAL&quot;: [&quot;{TEST} reveals {PROBLEM}.&quot;], } ) .setMultiLabel(True) ) pipeline = sparknlp.base.Pipeline().setStages( [ documenter, sentencer, tokenizer, words_embedder, ner_clinical, ner_clinical_converter, ner_posology, ner_posology_converter, chunk_merger, pos_tagger, dependency_parser, re_ner_chunk_filter, re_model, ] ) sample_text = &quot;Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer.&quot; data = spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;) model = pipeline.fit(data) results = model.transform(data) from pyspark.sql import functions as F results.select( F.explode(F.arrays_zip(results.relations.metadata, results.relations.result)).alias( &quot;cols&quot; ) ).select( F.expr(&quot;cols[&#39;0&#39;][&#39;sentence&#39;]&quot;).alias(&quot;sentence&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity1_begin&#39;]&quot;).alias(&quot;entity1_begin&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity1_end&#39;]&quot;).alias(&quot;entity1_end&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;chunk1&#39;]&quot;).alias(&quot;chunk1&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity1&#39;]&quot;).alias(&quot;entity1&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity2_begin&#39;]&quot;).alias(&quot;entity2_begin&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity2_end&#39;]&quot;).alias(&quot;entity2_end&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;chunk2&#39;]&quot;).alias(&quot;chunk2&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity2&#39;]&quot;).alias(&quot;entity2&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;hypothesis&#39;]&quot;).alias(&quot;hypothesis&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;nli_prediction&#39;]&quot;).alias(&quot;nli_prediction&quot;), F.expr(&quot;cols[&#39;1&#39;]&quot;).alias(&quot;relation&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;confidence&#39;]&quot;).alias(&quot;confidence&quot;), ).show( truncate=70 ) +--+-+--+--+-+-+--+--+-++--+--+-+ sentence|entity1_begin|entity1_end| chunk1|entity1|entity2_begin|entity2_end| chunk2|entity2| hypothesis|nli_prediction|relation|confidence| +--+-+--+--+-+-+--+--+-++--+--+-+ 0| 0| 10|Paracetamol| DRUG| 38| 45|sickness|PROBLEM|Paracetamol improves sickness.| entail| IMPROVE|0.98819494| 0| 0| 10|Paracetamol| DRUG| 26| 33|headache|PROBLEM|Paracetamol improves headache.| entail| IMPROVE| 0.9929625| 1| 48| 58|An MRI test| TEST| 80| 85| cancer|PROBLEM| An MRI test reveals cancer.| entail| REVEAL| 0.9760039| +--+-+--+--+-+-+--+--+-++--+--+-+ document_assembler = ( nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) ) sentence_detector = ( nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) ) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = ( nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ) ner_model = ( finance.NerModel.pretrained(&quot;finner_financial_small&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ) ner_converter = ( nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) re_model = ( finance.ZeroShotRelationExtractionModel.pretrained( &quot;finre_zero_shot&quot;, &quot;en&quot;, &quot;finance/models&quot; ) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;relations&quot;) .setMultiLabel(False) ) re_model.setRelationalCategories( { &quot;profit_decline_by&quot;: [ &quot;{PROFIT_DECLINE} decreased by {AMOUNT} from&quot;, &quot;{PROFIT_DECLINE} decreased by {AMOUNT} to&quot;, ], &quot;profit_decline_by_per&quot;: [ &quot;{PROFIT_DECLINE} decreased by a {PERCENTAGE} from&quot;, &quot;{PROFIT_DECLINE} decreased by a {PERCENTAGE} to&quot;, ], &quot;profit_decline_from&quot;: [ &quot;{PROFIT_DECLINE} decreased from {AMOUNT}&quot;, &quot;{PROFIT_DECLINE} decreased from {AMOUNT} for the year&quot;, ], &quot;profit_decline_from_per&quot;: [ &quot;{PROFIT_DECLINE} decreased from {PERCENTAGE} to&quot;, &quot;{PROFIT_DECLINE} decreased from {PERCENTAGE} to a total of&quot;, ], &quot;profit_decline_to&quot;: [&quot;{PROFIT_DECLINE} to {AMOUNT}&quot;], &quot;profit_increase_from&quot;: [&quot;{PROFIT_INCREASE} from {AMOUNT}&quot;], &quot;profit_increase_to&quot;: [&quot;{PROFIT_INCREASE} to {AMOUNT}&quot;], &quot;expense_decrease_by&quot;: [&quot;{EXPENSE_DECREASE} decreased by {AMOUNT}&quot;], &quot;expense_decrease_by_per&quot;: [&quot;{EXPENSE_DECREASE} decreased by a {PERCENTAGE}&quot;], &quot;expense_decrease_from&quot;: [&quot;{EXPENSE_DECREASE} decreased from {AMOUNT}&quot;], &quot;expense_decrease_to&quot;: [ &quot;{EXPENSE_DECREASE} for a total of {AMOUNT} for the fiscal year&quot; ], &quot;has_date&quot;: [ &quot;{AMOUNT} for the fiscal year ended {FISCAL_YEAR}&quot;, &quot;{PERCENTAGE} for the fiscal year ended {FISCAL_YEAR}&quot;, ], } ) pipeline = nlp.Pipeline( stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, re_model, ] ) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) light_model = nlp.LightPipeline(model) sample_text = &quot;&quot;&quot;License fees revenue decreased 40 %, or $ 0.5 million to $ 0.7 million for the year ended December 31, 2020 compared to $ 1.2 million for the year ended December 31, 2019. Services revenue increased 4 %, or $ 1.1 million, to $ 25.6 million for the year ended December 31, 2020 from $ 24.5 million for the year ended December 31, 2019. Costs of revenue, excluding depreciation and amortization increased by $ 0.1 million, or 2 %, to $ 8.8 million for the year ended December 31, 2020 from $ 8.7 million for the year ended December 31, 2019. Also, a decrease in travel costs of $ 0.4 million due to travel restrictions caused by the global pandemic. As a percentage of revenue, cost of revenue, excluding depreciation and amortization was 34 % for each of the years ended December 31, 2020 and 2019. Sales and marketing expenses decreased 20 %, or $ 1.5 million, to $ 6.0 million for the year ended December 31, 2020 from $ 7.5 million for the year ended December 31, 2019&quot;&quot;&quot; data = spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;) result = model.transform(data) result.selectExpr(&quot;explode(relations) as relation&quot;).show(truncate=False) ++ |relation | ++ |{category, 8462, 8693, has_date, {entity1_begin -&gt; 227, relation -&gt; has_date, hypothesis -&gt; 25.6 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.8744761, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 332, entity1_end -&gt; 238, entity2_begin -&gt; 316, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 25.6 million, sentence -&gt; 1}, []} | |{category, 4643, 4873, has_date, {entity1_begin -&gt; 31, relation -&gt; has_date, hypothesis -&gt; 40 for the fiscal year ended December 31, 2019, confidence -&gt; 0.7889031, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 169, entity1_end -&gt; 32, entity2_begin -&gt; 153, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 40, sentence -&gt; 0}, []} | |{category, 13507, 13748, expense_decrease_from, {entity1_begin -&gt; 799, relation -&gt; expense_decrease_from, hypothesis -&gt; Sales and marketing expenses decreased from 7.5 million, confidence -&gt; 0.9770538, nli_prediction -&gt; entail, entity1 -&gt; EXPENSE_DECREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 7.5 million, entity2_end -&gt; 933, entity1_end -&gt; 826, entity2_begin -&gt; 923, entity2 -&gt; AMOUNT, chunk1 -&gt; Sales and marketing expenses, sentence -&gt; 5}, []}| |{category, 5354, 5593, has_date, {entity1_begin -&gt; 59, relation -&gt; has_date, hypothesis -&gt; 0.7 million for the fiscal year ended December 31, 2020, confidence -&gt; 0.6718765, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 106, entity1_end -&gt; 69, entity2_begin -&gt; 90, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.7 million, sentence -&gt; 0}, []} | |{category, 6490, 6697, profit_increase_to, {entity1_begin -&gt; 172, relation -&gt; profit_increase_to, hypothesis -&gt; Services revenue to 25.6 million, confidence -&gt; 0.9674029, nli_prediction -&gt; entail, entity1 -&gt; PROFIT_INCREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 25.6 million, entity2_end -&gt; 238, entity1_end -&gt; 187, entity2_begin -&gt; 227, entity2 -&gt; AMOUNT, chunk1 -&gt; Services revenue, sentence -&gt; 1}, []} | |{category, 4412, 4642, has_date, {entity1_begin -&gt; 31, relation -&gt; has_date, hypothesis -&gt; 40 for the fiscal year ended December 31, 2020, confidence -&gt; 0.778003, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 106, entity1_end -&gt; 32, entity2_begin -&gt; 90, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 40, sentence -&gt; 0}, []} | |{category, 13989, 14221, has_date, {entity1_begin -&gt; 838, relation -&gt; has_date, hypothesis -&gt; 20 for the fiscal year ended December 31, 2020, confidence -&gt; 0.8545547, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 914, entity1_end -&gt; 839, entity2_begin -&gt; 898, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 20, sentence -&gt; 5}, []} | |{category, 11157, 11314, expense_decrease_by, {entity1_begin -&gt; 561, relation -&gt; expense_decrease_by, hypothesis -&gt; travel costs decreased by 0.4 million, confidence -&gt; 0.9946776, nli_prediction -&gt; entail, entity1 -&gt; EXPENSE_DECREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 0.4 million, entity2_end -&gt; 589, entity1_end -&gt; 572, entity2_begin -&gt; 579, entity2 -&gt; AMOUNT, chunk1 -&gt; travel costs, sentence -&gt; 3}, []} | |{category, 5114, 5353, has_date, {entity1_begin -&gt; 42, relation -&gt; has_date, hypothesis -&gt; 0.5 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.77566886, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 169, entity1_end -&gt; 52, entity2_begin -&gt; 153, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.5 million, sentence -&gt; 0}, []} | |{category, 6281, 6489, profit_increase_from, {entity1_begin -&gt; 172, relation -&gt; profit_increase_from, hypothesis -&gt; Services revenue from 1.1 million, confidence -&gt; 0.96610945, nli_prediction -&gt; entail, entity1 -&gt; PROFIT_INCREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 1.1 million, entity2_end -&gt; 219, entity1_end -&gt; 187, entity2_begin -&gt; 209, entity2 -&gt; AMOUNT, chunk1 -&gt; Services revenue, sentence -&gt; 1}, []} | |{category, 9199, 9471, has_date, {entity1_begin -&gt; 408, relation -&gt; has_date, hypothesis -&gt; 0.1 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.9083246, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 537, entity1_end -&gt; 418, entity2_begin -&gt; 521, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.1 million, sentence -&gt; 2}, []} | |{category, 14455, 14696, has_date, {entity1_begin -&gt; 849, relation -&gt; has_date, hypothesis -&gt; 1.5 million for the fiscal year ended December 31, 2020, confidence -&gt; 0.75281376, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 914, entity1_end -&gt; 859, entity2_begin -&gt; 898, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 1.5 million, sentence -&gt; 5}, []} | |{category, 14697, 14938, has_date, {entity1_begin -&gt; 849, relation -&gt; has_date, hypothesis -&gt; 1.5 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.8073463, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 970, entity1_end -&gt; 859, entity2_begin -&gt; 954, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 1.5 million, sentence -&gt; 5}, []} | |{category, 4874, 5113, has_date, {entity1_begin -&gt; 42, relation -&gt; has_date, hypothesis -&gt; 0.5 million for the fiscal year ended December 31, 2020, confidence -&gt; 0.71575713, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 106, entity1_end -&gt; 52, entity2_begin -&gt; 90, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.5 million, sentence -&gt; 0}, []} | |{category, 6908, 7115, profit_increase_to, {entity1_begin -&gt; 172, relation -&gt; profit_increase_to, hypothesis -&gt; Services revenue to 24.5 million, confidence -&gt; 0.85972106, nli_prediction -&gt; entail, entity1 -&gt; PROFIT_INCREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 24.5 million, entity2_end -&gt; 295, entity1_end -&gt; 187, entity2_begin -&gt; 284, entity2 -&gt; AMOUNT, chunk1 -&gt; Services revenue, sentence -&gt; 1}, []} | |{category, 5594, 5833, has_date, {entity1_begin -&gt; 59, relation -&gt; has_date, hypothesis -&gt; 0.7 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.7484568, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 169, entity1_end -&gt; 69, entity2_begin -&gt; 153, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.7 million, sentence -&gt; 0}, []} | |{category, 7326, 7546, has_date, {entity1_begin -&gt; 199, relation -&gt; has_date, hypothesis -&gt; 4 for the fiscal year ended December 31, 2020, confidence -&gt; 0.8412763, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 275, entity1_end -&gt; 199, entity2_begin -&gt; 259, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 4, sentence -&gt; 1}, []} | |{category, 9472, 9734, has_date, {entity1_begin -&gt; 424, relation -&gt; has_date, hypothesis -&gt; 2 for the fiscal year ended December 31, 2020, confidence -&gt; 0.8046481, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 481, entity1_end -&gt; 424, entity2_begin -&gt; 465, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 2, sentence -&gt; 2}, []} | |{category, 9735, 9997, has_date, {entity1_begin -&gt; 424, relation -&gt; has_date, hypothesis -&gt; 2 for the fiscal year ended December 31, 2019, confidence -&gt; 0.8485106, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 537, entity1_end -&gt; 424, entity2_begin -&gt; 521, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 2, sentence -&gt; 2}, []} | |{category, 691, 916, profit_decline_by_per, {entity1_begin -&gt; 0, relation -&gt; profit_decline_by_per, hypothesis -&gt; License fees revenue decreased by a 40 to, confidence -&gt; 0.9948003, nli_prediction -&gt; entail, entity1 -&gt; PROFIT_DECLINE, syntactic_distance -&gt; undefined, chunk2 -&gt; 40, entity2_end -&gt; 32, entity1_end -&gt; 19, entity2_begin -&gt; 31, entity2 -&gt; PERCENTAGE, chunk1 -&gt; License fees revenue, sentence -&gt; 0}, []} | ++ only showing top 20 rows document_assembler = ( nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) ) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) tokenClassifier = ( legal.BertForTokenClassification.pretrained( &quot;legner_obligations&quot;, &quot;en&quot;, &quot;legal/models&quot; ) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ) ner_converter = ( nlp.NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) re_model = ( legal.ZeroShotRelationExtractionModel.pretrained( &quot;legre_zero_shot&quot;, &quot;en&quot;, &quot;legal/models&quot; ) .setInputCols([&quot;ner_chunk&quot;, &quot;document&quot;]) .setOutputCol(&quot;relations&quot;) ) re_model.setRelationalCategories( { &quot;should_provide&quot;: [ &quot;{OBLIGATION_SUBJECT} will provide {OBLIGATION}&quot;, &quot;{OBLIGATION_SUBJECT} should provide {OBLIGATION}&quot;, ], &quot;commits_with&quot;: [ &quot;{OBLIGATION_SUBJECT} to {OBLIGATION_INDIRECT_OBJECT}&quot;, &quot;{OBLIGATION_SUBJECT} with {OBLIGATION_INDIRECT_OBJECT}&quot;, ], &quot;commits_to&quot;: [&quot;{OBLIGATION_SUBJECT} commits to {OBLIGATION}&quot;], &quot;agree_to&quot;: [&quot;{OBLIGATION_SUBJECT} agrees to {OBLIGATION}&quot;], } ) pipeline = nlp.Pipeline( stages=[document_assembler, tokenizer, tokenClassifier, ner_converter, re_model] ) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) light_model = nlp.LightPipeline(model) import pandas as pd def get_relations_df(results, col=&quot;relations&quot;): rel_pairs = [] for i in range(len(results)): for rel in results[i][col]: rel_pairs.append( ( rel.result, rel.metadata[&quot;entity1&quot;], rel.metadata[&quot;entity1_begin&quot;], rel.metadata[&quot;entity1_end&quot;], rel.metadata[&quot;chunk1&quot;], rel.metadata[&quot;entity2&quot;], rel.metadata[&quot;entity2_begin&quot;], rel.metadata[&quot;entity2_end&quot;], rel.metadata[&quot;chunk2&quot;], rel.metadata[&quot;confidence&quot;], ) ) rel_df = pd.DataFrame( rel_pairs, columns=[ &quot;relation&quot;, &quot;entity1&quot;, &quot;entity1_begin&quot;, &quot;entity1_end&quot;, &quot;chunk1&quot;, &quot;entity2&quot;, &quot;entity2_begin&quot;, &quot;entity2_end&quot;, &quot;chunk2&quot;, &quot;confidence&quot;, ], ) return rel_df sample_text = &quot;&quot;&quot;This INTELLECTUAL PROPERTY AGREEMENT (this &quot;Agreement&quot;), dated as of December 31, 2018 (the &quot;Effective Date&quot;) is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (&quot;Seller&quot;) and AFI Licensing LLC, a Delaware limited liability company (&quot;Licensing&quot; and together with Seller, &quot;Arizona&quot;) and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation (&quot;Buyer&quot;) and Armstrong Hardwood Flooring Company, a Tennessee corporation (the &quot;Company&quot; and together with Buyer the &quot;Buyer Entities&quot;) (each of Arizona on the one hand and the Buyer Entities on the other hand, a &quot;Party&quot; and collectively, the &quot;Parties&quot;).&quot;&quot;&quot; result = light_model.fullAnnotate(sample_text) rel_df = get_relations_df(result) rel_df[rel_df[&quot;relation&quot;] != &quot;no_rel&quot;] | relation | entity1 | entity1_begin | entity1_end | chunk1 | entity2 | entity2_begin | entity2_end | chunk2 | confidence | |:|--:|--:|:|:|--:|--:|:|:|--:| | dated_as | DOC | 5 | 35 | INTELLECTUAL PROPERTY AGREEMENT | EFFDATE | 69 | 85 | December 31, 2018 | 0.98433626 | | signed_by | DOC | 5 | 35 | INTELLECTUAL PROPERTY AGREEMENT | PARTY | 141 | 163 | Armstrong Flooring, Inc | 0.60404813 | | has_alias | PARTY | 141 | 163 | Armstrong Flooring, Inc | ALIAS | 192 | 197 | Seller | 0.96357507 | | has_alias | PARTY | 205 | 221 | AFI Licensing LLC | ALIAS | 263 | 271 | Licensing | 0.9546678 | | has_alias | PARTY | 315 | 330 | AHF Holding, Inc | ALIAS | 611 | 615 | Party | 0.5387175 | | has_alias | PARTY | 315 | 330 | AHF Holding, Inc | ALIAS | 641 | 647 | Parties | 0.5387175 | | has_collective_alias | ALIAS | 399 | 403 | Buyer | ALIAS | 611 | 615 | Party | 0.5539445 | | has_collective_alias | ALIAS | 399 | 403 | Buyer | ALIAS | 641 | 647 | Parties | 0.5539445 | | has_alias | PARTY | 411 | 445 | Armstrong Hardwood Flooring Company | ALIAS | 478 | 484 | Company | 0.92106056 | | has_alias | PARTY | 411 | 445 | Armstrong Hardwood Flooring Company | ALIAS | 611 | 615 | Party | 0.58123946 | | has_alias | PARTY | 411 | 445 | Armstrong Hardwood Flooring Company | ALIAS | 641 | 647 | Parties | 0.58123946 | | has_collective_alias | ALIAS | 505 | 509 | Buyer | ALIAS | 516 | 529 | Buyer Entities | 0.63492435 | | has_collective_alias | ALIAS | 505 | 509 | Buyer | ALIAS | 611 | 615 | Party | 0.6483803 | | has_collective_alias | ALIAS | 505 | 509 | Buyer | ALIAS | 641 | 647 | Parties | 0.6483803 | | has_collective_alias | ALIAS | 516 | 529 | Buyer Entities | ALIAS | 611 | 615 | Party | 0.6970743 | | has_collective_alias | ALIAS | 516 | 529 | Buyer Entities | ALIAS | 641 | 647 | Parties | 0.6970743 | Medical val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;tokens&quot;) val sentencer = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentences&quot;) val embeddings = WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val posTagger = PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;posTags&quot;) val nerTagger = MedicalNerModel .pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;nerTags&quot;) val nerConverter = new NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;nerTags&quot;)) .setOutputCol(&quot;nerChunks&quot;) val dependencyParser = DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;posTags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val reNerFilter = new RENerChunksFilter() .setRelationPairs(Array(&quot;problem-test&quot;,&quot;problem-treatment&quot;)) .setMaxSyntacticDistance(4) .setDocLevelRelations(false) .setInputCols(Array(&quot;nerChunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;RENerChunks&quot;) val re = ZeroShotRelationExtractionModel .load(&quot;/tmp/spark_sbert_zero_shot&quot;) .setRelationalCategories( Map( &quot;CURE&quot; -&gt; Array(&quot;{TREATMENT} cures {PROBLEM}.&quot;), &quot;IMPROVE&quot; -&gt; Array(&quot;{TREATMENT} improves {PROBLEM}.&quot;, &quot;{TREATMENT} cures {PROBLEM}.&quot;), &quot;REVEAL&quot; -&gt; Array(&quot;{TEST} reveals {PROBLEM}.&quot;) )) .setPredictionThreshold(0.9f) .setMultiLabel(false) .setInputCols(Array(&quot;sentences&quot;, &quot;RENerChunks&quot;)) .setOutputCol(&quot;relations) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentencer, tokenizer, embeddings, posTagger, nerTagger, nerConverter, dependencyParser, reNerFilter, re)) val model = pipeline.fit(Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;)) val results = model.transform( Seq(&quot;Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer.&quot;).toDS.toDF(&quot;text&quot;)) results .selectExpr(&quot;EXPLODE(relations) as relation&quot;) .selectExpr(&quot;relation.result&quot;, &quot;relation.metadata.confidence&quot;) .show(truncate = false) +-+-+ |result |confidence| +-+-+ |REVEAL |0.9760039 | |IMPROVE|0.98819494| |IMPROVE|0.9929625 | +-+-+",
    "url": "/docs/en/licensed_annotators",
    "relUrl": "/docs/en/licensed_annotators"
  },
  "1256": {
    "id": "1256",
    "title": "Enterprise Spark NLP Installation",
    "content": "AWS Marketplace The entire suite of John Snow Labs NLP and Visual NLP libraries are offered as a pay-as-you-go product on AWS Marketplace, pre-installed and ready to use. 30+ Notebooks are included in the AWS product to allow you to start experimenting on your own data right away. To subscribe to the pay-as-you-go product on AWS Marketplace navigate to the product page and follow the instructions in the video below. Subscribe to John Snow Labs NLP Libraries via AWS Marketplace Note: 30-day free trial are available for AWS and Azure subscriptions. Installation with johnsnowlabs On Oct 4th, 2022 we released johnsnowlabs library, which eases the installation and session starting processes in an almost transparent way for the user. Finance NLP and Legal NLP are built on the top of a new John Snow Labs library, called johnsnowlabs. If you are a former user of Spark NLP or Spark NLP for Healthcare, you will find this new way of deploying your Spark NLP clusters much more user-friendly! Clinical NLP (former Spark NLP for Healthcare) still can be run without johnsnowlabs library, although we highly recommend to install it with this new method. For advanced installation options, please check johnsnowlabs webpage. 1. Installing johnsnowlabs The first step you need to carry out is installing johnsnowlabs library. This is as easy as doing: !pip install johnsnowlabs 2. Installing Enterprise NLP (Finance, Legal, Clinical) Import johnsnowlabs and use our one-liner nlp.install() to install all the dependencies, downloading the jars (yes, Spark NLP runs on top of the Java Virtual Machine!), preparing the cluster environment variables, licenses, etc! from johnsnowlabs import * nlp.install(force_browser=True) The force_browser=True command gets rid of you uploading a license. It will open a popup to connect to our license server at my.johnsnowlabs.com retrieve the license for you, and install everything your license allows you to use! If you are a user of Financial NLP, you will get that installed. If you are a Legal user, then Legal NLP will be installed, or Clinical! Everything will be taken care on your behalf! Optional: Uploading the license manually We still have the way of downloading manually the license, in case the connection with my.johnsnowlabs.com is not an option for you. Just put your license json in the same folder of the notebook, and run: nlp.install() In colab, you can use this fancy widget to upload a file to your environment: from google.colab import files print(&#39;Please Upload your John Snow Labs License using the button below&#39;) license_keys = files.upload() And then do: nlp.install() 3. Starting an Enterprise NLP cluster Another one-liner can be used to start your Enterprise Spark NLP cluster: spark = nlp.start() It will take into account the previous steps and your license and return a Spark Session. 4. Ready to go! And you are done! Simple, isn’t it? Find hundreds of notebooks using johnsnowlabs library here: Finance NLP notebooks Legal NLP notebooks Clinical NLP notebooks Finance, Legal, Clinical NLP on Databricks List of tested runtimes. Recommended instance type Standard_F8s_v2 (16 GB Memory, 8 Cores) or higher. The installation takes around 15 minutes. Connection via Databricks Partner connect Databricks has an integration of Spark NLP libraries via Partner Connect. If you are eligible, you can connect your Databricks workspace to John Snow Labs. The Partner Connect wizard will redirect you to John Snow Labs portal. After you fill-in/validate your information a 30-day trial license will be automatically generated for you. A new Databricks cluster will also be created, and all necessary resources to run the library on your account will be installed on your new cluster. Furthermore, a set of ready to use notebooks will be copied to your workspace, so you can start experimenting on your data right away. The trial license file will also be deployed to your environment and made available to your cluster. The trial period is 30 days. You can use the trial period only once. After the trial period, we will contact you with a licensing offer. Start exploring preloaded notebooks Workspace -&gt; Shared -&gt; John Snow Labs Automatic deployment of John Snow Labs NLP libraries from www.johnsnowlabs.com/databricks Alternatively, you can automatically deploy John Snow Labs libraries on Databricks by filling in the form available here. This will allow you to start a 30-day free trial with no limit on the amount of processed data. You just need to provide a Databricks Access Token that is used by our deployment script to connect to your Databricks instance and install John Snow Labs NLP libraries on a cluster of your choice. Start exploring preloaded notebooks Workspace -&gt; Shared -&gt; John Snow Labs Automatic deployment via my.JohnSnowLabs.com Login to your account on my.JohnSnowLabs.com, navigate to ‘My Subscriptions’ page, and identify your license for Databricks. Click on the three dots as illustrated in the image below, then select the Install On Cluster option. On the install form, provide an access token for this account and then select the cluster where you want to install the libraries. Once it is done, you will get an email with information on the status of your deployment and on how to get started with the libraries. Automatic deployment or upgrade from the Databricks workspace If you have already deployed the libraries in the past, you have a script Workspace -&gt; Shared -&gt; John Snow Labs -&gt; Install JohnSnowLabs NLP. If you attach it to any cluster and run it, it will reinstall the libraries on the respective cluster. This is also the recommended way to upgrade to the latest versions of the libraries. Manual deployment of Enterprise Spark NLP Automatic deployment is the preferred option. Create a cluster with one of the supported runtimes if you don’t have one already. On a new cluster or existing one you need to add the following to the Advanced Options -&gt; Spark tab, in Spark.Config box: spark.kryoserializer.buffer.max 1000M spark.serializer org.apache.spark.serializer.KryoSerializer Please add the following to the Advanced Options -&gt; Spark tab, in Environment Variables box: AWS_ACCESS_KEY_ID=xxx AWS_SECRET_ACCESS_KEY=yyy SPARK_NLP_LICENSE=zzz Note: Enterprise Spark NLP also support reading the license from the Databricks DFS, on the fixed location, dbfs:/FileStore/johnsnowlabs/license.key. The precedence for that location is the highest, so make sure that file is not containing any outdated license key. (OPTIONAL) If the environment variables used to setup the AWS Access/Secret keys are conflicting with the credential provider chain in Databricks, you may not be able to access to other s3 buckets. To access both JSL repos with JSL AWS keys as well as your own s3 bucket with your own AWS keys), you need to use the following script, copy that to dbfs folder, then go to the Databricks console (init scripts menu) to add the init script for your cluster as follows: %scala val script = &quot;&quot;&quot; #!/bin/bash echo &quot;******** Inject Spark NLP AWS Profile Credentials ******** &quot; mkdir ~/.aws/ cat &lt;&lt; EOF &gt; ~/.aws/credentials [spark_nlp] aws_access_key_id=&lt;YOUR_AWS_ACCESS_KEY&gt; aws_secret_access_key=&lt;YOUR_AWS_SECRET_KEY&gt; EOF echo &quot;******** End Inject Spark NLP AWS Profile Credentials ******** &quot; &quot;&quot;&quot; In Libraries tab inside your cluster you need to follow these steps: Lookup the version of Healhcare NLP vs. Spark NLP you will install. Install Spark NLP (Public): New -&gt; PyPI -&gt; spark-nlp==${x.y.z_public_version} -&gt; Install Install: New -&gt; Maven -&gt; Coordinates -&gt; com.johnsnowlabs.nlp:spark-nlp_2.12:${x.y.z_public_version} -&gt; Install Please add following jars: Install: New -&gt; Python Whl -&gt; upload https://pypi.johnsnowlabs.com/${secret.code}/spark-nlp-jsl/spark_nlp_jsl-${x.y.z_healthcare_version}-py3-none-any.whl Install: New -&gt; Jar -&gt; upload https://pypi.johnsnowlabs.com/${secret.code}/spark-nlp-jsl-${x.y.z_healthcare_version}.jar (For Legal and Finance NLP) Install: New -&gt; PyPI -&gt; johnsnowlabs-for-databricks==${x.y.z_healthcare_version} -&gt; Install Now you can attach your notebook to the cluster and use Spark NLP! Windows Support In order to fully take advantage of Spark NLP on Windows (8 or 10), you need to setup/install Apache Spark, Apache Hadoop, Java and a Pyton environment correctly by following the following instructions: https://github.com/JohnSnowLabs/spark-nlp/discussions/1022 How to correctly install Spark NLP on Windows Follow the below steps to set up Spark NLP with Spark 3.1.2: Download Adopt OpenJDK 1.8 Make sure it is 64-bit Make sure you install it in the root of your main drive C: java. During installation after changing the path, select setting Path Download the pre-compiled Hadoop binaries winutils.exe, hadoop.dll and put it in a folder called C: hadoop bin from https://github.com/cdarlint/winutils/tree/master/hadoop-3.2.0/bin Note: The version above is for Spark 3.1.2, which was built for Hadoop 3.2.0. You might have to change the hadoop version in the link, depending on which Spark version you are using. Download Apache Spark 3.1.2 and extract it to C: spark. Set/add environment variables for HADOOP_HOME to C: hadoop and SPARK_HOME to C: spark. Add %HADOOP_HOME% bin and %SPARK_HOME% bin to the PATH environment variable. Install Microsoft Visual C++ 2010 Redistributed Package (x64). Create folders C: tmp and C: tmp hive If you encounter issues with permissions to these folders, you might need to change the permissions by running the following commands: %HADOOP_HOME% bin winutils.exe chmod 777 /tmp/hive %HADOOP_HOME% bin winutils.exe chmod 777 /tmp/ Requisites for PySpark We recommend using conda to manage your python environment on Windows. Download Miniconda for python 3.8 See Quick Install on how to set up a conda environment with Spark NLP. The following environment variables need to be set: PYSPARK_python=python Optionally, if you want to use the Jupyter Notebook runtime of Spark: first install it in the environment with conda install notebook then set PYSPARK_DRIVER_python=jupyter, PYSPARK_DRIVER_python_OPTS=notebook The environment variables can either be directly set in windows, or if only the conda env will be used, with conda env config vars set PYSPARK_python=python. After setting the variable with conda, you need to deactivate and re-activate the environment. Now you can use the downloaded binary by navigating to %SPARK_HOME% bin and running Either create a conda env for python 3.6, install pyspark==3.1.2 spark-nlp numpy and use Jupyter/python console, or in the same conda env you can go to spark bin for pyspark –packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.4. Windows Server Download and Install JAVA 8 i) Download and Install JAVA 8 from https://adoptium.net/temurin/releases/?version=8 ii) Once installed , We can check if java is installed by opening cmd and type java -version command Install Microsoft Visual C++ 2010 i) Install Microsoft Visual C++ 2010 from Microsoft Visual C++ 2010 Service Pack 1 Redistributable Package MFC Security Update Download the pre-compiled Hadoop binaries winutils.exe, hadoop.dll i) Download the pre-compiled Hadoop binaries winutils.exe, hadoop.dll from winutils/hadoop-3.2.0/bin at master · cdarlint/winutils ii) Copy files into a folder called C: hadoop bin Configure Hadoop ENV variables Windows Explorer → This PC -&gt; Right Click select properties -&gt; Click on Advanced system settings -&gt; Click on Environment Variables Under system variables Add HADOOP_HOME as below Under system variables -&gt; Click on new VARIABLE Name: HADOOP_HOME VARIABLE Value: C: hadoop Select the Path (from variable) -&gt; Click on edit → Click on New → add %HADOOP_HOME% bin Dowload and Install Conda and set Conda ENV variables i) Download Miniconda for python 3.8 from https://repo.anaconda.com/miniconda/Miniconda3-py38_4.11.0-Windows-x86_64.exe ii) Install miniconda exe file. iii) Under system variables -&gt; Select the Path (from variable) -&gt; Click on edit -&gt; (ADD the miniconda install location)/bin (Same steps as above) Configure conda env i) Open cmd and execute the following commands conda --version java -version conda create -n sparknlp python=3.8 -y conda activate sparknlp pip install spark-nlp==4.4.1 pyspark==3.1.2 pip install jupyter conda env config vars set PYSPARK_PYTHON=python conda activate sparknlp conda env config vars set PYSPARK_DRIVER_PYTHON=jupyter conda activate sparknlp conda env config vars set PYSPARK_DRIVER_python_OPTS=notebook conda activate sparknlp jupyter notebook Non-johnsnowlabs Clinical NLP on Ubuntu These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. For installing John Snow Labs NLP libraries on an Ubuntu machine/VM please run the following command: wget https://setup.johnsnowlabs.com/nlp/install.sh -O - | sudo bash -s -- -a PATH_TO_LICENSE_JSON_FILE -i -r This script will install Spark NLP, Enterprise Spark NLP, Spark OCR, NLU and Spark NLP Display on the specified virtual environment. It will also create a special folder, ./JohnSnowLabs, dedicated to all resources necessary for using the libraries. Under ./JohnSnowLabs/example_notebooks you will find some ready to use example notebooks that you can use to test the libraries on your data. For a complete step-by-step guide on how to install NLP Libraries check the video below: Install John Snow Labs NLP Libraries on Ubuntu The install script offers several options: -h show brief help -i install mode: create a virtual environment and install the library -r run mode: start jupyter after installation of the library -v path to virtual environment (default: ./sparknlp_env) -j path to license json file for Enterprise Spark NLP -o path to license json file for Spark OCR -a path to a single license json file for both Spark OCR and Spark NLP -s specify pyspark version -p specify port of jupyter notebook Use the -i flag for installing the libraries in a new virtual environment. You can provide the desired path for virtual env using -v flag, otherwise a default location of ./sparknlp_env will be selected. The PATH_TO_LICENSE_JSON_FILE parameter must be replaced with the path where the license file is available on the local machine. According to the libraries you want to use different flags are available: -j, -o or -a. The license files can be easily downloaded from My Subscription section in your my.JohnSnowLabs.com account. To start using Jupyter Notebook after the installation of the libraries use the -r flag. The install script downloads a couple of example notebooks that you can use to start experimenting with the libraries. Those will be availabe under ./JohnSnowLabs/example_notebooks folder. Non-johnsnowlabs Clinical NLP via Docker These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. A docker image that contains all the required libraries for installing and running Enterprise Spark NLP libraries is also available. However, it does not contain the library itself, as it is licensed, and requires installation credentials. Make sure you have a valid license for Enterprise Spark NLP libraries (in case you do not have one, you can ask for a trial here ), and follow the instructions below: Instructions Run the following commands to download the docker-compose.yml and the sparknlp_keys.txt files on your local machine: curl -o docker-compose.yaml https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/blob/513a4d682f11abc33b2e26ef8a9d72ad52a7b4f0/jupyter/docker_image_nlp_hc/docker-compose.yaml curl -o sparknlp_keys.txt https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/docker_image_nlp_hc/sparknlp_keys.txt Download your license key in json format from my.JohnSnowLabs.com Populate License keys in sparknlp_keys.txt file. Run the following command to run the container in detached mode: docker-compose up -d By default, the jupyter notebook runs on port 8888 - you can access it by typing localhost:8888 in your browser. Troubleshooting Make sure docker is installed on your system. If you face any error while importing the lib inside jupyter, make sure all the credentials are correct in the key files and restart the service again. If the default port 8888 is already occupied by another process, please change the mapping. You can change/adjust volume and port mapping in the docker-compose.yml file. You don’t have a license key? Ask for a trial license here. Non-johnsnowlabs Clinical NLP on python These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. You can install the Clinical NLP by using: pip install -q spark-nlp-jsl==${version} --extra-index-url https://pypi.johnsnowlabs.com/${secret.code} --upgrade {version} is the version part of the {secret.code} ({secret.code}.split(&#39;-&#39;)[0]) (i.e. 2.6.0) The {secret.code} is a secret code that is only available to users with valid/trial license. You can ask for a free trial for Enterprise Spark NLP libraries here. Then, you can obtain the secret code by visiting your account on my.JohnSnowLabs.com. Read more on how to get a license here. Setup AWS-CLI Credentials for licensed pretrained models You need to first set up your AWS credentials to be able to access the private repository for John Snow Labs Pretrained Models. You can do this setup via Amazon AWS Command Line Interface (AWSCLI). Instructions about how to install AWSCLI are available at: Installing the AWS CLI Make sure you configure your credentials with AWS configure following the instructions at: Configuring the AWS CLI Please substitute the ACCESS_KEY and SECRET_KEY with the credentials available on your license json file. This is available on your account from my.JohnSnowLabs.com. Read this for more information. Start Spark NLP Session from python The following will initialize the spark session in case you have run the Jupyter Notebook directly. If you have started the notebook using pyspark this cell is just ignored. Initializing the spark session takes some seconds (usually less than 1 minute) as the jar from the server needs to be loaded. The {secret.code} is a secret code that is only available to users with valid/trial license. You can ask for a free trial for Enterprise Spark NLP here. Then, you can obtain the secret code by visiting your account on my.JohnSnowLabs.com. Read more on how to get a license here. You can either use our convenience function to start your Spark Session that will use standard configuration arguments: import sparknlp_jsl spark = sparknlp_jsl.start(SECRET) Or use the SparkSession module for more flexibility: from pyspark.sql import SparkSession def start(SECRET): builder = SparkSession.builder .appName(&quot;Spark NLP Licensed&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;, &quot;16G&quot;) .config(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;) .config(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;) .config(&quot;spark.jars.packages&quot;, &quot;com.johnsnowlabs.nlp:spark-nlp_2.12:&quot;+PUBLIC_VERSION) .config(&quot;spark.jars&quot;, &quot;https://pypi.johnsnowlabs.com/&quot;+SECRET+&quot;/spark-nlp-jsl-&quot;+JSL_VERSION+&quot;.jar&quot;) return builder.getOrCreate() spark = start(SECRET) If you want to download the source files (jar and whl files) locally, you can follow the instructions here. Cheatsheet # Install Spark NLP from PyPI pip install spark-nlp==3.2.3 #install Spark NLP helathcare pip install spark-nlp-jsl==${version} --extra-index-url https://pypi.johnsnowlabs.com/${secret.code} --upgrade # Load Spark NLP with Spark Shell spark-shell --packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3 --jars spark-nlp-jsl-${version}.jar # Load Spark NLP with PySpark pyspark --packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3 --jars spark-nlp-jsl-${version}.jar # Load Spark NLP with Spark Submit spark-submit --packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3 --jars spark-nlp-jsl-${version}.jar Non-johnsnowlabs Clinical NLP for Scala These instructions use non-johnsnowlabs installation syntax, since johnsnowlabs is a Python library. Use Spark NLP in Spark shell 1.Download the fat jar for Enterprise Spark NLP aws s3 cp --region us-east-2 s3://pypi.johnsnowlabs.com/$jsl_secret/spark-nlp-jsl-$jsl_version.jar spark-nlp-jsl-$jsl_version.jar 2.Set up the Environment Variables box: AWS_ACCESS_KEY_ID=xxx AWS_SECRET_ACCESS_KEY=yyy SPARK_NLP_LICENSE=zzz 3.The preferred way to use the library when running Spark programs is using the --packagesand --jar option as specified in the spark-packages section. spark-shell --packages com.johnsnowlabs.nlp:spark-nlp_2.12:${public-version} --jars /spark-nlp-jsl-${version}.jar Non-johnsnowlabs Clinical NLP in Sbt project These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. 1.Download the fat jar for Enterprise Spark NLP. aws s3 cp --region us-east-2 s3://pypi.johnsnowlabs.com/$jsl_secret/spark-nlp-jsl-$jsl_version.jar spark-nlp-jsl-$jsl_version.jar 2.Set up the Environment Variables box: AWS_ACCESS_KEY_ID=xxx AWS_SECRET_ACCESS_KEY=yyy SPARK_NLP_LICENSE=zzz 3.Add the spark-nlp jar in your build.sbt project libraryDependencies += &quot;com.johnsnowlabs.nlp&quot; %% &quot;spark-nlp&quot; % &quot;{public-version}&quot; 4.You need to create the /lib folder and paste the spark-nlp-jsl-${version}.jar file. 5.Add the fat spark-nlp-healthcare in your classpath. You can do it by adding this line in your build.sbt unmanagedJars in Compile += file(&quot;lib/sparknlp-jsl.jar&quot;) Non-johnsnowlabs Clinical NLP on Colab This is the way to run Clinical NLP in Google Colab if you don’t use johnsnowlabs library. Run the following code in Google Colab notebook and start using Spark NLP right away. The first thing that you need is to create the json file with the credentials and the configuration in your local system. { &quot;PUBLIC_VERSION&quot;: &quot;3.2.3&quot;, &quot;JSL_VERSION&quot;: &quot;{version}&quot;, &quot;SECRET&quot;: &quot;{version}-{secret.code}&quot;, &quot;SPARK_NLP_LICENSE&quot;: &quot;xxxxx&quot;, &quot;AWS_ACCESS_KEY_ID&quot;: &quot;yyyy&quot;, &quot;AWS_SECRET_ACCESS_KEY&quot;: &quot;zzzz&quot; } If you have a valid floating license, the license json file can be downloaded from your account on my.JohnSnowLabs.com on My Subscriptions section. To get a trial license please visit Then you need to write that piece of code to load the credentials that you created before. import json import os from google.colab import files license_keys = files.upload() with open(list(license_keys.keys())[0]) as f: license_keys = json.load(f) # Defining license key-value pairs as local variables locals().update(license_keys) # Adding license key-value pairs to environment variables os.environ.update(license_keys) # This is only to setup PySpark and Spark NLP on Colab !wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jsl_colab_setup.sh # -p is for pyspark (by default 3.1.1) !bash jsl_colab_setup.sh Spark NLP quick start on Google Colab is a live demo on Google Colab that performs named entity recognitions for HealthCare. Non-johnsnowlabs Clinical NLP on GCP Dataproc These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. You can follow the steps here for installation via IU Create a cluster if you don’t have one already as follows. At gcloud shell: gcloud services enable dataproc.googleapis.com compute.googleapis.com storage-component.googleapis.com bigquery.googleapis.com bigquerystorage.googleapis.com REGION=&lt;region&gt; BUCKET_NAME=&lt;bucket_name&gt; gsutil mb -c standard -l ${REGION} gs://${BUCKET_NAME} REGION=&lt;region&gt; ZONE=&lt;zone&gt; CLUSTER_NAME=&lt;cluster_name&gt; BUCKET_NAME=&lt;bucket_name&gt; You can set image-version, master-machine-type, worker-machine-type, master-boot-disk-size, worker-boot-disk-size, num-workers as your needs. If you use the previous image-version from 2.0, you should also add ANACONDA to optional-components. And, you should enable gateway. As noticed below, you should explicitly write JSL_SECRET and JSL_VERSION at metadata param inside the quotes. This will start the pip installation using the wheel file of Licensed SparkNLP! gcloud dataproc clusters create ${CLUSTER_NAME} --region=${REGION} --network=${NETWORK} --zone=${ZONE} --image-version=2.0 --master-machine-type=n1-standard-4 --worker-machine-type=n1-standard-2 --master-boot-disk-size=128GB --worker-boot-disk-size=128GB --num-workers=2 --bucket=${BUCKET_NAME} --optional-components=JUPYTER --enable-component-gateway --metadata &#39;PIP_PACKAGES=google-cloud-bigquery google-cloud-storage spark-nlp-display https://s3.eu-west-1.amazonaws.com/pypi.johnsnowlabs.com/JSL_SECRET/spark-nlp-jsl/spark_nlp_jsl-JSL_VERSION-py3-none-any.whl&#39; --initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh On an existing one, you need to install spark-nlp and spark-nlp-display packages from PyPI. Now, you can attach your notebook to the cluster and use Spark NLP via following the instructions. The key part of this usage is how to start SparkNLP sessions using Apache Hadoop YARN cluster manager. 3.1. Read license file from the notebook using GCS. 3.2. Set the right path of the Java Home Path. 3.3. Use the start function to start the SparkNLP JSL version such as follows: def start(secret): builder = SparkSession.builder .appName(&quot;Spark NLP Licensed&quot;) .config(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;) .config(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;) .config(&quot;spark.jars.packages&quot;, &quot;com.johnsnowlabs.nlp:spark-nlp_2.12:&quot;+PUBLIC_VERSION) .config(&quot;spark.jars&quot;, &quot;https://pypi.johnsnowlabs.com/&quot;+SECRET+&quot;/spark-nlp-jsl-&quot;+JSL_VERSION+&quot;.jar&quot;) return builder.getOrCreate() spark = start(SECRET) As you see, we did not set .master(&#39;local[*]&#39;) explicitly to let YARN manage the cluster. Or you can set .master(&#39;yarn&#39;). Non-johnsnowlabs Clinical NLP on AWS SageMaker These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. Access AWS Sagemaker in AWS. Go to Notebook -&gt; Notebook Instances. Create a new Notebook Instance, follow this Instructions Steps Minimum requirement 16G RAM and 50G Volume. This is the configuration we have used, although most of the interesting models will require a ml.t3.xlarge instance or more. Reserve at least 50GB of memory Once created, open JupyterLab and use Conda python 3 kernel. Upload license key and set Environment Variables. import json import os with open(&#39;spark_nlp_for_healthcare.json&#39;, &#39;r&#39;) as f: for k, v in json.load(f).items(): %set_env $k=$v %set_env PYSPARK=3.2.2 %set_env SPARK_HOME=/home/ec2-user/SageMaker/spark-3.2.2-bin-hadoop2.7 Download and install libraries !wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jsl_sagemaker_setup.sh !bash jsl_sagemaker_setup.sh Import libraries and start session import sparknlp import sparknlp_jsl from pyspark.sql import SparkSession spark = sparknlp_jsl.start(license_keys[&#39;SECRET&#39;]) Non-johnsnowlabs Clinical NLP with Poetry These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. This is a sample project.toml file which you can use with poetry install to setup spark NLP + the Healthcare python library spark-nlp-jsl You need to point it to either the tar.gz or .whl file which are hosted at https://pypi.johnsnowlabs.com/&lt;SECRET&gt;/spark-nlp-jsl/ NOTE You must update the url whenever you are upgrading your spark-nlp-jsl version [tool.poetry] name = &quot;poertry_demo&quot; version = &quot;0.1.0&quot; description = &quot;&quot; authors = [&quot;person &lt;person@gmail.com&gt;&quot;] [tool.poetry.dependencies] python = &quot;^3.7&quot; [tool.poetry.dev-dependencies] spark-nlp = &quot;3.4.4&quot; spark-nlp-jsl = { url = &quot;https://pypi.johnsnowlabs.com/SECRET/spark-nlp-jsl/spark_nlp_jsl-tar.gz_OR_.whl&quot; } [build-system] requires = [&quot;poetry-core&gt;=1.0.0&quot;] build-backend = &quot;poetry.core.masonry.api&quot; Non-johnsnowlabs Clinical NLP on AWS EMR These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. In this page we explain how to setup Spark-NLP + Spark-NLP Healthcare in AWS EMR, using the AWS console. Steps You must go to the blue button “Create Cluster” on the UI. By doing that you will get directed to the “Create Cluster - Quick Options” page. Don’t use the quick options, click on “Go to advanced options” instead. Now in Advanced Options, on Step 1, “Software and Steps”, please pick the following selection in the checkboxes, Also in the “Edit Software Settings” page, enter the following, [{ &quot;Classification&quot;: &quot;spark-env&quot;, &quot;Configurations&quot;: [{ &quot;Classification&quot;: &quot;export&quot;, &quot;Properties&quot;: { &quot;PYSPARK_python&quot;: &quot;/usr/bin/python3&quot;, &quot;AWS_ACCESS_KEY_ID&quot;: &quot;XYXYXYXYXYXYXYXYXYXY&quot;, &quot;AWS_SECRET_ACCESS_KEY&quot;: &quot;XYXYXYXYXYXYXYXYXYXY&quot;, &quot;SPARK_NLP_LICENSE&quot;: &quot;XYXYXYXYXYXYXYXYXYXYXYXYXYXY&quot; } }] }, { &quot;Classification&quot;: &quot;spark-defaults&quot;, &quot;Properties&quot;: { &quot;spark.yarn.stagingDir&quot;: &quot;hdfs:///tmp&quot;, &quot;spark.yarn.preserve.staging.files&quot;: &quot;true&quot;, &quot;spark.kryoserializer.buffer.max&quot;: &quot;2000M&quot;, &quot;spark.serializer&quot;: &quot;org.apache.spark.serializer.KryoSerializer&quot;, &quot;spark.driver.maxResultSize&quot;: &quot;0&quot;, &quot;spark.driver.memory&quot;: &quot;32G&quot; } }] Make sure that you replace all the secret information(marked here as XYXYXYXYXY) by the appropriate values that you received with your license. In “Step 2” choose the hardware and networking configuration you prefer, or just pick the defaults. Move to next step by clocking the “Next” blue button. Now you are in “Step 3”, in which you assign a name to your cluster, and you can change the location of the cluster logs. If the location of the logs is OK for you, take note of the path so you can debug potential problems by using the logs. Still on “Step 3”, go to the bottom of the page, and expand the “Bootstrap Actions” tab. We’re gonna add an action to execute during bootstrap of the cluster. Select “Custom Action”, then press on “Configure and add”. You need to provide a path to a script on S3. The path needs to be public. Keep this in mind, no secret information can be contained there. The script we’ll used for this setup is emr_bootstrap.sh . This script will install Spark-NLP 3.1.0, and Spark-NLP Healthcare 3.1.1. You’ll have to edit the script if you need different versions. After you entered the route to S3 in which you place the emr_bootstrap.sh file, and before clicking “add” in the dialog box, you must pass an additional parameter containing the SECRET value you received with your license. Just paste the secret on the “Optional arguments” field in that dialog box. There’s not much additional setup you need to perform. So just start a notebook server, connect it to the cluster you just created(be patient, it takes a while), and test with the NLP_EMR_Setup.ipynb test notebook. Non-johnsnowlabs Clinical NLP on Amazon Linux 2 These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. # Update Package List &amp; Install Required Packages sudo yum update sudo yum install -y amazon-linux-extras sudo yum -y install python3-pip # Create python virtual environment and activate it: python3 -m venv .sparknlp-env source .sparknlp-env/bin/activate Check JAVA version: For Sparknlp versions above 3.x, please use JAVA-11 For Sparknlp versions below 3.x and SparkOCR, please use JAVA-8 Checking Java versions installed on your machine: sudo alternatives --config java You can pick the index number (I am using java-8 as default - index 2): If you dont have java-11 or java-8 in you system, you can easily install via: sudo yum install java-1.8.0-openjdk Now, we can start installing the required libraries: pip install jupyter We can start jupyter notebook via: jupyter notebook ### Now we are in the jupyter notebook cell: import json import os with open(&#39;sparknlp_for_healthcare.json) as f: license_keys = json.load(f) # Defining license key-value pairs as local variables locals().update(license_keys) # Adding license key-value pairs to environment variables os.environ.update(license_keys) # Installing pyspark and spark-nlp ! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION # Installing Spark NLP Healthcare ! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION --extra-index-url https://pypi.johnsnowlabs.com/$SECRET Deploying Spark NLP Healthcare on Kubernetes This guide will walk you through the deployment of a Spark NLP Healthcare application on a Kubernetes cluster using kind. Prerequisites Installing Necessary Tools: Docker: Install from Docker Desktop(https://www.docker.com/products/docker-desktop/). Ensure Kubernetes is enabled in Docker Desktop settings. kubectl: Install using the instructions from Kubernetes official documentation(https://kubernetes.io/docs/tasks/tools/). kind: Install using the instructions from Kubernetes official documentation(https://kubernetes.io/docs/tasks/tools/). Docker Hub Account: If you don’t have one, create your account at Docker Hub(https://hub.docker.com/signup). Install JohnSnow Labs licence key file to the project directory(https://my.johnsnowlabs.com/subscriptions). Project Structure: . ├── Dockerfile ├── main.py ├── README.md ├── requirements.txt ├── spark-nlp-healthcare-deployment.yaml └── spark_nlp_for_healthcare_spark_ocr_8204.json (licence key filename) Application Details The main application script, main.py, is as follows: from johnsnowlabs import nlp, medical import pandas as pd from pyspark.sql import DataFrame import pyspark.sql.functions as F import pyspark.sql.types as T import pyspark.sql as SQL from pyspark import keyword_only from pyspark.ml import PipelineModel import os class NLPProcessor: def __init__(self): &quot;&quot;&quot;Initialize and set up NLP tools.&quot;&quot;&quot; # Install all licensed Python Wheels and pre-download Jars the Spark Session JVM nlp.install() # Automatically load license data and start a session with all jars user has access to self.spark = nlp.start() # Set up the NLP pipeline self.model = self.setup_pipeline() def setup_pipeline(self): &quot;&quot;&quot;Set up the NLP pipeline using John Snow Labs library.&quot;&quot;&quot; # Annotator that transforms a text column from dataframe into an Annotation ready for NLP documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) # Sentence detector specific to healthcare data sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) # Tokenizer splits words in a relevant format for NLP tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) # Clinical word embeddings trained on PubMED dataset word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # NER model trained on i2b2 (sampled from MIMIC) dataset jsl_ner = medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;jsl_ner&quot;) # Converter to transform NER results jsl_ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;]) .setOutputCol(&quot;jsl_ner_chunk&quot;) # Combine all the stages of the pipeline nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, jsl_ner, jsl_ner_converter ]) # Fit an empty dataframe to initialize the pipeline return nlpPipeline.fit(self.spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) def annotate_text(self, text): &quot;&quot;&quot;Annotate the provided text using the NLP pipeline.&quot;&quot;&quot; light_model = nlp.LightPipeline(self.model) return light_model.annotate(text) def main(): &quot;&quot;&quot;Main function to run the NLP annotation.&quot;&quot;&quot; processor = NLPProcessor() sample_text = &#39;&#39;&#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM )&#39;&#39;&#39; result = processor.annotate_text(sample_text) print(result) if __name__ == &quot;__main__&quot;: main() Step-by-step Guide 1. Containerizing the Spark NLP Healthcare Application Dockerfile: # Use Ubuntu 20.04 as the base image FROM ubuntu:20.04 # Update and install necessary packages RUN apt-get update &amp;&amp; DEBIAN_FRONTEND=noninteractive apt-get install -y openjdk-8-jdk python3-pip curl # Set JAVA_HOME ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64/ # Copy the base requirements and main application into the image COPY requirements.txt /app/requirements.txt COPY &lt;licence_filename&gt; /app/&lt;licence_filename&gt; WORKDIR /app # Install Python packages RUN pip3 install -r requirements.txt # Copy the main application COPY main.py /app/main.py CMD [&quot;python3&quot;, &quot;main.py&quot;] Note: Before building the Docker image, replace in the Dockerfile with your actual Spark NLP Healthcare license key file name and set to the appropriate version number (e.g., 5.0.1). You can find the value in your licence key json file. Logging in to Docker Hub: Run the command:docker login -u &lt;your-docker-hub-username&gt; -p &lt;your-docker-hub-password&gt; This will authenticate you with Docker Hub, allowing you to push and pull private images. Build the Docker image with the specific tag: docker build -t &lt;your-docker-hub-username&gt;/spark-nlp-healthcare:&lt;JSL_VERSION&gt; . 2. Pushing Docker Image to Docker Hub Tag the image with your Docker Hub username: docker tag spark-nlp-healthcare:&lt;JSL_VERSION&gt; &lt;your-docker-hub-username&gt;/spark-nlp-healthcare:&lt;JSL_VERSION&gt; Push the image to Docker Hub: docker push &lt;your-docker-hub-username&gt;/spark-nlp-healthcare:&lt;JSL_VERSION&gt; 3. Setting Up the Kubernetes Cluster with kind Before deploying the application, you’ll need to set up a local Kubernetes cluster using kind. Run the following command: kind create cluster 4. Setting up Secrets in Kubernetes Make sure your Spark NLP Healthcare license key file (e.g., ) is present in the project directory. Replace with your actual license key file name in the below command: kubectl create secret generic spark-nlp-healthcare-secret --from-file=license=&lt;licence_filename&gt; 5. Deploying the Spark NLP Healthcare Application Before proceeding, ensure that you replace the placeholders and in the spark-nlp-healthcare-deployment.yaml with your Docker Hub username and the appropriate Spark NLP version respectively. Use the following content for spark-nlp-healthcare-deployment.yaml: apiVersion: apps/v1 kind: Deployment metadata: name: spark-nlp-healthcare-deployment spec: replicas: 1 selector: matchLabels: app: spark-nlp-healthcare template: metadata: labels: app: spark-nlp-healthcare spec: containers: - name: spark-nlp-healthcare image: &lt;your-docker-hub-username&gt;/spark-nlp-healthcare:&lt;JSL_VERSION&gt; ports: - containerPort: 8888 env: - name: SPARK_NLP_LICENSE valueFrom: secretKeyRef: name: spark-nlp-healthcare-secret key: license Apply the deployment: kubectl apply -f spark-nlp-healthcare-deployment.yaml To verify, run commands below: kubectl get deployments kubectl get pods The output will look like as following; kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE spark-nlp-healthcare-deployment 0/1 1 0 2m42s kubectl get pods NAME READY STATUS RESTARTS AGE spark-nlp-healthcare-deployment-7fc4c6b4ff-rdj97 0/1 ContainerCreating 0 2m50s Wait until the output becomes as following; kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE spark-nlp-healthcare-deployment 1/1 1 1 8m46s kubectl get pods NAME READY STATUS RESTARTS AGE spark-nlp-healthcare-deployment-7fc4c6b4ff-rdj97 1/1 Running 0 8m54s Now the pod is ready and running. 6. Validating the Deployment To get the name of the pod: kubectl get pods -l app=spark-nlp-healthcare -o jsonpath=&quot;{.items[0].metadata.name}&quot; You can verify if the application is running properly within the Kubernetes cluster by executing a shell within the pod: kubectl exec -it &lt;kubernetes_pod_name&gt; -- /bin/bash This command will open a bash shell and the program can be run with python3 main.py command. It will output the following; [OK!] {&#39;document&#39;: [&#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM )&#39;], &#39;jsl_ner_chunk&#39;: [&#39;28-year-old&#39;, &#39;female&#39;, &#39;gestational diabetes mellitus&#39;, &#39;eight years prior&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;], &#39;jsl_ner&#39;: [&#39;O&#39;, &#39;B-Age&#39;, &#39;B-Gender&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-Diabetes&#39;, &#39;I-Diabetes&#39;, &#39;I-Diabetes&#39;, &#39;O&#39;, &#39;B-RelativeDate&#39;, &#39;I-RelativeDate&#39;, &#39;I-RelativeDate&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-Diabetes&#39;, &#39;I-Diabetes&#39;, &#39;I-Diabetes&#39;, &#39;I-Diabetes&#39;, &#39;O&#39;, &#39;B-Diabetes&#39;, &#39;O&#39;], &#39;token&#39;: [&#39;A&#39;, &#39;28-year-old&#39;, &#39;female&#39;, &#39;with&#39;, &#39;a&#39;, &#39;history&#39;, &#39;of&#39;, &#39;gestational&#39;, &#39;diabetes&#39;, &#39;mellitus&#39;, &#39;diagnosed&#39;, &#39;eight&#39;, &#39;years&#39;, &#39;prior&#39;, &#39;to&#39;, &#39;presentation&#39;, &#39;and&#39;, &#39;subsequent&#39;, &#39;type&#39;, &#39;two&#39;, &#39;diabetes&#39;, &#39;mellitus&#39;, &#39;(&#39;, &#39;T2DM&#39;, &#39;)&#39;], &#39;embeddings&#39;: [&#39;A&#39;, &#39;28-year-old&#39;, &#39;female&#39;, &#39;with&#39;, &#39;a&#39;, &#39;history&#39;, &#39;of&#39;, &#39;gestational&#39;, &#39;diabetes&#39;, &#39;mellitus&#39;, &#39;diagnosed&#39;, &#39;eight&#39;, &#39;years&#39;, &#39;prior&#39;, &#39;to&#39;, &#39;presentation&#39;, &#39;and&#39;, &#39;subsequent&#39;, &#39;type&#39;, &#39;two&#39;, &#39;diabetes&#39;, &#39;mellitus&#39;, &#39;(&#39;, &#39;T2DM&#39;, &#39;)&#39;], &#39;sentence&#39;: [&#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM )&#39;]} If you have any questions or face any issues during the deployment process, please feel free to reach out to me at burhan@johnsnowlabs.com. I’m here to help! Fancy trying? You can ask for a free trial for Enterprise Spark NLP here. This will automatically create a new account for you on my.JohnSnowLabs.com. Login in to your new account and from My Subscriptions section, you can download your license key as a json file. The license json file contains: the secrets for installing the Enterprise Spark NLP and Spark OCR libraries, the license key as well as AWS credentials that you need to access the s3 bucket where the healthcare models and pipelines are published. If you have asked for a trial license, but you cannot access your account on my.JohnSnowLabs.com and you did not receive the license information via email, please contact us at support@johnsnowlabs.com. Azure Synapse Analytics Support Step 1: Sign in to Azure portal Sign in to the Azure portal at https://portal.azure.com. Step 2: Create a new Resource Group On the left-hand menu, click on “Resource groups”. In the new window, click “Create”. Provide a unique name for the Resource Group and select the Region where you want to create it. Click “Review + Create” and then “Create”. Step 3: Create a Storage Account On the left-hand menu, click on “Create a resource”. In the “New” window, search for “Storage Account”. In the search results, select “Storage Account” and then click “Create”. In the new window, select the Resource Group you just created, provide a unique name for your Storage Account, and select the Region. Select the Performance, Account kind, Replication, and Access tier according to your requirements. Click “Review + Create” and then “Create”. Step 4: Create a Synapse workspace On the left-hand menu, click on “Create a resource”. In the “New” window, search for “Azure Synapse Analytics”. In the search results, select “Azure Synapse Analytics” and then click “Create”. In the new window, select the Resource Group you just created, provide a unique name for your Synapse Workspace, select the Region, and provide the Storage Account you created earlier. You also need to create a new file system in your storage account for Synapse workspace, provide a unique name for it. Fill the Security &amp; networking details as per your requirements. Click “Review + Create” and then “Create”. Step 5: Configuring the Synapse Studio Once your workspace is created, open the Azure Synapse Studio. Navigate to the “Manage” section within Azure Synapse Studio. Under the “Workspace settings” section, find and select “Workspace Packages”. Click “Upload” to upload the necessary JAR and wheel files. For running licensed models, navigate to the “Apache Spark configurations” under the “Manage” section. Click on “New” to add a new configuration. For licensed Healthcare models, Add the following properties: spark.hadoop.fs.s3a.access.key : spark.hadoop.fs.s3a.secret.key : spark.yarn.appMasterEnv.SPARK_NLP_LICENSE : After adding these properties, the Apache Spark configuration is ready. Navigate to “Apache Spark pools” under the “Analytics pools” section. Click on “New” to create a new Spark pool. Configure the pool settings as required, selecting a “Medium” Node size under “Performance Settings”. Under “Additional settings”, allow “session level packages”. Add the Apache Spark configuration created above (this is needed for licensed models only). Review your settings, then click “Create”. Navigate to the “Develop” section in Azure Synapse Studio. Create a new notebook or import an existing one. Attach the notebook to the Apache Spark pool created above. Now, all the necessary licenses and JARs are ready to be used. You can proceed to run your notebook. For running OCR models, upload the following JAR and wheel files to the Workspace packages. For licensed OCR models, Add the following properties: spark.hadoop.fs.s3a.access.key : spark.hadoop.fs.s3a.secret.key : spark.yarn.appMasterEnv.SPARK_OCR_LICENSE : spark.driver.extraJavaOptions : -Dorg.fluentd.logger.sender.NullSender=org.fluentd.logger.sender.NullSender spark.executor.extraJavaOptions : -Dorg.fluentd.logger.sender.NullSender=org.fluentd.logger.sender.NullSender spark.sql.legacy.allowUntypedScalaUDF : True Now, you can proceed to run your OCR models and notebooks.",
    "url": "/docs/en/licensed_install",
    "relUrl": "/docs/en/licensed_install"
  },
  "1257": {
    "id": "1257",
    "title": "Licensed Models",
    "content": "Pretrained Models We are currently in the process of moving the pretrained models and pipelines to a Model Hub that you can explore here: Models Hub",
    "url": "/docs/en/licensed_models",
    "relUrl": "/docs/en/licensed_models"
  },
  "1258": {
    "id": "1258",
    "title": "Spark NLP for Healthcare Release Notes",
    "content": "5.1.0 Highlights We are delighted to announce remarkable enhancements and updates in our latest release of Spark NLP for Healthcare. This release comes with the first clinical NER models in 5 new languages as well as 22 new clinical pretrained models and pipelines. 5 new clinical NER models for extracting clinical entities in the French, Italian, Polish, Spanish, and Turkish languages Introducing the pretrained ContextualParserModel to allow saving &amp; loading rule based NER models and releasing the first date-of-birth NER model 3 new text classification models for classifying complaints and positive emotions in clinical texts 6 new augmented NER models by leveraging the capabilities of the LangTest library to significantly boost their robustness Improved the RelationExtractionModel annotator by enabling the selection of single or multiple labels in outputs and providing customizable feature scaling techniques Improved consistency of names during the deidentification process, regardless of variations in casing or altered token sequences Enhancing Text2SQL with custom schemas and releasing the first pretrained zero-shot Text2SQL Model for single tables. Enhancements in Text2SQL: tableLimit and postProcessingSubstitutions parameters, and expanded variable support Revamped the method names within the ocr_nlp_processor module and incorporated functionality to create colorful overlay bands using RGB codes over identified entities Various core improvements; bug fixes, enhanced overall robustness and reliability of Spark NLP for Healthcare The option to remove scope window constraints in the AssertionDLModel is now accessible by setting it to [-1, -1], default is [9, 15] Updated notebooks Updated Contextual Parser Rule Based NER Notebook with new CP model example Updated Spark OCR Utility Module Notebook with the new updates in ocr_nlp_processor module Updated Text To SQL Generation Notebook with new single tables model New demos New Multi-Language Clinical NER Demo New ASSERTION_SDOH Demo New ASSERTION_VOP Demo New TEXT2SQL Demo New CLASSIFICATION LITCOVID Demo New PATIENT COMPLAINT CLASSIFICATION Demo Updated Age Group Classification Demo The addition and update of numerous new clinical models and pipelines continue to reinforce our offering in the healthcare domain These enhancements will elevate your experience with Spark NLP for Healthcare, enabling more efficient, accurate, and streamlined analysis of healthcare-related natural language data. 5 New Clinical NER Models for Extracting Clinical Entities in the French, Italian, Polish, Spanish, and Turkish languages 5 new Clinical NER models provide valuable tools for processing and analyzing multi-language clinical texts. They assist in automating the extraction of important clinical information, facilitating research, medical documentation, and other applications within the multi-language healthcare domain. Model Name Lang Predicted Entities Language ner_clinical PROBLEM TEST TREATMENT es ner_clinical PROBLEM TEST TREATMENT fr ner_clinical PROBLEM TEST TREATMENT it ner_clinical PROBLEM TEST TREATMENT pl ner_clinical PROBLEM TEST TREATMENT tr Example: ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;tr&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;&quot;&quot;Hasta sıcak ve soğuk yiyecekler yerken diş hassasiyetinden şikayetçiydi. Olası çürük veya diş kökü problemlerini değerlendirmek için klinik ve radyografik muayene yapıldı ve diş köküne yakın bir boşluk tespit edildi. Sorunu gidermek için restoratif tedavi uygulandı.&quot;&quot;&quot; Result: chunk begin end ner_label soğuk yiyecekler yerken diş hassasiyeti 18 56 PROBLEM radyografik muayene 144 162 TEST restoratif tedavi 234 250 TREATMENT Please check: Multi-Language Clinical NER Demo Introducing the Pretrained ContextualParserModel to Allow Saving &amp; Loading Rule Based NER Models and Releasing the First Date-of-Birth NER Model Now you can save your ContextualParserModel models without exposing &amp; sharing the rule sets and load back later on. We also release the first pretrained ContextualParserModel that can extract date-of-birth (DOB) entities in clinical texts. Example: dob_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_birth_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;chunk_dob&quot;) text = &quot;&quot;&quot; Record date : 2081-01-04 DB : 11.04.1962 DT : 12-03-1978 DOD : 10.25.23 SOCIAL HISTORY: She was born on Nov 04, 1962 in London and got married on 04/05/1979. When she got pregnant on 15 May 1079, the doctor wanted to verify her DOB was November 4, 1962. Her date of birth was confirmed to be 11-04-1962, the patient is 45 years old on 25 Sep 2007. PROCEDURES: Patient was evaluated on 1988-03-15 for allergies. She was seen by the endocrinology service and she was discharged on 9/23/1988. MEDICATIONS 1. Coumadin 1 mg daily. Last INR was on August 14, 2007, and her INR was 2.3.&quot;&quot;&quot; Result: sentence_id chunk begin end ner_label 1 11.04.1962 32 41 DOB 3 Nov 04, 1962 109 120 DOB 4 November 4, 1962 241 256 DOB 5 11-04-1962 297 306 DOB please check: Model Card and Contextual Parser Rule Based NER Notebook for more information 3 New Text Classification Models for Classifying Complaints and Positive Emotions in Clinical Texts Introducing three novel text classification models tailored for healthcare contexts, specifically designed to differentiate between expressions of Complaint – characterized by negative or critical language reflecting dissatisfaction with healthcare experiences – and No_Complaint – denoting positive or neutral sentiments without any critical elements. These models offer enhanced insights into patient feedback and emotions within the healthcare domain. Model Name Predicted Entities Annotator few_shot_classifier_patient_complaint_sbiobert_cased_mli Complaint No_Complaint FewShotClassifierModel bert_sequence_classifier_patient_complaint Complaint, No_Complaint MedicalBertForSequenceClassification genericclassifier_patient_complaint_sbiobert_cased_mli Complaint No_Complaint GenericClassifierModel Example: sequenceClassifier = MedicalBertForSequenceClassification .pretrained(&quot;bert_sequence_classifier_patient_complaint&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&#39;token&#39;]) .setOutputCol(&quot;prediction&quot;) sample_text = [ [&quot;&quot;&quot;The Medical Center is a large state of the art hospital facility with great doctors, nurses, technicians and receptionists. Service is top notch, knowledgeable and friendly. This hospital site has plenty of parking&quot;&quot;&quot;], [&quot;&quot;&quot;My gf dad wasn’t feeling well so we decided to take him to this place cus it’s his insurance and we waited for a while and mind that my girl dad couldn’t breath good while the staff seem not to care and when they got to us they said they we’re gonna a take some blood samples and they made us wait again and to see the staff workers talking to each other and laughing taking there time and not seeming to care about there patience, while we were in the lobby there was another guy who told us they also made him wait while he can hardly breath and they left him there to wait my girl dad is coughing and not doing better and when the lady came in my girl dad didn’t have his shirt because he was hot and the lady came in said put on his shirt on and then left still waiting to get help rn&quot;&quot;&quot;] ] Result: text result The Medical Center is a large state of the art hospital facility with great doctors, nurses, technicians and receptionists. Service is top notch, … No_Complaint My gf dad wasn’t feeling well so we decided to take him to this place cus it’s his insurance and we waited for a while and mind that my girl dad co… Complaint 6 New Augmented NER Models by Leveraging the Capabilities of the LangTest Library to Significantly Boost Their Robustness Newly introduced augmented NER models namely ner_events_clinical_langtest, ner_oncology_anatomy_general_langtest, ner_oncology_anatomy_granular_langtest, ner_oncology_demographics_langtest, ner_oncology_posology_langtest, and ner_oncology_response_to_treatment_langtest are powered by the innovative LangTest library. This cutting-edge NLP toolkit is at the forefront of language processing advancements, incorporating state-of-the-art techniques and algorithms to enhance the capabilities of our models significantly. These models are strengthened against various perturbations (lowercase, uppercase, titlecase, punctuation removal, etc.), and the previous and new robustness scores are presented below model names original robustness new robustness ner_oncology_anatomy_granular_langtest 0.79 0.89 ner_oncology_response_to_treatment_langtest 0.76 0.90 ner_oncology_demographics_langtest 0.81 0.95 ner_oncology_anatomy_general_langtest 0.79 0.81 ner_oncology_posology_langtest 0.74 0.85 ner_events_clinical_langtest 0.71 0.80 Example: clinical_ner = MedicalNerModel.pretrained(&quot;ner_events_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;The patient presented to the emergency room last evening&quot; Result: chunk ner_label presented EVIDENTIAL the emergency room CLINICAL_DEPT last evening DATE Improved the RelationExtractionModel Annotator by Enabling the Selection of Single or Multiple Labels in Outputs and Providing Customizable Feature Scaling Techniques The RelationExtractionModel annotator is now equipped with the setMultiClass() method, which provides the option to specify whether the model should return only the label with the highest confidence score or include all labels in its output. Furthermore, the model offers the setFeatureScaling() method, granting the ability to apply different feature scaling techniques such as zscore, minmax or empty (no scaling). setFeatureScaling Example: reModel = RelationExtractionModel.pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(10) .setRelationPairs([&quot;drug-ade, ade-drug&quot;]) .setFeatureScaling(&quot;zscore&quot;) # or minmax text = &quot;I experienced fatigue, aggression, and sadness after taking Lipitor but no more adverse after passing Zocor.&quot; Result: index chunk1 entity1 chunk2 entity2 relation zscore minmax 0 fatigue ADE Lipitor DRUG 0 0.9964 0.9983 1 Zocor DRUG fatigue ADE 0 0.9884 0.9341 2 aggression ADE Lipitor DRUG 1 0.6123 0.9999 3 Zocor DRUG aggression ADE 0 0.9972 0.9833 4 sadness ADE Lipitor DRUG 1 0.9999 0.9644 5 Zocor DRUG sadness ADE 1 0.9080 0.9644 setFeatureScaling Example: reModel = RelationExtractionModel.pretrained(&quot;re_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(10) .setRelationPairs([&quot;problem-test&quot;, &quot;problem-treatment&quot;]) .setMultiClass(True) # or Default value is False text = &quot;&quot;&quot; A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation, associated with obesity with a body mass index ( BMI ) of 33.5 kg/m2 . &quot;&quot;&quot; setMultiClass(False) Result: chunk1 entity1 chunk2 entity2 relation confidence gestational diabetes mellitus PROBLEM BMI TEST TeRP 1.0 setMultiClass(True) Result: | chunk1 | entity1 | chunk2 | entity2 | relation | confidence | |——————————-|———|——–|———|———-|————| | gestational diabetes mellitus | PROBLEM | BMI | TEST | TeRP | TeRP_confidence: 1.0 TrCP_confidence: 0.0, TeCP_confidence: 2.36E-35 TrAP_confidence: 8.85E-32 TrWP_confidence: 1.16E-34 TrNAP_confidence: 0.0 TrIP_confidence: 0.0 PIP_confidence: 1.87E-28 O_confidence: 9.56E-13 | Improved Consistency of Names During the Deidentification Process, Regardless of Variations in Casing or Altered Token Sequences The Deidentification annotator maintains consistent name handling in its obfuscation mode, even when the same name appears in different formats, such as varying casing or altered token orders. This ensures that names remain consistently protected regardless of their presentation within the text. Example: deidentification = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) sample_text = &quot;&quot;&quot;Patient Name: SULLAVAN, John K, MRN: 123456 SULLAVAN, JOHN K, Male, 05/09/1985 John K Sullavan is 25 years old patient has heavy back pain started from last week. &quot;&quot;&quot; Results: sentence masked deidentified Patient Name: SULLAVAN, John K, MRN: 123456 Patient Name: &lt;PATIENT&gt; MRN: &lt;MEDICALRECORD&gt; Patient Name: Viviann Spare MRN: 376947 SULLAVAN, JOHN K, Male, 05/09/1985 &lt;PATIENT&gt;, Male, &lt;DATE&gt; Viviann Spare, Male, &lt;DATE&gt; John K Sullavan is 25 years old patient has heavy back pain started from last week. &lt;PATIENT&gt; is &lt;AGE&gt; years old patient has heavy back pain started from last week. Viviann Spare is 20 years old patient has heavy back pain started from last week. Enhancing Text2SQL with Custom Schemas and Releasing the First Pretrained Zero-Shot Text2SQL Model for Single Tables. Utilizing text2sql_with_schema_single_table to generate SQL queries from natural language queries and custom database schemas featuring single tables. Powered by a large-scale finetuned language model developed by John Snow Labs on single-table schema data Example: query_schema = {&quot;patient&quot;: [&quot;ID&quot;,&quot;Name&quot;,&quot;Age&quot;,&quot;Gender&quot;,&quot;BloodType&quot;,&quot;Weight&quot;,&quot;Height&quot;,&quot;Address&quot;,&quot;Email&quot;,&quot;Phone&quot;] } text2sql_with_schema_single_table = Text2SQL.pretrained(&quot;text2sql_with_schema_single_table&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setMaxNewTokens(200) .setSchema(query_schema) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sql_query&quot;) sample_text = &quot;&quot;&quot; Calculate the average age of patients with blood type &#39;A-&#39; &quot;&quot;&quot; Results: SELECT AVG(Age) FROM patient WHERE BloodType = &quot;A-&quot; please check: Model Card and Text To SQL Generation Notebook for more information Enhancements in Text2SQL: tableLimit and postProcessingSubstitutions Parameters, and Expanded Variable Support You can use the following code to replace particular strings with other strings in the generated sequence: text2sql_with_schema_single_table.setPostProcessingSubstitutions({ &#39;greater than&#39;: &#39;&gt;&#39;, &#39;not equal to&#39;: &#39;&lt;&gt;&#39;, &#39;less than or equal to&#39;: &#39;&lt;=&#39;, &#39;superior&#39;: &#39;&gt;&#39;, &#39;inferior&#39;: &#39;&lt;&#39;, &#39;greater than or equal to&#39;: &#39;&gt;=&#39;, &#39;inferior or equal&#39;: &#39;&lt;=&#39;, &#39;superior or equal&#39;: &#39;&gt;=&#39;, &#39;equal to&#39;: &#39;=&#39;, &#39;less than&#39;: &#39;&lt;&#39; }) Variables which can be used in the prompt template: &quot;{tables_list}&quot;: comma separated list of tables &quot;{tables}&quot;: comma separated list of tables with column names &quot;{table1_name}&quot;, &quot;{table2_name}&quot;, ... names of particular tables. &quot;{table1_columns}&quot;, &quot;{table2_columns}&quot;, ... comma separated lists of columns in particular tables. see Text To SQL Generation Notebook for more information Revamped the Method Names Within the ocr_nlp_processor Module and Incorporated Functionality to Create Colorful Overlay Bands Using RGB Codes Over Identified Entities We’ve modified the method names in the ocr_nlp_processor module and introduced the capability to specify RGB codes for overlaying colorful bands on entities. This allows improved readability for color-blind individuals when viewing deidentified PDF files if you set it box_color = (115, 203, 235) (“115” Red, “203” Green, “235” Blue). ocr_nlp_processor Methods: Previous Now black_band colored_box colored_box bounding_box highlight highlight Example: from sparknlp_jsl.utils.ocr_nlp_processor import ocr_entity_processor ocr_entity_processor(spark=spark, file_path = path, ner_pipeline = nlp_model, chunk_col = &quot;merged_chunk&quot;, style = box, save_dir = &quot;deidentified_pdfs&quot;, box_color= (115, 235, 255), label= True, label_color = &quot;red&quot;, resolution=100, display_result = True) Various Core Improvements; Bug Fixes, Enhanced Overall Robustness and Reliability of Spark NLP for Healthcare The option to remove scope window constraints in the AssertionDLModel is now accessible by setting it to [-1, -1], default is [9, 15] Updated Notebooks And Demonstrations For making Spark NLP For Healthcare Easier To Navigate And Understand Updated Contextual Parser Rule Based NER Notebook with new CP model example Updated Spark OCR Utility Module Notebook with the new updates in ocr_nlp_processor module Updated Text To SQL Generation Notebook with new single tables model New Multi-Language Clinical NER Demo New Social Determinants of Health Assertion Demo New Voice of Patients Assertion Demo New TEXT2SQL Demo New CLASSIFICATION LITCOVID Demo New PATIENT COMPLAINT CLASSIFICATION Demo Updated Age Group Classification Demo We Have Added And Updated A Substantial Number Of New Clinical Models And Pipelines, Further Solidifying Our Offering In The Healthcare Domain. date_of_birth_parser ner_clinical -&gt; es ner_clinical -&gt; fr ner_clinical -&gt; it ner_clinical -&gt; pl ner_clinical -&gt; tr bert_sequence_classifier_patient_complaint genericclassifier_patient_complaint_sbiobert_cased_mli few_shot_classifier_patient_complaint_sbiobert_cased_mli ner_events_clinical_langtest ner_oncology_anatomy_general_langtest ner_oncology_anatomy_granular_langtest ner_oncology_demographics_langtest ner_oncology_posology_langtest ner_oncology_response_to_treatment_langtest ner_clinical_pipeline -&gt; es ner_clinical_pipeline -&gt; fr ner_clinical_pipeline -&gt; it ner_clinical_pipeline -&gt; nl ner_clinical_pipeline -&gt; pl ner_clinical_pipeline -&gt; pt ner_clinical_pipeline -&gt; tr For all Spark NLP for Healthcare models, please check: Models Hub Page Previous versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/licensed_release_notes",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/licensed_release_notes"
  },
  "1259": {
    "id": "1259",
    "title": "Serving Spark NLP&#58 MLFlow on Databricks",
    "content": "This is the first article of the “Serving Spark NLP via API” series, showcasing how to serve Spark NLP using Databricks Jobs and MLFlow Serve APIs. Don’t forget to check the other articles in this series, namely: How to serve Spark NLP using Microsoft Synapse ML, available here. How to server Spark NLP using FastAPI and LightPipelines, available here. Background Spark NLP is a Natural Language Understanding Library built on top of Apache Spark, leveranging Spark MLLib pipelines, that allows you to run NLP models at scale, including SOTA Transformers. Therefore, it’s the only production-ready NLP platform that allows you to go from a simple PoC on 1 driver node, to scale to multiple nodes in a cluster, to process big amounts of data, in a matter of minutes. Before starting, if you want to know more about all the advantages of using Spark NLP (as the ability to work at scale on air-gapped environments, for instance) we recommend you to take a look at the following resources: John Snow Labs webpage; The official technical documentation of Spark NLP; Spark NLP channel on Medium; Also, follow Veysel Kocaman, Data Scientist Lead and Head of Spark NLP for Healthcare, for the latests tips. Motivation Spark NLP is server-agnostic, what means it does not come with an integrated API server, but offers a lot of options to serve NLP models using Rest APIs. There is a wide range of possibilities to add a web server and serve Spark NLP pipelines using RestAPI, and in this series of articles we are only describing some of them. Let’s have an overview of how to use Databricks Jobs API and MLFlow Serve as an example for that purpose. Databricks Jobs and MLFlow Serve APIs About Databricks Databricks is an enterprise software company founded by the creators of Apache Spark. The company has also created MLflow, the Serialization and Experiment tracking library you can use (inside or outside databricks), as described in the section “Experiment Tracking”. Databricks develops a web-based platform for working with Spark, that provides automated cluster management and IPython-style notebooks. Their infrastructured is provided for training and production purposes, and is integrated in cloud platforms as Azure and AWS. Spark NLP is a proud partner of Databricks and we offer a seamless integration with them — see Install on Databricks. All Spark NLP capabilities run in Databricks, including MLFlow serialization and Experiment tracking, what can be used for serving Spark NLP for production purposes. About MLFlow MLFlow is a serialization and Experiment Tracking platform, which also natively supports Spark NLP. We have a documentation entry about MLFlow in the “Experiment Tracking” section. It’s highly recommended that you take a look before moving forward in this document, since we will use some of the concepts explained there. We will use MLFlow serialization to serve our Spark NLP models. Strengths Easily configurable and scalable clusters in Databricks Seamless integration of SPark NLP and Databricks for automatically creating Spark NLP clusters (check Install on Databricks URL) Integration with MLFlow, experiment tracking, etc. Configure your training and serving environments separately. Use your serving environment for inference and scale it as you need. Weaknesses This approach does not allow you to customize your endpoints, it uses Databricks JOBS API ones Requires some time and expertise in Databricks to configure everything properly Creating a cluster in Databricks As mentioned before, Spark NLP offers a seamless integration with Databricks. To create a cluster, please follow the instructions in Install on Databricks. That cluster can be then replicated (cloned) for production purposes later on. Configuring Databricks for serving Spark NLP on MLFlow In Databricks Runtime Version, select any Standard runtime, not ML ones… These add their version of MLFlow, and some incompatibilities may arise. For this example, we have used 8.3 (includes Apache Spark 3.1.1, Scala 2.12) The cluster instantiated is prepared to use Spark NLP, but to make it production-ready using MLFlow, we need to add the MLFlow jar, in addition to the Spark NLP jar, as shown in the “Experiment Tracking” section. In that case, we did it adding both jars… (&quot;spark.jars.packages&quot;:&quot; com.johnsnowlabs.nlp:spark-nlp_2.12:[YOUR_SPARKNLP_VERSION],org.mlflow:mlflow-spark:1.21.0&quot;) …into the SparkSession. However, in Databricks, you don’t instantiate programmatically a session, but you configure it in the Compute screen, selecting your Spark NLP cluster, and then going to Configuration -&gt; Advanced Options -&gt; Spark -&gt; Spark Config, as shown in the following image: In addition to Spark Config, we need to add the Spark NLP and MLFlow libraries to the Cluster. You can do that by going to Libraries inside your cluster. Make sure you have spark-nlp and mlflow. If not, you can install them either using PyPI or Maven artifacts. In the image below you can see the PyPI alternative: TIP: You can also use the Libraries section to add the jars (using Maven Coordinates) instead of setting them in the Spark Config, as showed before. Creating a notebook You are ready to create a notebook in Databricks and attach it to the recently created cluster. To do that, go to Create --&gt; Notebook, and select the cluster you want in the dropdown above your notebook. Make sure you have selected the cluster with the right Spark NLP + MLFlow configuration. To check everything is ok, run the following lines: To check the session is running: spark To check jars are in the session: spark.sparkContext.getConf().get(&#39;spark.jars.packages&#39;) You should see the following output from the last line (versions may differ depending on which ones you used to configure your cluster) Out[2]: &#39;com.johnsnowlabs.nlp:spark-nlp_2.12:[YOUR_SPARKNLP_VERSION],org.mlflow:mlflow-spark:1.21.0&#39; Logging the experiment in Databricks using MLFlow As explained in the “Experiment Tracking” section, MLFlow can log Spark MLLib / NLP Pipelines as experiments, to carry out runs on them, track versions, etc. MLFlow is natively integrated in Databricks, so we can leverage the mlflow.spark.log_model() function of the Spark flavour of MLFlow, to start tracking our Spark NLP pipelines. Let’s first import our libraries: import mlflow import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline import pandas as pd from sparknlp.training import CoNLL import pyspark from pyspark.sql import SparkSession Then, create a Lemmatization pipeline: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) lemmatizer = LemmatizerModel.pretrained() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;prediction&quot;) # It&#39;s mandatory to call it prediction pipeline = Pipeline(stages=[ documentAssembler, tokenizer, lemmatizer ]) IMPORTANT: Last output column of the last component in the pipeline should be called prediction. Finally, let’s log the experiment. In the Experiment Tracking section, we used the pip_requirements parameter in the log_model() function to set the required libraries: But we mentioned using conda is also available. Let’s use conda in this example: conda_env = { &#39;channels&#39;: [&#39;conda-forge&#39;], &#39;dependencies&#39;: [ &#39;python=3.8.8&#39;, { &quot;pip&quot;: [ &#39;pyspark==3.1.1&#39;, &#39;mlflow==1.21.0&#39;, &#39;spark-nlp==[YOUR_SPARKNLP_VERSION]&#39; ] } ], &#39;name&#39;: &#39;mlflow-env&#39; } With this conda environment, we are ready to log our pipeline: mlflow.spark.log_model(p_model, &quot;lemmatizer&quot;, conda_env=conda_env) You should see an output similar to this one: (6) Spark Jobs (1) MLflow run *Logged 1 run to an experiment in MLflow. Learn more* Experiment UI On the top right corner of your notebook, you will see the Experiment widget, and inside, as shown in the image below. You can also access Experiments UI if you switch your environment from “Data Science &amp; Engineering” to “Machine Learning”, on the left panel… Once in the experiment UI, you will see the following screen, where your experiments are tracked. If you click on the Start Time cell of your experiment, you will reach the registered MLFlow run. On the left panel you will see the MLFlow model and some other artifacts, as the conda.yml and pip_requirements.txt that manage the dependencies of your models. On the right panel, you will see two snippets, about how to call to the model for inference internally from Databricks. Snippet for calling with a Pandas Dataframe: import mlflow logged_model = &#39;runs:/a8cf070528564792bbf66d82211db0a0/lemmatizer&#39; Load model as a Spark UDF. loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model) Predict on a Spark DataFrame. columns = list(df.columns) df.withColumn(&#39;predictions&#39;, loaded_model(*columns)).collect() Snippet for calling with a Spark Dataframe. We won’t include it in this documentation because that snippet does not include SPark NLP specificities. To make it work, the correct snippet should be: import mlflow logged_model = &#39;runs:/a8cf070528564792bbf66d82211db0a0/lemmatizer&#39; loaded_model = mlflow.pyfunc.load_model(model_uri=logged_model) ### Predict on a Spark DataFrame. res_spark = loaded_model.predict(df_1_spark.rdd) IMPORTANT: You will only get the last column (prediction) results, which is a list of Rows of Annotation Types. To convert the result list into a Spark Dataframe, use the following schema: import pyspark.sql.types as T import pyspark.sql.functions as f annotationType = T.StructType([ T.StructField(&#39;annotatorType&#39;, T.StringType(), False), T.StructField(&#39;begin&#39;, T.IntegerType(), False), T.StructField(&#39;end&#39;, T.IntegerType(), False), T.StructField(&#39;result&#39;, T.StringType(), False), T.StructField(&#39;metadata&#39;, T.MapType(T.StringType(), T.StringType()), False), T.StructField(&#39;embeddings&#39;, T.ArrayType(T.FloatType()), False) ]) And then, get the results (for example, in res_spark) and apply the schema: spark_res = spark.createDataFrame(res_pandas[0], schema=annotationType) Calling the experiment for production purposes using MLFlow Rest API Instead of choosing a Batch Inference, you can select REST API. This will lead you to another screen, when the model will be loaded for production purposes in an independent cluster. Once deployed, you will be able to: Check the endpoint URL to consume the model externally; Test the endpoint writing a json (in our example, ‘text’ is our first input col of the pipeline, so it shoud look similar to: {&quot;text&quot;: &quot;This is a test of how the lemmatizer works&quot;} You can see the response in the same screen. Check what is the Python code or cURL command to do that very same thing programatically. By just using that Python code, you can already consume it for production purposes from any external web app. IMPORTANT: As per 17/02/2022, there is an issue being studied by Databricks team, regarding the creation on the fly of job clusters to serve MLFlow models that require configuring the Spark Session with specific jars. This will be fixed in later versions of Databricks. In the meantime, the way to go is using Databricks Jobs API. Calling the experiment for production purposes using Databricks Asynchronous Jobs API Creating the notebook for the inference job And last, but not least, another approach to consume models for production purposes. the Jobs API. Databricks has its own API for managing jobs, that allows you to instantiate any notebook or script as a job, run it, stop it, and manage all the life cycle. And you can configure the cluster where this job will run before hand, what prevents having the issue described in point 3. To do that: Create a new production cluster, as described before, cloning you training environment but adapting it to your needs for production purposes. Make sure the Spark Config is right, as described at the beginning of this documentation. Create a new notebook. Always check that the jars are in the session: spark.sparkContext.getConf().get(&#39;spark.jars.packages&#39;) Out[2]: &#39;com.johnsnowlabs.nlp:spark-nlp_2.12:[YOUR_SPARKNLP_VERSION],org.mlflow:mlflow-spark:1.21.0&#39; Add the Spark NLP imports. import mlflow import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline import pandas as pd from sparknlp.training import CoNLL import pyspark from pyspark.sql import SparkSession import pyspark.sql.types as T import pyspark.sql.functions as f import json Let’s define that an input param called text will be sent in the request. Let’s get the text from that parameter using dbutils. input = &quot;&quot; try: input = dbutils.widgets.get(&quot;text&quot;) print(&#39;&quot;text&quot; input found: &#39; + input) except: print(&#39;Unable to run: dbutils.widgets.get(&quot;text&quot;). Setting it to NOT_SET&#39;) input = &quot;NOT_SET&quot; Right now, the input text will be in input var. You can trigger an exception or set the input to some default value if the parameter does not come in the request. Let’s create a Spark Dataframe with the input df = spark.createDataFrame([[input]]).toDF(&#39;text&#39;) And now, we just need to use the snippet for Spark Dataframe to consume MLFlow models, described above: import mlflow import pyspark.sql.types as T import pyspark.sql.functions as f logged_model = &#39;runs:/a8cf070528564792bbf66d82211db0a0/lemmatizer&#39; loaded_model = mlflow.pyfunc.load_model(model_uri=logged_model) Predict on a Spark DataFrame. res_spark = loaded_model.predict(df_1_spark.rdd) annotationType = T.StructType([ T.StructField(&#39;annotatorType&#39;, T.StringType(), False), T.StructField(&#39;begin&#39;, T.IntegerType(), False), T.StructField(&#39;end&#39;, T.IntegerType(), False), T.StructField(&#39;result&#39;, T.StringType(), False), T.StructField(&#39;metadata&#39;, T.MapType(T.StringType(), T.StringType()), False), T.StructField(&#39;embeddings&#39;, T.ArrayType(T.FloatType()), False) ]) spark_res = spark.createDataFrame(res_spark[0], schema=annotationType) Let’s transform our lemmatized tokens from the Dataframe into a list of strings: lemmas = spark_res.select(&quot;result&quot;).collect() txt_results = [x[&#39;result&#39;] for x in lemmas] And finally, let’s use again dbutils to tell Databricks to spin off the run and return an exit parameter: the list of token strings. dbutils.notebook.exit(json.dumps({ &quot;status&quot;: &quot;OK&quot;, &quot;results&quot;: txt_results })) Configuring the job Last, but not least. We need to precreate the job, so that we run it from the API. We could do that using the API as well, but we will show you how to do it using the UI. On the left panel, go to Jobs and then Create Job. In the jobs screen, you will see you job created. It’s not running, it’s prepared to be called on demand, programatically or in the interface, with a text input param. Let’s see how to do that: Running the job In the jobs screen, if you click on the job, you will enter the Job screen, and be able to set your text input parameter and run the job manually. You can use this for testing purposes, but the interesting part is calling it externally, using the Databricks Jobs API. Using the Databricks Jobs API, from for example, Postman. POST HTTP request URL: https://[your_databricks_instance]/api/2.1/jobs/run-now Authorization: [use Bearer Token. You can get it from Databricks, Settings, User Settings, Generate New Token.] Body: { &quot;job_id&quot;: [job_id, check it in the Jobs screen], &quot;notebook_params&quot;: {&quot;text&quot;: &quot;This is an example of how well the lemmatizer works&quot;} } As it’s an asynchronous call, it will return the number a number of run, but no results. You will need to query for results using the number of the run and the following url https://[your_databricks_instance]/2.1/jobs/runs/get-output You will get a big json, but the most relevant info, the output, will be up to the end: Results (list of lemmatized words) {&quot;notebook_output&quot;: { &quot;status&quot;: &quot;OK&quot;, &quot;results&quot;: [&quot;This&quot;, &quot;is&quot;, &quot;a&quot;, &quot;example&quot;, &quot;of&quot;, &quot;how&quot;, &quot;lemmatizer&quot;, &quot;work&quot;] }} The notebook will be prepared in the job, but idle, until you call it programmatically, what will instantiate a run. Check the Jobs API for more information about what you can do with it and how to adapt it to your solutions for production purposes. Do you want to know more? Check how to productionize Spark NLP in our official documentation here Visit John Snow Labs and Spark NLP Technical Documentation websites Follow us on Medium: Spark NLP and Veysel Kocaman Write to support@johnsnowlabs.com for any additional request you may have",
    "url": "/docs/en/licensed_serving_spark_nlp_via_api_databricks_mlflow",
    "relUrl": "/docs/en/licensed_serving_spark_nlp_via_api_databricks_mlflow"
  },
  "1260": {
    "id": "1260",
    "title": "Serving Spark NLP&#58 FastAPI",
    "content": "This is the second article of the “Serving Spark NLP via API” series, showcasing how to serve Spark NLP using FastAPI and LightPipelines for a quick inference. Don’t forget to check the other articles in this series, namely: How to serve Spark NLP using Microsoft Synapse ML, available here. How to serve Spark NLP using Databricks Jobs and MLFlow Rest APIs, available here. Background Spark NLP is a Natural Language Understanding Library built on top of Apache Spark, leveranging Spark MLLib pipelines, that allows you to run NLP models at scale, including SOTA Transformers. Therefore, it’s the only production-ready NLP platform that allows you to go from a simple PoC on 1 driver node, to scale to multiple nodes in a cluster, to process big amounts of data, in a matter of minutes. Before starting, if you want to know more about all the advantages of using Spark NLP (as the ability to work at scale on air-gapped environments, for instance) we recommend you to take a look at the following resources: John Snow Labs webpage; The official technical documentation of Spark NLP; Spark NLP channel on Medium; Also, follow Veysel Kocaman, Data Scientist Lead and Head of Spark NLP for Healthcare, for the latests tips. Motivation Spark NLP is server-agnostic, what means it does not come with an integrated API server, but offers a lot of options to serve NLP models using Rest APIs. There is a wide range of possibilities to add a web server and serve Spark NLP pipelines using RestAPI, and in this series of articles we are only describing some of them. Let’s have an overview of how to use Microsoft’s Synapse ML as an example for that purpose. FastAPI and Spark NLP LightPipelines FastAPI is, as defined by the creators… …a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints. FastAPI provides with a very good latency and response times that, all along with the good performance of Spark NLP LightPipelines, makes this option the quickest one of the four described in the article. Read more about the performance advantages of using LightPipelines in this article created by John Snow Labs Data Scientist Lead Veysel Kocaman. Strengths Quickest approach Adds flexibility to build and adapt a custom API for your models Weaknesses LightPipelines are executed sequentially and don’t leverage the distributed computation that Spark Clusters provide. As an alternative, you can use FastAPI with default pipelines and a custom LoadBalancer, to distribute the calls over your cluster nodes. You can serve SparkNLP + FastAPI on Docker. To do that, we will create a project with the following files: Dockerfile: Image for creating a SparkNLP + FastAPI Docker image requirements.txt: PIP Requirements entrypoint.sh: Dockerfile entrypoint content/: folder containing FastAPI webapp and SparkNLP keys content/main.py: FastAPI webapp, entrypoint content/sparknlp_keys.json: SparkNLP keys (for Healthcare or OCR) Dockerfile The aim of this file is to create a suitable Docker Image with all the OS and Python libraries required to run SparkNLP. Also, adds a entry endpoint for the FastAPI server (see below) and a main folder containing the actual code to run a pipeline on an input text and return the expected values. FROM ubuntu:18.04 RUN apt-get update &amp;&amp; apt-get -y update RUN apt-get -y update &amp;&amp; apt-get install -y wget &amp;&amp; apt-get install -y jq &amp;&amp; apt-get install -y lsb-release &amp;&amp; apt-get install -y openjdk-8-jdk-headless &amp;&amp; apt-get install -y build-essential python3-pip &amp;&amp; pip3 -q install pip --upgrade &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* /usr/share/man /usr/share/doc /usr/share/doc-base ENV PYSPARK_DRIVER_PYTHON=python3 ENV PYSPARK_PYTHON=python3 ENV LC_ALL=C.UTF-8 ENV LANG=C.UTF-8 # We expose the FastAPI default port 8515 EXPOSE 8515 # Install all Python required libraries COPY requirements.txt / RUN pip install -r /requirements.txt # Adds the entrypoint to the FastAPI server COPY entrypoint.sh / RUN chmod +x /entrypoint.sh # In /content folder we will have our main.py and the license files COPY ./content/ /content/ WORKDIR content/ # We tell Docker to run this file when a container is instantiated ENTRYPOINT [&quot;/entrypoint.sh&quot;] requirements.txt This file describes which Python libraries will be required when creating the Docker image to run Spark NLP on FastAPI. pyspark==3.1.2 fastapi==0.70.1 uvicorn==0.16 wget==3.2 pandas==1.4.1 entrypoint.sh This file is the entry point of our Docker container, which carries out the following actions: Takes the sparknlp_keys.json and exports its values as environment variables, as required by Spark NLP for Healthcare. Installs the proper version of Spark NLP for Healthcare, getting the values from the license keys we have just exported in the previous step. Runs the main.py file, that will load the pipelines and create and endpoint to serve them. #!/bin/bash # Load the license from sparknlp_keys.json and export the values as OS variables export_json () { for s in $(echo $values | jq -r &#39;to_entries|map(&quot; (.key)= (.value|tostring)&quot;)|.[]&#39; $1 ); do export $s done } export_json &quot;/content/sparknlp_keys.json&quot; # Installs the proper version of Spark NLP for Healthcare pip install --upgrade spark-nlp-jsl==$JSL_VERSION --user --extra-index-url [https://pypi.johnsnowlabs.com/$SECRET](https://pypi.johnsnowlabs.com/$SECRET) if [ $? != 0 ]; then exit 1 fi # Script to create FastAPI endpoints and preloading pipelines for inference python3 /content/main.py content/main.py: Serving 2 pipelines in a FastAPI endpoint To maximize the performance and minimize the latency, we are going to store two Spark NLP pipelines in memory, so that we load only once (at server start) and we just use them everytime we get an API request to infer. To do this, let’s create a content/main.py Python script to download the required resources, store them in memory and serve them in Rest API endpoints. First, the import section import uvicorn, json, os from fastapi import FastAPI from sparknlp.annotator import * from sparknlp_jsl.annotator import * from sparknlp.base import * import sparknlp, sparknlp_jsl from sparknlp.pretrained import PretrainedPipeline app = FastAPI() pipelines = {} Then, let’s define the endpoint to serve the pipeline: @app.get(&quot;/benchmark/pipeline&quot;) async def get_one_sequential_pipeline_result(modelname, text=&#39;&#39;): return pipelines[modelname].annotate(text) Then, the startup event to preload the pipelines and start a Spark NLP Session: @app.on_event(&quot;startup&quot;) async def startup_event(): with open(&#39;/content/sparknlp_keys.json&#39;, &#39;r&#39;) as f: license_keys = json.load(f) spark = sparknlp_jsl.start(secret=license_keys[&#39;SECRET&#39;]) pipelines[&#39;ner_profiling_clinical&#39;] = PretrainedPipeline(&#39;ner_profiling_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) pipelines[&#39;clinical_deidentification&#39;] = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;en&quot;, &quot;clinical/models&quot;) Finally, let’s run a uvicorn server, listening on port 8515 to the endpoints declared before: if __name__ == &quot;__main__&quot;: uvicorn.run(&#39;main:app&#39;, host=&#39;0.0.0.0&#39;, port=8515) content/sparknlp_keys.json For using Spark NLP for Healthcare, please add your Spark NLP for Healthcare license keys to content/sparknlp_keys.jsonDThe file is ready, you only need to fulfill with your own values taken from the json file John Snow Labs has provided you with. { &quot;AWS_ACCESS_KEY_ID&quot;: &quot;&quot;, &quot;AWS_SECRET_ACCESS_KEY&quot;: &quot;&quot;, &quot;SECRET&quot;: &quot;&quot;, &quot;SPARK_NLP_LICENSE&quot;: &quot;&quot;, &quot;JSL_VERSION&quot;: &quot;&quot;, &quot;PUBLIC_VERSION&quot;: &quot;&quot; } And now, let’s run the server! Creating the Docker image and running the container docker build -t johnsnowlabs/sparknlp:sparknlp_api . docker run -v jsl_keys.json:/content/sparknlp_keys.json -p 8515:8515 -it johnsnowlabs/sparknlp:sparknlp_api Consuming the API using a Python script Lets import some libraries import requests import time Then, let’s create a clinical note ner_text = &quot;&quot;&quot; A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting. The patient was prescribed 1 capsule of Advil 10 mg for 5 days and magnesium hydroxide 100mg/1ml suspension PO. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day. &quot;&quot;&quot; We have preloaded and served two Pretrained Pipelines: clinical_deidentification and ner_profiling_clinical . In modelname, let’s set which one we want to check # Change this line to execute any of the two pipelines modelname = &#39;clinical_deidentification&#39; # modelname = &#39;ner_profiling_clinical&#39; And finally, let’s use the requestslibrary to send a test request to the endpoint and get the results. query = f&quot;?modelname={modelname}&amp;text={ner_text}&quot; url = f&quot;http://localhost:8515/benchmark/pipeline{query}&quot; print(requests.get(url)) Results (original and deidentified texts in json format) &gt;&gt; { &#39;masked&#39;: [&#39;A &lt;AGE&gt; female with a history of gestational diabetes mellitus diagnosed ...], &#39;obfuscated&#39;: [&#39;A 48 female with a history of gestational diabetes mellitus diagnosed ...&#39;], &#39;ner_chunk&#39;: [&#39;28-year-old&#39;], &#39;sentence&#39;: [&#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed ...&#39;] } You can also prettify the json using the following function with the result of the annotate() function: def explode_annotate(ann_result): &#39;&#39;&#39; Function to convert result object to json input: raw result output: processed result dictionary &#39;&#39;&#39; result = {} for column, ann in ann_result[0].items(): result[column] = [] for lines in ann: content = { &quot;result&quot;: lines.result, &quot;begin&quot;: lines.begin, &quot;end&quot;: lines.end, &quot;metadata&quot;: dict(lines.metadata), } result[column].append(content) return result Do you want to know more? Check the example notebooks in the Spark NLP Workshop repository, available here Visit John Snow Labs and Spark NLP Technical Documentation websites Follow us on Medium: Spark NLP and Veysel Kocaman Write to support@johnsnowlabs.com for any additional request you may have",
    "url": "/docs/en/licensed_serving_spark_nlp_via_api_fastapi",
    "relUrl": "/docs/en/licensed_serving_spark_nlp_via_api_fastapi"
  },
  "1261": {
    "id": "1261",
    "title": "Serving Spark NLP&#58 SynapseML",
    "content": "This is the first article of the “Serving Spark NLP via API” series, showcasing how to serve Spark NLP using Synapse ML Don’t forget to check the other articles in this series, namely: How to server Spark NLP using FastAPI and LightPipelines, available here. How to serve Spark NLP using Databricks Jobs and MLFlow Rest APIs, available here. Background Spark NLP is a Natural Language Understanding Library built on top of Apache Spark, leveranging Spark MLLib pipelines, that allows you to run NLP models at scale, including SOTA Transformers. Therefore, it’s the only production-ready NLP platform that allows you to go from a simple PoC on 1 driver node, to scale to multiple nodes in a cluster, to process big amounts of data, in a matter of minutes. Before starting, if you want to know more about all the advantages of using Spark NLP (as the ability to work at scale on air-gapped environments, for instance) we recommend you to take a look at the following resources: John Snow Labs webpage; The official technical documentation of Spark NLP; Spark NLP channel on Medium; Also, follow Veysel Kocaman, Data Scientist Lead and Head of Spark NLP for Healthcare, for the latests tips. Motivation Spark NLP is server-agnostic, what means it does not come with an integrated API server, but offers a lot of options to serve NLP models using Rest APIs. There is a wide range of possibilities to add a web server and serve Spark NLP pipelines using RestAPI, and in this series of articles we are only describing some of them. Let’s have an overview of how to use Microsoft’s Synapse ML as an example for that purpose. Microsoft’s Synapse ML Synapse ML (previously named SparkMML) is, as they state in their official webpage: … an ecosystem of tools aimed towards expanding the distributed computing framework Apache Spark in several new directions. They offer a seamless integratation with OpenCV, LightGBM, Microsoft Cognitive Tool and, the most relevant for our use case, Spark Serving, an extension of *Spark Streaming *with an integrated server and a Load Balancer, that can attend multiple requests via Rest API, balance and attend them leveraging the capabilities of a Spark Cluster. That means that you can sin up a server and attend requests that will be distributed transparently over a Spark NLP cluster, in a very effortless way. Strengths Ready-to-use server Includes a Load Balancer Distributes the work over a Spark Cluster Can be used for both Spark NLP and Spark OCR Weaknesses For small use cases that don’t require big cluster processing, other approaches may be faster (as FastAPI using LightPipelines) Requires using an external Framework This approach does not allow you to customize your endpoints, it uses Synapse ML ones How to set up Synapse ML to serve Spark NLP pipelines We will skip here how to install Spark NLP. If you need to do that, please follow this official webpage about how to install Spark NLP or, if Spark NLP for Healthcare if you are using the Healthcare library. Synapse ML recommends using at least Spark 3.2, so first of all, let’s configure the Spark Session with the required jars packages(both for Synapse ML and Spark) with the the proper Spark version (take a look at the suffix spark-nlp-spark32) and also, very important, add to jars.repository the Maven repository for SynapseML. sparknlpjsl_jar = &quot;spark-nlp-jsl.jar&quot; from pyspark.sql import SparkSession spark = SparkSession.builder .appName(&quot;Spark&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;, &quot;16G&quot;) .config(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;) .config(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;) .config(&quot;spark.jars.packages&quot;, &quot;com.microsoft.azure:synapseml_2.12:0.9.5,com.johnsnowlabs.nlp:spark-nlp-spark32_2.12:[YOUR_SPARKNLP_VERSION]) .config(&quot;spark.jars&quot;, sparknlpjsl_jar) .config(&quot;spark.jars.repositories&quot;, &quot;https://mmlspark.azureedge.net/maven&quot;) .getOrCreate() After the initialization, add your required imports (Spark NLP) and add to them the SynapseML-specific ones: import sparknlp import sparknlp_jsl ... import synapse.ml from synapse.ml.io import * Now, let’s create a Spark NLP for Healthcare pipeline to carry out Entity Resolution. document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetectorDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter_icd = NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&#39;PROBLEM&#39;]) .setPreservePosition(False) c2doc = Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) .setCaseSensitive(False) icd_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_augmented_billable_hcc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;icd10cm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) resolver_pipeline = Pipeline( stages = [ document_assembler, sentenceDetectorDL, tokenizer, word_embeddings, clinical_ner, ner_converter_icd, c2doc, sbert_embedder, icd_resolver ]) Let’s use a clinical note to test Synapse ML. clinical_note = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting. Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection. She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation. Physical examination on presentation was significant for dry oral mucosa; significantly, her abdominal examination was benign with no tenderness, guarding, or rigidity.&quot;&quot;&quot; Since SynapseML serves a RestAPI, we will be sending JSON requests. Let’s define a simple json with the clinical note: data_json = {&quot;text&quot;: clinical_note } Now, let’s spin up a server using Synapse ML Spark Serving. It will consist of: a streaming server that will receive a json and transform it into a Spark Dataframe a call to Spark NLP transform on the dataframe, using the pipeline a write operation returning the output also in json format. #1: Creating the streaming server and transforming json to Spark Dataframe serving_input = spark.readStream.server() .address(&quot;localhost&quot;, 9999, &quot;benchmark_api&quot;) .option(&quot;name&quot;, &quot;benchmark_api&quot;) .load() .parseRequest(&quot;benchmark_api&quot;, data.schema) #2: Applying transform to the dataframe using our Spark NLP pipeline serving_output = resolver_p_model.transform(serving_input) .makeReply(&quot;icd10cm_code&quot;) #3: Returning the response in json format server = serving_output.writeStream .server() .replyTo(&quot;benchmark_api&quot;) .queryName(&quot;benchmark_query&quot;) .option(&quot;checkpointLocation&quot;, &quot;file:///tmp/checkpoints-{}&quot;.format(uuid.uuid1())) .start() And we are ready to test the endpoint using the requests library. import requests res = requests.post(&quot;http://localhost:9999/benchmark_api&quot;, data= json.dumps(data_json)) And last, but not least, let’s check the results: for i in range (0, len(response_list.json())): print(response_list.json()[i][&#39;result&#39;]) Results (list of ICD-10-CM codes from NER chunks) &gt;&gt; O2441 O2411 P702 K8520 B159 E669 Z6841 R35 R631 R630 R111... SynapseML on Databricks You can also run the above code in Databricks. To do that, you only need to remove the Creating a Spark Session, since Databricks manages that session for you. After we remove that part of the code from our notebook, we need to set the same configuration params in the Cluster Configuration, so that Databricks spins a cluster with the proper jars and config params (similarly to what we did programatically in Creating a Spark Session above, but using Databricks UI) To do so, go to Compute →Clusters in Databricks and create a new cluster (name it, for instance, Synapse). In your environment variables, as always, add the keys from your license in a key=value format Then, in Cluster → Libraries, you need to install: SynapseML jar (Maven → com.microsoft.azure:synapseml_2.12:0.9.5) Spark NLP jar ( Maven →com.johnsnowlabs.nlp:spark-nlp-spark32_2.12:[YOUR_SPARKNLP_VERSION]) Spark NLP wheel (PyPi → spark-nlp==[YOUR_SPARKNLP_VERSION]) If you are using Spark NLP for Healthcare Spark NLP for Healthcare jar. Download the jar using the secret from your license, and then upload the jar to DBFS and add it in the Libraries section (DBFS/ADLS → dbfs:/FileStore/johnsnowlabs/libs/spark_nlp_jsl_[YOUR_SPARKNLP_VERSION].jar) Spark NLP for Healthcare wheel. Same that with the jar. Download the jar using the secret from your license, and then upload the jar to DBFS and add it in the Libraries section (DBFS/ADLS → dbfs:/FileStore/johnsnowlabs/libs/spark_nlp_jsl_[YOUR_SPARKNLP_VERSION].whl) And the rest of the code from the Importing all the libraries section and on remains exactly the same. Do you want to know more? Check the example notebooks in the Spark NLP Workshop repository, available here Visit John Snow Labs and Spark NLP Technical Documentation websites Follow us on Medium: Spark NLP and Veysel Kocaman Write to support@johnsnowlabs.com for any additional request you may have",
    "url": "/docs/en/licensed_serving_spark_nlp_via_api_synapseml",
    "relUrl": "/docs/en/licensed_serving_spark_nlp_via_api_synapseml"
  },
  "1262": {
    "id": "1262",
    "title": "Training",
    "content": "Training Datasets These are classes to load common datasets to train annotators for tasks such as Relation Model, Assertion models and more. Annotation tool json reader. All the annotations from Annotation Lab can be exported in a standard JSON format as shown below. The JSON holds multiple types of annotations like NER, Assertion, and Relations. To generate training datasets from the json, a utility class AnnotationToolJsonReader can be used, which can generate training datasets for training NER and Assertion models. AnnotationToolJsonReader Colab Notebook provides the code and details of processing the exported JSON to generate training datasets for NER and Assertion models in section 2. Users can distinguish between different label types by using constructor parameters described below. This notebook also explains how to connect to your Annotation Lab instance via API for uploading tasks, pre-annotations, and exporting entire projects. Input File Format: [ { &quot;completions&quot;: [ { &quot;created_ago&quot;: &quot;2020-05-18T20:48:18.117Z&quot;, &quot;created_username&quot;: &quot;admin&quot;, &quot;id&quot;: 3001, &quot;lead_time&quot;: 19.255, &quot;result&quot;: [ { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;o752YyB2g9&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 3, &quot;text&quot;: &quot;have faith&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;wf2U3o7I6T&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 24, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 16, &quot;text&quot;: &quot; to trust&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;Q3BkU5eZNx&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 40, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 35, &quot;text&quot;: &quot;to the&quot; } } ] } ], &quot;created_at&quot;: &quot;2020-05-18 20:47:53&quot;, &quot;created_by&quot;: &quot;andres.fernandez&quot;, &quot;data&quot;: { &quot;text&quot;: &quot;To have faith is to trust yourself to the water&quot; }, &quot;id&quot;: 3 }, { &quot;completions&quot;: [ { &quot;created_ago&quot;: &quot;2020-05-17T17:52:41.563Z&quot;, &quot;created_username&quot;: &quot;andres.fernandez&quot;, &quot;id&quot;: 1, &quot;lead_time&quot;: 31.449, &quot;result&quot;: [ { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;IQjoZJNKEv&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;Disease&quot; ], &quot;start&quot;: 3, &quot;text&quot;: &quot;have faith&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;tHsbn4oYy5&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 46, &quot;labels&quot;: [ &quot;Treatment&quot; ], &quot;start&quot;: 42, &quot;text&quot;: &quot;water&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;IJHkc9bxJ-&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 0, &quot;text&quot;: &quot;To have faith&quot; } } ] } ], &quot;created_at&quot;: &quot;2020-05-17 17:52:02&quot;, &quot;created_by&quot;: &quot;andres.fernandez&quot;, &quot;data&quot;: { &quot;text&quot;: &quot;To have faith is to trust yourself to the water&quot; }, &quot;id&quot;: 0 }, { &quot;completions&quot;: [ { &quot;created_ago&quot;: &quot;2020-05-17T17:57:19.402Z&quot;, &quot;created_username&quot;: &quot;andres.fernandez&quot;, &quot;id&quot;: 1001, &quot;lead_time&quot;: 15.454, &quot;result&quot;: [ { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;j_lT0zwtrJ&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 46, &quot;labels&quot;: [ &quot;Disease&quot; ], &quot;start&quot;: 20, &quot;text&quot;: &quot;trust yourself to the water&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;e1FuGWu7EQ&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 33, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 19, &quot;text&quot;: &quot; trust yourself&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;q0MCSM9SXz&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;Treatment&quot; ], &quot;start&quot;: 0, &quot;text&quot;: &quot;To have faith&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;9R7dvPphPX&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 0, &quot;text&quot;: &quot;To have faith&quot; } } ] } ], &quot;created_at&quot;: &quot;2020-05-17 17:52:54&quot;, &quot;created_by&quot;: &quot;andres.fernandez&quot;, &quot;data&quot;: { &quot;text&quot;: &quot;To have faith is to trust yourself to the water&quot; }, &quot;id&quot;: 1, &quot;predictions&quot;: [] } ] Constructor Parameters: assertion_labels: The assertions labels are used for the training dataset creation. excluded_labels: The assertions labels that are excluded for the training dataset creation. split_chars: The split chars that are used in the default tokenizer. context_chars: The context chars that are used in the default tokenizer. SDDLPath: The context chars that are used in the default tokenizer. Parameters for readDataset: spark: Initiated Spark Session with Spark NLP path: Path to the resource Refer to the documentation for more details on the API: Python API: Scala API: AnnotationToolJsonReader Show Example PythonScala from sparknlp_jsl.training import AnnotationToolJsonReader assertion_labels = [&quot;AsPresent&quot;,&quot;Absent&quot;] excluded_labels = [&quot;Treatment&quot;] split_chars = [&quot; &quot;, &quot; -&quot;] context_chars = [&quot;.&quot;, &quot;,&quot;, &quot;;&quot;, &quot;:&quot;, &quot;!&quot;, &quot;?&quot;, &quot;*&quot;, &quot;-&quot;, &quot;(&quot;, &quot;)&quot;, &quot; &quot;&quot;, &quot;&#39;&quot;,&quot;+&quot;,&quot;%&quot;,&quot;&#39;&quot;] SDDLPath = &quot;&quot; rdr = AnnotationToolJsonReader(assertion_labels = assertion_labels, excluded_labels = excluded_labels, split_chars = split_chars, context_chars = context_chars,SDDLPath=SDDLPath) path = &quot;src/test/resources/anc-pos-corpus-small/test-training.txt&quot; df = rdr.readDataset(spark, json_path) assertion_df = rdr.generateAssertionTrainSet(df) assertion_df.show() +--+--++--++ | text| target| label|start|end| +--+--++--++ |To have faith is ...| To have faith|AsPresent| 0| 2| |To have faith is ...| have faith|AsPresent| 1| 2| |To have faith is ...| to trust|AsPresent| 4| 5| |To have faith is ...| to the|AsPresent| 7| 8| |To have faith is ...| yourself|AsPresent| 6| 6| |To have faith is ...| To have faith|AsPresent| 0| 2| |To have faith is ...|trust yourself|AsPresent| 5| 6| +--+--++--++ import com.johnsnowlabs.nlp.training.POS val filename = &quot;src/test/resources/json_import.json&quot; val reader = new AnnotationToolJsonReader(assertionLabels=List(&quot;AsPresent&quot;,&quot;Absent&quot;).asJava, splitChars=List(&quot; &quot;, &quot; -&quot;).asJava, excludedLabels = List(&quot;Treatment&quot;).asJava) val df = reader.readDataset(ResourceHelper.spark, filename) val assertionDf = reader.generateAssertionTrainSet(df) assertionDf.show() +--+--++--++ | text| target| label|start|end| +--+--++--++ |To have faith is ...| To have faith|AsPresent| 0| 2| |To have faith is ...| have faith|AsPresent| 1| 2| |To have faith is ...| to trust|AsPresent| 4| 5| |To have faith is ...| to the|AsPresent| 7| 8| |To have faith is ...| yourself|AsPresent| 6| 6| |To have faith is ...| To have faith|AsPresent| 0| 2| |To have faith is ...|trust yourself|AsPresent| 5| 6| +--+--++--++ Assertion Trains AssertionDL, a deep Learning based approach used to extract Assertion Status from extracted entities and text. AssertionDLApproach Train a Assertion Model algorithm using deep learning. The training data should have annotations columns of type DOCUMENT, CHUNK, WORD_EMBEDDINGS, the labelcolumn (The assertion status that you want to predict), the start (the start index for the term that has the assertion status), the end column (the end index for the term that has the assertion status).This model use a deep learning to predict the entity. Excluding the label, this can be done with for example a SentenceDetector, a Chunk , a WordEmbeddingsModel (any word embeddings can be chosen, e.g. BertEmbeddings for BERT based embeddings). Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionDLApproach Scala API: AssertionDLApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline document_assembler = DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;document&#39;) sentence_detector = SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) POSTag = PerceptronModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) chunker = Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) pubmed = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) assertion_status = AssertionDLApproach() .setInputCols(&quot;sentence&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setLabelCol(&quot;label&quot;) .setLearningRate(0.01) .setDropout(0.15) .setBatchSize(16) .setEpochs(3) .setValidationSplit(0.2) .setIncludeConfidence(True) pipeline = Pipeline().setStages([ document_assembler, sentence_detector, tokenizer, POSTag, chunker, pubmed, assertion_status ]) conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) // This CoNLL dataset already includes the sentence, token, pos and label column with their respective annotator types. // If a custom dataset is used, these need to be defined. import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.{Chunker, Tokenizer} import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotator.PerceptronModel import com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel import com.johnsnowlabs.nlp.annotator.NerCrfApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val POSTag = PerceptronModel .pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) val chunker = new Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) val pubmed = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(false) val assertionStatus = new AssertionDLApproach() .setInputCols(&quot;sentence&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setLabelCol(&quot;label&quot;) .setLearningRate(0.01f) .setDropout(0.15f) .setBatchSize(16) .setEpochs(3) .setValidationSplit(0.2f) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, POSTag, chunker, pubmed, assertionStatus )) datasetPath = &quot;/../src/test/resources/rsAnnotations-1-120-random.csv&quot; train_data = SparkContextForTest.spark.read.option(&quot;header&quot;, &quot;true&quot;).csv(path=&quot;file:///&quot; + os.getcwd() + datasetPath) val pipelineModel = pipeline.fit(trainingData) AssertionLogRegApproach Train a Assertion Model algorithm using a regression log model. The training data should have annotations columns of type DOCUMENT, CHUNK, WORD_EMBEDDINGS, the labelcolumn (The assertion status that you want to predict), the start (the start index for the term that has the assertion status), the end column (the end index for the term that has the assertion status).This model use a deep learning to predict the entity. Excluding the label, this can be done with for example a SentenceDetector, a Chunk , a WordEmbeddingsModel (any word embeddings can be chosen, e.g. BertEmbeddings for BERT based embeddings). Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionLogRegApproach Scala API: AssertionLogRegApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline document_assembler = DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;document&#39;) sentence_detector = SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) POSTag = PerceptronModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) chunker = Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) pubmed = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) assertion_status = AssertionLogRegApproach() .setInputCols(&quot;sentence&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setLabelCol(&quot;label&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setEpochs(3) pipeline = Pipeline().setStages([ document_assembler, sentence_detector, tokenizer, POSTag, chunker, pubmed, assertion_status ]) conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) // This CoNLL dataset already includes the sentence, token, pos and label column with their respective annotator types. // If a custom dataset is used, these need to be defined. import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.{Chunker, Tokenizer} import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotator.PerceptronModel import com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel import com.johnsnowlabs.nlp.annotator.NerCrfApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val POSTag = PerceptronModel .pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) val chunker = new Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) val pubmed = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(false) val assertion = new AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols(&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, POSTag, chunker, pubmed, assertion )) datasetPath = &quot;/../src/test/resources/rsAnnotations-1-120-random.csv&quot; train_data = SparkContextForTest.spark.read.option(&quot;header&quot;, &quot;true&quot;).csv(path=&quot;file:///&quot; + os.getcwd() + datasetPath) val pipelineModel = pipeline.fit(trainingData) Token Classification These are annotators that can be trained to recognize named entities in text. MedicalNer This Named Entity recognition annotator allows to train generic NER model based on Neural Networks. The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets. For instantiated/pretrained models, see NerDLModel. The training data should be a labeled Spark Dataset, in the format of CoNLL 2003 IOB with Annotation type columns. The data should have columns of type DOCUMENT, TOKEN, WORD_EMBEDDINGS and an additional label column of annotator type NAMED_ENTITY. Excluding the label, this can be done with for example a SentenceDetector, a Tokenizer and a WordEmbeddingsModel with clinical embeddings (any clinical word embeddings can be chosen). Input Annotator Types: DOCUMENT, TOKEN, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: MedicalNerApproach Scala API: MedicalNerApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp_jsl.annotator import * from sparknlp.training import * from pyspark.ml import Pipeline # First extract the prerequisites for the NerDLApproach documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Then the training can start nerTagger = MedicalNerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(2) .setBatchSize(64) .setRandomSeed(0) .setVerbose(1) .setValidationSplit(0.2) .setEvaluationLogExtended(True) .setEnableOutputLogs(True) .setIncludeConfidence(True) .setOutputLogsPath(&#39;ner_logs&#39;) .setGraphFolder(&#39;medical_ner_graphs&#39;) .setEnableMemoryOptimizer(True) #&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, clinical_embeddings, nerTagger ]) # We use the text and labels from the CoNLL dataset conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.ner.MedicalNerApproach import com.johnsnowlabs.nlp.training.CoNLL import org.apache.spark.ml.Pipeline // First extract the prerequisites for the NerDLApproach val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new MedicalNerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) // We use the text and labels from the CoNLL dataset val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) Text Classification These are annotators that can be trained to classify text into different classes, such as sentiment. DocumentLogRegClassifier Trains a model to classify documents with a Logarithmic Regression algorithm. Training data requires columns for text and their label. The result is a trained GenericClassifierModel. Input Annotator Types: TOKEN Output Annotator Type: CATEGORY Python API: DocumentLogRegClassifierApproach Scala API: DocumentLogRegClassifierApproach Show Example PythonScala import sparknlp from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline document_assembler = DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) normalizer = Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) stopwords_cleaner = StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) stemmer = Stemmer() .setInputCols(&quot;cleanTokens&quot;) .setOutputCol(&quot;stem&quot;) gen_clf = DocumentLogRegClassifierApproach() .setLabelColumn(&quot;category&quot;) .setInputCols(&quot;stem&quot;) .setOutputCol(&quot;prediction&quot;) pipeline = Pipeline().setStages([ document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg ]) clf_model = pipeline.fit(data) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.ner.MedicalNerApproach import com.johnsnowlabs.nlp.training.CoNLL import org.apache.spark.ml.Pipeline // First extract the prerequisites for the NerDLApproach val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new MedicalNerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) // We use the text and labels from the CoNLL dataset val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) GenericClassifier Trains a TensorFlow model for generic classification of feature vectors. It takes FEATURE_VECTOR annotations from FeaturesAssembler as input, classifies them and outputs CATEGORY annotations. Please see the Parameters section for required training parameters. For a more extensive example please see the Spark NLP Workshop. Input Annotator Types: FEATURE_VECTOR Output Annotator Type: CATEGORY Python API: GenericClassifierApproach Scala API: GenericClassifierApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline features_asm = FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline().setStages([ features_asm, gen_clf ]) clf_model = pipeline.fit(data) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.ner.MedicalNerApproach import com.johnsnowlabs.nlp.training.CoNLL import org.apache.spark.ml.Pipeline // First extract the prerequisites for the NerDLApproach val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new MedicalNerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) // We use the text and labels from the CoNLL dataset val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) Relation Models RelationExtractionApproach Trains a Relation Extraction Model to predict attributes and relations for entities in a sentence. Relation Extraction is the key component for building relation knowledge graphs, and it is of crucial significance to natural language processing applications such as structured search, sentiment analysis, question answering, and summarization. The dataset will be a csv with the following that contains the following columns (sentence,chunk1,firstCharEnt1,lastCharEnt1,label1,chunk2,firstCharEnt2,lastCharEnt2,label2,rel), This annotator can be don with for example: Excluding the rel, this can be done with for example a SentenceDetector, a Tokenizer and a WordEmbeddingsModel (any word embeddings can be chosen, e.g. BertEmbeddings for BERT based embeddings). a Chunk can be created using the firstCharEnt1, lastCharEnt1,chunk1, label1 columns and firstCharEnt2, lastCharEnt2, chunk2, label2 columns An example of that dataset can be found in the following link i2b2_clinical_dataset sentence,chunk1,firstCharEnt1,lastCharEnt1,label1,chunk2,firstCharEnt2,lastCharEnt2,label2,rel Previous studies have reported the association of prodynorphin (PDYN) promoter polymorphism with temporal lobe epilepsy (TLE) susceptibility, but the results remain inconclusive.,PDYN,64,67,GENE,epilepsy,111,118,PHENOTYPE,0 The remaining cases, clinically similar to XLA, are autosomal recessive agammaglobulinemia (ARA).,XLA,43,45,GENE,autosomal recessive,52,70,PHENOTYPE,0 YAP/TAZ have been reported to be highly expressed in malignant tumors.,YAP,19,21,GENE,tumors,82,87,PHENOTYPE,0 Apart from that, no additional training data is needed. Input Annotator Types: WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY Output Annotator Type: CATEGORY Python API: RelationExtractionApproach Scala API: RelationExtractionApproach Show Example PythonScala import functools import numpy as np import pyspark.sql.functions as F import pyspark.sql.types as T from sparknlp.base import annotationType = T.StructType([ T.StructField(&#39;annotatorType&#39;, T.StringType(), False), T.StructField(&#39;begin&#39;, T.IntegerType(), False), T.StructField(&#39;end&#39;, T.IntegerType(), False), T.StructField(&#39;result&#39;, T.StringType(), False), T.StructField(&#39;metadata&#39;, T.MapType(T.StringType(), T.StringType()), False), T.StructField(&#39;embeddings&#39;, T.ArrayType(T.FloatType()), False) ]) @F.udf(T.ArrayType(annotationType)) def createTrainAnnotations(begin1, end1, begin2, end2, chunk1, chunk2, label1, label2): entity1 = sparknlp.annotation.Annotation(&quot;chunk&quot;, begin1, end1, chunk1, {&#39;entity&#39;: label1.upper(), &#39;sentence&#39;: &#39;0&#39;}, []) entity2 = sparknlp.annotation.Annotation(&quot;chunk&quot;, begin2, end2, chunk2, {&#39;entity&#39;: label2.upper(), &#39;sentence&#39;: &#39;0&#39;}, []) entity1.annotatorType = &quot;chunk&quot; entity2.annotatorType = &quot;chunk&quot; return [entity1, entity2] data = spark.read.option(&quot;header&quot;,&quot;true&quot;).format(&quot;csv&quot;).load(&quot;i2b2_clinical_rel_dataset.csv&quot;) data = data .withColumn(&quot;begin1i&quot;, F.expr(&quot;cast(firstCharEnt1 AS Int)&quot;)) .withColumn(&quot;end1i&quot;, F.expr(&quot;cast(lastCharEnt1 AS Int)&quot;)) .withColumn(&quot;begin2i&quot;, F.expr(&quot;cast(firstCharEnt2 AS Int)&quot;)) .withColumn(&quot;end2i&quot;, F.expr(&quot;cast(lastCharEnt2 AS Int)&quot;)) .where(&quot;begin1i IS NOT NULL&quot;) .where(&quot;end1i IS NOT NULL&quot;) .where(&quot;begin2i IS NOT NULL&quot;) .where(&quot;end2i IS NOT NULL&quot;) .withColumn( &quot;train_ner_chunks&quot;, createTrainAnnotations( &quot;begin1i&quot;, &quot;end1i&quot;, &quot;begin2i&quot;, &quot;end2i&quot;, &quot;chunk1&quot;, &quot;chunk2&quot;, &quot;label1&quot;, &quot;label2&quot; ).alias(&quot;train_ner_chunks&quot;, metadata={&#39;annotatorType&#39;: &quot;chunk&quot;})) documentAssembler = DocumentAssembler() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;sentences&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;token&quot;) words_embedder = WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) reApproach = RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setLabelColumn(&quot;rel&quot;) .setEpochsNumber(70) .setBatchSize(200) .setDropout(0.5) .setLearningRate(0.001) .setModelFile(&quot;/content/RE_in1200D_out20.pb&quot;) .setFixImbalance(True) .setFromEntity(&quot;begin1i&quot;, &quot;end1i&quot;, &quot;label1&quot;) .setToEntity(&quot;begin2i&quot;, &quot;end2i&quot;, &quot;label2&quot;) .setOutputLogsPath(&#39;/content&#39;) train_pipeline = Pipeline(stages=[ documenter, tokenizer, words_embedder, pos_tagger, dependency_parser, reApproach ]) rel_model = train_pipeline.fit(data) import com.johnsnowlabs.nlp.{DocumentAssembler} import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.ner.{MedicalNerModel, NerConverter} import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel import com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel package com.johnsnowlabs.nlp.annotators.re.RelationExtractionApproach() import org.apache.spark.ml.Pipeline import org.apache.spark.sql.functions._ val data = spark.read.option(&quot;header&quot;,true).csv(&quot;src/test/resources/re/gene_hpi.csv&quot;).limit(10) def createTrainAnnotations = udf { ( begin1:Int, end1:Int, begin2:Int, end2:Int, chunk1:String, chunk2:String, label1:String, label2:String) =&gt; { val an1 = Annotation(CHUNK,begin1,end1,chunk1,Map(&quot;entity&quot; -&gt; label1.toUpperCase,&quot;sentence&quot; -&gt; &quot;0&quot;)) val an2 = Annotation(CHUNK,begin2,end2,chunk2,Map(&quot;entity&quot; -&gt; label2.toUpperCase,&quot;sentence&quot; -&gt; &quot;0&quot;)) Seq(an1,an2) } } val metadataBuilder: MetadataBuilder = new MetadataBuilder() val meta = metadataBuilder.putString(&quot;annotatorType&quot;, CHUNK).build() val dataEncoded = data .withColumn(&quot;begin1i&quot;, expr(&quot;cast(firstCharEnt1 AS Int)&quot;)) .withColumn(&quot;end1i&quot;, expr(&quot;cast(lastCharEnt1 AS Int)&quot;)) .withColumn(&quot;begin2i&quot;, expr(&quot;cast(firstCharEnt2 AS Int)&quot;)) .withColumn(&quot;end2i&quot;, expr(&quot;cast(lastCharEnt2 AS Int)&quot;)) .where(&quot;begin1i IS NOT NULL&quot;) .where(&quot;end1i IS NOT NULL&quot;) .where(&quot;begin2i IS NOT NULL&quot;) .where(&quot;end2i IS NOT NULL&quot;) .withColumn( &quot;train_ner_chunks&quot;, createTrainAnnotations( col(&quot;begin1i&quot;), col(&quot;end1i&quot;), col(&quot;begin2i&quot;), col(&quot;end2i&quot;), col(&quot;chunk1&quot;), col(&quot;chunk2&quot;), col(&quot;label1&quot;), col(&quot;label2&quot;) ).as(&quot;train_ner_chunks&quot;,meta)) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentences&quot;)) .setOutputCol(&quot;tokens&quot;) val embedder = ParallelDownload(WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;)) val posTagger = ParallelDownload(PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;posTags&quot;)) val nerTagger = ParallelDownload(MedicalNerModel .pretrained(&quot;ner_events_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_tags&quot;)) val nerConverter = new NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;)) .setOutputCol(&quot;nerChunks&quot;) val depencyParser = ParallelDownload(DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;posTags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;)) val re = new RelationExtractionApproach() .setInputCols(Array(&quot;embeddings&quot;, &quot;posTags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;rel&quot;) .setLabelColumn(&quot;target_rel&quot;) .setEpochsNumber(30) .setBatchSize(200) .setlearningRate(0.001f) .setValidationSplit(0.05f) .setFromEntity(&quot;begin1i&quot;, &quot;end1i&quot;, &quot;label1&quot;) .setToEntity(&quot;end2i&quot;, &quot;end2i&quot;, &quot;label2&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, tokenizer, embedder, posTagger, nerTagger, nerConverter, depencyParser, re).parallelDownload) val model = pipeline.fit(dataEncoded) Entity Resolution Those models predict what are the normalized entity for a particular trained ontology / curated dataset. (e.g. ICD-10, RxNorm, SNOMED etc.). SentenceEntityResolver Contains all the parameters and methods to train a SentenceEntityResolverModel. The model transforms a dataset with Input Annotation type SENTENCE_EMBEDDINGS, coming from e.g. BertSentenceEmbeddings and returns the normalized entity for a particular trained ontology / curated dataset. (e.g. ICD-10, RxNorm, SNOMED etc.) To use pretrained models please use SentenceEntityResolverModel and see the Models Hub for available models. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: ENTITY Python API: SentenceEntityResolverApproach Scala API: SentenceEntityResolverApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline # Training a SNOMED resolution model using BERT sentence embeddings # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. documentAssembler = DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) bertEmbeddings = BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) snomedTrainingPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, bertEmbeddings ]) snomedTrainingModel = snomedTrainingPipeline.fit(data) snomedData = snomedTrainingModel.transform(data).cache() # Then the Resolver can be trained with bertExtractor = SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols([&quot;bert_embeddings&quot;]) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(False) snomedModel = bertExtractor.fit(snomedData) // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData) ChunkEntityResolver Contains all the parameters and methods to train a ChunkEntityResolverModel. It transform a dataset with two Input Annotations of types TOKEN and WORD_EMBEDDINGS, coming from e.g. ChunkTokenizer and ChunkEmbeddings Annotators and returns the normalized entity for a particular trained ontology / curated dataset. (e.g. ICD-10, RxNorm, SNOMED etc.) To use pretrained models please use ChunkEntityResolverModel and see the Models Hub for available models. Input Annotator Types: TOKEN, WORD_EMBEDDINGS Output Annotator Type: ENTITY Python API: ChunkEntityResolverApproach Scala API: ChunkEntityResolverApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline # Training a SNOMED model # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data # and their labels. document = DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) chunk = Doc2Chunk() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;chunk&quot;) token = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_healthcare_100d&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) chunkEmb = ChunkEmbeddings() .setInputCols([&quot;chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;chunk_embeddings&quot;) snomedTrainingPipeline = Pipeline().setStages([ document, chunk, token, embeddings, chunkEmb ]) snomedTrainingModel = snomedTrainingPipeline.fit(data) snomedData = snomedTrainingModel.transform(data).cache() # Then the Resolver can be trained with snomedExtractor = ChunkEntityResolverApproach() .setInputCols([&quot;token&quot;, &quot;chunk_embeddings&quot;]) .setOutputCol(&quot;recognized&quot;) .setNeighbours(1000) .setAlternatives(25) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setEnableWmd(True).setEnableTfidf(True).setEnableJaccard(True) .setEnableSorensenDice(True).setEnableJaroWinkler(True).setEnableLevenshtein(True) .setDistanceWeights([1, 2, 2, 1, 1, 1]) .setAllDistancesMetadata(True) .setPoolingStrategy(&quot;MAX&quot;) .setThreshold(1e32) model = snomedExtractor.fit(snomedData) // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData)",
    "url": "/docs/en/licensed_training",
    "relUrl": "/docs/en/licensed_training"
  },
  "1263": {
    "id": "1263",
    "title": "Version Compatibility",
    "content": "Spark NLP for Healthcare Spark NLP (Public) 5.1.0 5.1.0 5.0.2 5.0.2 5.0.1 5.0.1 5.0.0 5.0.0 4.4.4 4.4.4 4.4.3 4.4.1 4.4.2 4.4.1 4.4.1 4.4.1 4.4.0 4.4.0 4.3.2 4.3.2 4.3.1 4.3.1 4.3.0 4.3.0 4.2.8 4.2.8 4.2.7 4.2.7 4.2.4 4.2.4 4.2.3 4.2.4 4.2.2 4.2.2 4.2.1 4.2.1 4.2.0 4.2.0 4.1.0 4.1.0 4.0.2 4.0.2 4.0.0 4.0.0 3.5.3 3.4.4 3.5.2 3.4.4 3.5.1 3.4.3 3.5.0 3.4.2 3.4.2 3.4.2 3.4.1 3.4.1 3.4.0 3.4.0 3.3.4 3.3.4 3.3.2 3.3.2 3.3.1 3.3.1 3.3.0 3.3.0 3.2.3 3.2.3 3.2.2 3.2.2 3.2.1 3.2.1 3.2.0 3.2.1 3.1.3 3.1.3 3.1.2 3.1.2 3.1.1 3.1.0 3.1.0 3.1.0 3.0.3 3.0.3 3.0.2 3.0.2 3.0.1 3.0.1 3.0.0 3.0.1 2.7.6 2.7.4 2.7.5 2.7.4 2.7.4 2.7.3 2.7.3 2.7.3 2.7.2 2.6.5 2.7.1 2.6.4 2.7.0 2.6.3 2.6.2 2.6.2 2.6.0 2.6.0 2.5.5 2.5.5 2.5.3 2.5.3 2.5.2 2.5.2 2.5.0 2.5.0 2.4.7 2.4.5 2.4.6 2.4.5 2.4.5 2.4.5 2.4.2 2.4.2 2.4.1 2.4.1 2.4.0 2.4.0 2.3.6 2.3.6 2.3.5 2.3.5 2.3.4 2.3.4 Spark NLP for Healthcare Spark OCR 4.3.0 4.3.1 4.2.4 4.3.0 4.2.3 4.2.4 4.2.1 4.2.0 4.1.0 4.1.0 4.0.0 4.0.0 3.5.3 3.13.0 3.5.1 3.12.0 3.5.0 3.11.0 3.4.2 3.11.0 3.4.1 3.11.0 3.4.0 3.11.0 3.3.4 3.10.0 3.3.2 3.9.0 3.3.1 3.9.0",
    "url": "/docs/en/licensed_version_compatibility",
    "relUrl": "/docs/en/licensed_version_compatibility"
  },
  "1264": {
    "id": "1264",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/light_pipeline.html",
    "relUrl": "/api/python/modules/sparknlp/base/light_pipeline.html"
  },
  "1265": {
    "id": "1265",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/light_pipelines.html",
    "relUrl": "/api/python/user_guide/light_pipelines.html"
  },
  "1266": {
    "id": "1266",
    "title": "LLM Prompts",
    "content": "Entity Extraction and Pre-Annotation via GPT Prompting The highlight of this release is the integration with an external service provider, Open AI, to expand and deepen the range of prompts available for pre-annotation (in addition to the Zero Shot entity and relation prompts already supported). This feature:. Broadens Prompt Possibilities: By integrating with Open AI LLM models, users can tap into a more diverse set of prompts, leveraging external expertise to craft pre-annotations, as an alternative pre-annotation solution or when pre-trained models are not available. Efficient Entity Extraction: As current LLMs, GPT family included, are not very good at entity recognition tasks, NLP Lab included a post-processing step on the result provided by LLM. This improves entity identification and helps precisely locate the entities in the given text. These entities, carefully curated and aligned with NLP Lab pre-annotation requirements pave the way for a more efficient and streamlined annotation experience. The following sections explain in detail how to define and use GPT prompts. Setting Up the Integration with Open AI service Integrating “ChatGPT” into the NLP Lab has been designed to be a straightforward process, ensuring users can harness the power of external expertise seamlessly. It consists of three easy steps: Integrations Page: Navigate to the Integrations Page located within the System Settings. This is the hub where all external service providers, including Open AI’s GPT Models, can be defined and managed. Define the Service Provider: To initiate the integration, users are required to provide specific details: Service Provider Name: This is the identifier for the external service, which in this case would be “ChatGPT” or any other name you prefer to use. Secret Key: Every external service comes with a unique Secret Key that ensures secure communication between the platforms. Enter the Secret Key associated with your Open AI subscription here. To ensure the integration process is error-free, users can validate the provided Secret Key directly within the form. This validation step ensures that the connection is secure and that the key is correct. Project Association: Once a successful connection with “ChatGPT” (or any external LLM service provider) is established, it doesn’t end there. The integrated service will now be available for association with selected projects. This means users can decide which projects will benefit from the “ChatGPT” integration and enable it accordingly. The Open AI integration allows users to tap into a vast reservoir of external expertise, enhancing the depth and breadth of their projects. We’ve ensured that the integration process is as intuitive as possible, allowing users to focus on what truly matters: crafting refined and effective pre-annotations. ChatGPT Prompt Definition and Testing Users can generate LLM prompts on the dedicated Prompt page from the Hub of Resources. For ChatGPT Prompts, NLP Lab offers a dedicated definition interface. Here’s what to expect when creating a new LLM prompt: Name the Prompt: Within this new tab, users will first be asked to provide a name for their prompt. This name will be used for pre-annotating identified entities. At this point, we recommend creating one prompt per target entity. Select the Service Provider: Next, users can choose the specific service provider they’ve previously set up via the Integrations Page. Test in Real-time: A standout feature is the ability to test ChatGPT prompts at creation time. As you craft your prompt, you can immediately see how it performs on some test data. This not only allows for immediate feedback but also ensures that the final prompt aligns perfectly with the user’s objectives. This streamlined approach ensures that integrating and testing external prompts is as intuitive and efficient as possible. Consistent Workflow with LLM Prompts Even with the introduction of new features in NLP Lab’s 5.3.0 release, users can take comfort in the consistent experience offered when working with prompts. The addition of external service provider prompts brings a fresh layer to the annotation process, yet the core workflow you’re familiar with stays the same. Familiarity Amidst Innovation: Despite the new integrations, the process of using available prompts remains as straightforward as ever. Whether you’re working with traditional prompts or the newly introduced ones, the experience is smooth and consistent. Seamless Transition: Our commitment to user-centric design means that even as we innovate, we prioritize the ease of use you’ve come to expect. Transitioning to or incorporating external prompts is made effortless, with the interface and steps for prompt creation, selection, and integration remaining intuitive and unchanged. With NLP Lab 5.3.0, you get the best of both worlds: exciting new features and the comfort of a familiar workflow. Note: Pre-annotation of tasks using LLM Prompts does not require the deployment of the pre-annotation server. The pop-up to deploy the pre-annotation server is only shown if the project configuration consists of both LLM prompts and spark NLP models.",
    "url": "/docs/en/alab/llm_prompts",
    "relUrl": "/docs/en/alab/llm_prompts"
  },
  "1267": {
    "id": "1267",
    "title": "The nlp.load() function",
    "content": "The nlp.load() method takes in one or multiple nlp pipeline, model or component references separated by whitespaces. See the Model Namespace for an overview of all possible nlp references. NLP will induce the following reference format for any query to the load method: language.component_type.dataset.embeddings i.e.: en.sentiment.twitter.use It is possible to omit many parts of the query and the nlp module will provide the best possible defaults, like embeddings for choosing a dataset. The NLP Namespace also provides a few aliases which make referencing a model even easier! This makes it possible to get predictions by only referencing the component name Examples for aliases are nlp.load(‘bert’) or nlp.load(‘sentiment’) It is possible to omit the language prefix and start the query with : component_type.dataset.embeddings the nlp module will automatically set the language to english in this case. The nlp.load() method returns a NLU pipeline object which provides predictions : from johnsnowlabs import nlp pipeline = nlp.load(&#39;sentiment&#39;) pipeline.predict(&quot;I love this Documentation! It&#39;s so good!&quot;) This is equal to: from johnsnowlabs import nlp nlp.load(&#39;sentiment&#39;).predict(&quot;I love this Documentation! It&#39;s so good!&quot;) Load Parameters The load method provides for now just one parameter verbose. Setting nlp.load(nlp_reference, verbose=True) will generate log outputs that can be helpful for troubleshooting. If you encounter any errors, please run Verbose mode and post your output on our Github Issues page. Description Parameter name NLP reference of the model request Path to a locally stored Spark NLP Model or Pipeline path Whether to load GPU jars or not. Set to True to enable. gpu Whether to load M1 jars or not. Set to True to enable. m1_chip Whether to use caching for the nlp.display() functions or not. Set to True to enable streamlit_caching Configuring loaded models To configure your model or pipeline, first load a NLP component and use the print_components() function. The print outputs tell you at which index of the pipe_components attribute which NLP component is located. Via setters which are named according to the parameter values a model can be configured # example for configuring the first element in the component_list pipe = nlp.load(&#39;en.sentiment.twitter&#39;) pipe.generate_class_metadata_table() document_assembler_model = pipe.components[0].model document_assembler_model.setCleanupMode(&#39;inplace&#39;) This will print -At pipe.pipe_components[0].model : document_assembler with configurable parameters: -- Param Name [ cleanupMode ] : Param Info : possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full currently Configured as : disabled --At pipe.pipe_components[1].model : glove with configurable parameters: -- Param Name [ dimension ] : Param Info : Number of embedding dimensions currently Configured as : 512 -At pipe.pipe_components[2].model : sentiment_dl with configurable parameters: - Param Name [ threshold ] : Param Info : The minimum threshold for the final result otherwise it will be neutral currently Configured as : 0.6 Param Name [ thresholdLabel ] : Param Info : In case the score is less than threshold, what should be the label. Default is neutral. currently Configured as : neutral Param Name [ classes ] : Param Info : get the tags used to trained this NerDLModel currently Configured as : [&#39;positive&#39;, &#39;negative&#39;] Namespace The NLP name space describes the collection of all models, pipelines and components available in NLP and supported by the nlp.load() method. You can view it on the Name Space page",
    "url": "/docs/en/jsl/load_api",
    "relUrl": "/docs/en/jsl/load_api"
  },
  "1268": {
    "id": "1268",
    "title": "Legal Document Splitting - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/long_document_splitting",
    "relUrl": "/long_document_splitting"
  },
  "1269": {
    "id": "1269",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/longformer_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/longformer_embeddings.html"
  },
  "1270": {
    "id": "1270",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_question_answering.html"
  },
  "1271": {
    "id": "1271",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification.html"
  },
  "1272": {
    "id": "1272",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_token_classification.html"
  },
  "1273": {
    "id": "1273",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/seq2seq/marian_transformer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/seq2seq/marian_transformer.html"
  },
  "1274": {
    "id": "1274",
    "title": "Medical Question Answering - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/medical_question_answering",
    "relUrl": "/medical_question_answering"
  },
  "1275": {
    "id": "1275",
    "title": "Medical Text Generation - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/medical_text_generation",
    "relUrl": "/medical_text_generation"
  },
  "1276": {
    "id": "1276",
    "title": "Medical Text Summarization - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/medical_text_summarization",
    "relUrl": "/medical_text_summarization"
  },
  "1277": {
    "id": "1277",
    "title": "Mental Health - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/mental_health",
    "relUrl": "/mental_health"
  },
  "1278": {
    "id": "1278",
    "title": "Middle Eastern Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/middle_eastern_languages",
    "relUrl": "/middle_eastern_languages"
  },
  "1279": {
    "id": "1279",
    "title": "Experiment Tracking",
    "content": "",
    "url": "/docs/en/mlflow",
    "relUrl": "/docs/en/mlflow"
  },
  "1280": {
    "id": "1280",
    "title": "Spellbook",
    "content": "Default Component References See and also the John Snow Labs Modelhub and also the John Snow Labs Model Repository for further information about the models and pipelines. Each String in the NLP reference column can be passed to nlp.load() to get the corresponding model wrapped inside a NLP Pipeline. Language nlp.load() Reference Spark NLP Reference Component Type English yake yake pipe English xlnet xlnet_base_cased pipe English use tfhub_use pipe English toxic multiclassifierdl_use_toxic pipe English tokenize spark_nlp_tokenizer pipe English t5 t5_base pipe English summarize t5_base pipe English stopwords stopwords_en pipe English stem stemmer pipe English spell spellcheck_dl pipe English spell.symmetric spellcheck_sd pipe English spell.norivg spellcheck_norvig pipe English spam classifierdl_use_spam pipe English sentiment sentimentdl_glove_imdb pipe English sentiment.vivekn sentiment_vivekn pipe English sentiment.twitter analyze_sentimentdl_use_twitter model English sentiment.twitter.use analyze_sentimentdl_use_twitter model English sentiment.imdb analyze_sentimentdl_use_imdb model English sentiment.imdb.use analyze_sentimentdl_use_imdb pipe English sentiment.imdb.glove sentimentdl_glove_imdb pipe English sentence_detector sentence_detector_dl pipe English sentence_detector.pragmatic pragmatic_sentence_detector pipe English sentence_detector.deep sentence_detector_dl model English sarcasm classifierdl_use_sarcasm model English questions classifierdl_use_trec50 model English pos pos_anc model English pos.ud_ewt pos_ud_ewt model English pos.anc pos_anc model English norm_document normalizer model English norm normalizer model English ngram ngram model English ner onto_recognize_entities_sm model English ner.onto onto_recognize_entities_sm model English ner.onto.sm onto_recognize_entities_sm model English ner.onto.glove.6B_300d onto_300 model English ner.onto.glove.6B_100d onto_100 model English ner.dl recognize_entities_dl model English ner.dl.glove.6B_100d ner_dl model English ner.dl.bert ner_dl_bert model English ner.conll recognize_entities_dl model English ner.bert recognize_entities_bert model English match.chunks match_chunks model English lemma lemma_antbnc model English lemma.antbnc lemma_antbnc model English lang detect_language_375 model English grammar_correctness t5_base model English glove glove_100d model English explain explain_document_ml model English explain.ml explain_document_ml model English explain.dl explain_document_dl model English emotion classifierdl_use_emotion model English embed_sentence tfhub_use model English embed_sentence.use_lg tfhub_use_lg model English embed_sentence.use tfhub_use model English embed_sentence.tfhub_use_lg tfhub_use_lg model English embed_sentence.tfhub_use tfhub_use model English embed_sentence.small_bert_L2_128 sent_small_bert_L2_128 model English embed_sentence.electra sent_electra_small_uncased model English embed_sentence.bert sent_small_bert_L2_128 model English embed_chunk chunk_embeddings model English embed glove_100d model English embed.xlnet_large_cased xlnet_large_cased model English embed.xlnet_base_cased xlnet_base_cased model English embed.xlnet xlnet_base_cased model English embed.glove glove_100d model English embed.glove.840B_300 glove_840B_300 model English embed.glove.100d glove_100d model English embed.elmo elmo model English embed.electra electra_small_uncased model English embed.biobert_pubmed_pmc_base_cased biobert_pubmed_pmc_base_cased model English embed.biobert_pubmed_large_cased biobert_pubmed_large_cased model English embed.biobert_pubmed_base_cased biobert_pubmed_base_cased model English embed.biobert_pmc_base_cased biobert_pmc_base_cased model English embed.biobert_discharge_base_cased biobert_discharge_base_cased model English embed.biobert_clinical_base_cased biobert_clinical_base_cased model English embed.biobert biobert_pubmed_base_cased model English embed.bert_large_uncased bert_large_uncased model English embed.bert_large_cased bert_large_cased model English embed.bert_base_uncased bert_base_uncased model English embed.bert_base_cased bert_base_cased model English embed.bert bert_base_uncased model English embed.albert_xxlarge_uncased albert_xxlarge_uncased model English embed.albert_xlarge_uncased albert_xlarge_uncased model English embed.albert_large_uncased albert_large_uncased model English embed.albert_base_uncased albert_base_uncased model English elmo elmo model English electra electra_small_uncased model English e2e multiclassifierdl_use_e2e model English dependency dependency_conllu model English dep dependency_typed_conllu model English dep.untyped dependency_conllu model English dep.untyped.conllu dependency_conllu model English dep.typed dependency_typed_conllu model English dep.typed.conllu dependency_typed_conllu model English cyberbullying classifierdl_use_cyberbullying model English covidbert covidbert_large_uncased model English clean.stop clean_stop model English clean.slang clean_slang model English classify analyze_sentiment model English classify.trec6 classifierdl_use_trec6 model English classify.trec6.use classifierdl_use_trec6 model English classify.trec50 classifierdl_use_trec50 model English classify.trec50.use classifierdl_use_trec50 model English classify.spam classifierdl_use_spam model English classify.spam.use classifierdl_use_spam model English classify.sentiment_t5 t5_base model English classify.sarcasm classifierdl_use_sarcasm model English classify.sarcasm.use classifierdl_use_sarcasm model English classify.questions classifierdl_use_trec50 model English classify.lang detect_language_375 model English classify.fakenews classifierdl_use_fakenews model English classify.fakenews.use classifierdl_use_fakenews model English classify.emotion classifierdl_use_emotion model English classify.emotion.use classifierdl_use_emotion model English classify.cyberbullying classifierdl_use_cyberbullying model English classify.cyberbullying.use classifierdl_use_cyberbullying model English chunk default_chunker model English biobert biobert_pubmed_base_cased model English bert small_bert_L2_128 model English answer_question t5_base model English albert albert_base_uncased model Model references | Language Name(s) | nlp.load() Reference | Spark NLP Reference | |:———————————————————————————————————————-|:—————————————————————————————————————————————————————————————————————————————————|:———————————————————————————————————————————————————————————————————————————————————————–| | Aequian | vn.answer_question.xlm_roberta.base | xlm_roberta_qa_xlm_roberta_base_vietnamese | | Aequian | roberta | distilroberta_base | | Church Slavic, Church Slavonic, Old Bulgarian, Old Church Slavonic, Old Slavonic | cu.pos | pos_proiel | | Church Slavic, Church Slavonic, Old Bulgarian, Old Church Slavonic, Old Slavonic | cu.lemma | lemma_proiel | | Church Slavic, Church Slavonic, Old Bulgarian, Old Church Slavonic, Old Slavonic | cu.lemma.proiel | lemma_proiel | | Gothic | got.pos.proiel | pos_proiel | | Gothic | got.lemma | lemma_proiel | | Gothic | got.lemma.proiel | lemma_proiel | | Latin | la.stopwords | stopwords_la | | Latin | la.pos | pos_perseus | | Latin | la.pos.udante | pos_udante | | Latin | la.pos.proiel | pos_proiel | | Latin | la.pos.perseus | pos_perseus | | Latin | la.pos.llct | pos_llct | | Latin | la.pos.ittb | pos_ittb | | Latin | la.lemma | lemma_proiel | | Latin | la.lemma.udante | lemma_udante | | Latin | la.lemma.proiel | lemma_proiel | | Latin | la.lemma.perseus | lemma_perseus | | Latin | la.lemma.llct | lemma_llct | | Latin | la.lemma.ittb | lemma_ittb | | Sanskrit | sa.stopwords | stopwords_iso | | Sanskrit | sa.pos | pos_vedic | | Sanskrit | sa.lemma | lemma_vedic | | Sanskrit | sa.embed.w2v_cc_300d | w2v_cc_300d | | Esperanto | xx.eo.marian.translate_to.vi | opus_mt_vi_eo | | Esperanto | xx.eo.marian.translate_to.tr | opus_mt_tr_eo | | Esperanto | xx.eo.marian.translate_to.sv | opus_mt_sv_eo | | Esperanto | xx.eo.marian.translate_to.sh | opus_mt_sh_eo | | Esperanto | xx.eo.marian.translate_to.ru | opus_mt_ru_eo | | Esperanto | xx.eo.marian.translate_to.ro | opus_mt_ro_eo | | Esperanto | xx.eo.marian.translate_to.pt | opus_mt_pt_eo | | Esperanto | xx.eo.marian.translate_to.pl | opus_mt_pl_eo | | Esperanto | xx.eo.marian.translate_to.nl | opus_mt_nl_eo | | Esperanto | xx.eo.marian.translate_to.lt | opus_mt_lt_eo | | Esperanto | xx.eo.marian.translate_to.it | opus_mt_it_eo | | Esperanto | xx.eo.marian.translate_to.is | opus_mt_is_eo | | Esperanto | xx.eo.marian.translate_to.hu | opus_mt_hu_eo | | Esperanto | xx.eo.marian.translate_to.he | opus_mt_he_eo | | Esperanto | xx.eo.marian.translate_to.fr | opus_mt_fr_eo | | Esperanto | xx.eo.marian.translate_to.fi | opus_mt_fi_eo | | Esperanto | xx.eo.marian.translate_to.es | opus_mt_es_eo | | Esperanto | xx.eo.marian.translate_to.en | opus_mt_eo_en | | Esperanto | xx.eo.marian.translate_to.el | opus_mt_el_eo | | Esperanto | xx.eo.marian.translate_to.de | opus_mt_de_eo | | Esperanto | xx.eo.marian.translate_to.da | opus_mt_da_eo | | Esperanto | xx.eo.marian.translate_to.cs | opus_mt_cs_eo | | Esperanto | xx.eo.marian.translate_to.bg | opus_mt_bg_eo | | Esperanto | xx.eo.marian.translate_to.ar | opus_mt_ar_eo | | Esperanto | xx.eo.marian.translate_to.af | opus_mt_af_eo | | Esperanto | eo.stopwords | stopwords_eo | | Esperanto | eo.embed.w2v_cc_300d | w2v_cc_300d | | Volapük | vo.embed.w2v_cc_300d | w2v_cc_300d | | Coptic | cop.pos | pos_scriptorium | | Coptic | cop.lemma | lemma_scriptorium | | Coptic | cop.lemma.scriptorium | lemma_scriptorium | | Afro-Asiatic languages | xx.afa.marian.translate_to.en | opus_mt_afa_en | | Afro-Asiatic languages | xx.afa.marian.translate_to.afa | opus_mt_afa_afa | | Atlantic-Congo languages | xx.alv.marian.translate_to.en | opus_mt_alv_en | | Austro-Asiatic languages | xx.aav.marian.translate_to.en | opus_mt_aav_en | | Baltic languages | xx.bat.marian.translate_to.en | opus_mt_bat_en | | Bantu languages | xx.bnt.marian.translate_to.en | opus_mt_bnt_en | | Basque (family) | xx.euq.marian.translate_to.en | opus_mt_euq_en | | Berber languages | xx.ber.marian.translate_to.fr | opus_mt_fr_ber | | Berber languages | xx.ber.marian.translate_to.es | opus_mt_es_ber | | Berber languages | xx.ber.marian.translate_to.en | opus_mt_ber_en | | Celtic languages | xx.cel.marian.translate_to.en | opus_mt_cel_en | | Cushitic languages | xx.cus.marian.translate_to.en | opus_mt_cus_en | | Dravidian languages | xx.dra.marian.translate_to.en | opus_mt_dra_en | | East Slavic languages | xx.zle.marian.translate_to.zle | opus_mt_zle_zle | | East Slavic languages | xx.zle.marian.translate_to.en | opus_mt_zle_en | | Eastern Malayo-Polynesian languages | xx.pqe.marian.translate_to.en | opus_mt_pqe_en | | Finno-Ugrian languages | xx.fiu.marian.translate_to.fiu | opus_mt_fiu_fiu | | Finno-Ugrian languages | xx.fiu.marian.translate_to.en | opus_mt_fiu_en | | Germanic languages | xx.gem.marian.translate_to.gem | opus_mt_gem_gem | | Germanic languages | xx.gem.marian.translate_to.en | opus_mt_gem_en | | Greek languages | xx.grk.marian.translate_to.en | opus_mt_grk_en | | Indic languages | xx.inc.marian.translate_to.inc | opus_mt_inc_inc | | Indic languages | xx.inc.marian.translate_to.en | opus_mt_inc_en | | Indo-European languages | xx.ine.marian.translate_to.ine | opus_mt_ine_ine | | Multilingual | xx.classify.wiki_21 | ld_wiki_tatoeba_cnn_21 | | Multilingual | xx.classify.wiki_21.bigru | ld_tatoeba_bigru_21 | | Multilingual | xx.classify.token_xlm_roberta.token_classifier_ner_40_lang | xlm_roberta_token_classifier_ner_40_lang | | Multilingual | xx.answer_question.xquad_tydiqa.bert.cased | bert_qa_bert_multi_cased_finedtuned_xquad_tydiqa_goldp | | Multilingual | xx.answer_question.xquad.bert.uncased | bert_qa_bert_multi_uncased_finetuned_xquadv1 | | Multilingual | xx.answer_question.xquad.bert.cased | bert_qa_bert_multi_cased_finetuned_xquadv1 | | Multilingual | xx.answer_question.xlm_roberta.distilled | xlm_roberta_qa_distill_xlm_mrc | | Multilingual | xx.answer_question.tydiqa.multi_lingual_bert | bert_qa_Part_1_mBERT_Model_E1 | | Multilingual | xx.answer_question.tydiqa.bert | bert_qa_telugu_bertu_tydiqa | | Multilingual | xx.answer_question.squad.distil_bert.en_de_es_tuned.by_ZYW | distilbert_qa_squad_en_de_es_model | | Multilingual | xx.answer_question.squad.distil_bert._en_de_es_vi_zh_tuned.by_ZYW | distilbert_qa_squad_en_de_es_vi_zh_model | | Multilingual | xx.answer_question.roberta | roberta_qa_ft_lr_cu_leolin12345 | | Multilingual | xx.answer_question.distil_bert.vi_zh_es_tuned.by_ZYW | distilbert_qa_en_de_vi_zh_es_model | | Multilingual | xx.answer_question.distil_bert.en_de_tuned.by_ZYW | distilbert_qa_en_de_model | | Multilingual | xx.answer_question.distil_bert.en_de_es_tuned.by_ZYW | distilbert_qa_en_de_es_model | | Multilingual | xx.answer_question.chaii.xlm_roberta | xlm_roberta_qa_xlm_roberta_qa_chaii | Pipeline references Language Name(s) nlp.load() Reference Spark NLP Reference Aequian lang detect_language_375 Aequian lang.bigru detect_language_bigru_21 Aequian lang.99 detect_language_99 Aequian lang.95 detect_language_95 Aequian lang.7 detect_language_7 Aequian lang.43 detect_language_43 Aequian lang.231 detect_language_231 Aequian lang.220 detect_language_220 Aequian lang.21 detect_language_21 Aequian lang.20 detect_language_20 Esperanto xx.eo.translate_to.vi translate_vi_eo Esperanto xx.eo.translate_to.tr translate_tr_eo Esperanto xx.eo.translate_to.sv translate_sv_eo Esperanto xx.eo.translate_to.sh translate_sh_eo Esperanto xx.eo.translate_to.ru translate_ru_eo Esperanto xx.eo.translate_to.ro translate_ro_eo Esperanto xx.eo.translate_to.pt translate_pt_eo Esperanto xx.eo.translate_to.pl translate_pl_eo Esperanto xx.eo.translate_to.nl translate_nl_eo Esperanto xx.eo.translate_to.lt translate_lt_eo Esperanto xx.eo.translate_to.it translate_it_eo Esperanto xx.eo.translate_to.is translate_is_eo Esperanto xx.eo.translate_to.hu translate_hu_eo Esperanto xx.eo.translate_to.he translate_he_eo Esperanto xx.eo.translate_to.fr translate_fr_eo Esperanto xx.eo.translate_to.fi translate_fi_eo Esperanto xx.eo.translate_to.es translate_es_eo Esperanto xx.eo.translate_to.en translate_eo_en Esperanto xx.eo.translate_to.el translate_el_eo Esperanto xx.eo.translate_to.de translate_de_eo Esperanto xx.eo.translate_to.da translate_da_eo Esperanto xx.eo.translate_to.cs translate_cs_eo Esperanto xx.eo.translate_to.bg translate_bg_eo Esperanto xx.eo.translate_to.ar translate_ar_eo Esperanto xx.eo.translate_to.af translate_af_eo Afro-Asiatic languages xx.afa.translate_to.en translate_afa_en Afro-Asiatic languages xx.afa.translate_to.afa translate_afa_afa Atlantic-Congo languages xx.alv.translate_to.en translate_alv_en Austro-Asiatic languages xx.aav.translate_to.en translate_aav_en Baltic languages xx.bat.translate_to.en translate_bat_en Bantu languages xx.bnt.translate_to.en translate_bnt_en Basque (family) xx.euq.translate_to.en translate_euq_en Berber languages xx.ber.translate_to.fr translate_fr_ber Berber languages xx.ber.translate_to.es translate_es_ber Berber languages xx.ber.translate_to.en translate_ber_en Celtic languages xx.cel.translate_to.en translate_cel_en Cushitic languages xx.cus.translate_to.en translate_cus_en Dravidian languages xx.dra.translate_to.en translate_dra_en East Slavic languages xx.zle.translate_to.zle translate_zle_zle East Slavic languages xx.zle.translate_to.en translate_zle_en Eastern Malayo-Polynesian languages xx.pqe.translate_to.en translate_pqe_en Finno-Ugrian languages xx.fiu.translate_to.fiu translate_fiu_fiu Finno-Ugrian languages xx.fiu.translate_to.en translate_fiu_en Germanic languages xx.gem.translate_to.gem translate_gem_gem Germanic languages xx.gem.translate_to.en translate_gem_en Greek languages xx.grk.translate_to.en translate_grk_en Indic languages xx.inc.translate_to.inc translate_inc_inc Indic languages xx.inc.translate_to.en translate_inc_en Indo-European languages xx.ine.translate_to.ine translate_ine_ine Indo-European languages xx.ine.translate_to.en translate_ine_en Indo-Iranian languages xx.iir.translate_to.iir translate_iir_iir Indo-Iranian languages xx.iir.translate_to.en translate_iir_en Italic languages xx.itc.translate_to.itc translate_itc_itc Italic languages xx.itc.translate_to.en translate_itc_en Mon-Khmer languages xx.mkh.translate_to.en translate_mkh_en Niger-Kordofanian languages xx.nic.translate_to.en translate_nic_en North Germanic languages xx.gmq.translate_to.gmq translate_gmq_gmq North Germanic languages xx.gmq.translate_to.en translate_gmq_en Romance languages xx.roa.translate_to.en translate_roa_en Salishan languages xx.sal.translate_to.en translate_sal_en Semitic languages xx.sem.translate_to.sem translate_sem_sem Semitic languages xx.sem.translate_to.en translate_sem_en Slavic languages xx.sla.translate_to.sla translate_sla_sla Slavic languages xx.sla.translate_to.en translate_sla_en South Caucasian languages xx.ccs.translate_to.en translate_ccs_en South Slavic languages xx.zls.translate_to.zls translate_zls_zls South Slavic languages xx.zls.translate_to.en translate_zls_en Turkic languages xx.trk.translate_to.en translate_trk_en Uralic languages xx.urj.translate_to.urj translate_urj_urj Uralic languages xx.urj.translate_to.en translate_urj_en West Germanic languages xx.gmw.translate_to.gmw translate_gmw_gmw West Germanic languages xx.gmw.translate_to.en translate_gmw_en West Slavic languages xx.zlw.translate_to.zlw translate_zlw_zlw West Slavic languages xx.zlw.translate_to.en translate_zlw_en Artificial languages xx.art.translate_to.en translate_art_en French-based creoles and pidgins xx.cpf.translate_to.en translate_cpf_en Portuguese-based creoles and pidgins xx.cpp.translate_to.en translate_cpp_en Portuguese-based creoles and pidgins xx.cpp.translate_to.cpp translate_cpp_cpp Caucasian languages xx.cau.translate_to.en translate_cau_en Philippine languages xx.phi.translate_to.en translate_phi_en Afrikaans xx.af.translate_to.sv translate_sv_af Afrikaans xx.af.translate_to.ru translate_ru_af Afrikaans xx.af.translate_to.nl translate_nl_af Afrikaans xx.af.translate_to.fr translate_fr_af Afrikaans xx.af.translate_to.fi translate_fi_af Afrikaans xx.af.translate_to.es translate_es_af Afrikaans xx.af.translate_to.eo translate_eo_af Afrikaans xx.af.translate_to.en translate_af_en Afrikaans xx.af.translate_to.de translate_de_af American Sign Language xx.ase.translate_to.sv translate_sv_ase American Sign Language xx.ase.translate_to.fr translate_fr_ase American Sign Language xx.ase.translate_to.es translate_es_ase American Sign Language xx.ase.translate_to.en translate_ase_en American Sign Language xx.ase.translate_to.de translate_de_ase Argentine Sign Language xx.aed.translate_to.es translate_es_aed Armenian xx.hy.translate_to.ru translate_ru_hy Armenian xx.hy.translate_to.en translate_hy_en Basque xx.eu.translate_to.ru translate_ru_eu Basque xx.eu.translate_to.es translate_es_eu Basque xx.eu.translate_to.en translate_eu_en Basque xx.eu.translate_to.de translate_de_eu Bemba (Zambia) xx.bem.translate_to.sv translate_sv_bem Bemba (Zambia) xx.bem.translate_to.fr translate_fr_bem Bemba (Zambia) xx.bem.translate_to.fi translate_fi_bem Bemba (Zambia) xx.bem.translate_to.en translate_bem_en Bengali xx.bn.translate_to.en translate_bn_en Bislama xx.bi.translate_to.sv translate_sv_bi Bislama xx.bi.translate_to.fr translate_fr_bi Bislama xx.bi.translate_to.es translate_es_bi Bislama xx.bi.translate_to.en translate_bi_en Bislama xx.bi.translate_to.de translate_de_bi Brazilian Sign Language xx.bzs.translate_to.sv translate_sv_bzs Brazilian Sign Language xx.bzs.translate_to.fr translate_fr_bzs Brazilian Sign Language xx.bzs.translate_to.fi translate_fi_bzs Brazilian Sign Language xx.bzs.translate_to.es translate_es_bzs Brazilian Sign Language xx.bzs.translate_to.en translate_bzs_en Brazilian Sign Language xx.bzs.translate_to.de translate_de_bzs Bulgarian xx.bg.translate_to.zh translate_zh_bg Bulgarian xx.bg.translate_to.uk translate_uk_bg Bulgarian xx.bg.translate_to.sv translate_sv_bg Bulgarian xx.bg.translate_to.ru translate_ru_bg Bulgarian xx.bg.translate_to.ja translate_ja_bg Bulgarian xx.bg.translate_to.it translate_it_bg Bulgarian xx.bg.translate_to.fr translate_fr_bg Bulgarian xx.bg.translate_to.fi translate_fi_bg Bulgarian xx.bg.translate_to.es translate_es_bg Bulgarian xx.bg.translate_to.eo translate_eo_bg Bulgarian xx.bg.translate_to.en translate_bg_en Bulgarian xx.bg.translate_to.de translate_de_bg Castilian, Spanish xx.es.translate_to.zne translate_zne_es Castilian, Spanish xx.es.translate_to.zai translate_zai_es Castilian, Spanish xx.es.translate_to.yo translate_yo_es Castilian, Spanish xx.es.translate_to.xh translate_xh_es Castilian, Spanish xx.es.translate_to.war translate_war_es Castilian, Spanish xx.es.translate_to.vsl translate_vsl_es Castilian, Spanish xx.es.translate_to.vi translate_vi_es Castilian, Spanish xx.es.translate_to.ve translate_ve_es Castilian, Spanish xx.es.translate_to.uk translate_uk_es Castilian, Spanish xx.es.translate_to.tzo translate_tzo_es Castilian, Spanish xx.es.translate_to.ty translate_ty_es Castilian, Spanish xx.es.translate_to.tw translate_tw_es Castilian, Spanish xx.es.translate_to.tvl translate_tvl_es Castilian, Spanish xx.es.translate_to.tum translate_tum_es Castilian, Spanish xx.es.translate_to.ts translate_ts_es Castilian, Spanish xx.es.translate_to.tr translate_tr_es Castilian, Spanish xx.es.translate_to.toi translate_toi_es Castilian, Spanish xx.es.translate_to.to translate_to_es Castilian, Spanish xx.es.translate_to.tn translate_tn_es Castilian, Spanish xx.es.translate_to.tll translate_tll_es Castilian, Spanish xx.es.translate_to.tl translate_tl_es Castilian, Spanish xx.es.translate_to.swc translate_swc_es Castilian, Spanish xx.es.translate_to.sv translate_sv_es Castilian, Spanish xx.es.translate_to.st translate_st_es Castilian, Spanish xx.es.translate_to.ssp translate_ssp_es Castilian, Spanish xx.es.translate_to.srn translate_srn_es Castilian, Spanish xx.es.translate_to.sq translate_sq_es Castilian, Spanish xx.es.translate_to.sn translate_sn_es Castilian, Spanish xx.es.translate_to.sm translate_sm_es Castilian, Spanish xx.es.translate_to.sl translate_sl_es Castilian, Spanish xx.es.translate_to.sk translate_sk_es Castilian, Spanish xx.es.translate_to.sg translate_sg_es Castilian, Spanish xx.es.translate_to.rw translate_rw_es Castilian, Spanish xx.es.translate_to.run translate_run_es Castilian, Spanish xx.es.translate_to.ru translate_ru_es Castilian, Spanish xx.es.translate_to.rn translate_rn_es Castilian, Spanish xx.es.translate_to.prl translate_prl_es Castilian, Spanish xx.es.translate_to.pon translate_pon_es Castilian, Spanish xx.es.translate_to.pl translate_pl_es Castilian, Spanish xx.es.translate_to.pis translate_pis_es Castilian, Spanish xx.es.translate_to.pap translate_pap_es Castilian, Spanish xx.es.translate_to.pag translate_pag_es Castilian, Spanish xx.es.translate_to.ny translate_ny_es Castilian, Spanish xx.es.translate_to.nso translate_nso_es Castilian, Spanish xx.es.translate_to.no translate_no_es Castilian, Spanish xx.es.translate_to.nl translate_nl_es Castilian, Spanish xx.es.translate_to.niu translate_niu_es Castilian, Spanish xx.es.translate_to.mt translate_mt_es Castilian, Spanish xx.es.translate_to.mk translate_mk_es Castilian, Spanish xx.es.translate_to.mh translate_mh_es Castilian, Spanish xx.es.translate_to.mg translate_mg_es Castilian, Spanish xx.es.translate_to.mfs translate_mfs_es Castilian, Spanish xx.es.translate_to.mfe translate_mfe_es Castilian, Spanish xx.es.translate_to.lv translate_lv_es Castilian, Spanish xx.es.translate_to.lus translate_lus_es Castilian, Spanish xx.es.translate_to.lue translate_lue_es Castilian, Spanish xx.es.translate_to.lua translate_lua_es Castilian, Spanish xx.es.translate_to.lu translate_lu_es Castilian, Spanish xx.es.translate_to.lt translate_lt_es Castilian, Spanish xx.es.translate_to.loz translate_loz_es Castilian, Spanish xx.es.translate_to.ln translate_ln_es Castilian, Spanish xx.es.translate_to.lg translate_lg_es Castilian, Spanish xx.es.translate_to.kqn translate_kqn_es Castilian, Spanish xx.es.translate_to.ko translate_ko_es Castilian, Spanish xx.es.translate_to.kg translate_kg_es Castilian, Spanish xx.es.translate_to.ja translate_ja_es Castilian, Spanish xx.es.translate_to.it translate_it_es Castilian, Spanish xx.es.translate_to.iso translate_iso_es Castilian, Spanish xx.es.translate_to.is translate_is_es Castilian, Spanish xx.es.translate_to.ilo translate_ilo_es Castilian, Spanish xx.es.translate_to.ig translate_ig_es Castilian, Spanish xx.es.translate_to.id translate_id_es Castilian, Spanish xx.es.translate_to.ht translate_ht_es Castilian, Spanish xx.es.translate_to.hr translate_hr_es Castilian, Spanish xx.es.translate_to.he translate_he_es Castilian, Spanish xx.es.translate_to.ha translate_ha_es Castilian, Spanish xx.es.translate_to.guw translate_guw_es Castilian, Spanish xx.es.translate_to.gl translate_gl_es Castilian, Spanish xx.es.translate_to.gil translate_gil_es Castilian, Spanish xx.es.translate_to.gaa translate_gaa_es Castilian, Spanish xx.es.translate_to.fr translate_fr_es Castilian, Spanish xx.es.translate_to.fi translate_fi_es Castilian, Spanish xx.es.translate_to.eu translate_eu_es Castilian, Spanish xx.es.translate_to.et translate_et_es Castilian, Spanish xx.es.translate_to.es translate_es_es Castilian, Spanish xx.es.translate_to.eo translate_eo_es Castilian, Spanish xx.es.translate_to.en translate_es_en Castilian, Spanish xx.es.translate_to.ee translate_ee_es Castilian, Spanish xx.es.translate_to.de translate_de_es Castilian, Spanish xx.es.translate_to.da translate_da_es Castilian, Spanish xx.es.translate_to.csn translate_csn_es Castilian, Spanish xx.es.translate_to.csg translate_csg_es Castilian, Spanish xx.es.translate_to.crs translate_crs_es Castilian, Spanish xx.es.translate_to.chk translate_chk_es Castilian, Spanish xx.es.translate_to.ceb translate_ceb_es Castilian, Spanish xx.es.translate_to.ca translate_ca_es Castilian, Spanish xx.es.translate_to.bzs translate_bzs_es Castilian, Spanish xx.es.translate_to.bi translate_bi_es Castilian, Spanish xx.es.translate_to.bg translate_bg_es Castilian, Spanish xx.es.translate_to.ber translate_ber_es Castilian, Spanish xx.es.translate_to.bem translate_bem_es Castilian, Spanish xx.es.translate_to.be translate_be_es Castilian, Spanish xx.es.translate_to.bcl translate_bcl_es Castilian, Spanish xx.es.translate_to.az translate_az_es Castilian, Spanish xx.es.translate_to.ase translate_ase_es Castilian, Spanish xx.es.translate_to.ar translate_ar_es Castilian, Spanish xx.es.translate_to.af translate_af_es Castilian, Spanish xx.es.translate_to.aed translate_aed_es Castilian, Spanish es.ner entity_recognizer_sm Castilian, Spanish es.ner.sm entity_recognizer_sm Castilian, Spanish es.ner.md entity_recognizer_md Castilian, Spanish es.ner.lg entity_recognizer_lg Castilian, Spanish es.explain explain_document_sm Castilian, Spanish es.explain.sm explain_document_sm Castilian, Spanish es.explain.md explain_document_md Castilian, Spanish es.explain.lg explain_document_lg Catalan, Valencian xx.ca.translate_to.uk translate_uk_ca Catalan, Valencian xx.ca.translate_to.pt translate_pt_ca Catalan, Valencian xx.ca.translate_to.nl translate_nl_ca Catalan, Valencian xx.ca.translate_to.it translate_it_ca Catalan, Valencian xx.ca.translate_to.fr translate_fr_ca Catalan, Valencian xx.ca.translate_to.es translate_es_ca Catalan, Valencian xx.ca.translate_to.en translate_ca_en Catalan, Valencian xx.ca.translate_to.de translate_de_ca Cebuano xx.ceb.translate_to.sv translate_sv_ceb Cebuano xx.ceb.translate_to.fr translate_fr_ceb Cebuano xx.ceb.translate_to.fi translate_fi_ceb Cebuano xx.ceb.translate_to.es translate_es_ceb Cebuano xx.ceb.translate_to.en translate_ceb_en Central Bikol xx.bcl.translate_to.sv translate_sv_bcl Central Bikol xx.bcl.translate_to.fr translate_fr_bcl Central Bikol xx.bcl.translate_to.fi translate_fi_bcl Central Bikol xx.bcl.translate_to.es translate_es_bcl Central Bikol xx.bcl.translate_to.en translate_bcl_en Central Bikol xx.bcl.translate_to.de translate_de_bcl Chewa, Chichewa, Nyanja xx.ny.translate_to.sv translate_sv_ny Chewa, Chichewa, Nyanja xx.ny.translate_to.fr translate_fr_ny Chewa, Chichewa, Nyanja xx.ny.translate_to.fi translate_fi_ny Chewa, Chichewa, Nyanja xx.ny.translate_to.es translate_es_ny Chewa, Chichewa, Nyanja xx.ny.translate_to.en translate_ny_en Chewa, Chichewa, Nyanja xx.ny.translate_to.de translate_de_ny Chilean Sign Language xx.csg.translate_to.es translate_es_csg Chuukese xx.chk.translate_to.sv translate_sv_chk Chuukese xx.chk.translate_to.en translate_chk_en Colombian Sign Language xx.csn.translate_to.es translate_es_csn Congo Swahili xx.swc.translate_to.sv translate_sv_swc Congo Swahili xx.swc.translate_to.fr translate_fr_swc Congo Swahili xx.swc.translate_to.fi translate_fi_swc Congo Swahili xx.swc.translate_to.es translate_es_swc Congo Swahili xx.swc.translate_to.en translate_swc_en Croatian xx.hr.translate_to.sv translate_sv_hr Croatian xx.hr.translate_to.fr translate_fr_hr Croatian xx.hr.translate_to.fi translate_fi_hr Croatian xx.hr.translate_to.es translate_es_hr Croatian xx.hr.translate_to.de translate_de_hr Czech xx.cs.translate_to.uk translate_uk_cs Czech xx.cs.translate_to.sv translate_sv_cs Czech xx.cs.translate_to.fi translate_fi_cs Czech xx.cs.translate_to.es translate_es_cs Czech xx.cs.translate_to.eo translate_eo_cs Czech xx.cs.translate_to.en translate_cs_en Czech xx.cs.translate_to.de translate_de_cs Danish xx.da.translate_to.ru translate_ru_da Danish xx.da.translate_to.no translate_no_da Danish xx.da.translate_to.ja translate_ja_da Danish xx.da.translate_to.es translate_es_da Danish xx.da.translate_to.eo translate_eo_da Danish xx.da.translate_to.en translate_da_en Danish xx.da.translate_to.de translate_de_da Danish da.ner entity_recognizer_sm Danish da.ner.sm entity_recognizer_sm Danish da.ner.md entity_recognizer_md Danish da.ner.lg entity_recognizer_lg Danish da.explain explain_document_sm Danish da.explain.sm explain_document_sm Danish da.explain.md explain_document_md Danish da.explain.lg explain_document_lg Dholuo, Luo (Kenya and Tanzania) xx.luo.translate_to.en translate_luo_en Dutch, Flemish xx.nl.translate_to.zh translate_zh_nl Dutch, Flemish xx.nl.translate_to.uk translate_uk_nl Dutch, Flemish xx.nl.translate_to.sv translate_sv_nl Dutch, Flemish xx.nl.translate_to.no translate_no_nl Dutch, Flemish xx.nl.translate_to.ja translate_ja_nl Dutch, Flemish xx.nl.translate_to.fi translate_fi_nl Dutch, Flemish xx.nl.translate_to.es translate_es_nl Dutch, Flemish xx.nl.translate_to.eo translate_eo_nl Dutch, Flemish xx.nl.translate_to.en translate_nl_en Dutch, Flemish xx.nl.translate_to.de translate_de_nl Dutch, Flemish xx.nl.translate_to.ca translate_ca_nl Dutch, Flemish xx.nl.translate_to.af translate_af_nl Dutch, Flemish nl.ner entity_recognizer_sm Dutch, Flemish nl.ner.sm entity_recognizer_sm Dutch, Flemish nl.ner.md entity_recognizer_md Dutch, Flemish nl.ner.lg entity_recognizer_lg Dutch, Flemish nl.explain explain_document_sm Dutch, Flemish nl.explain.sm explain_document_sm Dutch, Flemish nl.explain.md explain_document_md Dutch, Flemish nl.explain.lg explain_document_lg Efik xx.efi.translate_to.sv translate_sv_efi Efik xx.efi.translate_to.fr translate_fr_efi Efik xx.efi.translate_to.fi translate_fi_efi Efik xx.efi.translate_to.es translate_es_efi Efik xx.efi.translate_to.en translate_efi_en Efik xx.efi.translate_to.de translate_de_efi English xx.en.translate_to.zlw translate_en_zlw English xx.en.translate_to.zls translate_en_zls English xx.en.translate_to.zle translate_en_zle English xx.en.translate_to.zh translate_en_zh English xx.en.translate_to.xh translate_en_xh English xx.en.translate_to.vi translate_en_vi English xx.en.translate_to.urj translate_en_urj English xx.en.translate_to.ur translate_en_ur English xx.en.translate_to.umb translate_en_umb English xx.en.translate_to.uk translate_en_uk English xx.en.translate_to.ty translate_en_ty English xx.en.translate_to.tw translate_en_tw English xx.en.translate_to.tvl translate_en_tvl English xx.en.translate_to.tut translate_en_tut English xx.en.translate_to.ts translate_en_ts English xx.en.translate_to.trk translate_en_trk English xx.en.translate_to.tpi translate_en_tpi English xx.en.translate_to.toi translate_en_toi English xx.en.translate_to.to translate_en_to English xx.en.translate_to.tn translate_en_tn English xx.en.translate_to.tll translate_en_tll English xx.en.translate_to.tl translate_en_tl English xx.en.translate_to.tiv translate_en_tiv English xx.en.translate_to.ti translate_en_ti English xx.en.translate_to.tdt translate_en_tdt English xx.en.translate_to.swc translate_en_swc English xx.en.translate_to.sw translate_en_sw English xx.en.translate_to.sv translate_en_sv English xx.en.translate_to.st translate_en_st English xx.en.translate_to.ss translate_en_ss English xx.en.translate_to.sq translate_en_sq English xx.en.translate_to.sn translate_en_sn English xx.en.translate_to.sm translate_en_sm English xx.en.translate_to.sla translate_en_sla English xx.en.translate_to.sk translate_en_sk English xx.en.translate_to.sit translate_en_sit English xx.en.translate_to.sg translate_en_sg English xx.en.translate_to.sem translate_en_sem English xx.en.translate_to.sal translate_en_sal English xx.en.translate_to.rw translate_en_rw English xx.en.translate_to.run translate_en_run English xx.en.translate_to.ru translate_en_ru English xx.en.translate_to.roa translate_en_roa English xx.en.translate_to.ro translate_en_ro English xx.en.translate_to.rnd translate_en_rnd English xx.en.translate_to.rn translate_en_rn English xx.en.translate_to.pqw translate_en_pqw English xx.en.translate_to.pqe translate_en_pqe English xx.en.translate_to.poz translate_en_poz English xx.en.translate_to.pon translate_en_pon English xx.en.translate_to.pis translate_en_pis English xx.en.translate_to.phi translate_en_phi English xx.en.translate_to.pap translate_en_pap English xx.en.translate_to.pag translate_en_pag English xx.en.translate_to.om translate_en_om English xx.en.translate_to.nyk translate_en_nyk English xx.en.translate_to.ny translate_en_ny English xx.en.translate_to.nso translate_en_nso English xx.en.translate_to.nl translate_en_nl English xx.en.translate_to.niu translate_en_niu English xx.en.translate_to.nic translate_en_nic English xx.en.translate_to.ng translate_en_ng English xx.en.translate_to.mul translate_en_mul English xx.en.translate_to.mt translate_en_mt English xx.en.translate_to.mr translate_en_mr English xx.en.translate_to.mos translate_en_mos English xx.en.translate_to.ml translate_en_ml English xx.en.translate_to.mkh translate_en_mkh English xx.en.translate_to.mk translate_en_mk English xx.en.translate_to.mh translate_en_mh English xx.en.translate_to.mg translate_en_mg English xx.en.translate_to.mfe translate_en_mfe English xx.en.translate_to.map translate_en_map English xx.en.translate_to.lus translate_en_lus English xx.en.translate_to.luo translate_en_luo English xx.en.translate_to.lun translate_en_lun English xx.en.translate_to.lue translate_en_lue English xx.en.translate_to.lua translate_en_lua English xx.en.translate_to.lu translate_en_lu English xx.en.translate_to.loz translate_en_loz English xx.en.translate_to.ln translate_en_ln English xx.en.translate_to.lg translate_en_lg English xx.en.translate_to.kwy translate_en_kwy English xx.en.translate_to.kwn translate_en_kwn English xx.en.translate_to.kqn translate_en_kqn English xx.en.translate_to.kj translate_en_kj English xx.en.translate_to.kg translate_en_kg English xx.en.translate_to.jap translate_en_jap English xx.en.translate_to.itc translate_en_itc English xx.en.translate_to.it translate_en_it English xx.en.translate_to.iso translate_en_iso English xx.en.translate_to.is translate_en_is English xx.en.translate_to.ine translate_en_ine English xx.en.translate_to.inc translate_en_inc English xx.en.translate_to.ilo translate_en_ilo English xx.en.translate_to.iir translate_en_iir English xx.en.translate_to.ig translate_en_ig English xx.en.translate_to.id translate_en_id English xx.en.translate_to.hy translate_en_hy English xx.en.translate_to.hu translate_en_hu English xx.en.translate_to.ht translate_en_ht English xx.en.translate_to.ho translate_en_ho English xx.en.translate_to.hil translate_en_hil English xx.en.translate_to.hi translate_en_hi English xx.en.translate_to.he translate_en_he English xx.en.translate_to.ha translate_en_ha English xx.en.translate_to.gv translate_en_gv English xx.en.translate_to.guw translate_en_guw English xx.en.translate_to.grk translate_en_grk English xx.en.translate_to.gmw translate_en_gmw English xx.en.translate_to.gmq translate_en_gmq English xx.en.translate_to.gl translate_en_gl English xx.en.translate_to.gil translate_en_gil English xx.en.translate_to.gem translate_en_gem English xx.en.translate_to.gaa translate_en_gaa English xx.en.translate_to.ga translate_en_ga English xx.en.translate_to.fr translate_en_fr English xx.en.translate_to.fj translate_en_fj English xx.en.translate_to.fiu translate_en_fiu English xx.en.translate_to.fi translate_en_fi English xx.en.translate_to.euq translate_en_euq English xx.en.translate_to.eu translate_en_eu English xx.en.translate_to.et translate_en_et English xx.en.translate_to.es translate_en_es English xx.en.translate_to.eo translate_en_eo English xx.en.translate_to.el translate_en_el English xx.en.translate_to.efi translate_en_efi English xx.en.translate_to.ee translate_en_ee English xx.en.translate_to.dra translate_en_dra English xx.en.translate_to.de translate_en_de English xx.en.translate_to.da translate_en_da English xx.en.translate_to.cy translate_en_cy English xx.en.translate_to.cus translate_en_cus English xx.en.translate_to.cs translate_en_cs English xx.en.translate_to.crs translate_en_crs English xx.en.translate_to.cpp translate_en_cpp English xx.en.translate_to.cpf translate_en_cpf English xx.en.translate_to.chk translate_en_chk English xx.en.translate_to.cel translate_en_cel English xx.en.translate_to.ceb translate_en_ceb English xx.en.translate_to.ca translate_en_ca English xx.en.translate_to.bzs translate_en_bzs English xx.en.translate_to.bnt translate_en_bnt English xx.en.translate_to.bi translate_en_bi English xx.en.translate_to.bg translate_en_bg English xx.en.translate_to.ber translate_en_ber English xx.en.translate_to.bem translate_en_bem English xx.en.translate_to.bcl translate_en_bcl English xx.en.translate_to.bat translate_en_bat English xx.en.translate_to.az translate_en_az English xx.en.translate_to.ar translate_en_ar English xx.en.translate_to.alv translate_en_alv English xx.en.translate_to.afa translate_en_afa English xx.en.translate_to.af translate_en_af English xx.en.translate_to.aav translate_en_aav English en.spell check_spelling_dl English en.spell.dl check_spelling_dl English en.spell.context check_spelling_dl English en.sentiment analyze_sentiment English en.sentiment.twitter analyze_sentimentdl_use_twitter English en.sentiment.imdb analyze_sentimentdl_use_imdb English en.sentiment.imdb.use analyze_sentimentdl_use_imdb English en.sentiment.glove analyze_sentimentdl_glove_imdb English en.sentiment.glove.imdb analyze_sentimentdl_glove_imdb English en.ner recognize_entities_dl English en.ner.onto.sm onto_recognize_entities_sm English en.ner.onto.lg onto_recognize_entities_lg English en.ner.onto.large onto_recognize_entities_electra_large English en.ner.onto.electra.small onto_recognize_entities_electra_small English en.ner.onto.electra.base onto_recognize_entities_electra_base English en.ner.onto.bert.tiny onto_recognize_entities_bert_tiny English en.ner.onto.bert.small onto_recognize_entities_bert_small English en.ner.onto.bert.mini onto_recognize_entities_bert_mini English en.ner.onto.bert.medium onto_recognize_entities_bert_medium English en.ner.onto.bert.large onto_recognize_entities_bert_large English en.ner.onto.bert.base onto_recognize_entities_bert_base English en.ner.dl recognize_entities_dl English en.ner.conll recognize_entities_dl English en.ner.bert recognize_entities_bert English en.match.chunks match_chunks English en.explain explain_document_ml English en.explain.ml explain_document_ml English en.explain.dl explain_document_dl English en.clean.stop clean_stop English en.clean.slang clean_slang English en.classify analyze_sentiment English en.classify.trec50.component_list classifierdl_use_trec50_pipeline English en.classify.sentiment analyze_sentiment English en.classify.sentiment.glove analyze_sentimentdl_glove_imdb English en.classify.sentiment.glove.imdb analyze_sentimentdl_glove_imdb Ewe xx.ee.translate_to.sv translate_sv_ee Ewe xx.ee.translate_to.fr translate_fr_ee Ewe xx.ee.translate_to.fi translate_fi_ee Ewe xx.ee.translate_to.es translate_es_ee Ewe xx.ee.translate_to.en translate_ee_en Ewe xx.ee.translate_to.de translate_de_ee Fijian xx.fj.translate_to.sv translate_sv_fj Fijian xx.fj.translate_to.fr translate_fr_fj Fijian xx.fj.translate_to.fi translate_fi_fj Fijian xx.fj.translate_to.es translate_es_fj Fijian xx.fj.translate_to.en translate_fj_en Fijian xx.fj.translate_to.de translate_de_fj Finnish Sign Language xx.fse.translate_to.fi translate_fi_fse Finnish xx.fi.translate_to.zne translate_zne_fi Finnish xx.fi.translate_to.zh translate_zh_fi Finnish xx.fi.translate_to.yo translate_yo_fi Finnish xx.fi.translate_to.war translate_war_fi Finnish xx.fi.translate_to.uk translate_uk_fi Finnish xx.fi.translate_to.ty translate_ty_fi Finnish xx.fi.translate_to.tw translate_tw_fi Finnish xx.fi.translate_to.tvl translate_tvl_fi Finnish xx.fi.translate_to.ts translate_ts_fi Finnish xx.fi.translate_to.toi translate_toi_fi Finnish xx.fi.translate_to.tll translate_tll_fi Finnish xx.fi.translate_to.swc translate_swc_fi Finnish xx.fi.translate_to.sv translate_sv_fi Finnish xx.fi.translate_to.st translate_st_fi Finnish xx.fi.translate_to.sl translate_sl_fi Finnish xx.fi.translate_to.sk translate_sk_fi Finnish xx.fi.translate_to.sg translate_sg_fi Finnish xx.fi.translate_to.ru translate_ru_fi Finnish xx.fi.translate_to.ro translate_ro_fi Finnish xx.fi.translate_to.pon translate_pon_fi Finnish xx.fi.translate_to.pis translate_pis_fi Finnish xx.fi.translate_to.pap translate_pap_fi Finnish xx.fi.translate_to.pag translate_pag_fi Finnish xx.fi.translate_to.nso translate_nso_fi Finnish xx.fi.translate_to.no translate_no_fi Finnish xx.fi.translate_to.nl translate_nl_fi Finnish xx.fi.translate_to.niu translate_niu_fi Finnish xx.fi.translate_to.mt translate_mt_fi Finnish xx.fi.translate_to.mk translate_mk_fi Finnish xx.fi.translate_to.mh translate_mh_fi Finnish xx.fi.translate_to.lv translate_lv_fi Finnish xx.fi.translate_to.lus translate_lus_fi Finnish xx.fi.translate_to.lue translate_lue_fi Finnish xx.fi.translate_to.lua translate_lua_fi Finnish xx.fi.translate_to.lu translate_lu_fi Finnish xx.fi.translate_to.loz translate_loz_fi Finnish xx.fi.translate_to.lg translate_lg_fi Finnish xx.fi.translate_to.ko translate_ko_fi Finnish xx.fi.translate_to.ja translate_ja_fi Finnish xx.fi.translate_to.iso translate_iso_fi Finnish xx.fi.translate_to.is translate_is_fi Finnish xx.fi.translate_to.ilo translate_ilo_fi Finnish xx.fi.translate_to.ig translate_ig_fi Finnish xx.fi.translate_to.id translate_id_fi Finnish xx.fi.translate_to.hu translate_hu_fi Finnish xx.fi.translate_to.ht translate_ht_fi Finnish xx.fi.translate_to.hr translate_hr_fi Finnish xx.fi.translate_to.hil translate_hil_fi Finnish xx.fi.translate_to.he translate_he_fi Finnish xx.fi.translate_to.ha translate_ha_fi Finnish xx.fi.translate_to.guw translate_guw_fi Finnish xx.fi.translate_to.gil translate_gil_fi Finnish xx.fi.translate_to.gaa translate_gaa_fi Finnish xx.fi.translate_to.fse translate_fse_fi Finnish xx.fi.translate_to.fi translate_fi_fi Finnish xx.fi.translate_to.et translate_et_fi Finnish xx.fi.translate_to.es translate_es_fi Finnish xx.fi.translate_to.eo translate_eo_fi Finnish xx.fi.translate_to.en translate_fi_en Finnish xx.fi.translate_to.el translate_el_fi Finnish xx.fi.translate_to.efi translate_efi_fi Finnish xx.fi.translate_to.ee translate_ee_fi Finnish xx.fi.translate_to.de translate_de_fi Finnish xx.fi.translate_to.da translate_da_fi Finnish xx.fi.translate_to.cs translate_cs_fi Finnish xx.fi.translate_to.crs translate_crs_fi Finnish xx.fi.translate_to.ceb translate_ceb_fi Finnish xx.fi.translate_to.bzs translate_bzs_fi Finnish xx.fi.translate_to.bg translate_bg_fi Finnish xx.fi.translate_to.bem translate_bem_fi Finnish xx.fi.translate_to.bcl translate_bcl_fi Finnish xx.fi.translate_to.af translate_af_fi Finnish fi.ner entity_recognizer_sm Finnish fi.ner.sm entity_recognizer_sm Finnish fi.ner.md entity_recognizer_md Finnish fi.ner.lg entity_recognizer_lg Finnish fi.explain explain_document_sm Finnish fi.explain.sm explain_document_sm Finnish fi.explain.md explain_document_md Finnish fi.explain.lg explain_document_lg French xx.fr.translate_to.zne translate_zne_fr French xx.fr.translate_to.yo translate_yo_fr French xx.fr.translate_to.yap translate_yap_fr French xx.fr.translate_to.xh translate_xh_fr French xx.fr.translate_to.wls translate_wls_fr French xx.fr.translate_to.war translate_war_fr French xx.fr.translate_to.vi translate_vi_fr French xx.fr.translate_to.uk translate_uk_fr French xx.fr.translate_to.ty translate_ty_fr French xx.fr.translate_to.tw translate_tw_fr French xx.fr.translate_to.tvl translate_tvl_fr French xx.fr.translate_to.tum translate_tum_fr French xx.fr.translate_to.ts translate_ts_fr French xx.fr.translate_to.tr translate_tr_fr French xx.fr.translate_to.toi translate_toi_fr French xx.fr.translate_to.to translate_to_fr French xx.fr.translate_to.tn translate_tn_fr French xx.fr.translate_to.tll translate_tll_fr French xx.fr.translate_to.tiv translate_tiv_fr French xx.fr.translate_to.th translate_th_fr French xx.fr.translate_to.swc translate_swc_fr French xx.fr.translate_to.sv translate_sv_fr French xx.fr.translate_to.st translate_st_fr French xx.fr.translate_to.srn translate_srn_fr French xx.fr.translate_to.sn translate_sn_fr French xx.fr.translate_to.sm translate_sm_fr French xx.fr.translate_to.sl translate_sl_fr French xx.fr.translate_to.sk translate_sk_fr French xx.fr.translate_to.sg translate_sg_fr French xx.fr.translate_to.rw translate_rw_fr French xx.fr.translate_to.ru translate_ru_fr French xx.fr.translate_to.ro translate_ro_fr French xx.fr.translate_to.rnd translate_rnd_fr French xx.fr.translate_to.rn translate_rn_fr French xx.fr.translate_to.pon translate_pon_fr French xx.fr.translate_to.pl translate_pl_fr French xx.fr.translate_to.pis translate_pis_fr French xx.fr.translate_to.pap translate_pap_fr French xx.fr.translate_to.nso translate_nso_fr French xx.fr.translate_to.no translate_no_fr French xx.fr.translate_to.nl translate_nl_fr French xx.fr.translate_to.niu translate_niu_fr French xx.fr.translate_to.mt translate_mt_fr French xx.fr.translate_to.ms translate_ms_fr French xx.fr.translate_to.mk translate_mk_fr French xx.fr.translate_to.lv translate_lv_fr French xx.fr.translate_to.lus translate_lus_fr French xx.fr.translate_to.lue translate_lue_fr French xx.fr.translate_to.lua translate_lua_fr French xx.fr.translate_to.lu translate_lu_fr French xx.fr.translate_to.lt translate_lt_fr French xx.fr.translate_to.loz translate_loz_fr French xx.fr.translate_to.ln translate_ln_fr French xx.fr.translate_to.lg translate_lg_fr French xx.fr.translate_to.kwy translate_kwy_fr French xx.fr.translate_to.kqn translate_kqn_fr French xx.fr.translate_to.ko translate_ko_fr French xx.fr.translate_to.kg translate_kg_fr French xx.fr.translate_to.ja translate_ja_fr French xx.fr.translate_to.it translate_it_fr French xx.fr.translate_to.iso translate_iso_fr French xx.fr.translate_to.is translate_is_fr French xx.fr.translate_to.ig translate_ig_fr French xx.fr.translate_to.id translate_id_fr French xx.fr.translate_to.hu translate_hu_fr French xx.fr.translate_to.ht translate_ht_fr French xx.fr.translate_to.hr translate_hr_fr French xx.fr.translate_to.he translate_he_fr French xx.fr.translate_to.ha translate_ha_fr French xx.fr.translate_to.guw translate_guw_fr French xx.fr.translate_to.gil translate_gil_fr French xx.fr.translate_to.gaa translate_gaa_fr French xx.fr.translate_to.fj translate_fj_fr French xx.fr.translate_to.fi translate_fi_fr French xx.fr.translate_to.et translate_et_fr French xx.fr.translate_to.es translate_es_fr French xx.fr.translate_to.eo translate_eo_fr French xx.fr.translate_to.en translate_fr_en French xx.fr.translate_to.el translate_el_fr French xx.fr.translate_to.efi translate_efi_fr French xx.fr.translate_to.ee translate_ee_fr French xx.fr.translate_to.de translate_de_fr French xx.fr.translate_to.da translate_da_fr French xx.fr.translate_to.cs translate_cs_fr French xx.fr.translate_to.crs translate_crs_fr French xx.fr.translate_to.chk translate_chk_fr French xx.fr.translate_to.ceb translate_ceb_fr French xx.fr.translate_to.ca translate_ca_fr French xx.fr.translate_to.bzs translate_bzs_fr French xx.fr.translate_to.bi translate_bi_fr French xx.fr.translate_to.bg translate_bg_fr French xx.fr.translate_to.ber translate_ber_fr French xx.fr.translate_to.bem translate_bem_fr French xx.fr.translate_to.bcl translate_bcl_fr French xx.fr.translate_to.ase translate_ase_fr French xx.fr.translate_to.ar translate_ar_fr French xx.fr.translate_to.af translate_af_fr French fr.ner entity_recognizer_lg French fr.ner.md entity_recognizer_md French fr.ner.lg entity_recognizer_lg French fr.explain explain_document_lg French fr.explain.md explain_document_md French fr.explain.lg explain_document_lg Ga xx.gaa.translate_to.sv translate_sv_gaa Ga xx.gaa.translate_to.fr translate_fr_gaa Ga xx.gaa.translate_to.fi translate_fi_gaa Ga xx.gaa.translate_to.es translate_es_gaa Ga xx.gaa.translate_to.en translate_gaa_en Ga xx.gaa.translate_to.de translate_de_gaa Galician xx.gl.translate_to.pt translate_pt_gl Galician xx.gl.translate_to.es translate_es_gl Galician xx.gl.translate_to.en translate_gl_en Ganda xx.lg.translate_to.sv translate_sv_lg Ganda xx.lg.translate_to.fr translate_fr_lg Ganda xx.lg.translate_to.fi translate_fi_lg Ganda xx.lg.translate_to.en translate_lg_en Georgian xx.ka.translate_to.en translate_ka_en German xx.de.translate_to.zh translate_zh_de German xx.de.translate_to.vi translate_vi_de German xx.de.translate_to.uk translate_uk_de German xx.de.translate_to.tl translate_tl_de German xx.de.translate_to.rn translate_rn_de German xx.de.translate_to.pl translate_pl_de German xx.de.translate_to.pap translate_pap_de German xx.de.translate_to.pag translate_pag_de German xx.de.translate_to.ny translate_ny_de German xx.de.translate_to.nso translate_nso_de German xx.de.translate_to.no translate_no_de German xx.de.translate_to.niu translate_niu_de German xx.de.translate_to.ms translate_ms_de German xx.de.translate_to.lt translate_lt_de German xx.de.translate_to.loz translate_loz_de German xx.de.translate_to.ln translate_ln_de German xx.de.translate_to.ko translate_ko_de German xx.de.translate_to.ja translate_ja_de German xx.de.translate_to.it translate_it_de German xx.de.translate_to.is translate_is_de German xx.de.translate_to.ilo translate_ilo_de German xx.de.translate_to.ig translate_ig_de German xx.de.translate_to.hu translate_hu_de German xx.de.translate_to.hil translate_hil_de German xx.de.translate_to.he translate_he_de German xx.de.translate_to.guw translate_guw_de German xx.de.translate_to.gaa translate_gaa_de German xx.de.translate_to.fr translate_fr_de German xx.de.translate_to.fi translate_fi_de German xx.de.translate_to.eu translate_eu_de German xx.de.translate_to.et translate_et_de German xx.de.translate_to.es translate_es_de German xx.de.translate_to.eo translate_eo_de German xx.de.translate_to.en translate_de_en German xx.de.translate_to.efi translate_efi_de German xx.de.translate_to.ee translate_ee_de German xx.de.translate_to.de translate_de_de German xx.de.translate_to.da translate_da_de German xx.de.translate_to.cs translate_cs_de German xx.de.translate_to.crs translate_crs_de German xx.de.translate_to.ca translate_ca_de German xx.de.translate_to.bg translate_bg_de German xx.de.translate_to.bcl translate_bcl_de German xx.de.translate_to.ase translate_ase_de German xx.de.translate_to.ar translate_ar_de German xx.de.translate_to.af translate_af_de German de.ner.recognizer entity_recognizer_md German de.ner.recognizer.md entity_recognizer_md German de.ner.recognizer.lg entity_recognizer_lg German de.explain.document explain_document_md German de.explain.document.md explain_document_md German de.explain.document.lg explain_document_lg Gilbertese xx.gil.translate_to.sv translate_sv_gil Gilbertese xx.gil.translate_to.fr translate_fr_gil Gilbertese xx.gil.translate_to.fi translate_fi_gil Gilbertese xx.gil.translate_to.es translate_es_gil Gilbertese xx.gil.translate_to.en translate_gil_en Gilbertese xx.gil.translate_to.de translate_de_gil Greenlandic, Kalaallisut xx.kl.translate_to.en translate_kl_en Gun xx.guw.translate_to.sv translate_sv_guw Gun xx.guw.translate_to.fr translate_fr_guw Gun xx.guw.translate_to.fi translate_fi_guw Gun xx.guw.translate_to.es translate_es_guw Gun xx.guw.translate_to.en translate_guw_en Gun xx.guw.translate_to.de translate_de_guw Haitian, Haitian Creole xx.ht.translate_to.sv translate_sv_ht Haitian, Haitian Creole xx.ht.translate_to.fr translate_fr_ht Haitian, Haitian Creole xx.ht.translate_to.fi translate_fi_ht Haitian, Haitian Creole xx.ht.translate_to.es translate_es_ht Haitian, Haitian Creole xx.ht.translate_to.en translate_ht_en Haitian, Haitian Creole xx.ht.translate_to.de translate_de_ht Hausa xx.ha.translate_to.sv translate_sv_ha Hausa xx.ha.translate_to.fr translate_fr_ha Hausa xx.ha.translate_to.fi translate_fi_ha Hausa xx.ha.translate_to.es translate_es_ha Hausa xx.ha.translate_to.en translate_ha_en Hausa xx.ha.translate_to.de translate_de_ha Hebrew xx.he.translate_to.zh translate_zh_he Hebrew xx.he.translate_to.uk translate_uk_he Hebrew xx.he.translate_to.sv translate_sv_he Hebrew xx.he.translate_to.ru translate_ru_he Hebrew xx.he.translate_to.ja translate_ja_he Hebrew xx.he.translate_to.it translate_it_he Hebrew xx.he.translate_to.fr translate_fr_he Hebrew xx.he.translate_to.fi translate_fi_he Hebrew xx.he.translate_to.es translate_es_he Hebrew xx.he.translate_to.eo translate_eo_he Hebrew xx.he.translate_to.de translate_de_he Hebrew xx.he.translate_to.ar translate_ar_he Hebrew he.explain_document explain_document_lg Hebrew he.explain_document.lg explain_document_lg Hiligaynon xx.hil.translate_to.sv translate_sv_hil Hiligaynon xx.hil.translate_to.fr translate_fr_hil Hiligaynon xx.hil.translate_to.fi translate_fi_hil Hiligaynon xx.hil.translate_to.es translate_es_hil Hiligaynon xx.hil.translate_to.en translate_hil_en Hiligaynon xx.hil.translate_to.de translate_de_hil Hindi xx.hi.translate_to.en translate_hi_en Hiri Motu xx.ho.translate_to.sv translate_sv_ho Hiri Motu xx.ho.translate_to.fr translate_fr_ho Hiri Motu xx.ho.translate_to.fi translate_fi_ho Hiri Motu xx.ho.translate_to.es translate_es_ho Hiri Motu xx.ho.translate_to.en translate_ho_en Hiri Motu xx.ho.translate_to.de translate_de_ho Hungarian xx.hu.translate_to.uk translate_uk_hu Hungarian xx.hu.translate_to.sv translate_sv_hu Hungarian xx.hu.translate_to.ko translate_ko_hu Hungarian xx.hu.translate_to.ja translate_ja_hu Hungarian xx.hu.translate_to.fr translate_fr_hu Hungarian xx.hu.translate_to.fi translate_fi_hu Hungarian xx.hu.translate_to.eo translate_eo_hu Hungarian xx.hu.translate_to.en translate_hu_en Hungarian xx.hu.translate_to.de translate_de_hu Icelandic xx.is.translate_to.sv translate_sv_is Icelandic xx.is.translate_to.it translate_it_is Icelandic xx.is.translate_to.fi translate_fi_is Icelandic xx.is.translate_to.es translate_es_is Icelandic xx.is.translate_to.en translate_is_en Icelandic xx.is.translate_to.de translate_de_is Igbo xx.ig.translate_to.sv translate_sv_ig Igbo xx.ig.translate_to.fr translate_fr_ig Igbo xx.ig.translate_to.fi translate_fi_ig Igbo xx.ig.translate_to.es translate_es_ig Igbo xx.ig.translate_to.en translate_ig_en Igbo xx.ig.translate_to.de translate_de_ig Iloko xx.ilo.translate_to.sv translate_sv_ilo Iloko xx.ilo.translate_to.fr translate_fr_ilo Iloko xx.ilo.translate_to.fi translate_fi_ilo Iloko xx.ilo.translate_to.es translate_es_ilo Iloko xx.ilo.translate_to.en translate_ilo_en Iloko xx.ilo.translate_to.de translate_de_ilo Indonesian xx.id.translate_to.sv translate_sv_id Indonesian xx.id.translate_to.fr translate_fr_id Indonesian xx.id.translate_to.fi translate_fi_id Indonesian xx.id.translate_to.es translate_es_id Indonesian xx.id.translate_to.en translate_id_en Irish xx.ga.translate_to.en translate_ga_en Isoko xx.iso.translate_to.sv translate_sv_iso Isoko xx.iso.translate_to.fr translate_fr_iso Isoko xx.iso.translate_to.fi translate_fi_iso Isoko xx.iso.translate_to.es translate_es_iso Isoko xx.iso.translate_to.en translate_iso_en Isoko xx.iso.translate_to.de translate_de_iso Isthmus Zapotec xx.zai.translate_to.es translate_es_zai Italian xx.it.translate_to.zh translate_zh_it Italian xx.it.translate_to.vi translate_vi_it Italian xx.it.translate_to.uk translate_uk_it Italian xx.it.translate_to.ms translate_ms_it Italian xx.it.translate_to.lt translate_lt_it Italian xx.it.translate_to.ja translate_ja_it Italian xx.it.translate_to.is translate_is_it Italian xx.it.translate_to.he translate_he_it Italian xx.it.translate_to.fi translate_fi_it Italian xx.it.translate_to.es translate_es_it Italian xx.it.translate_to.eo translate_eo_it Italian xx.it.translate_to.en translate_it_en Italian xx.it.translate_to.de translate_de_it Italian xx.it.translate_to.ca translate_ca_it Italian xx.it.translate_to.bg translate_bg_it Italian xx.it.translate_to.ar translate_ar_it Italian it.ner entity_recognizer_md Italian it.ner.md entity_recognizer_md Italian it.ner.lg entity_recognizer_lg Italian it.explain.document explain_document_md Italian it.explain.document.md explain_document_md Italian it.explain.document.lg explain_document_lg Japanese xx.ja.translate_to.en translate_ja_en Kabyle xx.kab.translate_to.en translate_kab_en Kaonde xx.kqn.translate_to.sv translate_sv_kqn Kaonde xx.kqn.translate_to.fr translate_fr_kqn Kaonde xx.kqn.translate_to.fi translate_fi_kqn Kaonde xx.kqn.translate_to.en translate_kqn_en Kinyarwanda xx.rw.translate_to.sv translate_sv_rw Kinyarwanda xx.rw.translate_to.fr translate_fr_rw Kinyarwanda xx.rw.translate_to.fi translate_fi_rw Kinyarwanda xx.rw.translate_to.es translate_es_rw Kinyarwanda xx.rw.translate_to.en translate_rw_en Korean xx.ko.translate_to.en translate_ko_en Korean ko.explain_document explain_document_lg Korean ko.explain_document.lg explain_document_lg Kuanyama, Kwanyama xx.kj.translate_to.en translate_kj_en Kwangali xx.kwn.translate_to.en translate_kwn_en Lingala xx.ln.translate_to.sv translate_sv_ln Lingala xx.ln.translate_to.fr translate_fr_ln Lingala xx.ln.translate_to.fi translate_fi_ln Lingala xx.ln.translate_to.es translate_es_ln Lingala xx.ln.translate_to.en translate_ln_en Lingala xx.ln.translate_to.de translate_de_ln Lithuanian xx.lt.translate_to.tr translate_tr_lt Lithuanian xx.lt.translate_to.ru translate_ru_lt Lithuanian xx.lt.translate_to.pl translate_pl_lt Lithuanian xx.lt.translate_to.it translate_it_lt Lithuanian xx.lt.translate_to.es translate_es_lt Lithuanian xx.lt.translate_to.de translate_de_lt Lozi xx.loz.translate_to.fr translate_fr_loz Lozi xx.loz.translate_to.es translate_es_loz Lozi xx.loz.translate_to.en translate_loz_en Lozi xx.loz.translate_to.de translate_de_loz Luba-Katanga xx.lu.translate_to.sv translate_sv_lu Luba-Katanga xx.lu.translate_to.fr translate_fr_lu Luba-Katanga xx.lu.translate_to.fi translate_fi_lu Luba-Katanga xx.lu.translate_to.en translate_lu_en Luba-Lulua xx.lua.translate_to.sv translate_sv_lua Luba-Lulua xx.lua.translate_to.fr translate_fr_lua Luba-Lulua xx.lua.translate_to.fi translate_fi_lua Luba-Lulua xx.lua.translate_to.es translate_es_lua Luba-Lulua xx.lua.translate_to.en translate_lua_en Luba-Lulua xx.lua.translate_to.de translate_de_lua Lunda xx.lun.translate_to.en translate_lun_en Lushai xx.lus.translate_to.sv translate_sv_lus Lushai xx.lus.translate_to.fr translate_fr_lus Lushai xx.lus.translate_to.fi translate_fi_lus Lushai xx.lus.translate_to.es translate_es_lus Lushai xx.lus.translate_to.en translate_lus_en Luvale xx.lue.translate_to.sv translate_sv_lue Luvale xx.lue.translate_to.fr translate_fr_lue Luvale xx.lue.translate_to.fi translate_fi_lue Luvale xx.lue.translate_to.en translate_lue_en Macedonian xx.mk.translate_to.fi translate_fi_mk Macedonian xx.mk.translate_to.es translate_es_mk Macedonian xx.mk.translate_to.en translate_mk_en Malayalam xx.ml.translate_to.en translate_ml_en Maltese xx.mt.translate_to.sv translate_sv_mt Maltese xx.mt.translate_to.fr translate_fr_mt Maltese xx.mt.translate_to.fi translate_fi_mt Maltese xx.mt.translate_to.es translate_es_mt Maltese xx.mt.translate_to.en translate_mt_en Maltese xx.mt.translate_to.de translate_de_mt Manx xx.gv.translate_to.en translate_gv_en Marathi xx.mr.translate_to.en translate_mr_en Marshallese xx.mh.translate_to.sv translate_sv_mh Marshallese xx.mh.translate_to.fr translate_fr_mh Marshallese xx.mh.translate_to.fi translate_fi_mh Marshallese xx.mh.translate_to.en translate_mh_en Mexican Sign Language xx.mfs.translate_to.es translate_es_mfs Modern Greek (1453-) xx.el.translate_to.sv translate_sv_el Modern Greek (1453-) xx.el.translate_to.fr translate_fr_el Modern Greek (1453-) xx.el.translate_to.fi translate_fi_el Modern Greek (1453-) xx.el.translate_to.es translate_es_el Modern Greek (1453-) xx.el.translate_to.eo translate_eo_el Modern Greek (1453-) xx.el.translate_to.de translate_de_el Modern Greek (1453-) xx.el.translate_to.ar translate_ar_el Moldavian, Moldovan, Romanian xx.ro.translate_to.sv translate_sv_ro Moldavian, Moldovan, Romanian xx.ro.translate_to.fr translate_fr_ro Moldavian, Moldovan, Romanian xx.ro.translate_to.fi translate_fi_ro Moldavian, Moldovan, Romanian xx.ro.translate_to.es translate_es_ro Moldavian, Moldovan, Romanian xx.ro.translate_to.eo translate_eo_ro Morisyen xx.mfe.translate_to.sv translate_sv_mfe Morisyen xx.mfe.translate_to.fr translate_fr_mfe Morisyen xx.mfe.translate_to.fi translate_fi_mfe Morisyen xx.mfe.translate_to.en translate_mfe_en Mossi xx.mos.translate_to.sv translate_sv_mos Mossi xx.mos.translate_to.fr translate_fr_mos Mossi xx.mos.translate_to.fi translate_fi_mos Mossi xx.mos.translate_to.en translate_mos_en Ndonga xx.ng.translate_to.en translate_ng_en Niuean xx.niu.translate_to.sv translate_sv_niu Niuean xx.niu.translate_to.fr translate_fr_niu Niuean xx.niu.translate_to.fi translate_fi_niu Niuean xx.niu.translate_to.es translate_es_niu Niuean xx.niu.translate_to.en translate_niu_en Niuean xx.niu.translate_to.de translate_de_niu Northern Sotho, Pedi, Sepedi xx.nso.translate_to.sv translate_sv_nso Northern Sotho, Pedi, Sepedi xx.nso.translate_to.fr translate_fr_nso Northern Sotho, Pedi, Sepedi xx.nso.translate_to.fi translate_fi_nso Northern Sotho, Pedi, Sepedi xx.nso.translate_to.es translate_es_nso Northern Sotho, Pedi, Sepedi xx.nso.translate_to.en translate_nso_en Northern Sotho, Pedi, Sepedi xx.nso.translate_to.de translate_de_nso Nyaneka xx.nyk.translate_to.en translate_nyk_en Pangasinan xx.pag.translate_to.sv translate_sv_pag Pangasinan xx.pag.translate_to.fr translate_fr_pag Pangasinan xx.pag.translate_to.fi translate_fi_pag Pangasinan xx.pag.translate_to.es translate_es_pag Pangasinan xx.pag.translate_to.en translate_pag_en Pangasinan xx.pag.translate_to.de translate_de_pag Panjabi, Punjabi xx.pa.translate_to.en translate_pa_en Papiamento xx.pap.translate_to.sv translate_sv_pap Papiamento xx.pap.translate_to.fr translate_fr_pap Papiamento xx.pap.translate_to.fi translate_fi_pap Papiamento xx.pap.translate_to.es translate_es_pap Papiamento xx.pap.translate_to.en translate_pap_en Papiamento xx.pap.translate_to.de translate_de_pap Peruvian Sign Language xx.prl.translate_to.es translate_es_prl Pijin xx.pis.translate_to.sv translate_sv_pis Pijin xx.pis.translate_to.fr translate_fr_pis Pijin xx.pis.translate_to.fi translate_fi_pis Pijin xx.pis.translate_to.es translate_es_pis Pijin xx.pis.translate_to.en translate_pis_en Pijin xx.pis.translate_to.de translate_de_pis Pohnpeian xx.pon.translate_to.sv translate_sv_pon Pohnpeian xx.pon.translate_to.fr translate_fr_pon Pohnpeian xx.pon.translate_to.fi translate_fi_pon Pohnpeian xx.pon.translate_to.es translate_es_pon Pohnpeian xx.pon.translate_to.en translate_pon_en Pohnpeian xx.pon.translate_to.de translate_de_pon Polish xx.pl.translate_to.uk translate_uk_pl Polish xx.pl.translate_to.no translate_no_pl Polish xx.pl.translate_to.lt translate_lt_pl Polish xx.pl.translate_to.ja translate_ja_pl Polish xx.pl.translate_to.fr translate_fr_pl Polish xx.pl.translate_to.es translate_es_pl Polish xx.pl.translate_to.eo translate_eo_pl Polish xx.pl.translate_to.en translate_pl_en Polish xx.pl.translate_to.de translate_de_pl Polish xx.pl.translate_to.ar translate_ar_pl Polish pl.ner entity_recognizer_sm Polish pl.ner.sm entity_recognizer_sm Polish pl.ner.md entity_recognizer_md Polish pl.ner.lg entity_recognizer_lg Polish pl.explain explain_document_sm Polish pl.explain.sm explain_document_sm Polish pl.explain.md explain_document_md Polish pl.explain.lg explain_document_lg Portuguese xx.pt.translate_to.uk translate_uk_pt Portuguese xx.pt.translate_to.tl translate_tl_pt Portuguese xx.pt.translate_to.ja translate_ja_pt Portuguese xx.pt.translate_to.gl translate_gl_pt Portuguese xx.pt.translate_to.eo translate_eo_pt Portuguese xx.pt.translate_to.ca translate_ca_pt Portuguese pt.ner entity_recognizer_sm Portuguese pt.ner.sm entity_recognizer_sm Portuguese pt.ner.md entity_recognizer_md Portuguese pt.ner.lg entity_recognizer_lg Portuguese pt.explain explain_document_sm Portuguese pt.explain.sm explain_document_sm Portuguese pt.explain.md explain_document_md Portuguese pt.explain.lg explain_document_lg Rundi xx.rn.translate_to.es translate_es_rn Rundi xx.rn.translate_to.en translate_rn_en Rundi xx.run.translate_to.sv translate_sv_run Rundi xx.run.translate_to.fr translate_fr_run Rundi xx.run.translate_to.fi translate_fi_run Rundi xx.run.translate_to.en translate_run_en Russian xx.ru.translate_to.vi translate_vi_ru Russian xx.ru.translate_to.uk translate_uk_ru Russian xx.ru.translate_to.sv translate_sv_ru Russian xx.ru.translate_to.sl translate_sl_ru Russian xx.ru.translate_to.rn translate_rn_ru Russian xx.ru.translate_to.no translate_no_ru Russian xx.ru.translate_to.lv translate_lv_ru Russian xx.ru.translate_to.lt translate_lt_ru Russian xx.ru.translate_to.ko translate_ko_ru Russian xx.ru.translate_to.ka translate_ka_ru Russian xx.ru.translate_to.ja translate_ja_ru Russian xx.ru.translate_to.hy translate_hy_ru Russian xx.ru.translate_to.he translate_he_ru Russian xx.ru.translate_to.fr translate_fr_ru Russian xx.ru.translate_to.fi translate_fi_ru Russian xx.ru.translate_to.eu translate_eu_ru Russian xx.ru.translate_to.et translate_et_ru Russian xx.ru.translate_to.es translate_es_ru Russian xx.ru.translate_to.eo translate_eo_ru Russian xx.ru.translate_to.en translate_ru_en Russian xx.ru.translate_to.da translate_da_ru Russian xx.ru.translate_to.bg translate_bg_ru Russian xx.ru.translate_to.ar translate_ar_ru Russian xx.ru.translate_to.af translate_af_ru Russian ru.ner entity_recognizer_sm Russian ru.ner.sm entity_recognizer_sm Russian ru.ner.md entity_recognizer_md Russian ru.ner.lg entity_recognizer_lg Russian ru.explain explain_document_sm Russian ru.explain.sm explain_document_sm Russian ru.explain.md explain_document_md Russian ru.explain.lg explain_document_lg Ruund xx.rnd.translate_to.sv translate_sv_rnd Ruund xx.rnd.translate_to.fr translate_fr_rnd Ruund xx.rnd.translate_to.en translate_rnd_en Samoan xx.sm.translate_to.sv translate_sv_sm Samoan xx.sm.translate_to.fr translate_fr_sm Samoan xx.sm.translate_to.fi translate_fi_sm Samoan xx.sm.translate_to.es translate_es_sm Samoan xx.sm.translate_to.en translate_sm_en San Salvador Kongo xx.kwy.translate_to.sv translate_sv_kwy San Salvador Kongo xx.kwy.translate_to.fr translate_fr_kwy San Salvador Kongo xx.kwy.translate_to.en translate_kwy_en Sango xx.sg.translate_to.sv translate_sv_sg Sango xx.sg.translate_to.fr translate_fr_sg Sango xx.sg.translate_to.fi translate_fi_sg Sango xx.sg.translate_to.es translate_es_sg Sango xx.sg.translate_to.en translate_sg_en Seselwa Creole French xx.crs.translate_to.sv translate_sv_crs Seselwa Creole French xx.crs.translate_to.fr translate_fr_crs Seselwa Creole French xx.crs.translate_to.fi translate_fi_crs Seselwa Creole French xx.crs.translate_to.es translate_es_crs Seselwa Creole French xx.crs.translate_to.en translate_crs_en Seselwa Creole French xx.crs.translate_to.de translate_de_crs Shona xx.sn.translate_to.sv translate_sv_sn Shona xx.sn.translate_to.fr translate_fr_sn Shona xx.sn.translate_to.fi translate_fi_sn Shona xx.sn.translate_to.es translate_es_sn Shona xx.sn.translate_to.en translate_sn_en Slovak xx.sk.translate_to.sv translate_sv_sk Slovak xx.sk.translate_to.fr translate_fr_sk Slovak xx.sk.translate_to.fi translate_fi_sk Slovak xx.sk.translate_to.en translate_sk_en Slovenian xx.sl.translate_to.uk translate_uk_sl Slovenian xx.sl.translate_to.sv translate_sv_sl Slovenian xx.sl.translate_to.ru translate_ru_sl Slovenian xx.sl.translate_to.fr translate_fr_sl Slovenian xx.sl.translate_to.fi translate_fi_sl Slovenian xx.sl.translate_to.es translate_es_sl Southern Sotho xx.st.translate_to.sv translate_sv_st Southern Sotho xx.st.translate_to.fr translate_fr_st Southern Sotho xx.st.translate_to.fi translate_fi_st Southern Sotho xx.st.translate_to.es translate_es_st Southern Sotho xx.st.translate_to.en translate_st_en Sranan Tongo xx.srn.translate_to.sv translate_sv_srn Sranan Tongo xx.srn.translate_to.fr translate_fr_srn Sranan Tongo xx.srn.translate_to.fi translate_fi_srn Sranan Tongo xx.srn.translate_to.es translate_es_srn Sranan Tongo xx.srn.translate_to.en translate_srn_en Swati xx.ss.translate_to.en translate_ss_en Swedish xx.sv.translate_to.zne translate_zne_sv Swedish xx.sv.translate_to.zh translate_zh_sv Swedish xx.sv.translate_to.yo translate_yo_sv Swedish xx.sv.translate_to.yap translate_yap_sv Swedish xx.sv.translate_to.xh translate_xh_sv Swedish xx.sv.translate_to.wls translate_wls_sv Swedish xx.sv.translate_to.war translate_war_sv Swedish xx.sv.translate_to.uk translate_uk_sv Swedish xx.sv.translate_to.ty translate_ty_sv Swedish xx.sv.translate_to.tw translate_tw_sv Swedish xx.sv.translate_to.tvl translate_tvl_sv Swedish xx.sv.translate_to.tum translate_tum_sv Swedish xx.sv.translate_to.ts translate_ts_sv Swedish xx.sv.translate_to.tr translate_tr_sv Swedish xx.sv.translate_to.tpi translate_tpi_sv Swedish xx.sv.translate_to.toi translate_toi_sv Swedish xx.sv.translate_to.to translate_to_sv Swedish xx.sv.translate_to.tn translate_tn_sv Swedish xx.sv.translate_to.tll translate_tll_sv Swedish xx.sv.translate_to.tiv translate_tiv_sv Swedish xx.sv.translate_to.swc translate_swc_sv Swedish xx.sv.translate_to.sv translate_sv_sv Swedish xx.sv.translate_to.st translate_st_sv Swedish xx.sv.translate_to.srn translate_srn_sv Swedish xx.sv.translate_to.sq translate_sq_sv Swedish xx.sv.translate_to.sn translate_sn_sv Swedish xx.sv.translate_to.sl translate_sl_sv Swedish xx.sv.translate_to.sk translate_sk_sv Swedish xx.sv.translate_to.sg translate_sg_sv Swedish xx.sv.translate_to.rw translate_rw_sv Swedish xx.sv.translate_to.run translate_run_sv Swedish xx.sv.translate_to.ru translate_ru_sv Swedish xx.sv.translate_to.ro translate_ro_sv Swedish xx.sv.translate_to.rnd translate_rnd_sv Swedish xx.sv.translate_to.pon translate_pon_sv Swedish xx.sv.translate_to.pl translate_pl_sv Swedish xx.sv.translate_to.pis translate_pis_sv Swedish xx.sv.translate_to.pag translate_pag_sv Swedish xx.sv.translate_to.nso translate_nso_sv Swedish xx.sv.translate_to.no translate_no_sv Swedish xx.sv.translate_to.nl translate_nl_sv Swedish xx.sv.translate_to.niu translate_niu_sv Swedish xx.sv.translate_to.mt translate_mt_sv Swedish xx.sv.translate_to.lv translate_lv_sv Swedish xx.sv.translate_to.lus translate_lus_sv Swedish xx.sv.translate_to.lue translate_lue_sv Swedish xx.sv.translate_to.lua translate_lua_sv Swedish xx.sv.translate_to.lu translate_lu_sv Swedish xx.sv.translate_to.lt translate_lt_sv Swedish xx.sv.translate_to.loz translate_loz_sv Swedish xx.sv.translate_to.lg translate_lg_sv Swedish xx.sv.translate_to.kwy translate_kwy_sv Swedish xx.sv.translate_to.kqn translate_kqn_sv Swedish xx.sv.translate_to.ko translate_ko_sv Swedish xx.sv.translate_to.kg translate_kg_sv Swedish xx.sv.translate_to.ja translate_ja_sv Swedish xx.sv.translate_to.it translate_it_sv Swedish xx.sv.translate_to.iso translate_iso_sv Swedish xx.sv.translate_to.is translate_is_sv Swedish xx.sv.translate_to.ilo translate_ilo_sv Swedish xx.sv.translate_to.ig translate_ig_sv Swedish xx.sv.translate_to.id translate_id_sv Swedish xx.sv.translate_to.hu translate_hu_sv Swedish xx.sv.translate_to.ht translate_ht_sv Swedish xx.sv.translate_to.hr translate_hr_sv Swedish xx.sv.translate_to.he translate_he_sv Swedish xx.sv.translate_to.ha translate_ha_sv Swedish xx.sv.translate_to.guw translate_guw_sv Swedish xx.sv.translate_to.gil translate_gil_sv Swedish xx.sv.translate_to.gaa translate_gaa_sv Swedish xx.sv.translate_to.fr translate_fr_sv Swedish xx.sv.translate_to.fi translate_fi_sv Swedish xx.sv.translate_to.et translate_et_sv Swedish xx.sv.translate_to.eo translate_eo_sv Swedish xx.sv.translate_to.en translate_sv_en Swedish xx.sv.translate_to.el translate_el_sv Swedish xx.sv.translate_to.efi translate_efi_sv Swedish xx.sv.translate_to.ee translate_ee_sv Swedish xx.sv.translate_to.cs translate_cs_sv Swedish xx.sv.translate_to.crs translate_crs_sv Swedish xx.sv.translate_to.chk translate_chk_sv Swedish xx.sv.translate_to.ceb translate_ceb_sv Swedish xx.sv.translate_to.bzs translate_bzs_sv Swedish xx.sv.translate_to.bi translate_bi_sv Swedish xx.sv.translate_to.bg translate_bg_sv Swedish xx.sv.translate_to.bem translate_bem_sv Swedish xx.sv.translate_to.bcl translate_bcl_sv Swedish xx.sv.translate_to.ase translate_ase_sv Swedish xx.sv.translate_to.am translate_am_sv Swedish xx.sv.translate_to.af translate_af_sv Swedish sv.ner entity_recognizer_sm Swedish sv.ner.sm entity_recognizer_sm Swedish sv.ner.md entity_recognizer_md Swedish sv.ner.lg entity_recognizer_lg Swedish sv.explain explain_document_sm Swedish sv.explain.sm explain_document_sm Swedish sv.explain.md explain_document_md Swedish sv.explain.lg explain_document_lg Tagalog xx.tl.translate_to.pt translate_pt_tl Tagalog xx.tl.translate_to.fr translate_fr_tl Tagalog xx.tl.translate_to.es translate_es_tl Tagalog xx.tl.translate_to.en translate_tl_en Tagalog xx.tl.translate_to.de translate_de_tl Tahitian xx.ty.translate_to.sv translate_sv_ty Tahitian xx.ty.translate_to.fr translate_fr_ty Tahitian xx.ty.translate_to.fi translate_fi_ty Tahitian xx.ty.translate_to.es translate_es_ty Tai xx.taw.translate_to.en translate_taw_en Tetela xx.tll.translate_to.sv translate_sv_tll Tetela xx.tll.translate_to.fr translate_fr_tll Tetela xx.tll.translate_to.fi translate_fi_tll Tetela xx.tll.translate_to.es translate_es_tll Tetela xx.tll.translate_to.en translate_tll_en Thai xx.th.translate_to.sv translate_sv_th Thai xx.th.translate_to.en translate_th_en Tigrinya xx.ti.translate_to.en translate_ti_en Tiv xx.tiv.translate_to.sv translate_sv_tiv Tiv xx.tiv.translate_to.fr translate_fr_tiv Tiv xx.tiv.translate_to.fi translate_fi_tiv Tiv xx.tiv.translate_to.en translate_tiv_en Tok Pisin xx.tpi.translate_to.sv translate_sv_tpi Tok Pisin xx.tpi.translate_to.fr translate_fr_tpi Tok Pisin xx.tpi.translate_to.fi translate_fi_tpi Tok Pisin xx.tpi.translate_to.es translate_es_tpi Tok Pisin xx.tpi.translate_to.en translate_tpi_en Tonga (Tonga Islands) xx.to.translate_to.sv translate_sv_to Tonga (Tonga Islands) xx.to.translate_to.fr translate_fr_to Tonga (Tonga Islands) xx.to.translate_to.fi translate_fi_to Tonga (Tonga Islands) xx.to.translate_to.es translate_es_to Tonga (Tonga Islands) xx.to.translate_to.en translate_to_en Tonga (Zambia) xx.toi.translate_to.sv translate_sv_toi Tonga (Zambia) xx.toi.translate_to.fi translate_fi_toi Tonga (Zambia) xx.toi.translate_to.en translate_toi_en Tsonga xx.ts.translate_to.sv translate_sv_ts Tsonga xx.ts.translate_to.fr translate_fr_ts Tsonga xx.ts.translate_to.fi translate_fi_ts Tsonga xx.ts.translate_to.en translate_ts_en Tswana xx.tn.translate_to.sv translate_sv_tn Tswana xx.tn.translate_to.fr translate_fr_tn Tswana xx.tn.translate_to.fi translate_fi_tn Tswana xx.tn.translate_to.es translate_es_tn Tswana xx.tn.translate_to.en translate_tn_en Tumbuka xx.tum.translate_to.sv translate_sv_tum Tumbuka xx.tum.translate_to.fr translate_fr_tum Tumbuka xx.tum.translate_to.en translate_tum_en Turkish xx.tr.translate_to.uk translate_uk_tr Turkish xx.tr.translate_to.lt translate_lt_tr Turkish xx.tr.translate_to.ja translate_ja_tr Turkish xx.tr.translate_to.fi translate_fi_tr Turkish xx.tr.translate_to.en translate_tr_en Turkish xx.tr.translate_to.bg translate_bg_tr Turkish xx.tr.translate_to.az translate_az_tr Turkish xx.tr.translate_to.ar translate_ar_tr Tuvalu xx.tvl.translate_to.sv translate_sv_tvl Tuvalu xx.tvl.translate_to.fr translate_fr_tvl Tuvalu xx.tvl.translate_to.fi translate_fi_tvl Tuvalu xx.tvl.translate_to.es translate_es_tvl Tuvalu xx.tvl.translate_to.en translate_tvl_en Twi xx.tw.translate_to.sv translate_sv_tw Twi xx.tw.translate_to.fr translate_fr_tw Twi xx.tw.translate_to.fi translate_fi_tw Twi xx.tw.translate_to.es translate_es_tw Tzotzil xx.tzo.translate_to.es translate_es_tzo Ukrainian xx.uk.translate_to.zh translate_zh_uk Ukrainian xx.uk.translate_to.tr translate_tr_uk Ukrainian xx.uk.translate_to.sv translate_sv_uk Ukrainian xx.uk.translate_to.sl translate_sl_uk Ukrainian xx.uk.translate_to.sh translate_sh_uk Ukrainian xx.uk.translate_to.ru translate_ru_uk Ukrainian xx.uk.translate_to.pt translate_pt_uk Ukrainian xx.uk.translate_to.pl translate_pl_uk Ukrainian xx.uk.translate_to.no translate_no_uk Ukrainian xx.uk.translate_to.nl translate_nl_uk Ukrainian xx.uk.translate_to.it translate_it_uk Ukrainian xx.uk.translate_to.hu translate_hu_uk Ukrainian xx.uk.translate_to.he translate_he_uk Ukrainian xx.uk.translate_to.fr translate_fr_uk Ukrainian xx.uk.translate_to.fi translate_fi_uk Ukrainian xx.uk.translate_to.es translate_es_uk Ukrainian xx.uk.translate_to.en translate_uk_en Ukrainian xx.uk.translate_to.de translate_de_uk Ukrainian xx.uk.translate_to.cs translate_cs_uk Ukrainian xx.uk.translate_to.ca translate_ca_uk Ukrainian xx.uk.translate_to.bg translate_bg_uk Umbundu xx.umb.translate_to.sv translate_sv_umb Umbundu xx.umb.translate_to.en translate_umb_en Urdu xx.ur.translate_to.hi translate_hi_ur Urdu xx.ur.translate_to.en translate_ur_en Venda xx.ve.translate_to.sv translate_sv_ve Venda xx.ve.translate_to.fr translate_fr_ve Venda xx.ve.translate_to.fi translate_fi_ve Venda xx.ve.translate_to.es translate_es_ve Venda xx.ve.translate_to.en translate_ve_en Vietnamese xx.vi.translate_to.zh translate_zh_vi Vietnamese xx.vi.translate_to.ru translate_ru_vi Vietnamese xx.vi.translate_to.ja translate_ja_vi Vietnamese xx.vi.translate_to.it translate_it_vi Vietnamese xx.vi.translate_to.fr translate_fr_vi Vietnamese xx.vi.translate_to.es translate_es_vi Vietnamese xx.vi.translate_to.en translate_vi_en Vietnamese xx.vi.translate_to.de translate_de_vi Wallisian xx.wls.translate_to.sv translate_sv_wls Wallisian xx.wls.translate_to.fr translate_fr_wls Wallisian xx.wls.translate_to.fi translate_fi_wls Wallisian xx.wls.translate_to.es translate_es_wls Wallisian xx.wls.translate_to.en translate_wls_en Walloon xx.wa.translate_to.en translate_wa_en Waray (Philippines) xx.war.translate_to.sv translate_sv_war Waray (Philippines) xx.war.translate_to.fr translate_fr_war Waray (Philippines) xx.war.translate_to.fi translate_fi_war Waray (Philippines) xx.war.translate_to.es translate_es_war Waray (Philippines) xx.war.translate_to.en translate_war_en Welsh xx.cy.translate_to.en translate_cy_en Wolaitta, Wolaytta xx.wal.translate_to.en translate_wal_en Xhosa xx.xh.translate_to.sv translate_sv_xh Xhosa xx.xh.translate_to.fr translate_fr_xh Xhosa xx.xh.translate_to.fi translate_fi_xh Xhosa xx.xh.translate_to.es translate_es_xh Xhosa xx.xh.translate_to.en translate_xh_en Yapese xx.yap.translate_to.sv translate_sv_yap Yapese xx.yap.translate_to.fr translate_fr_yap Yapese xx.yap.translate_to.fi translate_fi_yap Yapese xx.yap.translate_to.en translate_yap_en Yoruba xx.yo.translate_to.sv translate_sv_yo Yoruba xx.yo.translate_to.fr translate_fr_yo Yoruba xx.yo.translate_to.fi translate_fi_yo Yoruba xx.yo.translate_to.es translate_es_yo Yoruba xx.yo.translate_to.en translate_yo_en Yucatec Maya, Yucateco xx.yua.translate_to.es translate_es_yua Zande (individual language) xx.zne.translate_to.sv translate_sv_zne Zande (individual language) xx.zne.translate_to.fr translate_fr_zne Zande (individual language) xx.zne.translate_to.fi translate_fi_zne Albanian xx.sq.translate_to.sv translate_sv_sq Albanian xx.sq.translate_to.fi translate_fi_sq Albanian xx.sq.translate_to.en translate_sq_en Arabic xx.ar.translate_to.tr translate_tr_ar Arabic xx.ar.translate_to.ru translate_ru_ar Arabic xx.ar.translate_to.pl translate_pl_ar Arabic xx.ar.translate_to.ja translate_ja_ar Arabic xx.ar.translate_to.it translate_it_ar Arabic xx.ar.translate_to.he translate_he_ar Arabic xx.ar.translate_to.fr translate_fr_ar Arabic xx.ar.translate_to.es translate_es_ar Arabic xx.ar.translate_to.en translate_ar_en Arabic xx.ar.translate_to.el translate_el_ar Arabic xx.ar.translate_to.de translate_de_ar Azerbaijani xx.az.translate_to.tr translate_tr_az Azerbaijani xx.az.translate_to.en translate_az_en Chinese xx.zh.translate_to.es translate_es_zh Chinese xx.zh.translate_to.en translate_zh_en Estonian xx.et.translate_to.sv translate_sv_et Estonian xx.et.translate_to.ru translate_ru_et Estonian xx.et.translate_to.fi translate_fi_et Estonian xx.et.translate_to.es translate_es_et Estonian xx.et.translate_to.en translate_et_en Estonian xx.et.translate_to.de translate_de_et Kongo xx.kg.translate_to.sv translate_sv_kg Kongo xx.kg.translate_to.fr translate_fr_kg Kongo xx.kg.translate_to.fi translate_fi_kg Kongo xx.kg.translate_to.es translate_es_kg Kongo xx.kg.translate_to.en translate_kg_en Kongo xx.kg.translate_to.de translate_de_kg Latvian xx.lv.translate_to.sv translate_sv_lv Latvian xx.lv.translate_to.ru translate_ru_lv Latvian xx.lv.translate_to.fi translate_fi_lv Latvian xx.lv.translate_to.en translate_lv_en Malagasy xx.mg.translate_to.fi translate_fi_mg Malagasy xx.mg.translate_to.en translate_mg_en Malay (macrolanguage) xx.ms.translate_to.zh translate_zh_ms Malay (macrolanguage) xx.ms.translate_to.ms translate_ms_ms Malay (macrolanguage) xx.ms.translate_to.ja translate_ja_ms Malay (macrolanguage) xx.ms.translate_to.it translate_it_ms Malay (macrolanguage) xx.ms.translate_to.fr translate_fr_ms Malay (macrolanguage) xx.ms.translate_to.de translate_de_ms Norwegian xx.no.translate_to.uk translate_uk_no Norwegian xx.no.translate_to.sv translate_sv_no Norwegian xx.no.translate_to.ru translate_ru_no Norwegian xx.no.translate_to.pl translate_pl_no Norwegian xx.no.translate_to.no translate_no_no Norwegian xx.no.translate_to.nl translate_nl_no Norwegian xx.no.translate_to.fr translate_fr_no Norwegian xx.no.translate_to.fi translate_fi_no Norwegian xx.no.translate_to.es translate_es_no Norwegian xx.no.translate_to.de translate_de_no Norwegian xx.no.translate_to.da translate_da_no Norwegian no.ner entity_recognizer_sm Norwegian no.ner.sm entity_recognizer_sm Norwegian no.ner.md entity_recognizer_md Norwegian no.ner.lg entity_recognizer_lg Norwegian no.explain explain_document_sm Norwegian no.explain.sm explain_document_sm Norwegian no.explain.md explain_document_md Norwegian no.explain.lg explain_document_lg Oromo xx.om.translate_to.en translate_om_en Persian fa.ner.dl recognize_entities_dl Serbo-Croatian xx.sh.translate_to.uk translate_uk_sh Serbo-Croatian xx.sh.translate_to.ja translate_ja_sh Serbo-Croatian xx.sh.translate_to.eo translate_eo_sh Swahili (macrolanguage) xx.sw.translate_to.fi translate_fi_sw Multiple languages xx.mul.translate_to.en translate_mul_en Multilingual xx.jap.translate_to.en translate_jap_en Multilingual xx.classify.lang detect_language_375 Multilingual xx.classify.lang.bigru detect_language_bigru_21 Multilingual xx.classify.lang.99 detect_language_99 Multilingual xx.classify.lang.95 detect_language_95 Multilingual xx.classify.lang.7 detect_language_7 Multilingual xx.classify.lang.43 detect_language_43 Multilingual xx.classify.lang.231 detect_language_231 Multilingual xx.classify.lang.220 detect_language_220 Multilingual xx.classify.lang.21 detect_language_21 Multilingual xx.classify.lang.20 detect_language_20 Healthcare Model references Language Name(s) NLU Reference Spark NLP Reference Castilian, Spanish es.resolve.snomed robertaresolve_snomed Castilian, Spanish es.med_ner ner_diag_proc Castilian, Spanish es.med_ner.roberta_ner_diag_proc roberta_ner_diag_proc Castilian, Spanish es.med_ner.neoplasm ner_neoplasms Castilian, Spanish es.med_ner.living_species ner_living_species Castilian, Spanish es.med_ner.living_species.roberta ner_living_species_roberta Castilian, Spanish es.med_ner.living_species.bert ner_living_species_bert Castilian, Spanish es.med_ner.living_species.300 ner_living_species_300 Castilian, Spanish es.med_ner.diag_proc ner_diag_proc Castilian, Spanish es.med_ner.deid.subentity ner_deid_subentity Castilian, Spanish es.med_ner.deid.subentity.roberta ner_deid_subentity_roberta_augmented Castilian, Spanish es.med_ner.deid.generic ner_deid_generic Castilian, Spanish es.med_ner.deid.generic.roberta ner_deid_generic_roberta_augmented Castilian, Spanish es.embed.sciwiki_300d embeddings_sciwiki_300d Castilian, Spanish es.embed.sciwiki.50d embeddings_sciwiki_50d Castilian, Spanish es.embed.sciwiki.300d embeddings_sciwiki_300d Castilian, Spanish es.embed.sciwiki.150d embeddings_sciwiki_150d Castilian, Spanish es.embed.scielowiki.50d embeddings_scielowiki_50d Castilian, Spanish es.embed.scielowiki.300d embeddings_scielowiki_300d Castilian, Spanish es.embed.scielowiki.150d embeddings_scielowiki_150d Castilian, Spanish es.embed.scielo300d embeddings_scielo_300d Castilian, Spanish es.embed.scielo.50d embeddings_scielo_50d Castilian, Spanish es.embed.scielo.300d embeddings_scielo_300d Castilian, Spanish es.embed.scielo.150d embeddings_scielo_150d Castilian, Spanish es.embed.roberta_base_biomedical roberta_base_biomedical Catalan, Valencian ca.med_ner.living_species ner_living_species English en.t5.mediqa t5_base_mediqa_mnli English en.spell.drug_norvig spellcheck_drug_norvig English en.spell.clinical spellcheck_clinical English en.snomed_to_umls snomed_umls_mapper English en.snomed_to_icdo snomed_icdo_mapper English en.snomed_to_icd10cm snomed_icd10cm_mapper English en.rxnorm_to_umls rxnorm_umls_mapper English en.rxnorm_to_ndc rxnorm_ndc_mapper English en.resolve sbiobertresolve_cpt English en.resolve.umls_drug_substance sbiobertresolve_umls_drug_substance English en.resolve.umls_disease_syndrome sbiobertresolve_umls_disease_syndrome English en.resolve.umls_clinical_drugs sbiobertresolve_umls_clinical_drugs English en.resolve.umls sbiobertresolve_umls_major_concepts English en.resolve.umls.findings sbiobertresolve_umls_findings English en.resolve.snomed_drug sbiobertresolve_snomed_drug English en.resolve.snomed_conditions sbertresolve_snomed_conditions English en.resolve.snomed_body_structure_med sbertresolve_snomed_bodyStructure_med English en.resolve.snomed_body_structure sbiobertresolve_snomed_bodyStructure English en.resolve.snomed sbiobertresolve_snomed_auxConcepts English en.resolve.snomed.findings_int sbiobertresolve_snomed_findings_int English en.resolve.snomed.findings sbiobertresolve_snomed_findings English en.resolve.snomed.aux_concepts_int sbiobertresolve_snomed_auxConcepts_int English en.resolve.snomed.aux_concepts sbiobertresolve_snomed_auxConcepts English en.resolve.rxnorm_ndc sbiobertresolve_rxnorm_ndc English en.resolve.rxnorm_disposition sbiobertresolve_rxnorm_disposition English en.resolve.rxnorm_disposition.sbert sbertresolve_rxnorm_disposition English en.resolve.rxnorm_action_treatment sbiobertresolve_rxnorm_action_treatment English en.resolve.rxnorm sbiobertresolve_rxnorm English en.resolve.rxnorm.disposition sbertresolve_rxnorm_disposition English en.resolve.rxnorm.disposition.sbert sbertresolve_rxnorm_disposition English en.resolve.rxnorm.augmented_re sbiobertresolve_rxnorm_augmented_re English en.resolve.rxnen.med_ner.deid_subentityorm_augmented sbiobertresolve_rxnorm_augmented English en.resolve.rxcui sbiobertresolve_rxcui English en.resolve.ndc sbiobertresolve_ndc English en.resolve.mesh sbiobertresolve_mesh English en.resolve.loinc_uncased sbluebertresolve_loinc_uncased English en.resolve.loinc_cased sbiobertresolve_loinc_cased English en.resolve.loinc sbiobertresolve_loinc English en.resolve.loinc.biobert sbiobertresolve_loinc English en.resolve.loinc.augmented sbiobertresolve_loinc_augmented English en.resolve.icdo_augmented sbiobertresolve_icdo_augmented English en.resolve.icdo sbiobertresolve_icdo English en.resolve.icdo.base sbiobertresolve_icdo_base English en.resolve.icd10pcs sbiobertresolve_icd10pcs English en.resolve.icd10cm_generalised sbiobertresolve_icd10cm_generalised English en.resolve.icd10cm sbiobertresolve_icd10cm English en.resolve.icd10cm.slim_billable_hcc_med sbertresolve_icd10cm_slim_billable_hcc_med English en.resolve.icd10cm.slim_billable_hcc sbiobertresolve_icd10cm_slim_billable_hcc English en.resolve.icd10cm.augmented_billable sbiobertresolve_icd10cm_augmented_billable_hcc English en.resolve.icd10cm.augmented sbiobertresolve_icd10cm_augmented English en.resolve.hcpcs sbiobertresolve_hcpcs English en.resolve.hcc sbiobertresolve_hcc_augmented English en.resolve.hcc.augmented sbiobertresolve_hcc_augmented English en.resolve.cpt sbiobertresolve_cpt English en.resolve.cpt.procedures_measurements sbiobertresolve_cpt_procedures_measurements_augmented English en.resolve.cpt.procedures_augmented sbiobertresolve_cpt_procedures_augmented English en.resolve.cpt.augmented sbiobertresolve_cpt_augmented English en.resolve.clinical_snomed_procedures_measurements sbiobertresolve_clinical_snomed_procedures_measurements English en.resolve.clinical_abbreviation_acronym sbiobertresolve_clinical_abbreviation_acronym English en.resolve.HPO sbiobertresolve_HPO English en.relation redl_bodypart_direction_biobert English en.relation.zeroshot_biobert re_zeroshot_biobert English en.relation.test_result_date re_test_result_date English en.relation.temporal_events_clinical re_temporal_events_clinical English en.relation.temporal_events redl_temporal_events_biobert English en.relation.humen_phenotype_gene redl_human_phenotype_gene_biobert English en.relation.drugprot redl_drugprot_biobert English en.relation.drugprot.clinical re_drugprot_clinical English en.relation.drug_drug_interaction redl_drug_drug_interaction_biobert English en.relation.date redl_date_clinical_biobert English en.relation.clinical redl_clinical_biobert English en.relation.chemprot redl_chemprot_biobert English en.relation.bodypart.procedure redl_bodypart_procedure_test_biobert English en.relation.bodypart.problem redl_bodypart_problem_biobert English en.relation.bodypart.direction redl_bodypart_direction_biobert English en.relation.adverse_drug_events.clinical re_ade_clinical English en.relation.adverse_drug_events.clinical.biobert redl_ade_biobert English en.relation.ade_clinical re_ade_clinical English en.relation.ade_biobert re_ade_biobert English en.relation.ade redl_ade_biobert English en.pos.clinical pos_clinical English en.norm_drugs drug_normalizer English en.ner.drug_development_trials bert_token_classifier_drug_development_trials English en.ner.clinical_trials_abstracts ner_clinical_trials_abstracts English en.mesh_to_umls mesh_umls_mapper English en.med_ner jsl_ner_wip_clinical English en.med_ner.tumour nerdl_tumour_demo English en.med_ner.supplement_clinical ner_supplement_clinical English en.med_ner.risk_factors ner_risk_factors English en.med_ner.risk_factors.biobert ner_risk_factors_biobert English en.med_ner.radiology ner_radiology English en.med_ner.radiology.wip_greedy_biobert jsl_rd_ner_wip_greedy_biobert English en.med_ner.radiology.wip_clinical ner_radiology_wip_clinical English en.med_ner.posology ner_posology English en.med_ner.posology.small ner_posology_small English en.med_ner.posology.large_biobert ner_posology_large_biobert English en.med_ner.posology.large ner_posology_large English en.med_ner.posology.healthcare ner_posology_healthcare English en.med_ner.posology.greedy ner_posology_greedy English en.med_ner.posology.experimental ner_posology_experimental English en.med_ner.posology.biobert ner_posology_biobert English en.med_ner.pathogen ner_pathogen English en.med_ner.nihss ner_nihss English en.med_ner.medmentions ner_medmentions_coarse English en.med_ner.measurements ner_measurements_clinical English en.med_ner.living_species ner_living_species English en.med_ner.living_species.token_bert bert_token_classifier_ner_living_species English en.med_ner.living_species.biobert ner_living_species_biobert English en.med_ner.jsl_slim ner_jsl_slim English en.med_ner.jsl_greedy_biobert ner_jsl_greedy_biobert English en.med_ner.jsl ner_jsl English en.med_ner.jsl.wip.clinical jsl_ner_wip_clinical English en.med_ner.jsl.wip.clinical.rd jsl_rd_ner_wip_greedy_clinical English en.med_ner.jsl.wip.clinical.modifier jsl_ner_wip_modifier_clinical English en.med_ner.jsl.wip.clinical.greedy jsl_ner_wip_greedy_clinical English en.med_ner.jsl.enriched_biobert ner_jsl_enriched_biobert English en.med_ner.jsl.enriched ner_jsl_enriched English en.med_ner.jsl.biobert ner_jsl_biobert English en.med_ner.human_phenotype.go_clinical ner_human_phenotype_go_clinical English en.med_ner.human_phenotype.go_biobert ner_human_phenotype_go_biobert English en.med_ner.human_phenotype.gene_clinical ner_human_phenotype_gene_clinical English en.med_ner.human_phenotype.gene_biobert ner_human_phenotype_gene_biobert English en.med_ner.healthcare ner_healthcare English en.med_ner.genetic_variants ner_genetic_variants English en.med_ner.financial_contract ner_financial_contract English en.med_ner.events_healthcre ner_events_healthcare English en.med_ner.events_clinical ner_events_clinical English en.med_ner.events_biobert ner_events_biobert English en.med_ner.drugsgreedy ner_drugs_greedy English en.med_ner.drugs ner_drugs English en.med_ner.drugs.large ner_drugs_large English en.med_ner.drugprot_clinical ner_drugprot_clinical English en.med_ner.diseases ner_diseases English en.med_ner.diseases.large ner_diseases_large English en.med_ner.diseases.biobert ner_diseases_biobert English en.med_ner.deid_subentity_augmented_i2b2 ner_deid_subentity_augmented_i2b2 English en.med_ner.deid ner_deidentify_dl English en.med_ner.deid.synthetic ner_deid_synthetic English en.med_ner.deid.subentity_augmented ner_deid_subentity_augmented English en.med_ner.deid.sd_large ner_deid_sd_large English en.med_ner.deid.sd ner_deid_sd English en.med_ner.deid.large ner_deid_large English en.med_ner.deid.generic_augmented ner_deid_generic_augmented English en.med_ner.deid.enriched_biobert ner_deid_enriched_biobert English en.med_ner.deid.enriched ner_deid_enriched English en.med_ner.deid.biobert ner_deid_biobert English en.med_ner.deid.augmented ner_deid_augmented English en.med_ner.covid_trials ner_covid_trials English en.med_ner.clinical_trials_abstracts bert_token_classifier_ner_clinical_trials_abstracts English en.med_ner.clinical_trials bert_sequence_classifier_rct_biobert English en.med_ner.clinical ner_clinical English en.med_ner.clinical.biobert ner_clinical_biobert English en.med_ner.chexpert ner_chexpert English en.med_ner.chemprot ner_chemprot_biobert English en.med_ner.chemprot.clinical ner_chemprot_clinical English en.med_ner.chemprot.bert bert_token_classifier_ner_chemprot English en.med_ner.chemicals ner_chemicals English en.med_ner.chemd ner_chemd_clinical English en.med_ner.cellular ner_cellular English en.med_ner.cellular.biobert ner_cellular_biobert English en.med_ner.cancer ner_cancer_genetics English en.med_ner.bionlp ner_bionlp English en.med_ner.bionlp.biobert ner_bionlp_biobert English en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm English en.med_ner.biomarker ner_biomarker English en.med_ner.bacterial_species ner_bacterial_species English en.med_ner.aspect_sentiment ner_aspect_based_sentiment English en.med_ner.anatomy ner_anatomy English en.med_ner.anatomy.coarse_biobert ner_anatomy_coarse_biobert English en.med_ner.anatomy.coarse ner_anatomy_coarse English en.med_ner.anatomy.biobert ner_anatomy_biobert English en.med_ner.admission_events ner_events_admission_clinical English en.med_ner.ade_biobert ner_ade_biobert English en.med_ner.ade.clinical_bert ner_ade_clinicalbert English en.med_ner.ade.clinical ner_ade_clinical English en.med_ner.ade.ade_healthcare ner_ade_healthcare English en.med_ner.abbreviation_clinical ner_abbreviation_clinical English en.map_entity.snomed_to_umls snomed_umls_mapper English en.map_entity.snomed_to_icdo snomed_icdo_mapper English en.map_entity.snomed_to_icd10cm snomed_icd10cm_mapper English en.map_entity.section_headers_normalized normalized_section_header_mapper English en.map_entity.rxnorm_to_umls rxnorm_umls_mapper English en.map_entity.rxnorm_to_ndc rxnorm_ndc_mapper English en.map_entity.rxnorm_to_action_treatment rxnorm_action_treatment_mapper English en.map_entity.rxnorm_resolver rxnorm_mapper English en.map_entity.mesh_to_umls mesh_umls_mapper English en.map_entity.icdo_to_snomed icdo_snomed_mapper English en.map_entity.icd10cm_to_umls icd10cm_umls_mapper English en.map_entity.icd10cm_to_snomed icd10cm_snomed_mapper English en.map_entity.drug_to_action_treatment drug_action_treatment_mapper English en.map_entity.drug_brand_to_ndc drug_brandname_ndc_mapper English en.map_entity.abbreviation_to_definition abbreviation_mapper English en.icdo_to_snomed icdo_snomed_mapper English en.icd10cm_to_umls icd10cm_umls_mapper English en.icd10cm_to_snomed icd10cm_snomed_mapper English en.extract_relation.nihss redl_nihss_biobert English en.embed_sentence.bluebert.mli sbluebert_base_uncased_mli English en.embed_sentence.biobert.rxnorm sbiobert_jsl_rxnorm_cased English en.embed_sentence.biobert.mli sbiobert_base_cased_mli English en.embed_sentence.biobert.jsl_umls_cased sbiobert_jsl_umls_cased English en.embed_sentence.biobert.jsl_cased sbiobert_jsl_cased English en.embed_sentence.bert_uncased.rxnorm sbert_jsl_medium_rxnorm_uncased English en.embed_sentence.bert.jsl_tiny_uncased sbert_jsl_tiny_uncased English en.embed_sentence.bert.jsl_tiny_umls_uncased sbert_jsl_tiny_umls_uncased English en.embed_sentence.bert.jsl_mini_uncased sbert_jsl_mini_uncased English en.embed_sentence.bert.jsl_mini_umlsuncased sbert_jsl_mini_umls_uncased English en.embed_sentence.bert.jsl_medium_uncased sbert_jsl_medium_uncased English en.embed_sentence.bert.jsl_medium_umls_uncased sbert_jsl_medium_umls_uncased English en.embed.glove.icdoem_2ng embeddings_icdoem_2ng English en.embed.glove.icdoem embeddings_icdoem English en.embed.glove.healthcare_100d embeddings_healthcare_100d English en.embed.glove.healthcare embeddings_healthcare English en.embed.glove.clinical embeddings_clinical English en.embed.glove.biovec embeddings_biovec English en.detect_sentence.clinical sentence_detector_dl_healthcare English en.de_identify deidentify_rb English en.de_identify.rules deid_rules English en.de_identify.rb_no_regex deidentify_rb_no_regex English en.de_identify.rb deidentify_rb English en.de_identify.large deidentify_large English en.de_identify.clinical deidentify_enriched_clinical English en.classify.token_bert.ner_jsl_slim bert_token_classifier_ner_jsl_slim English en.classify.token_bert.ner_jsl bert_token_classifier_ner_jsl English en.classify.token_bert.ner_drugs bert_token_classifier_ner_drugs English en.classify.token_bert.ner_deid bert_token_classifier_ner_deid English en.classify.token_bert.ner_clinical bert_token_classifier_ner_clinical English en.classify.token_bert.ner_chemical bert_token_classifier_ner_chemicals English en.classify.token_bert.ner_bacteria bert_token_classifier_ner_bacteria English en.classify.token_bert.ner_anatomy bert_token_classifier_ner_anatomy English en.classify.token_bert.ner_ade bert_token_classifier_ner_ade English en.classify.token_bert.chemicals bert_token_classifier_ner_chemicals English en.classify.token_bert.cellular bert_token_classifier_ner_cellular English en.classify.token_bert.bionlp bert_token_classifier_ner_bionlp English en.classify.stress bert_sequence_classifier_stress English en.classify.pico classifierdl_pico_biobert English en.classify.pico.seq_biobert bert_sequence_classifier_pico_biobert English en.classify.gender.seq_biobert bert_sequence_classifier_gender_biobert English en.classify.gender.sbert classifierdl_gender_sbert English en.classify.gender.biobert classifierdl_gender_biobert English en.classify.bert_sequence.question_statement_clinical bert_sequence_classifier_question_statement_clinical English en.classify.ade.seq_distilbert distilbert_sequence_classifier_ade English en.classify.ade.seq_biobert bert_sequence_classifier_ade English en.classify.ade.conversational classifierdl_ade_conversational_biobert English en.classify.ade.clinicalbert classifierdl_ade_clinicalbert English en.classify.ade.clinical classifierdl_ade_clinicalbert English en.classify.ade.biobert classifierdl_ade_biobert English en.assert assertion_dl English en.assert.radiology assertion_dl_radiology English en.assert.large assertion_dl_large English en.assert.jsl_large assertion_jsl_large English en.assert.jsl assertion_jsl English en.assert.healthcare assertion_dl_healthcare English en.assert.biobert assertion_dl_biobert French fr.med_ner.living_species ner_living_species French fr.med_ner.living_species.bert ner_living_species_bert French fr.med_ner.deid_subentity ner_deid_subentity French fr.med_ner.deid_generic ner_deid_generic Galician gl.med_ner.living_species ner_living_species German de.resolve.snomed sbertresolve_snomed German de.resolve.icd10gm sbertresolve_icd10gm German de.med_ner ner_healthcare_slim German de.med_ner.traffic ner_traffic German de.med_ner.legal ner_legal German de.med_ner.deid_subentity ner_deid_subentity German de.med_ner.deid_generic ner_deid_generic German de.embed w2v_cc_300d German de.embed.w2v w2v_cc_300d Italian it.med_ner.living_species ner_living_species Italian it.med_ner.living_species.bert ner_living_species_bert Italian it.med_ner.deid_subentity ner_deid_subentity Italian it.med_ner.deid_generic ner_deid_generic Moldavian, Moldovan, Romanian ro.med_ner.living_species.bert ner_living_species_bert Moldavian, Moldovan, Romanian ro.med_ner.deid.subentity ner_deid_subentity Moldavian, Moldovan, Romanian ro.med_ner.deid.subentity.bert ner_deid_subentity_bert Moldavian, Moldovan, Romanian ro.med_ner.clinical ner_clinical Moldavian, Moldovan, Romanian ro.embed.clinical.bert.base_cased ner_clinical_bert Portuguese pt.med_ner.living_species ner_living_species Portuguese pt.med_ner.living_species.token_bert bert_token_classifier_ner_living_species Portuguese pt.med_ner.living_species.roberta ner_living_species_roberta Portuguese pt.med_ner.living_species.bert ner_living_species_bert Portuguese pt.med_ner.deid ner_deid_generic Portuguese pt.med_ner.deid.subentity ner_deid_subentity Portuguese pt.med_ner.deid.generic ner_deid_generic Healthcare Pipeline references Language Name(s) nlp.load() Reference Spark NLP Reference English en.snomed.umls.mapping snomed_umls_mapping English en.rxnorm.umls.mapping rxnorm_umls_mapping English en.recognize_entities.posology recognize_entities_posology English en.mesh.umls.mapping mesh_umls_mapping English en.med_ner.profiling_clinical ner_profiling_clinical English en.med_ner.profiling_biobert ner_profiling_biobert English en.med_ner.pathogen.pipeline ner_pathogen_pipeline English en.med_ner.clinical_trials_abstracts.pipe ner_clinical_trials_abstracts_pipeline English en.med_ner.biomedical_bc2gm.pipeline ner_biomedical_bc2gm_pipeline English en.map_entity.snomed_to_icdo.pipe snomed_icdo_mapping English en.map_entity.snomed_to_icd10cm.pipe snomed_icd10cm_mapping English en.map_entity.rxnorm_to_ndc.pipe rxnorm_ndc_mapping English en.map_entity.icdo_to_snomed.pipe icdo_snomed_mapping English en.map_entity.icd10cm_to_snomed.pipe icd10cm_snomed_mapping English en.icd10cm.umls.mapping icd10cm_umls_mapping English en.explain_doc.era explain_clinical_doc_era English en.explain_doc.carp explain_clinical_doc_carp French fr.deid_obfuscated clinical_deidentification Moldavian, Moldovan, Romanian ro.deid.clinical clinical_deidentification",
    "url": "/docs/en/jsl/namespace",
    "relUrl": "/docs/en/jsl/namespace"
  },
  "1281": {
    "id": "1281",
    "title": "Models",
    "content": "All the models available in the Annotation Lab are listed in this page. The models are either trained within the Annotation Lab, uploaded to Annotation Lab by admin users, or downloaded from NLP Models Hub. General information about the models like labels/categories and the source (downloaded/trained/uploaded) is viewable. It is possible to delete any model, or redownload failed ones from the options available under the more action menu on each model. All available models are listed in the Spark NLP Pipeline Config on the Setup Page of any project and are ready to be included in the Labeling Config for pre-annotation. Auto download of model dependencies Starting from version 2.8.0, Annotation Lab automatically downloads all the necessary dependencies along with the model saving users valuable time from manually downloading the dependencies. Previously, users had to first download the model from the Models Hub page (e.g. ner_healthcare_de) and then again download the necessary embeddings required to train the model (e.g. w2v_cc_300d). Custom Model Upload Custom models can be uploaded using the Upload button present in the top right corner of the page. The labels predicted by this model need to be specified in the upload form. Note: The models to upload need to be Spark NLP compatible.",
    "url": "/docs/en/alab/models",
    "relUrl": "/docs/en/alab/models"
  },
  "1282": {
    "id": "1282",
    "title": "Spark NLP Models Hub",
    "content": "",
    "url": "/models",
    "relUrl": "/models"
  },
  "1283": {
    "id": "1283",
    "title": "Models Hub",
    "content": "Annotation Lab offers tight integration with NLP Models. Any compatible model and embeddings can be downloaded and made available to the Annotation Lab users for pre-annotations either from within the application or via manual upload. NLP Models HUB page is accessible from the left navigation panel by users in the Admins group. The Models Hub page lists all the pre-trained models and embeddings from NLP Models Hub that are compatible with the Spark NLP version present in the Annotation Lab. Search Search features are offered to help users identify the models they need based on their names. Additional information such as Library Edition, task for which the model was build as well as publication date are also available on the model tile. Language of the model/embeddings is also available as well as a direct link to the model description page on the NLP Models Hub where you can get more details about the model and usage examples. Filter Users can use the Edition filter to search models specific to an edition. It includes all supported NLP editions: Healthcare, Opensource, Legal, Finance, and Visual. When selecting one option, e.g. “Legal”, users will be presented with all available models for that specific domain. This will ease the exploration of available models, which can then easily be downloaded and used within Annotation Lab projects. To make searching models/embeddings more efficient, Annotation Lab offers a Language filter. Users can select models/embeddings on the Models Hub page according to their language preference. Download By selecting one or multiple models from the list, users can download those to the Annotation Lab. The licensed (Healthcare, Visual, Finance or Legal) models and embeddings are available to download only when a valid license is present. One restriction on models download/upload is related to the available disk space. Any model download requires that the double of its size is available on the local storage. If enough space is not available then the download cannot proceed. Disk usage view, search, and filter features are available on the upper section of the Models Hub page. Benchmarking For the licensed models, benchmarking information is available on the Models Hub page. To check this click on the icon on the lower right side of the model tile. The benchmarking information can be used to guide the selection of the model you include in your project configuration.",
    "url": "/docs/en/alab/models_hub",
    "relUrl": "/docs/en/alab/models_hub"
  },
  "1284": {
    "id": "1284",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/multi_classifier_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/multi_classifier_dl.html"
  },
  "1285": {
    "id": "1285",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/multi_date_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/multi_date_matcher.html"
  },
  "1286": {
    "id": "1286",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/multi_document_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/multi_document_assembler.html"
  },
  "1287": {
    "id": "1287",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/n_gram_generator.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/n_gram_generator.html"
  },
  "1288": {
    "id": "1288",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_approach.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_approach.html"
  },
  "1289": {
    "id": "1289",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_converter.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_converter.html"
  },
  "1290": {
    "id": "1290",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_crf.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_crf.html"
  },
  "1291": {
    "id": "1291",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_dl.html"
  },
  "1292": {
    "id": "1292",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_overwriter.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_overwriter.html"
  },
  "1293": {
    "id": "1293",
    "title": "NLP Pipelines",
    "content": "Concepts Spark ML provides a set of Machine Learning applications that can be build using two main components: Estimators and Transformers. The Estimators have a method called fit() which secures and trains a piece of data to such application. The Transformer is generally the result of a fitting process and applies changes to the the target dataset. These components have been embedded to be applicable to Spark NLP. Pipelines are a mechanism for combining multiple estimators and transformers in a single workflow. They allow multiple chained transformations along a Machine Learning task. For more information please refer to Spark ML library. Annotation The basic result of a NLP operation is an annotation. It’s structure includes: annotatorType: the type of annotator that generated the current annotation begin: the begin of the matched content relative to raw-text end: the end of the matched content relative to raw-text result: the main output of the annotation metadata: content of matched result and additional information embeddings: (new in 2.0) contains vector mappings if required This object is automatically generated by annotators after a transform process. No manual work is required. However, it is important to clearly understand the structure of an annotation to be able too efficiently use it. Annotators Annotators are the spearhead of NLP functions in Spark NLP. There are two forms of annotators: Annotator Approaches: are those who represent a Spark ML Estimator and require a training stage. They have a function called fit(data) which trains a model based on some data. They produce the second type of annotator which is an annotator model or transformer. Annotator Models: are spark models or transformers, meaning they have a transform(data) function. This function takes as input a dataframe to which it adds a new column containing the result of the current annotation. All transformers are additive, meaning they append to current data, never replace or delete previous information. Both forms of annotators can be included in a Pipeline. All annotators included in a Pipeline will be automatically executed in the defined order and will transform the data accordingly. A Pipeline is turned into a PipelineModel after the fit() stage. The Pipeline can be saved to disk and re-loaded at any time. Common Functions setInputCols(column_names): Takes a list of column names of annotations required by this annotator. Those are generated by the annotators which precede the current annotator in the pipeline. setOutputCol(column_name): Defines the name of the column containing the result of the current annotator. Use this name as an input for other annotators down the pipeline requiring the outputs generated by the current annotator. Quickly annotate some text You can run these examples using Python or Scala. The easiest way to run the python examples is by starting a pyspark jupyter notebook including the spark-nlp package: $ java -version # should be Java 8 (Oracle or OpenJDK) $ conda create -n sparknlp python=3.7 -y $ conda activate sparknlp # spark-nlp by default is based on pyspark 3.x $ pip install spark-nlp==4.2.2 pyspark==3.2.1 jupyter $ jupyter notebook Explain Document ML Spark NLP offers a variety of pretrained pipelines that will help you get started, and get a sense of how the library works. We are constantly working on improving the available content. You can checkout a demo application of the Explain Document ML pipeline here: View Demo Downloading and using a pretrained pipeline Explain Document ML (explain_document_ml) is a pretrained pipeline that does a little bit of everything NLP related. Let’s try it out in scala. Note that the first time you run the below code it might take longer since it downloads the pretrained pipeline from our servers! from johnsnowlabs import nlp spark = nlp.start() explain_document_pipeline = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;) annotations = explain_document_pipeline.annotate(&quot;We are very happy about SparkNLP&quot;) print(annotations) OUTPUT: { &#39;stem&#39;: [&#39;we&#39;, &#39;ar&#39;, &#39;veri&#39;, &#39;happi&#39;, &#39;about&#39;, &#39;sparknlp&#39;], &#39;checked&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;lemma&#39;: [&#39;We&#39;, &#39;be&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;document&#39;: [&#39;We are very happy about SparkNLP&#39;], &#39;pos&#39;: [&#39;PRP&#39;, &#39;VBP&#39;, &#39;RB&#39;, &#39;JJ&#39;, &#39;IN&#39;, &#39;NNP&#39;], &#39;token&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;sentence&#39;: [&#39;We are very happy about SparkNLP&#39;] } As you can see the explain_document_ml is able to annotate any “document” providing as output a list of stems, check-spelling, lemmas, part of speech tags, tokens and sentence boundary detection and all this “out-of-the-box”!. Using a pretrained pipeline with spark dataframes You can also use the pipeline with a spark dataframe. You just need to create first a spark dataframe with a column named “text” that will work as the input for the pipeline and then use the .transform() method to run the pipeline over that dataframe and store the outputs of the different components in a spark dataframe. Remember than when starting jupyter notebook from pyspark or when running the spark-shell for scala, a Spark Session is started in the background by default within the namespace ‘scala’. from johnsnowlabs import nlp spark = nlp.start() sentences = [ [&#39;Hello, this is an example sentence&#39;], [&#39;And this is a second sentence.&#39;] ] # spark is the Spark Session automatically started by pyspark. data = spark.createDataFrame(sentences).toDF(&quot;text&quot;) # Download the pretrained pipeline from Johnsnowlab&#39;s servers explain_document_pipeline = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;) OUTPUT: explain_document_ml download started this may take some time. Approx size to download 9.4 MB [OK!] # Transform &#39;data&#39; and store output in a new &#39;annotations_df&#39; dataframe annotations_df = explain_document_pipeline.transform(data) # Show the results annotations_df.show() OUTPUT: +--+--+--+--+--+--+--+--+ | text| document| sentence| token| checked| lemma| stem| pos| +--+--+--+--+--+--+--+--+ |Hello, this is an...|[[document, 0, 33...|[[document, 0, 33...|[[token, 0, 4, He...|[[token, 0, 4, He...|[[token, 0, 4, He...|[[token, 0, 4, he...|[[pos, 0, 4, UH, ...| |And this is a sec...|[[document, 0, 29...|[[document, 0, 29...|[[token, 0, 2, An...|[[token, 0, 2, An...|[[token, 0, 2, An...|[[token, 0, 2, an...|[[pos, 0, 2, CC, ...| +--+--+--+--+--+--+--+--+ Manipulating pipelines The output of the previous DataFrame was in terms of Annotation objects. This output is not really comfortable to deal with, as you can see by running the code: annotations_df.select(&quot;token&quot;).show(truncate=False) OUTPUT: +--+ |token | +--+ |[[token, 0, 4, Hello, [sentence -&gt; 0], [], []], [token, 5, 5, ,, [sentence -&gt; 0], [], []], [token, 7, 10, this, [sentence -&gt; 0], [], []], [token, 12, 13, is, [sentence -&gt; 0], [], []], [token, 15, 16, an, [sentence -&gt; 0], [], []], [token, 18, 24, example, [sentence -&gt; 0], [], []], [token, 26, 33, sentence, [sentence -&gt; 0], [], []]]| |[[token, 0, 2, And, [sentence -&gt; 0], [], []], [token, 4, 7, this, [sentence -&gt; 0], [], []], [token, 9, 10, is, [sentence -&gt; 0], [], []], [token, 12, 12, a, [sentence -&gt; 0], [], []], [token, 14, 19, second, [sentence -&gt; 0], [], []], [token, 21, 28, sentence, [sentence -&gt; 0], [], []], [token, 29, 29, ., [sentence -&gt; 0], [], []]] | +--+ What if we want to deal with just the resulting annotations? We can use the Finisher annotator, retrieve the Explain Document ML pipeline, and add them together in a Spark ML Pipeline. Remember that pretrained pipelines expect the input column to be named “text”. from johnsnowlabs import nlp spark = nlp.start() finisher = nlp.Finisher().setInputCols([&quot;token&quot;, &quot;lemmas&quot;, &quot;pos&quot;]) explain_pipeline_model = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;).model pipeline = nlp.Pipeline() .setStages([ explain_pipeline_model, finisher ]) sentences = [ [&#39;Hello, this is an example sentence&#39;], [&#39;And this is a second sentence.&#39;] ] data = spark.createDataFrame(sentences).toDF(&quot;text&quot;) model = pipeline.fit(data) annotations_finished_df = model.transform(data) annotations_finished_df.select(&#39;finished_token&#39;).show(truncate=False) OUTPUT: +-+ |finished_token | +-+ |[Hello, ,, this, is, an, example, sentence]| |[And, this, is, a, second, sentence, .] | +-+ Setup your own pipeline Annotator types Every annotator has a type. Those annotators that share a type, can be used interchangeably, meaning you could use any of them when needed. For example, when a token type annotator is required by another annotator, such as a sentiment analysis annotator, you can either provide a normalized token or a lemma, as both are of type token. DocumentAssembler: Getting data in In order to get through the NLP process, we need to get raw data annotated. There is a special transformer that does this for us: the DocumentAssembler, it creates the first annotation of type Document which may be used by annotators down the road. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) Sentence detection and tokenization In this quick example, we now proceed to identify the sentences in the input document. SentenceDetector requires a Document annotation, which is provided by the DocumentAssembler output, and it’s itself a Document type token. The Tokenizer requires a Document annotation type. That means it works both with DocumentAssembler or SentenceDetector output. In the following example we use the sentence output. sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;Sentence&quot;) regexTokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) Spark NLP also includes another special transformer, called Finisher to show tokens in a human language. finisher = nlp.Finisher() .setInputCols([&quot;token&quot;]) .setCleanAnnotations(False) Finisher: Getting data out At the end of each pipeline or any stage that was done by Spark NLP, you may want to get results out whether onto another pipeline or simply write them on disk. The Finisher annotator helps you to clean the metadata (if it’s set to true) and output the results into an array: finisher = nlp.Finisher() .setInputCols([&quot;token&quot;]) .setIncludeMetadata(True) If you need to have a flattened DataFrame (each sub-array in a new column) from any annotations other than struct type columns, you can use explode function from Spark SQL. You can also use Apache Spark functions (SQL) to manipulate the output DataFrame in any way you need. Here we combine the tokens and NER results together: from johnsnowlabs import nlp df.withColumn(&quot;tmp&quot;, nlp.F.explode(&quot;chunk&quot;)).select(&quot;tmp.*&quot;) Using Spark ML Pipeline Now we want to put all this together and retrieve the results, we use a Pipeline for this. We use the same data in fit() that we will use in transform since none of the pipeline stages have a training stage. from johnsnowlabs import nlp pipeline = nlp.Pipeline() .setStages([ documentAssembler, sentenceDetector, regexTokenizer, finisher ]) OUTPUT: +-+ |finished_token | +-+ |[hello, ,, this, is, an, example, sentence]| +-+ Using Spark NLP’s LightPipeline LightPipeline is a Spark NLP specific Pipeline class equivalent to Spark ML Pipeline. The difference is that it’s execution does not hold to Spark principles, instead it computes everything locally (but in parallel) in order to achieve fast results when dealing with small amounts of data. This means, we do not input a Spark Dataframe, but a string or an Array of strings instead, to be annotated. To create Light Pipelines, you need to input an already trained (fit) Spark ML Pipeline. It’s transform() stage is converted into annotate() instead. from johnsnowlabs import nlp explain_document_pipeline = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;) lightPipeline = nlp.LightPipeline(explain_document_pipeline.model) OUTPUT: explain_document_ml download started this may take some time. Approx size to download 9.4 MB [OK!] lightPipeline.annotate(&quot;Hello world, please annotate my text&quot;) OUTPUT: {&#39;stem&#39;: [&#39;hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;pleas&#39;, &#39;annot&#39;, &#39;my&#39;, &#39;text&#39;], &#39;checked&#39;: [&#39;Hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;please&#39;, &#39;annotate&#39;, &#39;my&#39;, &#39;text&#39;], &#39;lemma&#39;: [&#39;Hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;please&#39;, &#39;annotate&#39;, &#39;i&#39;, &#39;text&#39;], &#39;document&#39;: [&#39;Hello world, please annotate my text&#39;], &#39;pos&#39;: [&#39;UH&#39;, &#39;NN&#39;, &#39;,&#39;, &#39;VB&#39;, &#39;NN&#39;, &#39;PRP$&#39;, &#39;NN&#39;], &#39;token&#39;: [&#39;Hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;please&#39;, &#39;annotate&#39;, &#39;my&#39;, &#39;text&#39;], &#39;sentence&#39;: [&#39;Hello world, please annotate my text&#39;]} Training annotators Training methodology Training your own annotators is a key concept when dealing with real life scenarios. Any of the annotators provided above, such as pretrained pipelines and models, can be applied out-of-the-box to a specific use case, but better results are obtained when they are fine-tuned to your specific use-case. Dealing with real life problems ofter requires training your own models. In Spark NLP, we support three ways of training a custom annotator: Train from a dataset. Most annotators are capable of training from a dataset passed to fit() method just as Spark ML does. Annotators that use the suffix Approach are such trainable annotators. Training from fit() is the standard behavior in Spark ML. Annotators have different schema requirements for training. Check the reference to see what are the requirements of each annotators. Training from an external source: Some of our annotators train from an external file or folder passed to the annotator as a param. You will see such ones as setCorpus() or setDictionary() param setter methods, allowing you to configure the input to use. You can set Spark NLP to read them as Spark datasets or LINE_BY_LINE which is usually faster for small files. Last but not least, some of our annotators are Deep Learning based. These models may be trained with the standard AnnotatorApproach API just like any other annotator. For more advanced users, we also allow importing your own graphs or even training from Python and converting them into an AnnotatorModel. Spark ML Pipelines SparkML Pipelines are a uniform structure that helps creating and tuning practical machine learning pipelines. Spark NLP integrates with them seamlessly so it is important to have this concept handy. Once a Pipeline is trained with fit(), it becomes a PipelineModel Example: from johnsnowlabs import nlp pipeline = nlp.Pipeline().setStages([...]) LightPipeline LightPipelines are Spark ML pipelines converted into a single machine but multithreaded task, becoming more than 10x times faster for smaller amounts of data (small is relative, but 50k sentences is roughly a good maximum). To use them, simply plug in a trained (fitted) pipeline. Example: from johnsnowlabs import nlp nlp.LightPipeline(someTrainedPipeline).annotate(someStringOrArray) Functions: annotate(string or string[]): returns dictionary list of annotation results fullAnnotate(string or string[]): returns dictionary list of entire annotations content For more details please refer to Using Spark NLP’s LightPipelines. RecursivePipeline Recursive pipelines are SparkNLP specific pipelines that allow a Spark ML Pipeline to know about itself on every Pipeline Stage task, allowing annotators to utilize this same pipeline against external resources to process them in the same way the user decides. Only some of our annotators take advantage of this. RecursivePipeline behaves exactly the same as normal Spark ML pipelines, so they can be used with the same intention. Example: from johnsnowlabs import nlp recursivePipeline = nlp.RecursivePipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, lemmatizer, finisher ]) Params and Features Annotator parameters SparkML uses ML Params to store pipeline parameter maps. In SparkNLP, we also use Features, which are a way to store parameter maps that are larger than just a string or a boolean. These features are serialized as either Parquet or RDD objects, allowing much faster and scalable annotator information. Features are also broadcasted among executors for better performance.",
    "url": "/docs/en/jsl/nlp_pipes",
    "relUrl": "/docs/en/jsl/nlp_pipes"
  },
  "1294": {
    "id": "1294",
    "title": "NLP Server",
    "content": "This is a ready to use NLP Server for analyzing text documents using NLU library. Over 4500+ industry grade NLP Models in 300+ Languages are available to use via a simple and intuitive UI, without writing a line of code. For more expert users and more complex tasks, NLP Server also provides a REST API that can be used to process high amounts of data. The models, refered to as spells, are provided by the NLU library and powered by the most widely used NLP library in the industry, Spark NLP. NLP Server is free for everyone to download and use. There is no limitation in the amount of text to analyze. You can setup NLP-Server as a Docker Machine in any enviroment or get it via the AWS Marketplace in just 1 click. Web UI The Web UI is accessible at the following URL: http://localhost:5000/ It allows a very simple and intuitive interaction with the NLP Server. As a first step the user chooses the spell from the first dropdown. All NLU spells are available. Then the user has to provide a text document for analysis. This can be done by either copy/pasting text on the text box, or by uploading a csv/json file. After selecting the grouping option, the user clicks on the Preview button to get the results for the first 10 rows of text. REST API NLP Server includes a REST API which can be used to process any amount of data using NLU. Once you deploy the NLP Server, you can access the API documentation at the following URL http://localhost:5000/docs. Integrate via the Rest API Rest APIs are a popular way to integrate different services into one common platform. NLP Server offers its own API to offer a quick programmatic integration with customers’ services and applications. Bellow is a quick overview of the provided endpoints. More details are provided in the API documentation available http://localhost:5000/docs. Start to analyze Endpoint : /results Method : POST Content-Type (Format) : multipart/form-data Parameters: Spell – the spell that you want to use for this analyze (if you want to run multiple spells you should join them with space character) Data – The data to analyse that can be a single text or an array of strings or files. Grouping – can be choosen from [“document”, “sentence”, “entity”, “word”]. The default value is “” for automatic selection based on spell. Format – The format of the provided input. The default value is “text”. Response: uuid – the unique identifier for the analysis process. Check the status of an analysis process Endpoint : /results/{uuid}/status Method : GET Content-Type (Format) : application/json Response: code – the status code that can be one of “progress”, “success”, “failure”, “broken spell”, “invalid license”, “licensed spell with no license” message – the status message Get the results After ensuring the status of an analysis is “success” you can get the results: Endpoint : /results/{uuid} Method : GET Content-Type (Format) : application/json Parameters: target – if the specified target is “preview” you only get a small part of results. Response: A JSON object that contains the results generated by the spell (each spell has their own specific keys) How to use in Python import requests # Invoke Processing with tokenization spell r = requests.post(f&#39;http://localhost:5000/api/results&#39;,json={&quot;spell&quot;: &quot;tokenize&quot;,&quot;data&quot;: &quot;I love NLU! &lt;3&quot;}) # Use the uuid to get your processed data uuid = r.json()[&#39;uuid&#39;] # Get status of processing r = requests.get(f&#39;http://localhost:5000/api/results/{uuid}/status&#39;).json &gt;&gt;&gt; {&#39;status&#39;: {&#39;code&#39;: &#39;success&#39;, &#39;message&#39;: None}} # Get results r = requests.get(f&#39;http://localhost:5000/api/results/{uuid}&#39;).json() &gt;&gt;&gt; {&#39;sentence&#39;: {&#39;0&#39;: [&#39;I love NLU! &lt;3&#39;]}, &#39;document&#39;: {&#39;0&#39;: &#39;I love NLU! &lt;3&#39;}, &#39;token&#39;: {&#39;0&#39;: [&#39;I&#39;, &#39;love&#39;, &#39;NLU&#39;, &#39;!&#39;, &#39;&lt;3&#39;]}} Import a license key Thanks to the close integration between NLP Server and https://my.JohnSnowLabs.com website, users can easily select and import one of the available licenses to be used on NLP Server. The steps to execute for this are: 1.Click on Login via MYJSL button on the menu bar. 2.In the pop-up window click on the Authorize button. 3.After redirecting back to NLP Server click on the Choose License button. 4.In the modal choose the license that you want to use and then click on the Select button. 5.After the above steps you will see this success alert on the top right of the page. That confirms the import of license completed successfully.",
    "url": "/docs/en/nlp_server/nlp_server",
    "relUrl": "/docs/en/nlp_server/nlp_server"
  },
  "1295": {
    "id": "1295",
    "title": "Healthcare Models and Domains overview",
    "content": "This page gives you an overview of every healthcare problem and domain that can be solved with NLU for healthcare models, together with concrete examples. See this notebook and the accompanying video below for an introduction to every healthcare domain. Medical Named Entity Recognition (NER) Named entities are sub-strings in a text that can be classified into catogires of a domain. For example, in the String &quot;Tesla is a great stock to invest in &quot; , the sub-string &quot;Tesla&quot; is a named entity, it can be classified with the label company by an ML algorithm. Named entities can easily be extracted by the various pre-trained Deep Learning based NER algorithms provided by NLU. NER models can be trained for many different domains and aquire expert domain knowledge in each of them. JSL provides a wide array of experts for various Medical, Helathcare and Clinical domains This algorithm is provided by Spark NLP for Healthcare’s MedicalNerModel Domain Description Sample NLU Spells Sample Entities Sample Predicted Labels Reference Links ADE (Adverse Drug Events) Find adverse drug event (ADE) related entities med_ner.ade_biobert Aspirin , vomiting DRUG, ADE CADEC, Twimed Anatomy Find body parts, anatomical sites a nd reference related entities med_ner.anatomy tubules, nasopharyngeal aspirates, embryoid bodies, NK cells, Mitochondrial, tracheoesophageal fistulas, heart, colon cancer, cervical, central nervous system Tissue_structure, Organism_substance, Developing_anatomical_structure, Cell, Cellular_component, Immaterial_anatomical_entity, organ, Pathological_formation, Organism_subdivision, Anatomical_system AnEM Cellular/Molecular Biology Find Genes, Molecules, Cell or general Biology related entities med_ner.cellular.biobert human T-cell leukemia virus type 1 Tax-responsive , primary T lymphocytes, E1A-immortalized, Spi-B mRNA, zeta-globin DNA, Cell_type, Cell_line, RNA, Protein JNLPBA Chemical/Genes/Proteins Find Chemical, Gene and Protein related entities med_ner.chemprot.clinical nitrogen , β-amyloid , NF-kappaB CHEMICAL, GENE-Y, GENE-N ChemProt Chemical Compounds Find general chemical compound related entities med_ner.chemicals resveratrol , β-polyphenol CHEM Dataset by John Snow Labs Drug Chemicals Find chemical and drug related entities med_ner.drugs potassium , anthracyclines, taxanes DrugChem.DrugChem.DrugChem i2b2 + FDA Posology/Drugs Find posology and drug related entities med_ner.posology.biobert 5000 units, Aspirin, 14 days, tablets, daily, topically, 30 mg DOSAGE, DRUG, DURATION, FORM, FREQUENCY, ROUTE, STRENGTH. i2b2 + FDA Risk Factors Find risk factor of patient related entities med_ner.risk_factors.biobert coronary artery disease, hypertension, Smokes 2 packs of cigarettes per day, morbid obesity, Actos, Works in School, diabetic, diabetic CAD, HYPERTENSION, SMOKER, OBESE, FAMILY_HIST, MEDICATION, PHI, HYPERLIPIDEMIA, DIABETES De-identification and Heart Disease Risk Factors Challenge datasets cancer Genetics Find cancer and genetics related entities med_ner.cancer human, Kir 3.3, GIRK3, potassium, GIRK, chromosome 1q21-23, pancreas, tissues, fat andskeletal muscle, KCNJ9, Type II, breast cancer, patients, anthracyclines, taxanes, vinorelbine, patients, breast, vinorelbine inpatients, anthracyclines Amino_acid, Anatomical_system, cancer, Cell, Cellular_component, Developing_anatomical_Structure , Gene_or_gene_product, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism , Organism_subdivision, Simple_chemical, Tissue CG TASK of BioNLP 2013 Diseases Find disease related entities med_ner.diseases.biobert the cyst, a large Prolene suture, a very small incisional hernia, the hernia cavity, omentum, the hernia, the wound lesion, The lesion, the existing scar, the cyst, the wound, this cyst down to its base, a small incisional hernia, The cyst Disease CG TASK of BioNLP 2013 Bacterial Species Find bacterial species related entities med_ner.bacterial_species Neisseria wadsworthii, N. bacilliformis, Spirochaeta litoralis SPECIES Dataset by John Snow Labs Medical Problem/Test/Treatment Find medical problem,test and treatment related entities med_ner.healthcare respiratory tract infection , Ourexpression studies, atorvastatin PROBLEM, TEST, TREATMENT i2b2 Clinical Admission Events Find clinical admission event related entities med_ner.admission_events 2007, 12 AM, Headache, blood sample, presented, emergency room, daily DATE, TIME, PROBLEM, TEST, TREATMENT, OCCURENCE, CLINICAL_DEPT, EVIDENTIAL, DURATION, FREQUENCY, ADMISSION, DISCHARGE Custom i2b2, enriched with Events Genetic Variants Find genetic variant related entities en.med_ner.genetic_variants rs1061170, p.S45P, T13046C DNAMutation, ProteinMutation, SNP TMVAR PHI (Protected Healthcare Information) Find PHI(Protected Healthcare) related entities en.med_ner.deid 2093-01-13, David Hale, Hendrickson,&lt;br&gt; Ora, 7194334, 01/13/93, Oliveira, 25-year-old, 1-11-2000, Cocke County Baptist Hospital, 0295 Keats Street., (302) 786-5227, Brothers Coal-Mine MEDICALRECORD, ORGANIZATION, DOCTOR, USERNAME, PROFESSION, HEALTHPLAN, URL, CITY, DATE, LOCATION-OTHER, STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL, EMAIL, IDNUM, SREET, BIOID, FAX, AGE n2c2 i2b2-PHI Social Determinants / Demographic Data Find Social Determinants and Demographic Data Related Entities med_ner.jsl.enriched 21-day-old, male, congestion, mom, suctioning yellow discharge, she, problems with his breathing, perioral cyanosis, retractions, mom, Tylenol, His, his, respiratory congestion, He, tired, fussy, albuterol Age, Diagnosis, Dosage, Drug_Name, Frequency, Gender, Lab_Name, Lab_Result, Symptom_Name Dataset by John Snow Labs General Clinical Find General Clinical Entities med_ner.jsl.wip.clinical.modifier 28-year-old, female, gestational, diabetes, mellitus, eight, years, prior, type, two, diabetes, mellitus, T2DM, HTG-induced, pancreatitis, three, years, prior, acute, hepatitis, obesity, body, mass, index, BMI, kg/m2, polyuria, polydipsia, poor, appetite, vomiting, Two, weeks, prior, she, five-day, course Injury_or_Poisoning, Direction, Test, Admission_Discharge, Death_Entity, Relationship_Status, Duration, Respiration, Hyperlipidemia, Birth_Entity, Age, Labour_Delivery, Family_History_Header, BMI, Temperature, Alcohol, Kidney_Disease, Oncological, Medical_History_Header, Cerebrovascular_Disease, Oxygen_Therapy, O2_Saturation, Psychological_Condition, Heart_Disease, Employment, Obesity, Disease_Syndrome_Disorder, Pregnancy, ImagingFindings, Procedure, Medical_Device, Race_Ethnicity, Section_Header, Symptom, Treatment, Substance, Route, Drug_Ingredient, Blood_Pressure, Diet, External_body_part_or_region, LDL, VS_Finding, Allergen, EKG_Findings, Imaging_Technique, Triglycerides, RelativeTime, Gender, Pulse, Social_History_Header, Substance_Quantity, Diabetes, Modifier, Internal_organ_or_component, Clinical_Dept, Form, Drug_BrandName, Strength, Fetus_NewBorn, RelativeDate, Height, Test_Result, Sexually_Active_or_Sexual_Orientation, Frequency, Time, Weight, Vaccine, Vital_Signs_Header, Communicable_Disease, Dosage, Overweight, Hypertension, HDL, Total_Cholesterol, Smoking, ` Dataset by John Snow Labs Radiology Find Radiology related entities med_ner.radiology.wip_clinical Bilateral, breast, ultrasound, ovoid mass, 0.5 x 0.5 x 0.4, cm, anteromedial aspect, left, shoulder, mass, isoechoic echotexture, muscle, internal color flow, benign fibrous tissue, lipoma ImagingTest, Imaging_Technique, ImagingFindings, OtherFindings, BodyPart, Direction, Test, Symptom, Disease_Syndrome_Disorder, Medical_Device, Procedure, Measurements, Units Dataset by John Snow Labs, MIMIC-CXR and MT Radiology texts Radiology Clinical JSL-V1 Find radiology related entities in clinical setting med_ner.radiology.wip_greedy_biobert Bilateral, breast, ultrasound, ovoid mass, 0.5 x 0.5 x 0.4, cm, anteromedial aspect, left, shoulder, mass, isoechoic echotexture, muscle, internal color flow, benign fibrous tissue, lipoma Test_Result, OtherFindings, BodyPart, ImagingFindings, Disease_Syndrome_Disorder, ImagingTest, Measurements, Procedure, Score, Test, Medical_Device, Direction, Symptom, Imaging_Technique, ManualFix, Units Dataset by John Snow Labs, Genes and Phenotypes Find Genes and Phenotypes (the observable physical properties of an organism) related entities med_ner.human_phenotype.gene_biobert APOC4 , polyhydramnios GENE, PHENOTYPE PGR_1, PGR_2 Normalized Genes and Phenotypes Find Normalized Genes and Phenotypes (the observable physical properties of an organism) related entities med_ner.human_phenotype.go_biobert protein complex oligomerization , defective platelet aggregation GO, HP PGR_1, PGR_2 Radiology Clinical JSL-V2 Find radiology related entities in clinical setting med_ner.jsl.wip.clinical.rd   Kidney_Disease, HDL, Diet, Test, Imaging_Technique, Triglycerides, Obesity, Duration, Weight, Social_History_Header, ImagingTest, Labour_Delivery, Disease_Syndrome_Disorder, Communicable_Disease, Overweight, Units, Smoking, Score, Substance_Quantity, Form, Race_Ethnicity, Modifier, Hyperlipidemia, ImagingFindings, Psychological_Condition, OtherFindings, Cerebrovascular_Disease, Date, Test_Result, VS_Finding, Employment, Death_Entity, Gender, Oncological, Heart_Disease, Medical_Device, Total_Cholesterol, ManualFix, Time, Route, Pulse, Admission_Discharge, RelativeDate, O2_Saturation, Frequency, RelativeTime, Hypertension, Alcohol, Allergen, Fetus_NewBorn, Birth_Entity, Age, Respiration, Medical_History_Header, Oxygen_Therapy, Section_Header, LDL, Treatment, Vital_Signs_Header, Direction, BMI, Pregnancy, Sexually_Active_or_Sexual_Orientation, Symptom, Clinical_Dept, Measurements, Height, Family_History_Header, Substance, Strength, Injury_or_Poisoning, Relationship_Status, Blood_Pressure, Drug, Temperature, ,EKG_Findings, Diabetes, BodyPart, Vaccine, Procedure, Dosage Dataset by John Snow Labs, General Medical Terms Find general medical terms and medical entities. med_ner.medmentions   Qualitative_Concept, Organization, Manufactured_Object, Amino_Acid, Peptide_or_Protein, Pharmacologic_Substance, Professional_or_Occupational_Group, Cell_Component, Neoplastic_Process, Substance, Laboratory_Procedure, Nucleic_Acid_Nucleoside_or_Nucleotide, Research_Activity, Gene_or_Genome, Indicator_Reagent_or_Diagnostic_Aid, Biologic_Function, Chemical, Mammal, Molecular_Function, Quantitative_Concept, Prokaryote, Mental_or_Behavioral_Dysfunction, Injury_or_Poisoning, Body_Location_or_Region, Spatial_Concept, Nucleotide_Sequence, Tissue, Pathologic_Function, Body_Substance, Fungus, Mental_Process, Medical_Device, Plant, Health_Care_Activity, Clinical_Attribute, Genetic_Function, Food, Therapeutic_or_Preventive_Procedure, Body_Part_Organ, Organ_Component, Geographic_Area, Virus, Biomedical_or_Dental_Material, Diagnostic_Procedure, Eukaryote, Anatomical_Structure, Organism_Attribute, Molecular_Biology_Research_Technique, Organic_Chemical, Cell, Daily_or_Recreational_Activity, Population_Group, Disease_or_Syndrome, Group, Sign_or_Symptom, Body_System MedMentions Entity Status Assertion Named Entities extracted by an NER model can be further classified into sub-classes or statuses, depending on the context of the sentence. See the following two examples : Billy hates having a headache Billy has a headache Billy said his father has regular headaches All sentences have the entity headache which is of class disease. But there is a semantic difference on what the actual status of the disease mentioned in text is. In the first and third sentence, Billy has no headache, but in the second sentence Billy actually has a sentence. The Entity Assertion Algorithms provided by JSL solve this problem. The disease entity can be classified into ABSENT for the first case and into PRESENT for the second case. The third case can be classified into PRESENT IN FAMILY. This has immense implications for various data analytical approaches in the helathcare domain. I.e. imagine you want you want to make a study about hearth attacks and survival rate of potential procedures. You can process all your digital patient notes with an Medical NER model and filter for documents that have the Hearth Attack entity. But your collected data will have wrong data entries because of the above mentioned Entity status problem. You cannot deduct that a document is talking about a patient having a hearth attack, unless you assert that the problem is actually there which is what the Resolutions algorithms do for you. Keep in mind: This is a simplified example, entities should actually be mapped to their according Terminology (ICD-10-CM/ICD-10-PCS, etc..) to solve disambiguity problems and based on their codes all analysis should be performed This algorithm is provided by Spark NLP for Healthcare’s AssertionDLModel Domain Description Spell Predicted Entities Examples Reference Dataset Radiology Predict status of Radiology related entities assert.radiology Confirmed, Negative, Suspected - Confirmed: X-Ray scan shows cancer in lung. - Negative : X-Ray scan shows no sign of cancer in lung. - Suspected :X-Ray raises suspicion of cancer in lung but does not confirm it. Internal Dataset by Annotated by John Snow Labs Healthcare/Clinical extended and Family JSL powerd Predict status of, Healthcare/Clinical/Family related entities. Additional training with JSL Dataset assert.jsl Present, Absent, Possible, Planned, Someoneelse, Past, Family, Hypotetical - Present: Patient diagnosed with cancer in 1999 - Absent: No sign of cancer was shown by the scans - Possible: Tests indicate patient might have cancer - Planned: CT-Scan is scheduled for 23.03.1999 - Someoneelse: The patient gave Aspirin to daugther. - Past: The patient has no more headaches since the operation - Family: The patients father has cancer. - Hypotetical:Death could be possible. 2010 i2b2 + Data provided by JSL Healthcare/Clinical JSL powerd Predict status of Healthcare/Clinical related entities. Additional training with JSL Dataset assert.jsl_large present, absent, possible, planned, someoneelse, past - present: Patient diagnosed with cancer in 1999 - absent: No sign of cancer was shown by the scans - possible: Tests indicate patient might have cancer - planned: CT-Scan is scheduled for 23.03.1999 - someoneelse: The patient gave Aspirin to daugther - past: The patient has no more headaches since the operation 2010 i2b2 + Data provided by JSL Healthcare/Clinical classic Predict status of Healthcare/Clinical related entities assert.biobert present , absent, possible, conditional, associated_with_someone_else ,hypothetical - present: Patient diagnosed with cancer in 1999 - absent: No sign of cancer was shown by the scans - possible: Tests indicate patient might have cancer - conditional If the test is positive, patient has AIDS - associated_with_someone_else: The patients father has cancer. -hypothetical :Death could be possible. 2010 i2b2 Entity Resolution Named entities are sub-strings in a text that can be classified into catogires of a domain. For example, in the String &quot;Tesla is a great stock to invest in &quot; , the sub-string &quot;Tesla&quot; is a named entity, it can be classified with the label company by an ML algorithm. Named entities can easily be extracted by the various pre-trained Deep Learning based NER algorithms provided by NLU. After extracting named entities an entity resolution algorithm can be applied to the extracted named entities. The resolution algorithm classifies each extracted entitiy into a class, which reduces dimensionality of the data and has many useful applications. For example : “Tesla is a great stock to invest in “ “TSLA is a great stock to invest in “ “Tesla, Inc is a great company to invest in” The sub-strings Tesla , TSLA and Tesla, Inc are all named entities, that are classified with the labeld company by the NER algorithm. It tells us, all these 3 sub-strings are of type company, but we cannot yet infer that these 3 strings are actually referring to literally the same company. This exact problem is solved by the resolver algorithms, it would resolve all these 3 entities to a common name, like a company ID. This maps every reference of Tesla, regardless of how the string is represented, to the same ID. This example can analogusly be expanded to healthcare any any other text problems. In medical documents, the same disease can be referenced in many different ways. With NLU Healthcare you can leverage state of the art pre-trained NER models to extract Medical Named Entities (Diseases, Treatments, Posology, etc..) and resolve these to common healthcare disease codes. This algorithm is provided by Spark NLP for Healthcare’s SentenceEntitiyResolver Domain/Terminology Description Sample NLU Spells Sample Entities Sample Predicted Codes Reference Links ICD-10 / ICD-10-CM (International Classification of Diseases - Clinical Modification) Get ICD-10-CM codes of Medical and Clinical Entities. The ICD-10 Clinical Modification (ICD-10-CM) is a modification of the ICD-10, authorized by the World Health Organization, used as a source for diagnosis codes in the U.S. Be aware, ICD10-CM is often referred to as ICD10 resolve.icd10cm.augmented hypertension , gastritis I10, K2970 ICD-10-CM , WHO ICD-10-CM ICD-10-PCS (International Classification of Diseases - Procedure Coding System) Get ICD-10-PCS codes of Medical and Clinical Entities. The International Classification of Diseases, Procedure Coding System (ICD-10-PCS), is a U.S. cataloging system for procedural code It is maintaining by Centers for Medicare &amp; Medicaid Services resolve.icd10pcs hypertension , gastritis DWY18ZZ, 04723Z6 ICD10-PCS, CMS ICD-10-PCS ICD-O (International Classification of Diseases, Oncollogy) Topography &amp; Morphology codes Get ICD-0 codes of Medical and Clinical Entities. The International Classification of Diseases for Oncology (ICD-O), is a domain-specific extension of the International Statistical Classification of Diseases and Related Health Problems for tumor diseases. resolve.icdo.base metastatic lung cancer 9050/3+C38.3, 8001/3+C39.8 ICD-O Histology Behaviour dataset HCC (Hierachical Conditional Categories) Get HCC codes of Medical and Clinical Entities. Hierarchical condition category (HCC) relies on ICD-10 coding to assign risk scores to patients. Along with demographic factors (such as age and gender), insurance companies use HCC coding to assign patients a risk adjustment factor (RAF) score. resolve.hcc hypertension , gastritis 139, 188 HCC ICD-10-CM + HCC Billable Get ICD-10-CM and HCC codes of Medical and Clinical Entities. resolve.icd10cm.augmented_billable metastatic lung cancer C7800 + [&#39;1&#39;, &#39;1&#39;, &#39;8&#39;] ICD10-CM HCC CPT (Current Procedural Terminology) Get CPT codes of Medical and Clinical Entities. The Current Procedural Terminology(CPT) is developed by the American Medical Association (AMA) and used to assign codes to medical procedures/services/diagonstics. The codes are used to derive the amount of payment a healthcare provider may receives from insurance companies for the provided service.receives resolve.cpt.procedures_measurements calcium score, heart surgery 82310, 33257 CPT LOINC (Logical Observation Identifiers Names and Codes) Get LOINC codes of Medical and Clinical Entities. Logical Observation Identifiers Names and Codes (LOINC) developed by theU.S. organization Regenstrief Institute LOINC is a code system for identifying test observations. resolve.loinc acute hepatitis ,obesity 28083-4,50227-8 LOINC HPO (Human Phenotype Ontology) Get HPO codes of Medical and Clinical Entities. resolve.HPO cancer, bipolar disorder 0002664, 0007302, 0100753 HPO UMLS (Unified Medical Language System) CUI Get UMLS codes of Medical and Clinical Entities. resolve.umls.findings vomiting, polydipsia, hepatitis C1963281, C3278316, C1963279 UMLS SNOMED International (Systematized Nomenclature of Medicine) Get SNOMED (INT) codes of Medical and Clinical Entities. Defines sets of codes for entities in medical reports. resolve.snomed.findings_int hypertension 148439002 SNOMED SNOMED CT (Clinical Terms) Get SNOMED (CT) codes of Medical and Clinical Entities. resolve.snomed.findings hypertension 73578008 SNOMED SNOMED Conditions Get SNOMED Conditions codes of Medical and Clinical Entities. resolve.snomed_conditions schizophrenia 58214004 SNOMED RxNorm and RxCUI (Concept Uinque Indentifier) Get Normalized RxNorm and RxCUI codes of Medical, Clinical and Drug Entities. resolve.rxnorm 50 mg of eltrombopag oral 825427 [RxNorm Overview] [November 2020 RxNorm Clinical Drugs ontology graph] Entity Relationship Extraction Most sentences and documents have a lof of entities which can be extracted with NER. These entities alone already provide a lot of insight and information about your data, but there is even more information extractable… Each entity in a sentence always has some kind of relationship to every other entity in the sentence. In other words, each entity pair has a relationship ! If a sentence has N entities, there are NxN potential binary relationships and NxNxK for k-ary relationships. The RelationExtraction algortihms provided by JSL classify for each pair of entities what the type of relationship between is, based on some domain. A concrete use-case example: Lets say you want to analyze the survival rate of amputation procedures performed on the left hand. Using just NER, we could find all documents that mention the entity amputation , left and hand. The collected data will have wrong entries, imagine the following clinical note : The patients left foot and his right hand were amputated This record would be part of our analysis, if we just use NER with the above mentioned filtering. The RelationExtraction Algorithms provided by JSL solves this problem. The relation.bodypart.directions model can classify for each entity pair, wether they are related or not. In our example, it can classify that left and foot are related and that right and hand are related. Based on these classified relationships, we can easily enhance our filters and make sure no wrong records are used for our surival rate analysis. But what about the following sentence? The patients left hand was saved but his foot was amputated This would pass all the NER and Relationship filters defined sofar. But we can easily cover this case by using the relation.bodypart.procedures model, which can predict wether a procedure entity was peformed on some bodypart or not. In the last example, it can predict foot and amputated are related, buthand and amputated are not in relationship, aswell as left and amputated (since every entity pair gets a prediction). In conclusion, we can adjust our filters to additionaly verify that the amputation procedure is peformed on a hand and that this hand is in relationship with a direction entity with the value left. Keep in mind: This is a simplified example, entities should actually be mapped to their according Terminology (ICD-10-CM/ICD-10-PCS, etc..) to solve disambiguity problems and based on their codes all analysis should be performed These algorithms are provided by Spark NLP for Healthcare’s RelationExtraction and RelationExtractionDL Entity Relationship Extraction - Overview Domain Description Sample NLU Spells Predictable Relationships and Explanation Dates and Clinical Entities Predict binary temporal relationship between Date Entities and Clinical Entities relation.date - 1 for Date Entity and Clinical Entity are related. - 0 for Date Entity and Clinical Entity are not related Body Parts and Directions Predict binary direction relationship between Bodypart Entities and Direction Entities relation.bodypart.direction - 1 for Body Part and Direction are related - 0 for Body Part and Direction are not related Body Parts and Problems Predict binary location relationship between Bodypart Entities and Problem Entities relation.bodypart.problem - 1 for Body Part and Problem are related - 0 for Body Part and Problem are not related Body Parts and Procedures Predict binary application relationship between Bodypart Entities and Procedure Entities relation.bodypart.procedure - 1 for Body Part and Test/Procedure are related - 0 for Body Part and Test/Procedure are not related Adverse Effects between drugs (ADE) Predict binary effect relationship between Drugs Entities and Adverse Effects/Problem Entities relation.ade - 1 for Adverse Event Entity and Drug are related - 0 for Adverse Event Entity and Drug are not related Phenotype abnormalities,Genes and Diseases Predict binary caused by relationship between Phenotype Abnormality Entities, Gene Entities and Disease Entities relation.humen_phenotype_gene - 1 for Gene Entity and Phenotype Entity are related - 0 for Gene Entity and Phenotype Entity are not related Temporal events Predict multi-class temporal relationship between Time Entities and Event Entities relation.temporal_events - AFTER if Any Entity occured after Another Entity - BEFORE if Any Entity occured before Another Entity - OVERLAP if Any Entity during Another Entity Dates and Tests/Results Predict multi-class temporal cause,reasoning and conclusion relationship between Date Entities, Test Entities and Result Entities relation.test_result_date - relation.test_result_date - is_finding_of for Medical Entity is found because of Test Entity - is_result_of for Medical Entity reason for doing Test Entity - is_date_of for Date Entity relates to time of Test/Result - 0 : No relationship Clinical Problem, Treatment and Tests Predict multi-class cause,reasoning and effect relationship between Treatment Entities, Problem Entities and Test Entities relation.clinical - TrIP: A certain treatment has improved/cured a medical problem - TrWP: A patient’s medical problem has deteriorated or worsened because of treatment - TrCP: A treatment caused a medical problem - TrAP: A treatment administered for a medical problem - TrNAP: The administration of a treatment was avoided because of a medical problem - TeRP: A test has revealed some medical problem - TeCP: A test was performed to investigate a medical problem - PIP: Two problems are related to each other DDI Effects of using Multiple Drugs (Drug Drug Interaction) Predict multi-class effects, mechanisms and reasoning for DDI effects(Drug Drug Interaction) relationships between Drug Entities relation.drug_drug_interaction - DDI-advise when an advice/recommendation regarding aDrug Entity and Drug Entity is given - DDI-effect when Drug Entity and Drug Entity have an effect on the human body (pharmacodynamic mechanism). Including a clinical finding, signs or symptoms, an increased toxicity or therapeutic failure. - DDI-int when effect between Drug Entity and Drug Entity is already known and thus provides no additional information. - DDI-mechanism when ** Drug Entity** and Drug Entity are affected by an organism (pharmacokinetic). Such as the changes in levels or concentration in a drug. Used for DDIs that are described by their PK mechanism - DDI-false when a Drug Entity and Drug Entity have no interaction mentioned in the text Posology (Drugs, Dosage, Duration, Frequency,Strength) Predict multi-class posology relationships between Drug Entities,Dosage Entities,Strength Entities,Route Entities, Form Entities, Duration Entities and Frequency Entities relation.posology - DRUG-ADE if Problem Entity Adverse effect of Drug Entity - DRUG-DOSAGE if Dosage Entity refers to a Drug Entity - DRUG-DURATION if Duration Entity refers to a Drug Entity - DRUG-FORM if Mode/Form Entity refers to intake form of Drug Entity - DRUG-FREQUENCY if Frequency Entity refers to usage of Drug Entity - DRUG-REASON if Problem Entity is reason for taking Drug Entity - DRUG-ROUTE if Route Entity refer to administration method of Drug Entity - DRUG-STRENGTH if Strength Entity refers to Drug Entity Chemicals and Proteins Predict Regulator, Upregulator, Downregulator, Agonist, Antagonist, Modulator, Cofactor, Substrate relationships between Chemical Entities and Protein Entities relation.chemprot - CPR:1 if One ChemProt Entity is Part of of Another ChemProt Entity - CPR:2 if One ChemProt Entity is Regulator (Direct or Indirect) of Another ChemProt Entity - CPR:3 if One ChemProt Entity is Upregulator/Activator/Indirect Upregulator of Another ChemProt Entity - CPR:4 if One ChemProt Entity is Downregulator/Inhibitor/Indirect Downregulator of Another ChemProt Entity - CPR:5 if One ChemProt Entity is Agonist of Another ChemProt Entity - CPR:6 if One ChemProt Entity is Antagonist of Another ChemProt Entity - CPR:7 if One ChemProt Entity is Modulator (Activator/Inhibitor) of Another ChemProt Entity - CPR:8 if One ChemProt Entity is Cofactor of Another ChemProt Entity - CPR:9 if One ChemProt Entity is Substrate and product of of Another ChemProt Entity - CPR:10 if One ChemProt Entity is Not Related to Another ChemProt Entity Entity Relationship Extraction - Examples Domain Sentence With Relationships Predicted Relationships for Sample Sentence Reference Links Dates and Clinical Entities This 73 y/o patient had CT on 1/12/95, with cognitive decline since 8/11/94. - 1 for CT and1/12/95 - 0 for ** cognitive decline** and 1/12/95 - 1 for cognitive decline and 8/11/94 Internal Dataset by Annotated by John Snow Labs Body Parts and Directions MRI demonstrated infarction in the upper - brain stem , left cerebellum and right basil ganglia - 1 for uppper and brain stem - 0 for upper and cerebellum - 1 for left and cerebellum Internal Dataset by Annotated by John Snow Labs Body Parts and Problems Patient reported numbness in his left hand and bleeding from ear. - 1 for numbness and hand - 0 for numbness and ear - 1 for bleeding and ear Internal Dataset by Annotated by John Snow Labs Body Parts and Procedures The chest was scanned with portable ultrasound and amputation was performed on foot - 1 for chest and portable ultrasound - 0 for chest and amputation - 1 for foot and amputation Internal Dataset by Annotated by John Snow Labs Adverse Effects between drugs (ADE) Taking Lipitor for 15 years, experienced much sever fatigue! Doctor moved me to voltaren 2 months ago , so far only experienced cramps - 1 for sever fatigue and Liptor - 0 for sever fatigue and voltaren - 0 for cramps and Liptor - 1 for cramps and voltaren Internal Dataset by Annotated by John Snow Labs Phenotype abnormalities,Genes and Diseases She has a retinal degeneration, hearing loss and renal failure, short stature, Mutations in the SH3PXD2B gene coding for the Tks4 protein are responsible for the autosomal recessive. - 1 for ** hearing loss** and SH3PXD2B - 0 for retinal degeneration and hearing loss - 1 for retinal degeneration and autosomal recessive PGR aclAntology Temporal events She is diagnosed with cancer in 1991. Then she was admitted to Mayo Clinic in May 2000 and discharged in October 2001 - OVERLAP for cancer and 1991 - AFTER for additted and Mayo Clinic - BEFORE for admitted and discharged Temporal JSL Dataset and n2c2 Dates and Tests/Results On 23 March 1995 a X-Ray applied to patient because of headache, found tumor in brain - is_finding_of for tumor ** and **X-Ray - is_result_of for headache ** and **X-Ray - is_date_of for 23 March 1995 ** and **X-Ray Internal Dataset by Annotated by John Snow Labs Clinical Problem, Treatment and Tests - TrIP : infection resolved with antibiotic course - TrWP : the tumor was growing despite the drain - TrCP: penicillin causes a rash - TrAP:Dexamphetamine for narcolepsy - TrNAP: Ralafen was not given because of ulcers - TeRP: an echocardiogram revealed a pericardial effusion - TeCP: chest x-ray for pneumonia - PIP: Azotemia presumed secondary to sepsis - TrIP for infection and antibiotic course - TrWP for tumor and drain - TrCP for penicillin andrash - TrAP for Dexamphetamine and narcolepsy - TrNAP for Ralafen and ulcers - TeRP for echocardiogram and pericardial effusion - TeCP for chest x-ray and pneumonia - PIP for Azotemia and sepsis 2010 i2b2 relation challenge DDI Effects of using Multiple Drugs (Drug Drug Interaction) - DDI-advise: UROXATRALshould not be used in combination with other alpha-blockers - DDI-effect: Chlorthalidone may potentiate the action of other antihypertensive drugs - DDI-int : The interaction of omeprazole and ketoconazole has been established - DDI-mechanism : Grepafloxacin may inhibit the metabolism of theobromine - DDI-false : Aspirin does not interact with Chlorthalidone - DDI-advise for UROXATRAL and alpha-blockers - DDI-effect for Chlorthalidone and antihypertensive drugs - DDI-int for omeprazole and ketoconazole - DDI-mechanism for Grepafloxacin and theobromine - DDI-false for Aspirin and Chlorthalidone DDI Extraction corpus Posology (Drugs, Dosage, Duration, Frequency,Strength) - DRUG-ADE: had a headache after taking Paracetamol - DRUG-DOSAGE: took 0.5ML of** Celstone** - DRUG-DURATION: took Aspirin daily for two weeks - DRUG-FORM: took Aspirin as tablets - DRUG-FREQUENCY : Aspirin usage is weekly - DRUG-REASON : Took Aspirin because of headache - DRUG-ROUTE: Aspirin taken orally - DRUG-STRENGTH: 2mg of Aspirin - DRUG-ADE for headache and Paracetamol - DRUG-DOSAGE for 0.5ML and ** Celstone** - DRUG-DURATION for Aspirin and for two weeks - DRUG-FORM for Aspirin and tablets - DRUG-FREQUENCY for Aspirin and weekly - DRUG-REASON for Aspirin and headache - DRUG-ROUTE for Aspirin and orally - DRUG-STRENGTH for 2mg and Aspirin Magge, Scotch, Gonzalez-Hernandez (2018) Chemicals and Proteins - CPR:1 (Part of) : The amino acid sequence of the rabbit alpha(2A)-adrenoceptor has many interesting properties. - CPR:2 (Regulator) : Triacsin inhibited ACS activity - CPR:3 (Upregulator) : Ibandronate increases the expression of the FAS gene - CPR:4 (Downregulator) : Vitamin C treatment resulted in reduced C-Rel nuclear translocation - CPR:5 (Agonist) : Reports show tricyclic antidepressants act as agnonists at distinct opioid receptors - CPR:6 (Antagonist) : GDC-0152 is a drug triggers tumor cell apoptosis by selectively antagonizing LAPs - CPR:7 (Modulator) : Hydrogen sulfide is a allosteric modulator of ATP-sensitive potassium channels - CPR:8 (Cofactor) : polyinosinic:polycytidylic acid ** and the **IFNα/β demonstrate capability of endogenous IFN. - CPR:9 (Substrate) : ZIP9 plays an important role in the transport and toxicity of Cd(2+) cells - CPR:10 (Not Related) **: Studies indicate that **GSK-3β inhibition by palinurin cannot be competed out by ATP - CPR:1 (Part of) for amino acid and rabbit alpha(2A)-adrenoceptor - CPR:2 (Regulator) for Triacsin and ACS - CPR:3 (Upregulator) for Ibandronate and FAS gene - CPR:4 (Downregulator) for Vitamin C and C-Rel - CPR:5 (Agonist) for tricyclic antidepressants and opioid receptors - CPR:6 (Antagonist) (Antagonist) for GDC-0152 and LAPs - CPR:7 (Modulator) for Hydrogen sulfide and ATP-sensitive potassium channels - CPR:8 (Cofactor) for polyinosinic:polycytidylic acid ** and **IFNα/β - CPR:9 (Substrate) for ZIP9 and Cd(2+) cells - CPR:10 (Not Related) ** for **GSK-3β and ATP ChemProt Paper",
    "url": "/docs/en/jsl/nlu_for_healthcare",
    "relUrl": "/docs/en/jsl/nlu_for_healthcare"
  },
  "1296": {
    "id": "1296",
    "title": "OCR models overview",
    "content": "This page gives you an overview of every OCR model in NLU which are provided by Spark OCR. Additionally you can refer to the OCR tutorial Notebooks OCR Tutorial for extracting Text from Image/PDF/DOC(X) files OCR Tutorial for extracting Tables from Image/PDF/DOC(X) files Overview of all OCR features Overview of OCR Text Extractors These models grab the text directly from your input file and returns it as a Pandas DataFrame NLU Spell Transformer Class nlp.load(img2text) ImageToText nlp.load(pdf2text) PdfToText nlp.load(doc2text) DocToText Overview of OCR Table Extractors These models grab all Table data from the files detected and return a list of Pandas DataFrames, containing Pandas DataFrame for every table detected NLU Spell Transformer Class nlp.load(pdf2table) PdfToTextTable nlp.load(ppt2table) PptToTextTable nlp.load(doc2table) DocToTextTable File Path handling for OCR Models When your nlu pipeline contains a ocr spell the predict method will accept the following inputs : a string pointing to a folder or to a file a list, numpy array or Pandas Series containing paths pointing to folders or files a Pandas Dataframe or Spark Dataframe containing a column named path which has one path entry per row pointing to folders or files For every path in the input passed to the predict() method, nlu will distinguish between two cases: If the path points to a file, nlu will apply OCR transformers to it, if the file type is processable with the currently loaded OCR pipeline. If the path points to a folder, nlu will recursively search for files in the folder and sub-folders which have file types which are applicable with the loaded OCR pipeline. NLU checks the file endings to determine whether the OCR models can be applied or not, i.e. .pdf, .img etc.. If your files lack these endings, NLU will not process them. Image to Text Sample image: nlu.load(&#39;img2text&#39;).predict(&#39;path/to/haiku.png&#39;) Output of IMG OCR: text “The Old Pond” by Matsuo Basho An old silent pond A frog jumps into the pond— Splash! Silence again. PDF to Text Sample PDF: nlu.load(&#39;pdf2text&#39;).predict(&#39;path/to/haiku.pdf&#39;) Output of PDF OCR: text “Lighting One Candle” by Yosa Buson The light of a candle Is transferred to another candle— Spring twilight DOCX to text Sample DOCX: nlu.load(&#39;doc2text&#39;).predict(&#39;path/to/haiku.docx&#39;) Output of DOCX OCR: text “In a Station of the Metro” by Ezra Pound The apparition of these faces in the crowd; Petals on a wet, black bough. PDF with Tables Sample PDF: nlu.load(&#39;pdf2table&#39;).predict(&#39;/path/to/sample.pdf&#39;) Output of PDF Table OCR : mpg cyl disp hp drat wt qsec vs am gear 21 6 160 110 3.9 2.62 16.46 0 1 4 21 6 160 110 3.9 2.875 17.02 0 1 4 22.8 4 108 93 3.85 2.32 18.61 1 1 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 18.7 8 360 175 3.15 3.44 17.02 0 0 3 13.3 8 350 245 3.73 3.84 15.41 0 0 3 19.2 8 400 175 3.08 3.845 17.05 0 0 3 27.3 4 79 66 4.08 1.935 18.9 1 1 4 26 4 120.3 91 4.43 2.14 16.7 0 1 5 30.4 4 95.1 113 3.77 1.513 16.9 1 1 5 15.8 8 351 264 4.22 3.17 14.5 0 1 5 19.7 6 145 175 3.62 2.77 15.5 0 1 5 15 8 301 335 3.54 3.57 14.6 0 1 5 21.4 4 121 109 4.11 2.78 18.6 1 1 4 DOCX with Tables Sample DOCX: nlu.load(&#39;doc2table&#39;).predict(&#39;/path/to/sample.docx&#39;) Output of DOCX Table OCR : Screen Reader Responses Share JAWS 853 49% NVDA 238 14% Window-Eyes 214 12% System Access 181 10% VoiceOver 159 9% PPT with Tables Sample PPT with two tables: nlu.load(&#39;ppt2table&#39;).predict(&#39;/path/to/sample.docx&#39;) Output of PPT Table OCR : Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa and Sepal.Length Sepal.Width Petal.Length Petal.Width Species 6.7 3.3 5.7 2.5 virginica 6.7 3 5.2 2.3 virginica 6.3 2.5 5 1.9 virginica 6.5 3 5.2 2 virginica 6.2 3.4 5.4 2.3 virginica 5.9 3 5.1 1.8 virginica Combine OCR and NLP models Sample image containing named entities from U.S. Presidents Wikipedia: nlu.load(&#39;img2text ner&#39;).predict(&#39;path/to/presidents.png&#39;) Output of image OCR and NER NLP : entities_ner entities_ner_class entities_ner_confidence Four CARDINAL 0.9986 Abraham Lincoln PERSON 0.705514 John F. Kennedy), PERSON 0.966533 one CARDINAL 0.9457 Richard Nixon, PERSON 0.71895 John Tyler PERSON 0.9929 first ORDINAL 0.9811 The Twenty-fifth Amendment LAW 0.548033 Constitution LAW 0.9762 Tyler’s CARDINAL 0.5329 1967 DATE 0.8926 Richard Nixon PERSON 0.99515 first ORDINAL 0.9588 Gerald Ford PERSON 0.996 Spiro Agnew’s PERSON 0.99165 1973 DATE 0.9438 Ford PERSON 0.8337 second ORDINAL 0.9119 Nelson Rockefeller PERSON 0.98615 1967 DATE 0.589 Authorize NLU for OCR You need a set of credentials to access the licensed OCR features. You can grab one here Authorize anywhere via providing via JSON file If you provide a JSON file with credentials, nlu will check whether there are only OCR or also Healthcare secrets. If both are contained in the JSON file, nlu will give you access to healthcare and OCR features, if only one of them is present you will be accordingly only authorized for one set of the features. You can specify the location of your secrets.json like this : path = &#39;/path/to/secrets.json&#39; nlu.auth(path).load(&#39;licensed_model&#39;).predict(data) Authorize via providing String parameters You can manually enter your secrets and authorize nlu for OCR and Healthcare features import nlu AWS_ACCESS_KEY_ID = &#39;YOUR_SECRETS&#39; AWS_SECRET_ACCESS_KEY = &#39;cgsHeZR+YOUR_SECRETS&#39; OCR_SECRET = &#39;YOUR_SECRETS&#39; JSL_SECRET = &#39;YOUR_SECRETS&#39; OCR_LICENSE = &quot;YOUR_SECRETS&quot; SPARK_NLP_LICENSE = &#39;YOUR_SECRETS&#39; # this will automatically install the OCR library and NLP Healthcare library when credentials are provided nlu.auth(SPARK_NLP_LICENSE,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,JSL_SECRET, OCR_LICENSE, OCR_SECRET)",
    "url": "/docs/en/jsl/nlu_for_ocr",
    "relUrl": "/docs/en/jsl/nlu_for_ocr"
  },
  "1297": {
    "id": "1297",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/normalizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/normalizer.html"
  },
  "1298": {
    "id": "1298",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/spell_check/norvig_sweeting.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/spell_check/norvig_sweeting.html"
  },
  "1299": {
    "id": "1299",
    "title": "1-liner Tutorial Notebooks",
    "content": "The following tables give an overview on the different tutorials with the 1-liners. The tables are grouped by category. Embeddings Tutorials Overview Tutorial Description 1-liners used Open In Colab Dataset and Paper References Albert Word Embeddings albert, sentiment pos albert emotion Albert-Paper, Albert on Github, Albert on TensorFlow, T-SNE, T-SNE-Albert, Albert_Embedding Bert Word Embeddings bert, pos sentiment emotion bert Bert-Paper, Bert Github, T-SNE, T-SNE-Bert, Bert_Embedding BIOBERT Word Embeddings biobert , sentiment pos biobert emotion BioBert-Paper, Bert Github , BERT: Deep Bidirectional Transformers, Bert Github, T-SNE, T-SNE-Biobert, Biobert_Embedding COVIDBERT Word Embeddings covidbert, sentiment covidbert pos CovidBert-Paper, Bert Github, T-SNE, T-SNE-CovidBert, Covidbert_Embedding ELECTRA Word Embeddings electra, sentiment pos en.embed.electra emotion Electra-Paper, T-SNE, T-SNE-Electra, Electra_Embedding ELMO Word Embeddings elmo, sentiment pos elmo emotion ELMO-Paper, Elmo-TensorFlow, T-SNE, T-SNE-Elmo, Elmo-Embedding GLOVE Word Embeddings glove, sentiment pos glove emotion Glove-Paper, T-SNE, T-SNE-Glove , Glove_Embedding XLNET Word Embeddings xlnet, sentiment pos xlnet emotion XLNet-Paper, Bert Github, T-SNE, T-SNE-XLNet, Xlnet_Embedding Multiple Word-Embeddings and Part of Speech in 1 Line of code bert electra elmo glove xlnet albert pos Bert-Paper, Albert-Paper, ELMO-Paper, Electra-Paper, XLNet-Paper, Glove-Paper Text Preprocessing and Cleaning Tutorial Description 1-liners used Open In Colab Dataset and Paper References Normalzing norm - Detect sentences sentence_detector.deep, sentence_detector.pragmatic, xx.sentence_detector Sentence Detector Spellchecking n.a. n.a. - Stemming en.stem, de.stem - Stopwords removal stopwords Stopwords Tokenization tokenize - Normalization of Documents norm_document - Sequence to Sequence Tutorial Description 1-liners used Open In Colab Dataset and Paper References Open and Closed book question answering with Google’s T5 en.t5 , answer_question T5-Paper, T5-Model Overview of every task available with T5 en.t5.base T5-Paper, T5-Model Translate between more than 200 Languages in 1 line of code with Marian Models tr.translate_to.fr, en.translate_to.fr ,fr.translate_to.he , en.translate_to.de Marian-Papers, Translation-Pipeline (En to Fr), Translation-Pipeline (En to Ger) Text Generation with Google’s T5 ten.text_generator.biomedical_biogpt_base, en.text_generator.generic_flan_base ,en.text_generator.generic_jsl_base , en.text_generator.generic_flan_t5_large , en.text_generator.biogpt_chat_jsl , en.text_generator.biogpt_chat_jsl_conversational , en.text_generator.biogpt_chat_jsl_conditions T5-Paper, T5-Model Bart Transformer en.seq2seq.distilbart_xsum_12_6, en.seq2seq.bart_large_cnn ,en.seq2seq.distilbart_cnn_6_6 , en.seq2seq.distilbart_cnn_12_6 , en.seq2seq.distilbart_xsum_6_6 Bart-Paper Sentence Embeddings Tutorial Description 1-liners used Open In Colab Dataset and Paper References BERT Sentence Embeddings embed_sentence.bert, pos sentiment embed_sentence.bert Bert-Paper, Bert Github, Bert-Sentence_Embedding ELECTRA Sentence Embeddings embed_sentence.electra, pos sentiment embed_sentence.electra Electra Paper, Sentence-Electra-Embedding USE Sentence Embeddings use, pos sentiment use emotion Universal Sentence Encoder, USE-TensorFlow, Sentence-USE-Embedding Sentence similarity using BERT embeddings embed_sentence.bert, use en.embed_sentence.electra embed_sentence.bert Bert-Paper, Bert Github, Bert-Sentence_Embedding Part of Speech Tutorial Description 1-liners used Open In Colab Dataset and Paper References Part of Speech tagging pos Part of Speech Named Entity Recognition (NER) Tutorial Description 1-liners used Open In Colab Dataset and Paper References NER Aspect Airline ATIS en.ner.aspect.airline NER Airline Model, Atis intent Dataset NLU-NER_CONLL_2003_5class_example ner NER-Piple Named-entity recognition with Deep Learning ONTO NOTES ner.onto NER_Onto Aspect based NER-Sentiment-Restaurants en.ner.aspect_sentiment - Multilingual Tasks Tutorial Description 1-liners used Open In Colab Dataset and Paper References Detect Named Entities (NER), Part of Speech Tags (POS) and Tokenize in Chinese zh.segment_words, zh.pos, zh.ner, zh.translate_to.en Translation-Pipeline (Zh to En) Detect Named Entities (NER), Part of Speech Tags (POS) and Tokenize in Japanese ja.segment_words, ja.pos, ja.ner, ja.translate_to.en Translation-Pipeline (Ja to En) Detect Named Entities (NER), Part of Speech Tags (POS) and Tokenize in Korean ko.segment_words, ko.pos, ko.ner.kmou.glove_840B_300d, ko.translate_to.en - Matchers Tutorial Description 1-liners used Open In Colab Dataset and Paper References Date Matching match.datetime - Dependency Parsing Tutorial Description 1-liners used Open In Colab Dataset and Paper References Typed Dependency Parsing dep Dependency Parsing Untyped Dependency Parsing dep.untyped - Classifiers Tutorial Description 1-liners used Open In Colab Dataset and Paper References E2E Classification e2e e2e-Model Language Classification lang - Cyberbullying Classification classify.cyberbullying Cyberbullying-Classifier Sentiment Classification for Twitter emotion Emotion detection Fake News Classification en.classify.fakenews Fakenews-Classifier Intent Classification en.classify.intent.airline Airline-Intention classifier, Atis-Dataset Question classification based on the TREC dataset en.classify.questions Question-Classifier Sarcasm Classification en.classify.sarcasm Sarcasm-Classifier Sentiment Classification for Twitter en.sentiment.twitter Sentiment_Twitter-Classifier Sentiment Classification for Movies en.sentiment.imdb Sentiment_imdb-Classifier Spam Classification en.classify.spam Spam-Classifier Toxic text classification en.classify.toxic Toxic-Classifier Unsupervised keyword extraction using the YAKE algorithm yake - Notebook for Classification of Banking Queries en.classify.distilbert_sequence.banking77 DistilBERT Sequence Classification - Banking77 Notebook for Classification of Intent in Texts en.ner.snips Identify intent in general text - SNIPS dataset Notebook for classification of Similar Questions en.classify.questionpair Question Pair Classifier Notebook for Classification of Questions vs Statements en.classify.question_vs_statement Bert for Sequence Classification (Question vs Statement) Notebook for Classification of News into 4 classes en.classify.distilbert_sequence.ag_news DistilBERT Sequence Classification Base - AG News (distilbert_base_sequence_classifier_ag_news) ConvNext Image Classification en.classify_image.convnext.tiny A ConvNet for the 2020s Chunkers Tutorial Description 1-liners used Open In Colab Dataset and Paper References Grammatical Chunk Matching match.chunks - Getting n-Grams ngram - Healthcare Tutorial Description 1-liners used Open In Colab Dataset and Paper References Assertion en.med_ner.clinical en.assert, en.med_ner.clinical.biobert en.assert.biobert, … Healthcare-NER, NER_Clinical-Classifier, Toxic-Classifier De-Identification Model overview med_ner.jsl.wip.clinical en.de_identify, med_ner.jsl.wip.clinical en.de_identify.clinical, … NER-Clinical Drug Normalization norm_drugs - Entity Resolution med_ner.jsl.wip.clinical en.resolve_chunk.cpt_clinical, med_ner.jsl.wip.clinical en.resolve.icd10cm, … NER-Clinical, Entity-Resolver clinical Medical Named Entity Recognition en.med_ner.ade.clinical, en.med_ner.ade.clinical_bert, en.med_ner.anatomy,en.med_ner.anatomy.biobert, … - Relation Extraction en.med_ner.jsl.wip.clinical.greedy en.relation, en.med_ner.jsl.wip.clinical.greedy en.relation.bodypart.problem, … - Visualization Tutorial Description 1-liners used Open In Colab Dataset and Paper References Visualization of NLP-Models with Spark-NLP and NLU ner, dep.typed, med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in, med_ner.jsl.wip.clinical resolve.icd10cm NER-Piple, Dependency Parsing, NER-Clinical, Entity-Resolver (Chunks) clinical Example Notebooks on Kaggle, Examination on real life Problems. Tutorial Description 1-liners used Open In Colab Dataset and Paper References NLU Covid-19 Emotion Showcase emotion Emotion detection NLU Covid-19 Sentiment Showcase sentiment Sentiment classification NLU Airline Emotion Demo emotion Emotion detection NLU Airline Sentiment Demo sentiment Sentiment classification Release Notebooks Tutorial Description 1-liners used Open In Colab Dataset and Paper References Bengali NER Hindi Embeddings for 30 Models bn.ner, bn.lemma, ja.lemma, am.lemma, bh.lemma, en.ner.onto.bert.small_l2_128,.. Bengali-NER, Bengali-Lemmatizer, Japanese-Lemmatizer, Amharic-Lemmatizer Entity Resolution med_ner.jsl.wip.clinical en.resolve.umls, med_ner.jsl.wip.clinical en.resolve.loinc, med_ner.jsl.wip.clinical en.resolve.loinc.biobert - Crash-Course Tutorial Description 1-liners used Open In Colab Dataset and Paper References NLU 20 Minutes Crashcourse - the fast Data Science route spell, sentiment, pos, ner, yake, en.t5, emotion, answer_question, en.t5.base … T5-Model, Part of Speech, NER-Piple, Emotion detection , Spellchecker, Sentiment classification Natural Language Processing (NLP) Tutorial Description 1-liners used Open In Colab Dataset and Paper References Chapter 0: Intro: 1-liners sentiment, pos, ner, bert, elmo, embed_sentence.bert Part of Speech, NER-Piple, Sentiment classification, Elmo-Embedding, Bert-Sentence_Embedding Chapter 1: NLU base-features with some classifiers on testdata emotion, yake, stem Emotion detection Chapter 2: Translation between 300+ langauges with Marian tr.translate_to.en, en.translate_to.fr, en.translate_to.he Translation-Pipeline (En to Fr), Translation (En to He) Chapter 3: Answer questions and summarize Texts with T5 answer_question, en.t5, en.t5.base T5-Model Chapter 4: Overview of T5-Tasks en.t5.base T5-Model NLU-Crashcourse Graph AI Tutorial Description 1-liners used Open In Colab Dataset and Paper References Graph NLU 20 Minutes Crashcourse - State of the Art Text Mining for Graphs spell, sentiment, pos, ner, yake, emotion, med_ner.jsl.wip.clinical, … Part of Speech, NER-Piple, Emotion detection, Spellchecker, Sentiment classification Healthcare-Training Tutorial Description 1-liners used Open In Colab Dataset and Paper References Healthcare med_ner.human_phenotype.gene_biobert, med_ner.ade_biobert, med_ner.anatomy, med_ner.bacterial_species,… - Multilingual-Training Tutorial Description 1-liners used Open In Colab Dataset and Paper References Part 0: Intro: 1-liners spell, sentiment, pos, ner, bert, elmo, embed_sentence.bert Bert-Paper, Bert Github, T-SNE, T-SNE-Bert , Part of Speech, NER-Piple, Spellchecker, Sentiment classification, Elmo-Embedding , Bert-Sentence_Embedding Part 1: Quick Start, base-features with some classifiers on Testdata yake, stem, ner, emotion NER-Piple, Emotion detection Part 2: Translate between 200+ Languages in 1 line of code with Marian-Models en.translate_to.de, en.translate_to.fr, en.translate_to.he Translation-Pipeline (En to Fr), Translation-Pipeline (En to Ger), Translation (En to He) Part 3: More Multilingual NLP-translations for Asian Languages with Marian en.translate_to.hi, en.translate_to.ru, en.translate_to.zh Translation (En to Hi), Translation (En to Ru), Translation (En to Zh) Part 4: Unsupervised Chinese Keyword Extraction, NER and Translation from chinese news zh.translate_to.en, zh.segment_words, yake, zh.lemma, zh.ner Translation-Pipeline (Zh to En), Zh-Lemmatizer Part 5: Multilingual sentiment classifier training for 100+ languages train.sentiment, xx.embed_sentence.labse train.sentiment n.a. Sentence_Embedding.Labse Part 6: Question-answering and Text-summarization with T5-Modell answer_question, en.t5, en.t5.base T5-Paper Part 7: Overview of all tasks available with T5 en.t5.base T5-Paper Part 8: Overview of some of the Multilingual modes with State Of the Art accuracy (1-liner) bn.lemma, ja.lemma, am.lemma, bh.lemma, zh.segment_words, … Bengali-Lemmatizer, Japanese-Lemmatizer , Amharic-Lemmatizer Multilinigual-Examples Tutorial Description 1-liners used Open In Colab Dataset and Paper References Overview of some Multilingual modes avaiable with State Of the Art accuracy (1-liner) bn.ner.cc_300d, ja.ner, zh.ner, th.ner.lst20.glove_840B_300D, ar.ner Bengali-NER NLU 20 Minutes Crashcourse - the fast Data Science route    ",
    "url": "/docs/en/jsl/notebooks",
    "relUrl": "/docs/en/jsl/notebooks"
  },
  "1300": {
    "id": "1300",
    "title": "Visual NLP (Spark OCR)",
    "content": "Spark OCR is another commercial extension of Spark NLP for optical character recognition from images, scanned PDF documents, Microsoft DOCX and DICOM files. If you want to try it out on your own documents click on the below button: Try Free Spark OCR is built on top of Apache Spark and offers the following capabilities: Image pre-processing algorithms to improve text recognition results: Adaptive thresholding &amp; denoising Skew detection &amp; correction Adaptive scaling Layout Analysis &amp; region detection Image cropping Removing background objects Text recognition, by combining NLP and OCR pipelines: Extracting text from images (optical character recognition) Support English, German, French, Spanish, Russian, Vietnamese and Arabic languages Extracting data from tables Recognizing and highlighting named entities in PDF documents Masking sensitive text in order to de-identify images Table detection and recognition from images Signature detection Visual document understanding Document classification Visual NER Output generation in different formats: PDF, images, or DICOM files with annotated or masked entities Digital text for downstream processing in Spark NLP or other libraries Structured data formats (JSON and CSV), as files or Spark data frames Scale out: distribute the OCR jobs across multiple nodes in a Spark cluster. Frictionless unification of OCR, NLP, ML &amp; DL pipelines. Spark OCR Workshop If you prefer learning by example, click the button below to checkout the workshop repository full of fresh examples. Spark OCR Workshop Below, you can follow a more theoretical and thorough quick start guide. Quickstart Examples Images The following code example creates an OCR Pipeline for processing image(s). The image file(s) can contain complex layout like columns, tables, images inside. PythonScala import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers._ val imagePath = &quot;path to image files&quot; // Read image files as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) // Transform binary content to image val binaryToImage = new BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) // OCR val ocr = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) // Define Pipeline val pipeline = new Pipeline() pipeline.setStages(Array( binaryToImage, ocr )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = modelPipeline.transform(df) data.show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image files&quot; # Read image files as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) # Transform binary content to image binaryToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # OCR ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) # Define Pipeline pipeline = PipelineModel(stages=[ binaryToImage, ocr ]) data = pipeline.transform(df) data.show() Scanned PDF files Next sample provides an example of OCR Pipeline for processing PDF files containing image data. In this case, the PdfToImage transformer is used to convert PDF file to a set of images. PythonScala import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers._ val imagePath = &quot;path to pdf files&quot; // Read pdf files as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) // Transform PDF file to the image val pdfToImage = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) // OCR val ocr = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( pdfToImage, ocr )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = modelPipeline.transform(df) data.show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to pdf files&quot; # Read pdf files as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) # Transform PDF file to the image pdfToImage = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # OCR ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) # Define pipeline pipeline = PipelineModel(stages=[ pdfToImage, ocr ]) data = pipeline.transform(df) data.show() PDF files (scanned or text) In the following code example we will create OCR Pipeline for processing PDF files that contain text or image data. For each PDF file, this pipeline will: extract the text from document and save it to the text column if text contains less than 10 characters (so the document isn’t PDF with text layout) it will process the PDF file as a scanned document: convert PDF file to an image detect and split image to regions run OCR and save output to the text column PythonScala import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers._ val imagePath = &quot;path to PDF files&quot; // Read PDF files as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) // Extract text from PDF text layout val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) // In case of `text` column contains less then 10 characters, // pipeline run PdfToImage as fallback method val pdfToImage = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setFallBackCol(&quot;text&quot;) .setMinSizeBeforeFallback(10) // OCR val ocr = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( pdfToText, pdfToImage, ocr )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = modelPipeline.transform(df) data.show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to PDF files&quot; # Read PDF files as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) # Extract text from PDF text layout pdfToText = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) # In case of `text` column contains less then 10 characters, # pipeline run PdfToImage as fallback method pdfToImage = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setFallBackCol(&quot;text&quot;) .setMinSizeBeforeFallback(10) # OCR ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) # Define pipeline pipeline = PipelineModel(stages=[ pdfToText, pdfToImage, ocr, ]) data = pipeline.transform(df) data.show() Images (streaming mode) Next code segments provide an example of streaming OCR pipeline. It processes images and stores results to memory table. PythonScala val imagePath = &quot;path folder with images&quot; val batchDataFrame = spark.read.format(&quot;binaryFile&quot;).load(imagePath).limit(1) val pipeline = new Pipeline() pipeline.setStages(Array( binaryToImage, binarizer, ocr )) val modelPipeline = pipeline.fit(batchDataFrame) // Read files in streaming mode val dataFrame = spark.readStream .format(&quot;binaryFile&quot;) .schema(batchDataFrame.schema) .load(imagePath) // Call pipeline and store results to &#39;results&#39; memory table val query = modelPipeline.transform(dataFrame) .select(&quot;text&quot;, &quot;exception&quot;) .writeStream .format(&quot;memory&quot;) .queryName(&quot;results&quot;) .start() imagePath = &quot;path folder with images&quot; batchDataFrame = spark.read.format(&quot;binaryFile&quot;).load(imagePath).limit(1) pipeline = Pipeline() pipeline.setStages(Array( binaryToImage, binarizer, ocr )) modelPipeline = pipeline.fit(batchDataFrame) # Read files in streaming mode dataFrame = spark.readStream .format(&quot;binaryFile&quot;) .schema(batchDataFrame.schema) .load(imagePath) # Call pipeline and store results to &#39;results&#39; memory table query = modelPipeline.transform(dataFrame) .select(&quot;text&quot;, &quot;exception&quot;) .writeStream() .format(&quot;memory&quot;) .queryName(&quot;results&quot;) .start() For getting results from memory table following code could be used: PythonScala spark.table(&quot;results&quot;).select(&quot;path&quot;, &quot;text&quot;).show() spark.table(&quot;results&quot;).select(&quot;path&quot;, &quot;text&quot;).show() More details about Spark Structured Streaming could be found in spark documentation. Advanced Topics Error Handling Pipeline execution would not be interrupted in case of the runtime exceptions while processing some records. In this case OCR transformers would fill exception column that contains transformer name and exception. NOTE: Storing runtime errors to the exception field allows to process batch of files. Output Here is an output with exception when try to process js file using OCR pipeline: PythonScala result.select(&quot;path&quot;, &quot;text&quot;, &quot;exception&quot;).show(2, false) result.select(&quot;path&quot;, &quot;text&quot;, &quot;exception&quot;).show(2, False) +-+-+--+ |path |text |exception | +-+-+--+ |file:jquery-1.12.3.js | |BinaryToImage_c0311dc62161: Can&#39;t open file as image.| |file:image.png |I prefer the morning flight through Denver |null | +-+-+--+ Performance In case of big count of text PDF’s in dataset need have manual partitioning for avoid skew in partitions and effective utilize resources. For example the randomization could be used.",
    "url": "/docs/en/ocr",
    "relUrl": "/docs/en/ocr"
  },
  "1301": {
    "id": "1301",
    "title": "Installation",
    "content": "Spark OCR is built on top of Apache Spark. Currently, it supports 3.0., 2.4. and 2.3.* versions of Spark. It is recommended to have basic knowledge of the framework and a working environment before using Spark OCR. Refer to Spark documentation to get started with Spark. Spark OCR requires: Scala 2.11 or 2.12 related to the Spark version Python 3.7 + (in case using PySpark) Before you start, make sure that you have: Spark OCR jar file (or secret for download it) Spark OCR python wheel file License key If you don’t have a valid subscription yet and you want to test out the Spark OCR library press the button below: Try Free Spark OCR from Scala You can start a spark REPL with Scala by running in your terminal a spark-shell including the com.johnsnowlabs.nlp:spark-ocr_2.11:1.0.0 package: spark-shell --jars #### The #### is a secret url only available for license users. If you have purchased a license but did not receive it please contact us at info@johnsnowlabs.com. Start Spark OCR Session The following code will initialize the spark session in case you have run the jupyter notebook directly. If you have started the notebook using pyspark this cell is just ignored. Initializing the spark session takes some seconds (usually less than 1 minute) as the jar from the server needs to be loaded. The #### in .config(“spark.jars”, “####”) is a secret code, if you have not received it please contact us at info@johnsnowlabs.com. import org.apache.spark.sql.SparkSession val spark = SparkSession .builder() .appName(&quot;Spark OCR&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;, &quot;4G&quot;) .config(&quot;spark.driver.maxResultSize&quot;, &quot;2G&quot;) .config(&quot;spark.jars&quot;, &quot;####&quot;) .getOrCreate() Spark OCR from Python Install Python package Install python package using pip: pip install spark-ocr==1.8.0.spark24 --extra-index-url #### --ignore-installed The #### is a secret url only available for license users. If you have purchased a license but did not receive it please contact us at info@johnsnowlabs.com. Start Spark OCR Session Manually from pyspark.sql import SparkSession spark = SparkSession .builder .appName(&quot;Spark OCR&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;, &quot;4G&quot;) .config(&quot;spark.driver.maxResultSize&quot;, &quot;2G&quot;) .config(&quot;spark.jars&quot;, &quot;https://pypi.johnsnowlabs.com/####&quot;) .getOrCreate() Using Start function Another way to initialize SparkSession with Spark OCR to use start function in Python. Start function has following params: Param name Type Default Description secret string None Secret for download Spark OCR jar file jar_path string None Path to jar file in case you need to run spark session offline extra_conf SparkConf None Extra spark configuration master_url string local[*] Spark master url nlp_version string None Spark NLP version for add it Jar to session nlp_internal boolean/string None Run Spark session with Spark NLP Internal if set to ‘True’ or specify version nlp_secret string None Secret for get Spark NLP Internal jar keys_file string keys.json Name of the json file with license, secret and aws keys For start Spark session with Spark NLP please specify version of it in nlp_version param. Example: from sparkocr import start spark = start(secret=secret, nlp_version=&quot;2.4.4&quot;) Databricks The installation process to Databricks includes following steps: Installing Spark OCR library to Databricks and attaching it to the cluster Same step for Spark OCR python wheel file Adding license key Adding cluster init script for install dependencies Please look databricks python helpers for simplify install init script. Example notebooks: Spark OCR Databricks python notebooks Spark OCR Databricks Scala notebooks",
    "url": "/docs/en/ocr_install",
    "relUrl": "/docs/en/ocr_install"
  },
  "1302": {
    "id": "1302",
    "title": "Object detection",
    "content": "ImageHandwrittenDetector ImageHandwrittenDetector is a DL model for detect handwritten text on the image. It’s based on Cascade Region-based CNN network. Detector support following labels: ‘signature’ ‘date’ ‘name’ ‘title’ ‘address’ ‘others’ Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scoreThreshold float 0.5 Score threshold for output regions. outputLabels Array[String]   White list for output labels. labels Array[String]   List of labels Output Columns Param name Type Default Column Data Description outputCol string table_regions array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect signature signature_detector = ImageHandwrittenDetector .pretrained(&quot;image_signature_detector_gsa0628&quot;, &quot;en&quot;, &quot;public/ocr/models&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;signature_regions&quot;) draw_regions = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;signature_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, signature_detector, draw_regions ]) data = pipeline.transform(df) display_images(data, &quot;image_with_regions&quot;) import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect signature val signature_detector = ImageHandwrittenDetector .pretrained(&quot;image_signature_detector_gsa0628&quot;, &quot;en&quot;, &quot;public/ocr/models&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;signature_regions&quot;) val draw_regions = new ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;signature_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, signature_detector, draw_regions ]) val data = pipeline.transform(df) data.storeImage(&quot;image_with_regions&quot;) Output: ImageTextDetector ImageTextDetector is a DL model for detecting text on the image. It’s based on CRAFT network architecture. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scoreThreshold float 0.9 Score threshold for output regions. Regions with an area below the threshold won’t be returned. sizeThreshold int 5 Threshold for the area of the detected regions. textThreshold float 0.4f Threshold for the score of a region potentially containing text. The region score represents the probability that a given pixel is the center of the character. Higher values for this threshold will result in that only regions for which the confidence of containing text is high will be returned. linkThreshold float 0.4f Threshold for the the link(affinity) score. The link score represents the space allowed between adjacent characters to be considered as a single word. width integer 0 Scale width to this value, if 0 use original width height integer 0 Scale height to this value, if 0 use original height Output Columns Param name Type Default Column Data Description outputCol string table_regions array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect text text_detector = ImageTextDetector .pretrained(&quot;text_detection_v1&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text_regions&quot;) .setSizeThreshold(10) .setScoreThreshold(0.9) .setLinkThreshold(0.4) .setTextThreshold(0.2) .setWidth(1512) .setHeight(2016) draw_regions = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;text_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, text_detector, draw_regions ]) data = pipeline.transform(df) display_images(data, &quot;image_with_regions&quot;) import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect text val text_detector = ImageTextDetector .pretrained(&quot;text_detection_v1&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text_regions&quot;) val draw_regions = new ImageTextDetector() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;text_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) .setSizeThreshold(10) .setScoreThreshold(0.9) .setLinkThreshold(0.4) .setTextThreshold(0.2) .setWidth(1512) .setHeight(2016) pipeline = PipelineModel(stages=[ binary_to_image, text_detector, draw_regions ]) val data = pipeline.transform(df) data.storeImage(&quot;image_with_regions&quot;) Output: ImageTextDetectorV2 ImageTextDetectorV2 is a DL model for detecting text on images. It is based on the CRAFT network architecture with refiner net. Refiner net runs as postprocessing, and is able to merge single words regions into lines. Currently, it’s available only on Python side. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scoreThreshold float 0.7 Score threshold for output regions. sizeThreshold int 10 Threshold for height of the detected regions. Regions with a height below the threshold won’t be returned. textThreshold float 0.4f Threshold for the score of a region potentially containing text. The region score represents the probability that a given pixel is the center of the character. Higher values for this threshold will result in that only regions for which the confidence of containing text is high will be returned. linkThreshold float 0.4f Threshold for the the link(affinity) score. The link score represents the space allowed between adjacent characters to be considered as a single word. width integer 1280 Width of the desired input image. Image will be resized to this width. withRefiner boolean false Enable to run refiner net as postprocessing step. Output Columns Param name Type Default Column Data Description outputCol string table_regions array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect text text_detector = ImageTextDetectorV2 .pretrained(&quot;image_text_detector_v2&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text_regions&quot;) .setScoreThreshold(0.5) .setTextThreshold(0.2) .setSizeThreshold(10) .setWithRefiner(True) draw_regions = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;text_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, text_detector, draw_regions ]) data = pipeline.transform(df) display_images(data, &quot;image_with_regions&quot;) not implemented",
    "url": "/docs/en/ocr_object_detection",
    "relUrl": "/docs/en/ocr_object_detection"
  },
  "1303": {
    "id": "1303",
    "title": "Spark OCR 2.3.x (Licensed)",
    "content": "Spark NLP comes with an OCR module that can read both PDF files and scanned images (requires Tesseract 4.x+). Installation Installing Tesseract As mentioned above, if you are dealing with scanned images instead of test-selectable PDF files you need to install tesseract 4.x+ on all the nodes in your cluster. Here how you can install it on Ubuntu/Debian: apt-get install tesseract-ocr In Databricks this command may result in installing tesseract 3.x instead of version 4.x. You can simply run this init script to install tesseract 4.x in your Databricks cluster: #!/bin/bash sudo apt-get install -y g++ # or clang++ (presumably) sudo apt-get install -y autoconf automake libtool sudo apt-get install -y pkg-config sudo apt-get install -y libpng-dev sudo apt-get install -y libjpeg8-dev sudo apt-get install -y libtiff5-dev sudo apt-get install -y zlib1g-dev ​ wget https://www.leptonica.org/source/leptonica-1.74.4.tar.gz tar xvf leptonica-1.74.4.tar.gz cd leptonica-1.74.4 ./configure make sudo make install ​ git clone --single-branch --branch 4.1 https://github.com/tesseract-ocr/tesseract.git cd tesseract ./autogen.sh ./configure make sudo make install sudo ldconfig ​ tesseract -v Quick start Let’s read a PDF file: import com.johnsnowlabs.nlp._ val ocrHelper = new OcrHelper() //If you do this locally you can use file:/// or hdfs:/// if the files are hosted in Hadoop val dataset = ocrHelper.createDataset(spark, &quot;/tmp/sample_article.pdf&quot;) If you are trying to extract text from scanned images in the format of PDF, please keep in mind to use these configs: ocrHelper.setPreferredMethod(&quot;image&quot;) ocrHelper.setFallbackMethod(false) ocrHelper.setMinSizeBeforeFallback(0) Configuration setPreferredMethod(text/image = text) either text or image will work. Defaults to text. Text mode works better and faster for digital or text scanned PDFs setFallbackMethod(boolean) on true, when text or image fail, it will fallback to the alternate method setMinSizeBeforeFallback(int = 1) number of characters to have at a minimum, before falling back. setPageSegMode(int = 3) image mode page segmentation mode setEngineMode(int = 1) image mode engine mode setPageIteratorLevel(int = 0) image mode page iteratior level setScalingFactor(float) Specifies the scaling factor to apply to images, in both axes, before OCR. It can scale up the image(factor &gt; 1.0) or scale it down(factor &lt; 1.0) setSplitPages(boolean = true) Whether to split pages into different rows and documents setSplitRegions(boolean = true) Whether to split by document regions. Works only in image mode. Enables split pages as well. setIncludeConfidence(boolean = false) setAutomaticSkewCorrection(use: boolean, half_angle: double = 5.0, resolution: double = 1.0) setAutomaticSizeCorrection(use: boolean, desired_size: int = 34) setEstimateNoise(string) image mode estimator noise level useErosion(use: boolean, kernel_size: int = 2, kernel_shape: Int = 0) image mode erosion Utilizing Spark NLP OCR Module Spark NLP OCR Module is not included within Spark NLP. It is not an annotator and not an extension to Spark ML. You can use OcrHelper to directly create spark dataframes from PDF. This will hold entire documents in single rows, meant to be later processed by a SentenceDetector. This way, you won’t be breaking the content in rows as if you were reading a standard document. Metadata columns are added automatically and will include page numbers, file name and other useful information per row. Python code from pyspark.sql import SparkSession from sparknlp.ocr import OcrHelper from sparknlp import DocumentAssembler data = OcrHelper().createDataset(spark = spark, input_path = &quot;/your/example.pdf&quot; ) documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;) annotations = documentAssembler.transform(data) annotations.columns [&#39;text&#39;, &#39;pagenum&#39;, &#39;method&#39;, &#39;noiselevel&#39;, &#39;confidence&#39;, &#39;positions&#39;, &#39;filename&#39;, &#39;document&#39;] Scala code import com.johnsnowlabs.nlp.util.io.OcrHelper import com.johnsnowlabs.nlp.DocumentAssembler val myOcrHelper = new OcrHelper val data = myOcrHelper.createDataset(spark, &quot;/your/example.pdf&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;) val annotations = documentAssembler.transform(data) annotations.columns Array[String] = Array(text, pagenum, method, noiselevel, confidence, positions, filename, document) … where the text column of the annotations spark dataframe includes the text content of the PDF, pagenum the page number, etc… Creating an Array of Strings from PDF (For LightPipeline) Another way, would be to simply create an array of strings. This is useful for example if you are parsing a small amount of pdf files and would like to use LightPipelines instead. See an example below. Scala code import com.johnsnowlabs.nlp.util.io.OcrHelper import com.johnsnowlabs.nlp.{DocumentAssembler,LightPipeline} import com.johnsnowlabs.nlp.annotator.SentenceDetector import org.apache.spark.ml.Pipeline val myOcrHelper = new OcrHelper val raw = myOcrHelper.createMap(&quot;/pdfs/&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val lightPipeline = new LightPipeline(new Pipeline().setStages(Array(documentAssembler, sentenceDetector)).fit(Seq.empty[String].toDF(&quot;text&quot;))) val annotations = ligthPipeline.annotate(raw.values.toArray) Now to get the whole first PDF content in your /pdfs/ folder you can use: annotations(0)(&quot;document&quot;)(0) and to get the third sentence found in that first pdf: annotations(0)(&quot;sentence&quot;)(2) To get from the fifth pdf the second sentence: annotations(4)(&quot;sentence&quot;)(1) Similarly, the whole content of the fifth pdf can be retrieved by: annotations(4)(&quot;document&quot;)(0)",
    "url": "/docs/en/ocr_old",
    "relUrl": "/docs/en/ocr_old"
  },
  "1304": {
    "id": "1304",
    "title": "Pipeline components",
    "content": "PDF processing Next section describes the transformers that deal with PDF files with the purpose of extracting text and image data from PDF files. PdfToText PDFToText extracts text from selectable PDF (with text layout). Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PDF document originCol string path path to the original file Parameters Param name Type Default Description splitPage bool true Whether it needed to split document to pages textStripper   TextStripperType.PDF_TEXT_STRIPPER Extract unstructured text sort bool false Sort text during extraction with TextStripperType.PDF_LAYOUT_STRIPPER partitionNum int 0 Force repartition dataframe if set to value more than 0. onlyPageNum bool false Extract only page numbers. extractCoordinates bool false Extract coordinates and store to the positions column storeSplittedPdf bool false Store one page pdf’s for process it using PdfToImage. Output Columns Param name Type Default Column Data Description outputCol string text extracted text pageNumCol string pagenum page number or 0 when splitPage = false NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * pdfPath = &quot;path to pdf with text layout&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) transformer = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;pagenum&quot;) .setSplitPage(True) data = transformer.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() import com.johnsnowlabs.ocr.transformers.PdfToText val pdfPath = &quot;path to pdf with text layout&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val transformer = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;pagenum&quot;) .setSplitPage(true) val data = transformer.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() Output: +-+-+ |pagenum|text | +-+-+ |0 |This is a page. | |1 |This is another page. | |2 |Yet another page. | +-+-+ PdfToImage PdfToImage renders PDF to an image. To be used with scanned PDF documents. Output dataframe contains total_pages field with total number of pages. For process pdf with a big number of pages prefer to split pdf by setting splitNumBatch param. Number of partitions should be equal to number of cores/executors. Input Columns Param name Type Default Column Data Description inputCol string content binary representation of the PDF document originCol string path path to the original file fallBackCol string text extracted text from previous method for detect if need to run transformer as fallBack Parameters Param name Type Default Description splitPage bool true whether it needed to split document to pages minSizeBeforeFallback int 10 minimal count of characters to extract to decide, that the document is the PDF with text layout imageType ImageType ImageType.TYPE_BYTE_GRAY type of the image resolution int 300 Output image resolution in dpi keepInput boolean false Keep input column in dataframe. By default it is dropping. partitionNum int 0 Number of Spark RDD partitions (0 value - without repartition) binarization boolean false Enable/Disable binarization image after extract image. binarizationParams Array[String] null Array of Binarization params in key=value format. splitNumBatch int 0 Number of partitions or size of partitions, related to the splitting strategy. partitionNumAfterSplit int 0 Number of Spark RDD partitions after splitting pdf document (0 value - without repartition). splittingStategy SplittingStrategy SplittingStrategy.FIXED_SIZE_OF_PARTITION Splitting strategy. Output Columns Param name Type Default Column Data Description outputCol string image extracted image struct (Image schema) pageNumCol string pagenum page number or 0 when splitPage = false Example: PythonScala from sparkocr.transformers import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdfToImage = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;pagenum&quot;) .setSplitPage(True) data = pdfToImage.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() import com.johnsnowlabs.ocr.transformers.PdfToImage val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToImage = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;pagenum&quot;) .setSplitPage(true) val data = pdfToImage.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() ImageToPdf ImageToPdf transform image to Pdf document. If dataframe contains few records for same origin path, it groups image by origin column and create multipage PDF document. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string content binary representation of the PDF document Example: Read images and store them as single page PDF documents. PythonScala from sparkocr.transformers import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) # Define transformer for convert to Image struct binaryToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for store to PDF imageToPdf = ImageToPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;content&quot;) # Call transformers image_df = binaryToImage.transform(df) pdf_df = pdfToImage.transform(image_df) pdf_df.select(&quot;content&quot;).show() import com.johnsnowlabs.ocr.transformers._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(imagePath) // Define transformer for convert to Image struct val binaryToImage = new BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) // Define transformer for store to PDF val imageToPdf = new ImageToPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;content&quot;) // Call transformers val image_df = binaryToImage.transform(df) val pdf_df = pdfToImage.transform(image_df) pdf_df.select(&quot;content&quot;).show() TextToPdf TextToPdf renders ocr results to PDF document as text layout. Each symbol will render to the same position with the same font size as in original image or PDF. If dataframe contains few records for same origin path, it groups image by origin column and create multipage PDF document. Input Columns Param name Type Default Column Data Description inputCol string positions column with positions struct inputImage string image image struct (Image schema) inputText string text column name with recognized text originCol string path path to the original file inputContent string content column name with binary representation of original PDF file Output Columns Param name Type Default Column Data Description outputCol string pdf binary representation of the PDF document Example: Read PDF document, run OCR and render results to PDF document. PythonScala from sparkocr.transformers import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_image = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image_raw&quot;) binarizer = ImageBinarizer() .setInputCol(&quot;image_raw&quot;) .setOutputCol(&quot;image&quot;) .setThreshold(130) ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setIgnoreResolution(False) .setPageSegMode(PageSegmentationMode.SPARSE_TEXT) .setConfidenceThreshold(60) textToPdf = TextToPdf() .setInputCol(&quot;positions&quot;) .setInputImage(&quot;image&quot;) .setOutputCol(&quot;pdf&quot;) pipeline = PipelineModel(stages=[ pdf_to_image, binarizer, ocr, textToPdf ]) result = pipeline.transform(df).collect() # Store to file for debug with open(&quot;test.pdf&quot;, &quot;wb&quot;) as file: file.write(result[0].pdf) import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers._ val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToImage = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image_raw&quot;) .setResolution(400) val binarizer = new ImageBinarizer() .setInputCol(&quot;image_raw&quot;) .setOutputCol(&quot;image&quot;) .setThreshold(130) val ocr = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setIgnoreResolution(false) .setPageSegMode(PageSegmentationMode.SPARSE_TEXT) .setConfidenceThreshold(60) val textToPdf = new TextToPdf() .setInputCol(&quot;positions&quot;) .setInputImage(&quot;image&quot;) .setOutputCol(&quot;pdf&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( pdfToImage, binarizer, ocr, textToPdf )) val modelPipeline = pipeline.fit(df) val pdf = modelPipeline.transform(df) val pdfContent = pdf.select(&quot;pdf&quot;).collect().head.getAs[Array[Byte]](0) // store to file val tmpFile = Files.createTempFile(suffix=&quot;.pdf&quot;).toAbsolutePath.toString val fos = new FileOutputStream(tmpFile) fos.write(pdfContent) fos.close() println(tmpFile) PdfAssembler PdfAssembler group single page PDF documents by the filename and assemble muliplepage PDF document. Input Columns Param name Type Default Column Data Description inputCol string page_pdf binary representation of the PDF document originCol string path path to the original file pageNumCol string pagenum for compatibility with another transformers Output Columns Param name Type Default Column Data Description outputCol string pdf binary representation of the PDF document Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_image = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setKeepInput(True) # Run OCR and render results to PDF ocr = ImageToTextPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;pdf_page&quot;) # Assemble multipage PDF pdf_assembler = PdfAssembler() .setInputCol(&quot;pdf_page&quot;) .setOutputCol(&quot;pdf&quot;) pipeline = PipelineModel(stages=[ pdf_to_image, ocr, pdf_assembler ]) pdf = pipeline.transform(df) pdfContent = pdf.select(&quot;pdf&quot;).collect().head.getAs[Array[Byte]](0) # store pdf to file with open(&quot;test.pdf&quot;, &quot;wb&quot;) as file: file.write(pdfContent[0].pdf) import java.io.FileOutputStream import java.nio.file.Files import com.johnsnowlabs.ocr.transformers._ val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdf_to_image = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setKeepInput(True) // Run OCR and render results to PDF val ocr = new ImageToTextPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;pdf_page&quot;) // Assemble multipage PDF val pdf_assembler = new PdfAssembler() .setInputCol(&quot;pdf_page&quot;) .setOutputCol(&quot;pdf&quot;) // Create pipeline val pipeline = new Pipeline() .setStages(Array( pdf_to_image, ocr, pdf_assembler )) val pdf = pipeline.fit(df).transform(df) val pdfContent = pdf.select(&quot;pdf&quot;).collect().head.getAs[Array[Byte]](0) // store to pdf file val tmpFile = Files.createTempFile(&quot;with_regions_&quot;, s&quot;.pdf&quot;).toAbsolutePath.toString val fos = new FileOutputStream(tmpFile) fos.write(pdfContent) fos.close() println(tmpFile) PdfDrawRegions PdfDrawRegions transformer for drawing regions to Pdf document. Input Columns Param name Type Default Column Data Description inputCol string content binary representation of the PDF document originCol string path path to the original file inputRegionsCol string region input column which contain regions Parameters Param name Type Default Description lineWidth integer 1 line width for draw regions Output Columns Param name Type Default Column Data Description outputCol string pdf_regions binary representation of the PDF document Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparknlp.annotator import * from sparknlp.base import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;page&quot;) .setSplitPage(False) document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) entity_extractor = TextMatcher() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setEntities(&quot;./sparkocr/resources/test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) position_finder = PositionFinder() .setInputCols(&quot;entity&quot;) .setOutputCol(&quot;coordinates&quot;) .setPageMatrixCol(&quot;positions&quot;) .setMatchingWindow(10) .setPadding(2) draw = PdfDrawRegions() .setInputRegionsCol(&quot;coordinates&quot;) .setOutputCol(&quot;pdf_with_regions&quot;) .setInputCol(&quot;content&quot;) .setLineWidth(1) pipeline = Pipeline(stages=[ pdf_to_text, document_assembler, sentence_detector, tokenizer, entity_extractor, position_finder, draw ]) pdfWithRegions = pipeline.fit(df).transform(df) pdfContent = pdfWithRegions.select(&quot;pdf_regions&quot;).collect().head.getAs[Array[Byte]](0) # store to pdf to tmp file with open(&quot;test.pdf&quot;, &quot;wb&quot;) as file: file.write(pdfContent[0].pdf_regions) import java.io.FileOutputStream import java.nio.file.Files import com.johnsnowlabs.ocr.transformers._ import com.johnsnowlabs.nlp.{DocumentAssembler, SparkAccessor} import com.johnsnowlabs.nlp.annotators._ import com.johnsnowlabs.nlp.util.io.ReadAs val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val entityExtractor = new TextMatcher() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setEntities(&quot;test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) val positionFinder = new PositionFinder() .setInputCols(&quot;entity&quot;) .setOutputCol(&quot;coordinates&quot;) .setPageMatrixCol(&quot;positions&quot;) .setMatchingWindow(10) .setPadding(2) val pdfDrawRegions = new PdfDrawRegions() .setInputRegionsCol(&quot;coordinates&quot;) // Create pipeline val pipeline = new Pipeline() .setStages(Array( pdfToText, documentAssembler, sentenceDetector, tokenizer, entityExtractor, positionFinder, pdfDrawRegions )) val pdfWithRegions = pipeline.fit(df).transform(df) val pdfContent = pdfWithRegions.select(&quot;pdf_regions&quot;).collect().head.getAs[Array[Byte]](0) // store to pdf to tmp file val tmpFile = Files.createTempFile(&quot;with_regions_&quot;, s&quot;.pdf&quot;).toAbsolutePath.toString val fos = new FileOutputStream(tmpFile) fos.write(pdfContent) fos.close() println(tmpFile) Results: PdfToTextTable Extract tables from Pdf document page. Input is a column with binary representation of PDF document. As output generate column with tables and tables text chunks coordinates (rows/cols). Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PDF document originCol string path path to the original file Parameters Param name Type Default Description pageIndex integer -1 Page index to extract Tables. guess bool false A logical indicating whether to guess the locations of tables on each page. method string decide Identifying the prefered method of table extraction: basic, spreadsheet. Output Columns Param name Type Default Column Data Description outputCol TableContainer tables Extracted tables Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparknlp.annotator import * from sparknlp.base import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text_table = PdfToTextTable() pdf_to_text_table.setInputCol(&quot;content&quot;) pdf_to_text_table.setOutputCol(&quot;table&quot;) pdf_to_text_table.setPageIndex(1) pdf_to_text_table.setMethod(&quot;basic&quot;) table = pdf_to_text_table.transform(df) # Show first row table.select(table[&quot;table.chunks&quot;].getItem(1)[&quot;chunkText&quot;]).show(1, False) import java.io.FileOutputStream import java.nio.file.Files import com.johnsnowlabs.ocr.transformers._ import com.johnsnowlabs.nlp.{DocumentAssembler, SparkAccessor} import com.johnsnowlabs.nlp.annotators._ import com.johnsnowlabs.nlp.util.io.ReadAs val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToTextTable = new PdfToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;table&quot;) .pdf_to_text_table.setPageIndex(1) .pdf_to_text_table.setMethod(&quot;basic&quot;) table = pdfToTextTable.transform(df) // Show first row table.select(table[&quot;table.chunks&quot;].getItem(1)[&quot;chunkText&quot;]).show(1, False) Output: ++ |table.chunks AS chunks#760[1].chunkText | ++ |[Mazda RX4, 21.0, 6, , 160.0, 110, 3.90, 2.620, 16.46, 0, 1, 4, 4]| ++ DOCX processing Next section describes the transformers that deal with DOCX files with the purpose of extracting text and table data from it. DocToText DocToText extracts text from the DOCX document. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the DOCX document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string text extracted text pageNumCol string pagenum for compatibility with another transformers NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to docx with text layout&quot; # Read DOCX file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = DocToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) data = transformer.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() import com.johnsnowlabs.ocr.transformers.DocToText val docPath = &quot;path to docx with text layout&quot; // Read DOCX file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new DocToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) val data = transformer.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() DocToTextTable DocToTextTable extracts table data from the DOCX documents. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PDF document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol TableContainer tables Extracted tables NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to docx with text layout&quot; # Read DOCX file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = DocToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;tables&quot;) data = transformer.transform(df) data.select(&quot;tables&quot;).show() import com.johnsnowlabs.ocr.transformers.DocToTextTable val docPath = &quot;path to docx with text layout&quot; // Read DOCX file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new DocToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;tables&quot;) val data = transformer.transform(df) data.select(&quot;tables&quot;).show() DocToPdf DocToPdf convert DOCX document to PDF document. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the DOCX document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string text binary representation of the PDF document NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to docx with text layout&quot; # Read DOCX file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = DocToPdf() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;pdf&quot;) data = transformer.transform(df) data.select(&quot;pdf&quot;).show() import com.johnsnowlabs.ocr.transformers.DocToPdf val docPath = &quot;path to docx with text layout&quot; // Read DOCX file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new DocToPdf() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;pdf&quot;) val data = transformer.transform(df) data.select(&quot;pdf&quot;).show() PptToTextTable PptToTextTable extracts table data from the PPT and PPTX documents. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PPT document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol TableContainer tables Extracted tables NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to docx with text layout&quot; # Read PPT file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = PptToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;tables&quot;) data = transformer.transform(df) data.select(&quot;tables&quot;).show() import com.johnsnowlabs.ocr.transformers.PptToTextTable val docPath = &quot;path to docx with text layout&quot; // Read PPT file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new PptToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;tables&quot;) val data = transformer.transform(df) data.select(&quot;tables&quot;).show() PptToPdf PptToPdf convert PPT and PPTX documents to PDF document. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PPT document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string text binary representation of the PDF document NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to PPT with text layout&quot; # Read DOCX file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = PptToPdf() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;pdf&quot;) data = transformer.transform(df) data.select(&quot;pdf&quot;).show() import com.johnsnowlabs.ocr.transformers.PptToPdf val docPath = &quot;path to docx with text layout&quot; // Read PPT file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new PptToPdf() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;pdf&quot;) val data = transformer.transform(df) data.select(&quot;pdf&quot;).show() Dicom processing DicomToImage DicomToImage transforms dicom object (loaded as binary file) to image struct. Input Columns Param name Type Default Column Data Description inputCol string content binary dicom object originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string image extracted image struct (Image schema) pageNumCol integer pagenum page (image) number begin from 0 metadataCol string metadata Output column name for dicom metatdata ( json formatted ) Scala example: PythonScala from sparkocr.transformers import * dicomPath = &quot;path to dicom files&quot; # Read dicom file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(dicomPath) dicomToImage = DicomToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setMetadataCol(&quot;meta&quot;) data = dicomToImage.transform(df) data.select(&quot;image&quot;, &quot;pagenum&quot;, &quot;meta&quot;).show() import com.johnsnowlabs.ocr.transformers.DicomToImage val dicomPath = &quot;path to dicom files&quot; // Read dicom file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(dicomPath) val dicomToImage = new DicomToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setMetadataCol(&quot;meta&quot;) val data = dicomToImage.transform(df) data.select(&quot;image&quot;, &quot;pagenum&quot;, &quot;meta&quot;).show() ImageToDicom ImageToDicom transforms image to Dicom document. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) originCol string path path to the original file metadataCol string metadata dicom metatdata ( json formatted ) Output Columns Param name Type Default Column Data Description outputCol string dicom binary dicom object Scala example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image file&quot; # Read image file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(imagePath) binaryToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) image_df = binaryToImage.transform(df) imageToDicom = ImageToDicom() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;dicom&quot;) data = imageToDicom.transform(image_df) data.select(&quot;dicom&quot;).show() import com.johnsnowlabs.ocr.transformers.ImageToDicom val imagePath = &quot;path to image file&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToDicom = new ImageToDicom() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;dicom&quot;) val data = imageToDicom.transform(df) data.select(&quot;dicom&quot;).show() Image pre-processing Next section describes the transformers for image pre-processing: scaling, binarization, skew correction, etc. BinaryToImage BinaryToImage transforms image (loaded as binary file) to image struct. Input Columns Param name Type Default Column Data Description inputCol string content binary representation of the image originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string image extracted image struct (Image schema) Scala example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(imagePath) binaryToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) data = binaryToImage.transform(df) data.select(&quot;image&quot;).show() import com.johnsnowlabs.ocr.transformers.BinaryToImage val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(imagePath) val binaryToImage = new BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) val data = binaryToImage.transform(df) data.select(&quot;image&quot;).show() GPUImageTransformer GPUImageTransformer allows to run image pre-processing operations on GPU. It supports the following operations: Scaling Otsu thresholding Huang thresholding Erosion Dilation GPUImageTransformer allows to add few operations. To add operations you need to call one of the methods with params: Method name Params Description addScalingTransform factor Scale image by scaling factor. addOtsuTransform   The automatic thresholder utilizes the Otsu threshold method. addHuangTransform   The automatic thresholder utilizes the Huang threshold method. addDilateTransform width, height Computes the local maximum of a pixels rectangular neighborhood. The rectangles size is specified by its half-width and half-height. addErodeTransform width, height Computes the local minimum of a pixels rectangular neighborhood. The rectangles size is specified by its half-width and half-height Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description imageType ImageType ImageType.TYPE_BYTE_BINARY Type of the output image gpuName string ”” GPU device name. Output Columns Param name Type Default Column Data Description outputCol string transformed_image image struct (Image schema) Example: PythonScala from sparkocr.transformers import * from sparkocr.enums import ImageType from sparkocr.utils import display_images imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) transformer = GPUImageTransformer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;transformed_image&quot;) .addHuangTransform() .addScalingTransform(3) .addDilateTransform(2, 2) .setImageType(ImageType.TYPE_BYTE_BINARY) pipeline = PipelineModel(stages=[ binary_to_image, transformer ]) result = pipeline.transform(df) display_images(result, &quot;transformed_image&quot;) import com.johnsnowlabs.ocr.transformers.GPUImageTransformer import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new GPUImageTransformer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;transformed_image&quot;) .addHuangTransform() .addScalingTransform(3) .addDilateTransform(2, 2) .setImageType(ImageType.TYPE_BYTE_BINARY) val data = transformer.transform(df) data.storeImage(&quot;transformed_image&quot;) ImageBinarizer ImageBinarizer transforms image to binary color schema, based on threshold. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description threshold int 170   Output Columns Param name Type Default Column Data Description outputCol string binarized_image image struct (Image schema) Example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) binirizer = ImageBinarizer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;binary_image&quot;) .setThreshold(100) data = binirizer.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageBinarizer import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val binirizer = new ImageBinarizer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;binary_image&quot;) .setThreshold(100) val data = binirizer.transform(df) data.storeImage(&quot;binary_image&quot;) Original image: Binarized image with 100 threshold: ImageAdaptiveBinarizer Supported Methods: OTSU. Returns a single intensity threshold that separate pixels into two classes, foreground and background. Gaussian local thresholding. Thresholds the image using a locally adaptive threshold that is computed using a local square region centered on each pixel. The threshold is equal to the gaussian weighted sum of the surrounding pixels times the scale. Sauvola. Is a Local thresholding technique that are useful for images where the background is not uniform. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description width float 90 Width of square region. method TresholdingMethod TresholdingMethod.GAUSSIAN Method used to determine adaptive threshold. scale float 1.1f Scale factor used to adjust threshold. imageType ImageType ImageType.TYPE_BYTE_BINARY Type of the output image Output Columns Param name Type Default Column Data Description outputCol string binarized_image image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * from sparkocr.utils import display_image imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) adaptive_thresholding = ImageAdaptiveBinarizer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;binarized_image&quot;) .setWidth(100) .setScale(1.1) pipeline = PipelineModel(stages=[ binary_to_image, adaptive_thresholding ]) result = pipeline.transform(df) for r in result.select(&quot;image&quot;, &quot;corrected_image&quot;).collect(): display_image(r.image) display_image(r.corrected_image) import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val binirizer = new ImageAdaptiveBinarizer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;binary_image&quot;) .setWidth(100) .setScale(1.1) val data = binirizer.transform(df) data.storeImage(&quot;binary_image&quot;) ImageAdaptiveThresholding Compute a threshold mask image based on local pixel neighborhood and apply it to image. Also known as adaptive or dynamic thresholding. The threshold value is the weighted mean for the local neighborhood of a pixel subtracted by a constant. Supported methods: GAUSSIAN MEAN MEDIAN WOLF SINGH Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description blockSize int 170 Odd size of pixel neighborhood which is used to calculate the threshold value (e.g. 3, 5, 7, …, 21, …). method AdaptiveThresholdingMethod AdaptiveThresholdingMethod.GAUSSIAN Method used to determine adaptive threshold for local neighbourhood in weighted mean image. offset int   Constant subtracted from weighted mean of neighborhood to calculate the local threshold value. Default offset is 0. mode string   The mode parameter determines how the array borders are handled, where cval is the value when mode is equal to ‘constant’ cval int   Value to fill past edges of input if mode is ‘constant’. Output Columns Param name Type Default Column Data Description outputCol string binarized_image image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * from sparkocr.utils import display_image imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) adaptive_thresholding = ImageAdaptiveThresholding() .setInputCol(&quot;scaled_image&quot;) .setOutputCol(&quot;binarized_image&quot;) .setBlockSize(21) .setOffset(73) pipeline = PipelineModel(stages=[ binary_to_image, adaptive_thresholding ]) result = pipeline.transform(df) for r in result.select(&quot;image&quot;, &quot;corrected_image&quot;).collect(): display_image(r.image) display_image(r.corrected_image) // Implemented only for Python Original image: Binarized image: ImageScaler ImageScaler scales image by provided scale factor or needed output size. It supports keeping original ratio of image by padding the image in case fixed output size. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scaleFactor double 1.0 scale factor keepRatio boolean false Keep original ratio of image width int 0 Output width of image height int 0 Outpu height of imgae Output Columns Param name Type Default Column Data Description outputCol string scaled_image scaled image struct (Image schema) Example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) transformer = ImageScaler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;scaled_image&quot;) .setScaleFactor(0.5) data = transformer.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageScaler import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageScaler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;scaled_image&quot;) .setScaleFactor(0.5) val data = transformer.transform(df) data.storeImage(&quot;scaled_image&quot;) ImageAdaptiveScaler ImageAdaptiveScaler detects font size and scales image for have desired font size. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description desiredSize int 34 desired size of font in pixels Output Columns Param name Type Default Column Data Description outputCol string scaled_image scaled image struct (Image schema) Example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) transformer = ImageAdaptiveScaler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;scaled_image&quot;) .setDesiredSize(34) data = transformer.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageAdaptiveScaler import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageAdaptiveScaler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;scaled_image&quot;) .setDesiredSize(34) val data = transformer.transform(df) data.storeImage(&quot;scaled_image&quot;) ImageSkewCorrector ImageSkewCorrector detects skew of the image and rotates it. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description rotationAngle double 0.0 rotation angle automaticSkewCorrection boolean true enables/disables adaptive skew correction halfAngle double 5.0 half the angle(in degrees) that will be considered for correction resolution double 1.0 The step size(in degrees) that will be used for generating correction angle candidates Output Columns Param name Type Default Column Data Description outputCol string corrected_image corrected image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * from sparkocr.utils import display_images imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) skew_corrector = ImageSkewCorrector() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;corrected_image&quot;) .setAutomaticSkewCorrection(True) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, skew_corrector ]) data = pipeline.transform(df) display_images(data, &quot;corrected_image&quot;) import com.johnsnowlabs.ocr.transformers.ImageSkewCorrector import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageSkewCorrector() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;corrected_image&quot;) .setAutomaticSkewCorrection(true) val data = transformer.transform(df) data.storeImage(&quot;corrected_image&quot;) Original image: Corrected image: ImageNoiseScorer ImageNoiseScorer computes noise score for each region. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) inputRegionsCol string regions regions Parameters Param name Type Default Description method NoiseMethod string NoiseMethod.RATIO method of computation noise score Output Columns Param name Type Default Column Data Description outputCol string noisescores noise score for each region Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * from sparkocr.enums import NoiseMethod imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) # Define transformer for detect regions layoutAnalyzer = ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) # Define transformer for compute noise level for each region noisescorer = ImageNoiseScorer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;noiselevel&quot;) .setInputRegionsCol(&quot;regions&quot;) .setMethod(NoiseMethod.VARIANCE) # Define pipeline pipeline = Pipeline() pipeline.setStages(Array( layoutAnalyzer, noisescorer )) data = pipeline.transform(df) data.select(&quot;path&quot;, &quot;noiselevel&quot;).show() import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.{ImageNoiseScorer, ImageLayoutAnalyzer} import com.johnsnowlabs.ocr.NoiseMethod import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect regions val layoutAnalyzer = new ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) // Define transformer for compute noise level for each region val noisescorer = new ImageNoiseScorer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;noiselevel&quot;) .setInputRegionsCol(&quot;regions&quot;) .setMethod(NoiseMethod.VARIANCE) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( layoutAnalyzer, noisescorer )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = modelPipeline.transform(df) data.select(&quot;path&quot;, &quot;noiselevel&quot;).show() Output: ++--+ |path |noiselevel | ++--+ |file:./noisy.png |[32.01805641767766, 32.312916551193354, 29.99257352247787, 30.62470388308217]| ++--+ ImageRemoveObjects python only ImageRemoveObjects to remove background objects. It supports removing: objects less than elements of font with minSizeFont size objects less than minSizeObject holes less than minSizeHole objects more than maxSizeObject Input Columns Param name Type Default Column Data Description inputCol string None image struct (Image schema) Parameters Param name Type Default Description minSizeFont int 10 Min size font in pt. minSizeObject int None Min size of object which will keep on image [*]. connectivityObject int 0 The connectivity defining the neighborhood of a pixel. minSizeHole int None Min size of hole which will keep on image[ *]. connectivityHole int 0 The connectivity defining the neighborhood of a pixel. maxSizeObject int None Max size of object which will keep on image [*]. connectivityMaxObject int 0 The connectivity defining the neighborhood of a pixel. [*] : None value disables removing objects. Output Columns Param name Type Default Column Data Description outputCol string None scaled image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) remove_objects = ImageRemoveObjects() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;corrected_image&quot;) .setMinSizeObject(20) pipeline = PipelineModel(stages=[ binary_to_image, remove_objects ]) data = pipeline.transform(df) // Implemented only for Python ImageMorphologyOperation python only ImageMorphologyOperationis a transformer for applying morphological operations to image. It supports following operation: Erosion Dilation Opening Closing Input Columns Param name Type Default Column Data Description inputCol string None image struct (Image schema) Parameters Param name Type Default Description operation MorphologyOperationType MorphologyOperationType.OPENING Operation type kernelShape KernelShape KernelShape.DISK Kernel shape. kernelSize int 1 Kernel size in pixels. Output Columns Param name Type Default Column Data Description outputCol string None scaled image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setOperation(MorphologyOperationType.OPENING) adaptive_thresholding = ImageAdaptiveThresholding() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;corrected_image&quot;) .setBlockSize(75) .setOffset(0) opening = ImageMorphologyOperation() .setInputCol(&quot;corrected_image&quot;) .setOutputCol(&quot;opening_image&quot;) .setkernelSize(1) pipeline = PipelineModel(stages=[ binary_to_image, adaptive_thresholding, opening ]) result = pipeline.transform(df) for r in result.select(&quot;image&quot;, &quot;corrected_image&quot;).collect(): display_image(r.image) display_image(r.corrected_image) // Implemented only for Python Original image: Opening image: ImageCropper ImageCropperis a transformer for cropping image. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description cropRectangle Rectangle Rectangle(0,0,0,0) Image rectangle. cropSquareType CropSquareType CropSquareType.TOP_LEFT Type of square. Output Columns Param name Type Default Column Data Description outputCol string cropped_image scaled image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setOperation(MorphologyOperationType.OPENING) cropper = ImageCropper() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cropped_image&quot;) .setCropRectangle((0, 0, 200, 110)) pipeline = PipelineModel(stages=[ binary_to_image, cropper ]) result = pipeline.transform(df) for r in result.select(&quot;image&quot;, &quot;cropped_image&quot;).collect(): display_image(r.image) display_image(r.cropped_image) import com.johnsnowlabs.ocr.transformers.ImageAdaptiveScaler import com.johnsnowlabs.ocr.OcrContext.implicits._ import java.awt.Rectangle val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val rectangle: Rectangle = new Rectangle(0, 0, 200, 110) val cropper: ImageCropper = new ImageCropper() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cropped_image&quot;) .setCropRectangle(rectangle) val data = transformer.transform(df) data.storeImage(&quot;cropped_image&quot;) Splitting image to regions ImageLayoutAnalyzer ImageLayoutAnalyzer analyzes the image and determines regions of text. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description pageSegMode PageSegmentationMode AUTO page segmentation mode pageIteratorLevel PageIteratorLevel BLOCK page iteration level ocrEngineMode EngineMode LSTM_ONLY OCR engine mode Output Columns Param name Type Default Column Data Description outputCol string region array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect regions layout_analyzer = ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, layout_analyzer ]) data = pipeline.transform(df) data.show() import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.{ImageSplitRegions, ImageLayoutAnalyzer} import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect regions val layoutAnalyzer = new ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) val data = layoutAnalyzer.transform(df) data.show() ImageSplitRegions ImageSplitRegions splits image into regions. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) inputRegionsCol string region array of [Coordinaties]ocr_structures#coordinate-schema) Parameters Param name Type Default Description explodeCols Array[string]   Columns which need to explode rotated boolean False Support rotated regions Output Columns Param name Type Default Column Data Description outputCol string region_image image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect regions layout_analyzer = ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) splitter = ImageSplitRegions() .setInputCol(&quot;image&quot;) .setRegionCol(&quot;regions&quot;) .setOutputCol(&quot;region_image&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, layout_analyzer, splitter ]) data = pipeline.transform(df) data.show() import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.{ImageSplitRegions, ImageLayoutAnalyzer} import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect regions val layoutAnalyzer = new ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) val splitter = new ImageSplitRegions() .setInputCol(&quot;image&quot;) .setRegionCol(&quot;regions&quot;) .setOutputCol(&quot;region_image&quot;) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( layoutAnalyzer, splitter )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = pipeline.transform(df) data.show() ImageDrawAnnotations ImageDrawAnnotations draw annotations with label and score to the image. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) inputChunksCol string region array of Annotation Parameters Param name Type Default Description lineWidth Int 4 Line width for draw rectangles fontSize Int 12 Font size for render labels and score rectColor Color Color.black Color of lines Output Columns Param name Type Default Column Data Description outputCol string image_with_chunks image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) draw_annotations = ImageDrawAnnotations() .setInputCol(&quot;image&quot;) .setInputChunksCol(&quot;token&quot;) .setOutputCol(&quot;image_with_annotations&quot;) .setFilledRect(False) .setFontSize(40) .setRectColor(Color.red) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, tokenizer, image_with_annotations ]) result = pipeline.transform(df) import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val tokenizer = new HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) val draw_annotations = new ImageDrawAnnotations() .setInputCol(&quot;image&quot;) .setInputChunksCol(&quot;token&quot;) .setOutputCol(&quot;image_with_annotations&quot;) .setFilledRect(False) .setFontSize(40) .setRectColor(Color.red) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, tokenizer, draw_annotations )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) ImageDrawRegions ImageDrawRegions draw regions with label and score to the image. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) inputRegionsCol string region array of [Coordinaties]ocr_structures#coordinate-schema) Parameters Param name Type Default Description lineWidth Int 4 Line width for draw rectangles fontSize Int 12 Font size for render labels and score rotated boolean False Support rotated regions Output Columns Param name Type Default Column Data Description outputCol string image_with_regions image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect regions layout_analyzer = ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) draw = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setRegionCol(&quot;regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, layout_analyzer, draw ]) data = pipeline.transform(df) data.show() import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.{ImageSplitRegions, ImageLayoutAnalyzer} import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect regions val layoutAnalyzer = new ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) val draw = new ImageDrawRegions() .setInputCol(&quot;image&quot;) .setRegionCol(&quot;regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( layoutAnalyzer, draw )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = pipeline.transform(df) data.show() Characters recognition Next section describes the estimators for OCR ImageToText ImageToText runs OCR for input image, return recognized text to outputCol and positions with font size to ‘positionsCol’ column. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description pageSegMode PageSegmentationMode AUTO page segmentation mode pageIteratorLevel PageIteratorLevel BLOCK page iteration level ocrEngineMode EngineMode LSTM_ONLY OCR engine mode language Language Language.ENG language confidenceThreshold int 0 Confidence threshold. ignoreResolution bool false Ignore resolution from metadata of image. ocrParams array of strings [] Array of Ocr params in key=value format. pdfCoordinates bool false Transform coordinates in positions to PDF points. modelData string   Path to the local model data. modelType ModelType ModelType.BASE Model type downloadModelData bool false Download model data from JSL S3 withSpaces bool false Include spaces to output positions. keepLayout bool false Keep layout of text at result. outputSpaceCharacterWidth int 8 Output space character width in pts for layout keeper. Output Columns Param name Type Default Column Data Description outputCol string text Recognized text positionsCol string positions Positions of each block of text (related to pageIteratorLevel) in PageMatrix Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setOcrParams([&quot;preserve_interword_spaces=1&quot;, ]) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr ]) data = pipeline.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageToText import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setOcrParams(Array(&quot;preserve_interword_spaces=1&quot;)) val data = transformer.transform(df) print(data.select(&quot;text&quot;).collect()[0].text) Image: Output: FOREWORD Electronic design engineers are the true idea men of the electronic industries. They create ideas and use them in their designs, they stimu- late ideas in other designers, and they borrow and adapt ideas from others. One could almost say they feed on and grow on ideas. ImageToTextV2 ImageToTextV2 is based on the transformers architecture, and combines CV and NLP in one model. It is a visual encoder-decoder model. The Encoder is based on ViT, and the decoder on RoBERTa model. ImageToTextV2 can work on CPU, but GPU is preferred in order to achieve acceptable performance. ImageToTextV2 can receive regions representing single line texts, or regions coming from a text detection model. Input Columns Param name Type Default Column Data Description inputCols Array[string] [image] Can use as input image struct (Image schema) and regions. Parameters Param name Type Default Description lineTolerance integer 15 Line tolerance in pixels. It’s used for grouping text regions by lines. borderWidth integer 5 A value of more than 0 enables to border text regions with width equal to the value of the parameter. spaceWidth integer 10 A value of more than 0 enables to add white spaces between words on the image. Output Columns Param name Type Default Column Data Description outputCol string text Recognized text Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) text_detector = ImageTextDetectorV2 .pretrained(&quot;image_text_detector_v2&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text_regions&quot;) .setWithRefiner(True) .setSizeThreshold(20) ocr = ImageToTextV2.pretrained(&quot;ocr_base_printed&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols([&quot;image&quot;, &quot;text_regions&quot;]) .setOutputCol(&quot;text&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, text_detector, ocr ]) data = pipeline.transform(df) data.show() not implemented Image: Output: STARBUCKS STORE #10208 11302 EUCLID AVENUE CLEVELAND, OH (216) 229-0749 CHK 664290 12/07/2014 06:43 PM 1912003 DRAWER: 2. REG: 2 VT PEP MOCHA 4.95 SBUX CARD 4.95 XXXXXXXXXXXX3228 SUBTOTAL $4.95 TOTAL $4.95 CHANGE DUE $0.00 - CHECK CLOSED 12/07/2014 06:43 PM SBUX CARD X3228 NEW BALANCE: 37.45 CARD IS REGISTERED ImageToTextPdf ImageToTextPdf runs OCR for input image, render recognized text to the PDF as an invisible text layout with an original image. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) originCol string path path to the original file pageNumCol string pagenum for compatibility with another transformers Parameters Param name Type Default Description ocrParams array of strings [] Array of Ocr params in key=value format. Output Columns Param name Type Default Column Data Description outputCol string pdf Recognized text rendered to PDF PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToTextPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;pdf&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr ]) data = pipeline.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageToTextPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;pdf&quot;) val data = transformer.transform(df) data.show() ImageToHocr ImageToHocr runs OCR for input image, return recognized text and bounding boxes to outputCol column in HOCR format. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description pageSegMode PageSegmentationMode AUTO page segmentation mode pageIteratorLevel PageIteratorLevel BLOCK page iteration level ocrEngineMode EngineMode LSTM_ONLY OCR engine mode language string eng language ignoreResolution bool true Ignore resolution from metadata of image. ocrParams array of strings [] Array of Ocr params in key=value format. Output Columns Param name Type Default Column Data Description outputCol string hocr Recognized text Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr ]) data = pipeline.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageToHocr import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val data = transformer.transform(df) print(data.select(&quot;hocr&quot;).collect()[0].hocr) Image: Output: &lt;div class=&#39;ocr_page&#39; id=&#39;page_1&#39; title=&#39;image &quot;&quot;; bbox 0 0 1280 467; ppageno 0&#39;&gt; &lt;div class=&#39;ocr_carea&#39; id=&#39;block_1_1&#39; title=&quot;bbox 516 80 780 114&quot;&gt; &lt;p class=&#39;ocr_par&#39; id=&#39;par_1_1&#39; lang=&#39;eng&#39; title=&quot;bbox 516 80 780 114&quot;&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_1&#39; title=&quot;bbox 516 80 780 114; baseline 0 -1; x_size 44; x_descenders 11; x_ascenders 11&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_1&#39; title=&#39;bbox 516 80 780 114; x_wconf 96&#39;&gt;FOREWORD&lt;/span&gt; &lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class=&#39;ocr_carea&#39; id=&#39;block_1_2&#39; title=&quot;bbox 40 237 1249 425&quot;&gt; &lt;p class=&#39;ocr_par&#39; id=&#39;par_1_2&#39; lang=&#39;eng&#39; title=&quot;bbox 40 237 1249 425&quot;&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_2&#39; title=&quot;bbox 122 237 1249 282; baseline 0.001 -12; x_size 45; x_descenders 12; x_ascenders 13&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_2&#39; title=&#39;bbox 122 237 296 270; x_wconf 96&#39;&gt;Electronic&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_3&#39; title=&#39;bbox 308 237 416 281; x_wconf 96&#39;&gt;design&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_4&#39; title=&#39;bbox 428 243 588 282; x_wconf 96&#39;&gt;engineers&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_5&#39; title=&#39;bbox 600 250 653 271; x_wconf 96&#39;&gt;are&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_6&#39; title=&#39;bbox 665 238 718 271; x_wconf 96&#39;&gt;the&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_7&#39; title=&#39;bbox 731 246 798 272; x_wconf 97&#39;&gt;true&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_8&#39; title=&#39;bbox 810 238 880 271; x_wconf 96&#39;&gt;idea&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_9&#39; title=&#39;bbox 892 251 963 271; x_wconf 96&#39;&gt;men&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_10&#39; title=&#39;bbox 977 238 1010 272; x_wconf 96&#39;&gt;of&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_11&#39; title=&#39;bbox 1021 238 1074 271; x_wconf 96&#39;&gt;the&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_12&#39; title=&#39;bbox 1086 239 1249 272; x_wconf 96&#39;&gt;electronic&lt;/span&gt; &lt;/span&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_3&#39; title=&quot;bbox 41 284 1248 330; baseline 0.002 -13; x_size 44; x_descenders 11; x_ascenders 12&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_13&#39; title=&#39;bbox 41 284 214 318; x_wconf 96&#39;&gt;industries.&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_14&#39; title=&#39;bbox 227 284 313 328; x_wconf 96&#39;&gt;They&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_15&#39; title=&#39;bbox 324 292 427 319; x_wconf 96&#39;&gt;create&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_16&#39; title=&#39;bbox 440 285 525 319; x_wconf 96&#39;&gt;ideas&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_17&#39; title=&#39;bbox 537 286 599 318; x_wconf 96&#39;&gt;and&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_18&#39; title=&#39;bbox 611 298 668 319; x_wconf 96&#39;&gt;use&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_19&#39; title=&#39;bbox 680 286 764 319; x_wconf 96&#39;&gt;them&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_20&#39; title=&#39;bbox 777 291 808 319; x_wconf 96&#39;&gt;in&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_21&#39; title=&#39;bbox 821 286 900 319; x_wconf 96&#39;&gt;their&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_22&#39; title=&#39;bbox 912 286 1044 330; x_wconf 96&#39;&gt;designs,&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_23&#39; title=&#39;bbox 1058 286 1132 330; x_wconf 93&#39;&gt;they&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_24&#39; title=&#39;bbox 1144 291 1248 320; x_wconf 92&#39;&gt;stimu-&lt;/span&gt; &lt;/span&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_4&#39; title=&quot;bbox 42 332 1247 378; baseline 0.002 -14; x_size 44; x_descenders 12; x_ascenders 12&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_25&#39; title=&#39;bbox 42 332 103 364; x_wconf 97&#39;&gt;late&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_26&#39; title=&#39;bbox 120 332 204 365; x_wconf 96&#39;&gt;ideas&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_27&#39; title=&#39;bbox 223 337 252 365; x_wconf 96&#39;&gt;in&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_28&#39; title=&#39;bbox 271 333 359 365; x_wconf 96&#39;&gt;other&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_29&#39; title=&#39;bbox 376 333 542 377; x_wconf 96&#39;&gt;designers,&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_30&#39; title=&#39;bbox 561 334 625 366; x_wconf 96&#39;&gt;and&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_31&#39; title=&#39;bbox 643 334 716 377; x_wconf 96&#39;&gt;they&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_32&#39; title=&#39;bbox 734 334 855 366; x_wconf 96&#39;&gt;borrow&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_33&#39; title=&#39;bbox 873 334 934 366; x_wconf 96&#39;&gt;and&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_34&#39; title=&#39;bbox 954 335 1048 378; x_wconf 96&#39;&gt;adapt&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_35&#39; title=&#39;bbox 1067 334 1151 367; x_wconf 96&#39;&gt;ideas&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_36&#39; title=&#39;bbox 1169 334 1247 367; x_wconf 96&#39;&gt;from&lt;/span&gt; &lt;/span&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_5&#39; title=&quot;bbox 40 379 1107 425; baseline 0.002 -13; x_size 45; x_descenders 12; x_ascenders 12&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_37&#39; title=&#39;bbox 40 380 151 412; x_wconf 96&#39;&gt;others.&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_38&#39; title=&#39;bbox 168 383 238 412; x_wconf 96&#39;&gt;One&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_39&#39; title=&#39;bbox 252 379 345 412; x_wconf 96&#39;&gt;could&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_40&#39; title=&#39;bbox 359 380 469 413; x_wconf 96&#39;&gt;almost&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_41&#39; title=&#39;bbox 483 392 537 423; x_wconf 96&#39;&gt;say&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_42&#39; title=&#39;bbox 552 381 626 424; x_wconf 96&#39;&gt;they&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_43&#39; title=&#39;bbox 641 381 712 414; x_wconf 96&#39;&gt;feed&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_44&#39; title=&#39;bbox 727 393 767 414; x_wconf 96&#39;&gt;on&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_45&#39; title=&#39;bbox 783 381 845 414; x_wconf 96&#39;&gt;and&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_46&#39; title=&#39;bbox 860 392 945 425; x_wconf 97&#39;&gt;grow&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_47&#39; title=&#39;bbox 959 393 999 414; x_wconf 96&#39;&gt;on&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_48&#39; title=&#39;bbox 1014 381 1107 414; x_wconf 95&#39;&gt;ideas.&lt;/span&gt; &lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; ImageBrandsToText ImageBrandsToText runs OCR for specified brands of input image, return recognized text to outputCol and positions with font size to ‘positionsCol’ column. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description pageSegMode PageSegmentationMode AUTO page segmentation mode pageIteratorLevel PageIteratorLevel BLOCK page iteration level ocrEngineMode EngineMode LSTM_ONLY OCR engine mode language string eng language confidenceThreshold int 0 Confidence threshold. ignoreResolution bool true Ignore resolution from metadata of image. ocrParams array of strings [] Array of Ocr params in key=value format. brandsCoords string   Json with coordinates of brands. Output Columns Param name Type Default Column Data Description outputCol structure image_brands Structure with recognized text from brands. textCol string text Recognized text positionsCol string positions Positions of each block of text (related to pageIteratorLevel) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageBrandsToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setBrandsCoords(&quot;&quot;&quot;[ { &quot;name&quot;:&quot;part_one&quot;, &quot;rectangle&quot;:{ &quot;x&quot;:286, &quot;y&quot;:65, &quot;width&quot;:542, &quot;height&quot;:342 } }, { &quot;name&quot;:&quot;part_two&quot;, &quot;rectangle&quot;:{ &quot;x&quot;:828, &quot;y&quot;:65, &quot;width&quot;:1126, &quot;height&quot;:329 } } ]&quot;&quot;&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr ]) data = pipeline.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageToText import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageBrandsToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setBrandsCoordsStr( &quot;&quot;&quot; [ { &quot;name&quot;:&quot;part_one&quot;, &quot;rectangle&quot;:{ &quot;x&quot;:286, &quot;y&quot;:65, &quot;width&quot;:542, &quot;height&quot;:342 } }, { &quot;name&quot;:&quot;part_two&quot;, &quot;rectangle&quot;:{ &quot;x&quot;:828, &quot;y&quot;:65, &quot;width&quot;:1126, &quot;height&quot;:329 } } ] &quot;&quot;&quot;.stripMargin) val data = transformer.transform(df) print(data.select(&quot;text&quot;).collect()[0].text) Other Next section describes the extra transformers PositionFinder PositionFinder find the position of input text entities in the original document. Input Columns Param name Type Default Column Data Description inputCols string image Input annotations columns pageMatrixCol string   Column name for Page Matrix schema Parameters Param name Type Default Description matchingWindow int 10 Textual range to match in context, applies in both direction windowPageTolerance boolean true whether or not to increase tolerance as page number grows padding int 5 padding for area Output Columns Param name Type Default Column Data Description outputCol string   Name of output column for store coordinates. Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparknlp.annotator import * from sparknlp.base import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;page&quot;) .setSplitPage(False) document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) entity_extractor = TextMatcher() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setEntities(&quot;./sparkocr/resources/test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) position_finder = PositionFinder() .setInputCols(&quot;entity&quot;) .setOutputCol(&quot;coordinates&quot;) .setPageMatrixCol(&quot;positions&quot;) .setMatchingWindow(10) .setPadding(2) pipeline = Pipeline(stages=[ pdf_to_text, document_assembler, sentence_detector, tokenizer, entity_extractor, position_finder ]) results = pipeline.fit(df).transform(df) results.show() import com.johnsnowlabs.ocr.transformers._ import com.johnsnowlabs.nlp.{DocumentAssembler, SparkAccessor} import com.johnsnowlabs.nlp.annotators._ import com.johnsnowlabs.nlp.util.io.ReadAs val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val entityExtractor = new TextMatcher() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setEntities(&quot;test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) val positionFinder = new PositionFinder() .setInputCols(&quot;entity&quot;) .setOutputCol(&quot;coordinates&quot;) .setPageMatrixCol(&quot;positions&quot;) .setMatchingWindow(10) .setPadding(2) // Create pipeline val pipeline = new Pipeline() .setStages(Array( pdfToText, documentAssembler, sentenceDetector, tokenizer, entityExtractor, positionFinder )) val results = pipeline.fit(df).transform(df) results.show() UpdateTextPosition UpdateTextPosition update output text and keep old coordinates of original document. Input Columns Param name Type Default Column Data Description inputCol string positions Сolumn name with original positions struct InputText string replace_text Column name for New Text to replace Old one Output Columns Param name Type Default Column Data Description outputCol string output_positions Name of output column for updated positions struct. Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparknlp.annotator import * from sparknlp.base import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;page&quot;) .setSplitPage(False) document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;tokens&quot;) spell = NorvigSweetingModel().pretrained(&quot;spellcheck_norvig&quot;, &quot;en&quot;) .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;spell&quot;) tokenAssem = TokenAssembler() .setInputCols(&quot;spell&quot;) .setOutputCol(&quot;newDocs&quot;) updatedText = UpdateTextPosition() .setInputCol(&quot;positions&quot;) .setOutputCol(&quot;output_positions&quot;) .setInputText(&quot;newDocs.result&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, spell, tokenAssem, updatedText ]) results = pipeline.fit(df).transform(df) results.show() import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingModel import com.johnsnowlabs.nlp.{DocumentAssembler, TokenAssembler} import com.johnsnowlabs.ocr.transformers._ import org.apache.spark.ml.Pipeline val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val token = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val spell = NorvigSweetingModel.pretrained(&quot;spellcheck_norvig&quot;, &quot;en&quot;) .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;spell&quot;) val tokenAssem = new TokenAssembler() .setInputCols(&quot;spell&quot;) .setOutputCol(&quot;newDocs&quot;) val updatedText = new UpdateTextPosition() .setInputCol(&quot;positions&quot;) .setOutputCol(&quot;output_positions&quot;) .setInputText(&quot;newDocs.result&quot;) val pipeline = new Pipeline() .setStages(Array( pdfToText, documentAssembler, sentence, token, spell, tokenAssem, updatedText )) val results = pipeline.fit(df).transform(df) results.show() FoundationOneReportParser FoundationOneReportParser is a transformer for parsing FoundationOne reports. Current implementation supports parsing patient info, genomic, biomarker findings and gene lists from appendix. Output format is json. Input Columns Param name Type Default Column Data Description inputCol string text Сolumn name with text of report originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string report Name of output column with report in json format. Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparkocr.enums import TextStripperType pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text = PdfToText() pdf_to_text.setInputCol(&quot;content&quot;) pdf_to_text.setOutputCol(&quot;text&quot;) pdf_to_text.setSplitPage(False) pdf_to_text.setTextStripper(TextStripperType.PDF_LAYOUT_TEXT_STRIPPER) genomic_parser = FoundationOneReportParser() genomic_parser.setInputCol(&quot;text&quot;) genomic_parser.setOutputCol(&quot;report&quot;) report = genomic_parser.transform(pdf_to_text.transform(df)).collect() import com.johnsnowlabs.ocr.transformers._ import org.apache.spark.ml.Pipeline val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) .setTextStripper(TextStripperType.PDF_LAYOUT_TEXT_STRIPPER) val genomicsParser = new FoundationOneReportParser() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;report&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( pdfToText, genomicsParser )) val modelPipeline = pipeline.fit(df) val report = modelPipeline.transform(df) Output: { &quot;Patient&quot; : { &quot;disease&quot; : &quot;Unknown primary melanoma&quot;, &quot;name&quot; : &quot;Lekavich Gloria&quot;, &quot;date_of_birth&quot; : &quot;11 November 1926&quot;, &quot;sex&quot; : &quot;Female&quot;, &quot;medical_record&quot; : &quot;11111&quot; }, &quot;Physician&quot; : { &quot;ordering_physician&quot; : &quot;Genes Pinley&quot;, &quot;medical_facility&quot; : &quot;Health Network Cancer Institute&quot;, &quot;additional_recipient&quot; : &quot;Nath&quot;, &quot;medical_facility_id&quot; : &quot;202051&quot;, &quot;pathologist&quot; : &quot;Manqju Nwath&quot; }, &quot;Specimen&quot; : { &quot;specimen_site&quot; : &quot;Rectum&quot;, &quot;specimen_id&quot; : &quot;AVS 1A&quot;, &quot;specimen_type&quot; : &quot;Slide&quot;, &quot;date_of_collection&quot; : &quot;20 March 2015&quot;, &quot;specimen_received&quot; : &quot;30 March 2015 &quot; }, &quot;Biomarker_findings&quot; : [ { &quot;name&quot; : &quot;Tumor Mutation Burden&quot;, &quot;state&quot; : &quot;TMB-Low (3Muts/Mb)&quot;, &quot;actionability&quot; : &quot;No therapies or clinical trials. &quot; } ], &quot;Genomic_findings&quot; : [ { &quot;name&quot; : &quot;FLT3&quot;, &quot;state&quot; : &quot;amplification&quot;, &quot;therapies_with_clinical_benefit_in_patient_tumor_type&quot; : [ &quot;none&quot; ], &quot;therapies_with_clinical_benefit_in_other_tumor_type&quot; : [ &quot;Sorafenib&quot;, &quot;Sunitinib&quot;, &quot;Ponatinib&quot; ] } ], &quot;Appendix&quot; : { &quot;dna_gene_list&quot; : [ &quot;ABL1&quot;, &quot;ACVR1B&quot;, &quot;AKT1&quot;, .... ], &quot;dna_gene_list_rearrangement&quot; : [ &quot;ALK&quot;, &quot;BCL2&quot;, &quot;BCR&quot;, .... ], &quot;additional_assays&quot; : [ &quot;Tumor Mutation Burden (TMB)&quot;, &quot;Microsatellite Status (MS)&quot; ] } } HocrDocumentAssembler HocrDocumentAssembler prepares data into a format that is processable by Spark NLP. Output Annotator Type: DOCUMENT Input Columns Param name Type Default Column Data Description inputCol string hocr Сolumn name with HOCR of the document Output Columns Param name Type Default Column Data Description outputCol string document Name of output column. Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) hocr_document_assembler = HocrDocumentAssembler() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;document&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, hocr_document_assembler ]) result = pipeline.transform(df) result.select(&quot;document&quot;).show() import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val hocrDocumentAssembler = HocrDocumentAssembler() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;document&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, hocrDocumentAssembler )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) result.select(&quot;document&quot;).show() Output: +--+ | document | +--+ | [[document, 0, 4392, Patient Nam Financial Numbe Random Hospital...| +--+ HocrTokenizer HocrTokenizer prepares into a format that is processable by Spark NLP. HocrTokenizer puts to metadata coordinates and ocr confidence. Output Annotator Type: TOKEN Input Columns Param name Type Default Column Data Description inputCol string hocr Сolumn name with HOCR of the document. Output Columns Param name Type Default Column Data Description outputCol string token Name of output column. Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, tokenizer ]) result = pipeline.transform(df) result.select(&quot;token&quot;).show() import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, tokenizer )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) result.select(&quot;token&quot;).show() Output: +--+ | token | +--+ | [[token, 0, 6, patient, [x -&gt; 2905, y -&gt; 527, height -&gt; 56, | | confidence -&gt; 95, word -&gt; Patient, width -&gt; 230], []], [token, 8, | |10, nam, [x -&gt; 3166, y -&gt; 526, height -&gt; 55, confidence -&gt; 95, word | |-&gt; Nam, width -&gt; 158], []] ... | +--+",
    "url": "/docs/en/ocr_pipeline_components",
    "relUrl": "/docs/en/ocr_pipeline_components"
  },
  "1305": {
    "id": "1305",
    "title": "Spark OCR release notes",
    "content": "5.0.0 Release date: 21-08-2023 We are glad to announce that Visual NLP 😎 5.0.0 has been released! This release comes with new models, bug fixes and more! New Models New dit_base_finetuned_rvlcdip_opt: Dit based Visual Document Classification model. This is an optimized version of previous dit_base_finetuned_rvlcdip model. It has a reduced model size of 80MB(vs. 304 of original model), which reduces the memory footprint, also memory management within the model itself has been improved. It offers a speedup of 1.54x compared to the original implementation. The impact in accuracy is minimal, it achieves an accuracy of 91.55% over RVL-CDIP dataset compared to 91.83% of the original model. Setting up the model is straightforward, doc_class = VisualDocumentClassifierV3() .pretrained(&quot;dit_base_finetuned_rvlcdip_opt&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols([&quot;image&quot;]) .setOutputCol(&quot;label&quot;) Use this notebook as a reference. New image_text_detector_mem_opt: memory optimized Craft Text Detection Model. This is new a model that improves the performance and memory consumption of the previous ImageTextDetector models. This is the same CRAFT architecture, where memory management has been improved, and refiner network has been merged into a single graph with the main network. This removes expensive data movement and reduces memory consumption. Setting up the model is straightforward, text_detector = ImageTextDetector.pretrained(&quot;image_text_detector_opt&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) text_detector.setInputCol(&quot;image&quot;) text_detector.setOutputCol(&quot;text_regions&quot;) Use this notebook as a reference. New lilt_rvl_cdip_296K: Lilt based Visual Document Classification model: Language-independent Layout Transformer (LiLT) model for document classification. The model was trained on RVL-CDIP dataset that consists of 400.000 grayscale images in 16 classes. Setting up the model is done like this, doc_class = VisualDocumentClassifierLilt() .pretrained(&quot;lilt_rvl_cdip_296K&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;label&quot;) Use this notebook as a reference. New Annotators New DicomToPdf and DicomUpdatePdf annotators: the new annotators now make it possible to extract and update encapsulated PDF files within DICOM documents. This opens up opportunities to building de-identification pipelines for the purpose of anonymizing PDF documents that have been encapsulated(embedded) into Dicom files. Bug Fixes ImageDrawAnnotations serialization issues were solved. FormRelationExtraction is now compatible with the new Lilt Visual Ner models. Pipeline serialization issues in Databricks affecting annotators like ImageHandwrittenDetector have been solved. Pillow related errors in Colab setup have been fixed. New Notebooks VisualDocumentClassifierTraining, notebooks for Visual Documents Classifier fine tuning have been updated to use the new Lilt based models. SparkOcrDeidentificationDicomWithEncapsulatedPDF.ipynb, learn how to use the new DicomToPdf and DicomUpdatePdf. SparkOcrDicomDeIdentificationV2Streaming.ipynb, learn how to setup a Spark Structured Streaming pipeline for Dicom Deidentification. Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/ocr_release_notes",
    "relUrl": "/docs/en/spark_ocr_versions/ocr_release_notes"
  },
  "1306": {
    "id": "1306",
    "title": "Structures and helpers",
    "content": "Schemas Image Schema Images are loaded as a DataFrame with a single column called “image.” It is a struct-type column, that contains all information about image: image: struct (nullable = true) | |-- origin: string (nullable = true) | |-- height: integer (nullable = false) | |-- width: integer (nullable = false) | |-- nChannels: integer (nullable = false) | |-- mode: integer (nullable = false) | |-- resolution: integer (nullable = true) | |-- data: binary (nullable = true) Fields Field name Type Description origin string source URI height integer image height in pixels width integer image width in pixels nChannels integer number of color channels mode ImageType the data type and channel order the data is stored in resolution integer resolution of image in dpi data binary image data in a binary format NOTE: Image data stored in a binary format. Image data is represented as a 3-dimensional array with the dimension shape (height, width, nChannels) and array values of type t specified by the mode field. Coordinate Schema element: struct (containsNull = true) | | |-- index: integer (nullable = false) | | |-- page: integer (nullable = false) | | |-- x: float (nullable = false) | | |-- y: float (nullable = false) | | |-- width: float (nullable = false) | | |-- height: float (nullable = false) Field name Type Description index integer Chunk index page integer Page number x float The lower left x coordinate y float The lower left y coordinate width float The width of the rectangle height float The height of the rectangle score float The score of the object label string The label of the object PageMatrix Schema element: struct (containsNull = true) | | |-- mappings: array[struct] (nullable = false) Field name Type Description mappings Array[Mapping] Array of mappings Mapping Schema element: struct (containsNull = true) | | |-- c: string (nullable = false) | | |-- p: integer (nullable = false) | | |-- x: float (nullable = false) | | |-- y: float (nullable = false) | | |-- width: float (nullable = false) | | |-- height: float (nullable = false) | | |-- fontSize: integer (nullable = false) Field name Type Description c string Character p integer Page number x float The lower left x coordinate y float The lower left y coordinate width float The width of the rectangle height float The height of the rectangle fontSize integer Font size in points Enums PageSegmentationMode OSD_ONLY: Orientation and script detection only. AUTO_OSD: Automatic page segmentation with orientation and script detection. AUTO_ONLY: Automatic page segmentation, but no OSD, or OCR. AUTO: Fully automatic page segmentation, but no OSD. SINGLE_COLUMN: Assume a single column of text of variable sizes. SINGLE_BLOCK_VERT_TEXT: Assume a single uniform block of vertically aligned text. SINGLE_BLOCK: Assume a single uniform block of text. SINGLE_LINE: Treat the image as a single text line. SINGLE_WORD: Treat the image as a single word. CIRCLE_WORD: Treat the image as a single word in a circle. SINGLE_CHAR: Treat the image as a single character. SPARSE_TEXT: Find as much text as possible in no particular order. SPARSE_TEXT_OSD: Sparse text with orientation and script detection. EngineMode TESSERACT_ONLY: Legacy engine only. OEM_LSTM_ONLY: Neural nets LSTM engine only. TESSERACT_LSTM_COMBINED: Legacy + LSTM engines. DEFAULT: Default, based on what is available. PageIteratorLevel BLOCK: Block of text/image/separator line. PARAGRAPH: Paragraph within a block. TEXTLINE: Line within a paragraph. WORD: Word within a text line. SYMBOL: Symbol/character within a word. Language ENG: English FRA: French SPA: Spanish RUS: Russian DEU: German VIE: Vietnamese ARA: Arabic ModelType BASE: Block of text/image/separator line. BEST: Paragraph within a block. FAST: Line within a paragraph. ImageType TYPE_BYTE_GRAY TYPE_BYTE_BINARY TYPE_3BYTE_BGR TYPE_4BYTE_ABGR NoiseMethod VARIANCE RATIO KernelShape SQUARE DIAMOND DISK OCTAHEDRON OCTAGON STAR MorphologyOperationType OPENING CLOSING EROSION DILATION CropSquareType TOP_LEFT TOP_CENTER TOP_RIGHT CENTER_LEFT CENTER CENTER_RIGHT BOTTOM_LEFT BOTTOM_CENTER BOTTOM_RIGHT SplittingStrategy FIXED_NUMBER_OF_PARTITIONS FIXED_SIZE_OF_PARTITION AdaptiveThresholdingMethod GAUSSIAN MEAN MEDIAN WOLF SINGH TresholdingMethod GAUSSIAN OTSU SAUVOLA WOLF CellDetectionAlgos CONTOURS - Detect cells in bordered tables MORPHOPS - Detected calls in: bordered, borderless and combined tables TableOutputFormat TABLE - Table struct format CSV - Comma separated CSV OCR implicits asImage asImage transforms binary content to Image schema. Parameters Param name Type Default Description outputCol string image output column name contentCol string content input column name with binary content pathCol string path input column name with path to original file Example: import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) df.show() storeImage storeImage stores the image(s) to tmp location and return Dataset with path(s) to stored image files. Parameters Param name Type Default Description inputColumn string   input column name with image struct formatName string png image format name prefix string sparknlp_ocr_ prefix for output file Example: import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) df.storeImage(&quot;image&quot;) showImages Show images on Databrics notebook. Parameters Param name Type Default Description field string image input column name with image struct limit integer 5 count of rows for display width string “800” width of image show_meta boolean true enable/disable displaying metadata of image Jupyter Python helpers display_image Show single image with metadata in Jupyter notebook. Parameters Param name Type Default Description width string “600” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.utils import display_image from sparkocr.transformers import BinaryToImage images_path = &quot;/tmp/ocr/images/*.tif&quot; images_example_df = spark.read.format(&quot;binaryFile&quot;).load(images_path).cache() display_image(BinaryToImage().transform(images_example_df).collect()[0].image) display_images Show images from dataframe. Parameters Param name Type Default Description field string image input column name with image struct limit integer 5 count of rows for display width string “600” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.utils import display_images from sparkocr.transformers import BinaryToImage images_path = &quot;/tmp/ocr/images/*.tif&quot; images_example_df = spark.read.format(&quot;binaryFile&quot;).load(images_path).cache() display_images(BinaryToImage().transform(images_example_df), limit=3) display_images_horizontal Show one or more images per row from dataframe. Parameters Param name Type Default Description fields string image comma separated input column names with image struct limit integer 5 count of rows for display width string “600” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.utils import display_images_horizontal display_images_horizontal(df_with_few_image_fields, fields=&quot;images, image_with_regions&quot;, limit=10) display_pdf Show pdf from dataframe. Parameters Param name Type Default Description field string content input column with binary representation of pdf limit integer 5 count of rows for display width string “600” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.utils import display_pdf pdf_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path) display_pdf(pdf_df) display_pdf_file Show pdf file using embedded pdf viewer. Parameters Param name Type Default Description pdf string   Path to the file name size integer size=(600, 500) count of rows for display Example: from sparkocr.utils import display_pdf_file display_pdf_file(&quot;path to the pdf file&quot;) Example output: display_table Display table from the dataframe. display_tables Display tables from the dataframe. It is useful for display results of table recognition from the multipage documents/few tables per page. Example output: Databricks Python helpers display_images Show images from dataframe. Parameters Param name Type Default Description field string image input column name with image struct limit integer 5 count of rows for display width string “800” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.databricks import display_images from sparkocr.transformers import BinaryToImage images_path = &quot;/tmp/ocr/images/*.tif&quot; images_example_df = spark.read.format(&quot;binaryFile&quot;).load(images_path).cache() display_images(BinaryToImage().transform(images_example_df), limit=3)",
    "url": "/docs/en/ocr_structures",
    "relUrl": "/docs/en/ocr_structures"
  },
  "1307": {
    "id": "1307",
    "title": "Table recognition",
    "content": "ImageTableDetector ImageTableDetector is a DL model for detecting tables on the image. It’s based on CascadeTabNet which used Cascade mask Region-based CNN High-Resolution Network (Cascade mask R-CNN HRNet). Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scoreThreshold float 0.9 Score threshold for output regions. applyCorrection boolean false Enable correction of results. Output Columns Param name Type Default Column Data Description outputCol string table_regions array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect tables val table_detector = ImageTableDetector .pretrained(&quot;general_model_table_detection_v2&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;table_regions&quot;) val draw_regions = new ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;table_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, table_detector, draw_regions ]) val data = pipeline.transform(df) data.storeImage(&quot;image_with_regions&quot;) from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect tables table_detector = ImageTableDetector .pretrained(&quot;general_model_table_detection_v2&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;table_regions&quot;) draw_regions = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;table_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, table_detector, draw_regions ]) data = pipeline.transform(df) display_images(data, &quot;image_with_regions&quot;) Output: ImageTableCellDetector ImageTableCellDetector detect cells in a table image. It’s based on an image processing algorithm that detects horizontal and vertical lines. Current implementation support few algorithm for extract cells: CellDetectionAlgos.CONTOURS works only for bordered tables. CellDetectionAlgos.MORPHOPS works for bordered, borderless and combined tables. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description algoType CellDetectionAlgos CellDetectionAlgos.CONTOURS Algorithm for detect cells. algoParams string row_treshold=0.05,row_treshold_wide=1.0, row_min_wide=5,column_treshold=0.05, column_treshold_wide=5,column_min_wide=5 Parameters of ‘MORPHOPS’ cells detection algorithm drawDetectedLines boolean false Enable to draw detected lines to the output image keepOriginalLines boolean false Keep original images on the output image Output Columns Param name Type Default Column Data Description outputCol string cells array of coordinates of cells outputImageCol string output_image output image Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect cells val transformer = new ImageTableCellDetector() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cells&quot;) val data = transformer.transform(df) data.select(&quot;cells&quot;).show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect cells transformer = ImageTableCellDetector .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cells&quot;) .setAlgoParams(&quot;row_treshold=0.05&quot;) pipeline = PipelineModel(stages=[ binary_to_image, transformer ]) data = pipeline.transform(df) data.select(&quot;cells&quot;).show() Image: Output:* +-+ | cells | +-+ ||[[[[15, 17, 224, 53]], [[241, 17, 179, 53]], [[423, 17, | | 194, 53]], [[619, 17, 164, 53]] .... | +-+ ImageCellsToTextTable ImageCellsToTextTable runs OCR for cells regions on image, return recognized text to outputCol as TableContainer structure. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) cellsCol string celss Array of cells Parameters Param name Type Default Description strip bool true Strip output text. margin bool 1 Margin of cells in pixelx. pageSegMode PageSegmentationMode AUTO page segmentation mode ocrEngineMode EngineMode LSTM_ONLY OCR engine mode language Language Language.ENG language ocrParams array of strings [] Array of Ocr params in key=value format. pdfCoordinates bool false Transform coordinates in positions to PDF points. modelData string   Path to the local model data. modelType ModelType ModelType.BASE Model type downloadModelData bool false Download model data from JSL S3 outputFormat TableOutputFormat TableOutputFormat.TABLE Output format Output Columns Param name Type Default Column Data Description outputCol string table Recognized text as TableContainer Example: PythonScala import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect cells val cell_detector = new ImageTableCellDetector() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cells&quot;) val table_recognition = new ImageCellsToTextTable() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;tables&quot;) .setMargin(2) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( cell_detector, table_recognition )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val results = modelPipeline.transform(df) results.select(&quot;tables&quot;) .withColumn(&quot;cells&quot;, explode(col(&quot;tables.chunks&quot;))) .select((0 until 7).map(i =&gt; col(&quot;cells&quot;)(i).getField(&quot;chunkText&quot;).alias(s&quot;col$i&quot;)): _*) .show(false) from pyspark.ml import PipelineModel import pyspark.sql.functions as f from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() binary_to_image.setImageType(ImageType.TYPE_BYTE_GRAY) binary_to_image.setInputCol(&quot;content&quot;) cell_detector = TableCellDetector() cell_detector.setInputCol(&quot;image&quot;) cell_detector.setOutputCol(&quot;cells&quot;) cell_detector.setKeepInput(True) table_recognition = ImageCellsToTextTable() table_recognition.setInputCol(&quot;image&quot;) table_recognition.setCellsCol(&#39;cells&#39;) table_recognition.setMargin(2) table_recognition.setStrip(True) table_recognition.setOutputCol(&#39;table&#39;) pipeline = PipelineModel(stages=[ binary_to_image, cell_detector, table_recognition ]) result = pipeline.transform(df) results.select(&quot;table&quot;) .withColumn(&quot;cells&quot;, f.explode(f.col(&quot;table.chunks&quot;))) .select([f.col(&quot;cells&quot;)[i].getField(&quot;chunkText&quot;).alias(f&quot;col{i}&quot;) for i in range(0, 7)]) .show(20, False) Image: Output: +-+-+--++--++-+ |col0 |col1 |col2 |col3 |col4 |col5 |col6 | +-+-+--++--++-+ |Order Date|Region |Rep |Item |Units|Unit Cost|Total | |1/23/10 |Ontario|Kivell |Binder|50 |$19.99 |$999.50| |2/9/10 |Ontario|Jardine |Pencil|36 |$4.99 |$179.64| |2/26/10 |Ontario|Gill |Pen |27 |$19.99 |$539.73| |3/15/10 |Alberta|Sorvino |Pencil|56 |$2.99 |$167.44| |4/1/10 |Quebec |Jones |Binder|60 |$4.99 |$299.40| |4/18/10 |Ontario|Andrews |Pencil|75 |$1.99 |$149.25| |5/5/10 |Ontario|Jardine |Pencil|90 |$4.99 |$449.10| |5/22/10 |Alberta|Thompson|Pencil|32 |$1.99 |$63.68 | +-+-+--++--++-+",
    "url": "/docs/en/ocr_table_recognition",
    "relUrl": "/docs/en/ocr_table_recognition"
  },
  "1308": {
    "id": "1308",
    "title": "Visual document understanding",
    "content": "NLP models are great at processing digital text, but many real-word applications use documents with more complex formats. For example, healthcare systems often include visual lab results, sequencing reports, clinical trial forms, and other scanned documents. When we only use an NLP approach for document understanding, we lose layout and style information - which can be vital for document image understanding. New advances in multi-modal learning allow models to learn from both the text in documents (via NLP) and visual layout (via computer vision). We provide multi-modal visual document understanding, built on Spark OCR based on the LayoutLM architecture. It achieves new state-of-the-art accuracy in several downstream tasks, including form understanding (from 70.7 to 79.3), receipt understanding (from 94.0 to 95.2) and document image classification (from 93.1 to 94.4). Please check also webinar: Visual Document Understanding with Multi-Modal Image &amp; Text Mining in Spark OCR 3 VisualDocumentClassifier VisualDocumentClassifier is a DL model for document classification using text and layout data. Currently available pretrained model on the Tobacco3482 dataset, that contains 3482 images belonging to 10 different classes (Resume, News, Note, Advertisement, Scientific, Report, Form, Letter, Email and Memo) Input Columns Param name Type Default Column Data Description inputCol string hocr Сolumn name with HOCR of the document Parameters Param name Type Default Description maxSentenceLength int 128 Maximum sentence length. caseSensitive boolean false Determines whether model is case sensitive. confidenceThreshold float 0f Confidence threshold. Output Columns Param name Type Default Column Data Description labelCol string label Name of output column with the predicted label. confidenceCol string confidence Name of output column with confidence. Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val visualDocumentClassifier = VisualDocumentClassifier .pretrained(&quot;visual_document_classifier_tobacco3482&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setMaxSentenceLength(128) .setInputCol(&quot;hocr&quot;) .setLabelCol(&quot;label&quot;) .setConfidenceCol(&quot;conf&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, visualDocumentClassifier )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) result.select(&quot;label&quot;).show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) document_classifier = VisualDocumentClassifier() .pretrained(&quot;visual_document_classifier_tobacco3482&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setMaxSentenceLength(128) .setInputCol(&quot;hocr&quot;) .setLabelCol(&quot;label&quot;) .setConfidenceCol(&quot;conf&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, document_classifier, ]) result = pipeline.transform(df) result.select(&quot;label&quot;).show() Output: ++ | label| ++ |Letter| ++ VisualDocumentNER VisualDocumentNER is a DL model for NER documents using text and layout data. Currently available pre-trained model on the SROIE dataset. The dataset has 1000 whole scanned receipt images. Input Columns Param name Type Default Column Data Description inputCol string hocr Сolumn name with HOCR of the document Parameters Param name Type Default Description maxSentenceLength int 512 Maximum sentence length. caseSensitive boolean false Determines whether model is case sensitive. whiteList Array[String]   Whitelist of output labels Output Columns Param name Type Default Column Data Description outputCol string entities Name of output column with entities Annotation. Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val visualDocumentNER = VisualDocumentNER .pretrained(&quot;visual_document_NER_SROIE0526&quot;, &quot;en&quot;, &quot;public/ocr/models&quot;) .setMaxSentenceLength(512) .setInputCol(&quot;hocr&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, visualDocumentNER )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) result.select(&quot;entities&quot;).show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) document_ner = VisualDocumentNer() .pretrained(&quot;visual_document_NER_SROIE0526&quot;, &quot;en&quot;, &quot;public/ocr/models&quot;) .setMaxSentenceLength(512) .setInputCol(&quot;hocr&quot;) .setLabelCol(&quot;label&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, document_ner, ]) result = pipeline.transform(df) result.select(&quot;entities&quot;).show() Output: +-+ |entities | +-+ |[[entity, 0, 0, O, [word -&gt; 0£0, token -&gt; 0£0], []], [entity, 0, 0, | | B-COMPANY, [word -&gt; AEON, token -&gt; aeon], []], [entity, 0, 0, B-COMPANY,| | [word -&gt; CO., token -&gt; co], ... | +-+ VisualDocumentNERv2 VisualDocumentNERv2 is a DL model for NER documents which is an improved version of VisualDocumentNER. There is available pretrained model trained on FUNSD dataset. The dataset comprises 199 real, fully annotated, scanned forms. Input Columns Param name Type Default Column Data Description inputCols Array[String]   Сolumn names for tokens of the document and image Parameters Param name Type Default Description maxSentenceLength int 512 Maximum sentence length. whiteList Array[String]   Whitelist of output labels Output Columns Param name Type Default Column Data Description outputCol string entities Name of output column with entities Annotation. Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; var dataFrame = spark.read.format(&quot;binaryFile&quot;).load(imagePath) var bin2imTransformer = new BinaryToImage() bin2imTransformer.setImageType(ImageType.TYPE_3BYTE_BGR) val ocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) .setIgnoreResolution(false) .setOcrParams(Array(&quot;preserve_interword_spaces=0&quot;)) val tokenizer = new HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) val visualDocumentNER = VisualDocumentNERv2 .pretrained(&quot;layoutlmv2_funsd&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols(Array(&quot;token&quot;, &quot;image&quot;)) val pipeline = new Pipeline() .setStages(Array( bin2imTransformer, ocr, tokenizer, visualDocumentNER )) val results = pipeline .fit(dataFrame) .transform(dataFrame) .select(&quot;entities&quot;) .cache() result.select(&quot;entities&quot;).show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) .setIgnoreResolution(False) .setOcrParams([&quot;preserve_interword_spaces=0&quot;]) tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) ner = VisualDocumentNerV2() .pretrained(&quot;layoutlmv2_funsd&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols([&quot;token&quot;, &quot;image&quot;]) .setOutputCol(&quot;entities&quot;) pipeline = PipelineModel(stages=[ binToImage, ocr, tokenizer, ner ]) result = pipeline.transform(df) result.withColumn(&#39;filename&#39;, path _array.getItem(f.size(path_array)- 1)) .withColumn(&quot;exploded_entities&quot;, f.explode(&quot;entities&quot;)) .select(&quot;filename&quot;, &quot;exploded_entities&quot;) .show(truncate=False) Output sample: ++-+ |filename |exploded_entities | ++-+ |form1.jpg|[entity, 0, 6, i-answer, [x -&gt; 1027, y -&gt; 89, height -&gt; 19, confidence -&gt; 96, word -&gt; Version:, width -&gt; 90], []] | |form1.jpg|[entity, 25, 35, b-header, [x -&gt; 407, y -&gt; 190, height -&gt; 37, confidence -&gt; 96, word -&gt; Institution, width -&gt; 241], []] | |form1.jpg|[entity, 37, 40, i-header, [x -&gt; 667, y -&gt; 190, height -&gt; 37, confidence -&gt; 96, word -&gt; Name, width -&gt; 130], []] | |form1.jpg|[entity, 42, 52, b-question, [x -&gt; 498, y -&gt; 276, height -&gt; 19, confidence -&gt; 96, word -&gt; Institution, width -&gt; 113], []]| |form1.jpg|[entity, 54, 60, i-question, [x -&gt; 618, y -&gt; 276, height -&gt; 19, confidence -&gt; 96, word -&gt; Address, width -&gt; 89], []] | ++-+ FormRelationExtractor FormRelationExtractor detect relation between keys and values detected by VisualDocumentNERv2. It can detect relations only for key/value in same line. Input Columns Param name Type Default Column Data Description inputCol String   Column name for entities Annotation Parameters Param name Type Default Description lineTolerance int 15 Line tolerance in pixels. This is the space between lines that will be assumed. It is used for grouping text regions by lines. keyPattern String question Pattern of entity name for keys in form. valuePattern String answer Pattern of entity name for values in form. Output Columns Param name Type Default Column Data Description outputCol string relations Name of output column with relation Annotations. Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; var dataFrame = spark.read.format(&quot;binaryFile&quot;).load(imagePath) var bin2imTransformer = new BinaryToImage() bin2imTransformer.setImageType(ImageType.TYPE_3BYTE_BGR) val ocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) .setIgnoreResolution(false) .setOcrParams(Array(&quot;preserve_interword_spaces=0&quot;)) val tokenizer = new HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) val visualDocumentNER = VisualDocumentNERv2 .pretrained(&quot;layoutlmv2_funsd&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols(Array(&quot;token&quot;, &quot;image&quot;)) val relExtractor = new FormRelationExtractor() .setInputCol(&quot;entities&quot;) .setOutputCol(&quot;relations&quot;) val pipeline = new Pipeline() .setStages(Array( bin2imTransformer, ocr, tokenizer, visualDocumentNER, relExtractor )) val results = pipeline .fit(dataFrame) .transform(dataFrame) .select(&quot;relations&quot;) .cache() results.select(explode(&quot;relations&quot;)).show(3, False) from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) .setIgnoreResolution(False) .setOcrParams([&quot;preserve_interword_spaces=0&quot;]) tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) ner = VisualDocumentNerV2() .pretrained(&quot;layoutlmv2_funsd&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols([&quot;token&quot;, &quot;image&quot;]) .setOutputCol(&quot;entities&quot;) rel_extractor = FormRelationExtractor() .setInputCol(&quot;entities&quot;) .setOutputCol(&quot;relations&quot;) pipeline = PipelineModel(stages=[ binToImage, ocr, tokenizer, ner, rel_extractor ]) result = pipeline.transform(df) result.select(explode(&quot;relations&quot;)).show(3, False) Output sample: ++ |col | ++ |[relation, 112, 134, Name: Dribbler, bbb, [bbox1 -&gt; 58 478 69 19, ...| |[relation, 136, 161, Study Date: 12-09-2006, 6:34, [bbox1 -&gt; 431 ... | |[relation, 345, 361, BP: 120 80 mmHg, [bbox1 -&gt; 790 478 30 19, ... | ++",
    "url": "/docs/en/ocr_visual_document_understanding",
    "relUrl": "/docs/en/ocr_visual_document_understanding"
  },
  "1309": {
    "id": "1309",
    "title": "Oncology - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/oncology",
    "relUrl": "/oncology"
  },
  "1310": {
    "id": "1310",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/package$$Feature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/package$$Feature.html"
  },
  "1311": {
    "id": "1311",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/recursive/package$$Recursive.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/recursive/package$$Recursive.html"
  },
  "1312": {
    "id": "1312",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/recursive/package$$RecursiveModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/recursive/package$$RecursiveModel.html"
  },
  "1313": {
    "id": "1313",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/package$$WordData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/package$$WordData.html"
  },
  "1314": {
    "id": "1314",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/params_getters_setters.html",
    "relUrl": "/api/python/modules/sparknlp/internal/params_getters_setters.html"
  },
  "1315": {
    "id": "1315",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/pos/perceptron.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/pos/perceptron.html"
  },
  "1316": {
    "id": "1316",
    "title": "Pipelines",
    "content": "",
    "url": "/docs/en/pipelines",
    "relUrl": "/docs/en/pipelines"
  },
  "1317": {
    "id": "1317",
    "title": "Playground",
    "content": "The Playground feature of the NLP Lab allows users to deploy and test models, rules, and/or prompts without going through the project setup wizard. This simplifies the initial resources exploration, and facilitates experiments on custom data. Any model, rule, or prompt can now be selected and deployed for testing by clicking on the “Open in Playground” button. Experiment with Rules Rules can be deployed to the Playground from the rules page. When a particular rule is deployed in the playground, the user can also change the parameters of the rules via the rule definition form from the right side of the page. After saving the changes users need to click on the “Deploy” button to refresh the results of the pre-annotation on the provided text. Experiment with Prompts NLP Lab’s Playground also supports the deployment and testing of prompts. Users can quickly test the results of applying a prompt on custom text, can easily edit the prompt, save it, and deploy it right away to see the change in the pre-annotation results. Experiment with Models Any Classification, NER or Assertion Status model available on the NLP Lab can also be deployed to Playground for testing on custom text. Deployment of models and rules is supported by floating and air-gapped licenses. Healthcare, Legal, and Finance models require a license with their respective scopes to be deployed in Playground. Unlike pre-annotation servers, only one playground can be deployed at any given time. Direct Navigation to Active Playground Sessions Navigating between multiple projects to and from the playground experiments can be necessary, especially when you want to revisit a previously edited prompt or rule. This is why NLP Lab Playground now allow users to navigate to any active Playground session without having to redeploy the server. This feature enables users to check how their resources (models, rules and prompts) behave at project level, compare the preannotation results with ground truth, and quickly get back to experiments for modifying prompts or rules without losing progress or spending time on new deployments. This feature makes experimenting with NLP prompts and rules in a playground more efficient, streamlined, and productive. Automatic Deployment of Updated Rules/Prompts Another benefit of experimenting with NLP prompts and rules in the playground is the immediate feedback that you receive. When you make changes to the parameters of your rules or to the questions in your prompts, the updates are deployed instantly. Manually deploying the server is not necessary any more for changes made to Rules/Prompts to be reflected in the preannotation results. Once the changes are saved, by simply clicking on the Test button, updated results are presented. This allows you to experiment with a range of variables and see how each one affects the correctness and completeness of the results. The real-time feedback and immediate deployment of changes in the playground make it a powerful tool for pushing the boundaries of what is possible with language processing. Playground Server Destroyed after 5 Minutes of Inactivity When active, the NLP playground consumes resources from your server. For this reason, NLP Lab defines an idle time limit of 5 minutes after which the playground is automatically destroyed. This is done to ensure that the server resources are not being wasted on idle sessions. When the server is destroyed, a message is displayed, so users are aware that the session has ended. Users can view information regarding the reason for the Playground’s termination, and have the option to restart by pressing the Restart button. Playground Servers use Light Pipelines The replacement of regular preannotation pipelines with Light Pipelines has a significant impact on the performance of the NLP playground. Light pipelines allow for faster initial deployment, quicker pipeline update and fast processing of text data, resulting in overall quicker results in the UI. Direct Access to Model Details Page on the Playground Another useful feature of NLP Lab Playground is the ability to quickly and easily access information on the models being used. This information can be invaluable for users who are trying to gain a deeper understanding of the model’s inner workings and capabilities. In particular, by click on the model’s name it is now possible to navigate to the NLP Models hub page. This page provides users with additional details about the model, including its training data, architecture, and performance metrics. By exploring this information, users can gain a better understanding of the model’s strengths and weaknesses, and use this knowledge to make more informed decisions on how good the model is for the data they need to annotate.",
    "url": "/docs/en/alab/playground",
    "relUrl": "/docs/en/alab/playground"
  },
  "1318": {
    "id": "1318",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/pos.html",
    "relUrl": "/api/python/modules/sparknlp/training/pos.html"
  },
  "1319": {
    "id": "1319",
    "title": "Pre-Annotation",
    "content": "Annotation Lab offers out-of-the-box support for Named Entity Recognition, Classification, Assertion Status, and Relations preannotations. These are extremely useful for bootstrapping any annotation project as the annotation team does not need to start the labeling from scratch but can leverage the existing knowledge transfer from domain experts to models. This way, the annotation efforts are significantly reduced. To run pre-annotation on one or several tasks, the Project Owner or the Manager must select the target tasks and click on the Pre-Annotate button from the top right side of the Tasks page. It will display a popup with information regarding the last deployment of the model server with the list of models deployed and the labels they predict. This information is crucial, especially when multiple users are doing training and deployment in parallel. So before doing preannotations on your tasks, carefully check the list of currently deployed models and their labels. If needed, users can deploy the models defined in the current project (based on the current Labeling Config) by clicking the Deploy button. After the deployment is complete, the preannotation can be triggered. Since Annotation Lab 3.0.0, multiple preannotation servers are available to preannotate the tasks of a project. The dialog box that opens when clicking the Pre-Annotate button on the Tasks page now lists available model servers in the options. Project Owners or Managers can now select the server to use. On selecting a model server, information about the configuration deployed on the server is shown on the popup so users can make an informed decision on which server to use. In case a pre-annotation server does not exist for the current project, the dialog box also offers the option to deploy a new server with the current project’s configuration. If this option is selected and enough resources are available (infrastructure capacity and a license if required) the server is deployed, and pre-annotation can be started. If there are no free resources, users can delete one or several existing servers from Clusters page under the Settings menu. Concurrency is not only supported between pre-annotation servers but also between training and pre-annotation. Users can have training running on one project and pre-annotation running on another project at the same time. Pre-annotation Approaches Pretrained Models On the Predefined Labels step of the Project Configuration page we can find the list of available models with their respective prediction labels. By selecting the relevant labels for your project and clicking the Add Label button you can add the predefined labels to your project configuration and take advantage of the Spark NLP auto labeling capabilities. In the example below, we are reusing the ner_posology model that comes with 7 labels related to drugs. In the same manner classification, assertion status or relation models can be added to the project configuration and used for pre-annotation purpose. Starting from version 4.3.0, Finance and Legal models downloaded from the Models Hub can be used for pre-annotation of NER, assertion status and classification projects. Visual NER models can now be downloaded from the NLP Models Hub, and used for pre-annotating image-based documents. Once you download the models from the Models Hub page, you can see the model’s label in the Predefined Label tab on the project configuration page. Rules Pre-annotation of NER projects can also be done using Rules. Rules are used to speed up the manual annotation process. Once a rule is defined, it is available for use in any project. However, for defining and running the rules we will need a [Healthcare NLP](/docs/en/licensed_install) license. In the example below, we are reusing the available rules for pre-annotation. Read more on how to create rules and reuse them to speed up the annotation process here. Text Pre-annotation Pre-annotation is available for projects with text contents as the tasks. When you setup a project to use existing Spark NLP models for pre-annotation, you can run the designated models on all of your tasks by pressing the Pre-Annotate button on the top-right corner of the Tasks page. As a result, all predicted labels for a given task will be available in the Prediction widget on the Labeling page. The predictions are not editable. You can only view and navigate those or compare those with older predictions. However, you can create a new completion based on a given prediction. All labels and relations from such a new completion are now editable. Visual Pre-annotation For running pre-annotation on one or several tasks, the Project Owner or the Manager must select the target tasks and can click on the Pre-Annotate button from the upper right side of the Tasks Page. It will display a popup with information regarding the last deployment of the model server, including the list of models deployed and the labels they predict. Known Limitations: When bulk pre-annotation runs on many tasks, the pre-annotation can fail due to memory issues. Pre-annotation currently works at the token level, and does not merge all tokens of a chunk into one entity. Pipeline Limitations Loading too many models in the pre-annotation server is not memory efficient and may not be practically required. Starting from version 1.8.0, Annotation Lab supports maximum of five different models to be used for the pre-annotation server deployment. Another restriction for Annotation Lab versions older than 4.2.0 is that two models trained on different embeddings cannot be used together in the same project. The Labeling Config will throw validation errors in any of the cases above, and we cannot save the configuration preventing pre-annotation server deployment.",
    "url": "/docs/en/alab/preannotation",
    "relUrl": "/docs/en/alab/preannotation"
  },
  "1320": {
    "id": "1320",
    "title": "The predict() function",
    "content": "predict() expects either a column named ‘text’ in the dataframe passed to it, or alternatively it will assume the first column of the dataframe passed to it as the column it should predict for. Predict method Parameters Output metadata The NLP predict method has a boolean metadata parameter. When it is set to True, it output the confidence and additional metadata for each prediction. Its default value is False. nlp.load(&#39;lang&#39;).predict(&#39;What a wonderful day!&#39;) Output Level parameter predict() defines 4 output levels for the generated predictions. The output levels define how granular the predictions and outputs will be. Depending on your goal, may need to be output level should be adjusted. Token level: Outputs one row for every token in the input. One to many mapping. Chunk level: Outputs one row for every chunk in the input. One to many mapping. Sentence level: Outputs one row for every sentence the input. One to many mapping. Relation level output: Outputs one row for every relation predicted, i.e. . One to many. Document level output: Outputs one row for every document in the input. One to one mapping. predict() will try to infer the most useful output level automatically if an output level is not specified. The inferred output level will usually define the last element of the pipeline. Take a look at the different output levels Demo which goes over all the output levels. Document output level example Every row in the input data frame will be mapped to one row in the output dataframe. # outputs 1 row for 1 input document nlp.load(&#39;sentiment&#39;).predict([&#39;I love data science! It is so much fun! It can also be quite helpful to people.&#39;, &#39;I love the city New-York&#39;], output_level=&#39;document&#39;) document id checked sentiment_confidence sentiment I love data science! It is so much fun! It can… 0 [I, love, data, science, !, It, is, so, much, … ] [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] I love the city New-York 1 [I, love, the, city, New-York] [0.7342000007629395] [positive] Sentence output level example Every sentence in each row becomes a new row in the output dataframe. # will detect the 2 sentences and output 2 rows, one for each of the sentences. nlp.load(&#39;sentiment&#39;).predict([&#39;I love data science! It is so much fun! It can also be quite helpful to people.&#39;, &#39;I love the city New-York&#39;], output_level=&#39;sentence&#39;) sentence sentiment_confidence sentiment id checked I love data science! [0.7540] positive 0 [I, love, data, science, !, It, is, so, much, …] It is so much fun! [0.6121] positive 0 [I, love, data, science, !, It, is, so, much, …] It can also be quite helpful to people. [0.4895] positive 0 [I, love, data, science, !, It, is, so, much, …] I love the city New-York [0.7342] positive 1 [I, love, the, city, New-York] Chunk output level example Every chunk in each input row becomes a new row in the output dataframe. This is useful for components like the Named Entity Resolver. By setting output level to chunk, you will ensure ever Named Entity becomes one row in your datset. Named Entities are chunks. # &#39;New York&#39; is a Chunk. A chunk is an object that consists of multiple tokens, but it&#39;s not a sentence. nlp.load(&#39;ner&#39;).predict([&#39;Angela Merkel and Donald Trump dont share many opinions&#39;, &quot;Ashley wants to visit the Brandenburger Tor in Berlin&quot;], output_level=&#39;chunk&#39;,) entities ner_tag embeddings Angela Merkel PERSON [[-0.563759982585907, 0.26958999037742615, 0.3…,] Donald Trump PERSON [[-0.563759982585907, 0.26958999037742615, 0.3…,] Ashley PERSON [[0.24997000396251678, -0.12275999784469604, -…,] the Brandenburger Tor FAC [[0.24997000396251678, -0.12275999784469604, -…,] Berlin GPE [[0.24997000396251678, -0.12275999784469604, -…,] Token output level example Every token in each input row becomes a new row in the output dataframe. # Every token in our sentence will become a row nlp.load(&#39;sentiment&#39;).predict([&#39;I love data science! It is so much fun! It can also be quite helpful to people.&#39;, &#39;I love the city New-York&#39;], output_level=&#39;token&#39;) token checked sentiment_confidence sentiment I I [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] love love [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] data data [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] science science [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] ! ! [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] It It [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] is is [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] so so [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] much much [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] fun fun [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] ! ! [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] It It [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] can can [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] also also [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] be be [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] quite quite [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] helpful helpful [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] to to [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] people people [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] . . [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] I I [0.7342000007629395] [positive] love love [0.7342000007629395] [positive] the the [0.7342000007629395] [positive] city city [0.7342000007629395] [positive] New-York New-York [0.7342000007629395] [positive] Output positions parameter By setting output_positions=True, the Dataframe generated will contain additional columns which describe the beginning and end of each feature inside of the original document. These additional _begining and _end columns let you infer the piece of the original input string that has been used to generate the output. If output level is set to a different output level than some features output level, the resulting features will be inside of lists If output level is set to the same output level as some feature, the generated positional features will be single integers positional : For token based components the positional features refer to the beginning and the end of the token inside the original document the text originates from. For sentence based components like sentence embeddings and different sentence classifiers the output of positional will describe the beginning and the end of the sentence that was used to generate the output. nlp.load(&#39;sentiment&#39;).predict(&#39;I love data science!&#39;, output_level=&#39;token&#39;, output_positions=True) checked checked_begin checked_end token id document_begin document_end sentence_begin sentence_end sentiment_confidence sentiment_begin sentiment_end sentiment I 0 0 I 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] love 2 5 love 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] data 7 10 data 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] science 12 18 science 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] ! 19 19 ! 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] Row origin inference for one to many mappings predict() will recycle the Pandas index from the input Dataframe. The index is useful if one row is mapped to many rows during prediction. The new rows which are generated from the input row will all have the same index as the original source row. I.e. if one sentence row gets split into many token rows, each token row will have the same index as the sentence row. NaN Handling Every NaN value is converted to a Python None variable which is reflected in the final dataframe If a column contains only NaN or None, it will be dropped Memory optimization recommendations Instead of passing your entire Pandas Dataframe to predict() you can pass only the columns which you need for later tasks. This saves memory and computation time and can be achieved like in the following example, which assumes latitude and longitude are irrelevant for later tasks. from johnsnowlabs import nlp import pandas as pd data = { &#39;tweet&#39;: [&#39;@CKL-IT the john snow labs library is awesome!&#39;, &#39;@MaziyarPanahi johnsnowlabs library is pretty cool&#39;, &#39;@JohnSnowLabs Try out the johnsnowlabs library!&#39;], &#39;tweet_location&#39;: [&#39;Berlin&#39;, &#39;Paris&#39;, &#39;United States&#39;], &#39;tweet_lattitude&#39; : [&#39;52.55035&#39;, &#39;48.858093&#39;, &#39;40.689247&#39;], &#39;tweet_longtitude&#39; : [&#39;13.39139&#39;, &#39;2.294694&#39;,&#39;-74.044502&#39;] } text_df = pd.DataFrame(data) nlp.load(&#39;sentiment&#39;).predict(text_df[[&#39;tweet&#39;,&#39;tweet_location&#39;]]) Supported data types predict() supports all of the common Python data types and formats Pandas Dataframes Spark Dataframes Modin with Dask backend Modin with Ray backend 1-D Numpy arrays of Strings Strings Arrays of Strings Single strings from johnsnowlabs import nlp nlp.load(&#39;sentiment&#39;).predict(&#39;This is just one string&#39;) Lists of strings from johnsnowlabs import nlp nlp.load(&#39;sentiment&#39;).predict([&#39;This is an array&#39;, &#39; Of strings!&#39;]) Pandas Dataframe One column must be named text and of object/string type or the first column will be used instead if no column named ‘text’ exists note : Passing the entire dataframe with additional features to the predict() method is very memory intensive. It is recommended to only pass the columns required for further downstream tasks to the predict() method. from johnsnowlabs import nlp import pandas as pd data = {&quot;text&quot;: [&#39;This day sucks&#39;, &#39;I love this day&#39;, &#39;I dont like Sami&#39;]} text_df = pd.DataFrame(data) nlp.load(&#39;sentiment&#39;).predict(text_df) Pandas Series One column must be named text and of object/string type note : This way is the most memory efficient way from johnsnowlabs import nlp import pandas as pd data = {&quot;text&quot;: [&#39;This day sucks&#39;, &#39;I love this day&#39;, &#39;I dont like Sami&#39;]} text_df = pd.DataFrame(data) nlp.load(&#39;sentiment&#39;).predict(text_df[&#39;text&#39;]) Spark Dataframe One column must be named text and of string type or the first column will be used instead if no column named ‘text’ exists from johnsnowlabs import nlp import pandas as pd data = {&quot;text&quot;: [&#39;This day sucks&#39;, &#39;I love this day&#39;, &#39;I dont like Sami&#39;]} text_pdf = pd.DataFrame(data) text_sdf = nlp.spark.createDataFrame(text_pdf) nlp.load(&#39;sentiment&#39;).predict(text_sdf) Modin Dataframe Supports Ray Dask backends One column must be named text and of string type or the first column will be used instead if no column named ‘text’ exists from johnsnowlabs import nlp import modin.pandas as pd data = {&quot;text&quot;: [&#39;This day sucks&#39;, &#39;I love this day&#39;, &#39;I don&#39;t like Sami&#39;]} text_pdf = pd.DataFrame(data) nlp.load(&#39;sentiment&#39;).predict(text_pdf)",
    "url": "/docs/en/jsl/predict_api",
    "relUrl": "/docs/en/jsl/predict_api"
  },
  "1321": {
    "id": "1321",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/pretrained/pretrained_pipeline.html",
    "relUrl": "/api/python/modules/sparknlp/pretrained/pretrained_pipeline.html"
  },
  "1322": {
    "id": "1322",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/pretrained_pipelines.html",
    "relUrl": "/api/python/user_guide/pretrained_pipelines.html"
  },
  "1323": {
    "id": "1323",
    "title": "Productionizing Spark NLP",
    "content": "Productionizing Spark NLP in Databricks This documentation page will describe how to use Databricks to run Spark NLP Pipelines for production purposes. About Databricks Databricks is an enterprise software company founded by the creators of Apache Spark. The company has also created MLflow, the Serialization and Experiment tracking library you can use (inside or outside databricks), as described in the section “Experiment Tracking”. Databricks develops a web-based platform for working with Spark, that provides automated cluster management and IPython-style notebooks. Their infrastructured is provided for training and production purposes, and is integrated in cloud platforms as Azure and AWS. Spark NLP is a proud partner of Databricks and we offer a seamless integration with them - see Install on Databricks. All Spark NLP capabilities run in Databricks, including MLFlow serialization and Experiment tracking, what can be used for serving Spark NLP for production purposes. About MLFlow MLFlow is a serialization and Experiment Tracking platform, which also natively suports Spark NLP. We have a documentation entry about MLFlow in the “Experiment Tracking” section. It’s highly recommended that you take a look before moving forward in this document, since we will use some of the concepts explained there. We will use MLFlow serialization to serve our Spark NLP models. Creating a cluster in Databricks As mentioned before, Spark NLP offers a seamless integration with Databricks. To create a cluster, please follow the instructions in Install on Databricks. That cluster can be then replicated (cloned) for production purposes later on. Configuring Databricks for Spark NLP and MLFlow In Databricks Runtime Version, select any Standard runtime, not ML ones.. These ones add their version of MLFlow, and some incompatibilities may arise. For this example, we have used 8.3 (includes Apache Spark 3.1.1, Scala 2.12) The cluster instantiated is prepared to use Spark NLP, but to make it production-ready using MLFlow, we need to add the MLFlow jar, in addition to the Spark NLP jar, as shown in the “Experiment Tracking” section. In that case, we did it instantiating adding both jars (&quot;spark.jars.packages&quot;:&quot; com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2,org.mlflow:mlflow-spark:1.21.0&quot;) into the SparkSession. However, in Databricks, you don’t instantiate programatically a session, but you configure it in the Compute screen, selecting your Spark NLP cluster, and then going to Configuration -&gt; Advanced Options -&gt; Sparl -&gt; Spark Config, as shown in the following image: In addition to Spark Config, we need to add the Spark NLP and MLFlow libraries to the Cluster. You can do that by going to Libraries inside your cluster. Make sure you have spark-nlp and mlflow. If not, you can install them either using PyPI or Maven artifacts. In the image below you can see the PyPI alternative: Creating a notebook You are ready to create a notebook in Databricks and attach it to the recently created cluster. To do that, go to Create - Notebook, and select the cluster you want in the dropdown above your notebook. Make sure you have selected the cluster with the right Spark NLP + MLFlow configuration. To check everything is ok, run the following lines: 1) To check the session is running: spark 2) To check jars are in the session: spark.sparkContext.getConf().get(&#39;spark.jars.packages&#39;) You should see the following output from the last line (versions may differ depending on which ones you used to configure your cluster) Out[2]: &#39;com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2,org.mlflow:mlflow-spark:1.21.0&#39; Logging the experiment in Databricks using MLFlow As explained in the “Experiment Tracking” section, MLFlow can log Spark MLLib / NLP Pipelines as experiments, to carry out runs on them, track versions, etc. MLFlow is natively integrated in Databricks, so we can leverage the mlflow.spark.log_model() function of the Spark flavour of MLFlow, to start tracking our Spark NLP pipelines. Let’s first import our libraries… import mlflow import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline import pandas as pd from sparknlp.training import CoNLL import pyspark from pyspark.sql import SparkSession Then, create a Lemmatization pipeline: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) lemmatizer = LemmatizerModel.pretrained() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;prediction&quot;) # It&#39;s mandatory to call it prediction pipeline = Pipeline(stages=[ documentAssembler, tokenizer, lemmatizer ]) IMPORTANT: Last output column of the last component in the pipeline should be called prediction. Finally, let’s log the experiment. In the “Experiment Tracking” section, we used the pip_requirements parameter in the log_model() function to set the required libraries: But we mentioned using conda is also available. Let’s use conda in this example: conda_env = { &#39;channels&#39;: [&#39;conda-forge&#39;], &#39;dependencies&#39;: [ &#39;python=3.8.8&#39;, { &quot;pip&quot;: [ &#39;pyspark==3.1.1&#39;, &#39;mlflow==1.21.0&#39;, &#39;spark-nlp==3.3.2&#39; ] } ], &#39;name&#39;: &#39;mlflow-env&#39; } With this conda environment, we are ready to log our pipeline: mlflow.spark.log_model(p_model, &quot;lemmatizer&quot;, conda_env=conda_env) You should see an output similar to this one: (6) Spark Jobs (1) MLflow run Logged 1 run to an experiment in MLflow. Learn more Experiment UI On the top right corner of your notebook, you will see the Experiment widget, and inside, as shown in the image below. You can also access Experiments UI if you switch your environment from “Data Science &amp; Engineering” to “Machine Learning”, on the left panel… … or clicking on the “experiment” word in the cell output (it’s a link!) Once in the experiment UI, you will see the following screen, where your experiments are tracked. If you click on the Start Time cell of your experiment, you will reach the registered MLFlow run. On the left panel you will see the MLFlow model and some other artifacts, as the conda.yml and pip_requirements.txt that manage the dependencies of your models. On the right panel, you will see two snippets, about how to call to the model for inference internally from Databricks. 1) Snippet for calling with a Pandas Dataframe: import mlflow logged_model = &#39;runs:/a8cf070528564792bbf66d82211db0a0/lemmatizer&#39; # Load model as a Spark UDF. loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model) # Predict on a Spark DataFrame. columns = list(df.columns) df.withColumn(&#39;predictions&#39;, loaded_model(*columns)).collect() 2) Snippet for calling with a Spark Dataframe. We won’t include it in this documentation because that snippet does not include SPark NLP specificities. To make it work, the correct snippet should be: import mlflow logged_model = &#39;runs:/a8cf070528564792bbf66d82211db0a0/lemmatizer&#39; loaded_model = mlflow.pyfunc.load_model(model_uri=logged_model) # Predict on a Spark DataFrame. res_spark = loaded_model.predict(df_1_spark.rdd) IMPORTANT: You will only get the last column (prediction) results, which is a list of Rows of Annotation Types. To convert the result list into a Spark Dataframe, use the following schema: import pyspark.sql.types as T import pyspark.sql.functions as f annotationType = T.StructType([ T.StructField(&#39;annotatorType&#39;, T.StringType(), False), T.StructField(&#39;begin&#39;, T.IntegerType(), False), T.StructField(&#39;end&#39;, T.IntegerType(), False), T.StructField(&#39;result&#39;, T.StringType(), False), T.StructField(&#39;metadata&#39;, T.MapType(T.StringType(), T.StringType()), False), T.StructField(&#39;embeddings&#39;, T.ArrayType(T.FloatType()), False) ]) And then, get the results (for example, in res_spark) and apply the schema: spark_res = spark.createDataFrame(res_pandas[0], schema=annotationType) Calling the experiment for production purposes 1. Internally, if the data is in Databricks If your data lies in Datalake, in Spark Tables, or any other internal storage in Databricks, you just need to use the previous snippets (depending if you want to use Pandas or Spark Dataframes), and you are ready to go. Example for Spark Dataframes: Try to use Spark Dataframes by default, since converting from Spark Dataframes into Pandas triggers a collect() first, removing all the parallelism capabilities of Spark Dataframes. The next logical step is to create Notebooks to be called programatically using the snippets above, running into production clusters. There are two ways to do this: using Batch Inference or using Jobs. 2. Internally, using Batch Inference (with Spark Tables) If we come back to the experiment ui, you will see, above the Pandas and Spark snippets, a button with the text “Register Model”. If you do that, you will register the experiment to be called externally, either for Batch Inference or with a REST API (we will get there!). After clicking the Register Model button, you will see a link instead of the button, that will enabled after some seconds. By clicking that link, you will be redirected to the Model Inference screen. This new screen has a button on the top right, that says “Use model for inference”. By clicking on it, you will see two options: Batch Inference or REST API. Batch inference requires a Spark Table for input, and another for output, and after configuring them, what you will see is an auto-generated notebook to be executed on-demand, programatically or with crons, that is prepared to load the environment and do the inference, getting the text fron the input table and storing the results in the output table. This is an example of how the notebook looks like: 3. Externally, with the MLFlow Serve REST API Instead of chosing a Batch Inference, you can select REST API. This will lead you to another screen, when the model will be loaded for production purposes in an independent cluster. Once deployed, you will be able to: 1) Check the endpoint URL to consume the model externally; 2) Test the endpoint writing a json (in our example, ‘text’ is our first input col of the pipeline, so it shoud look similar to: {&quot;text&quot;: &quot;This is a test of how the lemmatizer works&quot;} You can see the response in the same screen. 3) Check what is the Python code or cURL command to do that very same thing programatically. By just using that Python code, you can already consume it for production purposes from any external web app. IMPORTANT: As per 26/11/2021, there is an issue being studied by Databricks team, regarding the creation on the fly of job clusters to serve MLFlow models. There is not a way to configure the Spark Session, so the jars are not loaded and the model fails to start. This will be fixed in later versions of Databricks. In the meantime, see a workaround in point 4. 4. Databricks Jobs asynchronous REST API Creating the notebook for the job And last, but not least, another approach to consume models for production purposes. the Jobs API. Databricks has its own API for managing jobs, that allows you to instantiate any notebook or script as a job, run it, stop it, and manage all the life cycle. And you can configure the cluster where this job will run before hand, what prevents having the issue described in point 3. To do that: 1) Create a new production cluster, as described before, cloning you training environment but adapting it to your needs for production purposes. Make sure the Spark Config is right, as described at the beginning of this documentation. 2) Create a new notebook. Always check that the jars are in the session: spark.sparkContext.getConf().get(&#39;spark.jars.packages&#39;) 3) Add the Spark NLP imports. import mlflow import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline import pandas as pd from sparknlp.training import CoNLL import pyspark from pyspark.sql import SparkSession import pyspark.sql.types as T import pyspark.sql.functions as f import json 4) Let’s define that an input param called text will be sent in the request. Let’s get the text from that parameter using dbutils. input = &quot;&quot; try: input = dbutils.widgets.get(&quot;text&quot;) print(&#39;&quot;text&quot; input found: &#39; + input) except: print(&#39;Unable to run: dbutils.widgets.get(&quot;text&quot;). Setting it to NOT_SET&#39;) input = &quot;NOT_SET&quot; Right now, the input text will be in input var. You can trigger an exception or set the input to some default value if the parameter does not come in the request. 5) Let’s create a Spark Dataframe with the input df = spark.createDataFrame([[input]]).toDF(&#39;text&#39;) 6) And now, we just need to use the snippet for Spark Dataframe to consume MLFlow models, described above: import mlflow logged_model = &#39;runs:/a8cf070528564792bbf66d82211db0a0/lemmatizer&#39; loaded_model = mlflow.pyfunc.load_model(model_uri=logged_model) # Predict on a Spark DataFrame. res_spark = loaded_model.predict(df_1_spark.rdd) import pyspark.sql.types as T import pyspark.sql.functions as f annotationType = T.StructType([ T.StructField(&#39;annotatorType&#39;, T.StringType(), False), T.StructField(&#39;begin&#39;, T.IntegerType(), False), T.StructField(&#39;end&#39;, T.IntegerType(), False), T.StructField(&#39;result&#39;, T.StringType(), False), T.StructField(&#39;metadata&#39;, T.MapType(T.StringType(), T.StringType()), False), T.StructField(&#39;embeddings&#39;, T.ArrayType(T.FloatType()), False) ]) spark_res = spark.createDataFrame(res_spark[0], schema=annotationType) 7) Let’s transform our lemmatized tokens from the Dataframe into a list of strings: l = spark_res.select(&quot;result&quot;).collect() txt_results = [x[&#39;result&#39;] for x in l] 8) And finally, let’s use again dbutils to tell Databricks to spin off the run and return an exit parameter: the list of token strings. dbutils.notebook.exit(json.dumps({ &quot;status&quot;: &quot;OK&quot;, &quot;results&quot;: txt_results })) Configuring the job Last, but not least. We need to precreate the job, so that we run it from the API. We could do that using the API as well, but we will show you how to do it using the UI. On the left panel, go to Jobs and then Create Job. In the jobs screen, you will see you job created. It’s not running, it’s prepared to be called on demand, programatically or in the interface, with a text input param. Let’s see how to do that: Running the job 1) In the jobs screen, if you click on the job, you will enter the Job screen, and be able to set your text input parameter and run the job manually. You can use this for testing purpores, but the interesting part is calling it externally, using the Databricks Jobs API. 2) Using the Databricks Jobs API, from for example, Postman. POST HTTP request URL: https://[your_databricks_instance]/api/2.1/jobs/run-now Authorization: [use Bearer Token. You can get it from Databricks, Settings, User Settings, Generate New Token.] Body: { &quot;job_id&quot;: [job_id, check it in the Jobs screen], &quot;notebook_params&quot;: {&quot;text&quot;: &quot;This is an example of how well the lemmatizer works&quot;} } As it’s an asynchronous call, it will return the number a number of run, but no results. You will need to query for results using the number of the run and the following url https://[your_databricks_instance]/2.1/jobs/runs/get-output You will get a big json, but the most relevant info, the output, will be up to the end: {&quot;notebook_output&quot;: { &quot;status&quot;: &quot;OK&quot;, &quot;results&quot;: [&quot;This&quot;, &quot;is&quot;, &quot;a&quot;, &quot;example&quot;, &quot;of&quot;, &quot;how&quot;, &quot;lemmatizer&quot;, &quot;work&quot;] }} The notebook will be prepared in the job, but idle, until you call it programatically, what will instantiate a run. Check the Jobs API for more information about what you can do with it and how to adapt it to your solutions for production purposes. Productionizing Spark NLP using Synapse ML This is the first article of the “Serving Spark NLP via API” series, showcasing how to serve Sparkl NLP using Synapse ML and Fast API. There is another article in this series, that showcases how to serve Spark NLP using Databricks Jobs and MLFlow Rest APIs, available here. Background Spark NLP is a Natural Language Understanding Library built on top of Apache Spark, leveranging Spark MLLib pipelines, that allows you to run NLP models at scale, including SOTA Transformers. Therefore, it’s the only production-ready NLP platform that allows you to go from a simple PoC on 1 driver node, to scale to multiple nodes in a cluster, to process big amounts of data, in a matter of minutes. Before starting, if you want to know more about all the advantages of using Spark NLP (as the ability to work at scale on air-gapped environments, for instance) we recommend you to take a look at the following resources: John Snow Labs webpage; The official technical documentation of Spark NLP; Spark NLP channel on Medium; Also, follow Veysel Kocaman, Data Scientist Lead and Head of Spark NLP for Healthcare, for the latests tips. Motivation Spark NLP is server-agnostic, what means it does not come with an integrated API server, but offers a lot of options to serve NLP models using Rest APIs. This is first of a series of 2 articles that explain four options you can use to serve Spark NLP models via Rest API: Using Microsoft’s Synapse ML; Using FastAPI and LightPipelines; Using Databricks Batch API (see Part 2/2 here); Using MLFlow serve API in Databricks (see Part 2/2 here); All of them have their Strengths and weaknesses, so let’s go over them in detail. Microsoft’s Synapse ML Synapse ML (previously named SparkMML) is, as they state in their official webpage: … an ecosystem of tools aimed towards expanding the distributed computing framework Apache Spark in several new directions. They offer a seamless integratation with OpenCV, LightGBM, Microsoft Cognitive Tool and, the most relevant for our use case, Spark Serving, an extension of *Spark Streaming *with an integrated server and a Load Balancer, that can attend multiple requests via Rest API, balance and attend them leveraging the capabilities of a Spark Cluster. That means that you can sin up a server and attend requests that will be distributed transparently over a Spark NLP cluster, in a very effortless way. Strengths Ready-to-use server Includes a Load Balancer Distributes the work over a Spark Cluster Can be used for both Spark NLP and Spark OCR Weaknesses For small use cases that don’t require big cluster processing, other approaches may be faster (as FastAPI using LightPipelines) Requires using an external Framework This approach does not allow you to customize your endpoints, it uses Synapse ML ones How to set up Synapse ML to serve Spark NLP pipelines We will skip here how to install Spark NLP. If you need to do that, please follow this official webpage about how to install Spark NLP or, if Spark NLP for Healthcare if you are using the Healthcare library. Synapse ML recommends using at least Spark 3.2, so first of all, let’s configure the Spark Session with the required jars packages(both for Synapse ML and Spark) with the the proper Spark version (take a look at the suffix spark-nlp-spark32) and also, very important, add to jars.repository the Maven repository for SynapseML. **sparknlpjsl_jar =** &quot;spark-nlp-jsl.jar&quot; **from** pyspark.sql **import** SparkSession **spark =** *SparkSession***.**builder **.**appName(&quot;Spark&quot;) **.**master(&quot;local[*]&quot;) **.***config*(&quot;spark.driver.memory&quot;, &quot;16G&quot;) **.***config*(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;) **.***config*(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;) **.***config*(&quot;**spark.jars.packages**&quot;, &quot;com.microsoft.azure:synapseml_2.12:0.9.5,com.johnsnowlabs.nlp:spark-nlp-spark32_2.12:3.4.0&quot;) **.***config*(&quot;**spark.jars**&quot;, sparknlpjsl_jar) **.***config*(&quot;**spark.jars.repositories**&quot;, &quot;https://mmlspark.azureedge.net/maven&quot;) **.**getOrCreate() After the initialization, add your required imports (Spark NLP) and add to them the SynapseML-specific ones: **import** sparknlp **import** sparknlp_jsl ... **import** synapse.ml **from** synapse.ml.io **import** ***** Now, let’s create a Spark NLP for Healthcare pipeline to carry out Entity Resolution. **document_assembler =** *DocumentAssembler*() **.**setInputCol(&quot;text&quot;) **.**setOutputCol(&quot;document&quot;) **sentenceDetectorDL =** *SentenceDetectorDLModel***.**pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &#39;clinical/models&#39;) **.**setInputCols([&quot;document&quot;]) **.**setOutputCol(&quot;sentence&quot;) **tokenizer =** *Tokenizer*() **.**setInputCols([&quot;sentence&quot;]) **.**setOutputCol(&quot;token&quot;) **word_embeddings =** *WordEmbeddingsModel***.**pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) **.**setInputCols([&quot;sentence&quot;, &quot;token&quot;]) **.**setOutputCol(&quot;word_embeddings&quot;) **clinical_ner =** *MedicalNerModel***.**pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) **.**setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) **.**setOutputCol(&quot;ner&quot;) **ner_converter_icd =** *NerConverterInternal*() **.**setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) **.**setOutputCol(&quot;ner_chunk&quot;) **.**setWhiteList([&#39;PROBLEM&#39;]) **.**setPreservePosition(**False**) **c2doc =** *Chunk2Doc*() **.**setInputCols(&quot;ner_chunk&quot;) **.**setOutputCol(&quot;ner_chunk_doc&quot;) **sbert_embedder =** *BertSentenceEmbeddings***.**pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) **.**setInputCols([&quot;ner_chunk_doc&quot;]) **.**setOutputCol(&quot;sentence_embeddings&quot;) **.**setCaseSensitive(**False**) **icd_resolver =** *SentenceEntityResolverModel***.**pretrained(&quot;sbiobertresolve_icd10cm_augmented_billable_hcc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) **.**setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) **.**setOutputCol(&quot;icd10cm_code&quot;) **.**setDistanceFunction(&quot;EUCLIDEAN&quot;) **resolver_pipeline =** *Pipeline*( stages **=** [ document_assembler, sentenceDetectorDL, tokenizer, word_embeddings, clinical_ner, ner_converter_icd, c2doc, sbert_embedder, icd_resolver ]) Let’s use a clinical note to test Synapse ML. **clinical_note =** &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting. Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection. She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation. Physical examination on presentation was significant for dry oral mucosa; significantly, her abdominal examination was benign with no tenderness, guarding, or rigidity.&quot;&quot;&quot; Since SynapseML serves a RestAPI, we will be sending JSON requests. Let’s define a simple json with the clinical note: **data_json =** {&quot;*text*&quot;: clinical_note } Now, let’s spin up a server using Synapse ML Spark Serving. It will consist of: a streaming server that will receive a json and transform it into a Spark Dataframe a call to Spark NLP transform on the dataframe, using the pipeline a write operation returning the output also in json format. #1: Creating the streaming server and transforming json to Spark Dataframe serving_input = spark.readStream.server() .address(“localhost”, 9999, “benchmark_api”) .option(“name”, “benchmark_api”) .load() .parseRequest(“benchmark_api”, data.schema) #2: Applying transform to the dataframe using our Spark NLP pipeline serving_output = resolver_p_model.transform(serving_input) .makeReply(“icd10cm_code”) #3: Returning the response in json format server = serving_output.writeStream .server() .replyTo(“benchmark_api”) .queryName(“benchmark_query”) .option(“checkpointLocation”, “file:///tmp/checkpoints-{}”.format(uuid.uuid1())) .start() And we are ready to test the endpoint using the requests library. **import** requests res **=** requests**.**post(&quot;http://localhost:9999/benchmark_api&quot;, data= json**.**dumps(data_json)) And last, but not least, let’s check the results: **for** i **in** range (0, len(response_list**.**json())): print(response_list**.**json()[i][&#39;result&#39;]) &gt;&gt;O2441 O2411 P702 K8520 B159 E669 Z6841 R35 R631 R630 R111... Productionizing Spark NLP using FastAPI and LightPipelines FastAPI is, as defined by the creators… …a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints. FastAPI provides with a very good latency and response times that, all along witht the good performance of Spark NLP LightPipelines, makes this option the quickest one of the four described in the article. Read more about the performance advantages of using *LightPipelines *in this article created by John Snow Labs Data Scientist Lead Veysel Kocaman. Strengths Quickest approach Adds flexibility to build and adapt a custom API for your models Weaknesses LightPipelines are executed sequentially and don’t leverage the distributed computation that Spark Clusters provide. As an alternative, you can use FastAPI with default pipelines and a custom LoadBalancer, to distribute the calls over your cluster nodes. You can serve SparkNLP + FastAPI on Docker. To do that, we will create a project with the following files: Dockerfile: Image for creating a SparkNLP + FastAPI Docker image requirements.txt: PIP Requirements entrypoint.sh: Dockerfile entrypoint content/: folder containing FastAPI webapp and SparkNLP keys content/main.py: FastAPI webapp, entrypoint content/sparknlp_keys.json: SparkNLP keys (for Healthcare or OCR) Dockerfile The aim of this file is to create a suitable Docker Image with all the OS and Python libraries required to run SparkNLP. Also, adds a entry endpoint for the FastAPI server (see below) and a main folder containing the actual code to run a pipeline on an input text and return the expected values. **FROM **ubuntu:18.04 **RUN **apt-get update &amp;&amp; apt-get -y update **RUN **apt-get -y update &amp;&amp; apt-get install -y wget &amp;&amp; apt-get install -y jq &amp;&amp; apt-get install -y lsb-release &amp;&amp; apt-get install -y openjdk-8-jdk-headless &amp;&amp; apt-get install -y build-essential python3-pip &amp;&amp; pip3 -q install pip --upgrade &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* /usr/share/man /usr/share/doc /usr/share/doc-base **ENV **PYSPARK_DRIVER_PYTHON=python3 **ENV **PYSPARK_PYTHON=python3 **ENV **LC_ALL=C.UTF-8 **ENV **LANG=C.UTF-8 **# We expose the FastAPI default port 8515** **EXPOSE **8515 **# Install all Python required libraries** **COPY **requirements.txt / **RUN **pip install -r /requirements.txt **# Adds the entrypoint to the FastAPI server** **COPY **entrypoint.sh / **RUN **chmod +x /entrypoint.sh **# In /content folder we will have our main.py and the license files COPY **./content/ /content/ **WORKDIR **content/ **# We tell Docker to run this file when a container is instantiated** **ENTRYPOINT **[&quot;/entrypoint.sh&quot;] requirements.txt This file describes which Python libraries will be required when creating the Docker image to run Spark NLP on FastAPI. **pyspark**==3.1.2 **fastapi**==0.70.1 **uvicorn**==0.16 **wget**==3.2 **pandas**==1.4.1 entrypoint.sh This file is the entry point of our Docker container, which carries out the following actions: Takes the sparknlp_keys.json and exports its values as environment variables, as required by Spark NLP for Healthcare. Installs the proper version of Spark NLP for Healthcare, getting the values from the license keys we have just exported in the previous step. Runs the main.py file, that will load the pipelines and create and endpoint to serve them. #!/bin/bash *# Load the license from sparknlp_keys.json and export the values as OS variables **export_json* () { for s in $(echo $values | jq -r ‘to_entries|map(“(.key)=(.value|tostring)”)|.[]’ $1 ); do export $s done } **export_json **“/content/sparknlp_keys.json” **# Installs the proper version of Spark NLP for Healthcare pip install **–upgrade spark-nlp-jsl==$JSL_VERSION –user –extra-index-url https://pypi.johnsnowlabs.com/$SECRET if [ $? != 0 ]; then exit 1 fi **# Script to create FastAPI endpoints and preloading pipelines for inference python3 **/content/main.py content/main.py: Serving 2 pipelines in a FastAPI endpoint To maximize the performance and minimize the latency, we are going to store two Spark NLP pipelines in memory, so that we load only once (at server start) and we just use them everytime we get an API request to infer. To do this, let’s create a content/main.py Python script to download the required resources, store them in memory and serve them in Rest API endpoints. First, the import section **import** uvicorn, json, os **from** fastapi **import** FastAPI **from** sparknlp.annotator **import** ***** **from **sparknlp_jsl.annotator **import ******* **from** sparknlp.base **import** ***** **import **sparknlp, sparknlp_jsl **from **sparknlp.pretrained **import** PretrainedPipeline app **=** FastAPI() pipelines **=** {} Then, let’s define the endpoint to serve the pipeline: **@app.get(&quot;/benchmark/pipeline&quot;)** **async** **def** get_one_sequential_pipeline_result(modelname, text**=**&#39;&#39;): **return** pipelines[modelname]**.**annotate(text) Then, the startup event to preload the pipelines and start a Spark NLP Session: **@app.on_event(&quot;startup&quot;)** **async** **def** startup_event(): **with** open(&#39;/content/sparknlp_keys.json&#39;, &#39;r&#39;) **as** f: license_keys **=** json**.**load(f) ** spark =** sparknlp_jsl**.**start(secret**=**license_keys[&#39;SECRE **pipelines**[&#39;ner_profiling_clinical&#39;] **=** *PretrainedPipeline*(&#39;ner_profiling_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) **pipelines**[&#39;clinical_deidentification&#39;] **=** *PretrainedPipeline*(&quot;clinical_deidentification&quot;, &quot;en&quot;, &quot;clinical/models&quot;) Finally, let’s run a uvicorn server, listening on port 8515 to the endpoints declared before: **if __name__ == &quot;__main__&quot;:** uvicorn**.**run(&#39;main:app&#39;, host**=**&#39;0.0.0.0&#39;, port**=**8515) content/sparknlp_keys.json For using Spark NLP for Healthcare, please add your Spark NLP for Healthcare license keys to content/sparknlp_keys.jsonDThe file is ready, you only need to fulfill with your own values taken from the json file John Snow Labs has provided you with. { &quot;**AWS_ACCESS_KEY_ID**&quot;: &quot;&quot;, &quot;**AWS_SECRET_ACCESS_KEY**&quot;: &quot;&quot;, &quot;**SECRET**&quot;: &quot;&quot;, &quot;**SPARK_NLP_LICENSE**&quot;: &quot;&quot;, &quot;**JSL_VERSION**&quot;: &quot;&quot;, &quot;**PUBLIC_VERSION**&quot;: &quot;&quot; } And now, let’s run the server! Creating the Docker image and running the container docker build -t johnsnowlabs/sparknlp:sparknlp_api . **docker run **-v jsl_keys.json:/content/sparknlp_keys.json -p 8515:8515 -it johnsnowlabs/sparknlp:sparknlp_api 2. Consuming the API using a Python script Lets import some libraries **import** requests **import** time Then, let’s create a clinical note **ner_text =** &quot;&quot;&quot; *A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting. The patient was prescribed 1 capsule of Advil 10 mg for 5 days and magnesium hydroxide 100mg/1ml suspension PO. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day.* &quot;&quot;&quot; We have preloaded and served two Pretrained Pipelines: clinical_deidentification and ner_profiling_clinical . In modelname, let’s set which one we want to check # Change this line to execute any of the two pipelines **modelname =** &#39;*clinical_deidentification*&#39; *# modelname = &#39;ner_profiling_clinical&#39;* And finally, let’s use the requestslibrary to send a test request to the endpoint and get the results. **query =** f&quot;?modelname={modelname}&amp;text={ner_text}&quot; **url =** f&quot;http://localhost:8515/benchmark/pipeline{query}&quot; **print**(requests**.**get(url)) &gt;&gt; {&#39;sentence&#39;: ..., &#39;masked&#39;: ..., &#39;ner_chunk&#39;: ..., } You can also prettify the json using the following function with the result of the annotate() function: **def explode_annotate(ann_result):** &#39;&#39;&#39; Function to convert result object to json input: raw result output: processed result dictionary &#39;&#39;&#39; result = {} for column, ann in ann_result[0].items(): result[column] = [] for lines in ann: content = { &quot;result&quot;: lines.result, &quot;begin&quot;: lines.begin, &quot;end&quot;: lines.end, &quot;metadata&quot;: dict(lines.metadata), } result[column].append(content) return result",
    "url": "/docs/en/production-readiness",
    "relUrl": "/docs/en/production-readiness"
  },
  "1324": {
    "id": "1324",
    "title": "Productivity",
    "content": "Analytics Charts By default, the Analytics page is disabled for every project because computing the analytical charts is a resource-intensive task and might temporarily influence the responsiveness of the application, especially when triggered in parallel with other training/preannotation jobs. However, users can file a request to enable the Analytics page which can be approved by any admin user. The request is published on the Analytics Requests page, visible to any admin user. Once the admin user approves the request, any team member can access the Analytics page. A refresh button is present on the top-right corner of the Analytics page. The Analytics charts doesn’t automatically reflect the changes made by the annotators (like creating tasks, adding new completion, etc.). Updating the analytics to reflect the latest changes can be done using the refresh button. Task Analytics To access Task Analytics, navigate on the first tab of the Analytics Dashboard, called Tasks. The following blog post explains how to Improve Annotation Quality using Task Analytics in the Annotation Lab. Below are the charts included in the Tasks section. Total number of task in the Project Total number of task in a Project in last 30 days Breakdown of task in the Project by Status Breakdown of task by author Summary of task status for each annotator Total number of label occurrences across all completions Average number of label occurrences for each completion Total number of label occurrences across all completions for each annotator Total vs distinct count of labels across all completions Average number of tokens by label Total number of label occurrences that include numeric values Team Productivity To access Team Productivity charts, navigate on the second tab of the Analytics Dashboard, called Team Productivity. The following blog post explains how to Keep Track of Your Team Productivity in the Annotation Lab. Below are the charts included in the Team Productivity section. Total number of completions in the Project Total number of completions in the Project in the last 30 days Total number of completions for each Annotator Total number of completions submitted over time for each Annotator Average time spent by the Annotator in each task Total number of completions submitted over time Inter-Annotator Agreement (IAA) Starting from version 2.8.0, Inter Annotator Agreement(IAA) charts allow the comparison between annotations produced by Annotators, Reviewers, or Managers. Inter Annotator Agreement charts can be used by Annotators, Reviewers, and Managers for identifying contradictions or disagreements within the starred completions (Ground Truth). When multiple annotators work on same tasks, IAA charts are handy to measure how well the annotations created by different annotators align. IAA chart can also be used to identify outliers in the labeled data, or to compare manual annotations with model predictions. To access IAA charts, navigate on the third tab of the Analytics Dashboard of NER projects, called Inter-Annotator Agreement. Several charts should appear on the screen with a default selection of annotators to compare. The dropdown selections on top-left corner of each chart allow you to change annotators for comparison purposes. There is another dropdown to select the label type for filtering between NER labels and Assertion Status labels for projects containing both NER and Assertion Status entities. It is also possible to download the data generated for some chart in CSV format by clicking the download button just below the dropdown selectors. Note: Only the Submitted and starred (Ground Truth) completions are used to render these charts. The following blog post explains how your team can Reach Consensus Faster by Using IAA Charts in the Annotation Lab. Below are the charts included in the Inter-Annotator Agreement section. High-level IAA between annotators on all common tasks IAA between annotators for each label on all common tasks Comparison of annotations by annotator on each chunk Comparison of annotations by model and annotator (Ground Truth) on each chunk All chunks annotated by an annotator Frequency of labels on chunks annotated by an annotator Frequency of a label on chunks annotated by each annotator Download data used for charts CSV file for specific charts can be downloaded using the new download button which will call specific API endpoints: /api/projects/{project_name}/charts/{chart_type}/download_csv",
    "url": "/docs/en/alab/productivity",
    "relUrl": "/docs/en/alab/productivity"
  },
  "1325": {
    "id": "1325",
    "title": "Project Configuration",
    "content": "Annotation Lab currently supports multiple predefined project configurations. The most popular ones are Text Classification, Named Entity Recognition (NER) and Visual NER. Create a setup from scratch or customize a predefined one according to your needs. For customizing a predefined configuration, click on the corresponding link in the table above and then navigate to the Labeling configuration tab and manually edit or update it to contain the labels you want. After you finish editing the labels you want to define for your project click the “Save” button. Project templates We currently support multiple predefined project configurations. The most popular ones are Text Classification, Named Entity Recognition and Visual NER. Content Type The first step when creating a new project or customizing an existing one is to choose what content you need to annotate. Five content types are currently supported: Video, Audio, HTML, Image, PDF and Text. For each content type a list of available templates is available. You can pick any one of those as a starting point in your project configuration. For customizing a predefined configuration, choose a Content Type and then a template from the list. Then navigate to the Customize Labels tab and manually edit/update the configuration to contain the labels you need. Users can add custom labels and choices in the project configuration from the Visual tab for both text and Visual NER projects. After you finish editing the labels click the “Save” button. Named Entity Recognition Named Entity Recognition (NER) refers to the identification and classification of entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc. The Annotation Lab offers support for two types of labels: Simple labels for NER or assertion models; Binary relations for relation extraction models. Assertion Labels The syntax for defining an Assertion Status label is the same as for the NER labels, with an additional attribute - assertion which should be set to true (see example below). This convention is defined by Annotation Lab users which we exploited for identifying the labels to include in the training and prediction of Assertion Models. A simple Labeling Config with Assertion Status defined should look like the following: &lt;View&gt; &lt;Labels name=&quot;ner&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;Medicine&quot; background=&quot;orange&quot; hotkey=&quot;_&quot;/&gt; &lt;Label value=&quot;Condition&quot; background=&quot;orange&quot; hotkey=&quot;_&quot;/&gt; &lt;Label value=&quot;Procedure&quot; background=&quot;green&quot; hotkey=&quot;8&quot;/&gt; &lt;Label value=&quot;Absent&quot; assertion=&quot;true&quot; background=&quot;red&quot; hotkey=&quot;Z&quot;/&gt; &lt;Label value=&quot;Past&quot; assertion=&quot;true&quot; background=&quot;red&quot; hotkey=&quot;X&quot;/&gt; &lt;/Labels&gt; &lt;View style=&quot;height: 250px; overflow: auto;&quot;&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt; &lt;/View&gt; NOTE: Notice assertion=”true” in Absent and Past labels, which marks each of those labels as Assertion Status Labels. Classification The choices tag is used as part of the classification projects to create a group of choices. It can be used for a single or multiple-class classification. According to the parameters used along with the choices tag, annotators can select single or multiple choices. Parameters The Choices tag supports the following parameters/attributes: Param Type Default Description required boolean false Verify if a choice is selected requiredMessage string   Show a message if the required validation fails choice single | multiple single Allow user to select single or multiple answer showInline boolean false Show choices in a single visual line perRegion boolean   Use this attribute to select an option for a specific region rather than the entire task &lt;!--text classification labeling config--&gt; &lt;View&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;Choices name=&quot;surprise&quot; toName=&quot;text&quot; choice=&quot;single&quot; required=&#39;true&#39; requiredMessage=&#39;Please select choice&#39;&gt; &lt;Choice value=&quot;surprise&quot;/&gt; &lt;Choice value=&quot;sadness&quot;/&gt; &lt;Choice value=&quot;fear&quot;/&gt; &lt;Choice value=&quot;joy&quot;/&gt; &lt;/Choices&gt; &lt;/View&gt; When using the perRegion attribute, choices can be defined for each chunk annotation as shown below: Relation Extraction Annotation Lab also offers support for relation extraction. Relations are introduced by simply specifying their label in the project configuration. &lt;Relations&gt; &lt;Relation value=&quot;CancerSize&quot; /&gt; &lt;Relation value=&quot;CancerLocation&quot;/&gt; &lt;Relation value=&quot;MetastasisLocation&quot;/&gt; &lt;/Relations&gt; Constraints for relation labeling While annotating projects with Relations between Entities, defining constraints (the direction, the domain, the co-domain) of relations is important. Annotation Lab offers a way to define such constraints by editing the Project Configuration. The Project Owner or Project Managers can specify which Relation needs to be bound to which Labels and in which direction. This will hide some Relations in Labeling Page for NER Labels which will simplify the annotation process and will avoid the creation of any incorrect relations in the scope of the project. To define such constraint, add allowed attribute to the tag: L1&gt;L2 means Relation can be created in the direction from Label L1 to Label L2, but not the other way around L1&lt;&gt;L2 means Relation can be created in either direction between Label L1 to Label L2 If the allowed attribute is not present in the tag, there is no such restriction. Below you can find a sample Project Configuration with constraints for Relation Labels: &lt;View&gt; &lt;Header value=&quot;Sample Project Configuration for Relations Annotation&quot;/&gt; &lt;Relations&gt; &lt;Relation value=&quot;Was In&quot; allowed=&quot;PERSON&gt;LOC&quot;/&gt; &lt;Relation value=&quot;Has Function&quot; allowed=&quot;LOC&gt;EVENT,PERSON&gt;MEDICINE&quot;/&gt; &lt;Relation value=&quot;Involved In&quot; allowed=&quot;PERSON&lt;&gt;EVENT&quot;/&gt; &lt;Relation value=&quot;No Constraints&quot;/&gt; &lt;/Relations&gt; &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;PERSON&quot;/&gt; &lt;Label value=&quot;EVENT&quot;/&gt; &lt;Label value=&quot;MEDICINE&quot;/&gt; &lt;Label value=&quot;LOC&quot;/&gt; &lt;/Labels&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt;",
    "url": "/docs/en/alab/project_configuration",
    "relUrl": "/docs/en/alab/project_configuration"
  },
  "1326": {
    "id": "1326",
    "title": "Project Creation",
    "content": "New project Every project in Annotation Lab should have the following information: a unique name and a short description; a team of annotators, reviewers and a manager who will collaborate on the project; a configuration which specifies the type of annotations that will be created. You can create a new project using the dedicated wizard which will guide users through each step of the project creation and configuration process. Those steps are illustrated below. Project Description To open the project creation wizard click on the + New Project button on the Projects Dashboard, then provide the following information: a unique name or title; a sampling type which will define how the tasks assigned to annotators/reviewers will be served - randomly or sequentially; a short description that helps users quickly grasp the main purpose of the project; instructions for annotators or Annotation Guidelines which will help annotators and reviewers generate high quality annotations. NOTE: Reserved words cannot be used as project names. The use of keywords like count, permission, or name as project names generated UI glitches. To avoid such issues, these keywords are no longer accepted as project names. Adding Team Members When working in teams, projects can be shared with other team members. The user who creates a project is called a Project Owner. He/she has complete visibility and ownership of the project for its entire lifecycle. If the Project Owner is removed from the user database, then all his/her projects are transfered to a new project owner. The Project Owner can edit the project configuration, can import/export tasks, can create a project team that will work on his project and can access project analytics. When defining the project team, a project owner has access to three distinct roles: Annotator, Reviewer, and Manager. These are very useful for most of the workflows that our users follow. An Annotator is able to see the tasks which have been assigned to him or her and can create annotations on the documents. The Reviewer is able to see the work of the annotators and approve it or reject in case he finds issues that need to be solved. The Manager is able to see the work of the Annotators and of the Reviewers and he can assign tasks to team members. This is useful for eliminating work overlap and for a better management of the work load. To add a user to your project team, select your Project, then from the left side menu access the Setup option and then the Team option. On the Add Team Member page that opens, start typing the name of a user in the available text box. This will populate a list of available users having the username start with the characters you typed. From the dropdown select the user you want to add to your team. Select a role for the user and click on the Add to team button. In the Add Team Member page users can add/remove/update the team members even in the case of a large number of members. The team members are displayed in a tabular view. Each member has a priority assigned to them for CONLL export which can be changed by dragging users across the list. NOTE: The priority assigned for users in the Add Team Member page is taken into account by the Model Training script for differentiating among the available ground truth completions (when more than one is available for a task) in view of choosing the higer priority completion which will be used for model training. Learn more here. Project Configuration The Project Configuration itself is a multi-step process. The wizard will guide users through each step while providing useful information and hints for all available options. Clone You can create a copy of a project, by using the Clone option. The option to clone the project is also listed in the kebab menu of each project. The cloned project is differentiated as it contains cloned suffix in its project name. Export Projects can be exported. The option to export a project is listed in the kebab menu of each project. All project-related items such as tasks, project configuration, project members, task assignments, and comments are included in the export file. NOTE: Project export does not contain the model trained in the project as models are independent and not attached to a particular project. Import A project can be imported by uploading the project zip archive in the upload dialog box. When the project is imported back to Annotation Lab, all elements of the original project configuration will be included in the new copy. Project Grouping As the number of projects can grow significantly over time, for an easier management and organization of those, Annotation Lab allows project grouping. As such, a project owner can assign a group to one or several of his/her projects. Each group can be assigned a color which will be used to highlight projects included in that group. Once a project is assigned to a group, the group name will appear as a tag on the project tile. At any time a project can be remove from one group and added to another group. The list of visible projects can be filtered based on group name, or using the search functionality which applies to both group name and project name. Projects can be organized in custom groups, and each project card will inherit the group color so that the users can visually distinguish the projects easily in a large cluster of projects. The new color picker for the group is user-friendly and customizable.",
    "url": "/docs/en/alab/project_creation",
    "relUrl": "/docs/en/alab/project_creation"
  },
  "1327": {
    "id": "1327",
    "title": "Dashboard",
    "content": "When logging in to the Annotation Lab, the user sees the main Projects Dashboard. For each project, details like description, task counts, assigned groups, team members, etc. are available on the main dashboard so users can quickly identify the projects they need to work on, without navigating to the Project Details page. Projects can be filtered based on the creator: My Projects, created by the current user or Shared With Me, created by other users and shared with the current one. All Projects option combines the list of the projects created by the current user and those shared by others. The list of projects can be sorted according to the name of the project. Also, projects can be sorted in ascending or descending order according to the creation date. The filters associated with the Projects Dashboard are clear, simple, and precise to make the users more productive and efficient while working with a large number of projects. Searching features are also available and help users identify projects based on their name.",
    "url": "/docs/en/alab/project_dashboard",
    "relUrl": "/docs/en/alab/project_dashboard"
  },
  "1328": {
    "id": "1328",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/properties.html",
    "relUrl": "/api/python/modules/sparknlp/common/properties.html"
  },
  "1329": {
    "id": "1329",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/pub_tator.html",
    "relUrl": "/api/python/modules/sparknlp/training/pub_tator.html"
  },
  "1330": {
    "id": "1330",
    "title": "Public Health - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/public_health",
    "relUrl": "/public_health"
  },
  "1331": {
    "id": "1331",
    "title": "",
    "content": "",
    "url": "/api/python/py-modindex.html",
    "relUrl": "/api/python/py-modindex.html"
  },
  "1332": {
    "id": "1332",
    "title": "Question Answering - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/question_answering",
    "relUrl": "/question_answering"
  },
  "1333": {
    "id": "1333",
    "title": "Quick Start",
    "content": "Installing Annotator &amp; PretrainedPipeline based pipelines You can create Finance Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the finance &amp; nlp module after installing the licensed libraries. nlp.PretrainedPipeline(&#39;pipe_name&#39;) gives access to Pretrained Pipelines from johnsnowlabs import nlp from sparknlp.pretrained import PretrainedPipeline nlp.start() deid_pipeline = nlp.PretrainedPipeline(&quot;finpipe_deid&quot;, &quot;en&quot;, &quot;finance/models&quot;) sample = &quot;&quot;&quot;CARGILL, INCORPORATED By: Pirkko Suominen Name: Pirkko Suominen Title: Director, Bio Technology Development, Date: 10/19/2011 BIOAMBER, SAS By: Jean-François Huc Name: Jean-François Huc Title: President Date: October 15, 2011 email : jeanfran@gmail.com phone : 1808733909 &quot;&quot;&quot; result = deid_pipeline.annotate(sample) print(&quot; nMasked with entity labels&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;deidentified&#39;])) print(&quot; nMasked with chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; nMasked with fixed length chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; nObfuscated&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) Output: Masked with entity labels &lt;PARTY&gt;, &lt;PARTY&gt; By: &lt;SIGNING_PERSON&gt; Name: &lt;PARTY&gt;: &lt;SIGNING_TITLE&gt;, Date: &lt;EFFDATE&gt; &lt;PARTY&gt;, &lt;PARTY&gt; By: &lt;SIGNING_PERSON&gt; Name: &lt;PARTY&gt;: &lt;SIGNING_TITLE&gt;Date: &lt;EFFDATE&gt; email : &lt;EMAIL&gt; phone : &lt;PHONE&gt; Masked with chars [*****], [**********] By: [*************] Name: [*******************]: [**********************************] Center, Date: [********] [******], [*] By: [***************] Name: [**********************]: [*******]Date: [**************] email : [****************] phone : [********] Masked with fixed length chars ****, **** By: **** Name: ****: ****, Date: **** ****, **** By: **** Name: ****: ****Date: **** email : **** phone : **** Obfuscated MGT Trust Company, LLC., Clarus llc. By: Benjamin Dean Name: John Snow Labs Inc: Sales Manager, Date: 03/08/2025 Clarus llc., SESA CO. By: JAMES TURNER Name: MGT Trust Company, LLC.: Business ManagerDate: 11/7/2016 email : Tyrus@google.com phone : 78 834 854 Custom Pipes Alternatively you can compose Legal Annotators &amp; Open Source Annotators into a pipeline which offers the highest degree of customization. from johnsnowlabs import nlp,finance spark = nlp.start() documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sparktokenizer = nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) zero_shot_ner = finance.ZeroShotNerModel.pretrained(&quot;finner_roberta_zeroshot&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;DATE&quot;: [&#39;When was the company acquisition?&#39;, &#39;When was the company purchase agreement?&#39;], &quot;ORG&quot;: [&quot;Which company was acquired?&quot;], &quot;PRODUCT&quot;: [&quot;Which product?&quot;], &quot;PROFIT_INCREASE&quot;: [&quot;How much has the gross profit increased?&quot;], &quot;REVENUES_DECLINED&quot;: [&quot;How much has the revenues declined?&quot;], &quot;OPERATING_LOSS_2020&quot;: [&quot;Which was the operating loss in 2020&quot;], &quot;OPERATING_LOSS_2019&quot;: [&quot;Which was the operating loss in 2019&quot;] }) nerconverter = nlp.NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = nlp.Pipeline(stages=[ documentAssembler, sparktokenizer, zero_shot_ner, nerconverter, ] ) sample_text = [&quot;In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.&quot;, &quot;In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.&quot;, &quot;While our gross profit margin increased to 81.4% in 2020 from 63.1% in 2019, our revenues declined approximately 27% in 2020 as compared to 2019.&quot; &quot;We reported an operating loss of approximately $8,048,581 million in 2020 as compared to an operating loss of approximately $7,738,193 million in 2019.&quot;] p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) res = p_model.transform(spark.createDataFrame(sample_text, nlp.StringType()).toDF(&quot;text&quot;)) res.select(nlp.F.explode(nlp.F.arrays_zip(res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata)).alias(&quot;cols&quot;)) .select(nlp.F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), nlp.F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;)) .filter(&quot;ner_label!=&#39;O&#39;&quot;) .show(truncate=False) Output: ++--+ |chunk |ner_label | ++--+ |March 2012 |DATE | |Vertro, Inc |ORG | |February 2017 |DATE | |asset purchase agreement |AGREEMENT | |NetSeer |ORG | |INTELLECTUAL PROPERTY AGREEMENT |AGREEMENT | |December 31, 2018 |DATE | |Armstrong Flooring |ORG | |Delaware |STATE | |AFI Licensing LLC |ORG | |Delaware |ORG | |Seller |LICENSE_RECIPIENT| |perpetual, non- exclusive, royalty-free|LICENSE | ++--+",
    "url": "/docs/en/jsl/quickstart_finance",
    "relUrl": "/docs/en/jsl/quickstart_finance"
  },
  "1334": {
    "id": "1334",
    "title": "Quick Start",
    "content": "Installing Annotator &amp; PretrainedPipeline based pipelines You can create Legal Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the legal &amp; nlp module after installing the licensed libraries. nlp.PretrainedPipeline(&#39;pipe_name&#39;) gives access to Pretrained Pipelines from johnsnowlabs import nlp nlp.start() deid_pipeline = nlp.PretrainedPipeline(&quot;legpipe_deid&quot;, &quot;en&quot;, &quot;legal/models&quot;) sample_2 = &quot;&quot;&quot;Pizza Fusion Holdings, Inc. Franchise Agreement This Franchise Agreement (the &quot;Agreement&quot;) is entered into as of the Agreement Date shown on the cover page between Pizza Fusion Holding, Inc., a Florida corporation, and the individual or legal entity identified on the cover page. Source: PF HOSPITALITY GROUP INC., 9/23/2015 1. RIGHTS GRANTED 1.1. Grant of Franchise. 1.1.1 We grant you the right, and you accept the obligation, to use the Proprietary Marks and the System to operate one Restaurant (the &quot;Franchised Business&quot;) at the Premises, in accordance with the terms of this Agreement. Source: PF HOSPITALITY GROUP INC., 9/23/2015 1.3. Our Limitations and Our Reserved Rights. The rights granted to you under this Agreement are not exclusive.sed Business. Source: PF HOSPITALITY GROUP INC., 9/23/2015 &quot;&quot;&quot; result = deid_pipeline.annotate(sample_2) print(&quot; nMasked with entity labels&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;deidentified&#39;])) print(&quot; nMasked with chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; nMasked with fixed length chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; nObfuscated&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) Output: Masked with entity labels &lt;PARTY&gt;. &lt;DOC&gt; This &lt;DOC&gt; (the &lt;ALIAS&gt;) is entered into as of the Agreement Date shown on the cover page between &lt;PARTY&gt; a Florida corporation, and the individual or legal entity identified on the cover page. Source: &lt;PARTY&gt;., &lt;EFFDATE&gt; 1. &lt;PARTY&gt; 1.1. &lt;PARTY&gt;. 1.1.1 We grant you the right, and you accept the obligation, to use the &lt;PARTY&gt; and the System to operate one Restaurant (the &lt;ALIAS&gt;) at the Premises, in accordance with the terms of this Agreement. Source: &lt;PARTY&gt;., &lt;EFFDATE&gt; 1.3. Our &lt;PARTY&gt; and &lt;PARTY&gt;. The rights granted to you under this Agreement are not exclusive.sed Business. Source: &lt;PARTY&gt;., &lt;EFFDATE&gt; Masked with chars [************************]. [*****************] This [*****************] (the [*********]) is entered into as of the Agreement Date shown on the cover page between [*************************] a Florida corporation, and the individual or legal entity identified on the cover page. Source: [**********************]., [*******] 1. [************] 1.1. [****************]. 1.1.1 We grant you the right, and you accept the obligation, to use the [***************] and the System to operate one Restaurant (the [*******************]) at the Premises, in accordance with the terms of this Agreement. Source: [**********************]., [*******] 1.3. Our [*********] and [*****************]. The rights granted to you under this Agreement are not exclusive.sed Business. Source: [**********************]., [*******] Masked with fixed length chars ****. **** This **** (the ****) is entered into as of the Agreement Date shown on the cover page between **** a Florida corporation, and the individual or legal entity identified on the cover page. Source: ****., **** 1. **** 1.1. ****. 1.1.1 We grant you the right, and you accept the obligation, to use the **** and the System to operate one Restaurant (the ****) at the Premises, in accordance with the terms of this Agreement. Source: ****., **** 1.3. Our **** and ****. The rights granted to you under this Agreement are not exclusive.sed Business. Source: ****., **** Obfuscated SESA CO.. Estate Document This Estate Document (the (the &quot;Contract&quot;)) is entered into as of the Agreement Date shown on the cover page between Clarus llc. a Florida corporation, and the individual or legal entity identified on the cover page. Source: SESA CO.., 11/7/2016 1. SESA CO. 1.1. Clarus llc.. 1.1.1 We grant you the right, and you accept the obligation, to use the John Snow Labs Inc and the System to operate one Restaurant (the (the&quot; Agreement&quot;)) at the Premises, in accordance with the terms of this Agreement. Source: SESA CO.., 11/7/2016 1.3. Our MGT Trust Company, LLC. and John Snow Labs Inc. The rights granted to you under this Agreement are not exclusive.sed Business. Source: SESA CO.., 11/7/2016 Custom Pipes Alternatively you can compose Legal Annotators &amp; Open Source Annotators into a pipeline which offers the highest degree of customization. from johnsnowlabs import nlp,legal spark = nlp.start() documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sparktokenizer = nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) zero_shot_ner = legal.ZeroShotNerModel.pretrained(&quot;legner_roberta_zeroshot&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;DATE&quot;: [&#39;When was the company acquisition?&#39;, &#39;When was the company purchase agreement?&#39;, &quot;When was the agreement?&quot;], &quot;ORG&quot;: [&quot;Which company?&quot;], &quot;STATE&quot;: [&quot;Which state?&quot;], &quot;AGREEMENT&quot;: [&quot;What kind of agreement?&quot;], &quot;LICENSE&quot;: [&quot;What kind of license?&quot;], &quot;LICENSE_RECIPIENT&quot;: [&quot;To whom the license is granted?&quot;] }) nerconverter = nlp.NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = nlp.Pipeline(stages=[ documentAssembler, sparktokenizer, zero_shot_ner, nerconverter, ] ) sample_text = [&quot;In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.&quot;, &quot;In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.&quot;, &quot;This INTELLECTUAL PROPERTY AGREEMENT, dated as of December 31, 2018 (the &#39;Effective Date&#39;) is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (&#39;Seller&#39;) and AFI Licensing LLC, a Delaware company(&#39;Licensing&#39;)&quot; &quot;The Company hereby grants to Seller a perpetual, non- exclusive, royalty-free license&quot;] p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) res = p_model.transform(spark.createDataFrame(sample_text, StringType()).toDF(&quot;text&quot;)) res.select(nlp.F.explode(nlp.F.arrays_zip(res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata)).alias(&quot;cols&quot;)) .select(nlp.F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), nlp.F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;)) .filter(&quot;ner_label!=&#39;O&#39;&quot;) .show(truncate=False) Output: ++--+ |chunk |ner_label | ++--+ |March 2012 |DATE | |Vertro, Inc |ORG | |February 2017 |DATE | |asset purchase agreement |AGREEMENT | |NetSeer |ORG | |INTELLECTUAL PROPERTY AGREEMENT |AGREEMENT | |December 31, 2018 |DATE | |Armstrong Flooring |ORG | |Delaware |STATE | |AFI Licensing LLC |ORG | |Delaware |ORG | |Seller |LICENSE_RECIPIENT| |perpetual, non- exclusive, royalty-free|LICENSE | ++--+",
    "url": "/docs/en/jsl/quickstart_legal",
    "relUrl": "/docs/en/jsl/quickstart_legal"
  },
  "1335": {
    "id": "1335",
    "title": "Quick Start",
    "content": "You can create Medical Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the Medical &amp; nlp module after installing the licensed libraries. Load &amp; Predict 1 liner The johnsnowlabs library provides 2 simple methods with which most NLP tasks can be solved while achieving state-of-the-art results. The load and predict method. when building a load&amp;predict based model you will follow these steps: Pick a model/pipeline/component you want to create from the Namespace Call the model = nlp.load(component) method which will return an auto-completed pipeline Call model.predict(&#39;that was easy&#39;) on some String input These 3 steps can be boiled down to just 1 line from johnsnowlabs import nlp nlp.start() medical_text = &#39;&#39;&#39; The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days&#39;&#39;&#39; nlp.load(&#39;med_ner.jsl.wip.clinical&#39;).predict(medical_text) entity entity_class entity_confidence 5-month-old Age 0.9982 infant Age 0.9999 Monday RelativeDate 0.9983 cold Symptom 0.7517 cough Symptom 0.9969 runny nose Symptom 0.7796 for 2 days Duration 0.5479 nlp.load() defines additional components types usable in 1-liners which are only avaiable if a medical license is provided. Licensed Component Types : Component type nlp.load() base Medical Named Entity Recognition(NER) nlp.load(&#39;med.ner&#39;) Entity Resolution nlp.load(&#39;resolve&#39;) Entity Assertion nlp.load(&#39;assert&#39;) Entity Relation Classification nlp.load(&#39;relation&#39;) Entity De-Identification nlp.load(&#39;de_identify&#39;) Map Entities into Terminologies nlp.load(&#39;map_entity&#39;) Translate Entities from One Terminologies into Another Terminology nlp.load(&#39;&lt;Terminilogy&gt;_to_&lt;other_terminology&gt;&#39;) Drug Normalizers nlp.load(&#39;norm_drugs&#39;) Rule based NER with Context Matcher nlp.load(&#39;match.context&#39;) Annotator &amp; PretrainedPipeline based pipelines You can create Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the nlp module. nlp.PretrainedPipeline(&#39;pipe_name&#39;) gives access to Pretrained Pipelines from johnsnowlabs import nlp nlp.start() deid_pipeline = nlp.PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;en&quot;, &quot;clinical/models&quot;) sample = &quot;&quot;&quot;Name : Hendrickson, Ora, Record date: 2093-01-13, # 719435. Dr. John Green, ID: 1231511863, IP 203.120.223.13. He is a 60-year-old male was admitted to the Day Hospital for cystectomy on 01/13/93. Patient&#39;s VIN : 1HGBH41JXMN109286, SSN #333-44-6666, Driver&#39;s license no:A334455B. Phone (302) 786-5227, 0295 Keats Street, San Francisco, E-MAIL: smith@gmail.com.&quot;&quot;&quot; result = deid_pipeline.annotate(sample) print(&quot; n&quot;.join(result[&#39;masked&#39;])) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) OUTPUT: Masked with entity labels Name : &lt;PATIENT&gt;, Record date: &lt;DATE&gt;, # &lt;MEDICALRECORD&gt;. Dr. &lt;DOCTOR&gt;, ID&lt;IDNUM&gt;, IP &lt;IPADDR&gt;. He is a &lt;AGE&gt; male was admitted to the &lt;HOSPITAL&gt; for cystectomy on &lt;DATE&gt;. Patient&#39;s VIN : &lt;VIN&gt;, SSN &lt;SSN&gt;, Driver&#39;s license &lt;DLN&gt;. Phone &lt;PHONE&gt;, &lt;STREET&gt;, &lt;CITY&gt;, E-MAIL: &lt;EMAIL&gt;. Masked with chars Name : [**************], Record date: [********], # [****]. Dr. [********], ID[**********], IP [************]. He is a [*********] male was admitted to the [**********] for cystectomy on [******]. Patient&#39;s VIN : [***************], SSN [**********], Driver&#39;s license [*********]. Phone [************], [***************], [***********], E-MAIL: [*************]. Masked with fixed length chars Name : ****, Record date: ****, # ****. Dr. ****, ID****, IP ****. He is a **** male was admitted to the **** for cystectomy on ****. Patient&#39;s VIN : ****, SSN ****, Driver&#39;s license ****. Phone ****, ****, ****, E-MAIL: ****. Obfuscated Name : Berneta Phenes, Record date: 2093-03-14, # Y5003067. Dr. Dr Gaston Margo, IDOX:8976967, IP 001.001.001.001. He is a 91 male was admitted to the MADONNA REHABILITATION HOSPITAL for cystectomy on 07-22-1994. Patient&#39;s VIN : 5eeee44ffff555666, SSN 999-84-3686, Driver&#39;s license S99956482. Phone 74 617 042, 1407 west stassney lane, Edmonton, E-MAIL: Carliss@hotmail.com. Custom Pipes Alternatively you can compose Annotators into a pipeline which offers the highest degree of customization from johnsnowlabs import nlp,medical spark = nlp.start() documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) zero_shot_ner = medical.ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clincial/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;NAME&quot;: [&quot;What is his name?&quot;, &quot;What is my name?&quot;, &quot;What is her name?&quot;], &quot;CITY&quot;: [&quot;Which city?&quot;, &quot;Which is the city?&quot;] }) ner_converter = medical.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = nlp.Pipeline(stages = [ documentAssembler, sentenceDetector, tokenizer, zero_shot_ner, ner_converter]) zero_shot_ner_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) data = spark.createDataFrame([&quot;Hellen works in London, Paris and Berlin. My name is Clara, I live in New York and Hellen lives in Paris.&quot;, &quot;John is a man who works in London, London and London.&quot;], nlp.StringType()).toDF(&quot;text&quot;)",
    "url": "/docs/en/jsl/quickstart_medical",
    "relUrl": "/docs/en/jsl/quickstart_medical"
  },
  "1336": {
    "id": "1336",
    "title": "Quick Start",
    "content": "Load &amp; Predict 1 liner The johnsnowlabs library provides 2 simple methods with which most visual NLP tasks can be solved while achieving state-of-the-art results. The load and predict method. When building a load&amp;predict based model you will follow these steps: Pick a visual model/pipeline/component you want to create from the Namespace Call the model = ocr.load(&#39;visual_component&#39;) method which will return an auto-completed pipeline Call model.predict(&#39;path/to/image.png&#39;) with a path to a file or an array of paths These 3 steps can be boiled down to just 1 line from johnsnowlabs import nlp nlp.load(&#39;img2text&#39;).predict(&#39;path/to/haiku.png&#39;) nlp.load() defines 6 visual components types usable in 1-liners 1-liner Transformer Class nlp.load(&#39;img2text&#39;).predict(&#39;path/to/cat.png&#39;) ImageToText nlp.load(&#39;pdf2text&#39;).predict(&#39;path/to/taxes.pdf&#39;) PdfToText nlp.load(&#39;doc2text&#39;).predict(&#39;path/to/my_homework.docx&#39;) DocToText nlp.load(&#39;pdf2table&#39;).predict(&#39;path/to/data_tables.pdf&#39;) PdfToTextTable nlp.load(&#39;ppt2table&#39;).predict(&#39;path/to/great_presentation_with_tabular_data.pptx&#39;) PptToTextTable nlp.load(&#39;doc2table&#39;).predict(&#39;path/to/tabular_income_data.docx&#39;) DocToTextTable Custom Pipelines You can create Visual Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the visual module which gives you the highest degree of freedom from johnsnowlabs import nlp,visual spark = nlp.start(visual=True) # Load a PDF File and convert it into Spark DF format doc_example = visual.pkg_resources.resource_filename(&#39;sparkocr&#39;, &#39;resources/ocr/docs/doc2.docx&#39;) doc_example_df = spark.read.format(&quot;binaryFile&quot;).load(doc_example).cache() # Run the visual DocToText Annotator inside a pipe, recognize text and show the result pipe = nlp.PipelineModel(stages=[visual.DocToText().setInputCol(&quot;content&quot;).setOutputCol(&quot;text&quot;)]) result = pipe.transform(doc_example_df) print(result.take(1)[0].text) output:",
    "url": "/docs/en/jsl/quickstart_visual",
    "relUrl": "/docs/en/jsl/quickstart_visual"
  },
  "1337": {
    "id": "1337",
    "title": "NLP Annotation Lab&#58; Free No Code AI Platform",
    "content": "The Free No-Code NLP Lab A highly efficient End-to-End No Code NLP platform for all enterprise teams that need to: Annotate Text &amp; Images Train &amp; Tune NLP Models Speedup with AI Assisted Annotation Test for Responsible AI Manage Projects &amp; Teams Enterprise Security &amp; Privacy All that without writing a line of code! Install on AWS Install on Azure Productivity Never start from scratch Keep Annotators in the Zone Reach agreement quickly Auto NLP Active learning Deliver an accurate model, not just labels Built for High Compliance Enterprise Environments Teamwork Projects &amp; Teams Workflows Security Analytics Resources General tutorials Annotation best practices Tips and tricks Quick Intro Annotation Lab evolved to become the NLP Lab. NLP Lab is a Free End-to-End No-Code platform for document labeling and AI/ML model training. It enables domain experts (e.g. nurses, doctors, lawyers, accountants, investors, etc.) to extract meaningful facts from text documents, images or PDFs and train models that will automatically predict those facts on new documents. This is done by using state-of-the-art Spark NLP pre-trained models or by tuning models to better handle specific use cases. Based on an auto-scaling architecture powered by Kubernetes, it can scale to many teams and projects. Enterprise-grade security is provided for free including support for air-gap environments, zero data sharing, role-based access, full audit trails, MFA, and identity provider integrations. It allows powerful experiments for model training and finetuning, model testing, and model deployment as API endpoints. There is no limitation on the number of users, projects, tasks, models, or trainings that can be run with this subscription. Healthcare and Visual features are available via BYOL. Included Features: Annotation support for Text, Image, Audio, Video and HTML content; High productivity annotation UI with keyboard shortcuts and pre-annotations; Support for text annotation in 250+ languages; Out-of-the-box support for the following NLP tasks: Classification, Named Entity Recognition, Assertion Status, and Relation Extraction; Support for projects and teams: 30+ project templates; unlimited projects and users, project import, export and cloning, project grouping; Task assignment, tagging, and comments; duplicate tasks identification; task searching and filtering; Consensus analysis and Inter Annotator Agreement charts; Performance dashboards; Enterprise-level security and privacy: role-based access control, role-based views, annotation versioning, full audit trail, Single Sign on; AI-Assisted Annotation: never start from scratch but reuse existing models to pre-annotate tasks with the latest Spark NLP models for classification, NER, assertion status, and relation detection; Full Models Hub integration: you can explore available models and embeddings, download them with the click of a button and reuse those in your project configuration. Train Classification, NER, and Assertion Status models: use default parameters or easily tune them on the UI for different experiments; Active Learning automatically trains new versions of your models once new annotations are available; API access to all features for easy integration into custom data analysis pipelines;",
    "url": "/docs/en/alab/quickstart",
    "relUrl": "/docs/en/alab/quickstart"
  },
  "1338": {
    "id": "1338",
    "title": "Quick Start",
    "content": "Requirements &amp; Setup Spark NLP is built on top of Apache Spark 3.x. For using Spark NLP you need: Java 8 and 11 Apache Spark 3.3.x, 3.2.x, 3.1.x, 3.0.x It is recommended to have basic knowledge of the framework and a working environment before using Spark NLP. Please refer to Spark documentation to get started with Spark. Install Spark NLP in Python Scala and Java Databricks EMR Join our Slack channel Join our channel, to ask for help and share your feedback. Developers and users can help each other getting started here. Spark NLP Slack Spark NLP in Action Make sure to check out our demos built by Streamlit to showcase Spark NLP in action: Spark NLP Demo Spark NLP Examples If you prefer learning by example, check this repository: Spark NLP Examples It is full of fresh examples and even a docker container if you want to skip installation. Below, you can follow into a more theoretical and thorough quick start guide. Where to go next If you need more detailed information about how to install Spark NLP you can check the Installation page Detailed information about Spark NLP concepts, annotators and more may be found HERE",
    "url": "/docs/en/quickstart",
    "relUrl": "/docs/en/quickstart"
  },
  "1339": {
    "id": "1339",
    "title": "Radiology - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/radiology",
    "relUrl": "/radiology"
  },
  "1340": {
    "id": "1340",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/read_as.html",
    "relUrl": "/api/python/modules/sparknlp/common/read_as.html"
  },
  "1341": {
    "id": "1341",
    "title": "Recognize Entities - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/recognize_entitie",
    "relUrl": "/recognize_entitie"
  },
  "1342": {
    "id": "1342",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/recursive.html",
    "relUrl": "/api/python/modules/sparknlp/internal/recursive.html"
  },
  "1343": {
    "id": "1343",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/recursive_annotator_approach.html",
    "relUrl": "/api/python/modules/sparknlp/common/recursive_annotator_approach.html"
  },
  "1344": {
    "id": "1344",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/recursive_pipeline.html",
    "relUrl": "/api/python/modules/sparknlp/base/recursive_pipeline.html"
  },
  "1345": {
    "id": "1345",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/token/recursive_tokenizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/token/recursive_tokenizer.html"
  },
  "1346": {
    "id": "1346",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/regex_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/regex_matcher.html"
  },
  "1347": {
    "id": "1347",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/token/regex_tokenizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/token/regex_tokenizer.html"
  },
  "1348": {
    "id": "1348",
    "title": "Release Notes",
    "content": "5.3.2 Release date: 30-08-2023 NLP Lab 5.3 - A Leap Forward in Pre-Annotation through ChatGPT-Powered Entity Recognition We’re excited to present NLP Lab 5.3, an exciting update that marks our foray into integrating Large Language Models (LLMs) into our platform. Leading the charge is the integration with ChatGPT family of models, the first in a series of LLM integrations we have planned for the future. This not only sets the stage for a new era of enhanced pre-annotation capabilities but also underscores our commitment to staying at the forefront of NLP innovation. By weaving ChatGPT’s prowess into our ecosystem, we’re offering users an expanded range of prompt possibilities and a refined entity extraction process. But that’s not all! Beyond the ChatGPT integration, we’ve made a series of enhancements across the board. From a revamped taxonomy customization experience for section-based projects to thoughtful improvements in OCR text formatting, every change in this release is designed to improve your annotation experience. Whether you’re a seasoned NLP Lab user or just getting started, we believe this update will offer you a blend of familiarity and fresh innovation, ensuring a smoother, more productive annotation journey. Dive into the details below to discover all that NLP Lab 5.3 has in store for you. Entity Extraction and Pre-Annotation via GPT Prompting The highlight of this release is the integration with an external service provider, Open AI, to expand and deepen the range of prompts available for pre-annotation (in addition to the Zero Shot entity and relation prompts already supported). This feature:. Broadens Prompt Possibilities: By integrating with Open AI LLM models, users can tap into a more diverse set of prompts, leveraging external expertise to craft pre-annotations, as an alternative pre-annotation solution or when pre-trained models are not available. Efficient Entity Extraction: As current LLMs, GPT family included, are not very good at entity recognition tasks, NLP Lab included a post-processing step on the result provided by LLM. This improves entity identification and helps precisely locate the entities in the given text. These entities, carefully curated and aligned with NLP Lab pre-annotation requirements pave the way for a more efficient and streamlined annotation experience. The following sections explain in detail how to define and use GPT prompts. Setting Up the Integration with Open AI service Integrating “ChatGPT” into the NLP Lab has been designed to be a straightforward process, ensuring users can harness the power of external expertise seamlessly. It consists of three easy steps: Integrations Page: Navigate to the Integrations Page located within the System Settings. This is the hub where all external service providers, including Open AI’s GPT Models, can be defined and managed. Define the Service Provider: To initiate the integration, users are required to provide specific details: Service Provider Name: This is the identifier for the external service, which in this case would be “ChatGPT” or any other name you prefer to use. Secret Key: Every external service comes with a unique Secret Key that ensures secure communication between the platforms. Enter the Secret Key associated with your Open AI subscription here. To ensure the integration process is error-free, users can validate the provided Secret Key directly within the form. This validation step ensures that the connection is secure and that the key is correct. Project Association: Once a successful connection with “ChatGPT” (or any external LLM service provider) is established, it doesn’t end there. The integrated service will now be available for association with selected projects. This means users can decide which projects will benefit from the “ChatGPT” integration and enable it accordingly. The Open AI integration allows users to tap into a vast reservoir of external expertise, enhancing the depth and breadth of their projects. We’ve ensured that the integration process is as intuitive as possible, allowing users to focus on what truly matters: crafting refined and effective pre-annotations. ChatGPT Prompt Definition and Testing Users can generate LLM prompts on the dedicated Prompt page from the Hub of Resources. For ChatGPT Prompts, NLP Lab offers a dedicated definition interface. Here’s what to expect when creating a new LLM prompt: Name the Prompt: Within this new tab, users will first be asked to provide a name for their prompt. This name will be used for pre-annotating identified entities. At this point, we recommend creating one prompt per target entity. Select the Service Provider: Next, users can choose the specific service provider they’ve previously set up via the Integrations Page. Test in Real-time: A standout feature is the ability to test ChatGPT prompts at creation time. As you craft your prompt, you can immediately see how it performs on some test data. This not only allows for immediate feedback but also ensures that the final prompt aligns perfectly with the user’s objectives. This streamlined approach ensures that integrating and testing external prompts is as intuitive and efficient as possible. Consistent Workflow with LLM Prompts Even with the introduction of new features in NLP Lab’s 5.3.0 release, users can take comfort in the consistent experience offered when working with prompts. The addition of external service provider prompts brings a fresh layer to the annotation process, yet the core workflow you’re familiar with stays the same. Familiarity Amidst Innovation: Despite the new integrations, the process of using available prompts remains as straightforward as ever. Whether you’re working with traditional prompts or the newly introduced ones, the experience is smooth and consistent. Seamless Transition: Our commitment to user-centric design means that even as we innovate, we prioritize the ease of use you’ve come to expect. Transitioning to or incorporating external prompts is made effortless, with the interface and steps for prompt creation, selection, and integration remaining intuitive and unchanged. With NLP Lab 5.3.0, you get the best of both worlds: exciting new features and the comfort of a familiar workflow. Note: Pre-annotation of tasks using LLM Prompts does not require the deployment of the pre-annotation server. The pop-up to deploy the pre-annotation server is only shown if the project configuration consists of both LLM prompts and spark NLP models. Improvements Enhanced Taxonomy to Section Mapping NLP Labs 5.3.0 brings significant upgrades to the taxonomy customization experience when dealing with Section-based projects. Revamped Viewing Experience for Taxonomy Elements: We’ve reimagined the way users view “Labels to Sections” associations: At-a-Glance Overview: Gone are the days of manually selecting each label to view its associations. Now, users can instantly see the complete mapping of Labels to Sections, providing a holistic view of the project’s current configuration. Efficient Updates: This consolidated view enables users to quickly grasp their current setup and make any necessary adjustments with ease, making the entire process more user-centric. Bulk Association of “Labels/Choices to Section: A standout enhancement is the ability to associate “Labels/Choices” to sections in bulk. Unlike the previous version, where users could only associate one label at a time, this update allows for simultaneous selection and association of multiple labels to various sections. This enhancement not only streamlines the project configuration and annotation process but also offers a more intuitive user experience, saving valuable time and effort. To facilitate these new features, we have made minor adjustments to the project configuration page in NLP Labs. Under the “Customize Labels” tab, you can now find a new button named “Associate Sections”. Clicking on this button allows users to quickly access the tabular form of the mapping, making it easier to manage Labels/Choices linkage with specific sections. For both “Labels” and “Choices”, we have provided the dedicated “Associate Sections” button on their respective configuration tabs. These new improvements are supported in all section-based annotation-enabled projects, including Visual NER projects. Section-Based Annotation: automatically disregard empty sections In earlier iterations of the section-based annotation project feature, users noticed that some empty sections were marked as relevant when automatically splitting content into paragraphs. Recognizing this issue, version 5.3.0 brings a thoughtful enhancement: sections without any textual content are now automatically disregarded. This ensures a more streamlined annotation process, omitting empty sections like the examples provided below. Updated Pre-annotation Status indicator on task page In the past, the pre-annotate status exclusively indicated whether a prediction was marked as “generated,” “not generated,” or if the pre-annotation process had encountered a failure. With the integration of pre-annotations derived from ChatGPT, the updated approach to preannotation status will encompass statuses for both SparkNLP predictions and ChatGPT predictions. Specifically, for projects involving both SparkNLP models and prompts generated through ChatGPT as an external provider, a revamped pre-annotation circle has been reimagined as a ring divided into two halves. The first half of the ring will showcase the pre-annotation status derived from SparkNLP, while the second half will depict the status of predictions stemming from ChatGPT. Enhanced Formatting for OCR Text For text projects using PDF/Image processing via Visual NLP, we’re excited to introduce an enhanced format feature. Once this feature is activated, the imported text is reformatted to offer better clarity and spacing within the annotation interface. Our goal with this enhancement is to foster a clearer, more spacious workspace, ensuring precision and ease during text annotation. Tags Definition Button was moved on the Tasks Page In version 5.3.0, the “Add More” option for task tags was moved. Based on user feedback, we’ve moved the “Add More” button to a more accessible location at the top of the Tags dropdown list. Along with its new position, the button now sports a “+” icon and a refreshed design, while retaining its original functionality. Importantly, the button’s functionality remains consistent with its previous purpose. Bug Fixes For HTML sources projects replace the dialogue in PREVIEWS with the JSL link The preview format for HTML Dialogues &amp; Conversations projects has been enhanced to feature a JSL link in place of the traditional ‘Dialogues’. Tags are not consistently assigned to Tasks Previously, tasks generated from external providers lacked assigned tags, posing challenges for users in distinguishing imported tasks’ sources. To address this, tags are now consistently assigned when clicking on the edges of tag options or the color indicators instead of only being assigned when clicking directly on the tag name. Model evaluation starts before the required resources are available when the maximum server count is reached In the previous version, model evaluations would commence even if the necessary resources were unavailable or if the maximum server count had been reached. To address this, a new approach has been implemented. When a model evaluation is in progress, a dedicated server is generated on the cluster page. This server is designed to be automatically removed once the evaluation concludes. Furthermore, should the maximum server count be reached and a user initiates an evaluation, an error message indicating “Maximum Model Server Limit Reached” will be displayed. Additionally, users have the option to delete an evaluation server from the cluster page. This action results in the evaluation being aborted on the Train page, accompanied by a notification banner indicating the aborted evaluation. For all Search Fields, White Space before/after the “search keyword” causes the search action to return no results Previously, in all Search Fields, having white space before or after the “search keyword” resulted in the search action yielding no results. Consequently, a change has been implemented to ensure that search results are displayed accurately regardless of any leading/trailing whitespace around the search keyword. This enhancement is universally applicable to all search fields within the application. The duplication error for Section Field does not resolve if the user changes/deletes the value of the other duplicate field Previously, if a Section-based Rule with a duplicate name was added, the error would still show as if the first originally named rule was edited to a different name. With Version 5.3.0, the duplication error will now be resolved if any of the rules that fall under the duplication case are edited to be unique. Incorrect active section name is shown in the top bar for pages without relevant section In the case of a multi-page task that does not have relevant sections, the previously active section will no longer appear at the page’s top. Additionally, if a page contains no pertinent sections, the Active tab on the task’s upper part will be displayed in a subdued manner. Tasks imported in Visual NER Project are not visible until the tasks page is refreshed The issue of the OCR task imported in Visual NER projects not appearing on the Tasks page and the Import button staying disabled until manually refreshed has been resolved in this version. Clicking on undo button in the playground resets every detail of the rule deployed Previously, using the Undo button in the playground didn’t restore rules to their original state after modifications. The Undo action cleared all aspects (suffix, rule type, content length) from deployed playground rules. This problem has now been addressed. Section Based Annotation: Merger of consecutive sections of the same name Previously, when the option “Merge Consecutive sections of the same type” was chosen, any two sections created by the rule that appeared consecutively were combined into a single section. This approach posed a challenge as it could result in an elongated chain of sections if all sections were consecutive. With the recent improvement, only the relevant sections with matching section names are merged. For instance, if there are sections named S1, S1, S3, S1, S2, S2 created consecutively, only the first occurrence of S1 and the final instance of S2 will be merged into a single section, while S3 will remain unaffected. Section Based Annotation: Model is redeployed if the same classifier is modified for the same project The sections classifier no longer undergoes redeployment each time classifier options are modified for the same model. Additionally, the section classifier remains unaffected when an additional classifier rule using the same classifier is introduced. Consequently, in scenarios involving task importation, newly added classifier rules are integrated into the new tasks. However, the section classifier is automatically deployed in situations where a new classifier server is added and the previous one is subsequently removed. “Filter pre-annotations according to my latest completion” shows predictions for deleted sections in SBA-enabled project There was an inconsistency when applying “Filter pre-annotations according to my latest completion” for SBA enabled task. The problem of the filter not functioning correctly, resulting in predictions for deleted sections, has been resolved in version 5.3.0. RE prompts using NER Prompts cannot be deployed in the playground Previously, errors were encountered in the playground when deploying the Relation prompt using the NER prompt in the playground. With this update, these issues have been resolved. Generate Synthetic Text: Unable to import generated text if the SBA project has Classification Rules There was a singular case for Section-based Projects, where adding classification section-based rules to create sections prevented the import of the generated synthetic text. In version 5.3.0, this has been fixed and now users can import the synthetic tasks after or even while the classification model for the section rules is being deployed. Validation missing when deleting section rule which is already associated with label/choice in the Configuration &gt; Customize Labels page Previously, when a user tried to delete the section rule that was associated with label/choice, there was no warning suggesting user that the section is linked to labels/choices in the configuration. The issue has now been resolved and users are given a warning dialog box about the link between the section and the labels/choices and he/she can either proceed and delete the section or cancel it and make necessary changes in configuration. Filter XML code does not filter labels for the NER project Before, the Filter XML function failed to filter the label/assertion list effectively. This issue has now been resolved. When a project’s taxonomy contains a substantial number of NER/Assertion labels, the display of the taxonomy consumes significant screen space, impeding annotators’ navigation through the labels. To address this, Annotation Lab has introduced a search feature for labels within NER projects, offering an autocomplete search option. For incorporating the search bar targeting NER Labels or Choices, utilize the Filter tag as exemplified in the subsequent XML configuration. This filtering mechanism is also applicable to Visual NER filters. Versions 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/release_notes",
    "relUrl": "/docs/en/alab/release_notes"
  },
  "1349": {
    "id": "1349",
    "title": "Release Notes",
    "content": "0.7.1 Fields Details Name NLP Server Version 0.7.1 Type Patch Release Date 2022-06-17 Overview We are excited to release NLP Server v0.7.1! We are committed to continuously improve the experience for our users and make our product reliable and easy to use. This release focuses on solving a few bugs and improving the stability of the NLP Server. Key Information For smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications. NLP Server is available on both AWS and Azure marketplaces. Bug Fixes Issue when running NER ONTO spell. Issue when running dep spell. Since the spell was broken it is temporarily blacklisted. Document normalizer included the HTML, XML tags to the output even after normalization. Issue when running language translation spells &lt;from_lang&gt;.translate_to.&lt;to_lang&gt;. Upon cancelation of custom model uploading job exception was seen in the logs. Some few UI related issues and abnormalities during operation. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes"
  },
  "1350": {
    "id": "1350",
    "title": "NLU release notes",
    "content": "NLU Version 4.2.2 support for Medical Summarizers New Medical Summarizers: ‘en.summarize.clinical_jsl’ ‘en.summarize.clinical_jsl_augmented’ ‘en.summarize.biomedical_pubmed’ ‘en.summarize.generic_jsl’ ‘en.summarize.clinical_questions’ ‘en.summarize.radiology’ ‘en.summarize.clinical_guidelines_large’ ‘en.summarize.clinical_laymen’ NLU Version 4.2.1 Bugfixes for saving and reloading pipelines on databricks NLU Version 4.2.0 Support for Speech2Text, Images-Classification, Tabular Data, Zero-Shot-NER, via Wav2Vec2, Tapas, VIT , 4000+ New Models, 90+ Languages, in John Snow Labs NLU 4.2.0 We are incredibly excited to announce NLU 4.2.0 has been released with new 4000+ models in 90+ languages and support for new 8 Deep Learning Architectures. 4 new tasks are included for the very first time, Zero-Shot-NER, Automatic Speech Recognition, Image Classification and Table Question Answering powered by Wav2Vec 2.0, HuBERT, TAPAS, VIT, SWIN, Zero-Shot-NER. Additionally, CamemBERT based architectures are available for Sequence and Token Classification powered by Spark-NLPs CamemBertForSequenceClassification and CamemBertForTokenClassification Automatic Speech Recognition (ASR) Demo Notebook Wav2Vec 2.0 and HuBERT enable ASR for the very first time in NLU. Wav2Vec2 is a transformer model for speech recognition that uses unsupervised pre-training on large amounts of unlabeled speech data to improve the accuracy of automatic speech recognition (ASR) systems. It is based on a self-supervised learning approach that learns to predict masked portions of speech signal, and has shown promising results in reducing the amount of labeled training data required for ASR tasks. These Models are powered by Spark-NLP’s Wav2Vec2ForCTC Annotator HuBERT models match or surpass the SOTA approaches for speech representation learning for speech recognition, generation, and compression. The Hidden-Unit BERT (HuBERT) approach was proposed for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. These Models is powered by Spark-NLP’s HubertForCTC Annotator Usage You just need an audio-file on disk and pass the path to it or a folder of audio-files. import nlu # Let&#39;s download an audio file !wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/audio/samples/wavs/ngm_12484_01067234848.wav # Let&#39;s listen to it from IPython.display import Audio FILE_PATH = &quot;ngm_12484_01067234848.wav&quot; asr_df = nlu.load(&#39;en.speech2text.wav2vec2.v2_base_960h&#39;).predict(&#39;ngm_12484_01067234848.wav&#39;) asr_df text PEOPLE WHO DIED WHILE LIVING IN OTHER PLACES To test out HuBERT you just need to update the parameter for load() asr_df = nlu.load(&#39;en.speech2text.hubert&#39;).predict(&#39;ngm_12484_01067234848.wav&#39;) asr_df Image Classification Demo Notebook For the first time ever NLU introduces state-of-the-art image classifiers based on VIT and Swin giving you access to hundreds of image classifiers for various domains. Inspired by the Transformer scaling successes in NLP, the researchers experimented with applying a standard Transformer directly to images, with the fewest possible modifications. To do so, images are split into patches and the sequence of linear embeddings of these patches were provided as an input to a Transformer. Image patches were actually treated the same way as tokens (words) in an NLP application. Image classification models were trained in supervised fashion. You can check Scale Vision Transformers (ViT) Beyond Hugging Face article to learn deeper how ViT works and how it is implemeted in Spark NLP. This is Powerd by Spark-NLP’s VitForImageClassification Annotator Swin is a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks This is powerd by Spark-NLP’s Swin For Image Classification Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo. Usage: # Download an image os.system(&#39;wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/release/4.2.0/tests/datasets/ocr/vit/ox.jpg&#39;) # Load VIT model and predict on image file vit = nlu.load(&#39;en.classify_image.base_patch16_224&#39;).predict(&#39;ox.jpg&#39;) Lets download a folder of images and predict on it !wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/images.zip import shutil shutil.unpack_archive(&quot;images.zip&quot;, &quot;images&quot;, &quot;zip&quot;) ! ls /content/images/images/ Once we have image data its easy to label it, we just pass the folder with images to nlu.predict() and NLU will return a pandas DF with one row per image detected nlu.load(&#39;en.classify_image.base_patch16_224&#39;).predict(&#39;/content/images/images&#39;) To use SWIN we just update the parameter to load() load(&#39;en.classify_image.swin.tiny&#39;).predict(&#39;/content/images/images&#39;) Visual Table Question Answering TapasForQuestionAnswering can load TAPAS Models with a cell selection head and optional aggregation head on top for question-answering tasks on tables (linear layers on top of the hidden-states output to compute logits and optional logits_aggregation), e.g. for SQA, WTQ or WikiSQL-supervised tasks. TAPAS is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. Demo Notebook Powered by TAPAS: Weakly Supervised Table Parsing via Pre-training Usage: First we need a pandas dataframe on for which we want to ask questions. The so called “context” import pandas as pd context_df = pd.DataFrame({ &#39;name&#39;:[&#39;Donald Trump&#39;,&#39;Elon Musk&#39;], &#39;money&#39;: [&#39;$100,000,000&#39;,&#39;$20,000,000,000,000&#39;], &#39;married&#39;: [&#39;yes&#39;,&#39;no&#39;], &#39;age&#39; : [&#39;75&#39;,&#39;55&#39;] }) context_df Then we create an array of questions questions = [ &quot;Who earns less than 200,000,000?&quot;, &quot;Who earns more than 200,000,000?&quot;, &quot;Who earns 100,000,000?&quot;, &quot;How much money has Donald Trump?&quot;, &quot;Who is the youngest?&quot;, ] questions Now Combine the data, pass it to NLU and get answers for your questions import nlu # Now we combine both to a tuple and we are done! We can now pass this to the .predict() method tapas_data = (context_df, questions) # Lets load a TAPAS QA model and predict on (context,question). # It will give us an aswer for every question in the questions array, based on the context in context_df answers = nlu.load(&#39;en.answer_question.tapas.wtq.large_finetuned&#39;).predict(tapas_data) answers sentence tapas_qa_UNIQUE_aggregation tapas_qa_UNIQUE_answer tapas_qa_UNIQUE_cell_positions tapas_qa_UNIQUE_cell_scores tapas_qa_UNIQUE_origin_question Who earns less than 200,000,000? NONE Donald Trump [0, 0] 1 Who earns less than 200,000,000? Who earns more than 200,000,000? NONE Elon Musk [0, 1] 1 Who earns more than 200,000,000? Who earns 100,000,000? NONE Donald Trump [0, 0] 1 Who earns 100,000,000? How much money has Donald Trump? SUM SUM($100,000,000) [1, 0] 1 How much money has Donald Trump? Who is the youngest? NONE Elon Musk [0, 1] 1 Who is the youngest? Zero-Shot NER Demo Notebook Based on John Snow Labs Enterprise-NLP ZeroShotNerModel This architecture is based on RoBertaForQuestionAnswering. Zero shot models excel at generalization, meaning that the model can accurately predict entities in very different data sets without the need to fine tune the model or train from scratch for each different domain. Even though a model trained to solve a specific problem can achieve better accuracy than a zero-shot model in this specific task, it probably won’t be be useful in a different task. That is where zero-shot models shows its usefulness by being able to achieve good results in various domains. Usage: We just need to load the zero-shot NER model and configure a set of entity definitions. import nlu # load zero-shot ner model enterprise_zero_shot_ner = nlu.load(&#39;en.zero_shot.ner_roberta&#39;) # Configure entity definitions enterprise_zero_shot_ner[&#39;zero_shot_ner&#39;].setEntityDefinitions( { &quot;PROBLEM&quot;: [ &quot;What is the disease?&quot;, &quot;What is his symptom?&quot;, &quot;What is her disease?&quot;, &quot;What is his disease?&quot;, &quot;What is the problem?&quot;, &quot;What does a patient suffer&quot;, &quot;What was the reason that the patient is admitted to the clinic?&quot;, ], &quot;DRUG&quot;: [ &quot;Which drug?&quot;, &quot;Which is the drug?&quot;, &quot;What is the drug?&quot;, &quot;Which drug does he use?&quot;, &quot;Which drug does she use?&quot;, &quot;Which drug do I use?&quot;, &quot;Which drug is prescribed for a symptom?&quot;, ], &quot;ADMISSION_DATE&quot;: [&quot;When did patient admitted to a clinic?&quot;], &quot;PATIENT_AGE&quot;: [ &quot;How old is the patient?&quot;, &quot;What is the gae of the patient?&quot;, ], } ) Then we can already use this pipeline to predict labels # Predict entities df = enterprise_zero_shot_ner.predict( [ &quot;The doctor pescribed Majezik for my severe headache.&quot;, &quot;The patient was admitted to the hospital for his colon cancer.&quot;, &quot;27 years old patient was admitted to clinic on Sep 1st by Dr.&quot;+ &quot;X for a right-sided pleural effusion for thoracentesis.&quot;, ] ) df document entities_zero_shot entities_zero_shot_class entities_zero_shot_confidence entities_zero_shot_origin_chunk entities_zero_shot_origin_sentence The doctor pescribed Majezik for my severe headache. Majezik DRUG 0.646716 0 0 The doctor pescribed Majezik for my severe headache. severe headache PROBLEM 0.552635 1 0 The patient was admitted to the hospital for his colon cancer. colon cancer PROBLEM 0.88985 0 0 27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis. 27 years old PATIENT_AGE 0.694308 0 0 27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis. Sep 1st ADMISSION_DATE 0.956461 1 0 27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis. a right-sided pleural effusion for thoracentesis PROBLEM 0.500266 2 0 New Notebooks Image Classification with VIT and Swin Zero-Shot-NER Table Question Answering with TAPAS Automatic Speech Recognition with Wav2Vec2 and HuBERT New Models Overview Supported Languages are: ab, am, ar, ba, bem, bg, bn, ca, co, cs, da, de, dv, el, en, es, et, eu, fa, fi, fon, fr, fy, ga, gam, gl, gu, ha, he, hi, hr, hu, id, ig, is, it, ja, jv, kin, kn, ko, kr, ku, ky, la, lg, lo, lt, lu, luo, lv, lwt, ml, mn, mr, ms, mt, nb, nl, no, pcm, pl, pt, ro, ru, rw, sg, si, sk, sl, sq, st, su, sv, sw, swa, ta, te, th, ti, tl, tn, tr, tt, tw, uk, unk, ur, uz, vi, wo, xx, yo, yue, zh, zu Automatic Speech Recognition Models Overview Language NLU Reference Spark NLP Reference Annotator Class ab ab.speech2text.wav2vec_xlsr.gpu.by_hf_test asr_xls_r_ab_test_by_hf_test_gpu Wav2Vec2ForCTC ba ba.speech2text.wav2vec_xlsr.v2_large_300m_gpu asr_wav2vec2_large_xls_r_300m_bashkir_cv7_opt_gpu Wav2Vec2ForCTC bem bem.speech2text.wav2vec_xlsr.v2_large_gpu.by_csikasote asr_wav2vec2_large_xlsr_bemba_gpu Wav2Vec2ForCTC bg bg.speech2text.wav2vec_xlsr.v2_large_300m_d2_gpu asr_wav2vec2_large_xls_r_300m_d2_gpu Wav2Vec2ForCTC ca ca.speech2text.wav2vec2.voxpopuli.v2_large_gpu asr_wav2vec2_large_100k_voxpopuli_catala_by_ccoreilly_gpu Wav2Vec2ForCTC cs cs.speech2text.wav2vec_xlsr.v2_large.by_arampacha asr_wav2vec2_large_xlsr_czech Wav2Vec2ForCTC da da.speech2text.wav2vec2.v2_base asr_alvenir_wav2vec2_base_nst_cv9 Wav2Vec2ForCTC de de.speech2text.wav2vec_xlsr.v3_large.by_marcel asr_wav2vec2_large_xlsr_german_demo Wav2Vec2ForCTC el el.speech2text.wav2vec_xlsr.v3_large_gpu.by_skylord asr_wav2vec2_large_xlsr_greek_2_gpu Wav2Vec2ForCTC en en.speech2text.wav2vec_xlsr.v2gpu.by_bakhtullah123 asr_xlsr_training_gpu Wav2Vec2ForCTC fa fa.speech2text.wav2vec2.v2_gpu_s117_exp asr_exp_w2v2t_pretraining_s117_gpu Wav2Vec2ForCTC fa fa.speech2text.wav2vec_xlsr.v2_s44_exp asr_exp_w2v2t_xls_r_s44 Wav2Vec2ForCTC fi fi.speech2text.wav2vec2.voxpopuli.v2_base asr_wav2vec2_base_10k_voxpopuli Wav2Vec2ForCTC fi fi.speech2text.wav2vec_xlsrby_aapot asr_wav2vec2_xlsr_1b_finnish_lm_by_aapot Wav2Vec2ForCTC fon fon.speech2text.wav2vec_xlsr asr_fonxlsr Wav2Vec2ForCTC fr fr.speech2text.wav2vec_xlsr.v2_s800_exp asr_exp_w2v2t_xlsr_53_s800 Wav2Vec2ForCTC gu gu.speech2text.wav2vec_xlsr.v2_large_gpu asr_wav2vec2_large_xlsr_gpu Wav2Vec2ForCTC hi hi.speech2text.wav2vec2.by_harveenchadha asr_hindi_model_with_lm_vakyansh Wav2Vec2ForCTC hi hi.speech2text.wav2vec_xlsr.v2_large_gpu asr_wav2vec2_large_xlsr_hindi_gpu Wav2Vec2ForCTC hu hu.speech2text.wav2vec2.voxpopuli.v2_base_gpu asr_wav2vec2_base_10k_voxpopuli_gpu Wav2Vec2ForCTC hu hu.speech2text.wav2vec_xlsr.v2_large_gpu.by_gchhablani asr_wav2vec2_large_xlsr_gpu Wav2Vec2ForCTC id id.speech2text.wav2vec_xlsr.v2_s449_exp asr_exp_w2v2t_xlsr_53_s449 Wav2Vec2ForCTC it it.speech2text.wav2vec2.v2_gpu_s149_vp_exp asr_exp_w2v2t_vp_100k_s149_gpu Wav2Vec2ForCTC it it.speech2text.wav2vec_xlsr.v2_s417_exp asr_exp_w2v2t_xls_r_s417 Wav2Vec2ForCTC ja ja.speech2text.wav2vec_xlsr.v2_large asr_wav2vec2_large_xlsr_japanese_hiragana Wav2Vec2ForCTC ko ko.speech2text.wav2vec_xlsr.v2_large_gpu asr_wav2vec2_large_xlsr_korean_gpu Wav2Vec2ForCTC kr kr.speech2text.wav2vec_xlsr.v2 asr_wav2vec2_xlsr_korean_senior Wav2Vec2ForCTC kr kr.speech2text.wav2vec_xlsr.v2_gpu asr_wav2vec2_xlsr_korean_senior_gpu Wav2Vec2ForCTC ku ku.speech2text.wav2vec_xlsr.gpu asr_xlsr_kurmanji_kurdish_gpu Wav2Vec2ForCTC ky ky.speech2text.wav2vec_xlsr.v2_large asr_wav2vec2_large_xlsr_53_kyrgyz Wav2Vec2ForCTC ky ky.speech2text.wav2vec_xlsr.v2_large_gpu.by_iarfmoose asr_wav2vec2_large_xlsr_kyrgyz_by_iarfmoose_gpu Wav2Vec2ForCTC la la.speech2text.wav2vec2.v2_base asr_wav2vec2_base_latin Wav2Vec2ForCTC la la.speech2text.wav2vec2.v2_base_gpu asr_wav2vec2_base_latin_gpu Wav2Vec2ForCTC lg lg.speech2text.wav2vec_xlsr.v2_multilingual_gpu asr_wav2vec2_xlsr_multilingual_56_gpu Wav2Vec2ForCTC lt lt.speech2text.wav2vec_xlsr.v2_large_gpu.by_dundar asr_wav2vec2_large_xlsr_53_lithuanian_by_dundar_gpu Wav2Vec2ForCTC lv lv.speech2text.wav2vec_xlsr.v2_large asr_wav2vec2_large_xlsr_53_latvian Wav2Vec2ForCTC lv lv.speech2text.wav2vec_xlsr.v2_large_gpu.by_jimregan asr_wav2vec2_large_xlsr_latvian_gpu Wav2Vec2ForCTC mn mn.speech2text.wav2vec_xlsr.v2_large_gpu.by_manandey asr_wav2vec2_large_xlsr_mongolian_by_manandey_gpu Wav2Vec2ForCTC nl nl.speech2text.wav2vec_xlsr.v2_s972_exp asr_exp_w2v2t_xlsr_53_s972 Wav2Vec2ForCTC pt pt.speech2text.wav2vec_xlsr.voxforge1.gpu.by_lgris asr_bp_voxforge1_xlsr_gpu Wav2Vec2ForCTC ro ro.speech2text.wav2vec_xlsr.v2_large_gpu asr_wav2vec2_large_xlsr_53_romanian_by_gmihaila_gpu Wav2Vec2ForCTC sg sg.speech2text.wav2vec_xlsr.v2_large_gpu asr_wav2vec2_large_xlsr_53_swiss_german_gpu Wav2Vec2ForCTC su su.speech2text.wav2vec_xlsr.v2_large_gpu asr_wav2vec2_large_xlsr_sundanese_gpu Wav2Vec2ForCTC sv sv.speech2text.wav2vec_xlsr.v2_large_gpu.by_marma asr_wav2vec2_large_xlsr_swedish_gpu Wav2Vec2ForCTC tt tt.speech2text.wav2vec_xlsr.v2_large_small asr_wav2vec2_large_xlsr_53_W2V2_TATAR_SMALL Wav2Vec2ForCTC tw tw.speech2text.wav2vec_xlsr.v2 asr_wav2vec2large_xlsr_akan Wav2Vec2ForCTC uz uz.speech2text.wav2vec2 asr_uzbek_stt Wav2Vec2ForCTC vi vi.speech2text.wav2vec_xlsr.v2_large_gpu.by_not_tanh asr_wav2vec2_large_xlsr_53_vietnamese_by_not_tanh_gpu Wav2Vec2ForCTC wo wo.speech2text.wav2vec_xlsr.v2_300m_gpu asr_av2vec2_xls_r_300m_wolof_lm_gpu Wav2Vec2ForCTC yue yue.speech2text.wav2vec_xlsr.v2_large_gpu asr_wav2vec2_large_xlsr_cantonese_by_ctl_gpu Wav2Vec2ForCTC Image Classification Models Overview Language NLU Reference Spark NLP Reference Annotator Class en en.classify_image.Check_GoodBad_Teeth image_classifier_vit_Check_GoodBad_Teeth ViTForImageClassification en en.classify_image.Check_Gum_Teeth image_classifier_vit_Check_Gum_Teeth ViTForImageClassification en en.classify_image.Check_Missing_Teeth image_classifier_vit_Check_Missing_Teeth ViTForImageClassification en en.classify_image.Infrastructures image_classifier_vit_Infrastructures ViTForImageClassification en en.classify_image.Insectodoptera image_classifier_vit_Insectodoptera ViTForImageClassification en en.classify_image.Tomato_Leaf_Classifier image_classifier_vit_Tomato_Leaf_Classifier ViTForImageClassification en en.classify_image.Visual_transformer_chihuahua_cookies image_classifier_vit_Visual_transformer_chihuahua_cookies ViTForImageClassification en en.classify_image._spectrogram image_classifier_vit__spectrogram ViTForImageClassification en en.classify_image.age_classifier image_classifier_vit_age_classifier ViTForImageClassification en en.classify_image.airplanes image_classifier_vit_airplanes ViTForImageClassification en en.classify_image.animal_classifier image_classifier_vit_animal_classifier ViTForImageClassification en en.classify_image.anomaly image_classifier_vit_anomaly ViTForImageClassification en en.classify_image.apes image_classifier_vit_apes ViTForImageClassification en en.classify_image.autotrain_cifar10__base image_classifier_vit_autotrain_cifar10__base ViTForImageClassification en en.classify_image.autotrain_dog_vs_food image_classifier_vit_autotrain_dog_vs_food ViTForImageClassification en en.classify_image.baked_goods image_classifier_vit_baked_goods ViTForImageClassification en en.classify_image.base_beans image_classifier_vit_base_beans ViTForImageClassification en en.classify_image.base_cats_vs_dogs image_classifier_vit_base_cats_vs_dogs ViTForImageClassification en en.classify_image.base_cifar10 image_classifier_vit_base_cifar10 ViTForImageClassification en en.classify_image.base_food101 image_classifier_vit_base_food101 ViTForImageClassification en en.classify_image.base_movie_scenes_v1 image_classifier_vit_base_movie_scenes_v1 ViTForImageClassification en en.classify_image.base_mri image_classifier_vit_base_mri ViTForImageClassification en en.classify_image.base_patch16_224 image_classifier_vit_base_patch16_224 ViTForImageClassification en en.classify_image.base_patch16_224.by_google image_classifier_vit_base_patch16_224 ViTForImageClassification en en.classify_image.base_patch16_224_cifar10 image_classifier_vit_base_patch16_224_cifar10 ViTForImageClassification en en.classify_image.base_patch16_224_finetuned_eurosat image_classifier_vit_base_patch16_224_finetuned_eurosat ViTForImageClassification en en.classify_image.base_patch16_224_finetuned_kvasirv2_colonoscopy image_classifier_vit_base_patch16_224_finetuned_kvasirv2_colonoscopy ViTForImageClassification en en.classify_image.base_patch16_224_in21k_snacks image_classifier_vit_base_patch16_224_in21k_snacks ViTForImageClassification en en.classify_image.base_patch16_224_in21k_ucSat image_classifier_vit_base_patch16_224_in21k_ucSat ViTForImageClassification en en.classify_image.base_patch16_224_recylce_ft image_classifier_vit_base_patch16_224_recylce_ft ViTForImageClassification en en.classify_image.base_patch16_384 image_classifier_vit_base_patch16_384 ViTForImageClassification en en.classify_image.base_patch16_384.by_google image_classifier_vit_base_patch16_384 ViTForImageClassification en en.classify_image.base_patch32_384.by_google image_classifier_vit_base_patch32_384 ViTForImageClassification en en.classify_image.base_xray_pneumonia image_classifier_vit_base_xray_pneumonia ViTForImageClassification en en.classify_image.baseball_stadium_foods image_classifier_vit_baseball_stadium_foods ViTForImageClassification en en.classify_image.beer_vs_wine image_classifier_vit_beer_vs_wine ViTForImageClassification en en.classify_image.beer_whisky_wine_detection image_classifier_vit_beer_whisky_wine_detection ViTForImageClassification en en.classify_image.blocks image_classifier_vit_blocks ViTForImageClassification en en.classify_image.cifar10 image_classifier_vit_cifar10 ViTForImageClassification en en.classify_image.cifar_10_2 image_classifier_vit_cifar_10_2 ViTForImageClassification en en.classify_image.computer_stuff image_classifier_vit_computer_stuff ViTForImageClassification en en.classify_image.croupier_creature_classifier image_classifier_vit_croupier_creature_classifier ViTForImageClassification en en.classify_image.deit_base_patch16_224 image_classifier_vit_deit_base_patch16_224 ViTForImageClassification en en.classify_image.deit_base_patch16_224.by_facebook image_classifier_vit_deit_base_patch16_224 ViTForImageClassification en en.classify_image.deit_flyswot image_classifier_vit_deit_flyswot ViTForImageClassification en en.classify_image.deit_small_patch16_224 image_classifier_vit_deit_small_patch16_224 ViTForImageClassification en en.classify_image.deit_small_patch16_224.by_facebook image_classifier_vit_deit_small_patch16_224 ViTForImageClassification en en.classify_image.deit_tiny_patch16_224 image_classifier_vit_deit_tiny_patch16_224 ViTForImageClassification en en.classify_image.deit_tiny_patch16_224.by_facebook image_classifier_vit_deit_tiny_patch16_224 ViTForImageClassification en en.classify_image.demo image_classifier_vit_demo ViTForImageClassification en en.classify_image.denver_nyc_paris image_classifier_vit_denver_nyc_paris ViTForImageClassification en en.classify_image.diam image_classifier_vit_diam ViTForImageClassification en en.classify_image.digital image_classifier_vit_digital ViTForImageClassification en en.classify_image.dog image_classifier_vit_dog ViTForImageClassification en en.classify_image.dog_breed_classifier image_classifier_vit_dog_breed_classifier ViTForImageClassification en en.classify_image.dog_food__base_patch16_224_in21k image_classifier_vit_dog_food__base_patch16_224_in21k ViTForImageClassification en en.classify_image.dog_races image_classifier_vit_dog_races ViTForImageClassification en en.classify_image.dog_vs_chicken image_classifier_vit_dog_vs_chicken ViTForImageClassification en en.classify_image.doggos_lol image_classifier_vit_doggos_lol ViTForImageClassification en en.classify_image.dogs image_classifier_vit_dogs ViTForImageClassification en en.classify_image.dwarf_goats image_classifier_vit_dwarf_goats ViTForImageClassification en en.classify_image.electric_2 image_classifier_vit_electric_2 ViTForImageClassification en en.classify_image.electric_pole_type_classification image_classifier_vit_electric_pole_type_classification ViTForImageClassification en en.classify_image.ex_for_evan image_classifier_vit_ex_for_evan ViTForImageClassification en en.classify_image.finetuned_eurosat_kornia image_classifier_vit_finetuned_eurosat_kornia ViTForImageClassification en en.classify_image.flowers image_classifier_vit_flowers ViTForImageClassification en en.classify_image.food image_classifier_vit_food ViTForImageClassification en en.classify_image.fruits image_classifier_vit_fruits ViTForImageClassification en en.classify_image.garbage_classification image_classifier_vit_garbage_classification ViTForImageClassification en en.classify_image.grain image_classifier_vit_grain ViTForImageClassification en en.classify_image.greens image_classifier_vit_greens ViTForImageClassification en en.classify_image.hot_dog_or_sandwich image_classifier_vit_hot_dog_or_sandwich ViTForImageClassification en en.classify_image.hotdog_not_hotdog image_classifier_vit_hotdog_not_hotdog ViTForImageClassification en en.classify_image.housing_categories image_classifier_vit_housing_categories ViTForImageClassification en en.classify_image.hugging_geese image_classifier_vit_hugging_geese ViTForImageClassification en en.classify_image.ice_cream image_classifier_vit_ice_cream ViTForImageClassification en en.classify_image.iiif_manuscript_ image_classifier_vit_iiif_manuscript_ ViTForImageClassification en en.classify_image.indian_snacks image_classifier_vit_indian_snacks ViTForImageClassification en en.classify_image.koala_panda_wombat image_classifier_vit_koala_panda_wombat ViTForImageClassification en en.classify_image.lawn_weeds image_classifier_vit_lawn_weeds ViTForImageClassification en en.classify_image.llama_alpaca_guanaco_vicuna image_classifier_vit_llama_alpaca_guanaco_vicuna ViTForImageClassification en en.classify_image.llama_alpaca_snake image_classifier_vit_llama_alpaca_snake ViTForImageClassification en en.classify_image.llama_or_potato image_classifier_vit_llama_or_potato ViTForImageClassification en en.classify_image.llama_or_what image_classifier_vit_llama_or_what ViTForImageClassification en en.classify_image.lotr image_classifier_vit_lotr ViTForImageClassification en en.classify_image.lucky_model image_classifier_vit_lucky_model ViTForImageClassification en en.classify_image.lung_cancer image_classifier_vit_lung_cancer ViTForImageClassification en en.classify_image.mit_indoor_scenes image_classifier_vit_mit_indoor_scenes ViTForImageClassification en en.classify_image.modelversion01 image_classifier_vit_modelversion01 ViTForImageClassification en en.classify_image.my_bean_VIT image_classifier_vit_my_bean_VIT ViTForImageClassification en en.classify_image.new_york_tokyo_london image_classifier_vit_new_york_tokyo_london ViTForImageClassification en en.classify_image.occupation_prediction image_classifier_vit_occupation_prediction ViTForImageClassification en en.classify_image.opencampus_age_detection image_classifier_vit_opencampus_age_detection ViTForImageClassification en en.classify_image.orcs_and_friends image_classifier_vit_orcs_and_friends ViTForImageClassification en en.classify_image.oz_fauna image_classifier_vit_oz_fauna ViTForImageClassification en en.classify_image.pasta_pizza_ravioli image_classifier_vit_pasta_pizza_ravioli ViTForImageClassification en en.classify_image.pasta_shapes image_classifier_vit_pasta_shapes ViTForImageClassification en en.classify_image.places image_classifier_vit_places ViTForImageClassification en en.classify_image.planes_airlines image_classifier_vit_planes_airlines ViTForImageClassification en en.classify_image.planes_trains_automobiles image_classifier_vit_planes_trains_automobiles ViTForImageClassification en en.classify_image.puppies_classify image_classifier_vit_puppies_classify ViTForImageClassification en en.classify_image.rare_bottle image_classifier_vit_rare_bottle ViTForImageClassification en en.classify_image.roomclassifier image_classifier_vit_roomclassifier ViTForImageClassification en en.classify_image.rust_image_classification_1 image_classifier_vit_rust_image_classification_1 ViTForImageClassification en en.classify_image.skin_type image_classifier_vit_skin_type ViTForImageClassification en en.classify_image.snacks image_classifier_vit_snacks ViTForImageClassification en en.classify_image.south_indian_foods image_classifier_vit_south_indian_foods ViTForImageClassification en en.classify_image.string_instrument_detector image_classifier_vit_string_instrument_detector ViTForImageClassification en en.classify_image.vc_bantai__withoutAMBI_adunest image_classifier_vit_vc_bantai__withoutAMBI_adunest ViTForImageClassification en en.classify_image.trainer_rare_puppers image_classifier_vit_trainer_rare_puppers ViTForImageClassification en en.classify_image.world_landmarks image_classifier_vit_world_landmarks ViTForImageClassification NLU Version 4.1.0 Approximately 1000 new state-of-the-art transformer models for Question Answering (QA) for over 10 languages, up to 700% speedup on GPU, 100+ Embeddings such as Bert, Bert Sentence, CamemBert, DistilBert, Roberta, Roberta Sentence, Universal Sentence Encoder, Word, XLM Roberta, XLM Roberta Sentence, 40 sequence classification models, +400 token classification odels for over 10 languages various Spark NLP helper methods and much more in 1 line of code with John Snow Labs NLU 4.1.0 NLU 4.1.0 Core Overview On the NLU core side we have over 1000 new state-of-the-art models in over 10 languages. Additionally up to 700% speedup transformer-based Word Embeddings on GPU and up to 97% speedup on CPU for tensorflow operations, support for Apple M1 chips, Pyspark 3.2 and 3.3 support. Ontop of this, we are now supporting Apple M1 based architectures and every Pyspark 3.X version, while deprecating support for Pyspark 2.X. Finally, NLU-Core features various new helper methods for working with Spark NLP and embellishes now the entire universe of Annotators defined by Spark NLP. NLU captures every Annotator of Spark NLP The entire universe of Annotators in Spark NLP is now embellished by NLU Components by using generalizable annotation extractors methods and configs internally to support enable the new NLU util methods. The following annotator classes are newly captured: BertEmbeddings BertForQuestionAnswering BertForSequenceClassification BertForTokenClassification BertSentenceEmbeddings CamemBertEmbeddings ClassifierDLModel ContextSpellCheckerModel DistilBertEmbeddings DistilBertForSequenceClassification DistilBertForTokenClassification LemmatizerModel LongformerForTokenClassification NerCrfModel NerDLModel PerceptronModel RoBertaEmbeddings RoBertaForQuestionAnswering RoBertaForSequenceClassification RoBertaForTokenClassification RoBertaSentenceEmbeddings SentenceDetectorDLModel StopWordsCleaner T5Transformer UniversalSentenceEncoder WordEmbeddingsModel XlmRoBertaEmbeddings XlmRoBertaForTokenClassification XlmRoBertaSentenceEmbeddings Embeddings Embeddings provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture. On the NLU core side we have over 150 new embeddings models. We have new BertEmbeddings, BertSentenceEmbeddings, CamemBertEmbeddings, DistilBertEmbeddings, RoBertaEmbeddings, UniversalSentenceEncoder, XlmRoBertaEmbeddings, XlmRoBertaSentenceEmbeddings for in different languages. German BertEmbeddings nlu.load(&quot;de.embed.electra.base&quot;).predict(&quot;&quot;&quot;Ich liebe Spark NLP&quot;&quot;&quot;) token word_embedding_electra Ich -0.09518987685441971, -0.016133345663547516 liebe -0.07025116682052612, -0.35387516021728516 Spark -0.33390265703201294, 0.08874476701021194 NLP -0.2969835698604584, 0.1980721354484558 English BertEmbeddings text = [&quot;I love NLP&quot;] df = nlu.load(&#39;en.embed_sentence.bert.pubmed&#39;).predict(text, output_level=&#39;token&#39;) df token sentence_embedding_bert I -0.06332794576883316, -0.5097940564155579 love -0.06332794576883316, -0.5097940564155579 NLP -0.06332794576883316, -0.5097940564155579 Japan BertEmbeddings nlu.load(&quot;ja.embed.bert.base&quot;).predict(&quot;&quot;&quot;私はSpark NLPを愛しています&quot;&quot;&quot;) token word_embedding_bert 私はSpark 0.3989057242870331, -0.20664098858833313 NLPを愛しています 0.05264343321323395, -0.19963961839675903 XLM RoBerta Embeddings MultiLanguage text = [&quot;I love NLP&quot;, &quot;Me encanta usar SparkNLP&quot;] embeddings_df = nlu.load(&#39;xx.embed.xlmr_roberta.base_v2&#39;).predict(text, output_level=&#39;sentence&#39;) embeddings_df sentence word_embedding_xlmr_roberta I love NLP -0.07450243085622787, 0.022609828040003777 Me encanta usar SparkNLP 0.0961054190993309, 0.03734250366687775 RoBerta Embeddings English text = [&quot;&quot;&quot;I love Spark NLP&quot;&quot;&quot;] embeddings_df = nlu.load(&#39;en.embed.roberta&#39;).predict(text, output_level=&#39;token&#39;) embeddings_df token word_embedding_roberta I -0.06406927853822708, 0.16723069548606873 love -0.06369957327842712, 0.21014901995658875 Spark -0.1004200279712677, 0.03312099352478981 NLP -0.09467814117670059, -0.02236207202076912 Question Answering Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document. On the NLU core side we have over 200+ new question answering models. Bert For Question Answering nlu.load(&quot;answer_question.bert.base_uncased.by_ksabeh&quot;).predict(&quot;&quot;&quot;What is my name?|||&quot;My name is Clara and I live in Berkeley.&quot;&quot;&quot;) answer_confidence context question 0.3143375 “My name is Clara and I live in Berkeley. What is my name? Sequence Classification Sequence classification is the task of predicting a class label given a sequence of observations. On the NLU core side we have over 40 new sequence classification models. Bert For Sequence Classification nlu.load(&quot;classify.bert.by_mrm8488&quot;).predict(&quot;&quot;&quot;Camera - You are awarded a SiPix Digital Camera! call 09061221066 from landline. Delivery within 28 days.&quot;&quot;&quot;) classified_sequence classified_sequence_confidence sentence 1 0.89954 Camera - You are awarded a SiPix Digital Camera! call 09061221066 from landline. 0 0.93745 Delivery within 28 days. DistilBert For Sequence Classification nlu.load(&quot;de.classify.distil_bert.base&quot;).predict(&quot;Natürlich kann ich von zuwanderern mehr erwarten. muss ich sogar. sie müssen die sprache lernen, sie müssen die gepflogenheiten lernen und sich in die gesellschaft einfügen. dass muss ich nicht weil ich mich schon in die gesellschaft eingefügt habe. egal wo du hin ziehst, nirgendwo wird dir soviel zucker in den arsch geblasen wie in deutschland.&quot;) classified_sequence classified_sequence_confidence sentence non_toxic 0.955292 Natürlich kann ich von zuwanderern mehr erwarten. non_toxic 0.968591 muss ich sogar. non_toxic 0.841958 sie müssen die sprache lernen, sie müssen die gepflogenheiten lernen und sich in die gesellschaft einfügen. non_toxic 0.934119 dass muss ich nicht weil ich mich schon in die gesellschaft eingefügt habe. non_toxic 0.771795 egal wo du hin ziehst, nirgendwo wird dir soviel zucker in den arsch geblasen wie in deutschland. RoBerta For Sequence Classification nlu.load(&quot;en.classify.roberta.finetuned&quot;).predict(&quot;I love you very much!&quot;) classified_sequence classified_sequence_confidence sentence LABEL_0 0.597792 I love you very much! Lemmatizer Lemmatization in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word’s lemma, or dictionary form. On the NLU core side we have over 30 new lemmatizer models. ClassifierDLModel ClassifierDL for generic Multi-class Text Classification. ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications. The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to 100 classes. On the NLU core side we have over 5 new ClassifierDLModel models. ContextSpellCheckerModel Spell Checking is a sequence to sequence mapping problem. Given an input sequence, potentially containing a certain number of errors, ContextSpellChecker will rank correction sequences according to three things: Different correction candidates for each word — word level. The surrounding text of each word, i.e. it’s context — sentence level. The relative cost of different correction candidates according to the edit operations at the character level it requires — subword level. On the NLU core side we have over 5 new ClassifierDLModel models. Token Classification Token classification is a natural language understanding task in which a label is assigned to some tokens in a text. Some popular token classification subtasks are Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging. NER models could be trained to identify specific entities in a text, such as dates, individuals and places; and PoS tagging would identify, for example, which words in a text are verbs, nouns, and punctuation marks. We have new 463 models XlmRoBertaForTokenClassification, BertForTokenClassification, DistilBertForTokenClassification, DistilBertEmbeddings, LongformerForTokenClassification, RoBertaForTokenClassification for in different languages. BertForTokenClassification English nlu.load(&quot;en.ner.bc5cdr.biobert.disease&quot;).predict(&quot;I love you very much!&quot;) index document entities_wikiner_glove_840B_300 entities_wikiner_glove_840B_300_class entities_wikiner_glove_840B_300_confidence entities_wikiner_glove_840B_300_origin_chunk entities_wikiner_glove_840B_300_origin_sentence word_embedding_glove 0 I love you very much! I love you very much! MISC 0.66433334 0 0 [ 0.19410001 0.22603001 -0.43764001 ] BertForTokenClassification German nlu.load(&quot;de.ner.distil_bert.base_cased&quot;).predict(&quot;Ich liebe Spark NLP&quot;) index classified_token document entities_distil_bert entities_distil_bert_class entities_distil_bert_origin_chunk entities_distil_bert_origin_sentence 0 O,O,B-OTHderiv,O Ich liebe Spark NLP Spark OTHderiv 0 0 XlmRoBertaForTokenClassification Igbo nlu.load(&quot;ig.ner.xlmr_roberta.base&quot;).predict(&quot;Ahụrụ m n&#39;anya na-atọ m ụtọ&quot;) index classified_token document entities_xlmr_roberta entities_xlmr_roberta_class entities_xlmr_roberta_origin_chunk entities_xlmr_roberta_origin_sentence 0 B-ORG,I-ORG,I-ORG,I-ORG,I-ORG,I-ORG Ahụrụ m n’anya na-atọ m ụtọ Ahụrụ m n’anya na-atọ m ụtọ ORG 0 0 NerCrfModel This Named Entity Recognizer is based on a CRF Algorithm. Conditional random fields (CRFs) are a class of statistical modeling methods often applied in pattern recognition and machine learning and used for structured prediction. Whereas a classifier predicts a label for a single sample without considering “neighbouring” samples, a CRF can take context into account. To do so, the predictions are modelled as a graphical model, which represents the presence of dependencies between the predictions. What kind of graph is used depends on the application. For example, in natural language processing, “linear chain” CRFs are popular, for which each prediction is dependent only on its immediate neighbours. In image processing, the graph typically connects locations to nearby and/or similar locations to enforce that they receive similar predictions. NerCrfModel nlu.load(&#39;en.ner.ner.crf&#39;).predict(&quot;Donald Trump and Angela Merkel dont share many oppinions&quot;) index document entities_wikiner_glove_840B_300 entities_wikiner_glove_840B_300_class entities_wikiner_glove_840B_300_confidence entities_wikiner_glove_840B_300_origin_chunk entities_wikiner_glove_840B_300_origin_sentence word_embedding_glove 0 Donald Trump and Angela Merkel dont share many oppinions Donald Trump PER 0.78524995 0 0 [-0.074014 -0.23684999 0.17772 ] 0 Donald Trump and Angela Merkel dont share many oppinions Angela Merkel PER 0.7701 1 0 [-0.074014 -0.23684999 0.17772 ] NerDLModel This Named Entity recognition annotator is a generic NER model based on Neural Networks. Neural Network architecture is Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets. This is the instantiated model of the NerDLApproach. For training your own model, please see the documentation of that class. We have new 6 models. NerDLModel Japanese nlu.load(&#39;ja.ner.ner.base&#39;).predict(&quot;宮本茂氏は、日本の任天堂のゲームプロデューサーです。&quot;) index document entities_xtreme_glove_840B_300 word_embedding_glove 0 宮本茂氏は、日本の任天堂のゲームプロデューサーです。 NaN [0. 0. ] NerDLModel English text = [&quot;My name is John!&quot;] nlu.load(&#39;en.ner.conll.ner.large&#39;).predict(text, output_level=&#39;token&#39;) index entities_wikiner_glove_840B_300 entities_wikiner_glove_840B_300_class entities_wikiner_glove_840B_300_confidence entities_wikiner_glove_840B_300_origin_chunk entities_wikiner_glove_840B_300_origin_sentence token word_embedding_glove 0 My name is John! MISC 0.63266003 0 0 My [-2.19990000e-01 2.57800013e-01 -4.25859988e-01 ] 0 My name is John! MISC 0.63266003 0 0 name [ 2.32309997e-01 -2.41020005e-02] 0 My name is John! MISC 0.63266003 0 0 is [-8.49609971e-02 5.01999974e-01 2.38230010e-03] 0 My name is John! MISC 0.63266003 0 0 John [-2.96090007e-01 -8.18260014e-02 9.67490021e-03 ] 0 My name is John! MISC 0.63266003 0 0 ! [-2.65540004e-01 3.35310012e-01 2.18600005e-01 ] PerceptronModel We have new 26 models. StopWordsCleaner This model removes ‘stop words’ from text. Stop words are words so common that they can be removed without significantly altering the meaning of a text. Removing stop words is useful when one wants to deal with only the most semantically important words in a text, and ignore words that are rarely semantically relevant, such as articles and prepositions. We have new 33 models. NLU Version 4.0.0 OCR Visual Tables into Pandas DataFrames from PDF/DOC(X)/PPT files, 1000+ new state-of-the-art transformer models for Question Answering (QA) for over 30 languages, up to 700% speedup on GPU, 20 Biomedical models for over 8 languages, 50+ Terminology Code Mappers between RXNORM, NDC, UMLS,ICD10, ICDO, UMLS, SNOMED and MESH, Deidentification in Romanian, various Spark NLP helper methods and much more in 1 line of code with John Snow Labs NLU 4.0.0 NLU 4.0 for OCR Overview On the OCR side, we now support extracting tables from PDF/DOC(X)/PPT files into structured pandas dataframe, making it easier than ever before to analyze bulks of files visually! Checkout the OCR Tutorial for extracting Tables from Image/PDF/DOC(X) files to see this in action These models grab all Table data from the files detected and return a list of Pandas DataFrames, containing Pandas DataFrame for every table detected NLU Spell Transformer Class nlu.load(pdf2table) PdfToTextTable nlu.load(ppt2table) PptToTextTable nlu.load(doc2table) DocToTextTable This is powerd by John Snow Labs Spark OCR Annotataors for PdfToTextTable, DocToTextTable, PptToTextTable NLU 4.0 Core Overview On the NLU core side we have over 1000+ new state-of-the-art models in over 30 languages for modern extractive transformer-based Question Answering problems powerd by the ALBERT/BERT/DistilBERT/DeBERTa/RoBERTa/Longformer Spark NLP Annotators trained on various SQUAD-like QA datasets for domains like Twitter, Tech, News, Biomedical COVID-19 and in various model subflavors like sci_bert, electra, mini_lm, covid_bert, bio_bert, indo_bert, muril, sapbert, bioformer, link_bert, mac_bert Additionally up to 700% speedup transformer-based Word Embeddings on GPU and up to 97% speedup on CPU for tensorflow operations, support for Apple M1 chips, Pyspark 3.2 and 3.3 support. Ontop of this, we are now supporting Apple M1 based architectures and every Pyspark 3.X version, while deprecating support for Pyspark 2.X. Finally, NLU-Core features various new helper methods for working with Spark NLP and embellishes now the entire universe of Annotators defined by Spark NLP and Spark NLP for healthcare. NLU 4.0 for Healthcare Overview On the healthcare side NLU features 20 Biomedical models for over 8 languages (English, French, Italian, Portuguese, Romanian, Catalan and Galician) detect entities like HUMAN and SPECIES based on LivingNER corpus Romanian models for Deidentification and extracting Medical entities like Measurements, Form, Symptom, Route, Procedure, Disease_Syndrome_Disorder, Score, Drug_Ingredient, Pulse, Frequency, Date, Body_Part, Drug_Brand_Name, Time, Direction, Dosage, Medical_Device, Imaging_Technique, Test, Imaging_Findings, Imaging_Test, Test_Result, Weight, Clinical_Dept and Units with SPELL and SPELL respectively English NER models for parsing entities in Clinical Trial Abstracts like Age, AllocationRatio, Author, BioAndMedicalUnit, CTAnalysisApproach, CTDesign, Confidence, Country, DisorderOrSyndrome, DoseValue, Drug, DrugTime, Duration, Journal, NumberPatients, PMID, PValue, PercentagePatients, PublicationYear, TimePoint, Value using en.med_ner.clinical_trials_abstracts.pipe and also Pathogen NER models for Pathogen, MedicalCondition, Medicine with en.med_ner.pathogen and GENE_PROTEIN with en.med_ner.biomedical_bc2gm.pipeline  First Public Health Model for Emotional Stress classification It is a PHS-BERT-based model and trained with the Dreaddit dataset using en.classify.stress 50 + new Entity Mappers for problems like : Extract section headers in scientific articles and normalize them with en.map_entity.section_headers_normalized Map medical abbreviates to their definitions with en.map_entity.abbreviation_to_definition Map drugs to action and treatments with en.map_entity.drug_to_action_treatment Map drug brand to their National Drug Code (NDC) with en.map_entity.drug_brand_to_ndc Convert between terminologies using en.&lt;START_TERMINOLOGY&gt;_to_&lt;TARGET_TERMINOLOGY&gt; This works for the terminologies rxnorm, ndc, umls, icd10cm, icdo, umls, snomed, mesh snomed_to_icdo snomed_to_icd10cm rxnorm_to_umls powerd by Spark NLP for Healthcares ChunkMapper Annotator Extract Tables from PDF files as Pandas DataFrames Sample PDF: nlu.load(&#39;pdf2table&#39;).predict(&#39;/path/to/sample.pdf&#39;) Output of PDF Table OCR : mpg cyl disp hp drat wt qsec vs am gear 21 6 160 110 3.9 2.62 16.46 0 1 4 21 6 160 110 3.9 2.875 17.02 0 1 4 22.8 4 108 93 3.85 2.32 18.61 1 1 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 18.7 8 360 175 3.15 3.44 17.02 0 0 3 13.3 8 350 245 3.73 3.84 15.41 0 0 3 19.2 8 400 175 3.08 3.845 17.05 0 0 3 27.3 4 79 66 4.08 1.935 18.9 1 1 4 26 4 120.3 91 4.43 2.14 16.7 0 1 5 30.4 4 95.1 113 3.77 1.513 16.9 1 1 5 15.8 8 351 264 4.22 3.17 14.5 0 1 5 19.7 6 145 175 3.62 2.77 15.5 0 1 5 15 8 301 335 3.54 3.57 14.6 0 1 5 21.4 4 121 109 4.11 2.78 18.6 1 1 4 Extract Tables from DOC/DOCX files as Pandas DataFrames Sample DOCX: nlu.load(&#39;doc2table&#39;).predict(&#39;/path/to/sample.docx&#39;) Output of DOCX Table OCR : Screen Reader Responses Share JAWS 853 49% NVDA 238 14% Window-Eyes 214 12% System Access 181 10% VoiceOver 159 9% Extract Tables from PPT files as Pandas DataFrame Sample PPT with two tables: nlu.load(&#39;ppt2table&#39;).predict(&#39;/path/to/sample.docx&#39;) Output of PPT Table OCR : Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa and Sepal.Length Sepal.Width Petal.Length Petal.Width Species 6.7 3.3 5.7 2.5 virginica 6.7 3 5.2 2.3 virginica 6.3 2.5 5 1.9 virginica 6.5 3 5.2 2 virginica 6.2 3.4 5.4 2.3 virginica 5.9 3 5.1 1.8 virginica Span Classifiers for question answering Albert, Bert, DeBerta, DistilBert, LongFormer, RoBerta, XlmRoBerta based Transformer Architectures are now avaiable for question answering with almost 1000 models avaiable for 35 unique languages powerd by their corrosponding Spark NLP XXXForQuestionAnswering Annotator Classes and in various tuning and dataset flavours. &lt;lang&gt;.answer_question.&lt;domain&gt;.&lt;datasets&gt;.&lt;annotator_class&gt;&lt;tune info&gt;.by_&lt;username&gt; If multiple datasets or tune parameters are defined , they are connected with a _ . These substrings define up the &lt;domain&gt; part of the NLU reference Legal cuad COVID 19 Biomedical biosaq Biomedical Literature pubmed Twitter tweet Wikipedia wiki News news Tech tech These substrings define up the &lt;dataset&gt; part of the NLU reference Arabic SQUAD ARCD Turkish TQUAD German GermanQuad Indonesian AQG Korean KLUE, KORQUAD HindiCHAI Multi-LingualMLQA Multi-Lingualtydiqa Multi-Lingualxquad These substrings define up the &lt;dataset&gt; part of the NLU reference Alternative Eval method reqa Synthetic Data synqa Benchmark / Eval Method ABSA-Bench roberta_absa Arabic architecture type soqaol These substrings define the &lt;annotator_class&gt; substring, if it does not map to a sparknlp annotator sci_bert electra mini_lm covid_bert bio_bert indo_bert muril sapbert bioformer link_bert mac_bert These substrings define the &lt;tune_info&gt; substring, if it does not map to a sparknlp annotator Train tweaks : multilingual,mini_lm,xtremedistiled,distilled,xtreme,augmented,zero_shot Size tweaks xl, xxl, large, base, medium, base, small, tiny, cased, uncased Dimension tweaks : 1024d,768d,512d,256d,128d,64d,32d QA DataFormat You need to use one of the Data formats below to pass context and question correctly to the model. # use ||| to seperate question||context data = &#39;What is my name?|||My name is Clara and I live in Berkeley&#39; # pass a tuple (question,context) data = (&#39;What is my name?&#39;,&#39;My name is Clara and I live in Berkeley&#39;) # use pandas Dataframe, one column = question, one column=context data = pd.DataFrame({ &#39;question&#39;: [&#39;What is my name?&#39;], &#39;context&#39;: [&quot;My name is Clara and I live in Berkely&quot;] }) # Get your answers with any of above formats nlu.load(&quot;en.answer_question.squadv2.deberta&quot;).predict(data) returns : answer answer_confidence context question Clara 0.994931 My name is Clara and I live in Berkely What is my name? New NLU helper Methods You can see all features showcased in the notebook or on the new docs page for Spark NLP utils nlu.viz(pipe,data) Visualize input data with an already configured Spark NLP pipeline, for Algorithms of type (Ner,Assertion, Relation, Resolution, Dependency) using Spark NLP Display Automatically infers applicable viz type and output columns to use for visualization. Example: # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu.viz(ade_pipeline, text) returns: If a pipeline has multiple models candidates that can be used for a viz, the first Annotator that is vizzable will be used to create viz. You can specify which type of viz to create with the viz_type parameter Output columns to use for the viz are automatically deducted from the pipeline, by using the first annotator that provides the correct output type for a specific viz. You can specify which columns to use for a viz by using the corresponding ner_col, pos_col, dep_untyped_col, dep_typed_col, resolution_col, relation_col, assertion_col, parameters. nlu.autocomplete_pipeline(pipe) Auto-Complete a pipeline or single annotator into a runnable pipeline by harnessing NLU’s DAG Autocompletion algorithm and returns it as NLU pipeline. The standard Spark pipeline is avaiable on the .vanilla_transformer_pipe attribute of the returned nlu pipe Every Annotator and Pipeline of Annotators defines a DAG of tasks, with various dependencies that must be satisfied in topoligical order. NLU enables the completion of an incomplete DAG by finding or creating a path between the very first input node which is almost always is DocumentAssembler/MultiDocumentAssembler and the very last node(s), which is given by the topoligical sorting the iterable annotators parameter. Paths are created by resolving input features of annotators to the corrrosponding providers with matching storage references. Example: # Lets autocomplete the pipeline for a RelationExtractionModel, which as many input columns and sub-dependencies. from sparknlp_jsl.annotator import RelationExtractionModel re_model = RelationExtractionModel().pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;).setOutputCol(&#39;relation&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu_pipe = nlu.autocomplete_pipeline(re_model) nlu_pipe.predict(text) returns : relation relation_confidence relation_entity1 relation_entity2 relation_entity2_class 1 1 allergic reaction vancomycin Drug_Ingredient 1 1 skin itchy Symptom 1 0.99998 skin sore throat/burning/itchy Symptom 1 0.956225 skin numbness Symptom 1 0.999092 skin tongue External_body_part_or_region 0 0.942927 skin gums External_body_part_or_region 1 0.806327 itchy sore throat/burning/itchy Symptom 1 0.526163 itchy numbness Symptom 1 0.999947 itchy tongue External_body_part_or_region 0 0.994618 itchy gums External_body_part_or_region 0 0.994162 sore throat/burning/itchy numbness Symptom 1 0.989304 sore throat/burning/itchy tongue External_body_part_or_region 0 0.999969 sore throat/burning/itchy gums External_body_part_or_region 1 1 numbness tongue External_body_part_or_region 1 1 numbness gums External_body_part_or_region 1 1 tongue gums External_body_part_or_region nlu.to_pretty_df(pipe,data) Annotates a Pandas Dataframe/Pandas Series/Numpy Array/Spark DataFrame/Python List strings /Python String with given Spark NLP pipeline, which is assumed to be complete and runnable and returns it in a pythonic pandas dataframe format. Example: # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; # output is same as nlu.autocomplete_pipeline(re_model).nlu_pipe.predict(text) nlu.to_pretty_df(ade_pipeline,text) returns : assertion asserted_entitiy entitiy_class assertion_confidence present allergic reaction ADE 0.998 present itchy ADE 0.8414 present sore throat/burning/itchy ADE 0.9019 present numbness in tongue and gums ADE 0.9991 Annotators are grouped internally by NLU into output levels token,sentence, document,chunk and relation Same level annotators output columns are zipped and exploded together to create the final output df. Additionally, most keys from the metadata dictionary in the result annotations will be collected and expanded into their own columns in the resulting Dataframe, with special handling for Annotators that encode multiple metadata fields inside of one, seperated by strings like ||| or :::. Some columns are omitted from metadata to reduce total amount of output columns, these can be re-enabled by setting metadata=True For a given pipeline output level is automatically set to the last anntators output level by default. This can be changed by defining to_preddty_df(pipe,text,output_level=&#39;my_level&#39; for levels token,sentence, document,chunk and relation . nlu.to_nlu_pipe(pipe) Convert a pipeline or list of annotators into a NLU pipeline making .predict() and .viz() avaiable for every Spark NLP pipeline. Assumes the pipeline is already runnable. # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu_pipe = nlu.to_nlu_pipe(ade_pipeline) # Same output as nlu.to_pretty_df(pipe,text) nlu_pipe.predict(text) # same output as nlu.viz(pipe,text) nlu_pipe.viz(text) # Acces auto-completed Spark NLP big data pipeline, nlu_pipe.vanilla_transformer_pipe.transform(spark_df) returns : assertion asserted_entitiy entitiy_class assertion_confidence present allergic reaction ADE 0.998 present itchy ADE 0.8414 present sore throat/burning/itchy ADE 0.9019 present numbness in tongue and gums ADE 0.9991 and 4 new Demo Notebooks These notebooks showcase some of latest classifier models for Banking Queries, Intents in Text, Question and new s classification Notebook for Classification of Banking Queries Notebook for Classification of Intent in Texts Notebook for classification of Similar Questions Notebook for Classification of Questions vs Statements Notebook for Classification of News into 4 classes NLU captures every Annotator of Spark NLP and Spark NLP for healthcare The entire universe of Annotators in Spark NLP and Spark-NLP for healthcare is now embellished by NLU Components by using generalizable annotation extractors methods and configs internally to support enable the new NLU util methods. The following annotator classes are newly captured: AssertionFilterer ChunkConverter ChunkKeyPhraseExtraction ChunkSentenceSplitter ChunkFiltererApproach ChunkFilterer ChunkMapperApproach ChunkMapperFilterer DocumentLogRegClassifierApproach DocumentLogRegClassifierModel ContextualParserApproach ReIdentification NerDisambiguator NerDisambiguatorModel AverageEmbeddings EntityChunkEmbeddings ChunkMergeApproach ChunkMergeApproach IOBTagger NerChunker NerConverterInternalModel DateNormalizer PosologyREModel RENerChunksFilter ResolverMerger AnnotationMerger Router Word2VecApproach WordEmbeddings EntityRulerApproach EntityRulerModel TextMatcherModel BigTextMatcher BigTextMatcherModel DateMatcher MultiDateMatcher RegexMatcher TextMatcher NerApproach NerCrfApproach NerOverwriter DependencyParserApproach TypedDependencyParserApproach SentenceDetectorDLApproach SentimentDetector ViveknSentimentApproach ContextSpellCheckerApproach NorvigSweetingApproach SymmetricDeleteApproach ChunkTokenizer ChunkTokenizerModel RecursiveTokenizer RecursiveTokenizerModel Token2Chunk WordSegmenterApproach GraphExtraction Lemmatizer Normalizer All NLU 4.0 for Healthcare Models Some examples: en.rxnorm.umls.mapping Code: nlu.load(&#39;en.rxnorm.umls.mapping&#39;).predict(&#39;1161611 315677&#39;) mapped_entity_umls_code_origin_entity mapped_entity_umls_code 1161611 C3215948 315677 C0984912 en.ner.clinical_trials_abstracts Code: nlu.load(&#39;en.ner.clinical_trials_abstracts&#39;).predict(&#39;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&#39;) Results:   entities_clinical_trials_abstracts entities_clinical_trials_abstracts_class entities_clinical_trials_abstracts_confidence 0 randomised CTDesign 0.9996 0 multicentre CTDesign 0.9998 0 insulin glargine Drug 0.99135 0 NPH insulin Drug 0.96875 0 type 2 diabetes DisorderOrSyndrome 0.999933 Code: nlu.load(&#39;en.ner.clinical_trials_abstracts&#39;).viz(&#39;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&#39;) Results: en.med_ner.pathogen Code: nlu.load(&#39;en.med_ner.pathogen&#39;).predict(&#39;Racecadotril is an antisecretory medication and it has better tolerability than loperamide. Diarrhea is the condition of having loose, liquid or watery bowel movements each day. Signs of dehydration often begin with loss of the normal stretchiness of the skin. While it has been speculated that rabies virus, Lyssavirus and Ephemerovirus could be transmitted through aerosols, studies have concluded that this is only feasible in limited conditions.&#39;) Results:   entities_pathogen entities_pathogen_class entities_pathogen_confidence 0 Racecadotril Medicine 0.9468 0 loperamide Medicine 0.9987 0 Diarrhea MedicalCondition 0.9848 0 dehydration MedicalCondition 0.6307 0 rabies virus Pathogen 0.95685 0 Lyssavirus Pathogen 0.9694 0 Ephemerovirus Pathogen 0.6917 Code: nlu.load(&#39;en.med_ner.pathogen&#39;).viz(&#39;Racecadotril is an antisecretory medication and it has better tolerability than loperamide. Diarrhea is the condition of having loose, liquid or watery bowel movements each day. Signs of dehydration often begin with loss of the normal stretchiness of the skin. While it has been speculated that rabies virus, Lyssavirus and Ephemerovirus could be transmitted through aerosols, studies have concluded that this is only feasible in limited conditions.&#39;) Results: es.med_ner.living_species.roberta Code: nlu.load(&#39;es.med_ner.living_species.roberta&#39;).predict(&#39;Lactante varón de dos años. Antecedentes familiares sin interés. Antecedentes personales: Embarazo, parto y periodo neonatal normal. En seguimiento por alergia a legumbres, diagnosticado con diez meses por reacción urticarial generalizada con lentejas y garbanzos, con dieta de exclusión a legumbres desde entonces. En ésta visita la madre describe episodios de eritema en zona maxilar derecha con afectación ocular ipsilateral que se resuelve en horas tras la administración de corticoides. Le ha ocurrido en 5-6 ocasiones, en relación con la ingesta de alimentos previamente tolerados. Exploración complementaria: Cacahuete, ac(ige)19.2 Ku.arb/l. Resultados: Ante la sospecha clínica de Síndrome de Frey, se tranquiliza a los padres, explicándoles la naturaleza del cuadro y se cita para revisión anual.&#39;) Results:   entities_living_species entities_living_species_class entities_living_species_confidence 0 Lactante varón HUMAN 0.93175 0 familiares HUMAN 1 0 personales HUMAN 1 0 neonatal HUMAN 0.9997 0 legumbres SPECIES 0.9962 0 lentejas SPECIES 0.9988 0 garbanzos SPECIES 0.9901 0 legumbres SPECIES 0.9976 0 madre HUMAN 1 0 Cacahuete SPECIES 0.998 0 padres HUMAN 1 Code: nlu.load(&#39;es.med_ner.living_species.roberta&#39;).viz(&#39;Lactante varón de dos años. Antecedentes familiares sin interés. Antecedentes personales: Embarazo, parto y periodo neonatal normal. En seguimiento por alergia a legumbres, diagnosticado con diez meses por reacción urticarial generalizada con lentejas y garbanzos, con dieta de exclusión a legumbres desde entonces. En ésta visita la madre describe episodios de eritema en zona maxilar derecha con afectación ocular ipsilateral que se resuelve en horas tras la administración de corticoides. Le ha ocurrido en 5-6 ocasiones, en relación con la ingesta de alimentos previamente tolerados. Exploración complementaria: Cacahuete, ac(ige)19.2 Ku.arb/l. Resultados: Ante la sospecha clínica de Síndrome de Frey, se tranquiliza a los padres, explicándoles la naturaleza del cuadro y se cita para revisión anual.&#39;) Results: All healthcare models added in NLU 4.0 : Language NLU Reference Spark NLP Reference Task Annotator Class model_id en en.map_entity.abbreviation_to_definition abbreviation_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.abbreviation_to_definition en en.map_entity.abbreviation_to_definition abbreviation_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.abbreviation_to_definition en en.map_entity.drug_to_action_treatment drug_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_to_action_treatment en en.map_entity.drug_to_action_treatment drug_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_to_action_treatment en en.map_entity.drug_to_action_treatment drug_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_to_action_treatment en en.map_entity.drug_brand_to_ndc drug_brandname_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_brand_to_ndc en en.map_entity.drug_brand_to_ndc drug_brandname_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_brand_to_ndc en en.map_entity.icd10cm_to_snomed icd10cm_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icd10cm_to_snomed en en.map_entity.icd10cm_to_umls icd10cm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icd10cm_to_umls en en.map_entity.icdo_to_snomed icdo_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icdo_to_snomed en en.map_entity.mesh_to_umls mesh_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.mesh_to_umls en en.map_entity.rxnorm_to_action_treatment rxnorm_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_action_treatment en en.map_entity.rxnorm_to_action_treatment rxnorm_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_action_treatment en en.map_entity.rxnorm_resolver rxnorm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_resolver en en.map_entity.rxnorm_resolver rxnorm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_resolver en en.map_entity.rxnorm_to_ndc rxnorm_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_ndc en en.map_entity.rxnorm_to_ndc rxnorm_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_ndc en en.map_entity.rxnorm_to_ndc rxnorm_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_ndc en en.map_entity.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_umls en en.map_entity.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_umls en en.map_entity.snomed_to_icd10cm snomed_icd10cm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_icd10cm en en.map_entity.snomed_to_icdo snomed_icdo_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_icdo en en.map_entity.snomed_to_umls snomed_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_umls en en.map_entity.snomed_to_icd10cm snomed_icd10cm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_icd10cm en en.map_entity.icd10cm_to_snomed icd10cm_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icd10cm_to_snomed en en.map_entity.snomed_to_icdo snomed_icdo_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_icdo en en.map_entity.icdo_to_snomed icdo_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icdo_to_snomed en en.map_entity.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_umls en en.map_entity.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_umls en en.map_entity.icd10cm_to_umls icd10cm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icd10cm_to_umls en en.map_entity.mesh_to_umls mesh_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.mesh_to_umls en en.map_entity.snomed_to_umls snomed_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_umls en en.map_entity.section_headers_normalized normalized_section_header_mapper Chunk Mapping PretrainedPipeline Chunk Mappingen.map_entity.section_headers_normalized en en.map_entity.section_headers_normalized normalized_section_header_mapper Chunk Mapping PretrainedPipeline Chunk Mappingen.map_entity.section_headers_normalized en en.map_entity.section_headers_normalized normalized_section_header_mapper Chunk Mapping PretrainedPipeline Chunk Mappingen.map_entity.section_headers_normalized en en.icd10cm_to_snomed icd10cm_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.icd10cm_to_snomed en en.icd10cm_to_umls icd10cm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.icd10cm_to_umls en en.icdo_to_snomed icdo_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.icdo_to_snomed en en.mesh_to_umls mesh_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.mesh_to_umls en en.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.rxnorm_to_umls en en.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.rxnorm_to_umls en en.snomed_to_icd10cm snomed_icd10cm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.snomed_to_icd10cm en en.snomed_to_icdo snomed_icdo_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.snomed_to_icdo en en.snomed_to_umls snomed_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.snomed_to_umls en en.map_entity.icd10cm_to_snomed.pipe icd10cm_snomed_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.icd10cm_to_snomed.pipe en en.map_entity.snomed_to_icd10cm.pipe snomed_icd10cm_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.snomed_to_icd10cm.pipe en en.map_entity.snomed_to_icd10cm.pipe snomed_icd10cm_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.snomed_to_icd10cm.pipe en en.map_entity.icdo_to_snomed.pipe icdo_snomed_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.icdo_to_snomed.pipe en en.map_entity.snomed_to_icdo.pipe snomed_icdo_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.snomed_to_icdo.pipe en en.map_entity.rxnorm_to_ndc.pipe rxnorm_ndc_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.rxnorm_to_ndc.pipe en en.med_ner.pathogen.pipeline ner_pathogen_pipeline Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.med_ner.pathogen.pipeline en en.med_ner.biomedical_bc2gm.pipeline ner_biomedical_bc2gm_pipeline Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.med_ner.biomedical_bc2gm.pipeline ro ro.deid.clinical clinical_deidentification Pipeline Healthcare MedicalNerModel Pipeline Healthcarero.deid.clinical en en.med_ner.clinical_trials_abstracts.pipe ner_clinical_trials_abstracts_pipeline Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.med_ner.clinical_trials_abstracts.pipe en en.ner.clinical_trials_abstracts ner_clinical_trials_abstracts Named Entity Recognition MedicalNerModel Named Entity Recognitionen.ner.clinical_trials_abstracts en en.med_ner.clinical_trials_abstracts bert_token_classifier_ner_clinical_trials_abstracts Named Entity Recognition MedicalBertForTokenClassifier Named Entity Recognitionen.med_ner.clinical_trials_abstracts en en.med_ner.pathogen ner_pathogen Named Entity Recognition MedicalNerModel Named Entity Recognitionen.med_ner.pathogen en en.med_ner.living_species.token_bert bert_token_classifier_ner_living_species Named Entity Recognition MedicalBertForTokenClassifier Named Entity Recognitionen.med_ner.living_species.token_bert en en.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionen.med_ner.living_species en en.med_ner.living_species.biobert ner_living_species_biobert Named Entity Recognition MedicalNerModel Named Entity Recognitionen.med_ner.living_species.biobert en en.classify.stress bert_sequence_classifier_stress Text Classification MedicalBertForSequenceClassification Text Classificationen.classify.stress es es.embed.scielo300d embeddings_scielo_300d Embeddings WordEmbeddingsModel Embeddingses.embed.scielo300d es es.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species es es.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species.bert es es.med_ner.living_species.roberta ner_living_species_roberta Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species.roberta es es.med_ner.living_species.300 ner_living_species_300 Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species.300 es es.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species fr fr.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionfr.med_ner.living_species fr fr.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionfr.med_ner.living_species.bert pt pt.med_ner.living_species.token_bert bert_token_classifier_ner_living_species Named Entity Recognition MedicalBertForTokenClassifier Named Entity Recognitionpt.med_ner.living_species.token_bert pt pt.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionpt.med_ner.living_species pt pt.med_ner.living_species.roberta ner_living_species_roberta Named Entity Recognition MedicalNerModel Named Entity Recognitionpt.med_ner.living_species.roberta pt pt.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionpt.med_ner.living_species.bert it it.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionit.med_ner.living_species it it.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionit.med_ner.living_species.bert it it.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionit.med_ner.living_species ca ca.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionca.med_ner.living_species gl gl.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitiongl.med_ner.living_species ro ro.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionro.med_ner.living_species.bert ro ro.med_ner.clinical ner_clinical Named Entity Recognition MedicalNerModel Named Entity Recognitionro.med_ner.clinical ro ro.embed.clinical.bert.base_cased ner_clinical_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionro.embed.clinical.bert.base_cased ro ro.med_ner.deid.subentity ner_deid_subentity Named Entity Recognition MedicalNerModel Named Entity Recognitionro.med_ner.deid.subentity ro ro.med_ner.deid.subentity.bert ner_deid_subentity_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionro.med_ner.deid.subentity.bert All NLU 4.0 Core Models All core models added in NLU 4.0 : Can be found on the NLU website because of Github Limitations NLU Reference Spark NLP Reference Task Language Name(s) Annotator Class bn.answer_question.tydiqa.multi_lingual_bert bert_qa_mbert_bengali_tydiqa_qa Question Answering Bengali BertForQuestionAnswering es.answer_question.squadv2.electra.small electra_qa_biomedtra_small_es_squad2 Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squad_sqac.bert.base_cased bert_qa_bert_base_spanish_wwm_cased_finetuned_sqac_finetuned_squad Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2.bert.base_cased.by_MMG bert_qa_bert_base_spanish_wwm_cased_finetuned_squad2_es_MMG Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2.bert.base_cased.by_mrm8488 bert_qa_bert_base_spanish_wwm_cased_finetuned_spa_squad2_es_mrm8488 Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2.bert.distilled_base_cased bert_qa_distill_bert_base_spanish_wwm_cased_finetuned_spa_squad2_es_mrm8488 Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squad.ruperta.base.by_mrm8488 roberta_qa_RuPERTa_base_finetuned_squadv1 Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2.roberta.base roberta_qa_roberta_base_bne_squad2_hackathon_pln Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2_sqac.bert.base_cased_spa.by_MMG bert_qa_bert_base_spanish_wwm_cased_finetuned_spa_squad2_es_finetuned_sqac Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2_bio_medical.roberta.base roberta_qa_roberta_base_biomedical_es_squad2_hackathon_pln Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2_clinical_bio_medical.roberta.base roberta_qa_roberta_base_biomedical_clinical_es_squad2_hackathon_pln Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2_sqac.bert.base_cased.by_MMG bert_qa_bert_base_spanish_wwm_cased_finetuned_sqac_finetuned_squad2_es_MMG Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2_sqac.bert.base_cased_v2.by_MMG bert_qa_bert_base_spanish_wwm_cased_finetuned_squad2_es_finetuned_sqac Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_spanish Question Answering Castilian, Spanish XlmRoBertaForQuestionAnswering es.answer_question.xlm_roberta.multilingual_large xlm_roberta_qa_xlm_roberta_large_qa_multilingual_finedtuned_ru_ru_AlexKay Question Answering Castilian, Spanish XlmRoBertaForQuestionAnswering es.answer_question.squad.roberta.large.by_stevemobs roberta_qa_roberta_large_fine_tuned_squad_es_stevemobs Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2.roberta.base_v2 roberta_qa_RuPERTa_base_finetuned_squadv2 Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squad.roberta.large.by_jamarju roberta_qa_roberta_large_bne_squad_2.0_es_jamarju Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.large.by_BSC-TeMU roberta_qa_BSC_TeMU_roberta_large_bne_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squad.roberta.base.by_jamarju roberta_qa_roberta_base_bne_squad_2.0_es_jamarju Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squad.roberta.base_4096.by_mrm8488 roberta_qa_longformer_base_4096_spanish_finetuned_squad Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.distil_bert.base_uncased distilbert_qa_distillbert_base_spanish_uncased_finetuned_qa_tar Question Answering Castilian, Spanish DistilBertForQuestionAnswering es.answer_question.mlqa.distil_bert.base_uncased distilbert_qa_distillbert_base_spanish_uncased_finetuned_qa_mlqa Question Answering Castilian, Spanish DistilBertForQuestionAnswering es.answer_question.sqac.bert.base bert_qa_beto_base_spanish_sqac Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.sqac.distil_bert.base_uncased distilbert_qa_distillbert_base_spanish_uncased_finetuned_qa_sqac Question Answering Castilian, Spanish DistilBertForQuestionAnswering es.answer_question.sqac.roberta.base.by_BSC-TeMU roberta_qa_BSC_TeMU_roberta_base_bne_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.base.by_IIC roberta_qa_roberta_base_spanish_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.bert.base_cased bert_qa_bert_base_spanish_wwm_cased_finetuned_sqac Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.sqac.roberta.base.by_mrm8488 roberta_qa_mrm8488_roberta_base_bne_finetuned_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.base.by_nlp-en-es roberta_qa_nlp_en_es_roberta_base_bne_finetuned_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.large.by_PlanTL-GOB-ES roberta_qa_PlanTL_GOB_ES_roberta_large_bne_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.large.by_nlp-en-es roberta_qa_bertin_large_finetuned_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squad.electra.small electra_qa_electricidad_small_finetuned_squadv1 Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squad.roberta.base.by_IIC roberta_qa_roberta_base_spanish_squades Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.base.by_PlanTL-GOB-ES roberta_qa_PlanTL_GOB_ES_roberta_base_bne_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering ch.answer_question.xlm_roberta xlm_roberta_qa_ADDI_CH_XLM_R Question Answering Chamorro XlmRoBertaForQuestionAnswering da.answer_question.squad.bert bert_qa_danish_bert_botxo_qa_squad Question Answering Danish BertForQuestionAnswering da.answer_question.squad.xlmr_roberta.base xlm_roberta_qa_xlmr_base_texas_squad_da_da_saattrupdan Question Answering Danish XlmRoBertaForQuestionAnswering nl.answer_question.squadv2.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_dutch_squad2 Question Answering Dutch, Flemish BertForQuestionAnswering en.answer_question.squad.roberta.large.by_csarron roberta_qa_roberta_large_squad_v1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.large.by_rahulchakwate roberta_qa_roberta_large_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.scibert.by_amoux bert_qa_scibert_nli_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.scibert.by_ixa-ehu bert_qa_SciBERT_SQuAD_QuAC Question Answering English BertForQuestionAnswering en.answer_question.squad.scibert.uncased bert_qa_scibert_scivocab_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert bert_qa_spanbert_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_0 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_2 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_4 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_4 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_8 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_8 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_128d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_128_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_128d_seed_4 bert_qa_spanbert_base_cased_few_shot_k_128_finetuned_squad_seed_4 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_128d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_128_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_128d_seed_8 bert_qa_spanbert_base_cased_few_shot_k_128_finetuned_squad_seed_8 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_256d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_256_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_32d_seed_0 bert_qa_spanbert_base_cased_few_shot_k_32_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_32d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_32_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_32d_seed_2 bert_qa_spanbert_base_cased_few_shot_k_32_finetuned_squad_seed_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.distilled_base roberta_qa_distilroberta_base_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_42 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_42 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.distilled roberta_qa_distilroberta_finetuned_squadv1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_sq.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_5_new Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.by_sunitha roberta_qa_Roberta_Custom_Squad_DS Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_6 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_8 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_deletion_10.by_huxxx657 roberta_qa_roberta_base_finetuned_deletion_squad_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_deletion_15.by_huxxx657 roberta_qa_roberta_base_finetuned_deletion_squad_15 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_sae.by_jgammack roberta_qa_SAE_roberta_base_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_10.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_10_new.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_10_new Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_15.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_15 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_15_v2.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_15_new Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_5.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_5 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.by_vuiseng9 roberta_qa_roberta_l_squadv1.1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.span_bert.base_cased_32d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_32_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_seed_10 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_2 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_4 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_42 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_42 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_6 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_8 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_v1.by_huxxx657 roberta_qa_roberta_base_finetuned_squad_1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_v2.by_huxxx657 roberta_qa_roberta_base_finetuned_squad_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_v3.by_huxxx657 roberta_qa_roberta_base_finetuned_squad_3 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.by_cgou roberta_qa_fin_RoBERTa_v1_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_0 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.span_bert.base_cased_512d_seed_0 bert_qa_spanbert_base_cased_few_shot_k_512_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad_battery.bert.cased.by_batterydata bert_qa_batterybert_cased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_512d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_512_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.albert.xxl.by_replydotai albert_qa_xxlarge_v1_finetuned_squad2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.xxl.by_sultan albert_qa_BioM_xxlarge_SQuAD2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.xxl_512d albert_qa_xxlargev1_squad2_512 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.xxl_v2 albert_qa_xxlarge_v2_squad2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.bert.base bert_qa_bert_base_finetuned_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_cased.by_deepset bert_base_cased_qa_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_cased.by_vumichien bert_qa_tf_bert_base_cased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_cased.by_ydshieh bert_qa_ydshieh_bert_base_cased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_uncased.by_Vasanth bert_qa_bert_base_uncased_qa_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_uncased.by_deepset bert_qa_deepset_bert_base_uncased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_uncased.by_twmkn9 bert_qa_twmkn9_bert_base_uncased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_uncased_v2 bert_qa_bert_base_uncased_finetuned_squad_v2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_v2.by_mrm8488 bert_qa_bert_mini_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_v2_5.by_mrm8488 bert_qa_bert_mini_5_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.by_augustoortiz bert_qa_bert_finetuned_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.by_maroo93 bert_qa_squad2.0 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.by_pinecone bert_qa_bert_reader_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.distilled bert_qa_xdistil_l12_h384_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.distilled_medium bert_qa_bert_medium_squad2_distilled Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large.by_Sindhu bert_qa_muril_large_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large.by_phiyodr bert_qa_bert_large_finetuned_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.albert.xxl.by_elgeish albert_qa_cs224n_squad2.0_xxlarge_v1 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.xl_v2 albert_qa_xlarge_v2_squad_v2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.large_v2 albert_qa_cs224n_squad2.0_large_v2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.base_v2.by_vumichien albert_qa_vumichien_base_v2_squad2 Question Answering English AlbertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_512d_seed_8 bert_qa_spanbert_base_cased_few_shot_k_512_finetuned_squad_seed_8 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_0 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_2 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_4 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_4 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_seed_42 bert_qa_spanbert_base_cased_few_shot_k_16_finetuned_squad_seed_42 Question Answering English BertForQuestionAnswering en.answer_question.squad.xlm_roberta.by_jakobwes xlm_roberta_qa_xlm_roberta_squad_v1.1 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squad.xlm_roberta.by_meghana xlm_roberta_qa_hitalmqa_finetuned_squad Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squad_battery.bert.base_uncased bert_qa_batterydata_bert_base_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_512d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_512_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_4 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad_battery.bert.uncased.by_batterydata bert_qa_batterybert_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad_battery.bert.uncased_only_bert.by_batterydata bert_qa_batteryonlybert_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad_battery.scibert.cased bert_qa_batteryscibert_cased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad_battery.scibert.uncased bert_qa_batteryscibert_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad_ben_tel.bert.by_krinal214 bert_qa_bert_all_squad_ben_tel_context Question Answering English BertForQuestionAnswering en.answer_question.squad_covid.bert bert_qa_covid_squad Question Answering English BertForQuestionAnswering en.answer_question.squad_pubmed.biobert bert_qa_biobert_v1.1_pubmed_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad_translated.bert.by_krinal214 bert_qa_bert_all_squad_all_translated Question Answering English BertForQuestionAnswering en.answer_question.squad_translated.bert.que.by_krinal214 bert_qa_bert_all_squad_que_translated Question Answering English BertForQuestionAnswering en.answer_question.squadv2.albert.base_v2.by_elgeish albert_qa_cs224n_squad2.0_base_v2 Question Answering English AlbertForQuestionAnswering en.answer_question.squad_battery.bert.cased_only_bert.by_batterydata bert_qa_batteryonlybert_cased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_2 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_10 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_0 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_mtl.by_jgammack distilbert_qa_MTL_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_sae.by_jgammack distilbert_qa_SAE_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v2.by_arvalinno distilbert_qa_base_uncased_finetuned_indosquad_v2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v2.by_ericRosello distilbert_qa_base_uncased_finetuned_squad_frozen_v2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v2.by_holtin distilbert_qa_holtin_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v2.by_huxxx657 distilbert_qa_base_uncased_finetuned_jumbling_squad_15 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v3.by_anurag0077 distilbert_qa_anurag0077_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_AyushPJ distilbert_qa_test_squad_trained_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_ZYW distilbert_qa_test_squad_trained Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_abhilash1910 distilbert_qa_squadv1 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_rowan1224 distilbert_qa_squad_slp Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_sunitha distilbert_qa_AQG_CV_Squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_tabo distilbert_qa_checkpoint_500_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.electra electra_qa_squad_slp Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.base.by_Palak electra_qa_google_base_discriminator_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.base.by_mrm8488 electra_qa_base_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.base.by_usami electra_qa_base_discriminator_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.base.by_valhalla electra_qa_base_discriminator_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.large.by_howey electra_qa_large_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.small.by_Palak electra_qa_google_small_discriminator_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.small.by_bdickson electra_qa_small_discriminator_finetuned_squad_1 Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_full.by_holtin distilbert_qa_base_uncased_holtin_finetuned_full_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_colab.by_Adrian distilbert_qa_base_uncased_finetuned_squad_colab Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_vkrishnamoorthy distilbert_qa_vkrishnamoorthy_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_vkmr distilbert_qa_vkmr_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_gokulkarthik distilbert_qa_gokulkarthik_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_graviraja distilbert_qa_graviraja_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_guhuawuli distilbert_qa_guhuawuli_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_hark99 distilbert_qa_hark99_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_hcy11 distilbert_qa_hcy11_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_hiiii23 distilbert_qa_hiiii23_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_holtin distilbert_qa_base_uncased_holtin_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_huggingfaceepita distilbert_qa_huggingfaceepita_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_huxxx657 distilbert_qa_huxxx657_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_jgammack distilbert_qa_jgammack_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.electra.small.by_hankzhong electra_qa_hankzhong_small_discriminator_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_jhoonk distilbert_qa_jhoonk_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_kaggleodin distilbert_qa_kaggleodin_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_lewtun distilbert_qa_base_uncased_finetuned_squad_v1 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_machine2049 distilbert_qa_base_uncased_finetuned_squad_ Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_manudotc distilbert_qa_transformers_base_uncased_finetuneQA_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_sunitha distilbert_qa_base_uncased_3feb_2022_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_tli8hf distilbert_qa_unqover_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_tucan9389 distilbert_qa_tucan9389_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_uploaded by huggingface distilbert_qa_base_uncased_distilled_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_usami distilbert_qa_usami_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_vitusya distilbert_qa_vitusya_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_jsunster distilbert_qa_jsunster_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_10 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.electra.small.by_mrm8488 electra_qa_small_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.ixam_bert.by_MarcBrun bert_qa_ixambert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_42 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_42 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_6 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_8 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_0 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_10 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_2 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_4 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_6 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_8 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_0 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.bert.large_tiny_768d.by_MichelBartels bert_qa_tinybert_6l_768d_squad2_large_teacher_finetuned Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_2 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_4 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_6 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_8 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_0 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_10 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_2 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_4 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_6 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_8 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_4 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_2 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_10 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_0 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.ixam_bert.eu_en_tunedby_MarcBrun bert_qa_ixambert_finetuned_squad_eu_en_MarcBrun Question Answering English BertForQuestionAnswering en.answer_question.squad.ixam_bert.eu_tuned.by_MarcBrun bert_qa_ixambert_finetuned_squad_eu_MarcBrun Question Answering English BertForQuestionAnswering en.answer_question.squad.link_bert.large bert_qa_linkbert_large_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.multi_lingual_bert.by_ZYW bert_qa_squad_mbert_model Question Answering English BertForQuestionAnswering en.answer_question.squad.multi_lingual_bert.en_de_es.by_ZYW bert_qa_squad_mbert_en_de_es_model Question Answering English BertForQuestionAnswering en.answer_question.squad.multi_lingual_bert.en_de_es_vi_zh.by_ZYW bert_qa_squad_mbert_en_de_es_vi_zh_model Question Answering English BertForQuestionAnswering en.answer_question.squad.multi_lingual_bert.v2.by_ZYW bert_qa_squad_mbert_model_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base.by_Firat roberta_qa_Firat_roberta_base_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_ahmedattia143 roberta_qa_roberta_squadv1_base Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_csarron roberta_qa_roberta_base_squad_v1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.electra.small_v2.by_bdickson electra_qa_small_discriminator_finetuned_squad_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base.by_huxxx657 roberta_qa_huxxx657_roberta_base_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_mrm8488 roberta_qa_roberta_base_1B_1_finetuned_squadv1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_rahulchakwate roberta_qa_rahulchakwate_roberta_base_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_tli8hf roberta_qa_unqover_roberta_base_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_0 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_10 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_2 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_4 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_42 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_42 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_6 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_8 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_jgammack roberta_qa_roberta_base_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.bert.large_tiny_768d_v2.by_MichelBartels bert_qa_tinybert_6l_768d_squad2_large_teacher_finetuned_step1 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_768d bert_qa_tinybert_6l_768d_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased.by_andi611 bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_mit_restaurant_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_4l_256d_a4a_256d bert_qa_bert_uncased_L_4_H_256_A_4_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_4l_512d_a8a_512d bert_qa_bert_uncased_L_4_H_512_A_8_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_4l_768d_a12a_768d bert_qa_bert_uncased_L_4_H_768_A_12_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_6l_128d_a2a_128d bert_qa_bert_uncased_L_6_H_128_A_2_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.distil_bert.base_uncased distilbert_qa_base_uncased_squad2_covid_qa_deepset Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_covid.electra.base electra_qa_base_squad2_covid_deepset Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.roberta.base.by_armageddon roberta_qa_roberta_base_squad2_covid_qa_deepset Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2_covid.roberta.base.by_deepset roberta_qa_roberta_base_squad2_covid Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2_covid.roberta.large roberta_qa_roberta_large_squad2_covid_qa_deepset Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2_covid_cord19.bert.uncased_10l_512d_a8a_512d bert_qa_bert_uncased_L_10_H_512_A_8_cord19_200616_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid_cord19.bert.uncased_4l_256d_a4a_256d bert_qa_bert_uncased_L_4_H_256_A_4_cord19_200616_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid_cord19.bert.uncased_4l_512d_a8a_512d bert_qa_bert_uncased_L_4_H_512_A_8_cord19_200616_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid_cord19.bert.uncased_4l_768d_a12a_768d bert_qa_bert_uncased_L_4_H_768_A_12_cord19_200616_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_pubmed.bert.v2 bert_qa_pubmed_bert_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_pubmed.biobert.v2 bert_qa_biobert_v1.1_pubmed_squad_v2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_pubmed.sapbert bert_qa_sapbert_from_pubmedbert_squad2 Question Answering English BertForQuestionAnswering en.answer_question.synqa.electra.large electra_qa_large_synqa Question Answering English BertForQuestionAnswering en.answer_question.synqa.roberta.large.by_mbartolo roberta_qa_roberta_large_synqa Question Answering English RoBertaForQuestionAnswering en.answer_question.synqa_ext.roberta.large.by_mbartolo roberta_qa_roberta_large_synqa_ext Question Answering English RoBertaForQuestionAnswering en.answer_question.tquad.bert.xtremedistiled_uncased bert_qa_xtremedistil_l6_h256_uncased_TQUAD_finetuned_lr_2e_05_epochs_9 Question Answering English BertForQuestionAnswering en.answer_question.trial.bert.by_sunitha bert_qa_Trial_3_Results Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_2l_512d_a8a_512d bert_qa_bert_uncased_L_2_H_512_A_8_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_10l_512d_a8a_512d bert_qa_bert_uncased_L_10_H_512_A_8_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.large_uncased bert_qa_bert_large_uncased_squad2_covid_qa_deepset Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.base_uncased bert_qa_bert_base_uncased_squad2_covid_qa_deepset Question Answering English BertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.distilled_base xlm_roberta_qa_xlm_roberta_base_squad2_distilled Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_squad2 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2_bioasq8b.electra.base electra_qa_BioM_Base_SQuAD2_BioASQ8B Question Answering English BertForQuestionAnswering en.answer_question.squadv2_bioasq8b.electra.large electra_qa_BioM_Large_SQuAD2_BioASQ8B Question Answering English BertForQuestionAnswering en.answer_question.squadv2_chaii.xlm_roberta.distilled_base xlm_roberta_qa_xlm_roberta_base_squad2_distilled_finetuned_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2_chaii.xlm_roberta.distilled_base_small xlm_roberta_qa_xlm_roberta_base_squad2_distilled_finetuned_chaii_small Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2_chemical.bert.uncased bert_qa_chemical_bert_uncased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_conll.bert.large_uncased.by_andi611 bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_conll2003_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.squadv2_conll.bert.large_uncased_pistherea.by_andi611 bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_Pistherea_conll2003_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.squadv2_conll.bert.large_uncased_pwhatisthe.by_andi611 bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_Pwhatisthe_conll2003_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.trivia.albert.xxl albert_qa_xxlarge_tweetqa Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased.by_andi611 distilbert_qa_base_uncased_squad2_with_ner Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased_with_neg_with_multi.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_with_neg_with_multi Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased_with_neg_with_multi_with_repeat.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_with_neg_with_multi_with_repeat Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased_with_neg_with_repeat.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_with_neg_with_repeat Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_cord19.bert.small bert_qa_bert_small_cord19_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_10l_512d_a8a_512d bert_qa_bert_uncased_L_10_H_512_A_8_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_2l_512d_a8a_512d bert_qa_bert_uncased_L_2_H_512_A_8_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_4l_256d_a4a_256d bert_qa_bert_uncased_L_4_H_256_A_4_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_4l_512d_a8a_512d bert_qa_bert_uncased_L_4_H_512_A_8_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_4l_768d_a12a_768d bert_qa_bert_uncased_L_4_H_768_A_12_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.albert.xxl_v2 albert_qa_xxlarge_v2_squad2_covid_deepset Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased_with_neg.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_with_neg Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_v2 xlm_roberta_qa_squadv2_xlm_roberta_base Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.trivia.bert.base_1024d bert_qa_bert_base_1024_full_trivia_copied_embeddings Question Answering English BertForQuestionAnswering en.answer_question.trivia.bert.base_4096.by_MrAnderson bert_qa_bert_base_4096_full_trivia_copied_embeddings Question Answering English BertForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265898 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265898 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265899 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265899 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265900 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265900 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265901 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265901 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265902 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265902 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265903 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265903 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265904 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265904 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265905 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265905 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265906 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265906 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265907 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265907 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265908 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265908 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265909 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265909 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265910 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265910 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265911 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265911 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fr_tuned.by_Gantenbein roberta_qa_ADDI_FR_XLM_R Question Answering English RoBertaForQuestionAnswering en.answer_question.xlmr_roberta xlm_roberta_qa_XLMr_ENIS_QA_IsQ_EnA Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xquad.bert.multilingual_base bert_qa_bert_base_multilingual_xquad Question Answering English BertForQuestionAnswering en.answer_question.xquad.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_xquad Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xquad.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_xquad Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xquad_chaii.bert.cased bert_qa_bert_multi_cased_finedtuned_xquad_chaii Question Answering English BertForQuestionAnswering en.answer_question.xquad_squad.bert.cased bert_qa_bert_multi_cased_finetuned_xquadv1_finetuned_squad_colab Question Answering English BertForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265897 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265897 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_ncthuan xlm_roberta_qa_xlm_l_uetqa Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_laifuchicago xlm_roberta_qa_farm2tran Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_jeew xlm_roberta_qa_xlm_roberta_ckpt_95000 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.trivia.bert.base_512d bert_qa_bert_base_512_full_trivia Question Answering English BertForQuestionAnswering en.answer_question.trivia.bert.by_Danastos bert_qa_triviaqa_bert_el_Danastos Question Answering English BertForQuestionAnswering en.answer_question.trivia.bert.by_Kutay bert_qa_fine_tuned_tweetqa_aip Question Answering English BertForQuestionAnswering en.answer_question.trivia.distil_bert.base_uncased distilbert_qa_base_uncased_finetuned_triviaqa Question Answering English DistilBertForQuestionAnswering en.answer_question.trivia.longformer.large longformer_qa_large_4096_finetuned_triviaqa Question Answering English LongformerForQuestionAnswering en.answer_question.trivia.roberta roberta_qa_roberta_fine_tuned_tweet_sentiment_extractor Question Answering English RoBertaForQuestionAnswering en.answer_question.trivia.roberta.base roberta_qa_roberta_base_tweetqa_model Question Answering English RoBertaForQuestionAnswering en.answer_question.trivia.roberta.large roberta_qa_roberta_large_tweetqa Question Answering English RoBertaForQuestionAnswering en.answer_question.trivia.xlmr_roberta.large xlm_roberta_qa_xlmroberta_large_tweetqa Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.bert bert_qa_bert_all Question Answering English BertForQuestionAnswering en.answer_question.trivia.bert.base_2048.by_MrAnderson bert_qa_bert_base_2048_full_trivia_copied_embeddings Question Answering English BertForQuestionAnswering en.answer_question.tydiqa.bert.multilingual bert_qa_Part_2_BERT_Multilingual_Dutch_Model_E1 Question Answering English BertForQuestionAnswering en.answer_question.tydiqa.multi_lingual_bert bert_qa_Part_2_mBERT_Model_E2 Question Answering English BertForQuestionAnswering en.answer_question.tydiqa.roberta roberta_qa_roberta_tydiqa Question Answering English RoBertaForQuestionAnswering en.answer_question.tydiqa.xlm_roberta.3lang xlm_roberta_qa_xlm_3lang Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.xlm_roberta.by_horsbug98 xlm_roberta_qa_Part_1_XLM_Model_E1 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.xlm_roberta.by_krinal214 xlm_roberta_qa_xlm_all Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.xlm_roberta.v2.by_horsbug98 xlm_roberta_qa_Part_2_XLM_Model_E1 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_finetune_qa Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_Dongjae xlm_roberta_qa_mrc2reader Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_Srini99 xlm_roberta_qa_TQA Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_anukaver xlm_roberta_qa_xlm_roberta_est_qa Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.distil_bert distilbert_qa_multi_finetuned_for_xqua_on_tydiqa Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased.by_Salesforce bert_qa_qaconv_bert_large_uncased_whole_word_masking_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465525.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465525 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465523.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465523 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_mit_restaurant_with_neg_with_repeat Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_anurag0077 distilbert_qa_anurag0077_base_uncased_finetuned_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_mvonwyl distilbert_qa_mvonwyl_base_uncased_finetuned_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_tabo distilbert_qa_tabo_base_uncased_finetuned_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_twmkn9 distilbert_qa_base_uncased_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.by_threem distilbert_qa_mysquadv2_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.v2.by_threem distilbert_qa_mysquadv2_8Jan22_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.electra.base.by_PremalMatalia electra_qa_base_best_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.base.by_navteca electra_qa_base_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.base.by_sultan electra_qa_BioM_Base_SQuAD2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.base_v2 electra_qa_base_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.large.by_sultan electra_qa_BioM_Large_SQuAD2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.large.by_superspray electra_qa_large_discriminator_squad2_custom_dataset Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.large_512d electra_qa_large_discriminator_squad2_512 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.small_v2 electra_qa_small_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.longformer.base longformer_base_base_qa_squad2 Question Answering English LongformerForQuestionAnswering en.answer_question.squadv2.longformer.base_v2 longformer_qa_base_4096_finetuned_squadv2 Question Answering English LongformerForQuestionAnswering en.answer_question.squadv2.roberta.base.by_21iridescent roberta_qa_RoBERTa_base_finetuned_squad2_lwt Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_AnonymousSub roberta_qa_roberta_base_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_PremalMatalia roberta_qa_roberta_base_best_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_Shappey roberta_qa_roberta_base_QnA_squad2_trained Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.distil_bert.base_cased distilbert_base_cased_qa_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base distilbert_qa_base_squad2_custom_dataset Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.deberta deberta_v3_xsmall_qa_squad2 Question Answering English DeBertaForQuestionAnswering en.answer_question.squadv2.biobert.cased.by_ptnv-s bert_qa_biobert_squad2_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased.by_deepset bert_qa_bert_large_uncased_whole_word_masking_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased_v2.by_madlag bert_qa_bert_large_uncased_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased_v2_x2.15_f83.2_d25_hybrid.by_madlag bert_qa_bert_large_uncased_wwm_squadv2_x2.15_f83.2_d25_hybrid_v1 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased_v2_x2.63_f82.6_d16_hybrid.by_madlag bert_qa_bert_large_uncased_wwm_squadv2_x2.63_f82.6_d16_hybrid_v1 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased_whole_word_masking_v2.by_madlag bert_qa_bert_large_uncased_whole_word_masking_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.medium_v2 bert_qa_bert_medium_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.mini_lm_base_uncased bert_qa_minilm_uncased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.small.by_mrm8488 bert_qa_bert_small_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.small_v2.by_mrm8488 bert_qa_bert_small_2_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_.by_mrm8488 bert_qa_bert_tiny_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.roberta.base.by_Teepika roberta_qa_roberta_base_squad2_finetuned_selqa Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_fadhilarkan distilbert_qa_fadhilarkan_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.bert.tiny_v3.by_mrm8488 bert_qa_bert_tiny_3_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_v4.by_mrm8488 bert_qa_bert_tiny_4_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_v5.by_mrm8488 bert_qa_bert_tiny_5_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_10l_512d_a8a_512d bert_qa_bert_uncased_L_10_H_512_A_8_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_2l_512d_a8a_512d bert_qa_bert_uncased_L_2_H_512_A_8_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_4l_256d_a4a_256d bert_qa_bert_uncased_L_4_H_256_A_4_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_4l_512d_a8a_512d bert_qa_bert_uncased_L_4_H_512_A_8_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_4l_768d_a12a_768d bert_qa_bert_uncased_L_4_H_768_A_12_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_6l_128d_a2a_128d bert_qa_bert_uncased_L_6_H_128_A_2_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.biobert.cased.by_clagator bert_qa_biobert_squad2_cased Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_v2.by_mrm8488 bert_qa_bert_tiny_2_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465524.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465524 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_avioo1 roberta_qa_avioo1_roberta_base_squad2_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_deepset roberta_base_qa_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base_128d_32d_v2 roberta_qa_distilrobert_base_squadv2_328seq_128stride_test Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base_v2 roberta_qa_distilroberta_base_squad_v2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.emanuals.by_AnonymousSub roberta_qa_EManuals_RoBERTa_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.large.by_Salesforce roberta_qa_qaconv_roberta_large_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.large.by_deepset roberta_qa_roberta_large_squad2_hp Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.large.by_navteca roberta_qa_roberta_large_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.large.by_phiyodr roberta_qa_roberta_large_finetuned_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.tiny.by_deepset roberta_qa_tinyroberta_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.tiny.v2.by_deepset roberta_qa_tinyroberta_squad2_step1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.scibert.uncased_v2 bert_qa_scibert_scivocab_uncased_squad_v2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.span_bert.v2 bert_qa_spanbert_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base.by_deepset xlm_roberta_base_qa_squad2 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465514.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465514 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465515.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465515 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465516.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465516 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465517.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465517 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465518.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465518 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465519.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465519 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465520.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465520 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465521.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465521 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465522.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465522 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base.by_twmkn9 roberta_qa_distilroberta_base_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base.by_deepset roberta_qa_roberta_base_squad2_distilled Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base.by_21iridescent roberta_qa_distilroberta_base_finetuned_squad2_lwt Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.declutr.by_AnonymousSub roberta_qa_declutr_model_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_mvonwyl roberta_qa_roberta_base_finetuned_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_navteca roberta_qa_navteca_roberta_base_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_nlpconnect roberta_qa_roberta_base_squad2_nq Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_prk roberta_qa_prk_roberta_base_squad2_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_shahrukhx01 roberta_qa_roberta_base_squad2_boolq_baseline Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_sumba roberta_qa_sumba_roberta_base_squad2_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_ydshieh roberta_qa_ydshieh_roberta_base_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_hier_quadruplet_0.1_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_hier_quadruplet_0.1_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_hier_quadruplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_hier_quadruplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_hier_triplet_0.1_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_hier_triplet_0.1_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_deepakvk roberta_qa_deepakvk_roberta_base_squad2_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_hier_triplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_hier_triplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_only_classfn_twostage_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_only_classfn_twostage_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_quadruplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_bert_quadruplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_twostage_quadruplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_twostage_quadruplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_twostagequadruplet_hier_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_twostagequadruplet_hier_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_twostagetriplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_twostagetriplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_twostagetriplet_hier_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_twostagetriplet_hier_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_ruletriplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_bert_triplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_v2.by_AyushPJ roberta_qa_ai_club_inductions_21_nlp_roBERTa_base_squad_v2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_v2.by_mrm8488 roberta_qa_roberta_base_1B_1_finetuned_squadv2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.cline.by_AnonymousSub roberta_qa_cline_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_only_classfn_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_only_classfn_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_en distilbert_qa_en_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.electra.large.by_mrm8488 electra_qa_large_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_deepakvk distilbert_qa_base_uncased_distilled_squad_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.single_label_n_max.by_mcurmei distilbert_qa_single_label_N_max Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.single_label_n_max_long_training.by_mcurmei distilbert_qa_single_label_N_max_long_training Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.unique_n_max.by_mcurmei distilbert_qa_unique_N_max Question Answering English DistilBertForQuestionAnswering en.answer_question.electra.by_Andranik electra_qa_TestQA2 Question Answering English BertForQuestionAnswering en.answer_question.electra.by_carlosserquen electra_qa_elctrafp Question Answering English BertForQuestionAnswering en.answer_question.electra.by_rowan1224 electra_qa_slp Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_1 electra_qa_DSPFirst_Finetuning_1 Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_2 electra_qa_DSPFirst_Finetuning_2 Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_3 electra_qa_DSPFirst_Finetuning_3 Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_4 electra_qa_DSPFirst_Finetuning_4 Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_5 electra_qa_DSPFirst_Finetuning_5 Question Answering English BertForQuestionAnswering en.answer_question.klue.bert bert_qa_Klue_CommonSense_model Question Answering English BertForQuestionAnswering en.answer_question.klue.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_klue Question Answering English BertForQuestionAnswering en.answer_question.klue.xlm_roberta.base xlm_roberta_qa_klue_mrc_roberta_base Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_emre distilbert_qa_emre_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.korquad.bert.multilingual_base_cased.by_sangrimlee bert_qa_bert_base_multilingual_cased_korquad Question Answering English BertForQuestionAnswering en.answer_question.korquad.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_korquad_mask Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.longformer.by_Nomi97 longformer_qa_Chatbot Question Answering English LongformerForQuestionAnswering en.answer_question.longformer.by_manishiitg longformer_qa_recruit Question Answering English LongformerForQuestionAnswering en.answer_question.longformer.by_ponmari longformer_qa_ponmari Question Answering English LongformerForQuestionAnswering en.answer_question.longformer.large longformer_qa_recruit_large Question Answering English LongformerForQuestionAnswering en.answer_question.distil_bert.log_parser_winlogbeat.by_Slavka distilbert_qa_distil_bert_finetuned_log_parser_winlogbeat Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.log_parser.by_Slavka distilbert_qa_distil_bert_finetuned_log_parser_1 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.flat_n_max.by_mcurmei distilbert_qa_flat_N_max Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.custom5.by_aszidon distilbert_qa_custom5 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_cased.by_adamlin distilbert_qa_base_cased_sgd_qa_step5000 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_config1.by_nlpunibo distilbert_qa_base_config1 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_config2.by_nlpunibo distilbert_qa_base_config2 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_config3.by_nlpunibo distilbert_qa_base_config3 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_T-qualizer distilbert_qa_base_uncased_finetuned_advers Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_charlieoneill distilbert_qa_base_uncased_gradient_clinic Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_datarpit distilbert_qa_base_uncased_finetuned_natural_questions Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_machine2049 distilbert_qa_base_uncased_finetuned_duorc_ Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_tiennvcs distilbert_qa_base_uncased_finetuned_infovqa Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_Ifenna distilbert_qa_dbert_3epoch Question Answering English DistilBertForQuestionAnswering en.answer_question.longformer.v2 longformer_qa_recruit_v2 Question Answering English LongformerForQuestionAnswering en.answer_question.distil_bert.by_LucasS distilbert_qa_distilBertABSA Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_Sounak distilbert_qa_finetuned Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_ajaypyatha distilbert_qa_sdsqna Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_alinemati distilbert_qa_BERT Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_keras-io distilbert_qa_transformers_qa Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_minhdang241 distilbert_qa_robustqa_tapt Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_pakupoko distilbert_qa_bizlin_distil_model Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_poom-sci distilbert_qa_qa Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.custom.by_aszidon distilbert_qa_custom Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.custom3.by_aszidon distilbert_qa_custom3 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.custom4.by_aszidon distilbert_qa_custom4 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_Sarmad distilbert_qa_projectmodel_bert Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_cased.by_Slavka distilbert_qa_bert_base_cased_finetuned_log_parser_winlogbeat Question Answering English DistilBertForQuestionAnswering en.answer_question.mitmovie_squad.roberta.by_thatdramebaazguy roberta_qa_movie_roberta_MITmovie_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.mlqa.bert.base_uncased bert_qa_bert_base_spanish_wwm_uncased_finetuned_qa_mlqa Question Answering English BertForQuestionAnswering en.answer_question.news.roberta.qa_ft.by_AnonymousSub roberta_qa_news_pretrain_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_ft_new.by_AnonymousSub roberta_qa_news_pretrain_roberta_FT_new_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_roberta_ft_new_newsqa.by_AnonymousSub roberta_qa_roberta_FT_new_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_roberta_ft_newsqa.by_AnonymousSub roberta_qa_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.output_files.bert.by_sunitha bert_qa_output_files Question Answering English BertForQuestionAnswering en.answer_question.pubmed.bert.base_uncased.by_Shushant bert_qa_Shushant_BiomedNLP_PubMedBERT_base_uncased_abstract_fulltext_ContaminationQAmodel_PubmedBERT Question Answering English BertForQuestionAnswering en.answer_question.roberta.756523213.by_AlirezaBaneshi roberta_qa_autotrain_test2_756523213 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.756523214.by_AlirezaBaneshi roberta_qa_autotrain_test2_756523214 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.augmented roberta_qa_roberta_unaugmentedv3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_123tarunanand roberta_qa_roberta_base_finetuned Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_eAsyle roberta_qa_roberta_base_custom_QA Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_emr-se-miniproject roberta_qa_roberta_base_emr Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_nlpconnect roberta_qa_dpr_nq_reader_roberta_base Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_rsvp-ai roberta_qa_bertserini_roberta_base Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base_v2 roberta_qa_dpr_nq_reader_roberta_base_v2 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_AmazonScience roberta_qa_qanlu Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_Andranik roberta_qa_TestQaV1 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_AyushPJ roberta_qa_ai_club_inductions_21_nlp_roBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_Beri roberta_qa_legal_qa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_CNT-UPenn roberta_qa_RoBERTa_for_seizureFrequency_QA Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_triplet_roberta_ft_newsqa.by_AnonymousSub roberta_qa_fpdm_triplet_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_triplet_roberta_ft_new_newsqa.by_AnonymousSub roberta_qa_fpdm_triplet_roberta_FT_new_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_roberta_ft_newsqa.by_AnonymousSub roberta_qa_fpdm_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_hier_roberta_ft_newsqa.by_AnonymousSub roberta_qa_fpdm_hier_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.movie_squad.roberta.base roberta_qa_roberta_base_MITmovie_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.movie_squad.roberta.by_thatdramebaazguy roberta_qa_movie_roberta_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.movie_squadv2.bert.large_uncased bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_mit_movie_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.multi_lingual_bert.by_horsbug98 bert_qa_Part_1_mBERT_Model_E2 Question Answering English BertForQuestionAnswering en.answer_question.multi_lingual_bert.by_krinal214 bert_qa_mBERT_all_ty_SQen_SQ20_1 Question Answering English BertForQuestionAnswering en.answer_question.news.bert.base_uncased.by_mirbostani bert_qa_bert_base_uncased_finetuned_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.base_uncased.by_tli8hf bert_qa_unqover_bert_base_uncased_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.by_AnonymousSub bert_qa_news_pretrain_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.by_Danastos bert_qa_newsqa_bert_el_Danastos Question Answering English BertForQuestionAnswering en.answer_question.news.bert.fpdm_ft.by_AnonymousSub bert_qa_fpdm_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.mlqa.bert.base_cased bert_qa_bert_base_spanish_wwm_cased_finetuned_qa_mlqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.fpdm_ft_new.by_AnonymousSub bert_qa_fpdm_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.fpdm_hier_ft_by_AnonymousSub bert_qa_fpdm_hier_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.ft.by_AnonymousSub bert_qa_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.ft_new.by_AnonymousSub bert_qa_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.new.by_AnonymousSub bert_qa_news_pretrain_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.qa_fpdm_triplet_ft.by_AnonymousSub bert_qa_fpdm_triplet_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.qa_fpdm_triplet_ft_new.by_AnonymousSub bert_qa_fpdm_triplet_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.distil_bert.base_uncased distilbert_qa_unqover_base_uncased_newsqa Question Answering English DistilBertForQuestionAnswering en.answer_question.news.roberta.base roberta_qa_unqover_roberta_base_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.large roberta_qa_unqover_roberta_large_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_hier_roberta_ft_new_newsqa.by_AnonymousSub roberta_qa_fpdm_hier_roberta_FT_new_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.bert.fpdm_hier_ft.by_AnonymousSub bert_qa_fpdm_hier_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_Ching roberta_qa_negation_detector Question Answering English RoBertaForQuestionAnswering en.answer_question.distil_bert.base.by_minhdang241 distilbert_qa_robustqa_baseline_01 Question Answering English DistilBertForQuestionAnswering en.answer_question.cuad_gam.roberta.base.by_Gam roberta_qa_roberta_base_finetuned_cuad_gam Question Answering English RoBertaForQuestionAnswering en.answer_question.bert.by_SanayCo bert_qa_model_output Question Answering English BertForQuestionAnswering en.answer_question.bert.by_aymanm419 bert_qa_araSpeedest Question Answering English BertForQuestionAnswering en.answer_question.bert.by_ericRosello bert_qa_results Question Answering English BertForQuestionAnswering en.answer_question.bert.by_internetoftim bert_qa_demo Question Answering English BertForQuestionAnswering en.answer_question.bert.by_jackh1995 bert_qa_bert_finetuned_jackh1995 Question Answering English BertForQuestionAnswering en.answer_question.bert.by_krinal214 bert_qa_bert_all_translated Question Answering English BertForQuestionAnswering en.answer_question.bert.by_manav bert_qa_causal_qa Question Answering English BertForQuestionAnswering en.answer_question.bert.by_mezes bert_qa_eauction_section_parsing_from_pretrained Question Answering English BertForQuestionAnswering en.answer_question.bert.by_motiondew bert_qa_bert_finetuned_lr2_e5_b16_ep2 Question Answering English BertForQuestionAnswering en.answer_question.bert.by_mrm8488 bert_qa_ManuERT_for_xqua Question Answering English BertForQuestionAnswering en.answer_question.bert.by_nlpunibo bert_qa_bert Question Answering English BertForQuestionAnswering en.answer_question.bert.by_nvkha bert_qa_bert_qa_vi_nvkha Question Answering English BertForQuestionAnswering en.answer_question.bert.by_piEsposito bert_qa_braquad_bert_qna Question Answering English BertForQuestionAnswering en.answer_question.bert.by_voidful bert_qa_question_answering_zh_voidful Question Answering English BertForQuestionAnswering en.answer_question.bert.by_z-uo bert_qa_bert_qasper Question Answering English BertForQuestionAnswering en.answer_question.bert.distilled_base_uncased bert_qa_distilbert_base_uncased_finetuned_custom Question Answering English BertForQuestionAnswering en.answer_question.bert.docvqa.base_uncased.by_tiennvcs bert_qa_bert_base_uncased_finetuned_docvqa Question Answering English BertForQuestionAnswering en.answer_question.bert.infovqa.base_uncased.by_tiennvcs bert_qa_bert_base_uncased_finetuned_infovqa Question Answering English BertForQuestionAnswering en.answer_question.bert.large.by_Sounak bert_qa_bert_large_finetuned Question Answering English BertForQuestionAnswering en.answer_question.bert.large.by_atharvamundada99 bert_qa_bert_large_question_answering_finetuned_legal Question Answering English BertForQuestionAnswering en.answer_question.bert.large.by_ricardo-filho bert_qa_bert_large_faquad Question Answering English BertForQuestionAnswering en.answer_question.bert.by_Rocketknight1 bert_qa_bert_finetuned_qa Question Answering English BertForQuestionAnswering en.answer_question.bert.by_LenaSchmidt bert_qa_no_need_to_name_this Question Answering English BertForQuestionAnswering en.answer_question.bert.by_HankyStyle bert_qa_Multi_ling_BERT Question Answering English BertForQuestionAnswering en.answer_question.bert.by_ForutanRad bert_qa_bert_fa_QA_v1 Question Answering English BertForQuestionAnswering en.answer_qu estion.mqa_cls.bert.by_xraychen bert_qa_mqa_cls Question Answering English BertForQuestionAnswering en.answer_question.albert.by_AyushPJ albert_qa_ai_club_inductions_21_nlp Question Answering English AlbertForQuestionAnswering en.answer_question.albert.by_SalmanMo albert_qa_QA_1e Question Answering English AlbertForQuestionAnswering en.answer_question.albert.by_nlpunibo albert_qa_nlpunibo Question Answering English AlbertForQuestionAnswering en.answer_question.albert.by_rowan1224 albert_qa_slp Question Answering English AlbertForQuestionAnswering en.answer_question.albert.by_saburbutt albert_qa_generic Question Answering English AlbertForQuestionAnswering en.answer_question.albert.xl albert_qa_xlarge_finetuned Question Answering English AlbertForQuestionAnswering en.answer_question.bert.32d bert_qa_bert_set_date_1_lr_2e_5_bs_32_ep_4 Question Answering English BertForQuestionAnswering en.answer_question.bert.augmented bert_qa_augmented Question Answering English BertForQuestionAnswering en.answer_question.bert.base.by_peggyhuang bert_qa_finetune_bert_base_v1 Question Answering English BertForQuestionAnswering en.answer_question.bert.large_cased bert_qa_muril_large_cased_hita_qa Question Answering English BertForQuestionAnswering en.answer_question.bert.base.by_ricardo-filho bert_qa_bert_base_faquad Question Answering English BertForQuestionAnswering en.answer_question.bert.base_cased.by_CenIA bert_qa_bert_base_spanish_wwm_cased_finetuned_qa_tar Question Answering English BertForQuestionAnswering en.answer_question.bert.base_cased.by_husnu bert_qa_bert_base_turkish_cased_finetuned_lr_2e_05_epochs_3 Question Answering English BertForQuestionAnswering en.answer_question.bert.base_cased.by_nntadotzip bert_qa_bert_base_cased_IUChatbot_ontologyDts Question Answering English BertForQuestionAnswering en.answer_question.bert.base_uncased.by_CenIA bert_qa_bert_base_spanish_wwm_uncased_finetuned_qa_tar Question Answering English BertForQuestionAnswering en.answer_question.bert.base_uncased.by_machine2049 bert_qa_bert_base_uncased_finetuned_duorc_bert Question Answering English BertForQuestionAnswering en.answer_question.bert.base_uncased.by_peggyhuang bert_qa_bert_base_uncased_coqa Question Answering English BertForQuestionAnswering en.answer_question.bert.base_uncased.by_vanadhi bert_qa_bert_base_uncased_fiqa_flm_sq_flit Question Answering English BertForQuestionAnswering en.answer_question.bert.base_v2 bert_qa_finetune_bert_base_v2 Question Answering English BertForQuestionAnswering en.answer_question.bert.base_v3.by_peggyhuang bert_qa_finetune_bert_base_v3 Question Answering English BertForQuestionAnswering en.answer_question.bert.by_Danastos bert_qa_nq_bert_el_Danastos Question Answering English BertForQuestionAnswering en.answer_question.bert.base.by_xraychen bert_qa_mqa_baseline Question Answering English BertForQuestionAnswering en.answer_question.distil_bert.base.by_leemii18 distilbert_qa_robustqa_baseline_02 Question Answering English DistilBertForQuestionAnswering en.answer_question.bert.large_uncased bert_qa_bert_large_uncased_finetuned_docvqa Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_english_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_english Question Answering English BertForQuestionAnswering en.answer_question.chaii.xlm_roberta.base.by_SauravMaheshkar xlm_roberta_qa_xlm_roberta_base_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.chaii.xlm_roberta.base.by_tyqiangz xlm_roberta_qa_xlm_roberta_base_finetuned_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.chaii.xlm_roberta.large.by_SauravMaheshkar xlm_roberta_qa_xlm_roberta_large_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.chaii.xlm_roberta.large_multi.by_SauravMaheshkar xlm_roberta_qa_xlm_multi_roberta_large_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.clinical.distil_bert distilbert_qa_BERT_ClinicalQA Question Answering English DistilBertForQuestionAnswering en.answer_question.conll.distil_bert.base_uncased distilbert_qa_base_uncased_qa_with_ner Question Answering English DistilBertForQuestionAnswering en.answer_question.cord19.bert.by_JAlexis bert_qa_Bertv1_fine Question Answering English BertForQuestionAnswering en.answer_question.cord19.bert.small bert_qa_bert_small_cord19qa Question Answering English BertForQuestionAnswering en.answer_question.cord19.prueba_bert.by_JAlexis bert_qa_PruebaBert Question Answering English BertForQuestionAnswering en.answer_question.covid.distil_bert.a.by_rahulkuruvilla distilbert_qa_COVID_DistilBERTa Question Answering English DistilBertForQuestionAnswering en.answer_question.covid.distil_bert.b.by_rahulkuruvilla distilbert_qa_COVID_DistilBERTb Question Answering English DistilBertForQuestionAnswering en.answer_question.covid.distil_bert.c.by_rahulkuruvilla distilbert_qa_COVID_DistilBERTc Question Answering English DistilBertForQuestionAnswering en.answer_question.covid.longformer longformer_qa_covid Question Answering English LongformerForQuestionAnswering en.answer_question.covid_bert.a.by_rahulkuruvilla bert_qa_COVID_BERTa Question Answering English BertForQuestionAnswering en.answer_question.covid_bert.b.by_rahulkuruvilla bert_qa_COVID_BERTb Question Answering English BertForQuestionAnswering en.answer_question.covid_bert.c.by_rahulkuruvilla bert_qa_COVID_BERTc Question Answering English BertForQuestionAnswering en.answer_question.cuad.roberta.base.by_Gam roberta_qa_roberta_base_finetuned_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.cuad.roberta.base.by_Rakib roberta_qa_roberta_base_on_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.cuad.roberta.base.by_akdeniz27 roberta_qa_akdeniz27_roberta_base_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.cuad.roberta.base.by_marshmellow77 roberta_qa_marshmellow77_roberta_base_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.cuad.roberta.large roberta_qa_roberta_large_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.chaii.roberta.base roberta_qa_roberta_base_chaii Question Answering English RoBertaForQuestionAnswering en.answer_question.chaii.electra.base electra_qa_base_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.distil_bert.base_uncased distilbert_qa_base_uncased_distilled_chaii Question Answering English DistilBertForQuestionAnswering en.answer_question.chaii.distil_bert.base_cased distilbert_qa_base_cased_distilled_chaii Question Answering English DistilBertForQuestionAnswering en.answer_question.bert.multilingual_german_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_german Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_hindi_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_hindi Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_spanish_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_spanish Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_vietnamese_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_vietnamese Question Answering English BertForQuestionAnswering en.answer_question.bert.sim.by_xraychen bert_qa_mqa_sim Question Answering English BertForQuestionAnswering en.answer_question.bert.unsupsim.by_xraychen bert_qa_mqa_unsupsim Question Answering English BertForQuestionAnswering en.answer_question.bert.vi_infovqa.base_uncased.by_tiennvcs bert_qa_bert_base_uncased_finetuned_vi_infovqa Question Answering English BertForQuestionAnswering en.answer_question.bert.xtremedistiled_uncased_lr_2e_05_epochs_3.by_husnu bert_qa_xtremedistil_l6_h256_uncased_finetuned_lr_2e_05_epochs_3 Question Answering English BertForQuestionAnswering en.answer_question.bert.xtremedistiled_uncased_lr_2e_05_epochs_6.by_husnu bert_qa_xtremedistil_l6_h256_uncased_finetuned_lr_2e_05_epochs_6 Question Answering English BertForQuestionAnswering en.answer_question.bert.zero_shot.by_fractalego bert_qa_fewrel_zero_shot Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_arabic_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_arabic Question Answering English BertForQuestionAnswering en.answer_question.bert.zero_shot.by_krinal214 bert_qa_zero_shot Question Answering English BertForQuestionAnswering en.answer_question.bio_medical.bert.base bert_qa_biomedical_slot_filling_reader_base Question Answering English BertForQuestionAnswering en.answer_question.bio_medical.bert.large bert_qa_biomedical_slot_filling_reader_large Question Answering English BertForQuestionAnswering en.answer_question.biobert bert_qa_biobert_bioasq Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.base_cased bert_qa_bert_base_cased_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.cased bert_qa_bert_multi_cased_finetuned_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.large_uncased_uncased_whole_word_masking.by_SauravMaheshkar bert_qa_bert_large_uncased_whole_word_masking_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.large_uncased_uncased_whole_word_masking_finetuned.by_SauravMaheshkar bert_qa_bert_large_uncased_whole_word_masking_finetuned_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.uncased bert_qa_bert_multi_uncased_finetuned_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.distil_bert distilbert_qa_multi_finetuned_for_xqua_on_chaii Question Answering English DistilBertForQuestionAnswering en.answer_question.bio_clinical.bert bert_qa_sagemaker_BioclinicalBERT_ADR Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_LucasS roberta_qa_robertaBaseABSA Question Answering English RoBertaForQuestionAnswering en.answer_question.korquad.bert.multilingual_base_cased.by_eliza-dukim bert_qa_bert_base_multilingual_cased_korquad_v1 Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_Nakul24 roberta_qa_RoBERTa_emotion_extraction Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bert.large.by_rsvp-ai bert_qa_bertserini_bert_large_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large.by_ruselkomp bert_qa_sbert_large_nlu_ru_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_cased bert_qa_bert_large_cased_whole_word_masking_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_Graphcore bert_qa_Graphcore_bert_large_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_haddadalwi bert_qa_bert_large_uncased_whole_word_masking_finetuned_squad_finetuned_islamic_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_howey bert_qa_howey_bert_large_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_internetoftim bert_qa_internetoftim_bert_large_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_ofirzaf bert_qa_ofirzaf_bert_large_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_uploaded by huggingface bert_qa_bert_large_uncased_whole_word_masking_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased_sparse_80_1x4_block_pruneofa.by_Intel bert_qa_bert_large_uncased_squadv1.1_sparse_80_1x4_block_pruneofa Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased_sparse_90_unstructured.by_Intel bert_qa_bert_large_uncased_squadv1.1_sparse_90_unstructured Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.medium.by_anas-awadalla bert_qa_bert_medium_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.medium.by_mrm8488 bert_qa_bert_medium_wrslb_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.medium_finetuned.by_anas-awadalla bert_qa_bert_medium_pretrained_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.mini_lm_base_uncased bert_qa_MiniLM_L12_H384_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.ms_tuned.base.by_zhufy bert_qa_squad_ms_bert_base Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.multilingual_base_cased.by_Paul-Vinh bert_qa_Paul_Vinh_bert_base_multilingual_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.multilingual_base_cased.by_salti bert_qa_salti_bert_base_multilingual_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.multilingual_base_cased.by_vanichandna bert_qa_bert_base_multilingual_cased_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.multilingual_base_uncased bert_qa_bert_base_multilingual_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.sl256.by_vuiseng9 bert_qa_bert_l_squadv1.1_sl256 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.distilled_base_uncased.by_kamilali bert_qa_kamilali_distilbert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.distilled_base_uncased.by_juliusco bert_qa_juliusco_distilbert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.distilled_base_uncased.by_huggingface bert_qa_prunebert_base_uncased_6_finepruned_w_distil_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.cased bert_qa_bert_multi_cased_squad_sv_marbogusz Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Ghost1 bert_qa_bert_finetuned_squad1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Harsit bert_qa_Harsit_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_KevinChoi bert_qa_KevinChoi_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Kutay bert_qa_fine_tuned_squad_aip Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Laikokwei bert_qa_Laikokwei_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Neulvo bert_qa_Neulvo_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_andresestevez bert_qa_andresestevez_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_ankitkupadhyay bert_qa_ankitkupadhyay_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_datauma bert_qa_datauma_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_hendrixcosta bert_qa_bertimbau_squad1.1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.sl384.by_vuiseng9 bert_qa_bert_l_squadv1.1_sl384 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_huggingface-course bert_qa_huggingface_course_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_maroo93 bert_qa_squad1.1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_mrbalazs5 bert_qa_mrbalazs5_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_mrp bert_qa_mrp_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_nickmuchi bert_qa_nickmuchi_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_peterhsu bert_qa_tf_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_ruselkomp bert_qa_tests_finetuned_squad_test_bert Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_spacemanidol bert_qa_neuralmagic_bert_squad_12layer_0sparse Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_stevemobs bert_qa_bert_finetuned_squad_pytorch Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_vanichandna bert_qa_muril_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_youngjae bert_qa_youngjae_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_jatinshah bert_qa_jatinshah_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_FardinSaboori bert_qa_FardinSaboori_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.small.by_anas-awadalla bert_qa_bert_small_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.small_finetuned.by_anas-awadalla bert_qa_bert_small_pretrained_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_ParulChaudhari distilbert_qa_ParulChaudhari_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Plimpton distilbert_qa_Plimpton_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Raphaelg9 distilbert_qa_Raphaelg9_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Rocketknight1 distilbert_qa_Rocketknight1_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_SEISHIN distilbert_qa_SEISHIN_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Shashidhar distilbert_qa_Shashidhar_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Sourabh714 distilbert_qa_Sourabh714_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_SupriyaArun distilbert_qa_SupriyaArun_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Thitaree distilbert_qa_Thitaree_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Tianle distilbert_qa_Tianle_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_V3RX2000 distilbert_qa_V3RX2000_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Wiam distilbert_qa_Wiam_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_aaraki distilbert_qa_aaraki_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_abhinavkulkarni distilbert_qa_abhinavkulkarni_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_akr distilbert_qa_akr_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_andi611 distilbert_qa_andi611_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_anurag0077 distilbert_qa_base_uncased_finetuned_squad3 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_arvalinno distilbert_qa_arvalinno_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_avioo1 distilbert_qa_avioo1_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_bdickson distilbert_qa_bdickson_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_caiosantillo distilbert_qa_caiosantillo_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Nadhiya distilbert_qa_Nadhiya_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_MYX4567 distilbert_qa_MYX4567_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_HomayounSadri distilbert_qa_HomayounSadri_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Hoang distilbert_qa_Hoang_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.bert.tiny bert_qa_bert_tiny_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.v1.1.by_maroo93 bert_qa_squad1.1_1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.v1.by_vanichandna bert_qa_muril_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.v2.by_peterhsu bert_qa_peterhsu_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.v2.by_ruselkomp bert_qa_tests_finetuned_squad_test_bert_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.biobert.base_cased.by_dmis-lab bert_qa_biobert_base_cased_v1.1_squad Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_Mr-Wick roberta_qa_Roberta Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bioformer.cased bert_qa_bioformer_cased_v1.0_squad1 Question Answering English BertForQuestionAnswering en.answer_question.squad.covid_bert bert_qa_covidbert_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.covid_biobert.base_cased bert_qa_biobert_base_cased_v1.1_squad_finetuned_covbiobert Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.small.by_mrm8488 bert_qa_bert_small_wrslb_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.covid_roberta.base_cased bert_qa_biobert_base_cased_v1.1_squad_finetuned_covdrobert Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_cased.by_ncduy distilbert_qa_base_cased_distilled_squad_finetuned_squad_test Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_cased.by_uploaded by huggingface distilbert_qa_base_cased_distilled_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_small_cased distilbert_qa_base_cased_distilled_squad_finetuned_squad_small Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_tiny_cased distilbert_qa_tiny_base_cased_distilled_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_21iridescent distilbert_qa_21iridescent_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Adrian distilbert_qa_Adrian_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Ayoola distilbert_qa_Ayoola_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_FOFer distilbert_qa_FOFer_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Firat distilbert_qa_Firat_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Gayathri distilbert_qa_Gayathri_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base distilbert_qa_base_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.bert.by_Danastos bert_qa_squad_bert_el_Danastos Question Answering English BertForQuestionAnswering en.answer_question.squad.biobert.base_cased.by_juliusco bert_qa_biobert_base_cased_v1.1_squad_finetuned_biobert Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_ArpanZS bert_qa_debug_squad Question Answering English BertForQuestionAnswering en.answer_question.roberta.techqa_cline_emanuals.by_AnonymousSub roberta_qa_cline_emanuals_techqa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.techqa_declutr.by_AnonymousSub roberta_qa_declutr_techqa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.techqa_declutr_emanuals.by_AnonymousSub roberta_qa_declutr_emanuals_techqa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.testabsa.by_eAsyle roberta_qa_testABSA Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.testabsa3.by_eAsyle roberta_qa_testABSA3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.tiny_768d roberta_qa_tinyroberta_6l_768d Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.unaugv3.by_comacrae roberta_qa_roberta_unaugv3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta_absa roberta_qa_robertaABSA Question Answering English RoBertaForQuestionAnswering en.answer_question.scibert.v2 bert_qa_nolog_SciBert_v2 Question Answering English BertForQuestionAnswering en.answer_question.span_bert.by_Nakul24 bert_qa_Spanbert_emotion_extraction Question Answering English BertForQuestionAnswering en.answer_question.span_bert.by_manishiitg bert_qa_spanbert_recruit_qa Question Answering English BertForQuestionAnswering en.answer_question.span_bert.large bert_qa_spanbert_large_recruit_qa Question Answering English BertForQuestionAnswering en.answer_question.sqac.bert.base_cased bert_qa_bert_base_spanish_wwm_cased_finetuned_qa_sqac Question Answering English BertForQuestionAnswering en.answer_question.sqac.bert.base_uncased bert_qa_bert_base_spanish_wwm_uncased_finetuned_qa_sqac Question Answering English BertForQuestionAnswering en.answer_question.squad.albert.base_v2 albert_qa_base_v2_squad Question Answering English AlbertForQuestionAnswering en.answer_question.squad.albert.by_SS8 albert_qa_squad_2.0 Question Answering English AlbertForQuestionAnswering en.answer_question.squad.albert.xl albert_qa_xlarge_finetuned_squad Question Answering English AlbertForQuestionAnswering en.answer_question.squad.albert.xxl albert_qa_xxlarge_finetuned_squad Question Answering English AlbertForQuestionAnswering en.answer_question.squad.bert.accelerate.by_KevinChoi bert_qa_KevinChoi_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.accelerate.by_huggingface-course bert_qa_huggingface_course_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.accelerate.by_peterhsu bert_qa_peterhsu_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.roberta.techqa_cline.by_AnonymousSub roberta_qa_cline_techqa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.paraphrasev3.by_comacrae roberta_qa_roberta_paraphrasev3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.large_seed_4 roberta_qa_roberta_large_data_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.large_seed_0.by_anas-awadalla roberta_qa_roberta_large_data_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bert.by_DaisyMak bert_qa_bert_finetuned_squad_accelerate_10epoch_transformerfrozen Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_aravind-812 roberta_qa_roberta_train_json Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_arjunth2001 roberta_qa_priv_qna Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_billfrench roberta_qa_cyberlandr_door Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_nlpunibo roberta_qa_nlpunibo_roberta Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_pierrerappolt roberta_qa_cart Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_shmuelamar roberta_qa_REQA_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_stevemobs roberta_qa_quales_iberlef Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_sunitha roberta_qa_roberta_customds_finetune Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_veronica320 roberta_qa_QA_for_Event_Extraction Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bert.accelerate.by_youngjae bert_qa_youngjae_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_vesteinn roberta_qa_IceBERT_QA Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.ch_tuned.by_Gantenbein roberta_qa_ADDI_CH_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.cv_custom_ds.by_sunitha roberta_qa_CV_Custom_DS Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.cv_merge_ds.by_sunitha roberta_qa_CV_Merge_DS Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.de_tuned.by_Gantenbein roberta_qa_ADDI_DE_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.eda_and_parav3.by_comacrae roberta_qa_roberta_eda_and_parav3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.edav3.by_comacrae roberta_qa_roberta_edav3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.fi_tuned.by_Gantenbein roberta_qa_ADDI_FI_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.fr_tuned.by_Gantenbein roberta_qa_ADDI_FR_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.it_tuned.by_Gantenbein roberta_qa_ADDI_IT_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.large_init_large_seed_0.by_anas-awadalla roberta_qa_roberta_large_initialization_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_z-uo roberta_qa_roberta_qasper Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bert.augmented bert_qa_augmented_Squad_Translated Question Answering English BertForQuestionAnswering en.answer_question.squad.albert.by_rowan1224 albert_qa_squad_slp Question Answering English AlbertForQuestionAnswering en.answer_question.squad.bert.base.by_rsvp-ai bert_qa_bertserini_bert_base_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_vuiseng9 bert_qa_vuiseng9_bert_base_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.x1.16_f88.1_d8_unstruct.by_madlag bert_qa_bert_base_uncased_squadv1_x1.16_f88.1_d8_unstruct_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_1024d_seed_42 bert_qa_bert_base_uncased_few_shot_k_1024_finetuned_squad_seed_42 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_128d_seed_0 bert_qa_bert_base_uncased_few_shot_k_128_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base.by_mrm8488 bert_qa_bert_mini_wrslb_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_1_block_sparse_0.20_v1.by_madlag bert_qa_bert_base_uncased_squad1.1_block_sparse_0.13_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_256d_seed_0 bert_qa_bert_base_uncased_few_shot_k_256_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_32d_seed_0 bert_qa_bert_base_uncased_few_shot_k_32_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_512d_seed_0 bert_qa_bert_base_uncased_few_shot_k_512_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_64d_seed_0 bert_qa_bert_base_uncased_few_shot_k_64_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_victoraavila bert_qa_victoraavila_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_l3.by_howey bert_qa_bert_base_uncased_squad_L3 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_seed_42 bert_qa_bert_base_uncased_few_shot_k_16_finetuned_squad_seed_42 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_v2.by_ericRosello bert_qa_bert_base_uncased_finetuned_squad_frozen_v2 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_v2.by_madlag bert_qa_bert_base_uncased_squad1.1_pruned_x3.2_v2 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x1.16_f88.1_d8_unstruct_v1.by_madlag bert_qa_bert_base_uncased_squad1.1_block_sparse_0.20_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x1.84_f88.7_d36_hybrid_filled_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x1.96_f88.3_d27_hybrid_filled_opt_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x1.96_f88.3_d27_hybrid_filled_opt_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x2.01_f89.2_d30_hybrid_rewind_opt_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x2.01_f89.2_d30_hybrid_rewind_opt_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x2.32_f86.6_d15_hybrid_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x2.32_f86.6_d15_hybrid_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x2.44_f87.7_d26_hybrid_filled_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x2.44_f87.7_d26_hybrid_filled_v1.by_madlag bert_qa_bert_base_uncased_squad1.1_block_sparse_0.07_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Alexander-Learn bert_qa_Alexander_Learn_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_l6.by_howey bert_qa_bert_base_uncased_squad_L6 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_tli8hf bert_qa_unqover_bert_base_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_1_block_sparse_0.13_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x1.84_f88.7_d36_hybrid_filled_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_madlag bert_qa_bert_base_uncased_squad_v1_sparse0.25 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base.by_vuiseng9 bert_qa_bert_base_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base.by_xraychen bert_qa_squad_baseline Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base.by_zhufy bert_qa_squad_en_bert_base Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_srmukundb bert_qa_srmukundb_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_Seongkyu bert_qa_Seongkyu_bert_base_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_SreyanG-NVIDIA bert_qa_SreyanG_NVIDIA_bert_base_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_andresestevez bert_qa_andresestevez_bert_base_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_batterydata bert_qa_bert_base_cased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_ncduy bert_qa_bert_base_cased_finetuned_squad_test Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.1.1_block_sparse_0.32_v1.by_madlag bert_qa_bert_base_uncased_squad1.1_block_sparse_0.32_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_KB bert_qa_bert_base_swedish_cased_squad_experimental Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_Intel bert_qa_bert_base_uncased_squadv1.1_sparse_80_1x4_block_pruneofa Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_lewtun bert_qa_bert_base_uncased_finetuned_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_HomayounSadri bert_qa_HomayounSadri_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_kaporter bert_qa_kaporter_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_jgammack bert_qa_MTL_bert_base_uncased_ww_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_csarron bert_qa_csarron_bert_base_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_jimypbr bert_qa_jimypbr_bert_base_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_bdickson bert_qa_bdickson_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_Tianle bert_qa_Tianle_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_SupriyaArun bert_qa_SupriyaArun_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_SreyanG-NVIDIA bert_qa_SreyanG_NVIDIA_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering fi.answer_question.xlm_roberta xlm_roberta_qa_ADDI_FI_XLM_R Question Answering Finnish XlmRoBertaForQuestionAnswering fr.answer_question.squad.xlmr_roberta.base xlm_roberta_qa_xlmr_base_texas_squad_fr_fr_saattrupdan Question Answering French XlmRoBertaForQuestionAnswering de.answer_question.squad_spanish_tuned.xlmr_roberta.base.by_saattrupdan xlm_roberta_qa_xlmr_base_texas_squad_es_es_saattrupdan Question Answering German XlmRoBertaForQuestionAnswering de.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_german Question Answering German XlmRoBertaForQuestionAnswering de.answer_question.squadv2.electra.base electra_qa_base_squad2 Question Answering German BertForQuestionAnswering de.answer_question.squadv2.bert bert_qa_bert_multi_english_german_squad2 Question Answering German BertForQuestionAnswering de.answer_question.squad_de_tuned.xlmr_roberta.base.by_saattrupdan xlm_roberta_qa_xlmr_base_texas_squad_de_de_saattrupdan Question Answering German XlmRoBertaForQuestionAnswering de.answer_question.xlm_roberta xlm_roberta_qa_ADDI_DE_XLM_R Question Answering German XlmRoBertaForQuestionAnswering de.answer_question.electra.distilled_base electra_qa_g_base_germanquad_distilled Question Answering German BertForQuestionAnswering de.answer_question.electra.base electra_qa_g_base_germanquad Question Answering German BertForQuestionAnswering de.answer_question.electra electra_qa_German_question_answer Question Answering German BertForQuestionAnswering de.answer_question.bert bert_qa_GBERTQnA Question Answering German BertForQuestionAnswering de.answer_question.electra.large electra_qa_g_large_germanquad Question Answering German BertForQuestionAnswering he.answer_question.squad.bert bert_qa_hebert_finetuned_hebrew_squad Question Answering Hebrew BertForQuestionAnswering hi.answer_question.xlm_roberta xlm_roberta_qa_autonlp_hindi_question_answering_23865268 Question Answering Hindi XlmRoBertaForQuestionAnswering hi.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_hindi Question Answering Hindi XlmRoBertaForQuestionAnswering hu.answer_question.squad.bert bert_qa_huBert_fine_tuned_hungarian_squadv1 Question Answering Hungarian BertForQuestionAnswering is.answer_question.squad.roberta roberta_qa_icebert_texas_squad_is_saattrupdan Question Answering Icelandic RoBertaForQuestionAnswering is.answer_question.squad.xlmr_roberta.base xlm_roberta_qa_xlmr_base_texas_squad_is_is_saattrupdan Question Answering Icelandic XlmRoBertaForQuestionAnswering is.answer_question.xlmr_roberta xlm_roberta_qa_XLMr_ENIS_QA_Is Question Answering Icelandic XlmRoBertaForQuestionAnswering id.answer_question.indo_bert bert_qa_Indobert_QA Question Answering Indonesian BertForQuestionAnswering it.answer_question.squad.bert bert_qa_bert_italian_finedtuned_squadv1_it_alfa Question Answering Italian BertForQuestionAnswering it.answer_question.squad.bert.base_uncased bert_qa_bert_base_italian_uncased_squad_it_antoniocappiello Question Answering Italian BertForQuestionAnswering it.answer_question.squad.bert.xxl_cased bert_qa_squad_xxl_cased_hub1 Question Answering Italian BertForQuestionAnswering it.answer_question.xlm_roberta xlm_roberta_qa_ADDI_IT_XLM_R Question Answering Italian XlmRoBertaForQuestionAnswering ja.answer_question.wikipedia.bert.base bert_qa_base_japanese_wikipedia_ud_head Question Answering Japanese BertForQuestionAnswering ja.answer_question.wikipedia.bert.large bert_qa_large_japanese_wikipedia_ud_head Question Answering Japanese BertForQuestionAnswering ko.answer_question.korquad.electra.small electra_qa_small_v3_finetuned_korquad Question Answering Korean BertForQuestionAnswering ko.answer_question.korquad.electra.base_v2_384.by_monologg electra_qa_base_v2_finetuned_korquad_384 Question Answering Korean BertForQuestionAnswering ko.answer_question.korquad.electra.base_v2.by_monologg electra_qa_base_v2_finetuned_korquad Question Answering Korean BertForQuestionAnswering ko.answer_question.korquad.electra.base electra_qa_base_v3_finetuned_korquad Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.electra.base.by_seongju electra_qa_klue_mrc_base Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.bert.base.by_bespin-global bert_qa_bespin_global_klue_bert_base_mrc Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.bert.base_aihub.by_bespin-global bert_qa_klue_bert_base_aihub_mrc Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.bert.base.by_ainize bert_qa_ainize_klue_bert_base_mrc Question Answering Korean BertForQuestionAnswering ko.answer_question.electra electra_qa_long Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.electra.base.by_obokkkk electra_qa_base_v3_discriminator_finetuned_klue_v4 Question Answering Korean BertForQuestionAnswering el.answer_question.bert bert_qa_qacombination_bert_el_Danastos Question Answering Modern Greek (1453-) BertForQuestionAnswering pl.answer_question.squad.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_polish_squad1 Question Answering Polish BertForQuestionAnswering pl.answer_question.squadv2.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_polish_squad2 Question Answering Polish BertForQuestionAnswering pt.answer_question.squad.distil_bert distilbert_qa_multi_finedtuned_squad Question Answering Portuguese DistilBertForQuestionAnswering pt.answer_question.squad.bert.large_cased bert_qa_bert_large_cased_squad_v1.1_portuguese Question Answering Portuguese BertForQuestionAnswering pt.answer_question.squad.biobert bert_qa_bioBERTpt_squad_v1.1_portuguese Question Answering Portuguese BertForQuestionAnswering pt.answer_question.squad.bert.base_cased.by_mrm8488 bert_qa_bert_base_portuguese_cased_finetuned_squad_v1_pt_mrm8488 Question Answering Portuguese BertForQuestionAnswering pt.answer_question.squad.bert.base_cased.by_pierreguillou bert_qa_bert_base_cased_squad_v1.1_portuguese Question Answering Portuguese BertForQuestionAnswering ru.answer_question.distil_bert distilbert_qa_model_QA_5_epoch_RU Question Answering Russian DistilBertForQuestionAnswering si.answer_question.bert.base bert_qa_bert_base_sinhala_qa Question Answering Sinhala, Sinhalese BertForQuestionAnswering sv.answer_question.squadv2.bert.base bert_qa_bert_base_swedish_squad2 Question Answering Swedish BertForQuestionAnswering sv.answer_question.xlmr_roberta.large xlm_roberta_qa_xlmr_large_qa_sv_sv_m3hrdadfi Question Answering Swedish XlmRoBertaForQuestionAnswering ta.answer_question.squad.xlm_roberta xlm_roberta_qa_xlm_roberta_squad_tamil Question Answering Tamil XlmRoBertaForQuestionAnswering th.answer_question.xquad_squad.bert.cased bert_qa_thai_bert_multi_cased_finetuned_xquadv1_finetuned_squad Question Answering Thai BertForQuestionAnswering th.answer_question.xquad.multi_lingual_bert.base bert_qa_xquad_th_mbert_base Question Answering Thai BertForQuestionAnswering th.answer_question.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetune_qa Question Answering Thai BertForQuestionAnswering th.answer_question.squadv2.xlm_roberta.base xlm_roberta_qa_thai_xlm_roberta_base_squad2 Question Answering Thai XlmRoBertaForQuestionAnswering tr.answer_question.squad.electra electra_qa_enelpi_squad Question Answering Turkish BertForQuestionAnswering tr.answer_question.xlm_roberta xlm_roberta_qa_XLM_Turkish Question Answering Turkish XlmRoBertaForQuestionAnswering tr.answer_question.squadv2.electra.base_v2 electra_qa_base_discriminator_finetuned_squadv2 Question Answering Turkish BertForQuestionAnswering tr.answer_question.squad.electra.base electra_qa_base_discriminator_finetuned_squadv1 Question Answering Turkish BertForQuestionAnswering tr.answer_question.squad.bert.base bert_qa_bert_base_turkish_squad Question Answering Turkish BertForQuestionAnswering tr.answer_question.bert.base_uncased bert_qa_loodos_bert_base_uncased_QA_fine_tuned Question Answering Turkish BertForQuestionAnswering tr.answer_question.electra electra_qa_turkish Question Answering Turkish BertForQuestionAnswering tr.answer_question.bert.distilled bert_qa_distilbert_tr_q_a Question Answering Turkish BertForQuestionAnswering tr.answer_question.bert.by_yunusemreemik bert_qa_logo_qna_model Question Answering Turkish BertForQuestionAnswering tr.answer_question.bert.by_lserinol bert_qa_bert_turkish_question_answering Question Answering Turkish BertForQuestionAnswering tr.answer_question.electra.small_uncased electra_qa_small_turkish_uncased_discriminator_finetuned Question Answering Turkish BertForQuestionAnswering uk.answer_question.xlmr_roberta xlmroberta_qa_ukrainian Question Answering Ukrainian XlmRoBertaForQuestionAnswering vi.answer_question.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_vi_qa Question Answering Vietnamese XlmRoBertaForQuestionAnswering ar.answer_question.bert bert_qa_arap_qa_bert Question Answering Arabic BertForQuestionAnswering ar.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_arabic Question Answering Arabic XlmRoBertaForQuestionAnswering ar.answer_question.tydiqa.electra.base electra_qa_ara_base_artydiqa Question Answering Arabic BertForQuestionAnswering ar.answer_question.squad_arcd.electra.base electra_qa_AraElectra_base_finetuned_ARCD Question Answering Arabic BertForQuestionAnswering ar.answer_question.squad_arcd.electra.768d electra_qa_araElectra_SQUAD_ARCD_768 Question Answering Arabic BertForQuestionAnswering ar.answer_question.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_arabic_qa Question Answering Arabic XlmRoBertaForQuestionAnswering ar.answer_question.electra electra_qa_AraELECTRA_discriminator_SOQAL Question Answering Arabic BertForQuestionAnswering ar.answer_question.bert.v2 bert_qa_arap_qa_bert_v2 Question Answering Arabic BertForQuestionAnswering ar.answer_question.bert.large_v2 bert_qa_arap_qa_bert_large_v2 Question Answering Arabic BertForQuestionAnswering ar.answer_question.squad_arcd.electra electra_qa_araElectra_SQUAD_ARCD Question Answering Arabic BertForQuestionAnswering zh.answer_question.mac_bert.large bert_qa_chinese_pretrain_mrc_macbert_large Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.multilingual_base_cased bert_qa_multilingual_bert_base_cased_chinese Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.large.by_qalover bert_qa_chinese_pert_large_open_domain_mrc Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.large.by_luhua bert_qa_chinese_pretrain_mrc_roberta_wwm_ext_large Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.large.by_hfl bert_qa_chinese_pert_large_mrc Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.base.by_uer bert_qa_roberta_base_chinese_extractive_qa Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.by_jackh1995 bert_qa_bert_chinese_finetuned Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.base.by_liam168 bert_qa_qa_roberta_base_chinese_extractive Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.base.by_jackh1995 bert_qa_roberta_base_chinese_extractive_qa_scratch Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.base.by_hfl bert_qa_chinese_pert_base_mrc Question Answering Chinese BertForQuestionAnswering zh.answer_question.squad.bert.base bert_qa_bert_base_chinese_finetuned_squad_colab Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.by_yechen bert_qa_question_answering_chinese Question Answering Chinese BertForQuestionAnswering zh.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_chinese Question Answering Chinese XlmRoBertaForQuestionAnswering fa.answer_question.bert.base bert_qa_bert_base_fa_qa Question Answering Persian BertForQuestionAnswering fa.answer_question.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_fa_qa Question Answering Persian XlmRoBertaForQuestionAnswering fa.answer_question.xlmr_roberta.large xlmroberta_qa_xlmr_large Question Answering Persian XlmRoBertaForQuestionAnswering sw.answer_question.tydiqa.xlm_roberta.base xlm_roberta_qa_afriberta_base_finetuned_tydiqa Question Answering Swahili (macrolanguage) XlmRoBertaForQuestionAnswering vn.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_vietnamese Question Answering nan XlmRoBertaForQuestionAnswering xx.answer_question.chaii.xlm_roberta xlm_roberta_qa_xlm_roberta_qa_chaii Question Answering nan XlmRoBertaForQuestionAnswering xx.answer_question.xquad.bert.uncased bert_qa_bert_multi_uncased_finetuned_xquadv1 Question Answering nan BertForQuestionAnswering xx.answer_question.xquad.bert.cased bert_qa_bert_multi_cased_finetuned_xquadv1 Question Answering nan BertForQuestionAnswering xx.answer_question.xlm_roberta.distilled xlm_roberta_qa_distill_xlm_mrc Question Answering nan XlmRoBertaForQuestionAnswering xx.answer_question.tydiqa.multi_lingual_bert bert_qa_Part_1_mBERT_Model_E1 Question Answering nan BertForQuestionAnswering xx.answer_question.tydiqa.bert bert_qa_telugu_bertu_tydiqa Question Answering nan BertForQuestionAnswering xx.answer_question.xquad_tydiqa.bert.cased bert_qa_bert_multi_cased_finedtuned_xquad_tydiqa_goldp Question Answering nan BertForQuestionAnswering xx.answer_question.squad.distil_bert._en_de_es_vi_zh_tuned.by_ZYW distilbert_qa_squad_en_de_es_vi_zh_model Question Answering nan DistilBertForQuestionAnswering xx.answer_question.roberta roberta_qa_ft_lr_cu_leolin12345 Question Answering nan RoBertaForQuestionAnswering xx.answer_question.distil_bert.vi_zh_es_tuned.by_ZYW distilbert_qa_en_de_vi_zh_es_model Question Answering nan DistilBertForQuestionAnswering xx.answer_question.distil_bert.en_de_tuned.by_ZYW distilbert_qa_en_de_model Question Answering nan DistilBertForQuestionAnswering xx.answer_question.distil_bert.en_de_es_tuned.by_ZYW distilbert_qa_en_de_es_model Question Answering nan DistilBertForQuestionAnswering xx.answer_question.squad.distil_bert.en_de_es_tuned.by_ZYW distilbert_qa_squad_en_de_es_model Question Answering nan DistilBertForQuestionAnswering Minor Improvements IOB Schema Detection for Tokenclassifiers and adding NER Converting in those cases Tweaks in column name generation of most annotators Bug Fixes fixed bug in multi lang parsing fixed bug for Normalizers fixed bug in fetching metadata for resolvers fixed bug in deducting outputlevel and inferring output columns fixed broken nlp_refs NLU Version 3.4.4 600 new models with over 75 new languages including Ancient,Dead and Extinct languages, 155 languages total covered, 400% Tokenizer Speedup, 18x USE-Embeddings GPU speedup in John Snow Labs NLU 3.4.4 We are very excited to announce NLU 3.4.4 has been released with over 600 new model, over 75 new languages and 155 languages covered in total, 400% speedup for tokenizers and 18x speedup of UniversalSentenceEncoder on GPU. On the general NLP side we have transformer based Embeddings and Token Classifiers powered by state of the art CamemBertEmbeddings and DeBertaForTokenClassification based architectures as well as various new models for Historical, Ancient,Dead, Extinct, Genetic and Constructed languages like Old Church Slavonic, Latin, Sanskrit, Esperanto, Volapük, Coptic, Nahuatl, Ancient Greek (to 1453), Old Russian. On the healthcare side we have Portuguese De-identification Models, have NER models for Gene detection and finally RxNorm Sentence resolution model for mapping and extracting pharmaceutical actions (e.g. analgesic, hypoglycemic) as well as treatments (e.g. backache, diabetes). General NLP Models All general NLP models First time language models covered The languages for these models are covered for the very first time ever by NLU. Number Language Name(s) NLU Reference Spark NLP Reference Task Annotator Class ISO-639-1 ISO-639-2/639-5 ISO-639-3 Scope Language Type 0 Sanskrit sa.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel sa san san Individual Ancient 1 Sanskrit sa.lemma lemma_vedic Lemmatization LemmatizerModel sa san san Individual Ancient 2 Sanskrit sa.pos pos_vedic Part of Speech Tagging PerceptronModel sa san san Individual Ancient 3 Sanskrit sa.stopwords stopwords_iso Stop Words Removal StopWordsCleaner sa san san Individual Ancient 4 Volapük vo.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel vo vol vol Individual Constructed 5 Nahuatl languages nah.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nah nan Collective Genetic 6 Aragonese an.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel an arg arg Individual Living 7 Assamese as.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel as asm asm Individual Living 8 Asturian, Asturleonese, Bable, Leonese ast.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan ast ast Individual Living 9 Bashkir ba.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ba bak bak Individual Living 10 Bavarian bar.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan bar Individual Living 11 Bishnupriya bpy.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan bpy Individual Living 12 Burmese my.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel my 639-2/T: mya639-2/B: bur mya Individual Living 13 Cebuano ceb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan ceb ceb Individual Living 14 Central Bikol bcl.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan bcl Individual Living 15 Chechen ce.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ce che che Individual Living 16 Chuvash cv.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel cv chv chv Individual Living 17 Corsican co.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel co cos cos Individual Living 18 Dhivehi, Divehi, Maldivian dv.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel dv div div Individual Living 19 Egyptian Arabic arz.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan arz Individual Living 20 Emiliano-Romagnolo eml.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel eml nan nan Individual Living 21 Erzya myv.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan myv myv Individual Living 22 Georgian ka.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ka 639-2/T: kat639-2/B: geo kat Individual Living 23 Goan Konkani gom.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan gom Individual Living 24 Javanese jv.embed.distilbert distilbert_embeddings_javanese_distilbert_small Embeddings DistilBertEmbeddings jv jav jav Individual Living 25 Javanese jv.embed.javanese_distilbert_small_imdb distilbert_embeddings_javanese_distilbert_small_imdb Embeddings DistilBertEmbeddings jv jav jav Individual Living 26 Javanese jv.embed.javanese_roberta_small roberta_embeddings_javanese_roberta_small Embeddings RoBertaEmbeddings jv jav jav Individual Living 27 Javanese jv.embed.javanese_roberta_small_imdb roberta_embeddings_javanese_roberta_small_imdb Embeddings RoBertaEmbeddings jv jav jav Individual Living 28 Javanese jv.embed.javanese_bert_small_imdb bert_embeddings_javanese_bert_small_imdb Embeddings BertEmbeddings jv jav jav Individual Living 29 Javanese jv.embed.javanese_bert_small bert_embeddings_javanese_bert_small Embeddings BertEmbeddings jv jav jav Individual Living 30 Kirghiz, Kyrgyz ky.stopwords stopwords_iso Stop Words Removal StopWordsCleaner ky kir kir Individual Living 31 Letzeburgesch, Luxembourgish lb.stopwords stopwords_iso Stop Words Removal StopWordsCleaner lb ltz ltz Individual Living 32 Letzeburgesch, Luxembourgish lb.lemma lemma_spacylookup Lemmatization LemmatizerModel lb ltz ltz Individual Living 33 Letzeburgesch, Luxembourgish lb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel lb ltz ltz Individual Living 34 Ligurian lij.stopwords stopwords_iso Stop Words Removal StopWordsCleaner nan nan lij Individual Living 35 Lombard lmo.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan lmo Individual Living 36 Low German, Low Saxon nds.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nds nds Individual Living 37 Macedonian mk.stopwords stopwords_iso Stop Words Removal StopWordsCleaner mk 639-2/T: mkd639-2/B: mac mkd Individual Living 38 Macedonian mk.lemma lemma_spacylookup Lemmatization LemmatizerModel mk 639-2/T: mkd639-2/B: mac mkd Individual Living 39 Macedonian mk.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel mk 639-2/T: mkd639-2/B: mac mkd Individual Living 40 Maithili mai.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan mai mai Individual Living 41 Manx gv.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel gv glv glv Individual Living 42 Mazanderani mzn.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan mzn Individual Living 43 Minangkabau min.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan min min Individual Living 44 Mingrelian xmf.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan xmf Individual Living 45 Mirandese mwl.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan mwl mwl Individual Living 46 Neapolitan nap.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nap nap Individual Living 47 Nepal Bhasa, Newari new.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan new new Individual Living 48 Northern Frisian frr.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan frr frr Individual Living 49 Northern Sami sme.lemma lemma_giella Lemmatization LemmatizerModel se sme sme Individual Living 50 Northern Sami sme.pos pos_giella Part of Speech Tagging PerceptronModel se sme sme Individual Living 51 Northern Sotho, Pedi, Sepedi nso.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nso nso Individual Living 52 Occitan (post 1500) oc.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel oc oci oci Individual Living 53 Ossetian, Ossetic os.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel os oss oss Individual Living 54 Pfaelzisch pfl.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan pfl Individual Living 55 Piemontese pms.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan pms Individual Living 56 Romansh rm.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel rm roh roh Individual Living 57 Scots sco.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan sco sco Individual Living 58 Sicilian scn.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan scn scn Individual Living 59 Sinhala, Sinhalese si.stopwords stopwords_iso Stop Words Removal StopWordsCleaner si sin sin Individual Living 60 Sinhala, Sinhalese si.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel si sin sin Individual Living 61 Sundanese su.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel su sun sun Individual Living 62 Sundanese su.embed.sundanese_roberta_base roberta_embeddings_sundanese_roberta_base Embeddings RoBertaEmbeddings su sun sun Individual Living 63 Tagalog tl.lemma lemma_spacylookup Lemmatization LemmatizerModel tl tgl tgl Individual Living 64 Tagalog tl.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel tl tgl tgl Individual Living 65 Tagalog tl.stopwords stopwords_iso Stop Words Removal StopWordsCleaner tl tgl tgl Individual Living 66 Tagalog tl.embed.roberta_tagalog_large roberta_embeddings_roberta_tagalog_large Embeddings RoBertaEmbeddings tl tgl tgl Individual Living 67 Tagalog tl.embed.roberta_tagalog_base roberta_embeddings_roberta_tagalog_base Embeddings RoBertaEmbeddings tl tgl tgl Individual Living 68 Tajik tg.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel tg tgk tgk Individual Living 69 Tatar tt.stopwords stopwords_iso Stop Words Removal StopWordsCleaner tt tat tat Individual Living 70 Tatar tt.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel tt tat tat Individual Living 71 Tigrinya ti.stopwords stopwords_iso Stop Words Removal StopWordsCleaner ti tir tir Individual Living 72 Tosk Albanian als.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan als Individual Living 73 Tswana tn.stopwords stopwords_iso Stop Words Removal StopWordsCleaner tn tsn tsn Individual Living 74 Turkmen tk.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel tk tuk tuk Individual Living 75 Upper Sorbian hsb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan hsb hsb Individual Living 76 Venetian vec.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan vec Individual Living 77 Vlaams vls.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan vls Individual Living 78 Walloon wa.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel wa wln wln Individual Living 79 Waray (Philippines) war.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan war war Individual Living 80 Western Armenian hyw.pos pos_armtdp Part of Speech Tagging PerceptronModel nan nan hyw Individual Living 81 Western Armenian hyw.lemma lemma_armtdp Lemmatization LemmatizerModel nan nan hyw Individual Living 82 Western Frisian fy.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel fy fry fry Individual Living 83 Western Panjabi pnb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan pnb Individual Living 84 Yakut sah.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan sah sah Individual Living 85 Zeeuws zea.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan zea Individual Living 86 Albanian sq.stopwords stopwords_iso Stop Words Removal StopWordsCleaner sq 639-2/T: sqi639-2/B: alb sqi Macrolanguage Living 87 Albanian sq.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel sq 639-2/T: sqi639-2/B: alb sqi Macrolanguage Living 88 Azerbaijani az.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel az aze aze Macrolanguage Living 89 Azerbaijani az.stopwords stopwords_iso Stop Words Removal StopWordsCleaner az aze aze Macrolanguage Living 90 Malagasy mg.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel mg mlg mlg Macrolanguage Living 91 Malay (macrolanguage) ms.embed.albert albert_embeddings_albert_large_bahasa_cased Embeddings AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 92 Malay (macrolanguage) ms.embed.distilbert distilbert_embeddings_malaysian_distilbert_small Embeddings DistilBertEmbeddings ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 93 Malay (macrolanguage) ms.embed.albert_tiny_bahasa_cased albert_embeddings_albert_tiny_bahasa_cased Embeddings AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 94 Malay (macrolanguage) ms.embed.albert_base_bahasa_cased albert_embeddings_albert_base_bahasa_cased Embeddings AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 95 Malay (macrolanguage) ms.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 96 Mongolian mn.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel mn mon mon Macrolanguage Living 97 Oriya (macrolanguage) or.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel or ori ori Macrolanguage Living 98 Pashto, Pushto ps.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ps pus pus Macrolanguage Living 99 Quechua qu.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel qu que que Macrolanguage Living 100 Sardinian sc.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel sc srd srd Macrolanguage Living 101 Serbo-Croatian sh.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel sh nan nan Macrolanguage Living 102 Uzbek uz.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel uz uzb uzb Macrolanguage Living All general NLP models Powered by the incredible Spark NLP 3.4.4 and previous releases. Number NLU Reference Spark NLP Reference Task Language Name(s) Annotator Class ISO-639-1 ISO-639-2/639-5 ISO-639-3 Language Type Scope 0 cu.pos pos_proiel Part of Speech Tagging Church Slavic, Church Slavonic, Old Bulgarian, Old Church Slavonic, Old Slavonic PerceptronModel cu chu chu Ancient Individual 1 la.lemma lemma_proiel Lemmatization Latin LemmatizerModel la lat lat Ancient Individual 2 la.lemma lemma_proiel Lemmatization Latin LemmatizerModel la lat lat Ancient Individual 3 la.pos pos_perseus Part of Speech Tagging Latin PerceptronModel la lat lat Ancient Individual 4 la.pos pos_perseus Part of Speech Tagging Latin PerceptronModel la lat lat Ancient Individual 5 sa.embed.w2v_cc_300d w2v_cc_300d Embeddings Sanskrit WordEmbeddingsModel sa san san Ancient Individual 6 sa.lemma lemma_vedic Lemmatization Sanskrit LemmatizerModel sa san san Ancient Individual 7 sa.pos pos_vedic Part of Speech Tagging Sanskrit PerceptronModel sa san san Ancient Individual 8 sa.stopwords stopwords_iso Stop Words Removal Sanskrit StopWordsCleaner sa san san Ancient Individual 9 eo.embed.w2v_cc_300d w2v_cc_300d Embeddings Esperanto WordEmbeddingsModel eo epo epo Constructed Individual 10 vo.embed.w2v_cc_300d w2v_cc_300d Embeddings Volapük WordEmbeddingsModel vo vol vol Constructed Individual 11 cop.pos pos_scriptorium Part of Speech Tagging Coptic PerceptronModel nan cop cop Extinct Individual 12 nah.embed.w2v_cc_300d w2v_cc_300d Embeddings Nahuatl languages WordEmbeddingsModel nan nah nan Genetic Collective 13 grc.lemma lemma_proiel Lemmatization Ancient Greek (to 1453) LemmatizerModel nan grc grc Historical Individual 14 grc.stopwords stopwords_iso Stop Words Removal Ancient Greek (to 1453) StopWordsCleaner nan grc grc Historical Individual 15 grc.lemma lemma_proiel Lemmatization Ancient Greek (to 1453) LemmatizerModel nan grc grc Historical Individual 16 grc.pos pos_proiel Part of Speech Tagging Ancient Greek (to 1453) PerceptronModel nan grc grc Historical Individual 17 orv.lemma lemma_torot Lemmatization Old Russian LemmatizerModel nan nan orv Historical Individual 18 af.embed.w2v_cc_300d w2v_cc_300d Embeddings Afrikaans WordEmbeddingsModel af afr afr Living Individual 19 af.stopwords stopwords_iso Stop Words Removal Afrikaans StopWordsCleaner af afr afr Living Individual 20 am.embed.w2v_cc_300d w2v_cc_300d Embeddings Amharic WordEmbeddingsModel am amh amh Living Individual 21 am.embed.am_roberta roberta_embeddings_am_roberta Embeddings Amharic RoBertaEmbeddings am amh amh Living Individual 22 am.stopwords stopwords_iso Stop Words Removal Amharic StopWordsCleaner am amh amh Living Individual 23 an.embed.w2v_cc_300d w2v_cc_300d Embeddings Aragonese WordEmbeddingsModel an arg arg Living Individual 24 hy.stopwords stopwords_iso Stop Words Removal Armenian StopWordsCleaner hy 639-2/T: hye639-2/B: arm hye Living Individual 25 hy.lemma lemma_armtdp Lemmatization Armenian LemmatizerModel hy 639-2/T: hye639-2/B: arm hye Living Individual 26 hy.embed.w2v_cc_300d w2v_cc_300d Embeddings Armenian WordEmbeddingsModel hy 639-2/T: hye639-2/B: arm hye Living Individual 27 as.embed.w2v_cc_300d w2v_cc_300d Embeddings Assamese WordEmbeddingsModel as asm asm Living Individual 28 ast.embed.w2v_cc_300d w2v_cc_300d Embeddings Asturian, Asturleonese, Bable, Leonese WordEmbeddingsModel nan ast ast Living Individual 29 ba.embed.w2v_cc_300d w2v_cc_300d Embeddings Bashkir WordEmbeddingsModel ba bak bak Living Individual 30 eu.stopwords stopwords_iso Stop Words Removal Basque StopWordsCleaner eu 639-2/T: eus639-2/B: baq eus Living Individual 31 eu.embed.w2v_cc_300d w2v_cc_300d Embeddings Basque WordEmbeddingsModel eu 639-2/T: eus639-2/B: baq eus Living Individual 32 eu.lemma lemma_bdt Lemmatization Basque LemmatizerModel eu 639-2/T: eus639-2/B: baq eus Living Individual 33 bar.embed.w2v_cc_300d w2v_cc_300d Embeddings Bavarian WordEmbeddingsModel nan nan bar Living Individual 34 be.embed.w2v_cc_300d w2v_cc_300d Embeddings Belarusian WordEmbeddingsModel be bel bel Living Individual 35 be.lemma lemma_hse Lemmatization Belarusian LemmatizerModel be bel bel Living Individual 36 bn.embed.indic_transformers_bn_distilbert distilbert_embeddings_indic_transformers_bn_distilbert Embeddings Bengali DistilBertEmbeddings bn ben ben Living Individual 37 bn.embed.w2v_cc_300d w2v_cc_300d Embeddings Bengali WordEmbeddingsModel bn ben ben Living Individual 38 bn.embed.indic_transformers_bn_bert bert_embeddings_indic_transformers_bn_bert Embeddings Bengali BertEmbeddings bn ben ben Living Individual 39 bn.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Bengali BertEmbeddings bn ben ben Living Individual 40 bn.embed.bangla_bert bert_embeddings_bangla_bert Embeddings Bengali BertEmbeddings bn ben ben Living Individual 41 bn.stopwords stopwords_iso Stop Words Removal Bengali StopWordsCleaner bn ben ben Living Individual 42 bh.embed.w2v_cc_300d w2v_cc_300d Embeddings Bihari language group, also known ash bih in ISO 639-2/5 WordEmbeddingsModel bh nan nan Living Individual 43 bpy.embed.w2v_cc_300d w2v_cc_300d Embeddings Bishnupriya WordEmbeddingsModel nan nan bpy Living Individual 44 bs.embed.w2v_cc_300d w2v_cc_300d Embeddings Bosnian WordEmbeddingsModel bs bos bos Living Individual 45 br.embed.w2v_cc_300d w2v_cc_300d Embeddings Breton WordEmbeddingsModel br bre bre Living Individual 46 bg.embed.w2v_cc_300d w2v_cc_300d Embeddings Bulgarian WordEmbeddingsModel bg bul bul Living Individual 47 bg.stopwords stopwords_iso Stop Words Removal Bulgarian StopWordsCleaner bg bul bul Living Individual 48 my.embed.w2v_cc_300d w2v_cc_300d Embeddings Burmese WordEmbeddingsModel my 639-2/T: mya639-2/B: bur mya Living Individual 49 es.embed.distilbert_base_es_multilingual_cased distilbert_embeddings_distilbert_base_es_multilingual_cased Embeddings Castilian, Spanish DistilBertEmbeddings es spa spa Living Individual 50 es.embed.distilbert_base_es_cased distilbert_embeddings_distilbert_base_es_cased Embeddings Castilian, Spanish DistilBertEmbeddings es spa spa Living Individual 51 es.embed.bertin_base_gaussian roberta_embeddings_bertin_base_gaussian Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 52 es.embed.bertin_roberta_base_spanish roberta_embeddings_bertin_roberta_base_spanish Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 53 es.embed.bertin_roberta_large_spanish roberta_embeddings_bertin_roberta_large_spanish Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 54 es.embed.bertin_base_stepwise roberta_embeddings_bertin_base_stepwise Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 55 es.embed.dpr_spanish_passage_encoder_allqa_base bert_embeddings_dpr_spanish_passage_encoder_allqa_base Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 56 es.embed.dpr_spanish_question_encoder_allqa_base bert_embeddings_dpr_spanish_question_encoder_allqa_base Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 57 es.embed.beto_gn_base_cased bert_embeddings_beto_gn_base_cased Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 58 es.embed.dpr_spanish_passage_encoder_squades_base bert_embeddings_dpr_spanish_passage_encoder_squades_base Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 59 es.embed.dpr_spanish_question_encoder_squades_base bert_embeddings_dpr_spanish_question_encoder_squades_base Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 60 es.embed.bert_base_es_cased bert_embeddings_bert_base_es_cased Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 61 es.embed.bert_base_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 62 es.embed.alberti_bert_base_multilingual_cased bert_embeddings_alberti_bert_base_multilingual_cased Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 63 es.embed.roberta_base_bne roberta_embeddings_roberta_base_bne Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 64 es.embed.jurisbert roberta_embeddings_jurisbert Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 65 es.embed.mlm_spanish_roberta_base roberta_embeddings_mlm_spanish_roberta_base Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 66 es.embed.roberta_large_bne roberta_embeddings_roberta_large_bne Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 67 es.pos pos_ancora Part of Speech Tagging Castilian, Spanish PerceptronModel es spa spa Living Individual 68 es.embed.bertin_base_random_exp_512seqlen roberta_embeddings_bertin_base_random_exp_512seqlen Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 69 es.embed.bertin_base_gaussian_exp_512seqlen roberta_embeddings_bertin_base_gaussian_exp_512seqlen Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 70 es.ner.roberta_base_bne_capitel_ner_plus roberta_ner_roberta_base_bne_capitel_ner_plus Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 71 es.ner.roberta_base_bne_capitel_ner roberta_ner_roberta_base_bne_capitel_ner Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 72 es.ner.RuPERTa_base_finetuned_ner roberta_ner_RuPERTa_base_finetuned_ner Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 73 es.pos.roberta_base_bne_capitel_pos roberta_pos_roberta_base_bne_capitel_pos Part of Speech Tagging Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 74 es.ner.NER_LAW_MONEY4 roberta_ner_NER_LAW_MONEY4 Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 75 es.pos.roberta_large_bne_capitel_pos roberta_pos_roberta_large_bne_capitel_pos Part of Speech Tagging Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 76 es.ner.bsc_bio_ehr_es_pharmaconer roberta_ner_bsc_bio_ehr_es_pharmaconer Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 77 es.embed.RoBERTalex roberta_embeddings_RoBERTalex Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 78 es.ner.roberta_large_bne_capitel_ner roberta_ner_roberta_large_bne_capitel_ner Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 79 es.embed.RuPERTa_base roberta_embeddings_RuPERTa_base Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 80 es.embed.bertin_base_random roberta_embeddings_bertin_base_random Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 81 es.lemma lemma_spacylookup Lemmatization Castilian, Spanish LemmatizerModel es spa spa Living Individual 82 es.stopwords stopwords_iso Stop Words Removal Castilian, Spanish StopWordsCleaner es spa spa Living Individual 83 es.pos.RuPERTa_base_finetuned_pos roberta_pos_RuPERTa_base_finetuned_pos Part of Speech Tagging Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 84 es.embed.bertin_base_stepwise_exp_512seqlen roberta_embeddings_bertin_base_stepwise_exp_512seqlen Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 85 es.ner.bsc_bio_ehr_es_cantemist roberta_ner_bsc_bio_ehr_es_cantemist Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 86 ca.lemma lemma_spacylookup Lemmatization Catalan, Valencian LemmatizerModel ca cat cat Living Individual 87 ca.embed.w2v_cc_300d w2v_cc_300d Embeddings Catalan, Valencian WordEmbeddingsModel ca cat cat Living Individual 88 ca.stopwords stopwords_iso Stop Words Removal Catalan, Valencian StopWordsCleaner ca cat cat Living Individual 89 ceb.embed.w2v_cc_300d w2v_cc_300d Embeddings Cebuano WordEmbeddingsModel nan ceb ceb Living Individual 90 bcl.embed.w2v_cc_300d w2v_cc_300d Embeddings Central Bikol WordEmbeddingsModel nan nan bcl Living Individual 91 ce.embed.w2v_cc_300d w2v_cc_300d Embeddings Chechen WordEmbeddingsModel ce che che Living Individual 92 cv.embed.w2v_cc_300d w2v_cc_300d Embeddings Chuvash WordEmbeddingsModel cv chv chv Living Individual 93 co.embed.w2v_cc_300d w2v_cc_300d Embeddings Corsican WordEmbeddingsModel co cos cos Living Individual 94 hr.embed.w2v_cc_300d w2v_cc_300d Embeddings Croatian WordEmbeddingsModel hr hrv hrv Living Individual 95 hr.stopwords stopwords_iso Stop Words Removal Croatian StopWordsCleaner hr hrv hrv Living Individual 96 hr.lemma lemma_spacylookup Lemmatization Croatian LemmatizerModel hr hrv hrv Living Individual 97 cs.stopwords stopwords_iso Stop Words Removal Czech StopWordsCleaner cs 639-2/T: ces639-2/B: cze ces Living Individual 98 cs.embed.w2v_cc_300d w2v_cc_300d Embeddings Czech WordEmbeddingsModel cs 639-2/T: ces639-2/B: cze ces Living Individual 99 cs.pos pos_fictree Part of Speech Tagging Czech PerceptronModel cs 639-2/T: ces639-2/B: cze ces Living Individual 100 cs.lemma lemma_cltt Lemmatization Czech LemmatizerModel cs 639-2/T: ces639-2/B: cze ces Living Individual 101 cs.lemma lemma_cltt Lemmatization Czech LemmatizerModel cs 639-2/T: ces639-2/B: cze ces Living Individual 102 cs.lemma lemma_cltt Lemmatization Czech LemmatizerModel cs 639-2/T: ces639-2/B: cze ces Living Individual 103 da.embed.w2v_cc_300d w2v_cc_300d Embeddings Danish WordEmbeddingsModel da dan dan Living Individual 104 da.lemma lemma_spacylookup Lemmatization Danish LemmatizerModel da dan dan Living Individual 105 da.stopwords stopwords_iso Stop Words Removal Danish StopWordsCleaner da dan dan Living Individual 106 dv.embed.w2v_cc_300d w2v_cc_300d Embeddings Dhivehi, Divehi, Maldivian WordEmbeddingsModel dv div div Living Individual 107 nl.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_nl_cased Embeddings Dutch, Flemish DistilBertEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 108 nl.pos.fullstop_dutch_punctuation_prediction roberta_pos_fullstop_dutch_punctuation_prediction Part of Speech Tagging Dutch, Flemish RoBertaForTokenClassification nl 639-2/T: nld639-2/B: dut nld Living Individual 109 nl.stopwords stopwords_iso Stop Words Removal Dutch, Flemish StopWordsCleaner nl 639-2/T: nld639-2/B: dut nld Living Individual 110 nl.embed.robbert_v2_dutch_base roberta_embeddings_robbert_v2_dutch_base Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 111 nl.embed.robbertje_1_gb_bort roberta_embeddings_robbertje_1_gb_bort Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 112 nl.embed.robbertje_1_gb_shuffled roberta_embeddings_robbertje_1_gb_shuffled Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 113 nl.embed.robbertje_1_gb_non_shuffled roberta_embeddings_robbertje_1_gb_non_shuffled Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 114 nl.embed.robbertje_1_gb_merged roberta_embeddings_robbertje_1_gb_merged Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 115 nl.embed.w2v_cc_300d w2v_cc_300d Embeddings Dutch, Flemish WordEmbeddingsModel nl 639-2/T: nld639-2/B: dut nld Living Individual 116 nl.lemma lemma_spacylookup Lemmatization Dutch, Flemish LemmatizerModel nl 639-2/T: nld639-2/B: dut nld Living Individual 117 arz.embed.w2v_cc_300d w2v_cc_300d Embeddings Egyptian Arabic WordEmbeddingsModel nan nan arz Living Individual 118 eml.embed.w2v_cc_300d w2v_cc_300d Embeddings Emiliano-Romagnolo WordEmbeddingsModel eml nan nan Living Individual 119 en.ner.debertav3_large.conll03 deberta_v3_large_token_classifier_conll03 Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 120 en.ner.debertav3_base.conll03 deberta_v3_base_token_classifier_conll03 Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 121 en.ner.debertav3_small.conll03 deberta_v3_small_token_classifier_conll03 Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 122 en.ner.debertav3_xsmall.conll03 deberta_v3_xsmall_token_classifier_conll03 Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 123 en.ner.debertav3_large.ontonotes deberta_v3_large_token_classifier_ontonotes Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 124 en.ner.debertav3_base.ontonotes deberta_v3_base_token_classifier_ontonotes Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 125 en.ner.debertav3_small.ontonotes deberta_v3_small_token_classifier_ontonotes Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 126 en.ner.debertav3_xsmall.ontonotes deberta_v3_xsmall_token_classifier_ontonotes Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 127 en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm Named Entity Recognition English MedicalNerModel en eng eng Living Individual 128 en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm Named Entity Recognition English MedicalNerModel en eng eng Living Individual 129 en.resolve.rxnorm_action_treatment sbiobertresolve_rxnorm_action_treatment Entity Resolution English SentenceEntityResolverModel en eng eng Living Individual 130 en.embed.albert_xlarge_v1 albert_embeddings_albert_xlarge_v1 Embeddings English AlbertEmbeddings en eng eng Living Individual 131 en.embed.albert_base_v1 albert_embeddings_albert_base_v1 Embeddings English AlbertEmbeddings en eng eng Living Individual 132 en.embed.albert_xxlarge_v1 albert_embeddings_albert_xxlarge_v1 Embeddings English AlbertEmbeddings en eng eng Living Individual 133 en.embed.distilbert_base_en_cased distilbert_embeddings_distilbert_base_en_cased Embeddings English DistilBertEmbeddings en eng eng Living Individual 134 en.embed.distilbert_base_uncased_sparse_90_unstructured_pruneofa distilbert_embeddings_distilbert_base_uncased_sparse_90_unstructured_pruneofa Embeddings English DistilBertEmbeddings en eng eng Living Individual 135 en.embed.distilbert_base_uncased_sparse_85_unstructured_pruneofa distilbert_embeddings_distilbert_base_uncased_sparse_85_unstructured_pruneofa Embeddings English DistilBertEmbeddings en eng eng Living Individual 136 en.classify.questionpair classifierdl_electra_questionpair Text Classification English ClassifierDLModel en eng eng Living Individual 137 en.classify.question_vs_statement bert_sequence_classifier_question_statement Text Classification English BertForSequenceClassification en eng eng Living Individual 138 en.classify.song_lyrics bert_sequence_classifier_song_lyrics Text Classification English BertForSequenceClassification en eng eng Living Individual 139 en.embed.muppet_roberta_base roberta_embeddings_muppet_roberta_base Embeddings English RoBertaEmbeddings en eng eng Living Individual 140 en.embed.muppet_roberta_large roberta_embeddings_muppet_roberta_large Embeddings English RoBertaEmbeddings en eng eng Living Individual 141 en.embed.fairlex_ecthr_minilm roberta_embeddings_fairlex_ecthr_minilm Embeddings English RoBertaEmbeddings en eng eng Living Individual 142 en.embed.distilroberta_base_finetuned_jira_qt_issue_titles_and_bodies roberta_embeddings_distilroberta_base_finetuned_jira_qt_issue_titles_and_bodies Embeddings English RoBertaEmbeddings en eng eng Living Individual 143 en.embed.legal_roberta_base roberta_embeddings_legal_roberta_base Embeddings English RoBertaEmbeddings en eng eng Living Individual 144 en.embed.distilroberta_base roberta_embeddings_distilroberta_base Embeddings English RoBertaEmbeddings en eng eng Living Individual 145 en.embed.pmc_med_bio_mlm_roberta_large roberta_embeddings_pmc_med_bio_mlm_roberta_large Embeddings English RoBertaEmbeddings en eng eng Living Individual 146 en.lemma lemma_lines Lemmatization English LemmatizerModel en eng eng Living Individual 147 en.lemma lemma_lines Lemmatization English LemmatizerModel en eng eng Living Individual 148 en.lemma lemma_lines Lemmatization English LemmatizerModel en eng eng Living Individual 149 en.embed.roberta_pubmed roberta_embeddings_roberta_pubmed Embeddings English RoBertaEmbeddings en eng eng Living Individual 150 en.embed.fairlex_scotus_minilm roberta_embeddings_fairlex_scotus_minilm Embeddings English RoBertaEmbeddings en eng eng Living Individual 151 en.embed.distilroberta_base_finetuned_jira_qt_issue_title roberta_embeddings_distilroberta_base_finetuned_jira_qt_issue_title Embeddings English RoBertaEmbeddings en eng eng Living Individual 152 en.embed.chEMBL26_smiles_v2 roberta_embeddings_chEMBL26_smiles_v2 Embeddings English RoBertaEmbeddings en eng eng Living Individual 153 en.embed.SecRoBERTa roberta_embeddings_SecRoBERTa Embeddings English RoBertaEmbeddings en eng eng Living Individual 154 en.embed.distilroberta_base_climate_d_s roberta_embeddings_distilroberta_base_climate_d_s Embeddings English RoBertaEmbeddings en eng eng Living Individual 155 en.embed.chEMBL_smiles_v1 roberta_embeddings_chEMBL_smiles_v1 Embeddings English RoBertaEmbeddings en eng eng Living Individual 156 en.embed.distilroberta_base_climate_f roberta_embeddings_distilroberta_base_climate_f Embeddings English RoBertaEmbeddings en eng eng Living Individual 157 en.embed.distilroberta_base_climate_d roberta_embeddings_distilroberta_base_climate_d Embeddings English RoBertaEmbeddings en eng eng Living Individual 158 en.embed.Bible_roberta_base roberta_embeddings_Bible_roberta_base Embeddings English RoBertaEmbeddings en eng eng Living Individual 159 en.embed.w2v_cc_300d w2v_cc_300d Embeddings English WordEmbeddingsModel en eng eng Living Individual 160 en.pos pos_atis Part of Speech Tagging English PerceptronModel en eng eng Living Individual 161 en.ner.ner_chemical_bionlp_bc5cdr_pubmed roberta_ner_ner_chemical_bionlp_bc5cdr_pubmed Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 162 en.pos.roberta_large_english_upos roberta_pos_roberta_large_english_upos Part of Speech Tagging English RoBertaForTokenClassification en eng eng Living Individual 163 en.ner.roberta_ticker roberta_ner_roberta_ticker Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 164 en.embed.bert_political_election2020_twitter_mlm bert_embeddings_bert_political_election2020_twitter_mlm Embeddings English BertEmbeddings en eng eng Living Individual 165 en.embed.bert_base_uncased_mnli_sparse_70_unstructured_no_classifier bert_embeddings_bert_base_uncased_mnli_sparse_70_unstructured_no_classifier Embeddings English BertEmbeddings en eng eng Living Individual 166 en.embed.crosloengual_bert bert_embeddings_crosloengual_bert Embeddings English BertEmbeddings en eng eng Living Individual 167 en.embed.chemical_bert_uncased bert_embeddings_chemical_bert_uncased Embeddings English BertEmbeddings en eng eng Living Individual 168 en.embed.deberta_base_uncased bert_embeddings_deberta_base_uncased Embeddings English BertEmbeddings en eng eng Living Individual 169 en.embed.bert_base_en_cased bert_embeddings_bert_base_en_cased Embeddings English BertEmbeddings en eng eng Living Individual 170 en.embed.bert_for_patents bert_embeddings_bert_for_patents Embeddings English BertEmbeddings en eng eng Living Individual 171 en.embed.SecBERT bert_embeddings_SecBERT Embeddings English BertEmbeddings en eng eng Living Individual 172 en.embed.bert_base_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings English BertEmbeddings en eng eng Living Individual 173 en.embed.DiLBERT bert_embeddings_DiLBERT Embeddings English BertEmbeddings en eng eng Living Individual 174 en.embed.FinancialBERT bert_embeddings_FinancialBERT Embeddings English BertEmbeddings en eng eng Living Individual 175 en.embed.false_positives_scancode_bert_base_uncased_L8_1 bert_embeddings_false_positives_scancode_bert_base_uncased_L8_1 Embeddings English BertEmbeddings en eng eng Living Individual 176 en.embed.legal_bert_small_uncased bert_embeddings_legal_bert_small_uncased Embeddings English BertEmbeddings en eng eng Living Individual 177 en.embed.legal_bert_base_uncased bert_embeddings_legal_bert_base_uncased Embeddings English BertEmbeddings en eng eng Living Individual 178 en.embed.COVID_SciBERT bert_embeddings_COVID_SciBERT Embeddings English BertEmbeddings en eng eng Living Individual 179 en.embed.e bert_biolink_base Embeddings English BertEmbeddings en eng eng Living Individual 180 en.embed.danbert_small_cased bert_embeddings_danbert_small_cased Embeddings English BertEmbeddings en eng eng Living Individual 181 en.embed.bert_base_uncased_dstc9 bert_embeddings_bert_base_uncased_dstc9 Embeddings English BertEmbeddings en eng eng Living Individual 182 en.embed.hateBERT bert_embeddings_hateBERT Embeddings English BertEmbeddings en eng eng Living Individual 183 en.embed.childes_bert bert_embeddings_childes_bert Embeddings English BertEmbeddings en eng eng Living Individual 184 en.embed.clinical_pubmed_bert_base_512 bert_embeddings_clinical_pubmed_bert_base_512 Embeddings English BertEmbeddings en eng eng Living Individual 185 en.embed.netbert bert_embeddings_netbert Embeddings English BertEmbeddings en eng eng Living Individual 186 en.embed.psych_search bert_embeddings_psych_search Embeddings English BertEmbeddings en eng eng Living Individual 187 en.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings English BertEmbeddings en eng eng Living Individual 188 en.embed.finbert_pretrain_yiyanghkust bert_embeddings_finbert_pretrain_yiyanghkust Embeddings English BertEmbeddings en eng eng Living Individual 189 en.embed.lic_class_scancode_bert_base_cased_L32_1 bert_embeddings_lic_class_scancode_bert_base_cased_L32_1 Embeddings English BertEmbeddings en eng eng Living Individual 190 en.embed.sec_bert_sh bert_embeddings_sec_bert_sh Embeddings English BertEmbeddings en eng eng Living Individual 191 en.embed.sec_bert_num bert_embeddings_sec_bert_num Embeddings English BertEmbeddings en eng eng Living Individual 192 en.embed.finest_bert bert_embeddings_finest_bert Embeddings English BertEmbeddings en eng eng Living Individual 193 en.embed.bert_large_cased_whole_word_masking bert_embeddings_bert_large_cased_whole_word_masking Embeddings English BertEmbeddings en eng eng Living Individual 194 en.embed.clinical_pubmed_bert_base_128 bert_embeddings_clinical_pubmed_bert_base_128 Embeddings English BertEmbeddings en eng eng Living Individual 195 en.embed.bert_base_uncased_sparse_70_unstructured bert_embeddings_bert_base_uncased_sparse_70_unstructured Embeddings English BertEmbeddings en eng eng Living Individual 196 en.embed.sec_bert_base bert_embeddings_sec_bert_base Embeddings English BertEmbeddings en eng eng Living Individual 197 en.stopwords stopwords_iso Stop Words Removal English StopWordsCleaner en eng eng Living Individual 198 en.embed.agriculture_bert_uncased bert_embeddings_agriculture_bert_uncased Embeddings English BertEmbeddings en eng eng Living Individual 199 en.embed.bert_large_uncased_whole_word_masking bert_embeddings_bert_large_uncased_whole_word_masking Embeddings English BertEmbeddings en eng eng Living Individual 200 en.embed.ge bert_biolink_large Embeddings English BertEmbeddings en eng eng Living Individual 201 en.ner.roberta_large_finetuned_abbr roberta_ner_roberta_large_finetuned_abbr Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 202 en.ner.roberta_classics_ner roberta_ner_roberta_classics_ner Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 203 en.pos.roberta_base_english_upos roberta_pos_roberta_base_english_upos Part of Speech Tagging English RoBertaForTokenClassification en eng eng Living Individual 204 en.ner.roberta_large_ner_english roberta_ner_roberta_large_ner_english Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 205 en.ner.ner_gene_dna_rna_jnlpba_pubmed roberta_ner_ner_gene_dna_rna_jnlpba_pubmed Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 206 en.ner.ner_disease_ncbi_bionlp_bc5cdr_pubmed roberta_ner_ner_disease_ncbi_bionlp_bc5cdr_pubmed Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 207 myv.embed.w2v_cc_300d w2v_cc_300d Embeddings Erzya WordEmbeddingsModel nan myv myv Living Individual 208 fo.pos pos_farpahc Part of Speech Tagging Faroese PerceptronModel fo fao fao Living Individual 209 fi.embed.w2v_cc_300d w2v_cc_300d Embeddings Finnish WordEmbeddingsModel fi fin fin Living Individual 210 fi.pos pos_tdt Part of Speech Tagging Finnish PerceptronModel fi fin fin Living Individual 211 fi.lemma lemma_tdt Lemmatization Finnish LemmatizerModel fi fin fin Living Individual 212 fi.stopwords stopwords_iso Stop Words Removal Finnish StopWordsCleaner fi fin fin Living Individual 213 fi.lemma lemma_tdt Lemmatization Finnish LemmatizerModel fi fin fin Living Individual 214 fr.embed.camembert_large camembert_large Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 215 fr.embed.camembert_base camembert_base Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 216 fr.embed.camembert_ccnet4g camembert_base_ccnet_4gb Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 217 fr.embed.camembert_base_ccnet camembert_base_ccnet Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 218 fr.embed.camembert_oscar_4g camembert_base_oscar_4gb Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 219 fr.embed.camembert_wiki_4g camembert_base_wikipedia_4gb Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 220 fr.embed.albert albert_embeddings_fralbert_base Embeddings French AlbertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 221 fr.embed.distilbert distilbert_embeddings_distilbert_base_fr_cased Embeddings French DistilBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 222 fr.embed.bert_base_fr_cased bert_embeddings_bert_base_fr_cased Embeddings French BertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 223 fr.pos pos_sequoia Part of Speech Tagging French PerceptronModel fr 639-2/T: fra639-2/B: fre fra Living Individual 224 fr.pos pos_sequoia Part of Speech Tagging French PerceptronModel fr 639-2/T: fra639-2/B: fre fra Living Individual 225 fr.embed.french_roberta roberta_embeddings_french_roberta Embeddings French RoBertaEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 226 fr.lemma lemma_ftb Lemmatization French LemmatizerModel fr 639-2/T: fra639-2/B: fre fra Living Individual 227 fr.lemma lemma_ftb Lemmatization French LemmatizerModel fr 639-2/T: fra639-2/B: fre fra Living Individual 228 fr.stopwords stopwords_iso Stop Words Removal French StopWordsCleaner fr 639-2/T: fra639-2/B: fre fra Living Individual 229 fr.embed.roberta_base_wechsel_french roberta_embeddings_roberta_base_wechsel_french Embeddings French RoBertaEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 230 gd.embed.w2v_cc_300d w2v_cc_300d Embeddings Gaelic, Scottish Gaelic WordEmbeddingsModel gd gla gla Living Individual 231 gl.embed.w2v_cc_300d w2v_cc_300d Embeddings Galician WordEmbeddingsModel gl glg glg Living Individual 232 gl.lemma lemma_treegal Lemmatization Galician LemmatizerModel gl glg glg Living Individual 233 ka.embed.w2v_cc_300d w2v_cc_300d Embeddings Georgian WordEmbeddingsModel ka 639-2/T: kat639-2/B: geo kat Living Individual 234 de.embed.distilbert_base_de_cased distilbert_embeddings_distilbert_base_de_cased Embeddings German DistilBertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 235 de.embed.distilbert_base_german_cased distilbert_embeddings_distilbert_base_german_cased Embeddings German DistilBertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 236 de.embed.albert_german_ner albert_embeddings_albert_german_ner Embeddings German AlbertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 237 de.embed.bert_base_historical_german_rw_cased bert_embeddings_bert_base_historical_german_rw_cased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 238 de.embed.gbert_base bert_embeddings_gbert_base Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 239 de.embed.german_financial_statements_bert bert_embeddings_german_financial_statements_bert Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 240 de.stopwords stopwords_iso Stop Words Removal German StopWordsCleaner de 639-2/T: deu639-2/B: ger deu Living Individual 241 de.lemma lemma_spacylookup Lemmatization German LemmatizerModel de 639-2/T: deu639-2/B: ger deu Living Individual 242 de.embed.bert_base_german_dbmdz_uncased bert_embeddings_bert_base_german_dbmdz_uncased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 243 de.embed.roberta_base_wechsel_german roberta_embeddings_roberta_base_wechsel_german Embeddings German RoBertaEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 244 de.embed.gbert_large bert_embeddings_gbert_large Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 245 de.embed.bert_base_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 246 de.embed.bert_base_german_cased_oldvocab bert_embeddings_bert_base_german_cased_oldvocab Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 247 de.embed.bert_base_de_cased bert_embeddings_bert_base_de_cased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 248 de.embed.bert_base_german_uncased bert_embeddings_bert_base_german_uncased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 249 de.embed.bert_base_german_dbmdz_cased bert_embeddings_bert_base_german_dbmdz_cased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 250 gom.embed.w2v_cc_300d w2v_cc_300d Embeddings Goan Konkani WordEmbeddingsModel nan nan gom Living Individual 251 gu.embed.RoBERTa_hindi_guj_san roberta_embeddings_RoBERTa_hindi_guj_san Embeddings Gujarati RoBertaEmbeddings gu guj guj Living Individual 252 gu.stopwords stopwords_iso Stop Words Removal Gujarati StopWordsCleaner gu guj guj Living Individual 253 he.stopwords stopwords_iso Stop Words Removal Hebrew StopWordsCleaner he heb heb Living Individual 254 hi.embed.distilbert_base_hi_cased distilbert_embeddings_distilbert_base_hi_cased Embeddings Hindi DistilBertEmbeddings hi hin hin Living Individual 255 hi.embed.indic_transformers_hi_distilbert distilbert_embeddings_indic_transformers_hi_distilbert Embeddings Hindi DistilBertEmbeddings hi hin hin Living Individual 256 hi.stopwords stopwords_iso Stop Words Removal Hindi StopWordsCleaner hi hin hin Living Individual 257 hi.embed.RoBERTa_hindi_guj_san roberta_embeddings_RoBERTa_hindi_guj_san Embeddings Hindi RoBertaEmbeddings hi hin hin Living Individual 258 hi.embed.indic_transformers_hi_roberta roberta_embeddings_indic_transformers_hi_roberta Embeddings Hindi RoBertaEmbeddings hi hin hin Living Individual 259 hi.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Hindi BertEmbeddings hi hin hin Living Individual 260 hi.embed.indic_transformers_hi_bert bert_embeddings_indic_transformers_hi_bert Embeddings Hindi BertEmbeddings hi hin hin Living Individual 261 hu.lemma lemma_spacylookup Lemmatization Hungarian LemmatizerModel hu hun hun Living Individual 262 hu.stopwords stopwords_iso Stop Words Removal Hungarian StopWordsCleaner hu hun hun Living Individual 263 is.lemma lemma_icepahc Lemmatization Icelandic LemmatizerModel is 639-2/T: isl639-2/B: ice isl Living Individual 264 is.stopwords stopwords_iso Stop Words Removal Icelandic StopWordsCleaner is 639-2/T: isl639-2/B: ice isl Living Individual 265 id.embed.distilbert distilbert_embeddings_distilbert_base_indonesian Embeddings Indonesian DistilBertEmbeddings id ind ind Living Individual 266 id.pos pos_csui Part of Speech Tagging Indonesian PerceptronModel id ind ind Living Individual 267 id.embed.indo_roberta_small roberta_embeddings_indo_roberta_small Embeddings Indonesian RoBertaEmbeddings id ind ind Living Individual 268 id.embed.indonesian_roberta_base roberta_embeddings_indonesian_roberta_base Embeddings Indonesian RoBertaEmbeddings id ind ind Living Individual 269 id.pos.indonesian_roberta_base_posp_tagger roberta_pos_indonesian_roberta_base_posp_tagger Part of Speech Tagging Indonesian RoBertaForTokenClassification id ind ind Living Individual 270 id.lemma lemma_gsd Lemmatization Indonesian LemmatizerModel id ind ind Living Individual 271 id.lemma lemma_gsd Lemmatization Indonesian LemmatizerModel id ind ind Living Individual 272 id.embed.roberta_base_indonesian_522M roberta_embeddings_roberta_base_indonesian_522M Embeddings Indonesian RoBertaEmbeddings id ind ind Living Individual 273 id.stopwords stopwords_iso Stop Words Removal Indonesian StopWordsCleaner id ind ind Living Individual 274 id.embed.indonesian_roberta_large roberta_embeddings_indonesian_roberta_large Embeddings Indonesian RoBertaEmbeddings id ind ind Living Individual 275 ga.pos pos_idt Part of Speech Tagging Irish PerceptronModel ga gle gle Living Individual 276 ga.stopwords stopwords_iso Stop Words Removal Irish StopWordsCleaner ga gle gle Living Individual 277 it.embed.distilbert_base_it_cased distilbert_embeddings_distilbert_base_it_cased Embeddings Italian DistilBertEmbeddings it ita ita Living Individual 278 it.embed.BERTino distilbert_embeddings_BERTino Embeddings Italian DistilBertEmbeddings it ita ita Living Individual 279 it.stopwords stopwords_iso Stop Words Removal Italian StopWordsCleaner it ita ita Living Individual 280 it.pos pos_partut Part of Speech Tagging Italian PerceptronModel it ita ita Living Individual 281 it.embed.bert_base_italian_xxl_cased bert_embeddings_bert_base_italian_xxl_cased Embeddings Italian BertEmbeddings it ita ita Living Individual 282 it.embed.bert_base_italian_xxl_uncased bert_embeddings_bert_base_italian_xxl_uncased Embeddings Italian BertEmbeddings it ita ita Living Individual 283 it.embed.chefberto_italian_cased bert_embeddings_chefberto_italian_cased Embeddings Italian BertEmbeddings it ita ita Living Individual 284 it.embed.hseBert_it_cased bert_embeddings_hseBert_it_cased Embeddings Italian BertEmbeddings it ita ita Living Individual 285 it.embed.wineberto_italian_cased bert_embeddings_wineberto_italian_cased Embeddings Italian BertEmbeddings it ita ita Living Individual 286 it.pos pos_partut Part of Speech Tagging Italian PerceptronModel it ita ita Living Individual 287 it.lemma lemma_twittiro Lemmatization Italian LemmatizerModel it ita ita Living Individual 288 it.lemma lemma_twittiro Lemmatization Italian LemmatizerModel it ita ita Living Individual 289 it.lemma lemma_twittiro Lemmatization Italian LemmatizerModel it ita ita Living Individual 290 ja.embed.distilbert_base_ja_cased distilbert_embeddings_distilbert_base_ja_cased Embeddings Japanese DistilBertEmbeddings ja jpn jpn Living Individual 291 ja.embed.albert_base_japanese_v1 albert_embeddings_albert_base_japanese_v1 Embeddings Japanese AlbertEmbeddings ja jpn jpn Living Individual 292 ja.embed.bert_base_ja_cased bert_embeddings_bert_base_ja_cased Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 293 ja.embed.bert_base_japanese_char_v2 bert_embeddings_bert_base_japanese_char_v2 Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 294 ja.embed.bert_base_japanese_char_extended bert_embeddings_bert_base_japanese_char_extended Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 295 ja.embed.bert_large_japanese_char bert_embeddings_bert_large_japanese_char Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 296 ja.embed.bert_large_japanese bert_embeddings_bert_large_japanese Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 297 ja.embed.bert_small_japanese bert_embeddings_bert_small_japanese Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 298 ja.embed.bert_large_japanese_char_extended bert_embeddings_bert_large_japanese_char_extended Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 299 ja.pos pos_gsd Part of Speech Tagging Japanese PerceptronModel ja jpn jpn Living Individual 300 ja.embed.bert_small_japanese_fin bert_embeddings_bert_small_japanese_fin Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 301 ja.embed.bert_base_japanese_basic_char_v2 bert_embeddings_bert_base_japanese_basic_char_v2 Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 302 ja.stopwords stopwords_iso Stop Words Removal Japanese StopWordsCleaner ja jpn jpn Living Individual 303 ja.embed.bert_base_japanese_char_whole_word_masking bert_embeddings_bert_base_japanese_char_whole_word_masking Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 304 ja.embed.bert_base_japanese_char bert_embeddings_bert_base_japanese_char Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 305 ja.embed.bert_base_japanese_whole_word_masking bert_embeddings_bert_base_japanese_whole_word_masking Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 306 ja.embed.bert_base_japanese_v2 bert_embeddings_bert_base_japanese_v2 Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 307 jv.embed.distilbert distilbert_embeddings_javanese_distilbert_small Embeddings Javanese DistilBertEmbeddings jv jav jav Living Individual 308 jv.embed.javanese_distilbert_small_imdb distilbert_embeddings_javanese_distilbert_small_imdb Embeddings Javanese DistilBertEmbeddings jv jav jav Living Individual 309 jv.embed.javanese_roberta_small roberta_embeddings_javanese_roberta_small Embeddings Javanese RoBertaEmbeddings jv jav jav Living Individual 310 jv.embed.javanese_roberta_small_imdb roberta_embeddings_javanese_roberta_small_imdb Embeddings Javanese RoBertaEmbeddings jv jav jav Living Individual 311 jv.embed.javanese_bert_small_imdb bert_embeddings_javanese_bert_small_imdb Embeddings Javanese BertEmbeddings jv jav jav Living Individual 312 jv.embed.javanese_bert_small bert_embeddings_javanese_bert_small Embeddings Javanese BertEmbeddings jv jav jav Living Individual 313 kn.embed.KNUBert roberta_embeddings_KNUBert Embeddings Kannada RoBertaEmbeddings kn kan kan Living Individual 314 kn.embed.KanBERTo roberta_embeddings_KanBERTo Embeddings Kannada RoBertaEmbeddings kn kan kan Living Individual 315 kn.stopwords stopwords_iso Stop Words Removal Kannada StopWordsCleaner kn kan kan Living Individual 316 ky.stopwords stopwords_iso Stop Words Removal Kirghiz, Kyrgyz StopWordsCleaner ky kir kir Living Individual 317 ko.lemma lemma_gsd Lemmatization Korean LemmatizerModel ko kor kor Living Individual 318 ko.stopwords stopwords_iso Stop Words Removal Korean StopWordsCleaner ko kor kor Living Individual 319 ko.embed.roberta_ko_small roberta_embeddings_roberta_ko_small Embeddings Korean RoBertaEmbeddings ko kor kor Living Individual 320 ko.pos pos_gsd Part of Speech Tagging Korean PerceptronModel ko kor kor Living Individual 321 ko.embed.bert_kor_base bert_embeddings_bert_kor_base Embeddings Korean BertEmbeddings ko kor kor Living Individual 322 ko.embed.dbert bert_embeddings_dbert Embeddings Korean BertEmbeddings ko kor kor Living Individual 323 ko.embed.KR_FinBert bert_embeddings_KR_FinBert Embeddings Korean BertEmbeddings ko kor kor Living Individual 324 ko.embed.bert_base_v1_sports bert_embeddings_bert_base_v1_sports Embeddings Korean BertEmbeddings ko kor kor Living Individual 325 ko.lemma lemma_gsd Lemmatization Korean LemmatizerModel ko kor kor Living Individual 326 lb.stopwords stopwords_iso Stop Words Removal Letzeburgesch, Luxembourgish StopWordsCleaner lb ltz ltz Living Individual 327 lb.lemma lemma_spacylookup Lemmatization Letzeburgesch, Luxembourgish LemmatizerModel lb ltz ltz Living Individual 328 lb.embed.w2v_cc_300d w2v_cc_300d Embeddings Letzeburgesch, Luxembourgish WordEmbeddingsModel lb ltz ltz Living Individual 329 lij.stopwords stopwords_iso Stop Words Removal Ligurian StopWordsCleaner nan nan lij Living Individual 330 lt.embed.w2v_cc_300d w2v_cc_300d Embeddings Lithuanian WordEmbeddingsModel lt lit lit Living Individual 331 lt.lemma lemma_spacylookup Lemmatization Lithuanian LemmatizerModel lt lit lit Living Individual 332 lt.stopwords stopwords_iso Stop Words Removal Lithuanian StopWordsCleaner lt lit lit Living Individual 333 lmo.embed.w2v_cc_300d w2v_cc_300d Embeddings Lombard WordEmbeddingsModel nan nan lmo Living Individual 334 nds.embed.w2v_cc_300d w2v_cc_300d Embeddings Low German, Low Saxon WordEmbeddingsModel nan nds nds Living Individual 335 mk.stopwords stopwords_iso Stop Words Removal Macedonian StopWordsCleaner mk 639-2/T: mkd639-2/B: mac mkd Living Individual 336 mk.lemma lemma_spacylookup Lemmatization Macedonian LemmatizerModel mk 639-2/T: mkd639-2/B: mac mkd Living Individual 337 mk.embed.w2v_cc_300d w2v_cc_300d Embeddings Macedonian WordEmbeddingsModel mk 639-2/T: mkd639-2/B: mac mkd Living Individual 338 mai.embed.w2v_cc_300d w2v_cc_300d Embeddings Maithili WordEmbeddingsModel nan mai mai Living Individual 339 ml.stopwords stopwords_iso Stop Words Removal Malayalam StopWordsCleaner ml mal mal Living Individual 340 ml.embed.w2v_cc_300d w2v_cc_300d Embeddings Malayalam WordEmbeddingsModel ml mal mal Living Individual 341 mt.lemma lemma_mudt Lemmatization Maltese LemmatizerModel mt mlt mlt Living Individual 342 mt.pos pos_mudt Part of Speech Tagging Maltese PerceptronModel mt mlt mlt Living Individual 343 mt.embed.w2v_cc_300d w2v_cc_300d Embeddings Maltese WordEmbeddingsModel mt mlt mlt Living Individual 344 gv.embed.w2v_cc_300d w2v_cc_300d Embeddings Manx WordEmbeddingsModel gv glv glv Living Individual 345 mr.embed.distilbert distilbert_embeddings_marathi_distilbert Embeddings Marathi DistilBertEmbeddings mr mar mar Living Individual 346 mr.embed.albert albert_embeddings_marathi_albert Embeddings Marathi AlbertEmbeddings mr mar mar Living Individual 347 mr.embed.albert albert_embeddings_marathi_albert Embeddings Marathi AlbertEmbeddings mr mar mar Living Individual 348 mr.embed.albert_v2 albert_embeddings_marathi_albert_v2 Embeddings Marathi AlbertEmbeddings mr mar mar Living Individual 349 mr.embed.albert_v2 albert_embeddings_marathi_albert_v2 Embeddings Marathi AlbertEmbeddings mr mar mar Living Individual 350 mr.lemma lemma_ufal Lemmatization Marathi LemmatizerModel mr mar mar Living Individual 351 mr.stopwords stopwords_iso Stop Words Removal Marathi StopWordsCleaner mr mar mar Living Individual 352 mr.embed.marathi_bert bert_embeddings_marathi_bert Embeddings Marathi BertEmbeddings mr mar mar Living Individual 353 mr.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Marathi BertEmbeddings mr mar mar Living Individual 354 mr.pos pos_ufal Part of Speech Tagging Marathi PerceptronModel mr mar mar Living Individual 355 mzn.embed.w2v_cc_300d w2v_cc_300d Embeddings Mazanderani WordEmbeddingsModel nan nan mzn Living Individual 356 min.embed.w2v_cc_300d w2v_cc_300d Embeddings Minangkabau WordEmbeddingsModel nan min min Living Individual 357 xmf.embed.w2v_cc_300d w2v_cc_300d Embeddings Mingrelian WordEmbeddingsModel nan nan xmf Living Individual 358 mwl.embed.w2v_cc_300d w2v_cc_300d Embeddings Mirandese WordEmbeddingsModel nan mwl mwl Living Individual 359 el.stopwords stopwords_iso Stop Words Removal Modern Greek (1453-) StopWordsCleaner el 639-2/T: ell639-2/B: gre ell Living Individual 360 ro.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_ro_cased Embeddings Moldavian, Moldovan, Romanian DistilBertEmbeddings ro 639-2/T: ron639-2/B: rum ron Living Individual 361 ro.embed.ALR_BERT albert_embeddings_ALR_BERT Embeddings Moldavian, Moldovan, Romanian AlbertEmbeddings ro 639-2/T: ron639-2/B: rum ron Living Individual 362 ro.embed.w2v_cc_300d w2v_cc_300d Embeddings Moldavian, Moldovan, Romanian WordEmbeddingsModel ro 639-2/T: ron639-2/B: rum ron Living Individual 363 ro.stopwords stopwords_iso Stop Words Removal Moldavian, Moldovan, Romanian StopWordsCleaner ro 639-2/T: ron639-2/B: rum ron Living Individual 364 ro.pos pos_nonstandard Part of Speech Tagging Moldavian, Moldovan, Romanian PerceptronModel ro 639-2/T: ron639-2/B: rum ron Living Individual 365 ro.lemma lemma_spacylookup Lemmatization Moldavian, Moldovan, Romanian LemmatizerModel ro 639-2/T: ron639-2/B: rum ron Living Individual 366 nap.embed.w2v_cc_300d w2v_cc_300d Embeddings Neapolitan WordEmbeddingsModel nan nap nap Living Individual 367 new.embed.w2v_cc_300d w2v_cc_300d Embeddings Nepal Bhasa, Newari WordEmbeddingsModel nan new new Living Individual 368 frr.embed.w2v_cc_300d w2v_cc_300d Embeddings Northern Frisian WordEmbeddingsModel nan frr frr Living Individual 369 sme.lemma lemma_giella Lemmatization Northern Sami LemmatizerModel se sme sme Living Individual 370 sme.pos pos_giella Part of Speech Tagging Northern Sami PerceptronModel se sme sme Living Individual 371 nso.embed.w2v_cc_300d w2v_cc_300d Embeddings Northern Sotho, Pedi, Sepedi WordEmbeddingsModel nan nso nso Living Individual 372 nb.stopwords stopwords_iso Stop Words Removal Norwegian Bokmål StopWordsCleaner nb nob nob Living Individual 373 nb.lemma lemma_spacylookup Lemmatization Norwegian Bokmål LemmatizerModel nb nob nob Living Individual 374 nn.embed.w2v_cc_300d w2v_cc_300d Embeddings Norwegian Nynorsk WordEmbeddingsModel nn nno nno Living Individual 375 oc.embed.w2v_cc_300d w2v_cc_300d Embeddings Occitan (post 1500) WordEmbeddingsModel oc oci oci Living Individual 376 os.embed.w2v_cc_300d w2v_cc_300d Embeddings Ossetian, Ossetic WordEmbeddingsModel os oss oss Living Individual 377 pa.embed.w2v_cc_300d w2v_cc_300d Embeddings Panjabi, Punjabi WordEmbeddingsModel pa pan pan Living Individual 378 pa.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Panjabi, Punjabi BertEmbeddings pa pan pan Living Individual 379 pfl.embed.w2v_cc_300d w2v_cc_300d Embeddings Pfaelzisch WordEmbeddingsModel nan nan pfl Living Individual 380 pms.embed.w2v_cc_300d w2v_cc_300d Embeddings Piemontese WordEmbeddingsModel nan nan pms Living Individual 381 pl.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_pl_cased Embeddings Polish DistilBertEmbeddings pl pol pol Living Individual 382 pl.stopwords stopwords_iso Stop Words Removal Polish StopWordsCleaner pl pol pol Living Individual 383 pl.embed.w2v_cc_300d w2v_cc_300d Embeddings Polish WordEmbeddingsModel pl pol pol Living Individual 384 pl.lemma lemma_lfg Lemmatization Polish LemmatizerModel pl pol pol Living Individual 385 pt.med_ner.deid.subentity ner_deid_subentity De-identification Portuguese MedicalNerModel pt por por Living Individual 386 pt.med_ner.deid.generic ner_deid_generic De-identification Portuguese MedicalNerModel pt por por Living Individual 387 pt.med_ner.deid ner_deid_generic De-identification Portuguese MedicalNerModel pt por por Living Individual 388 pt.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_pt_cased Embeddings Portuguese DistilBertEmbeddings pt por por Living Individual 389 pt.embed.BR_BERTo roberta_embeddings_BR_BERTo Embeddings Portuguese RoBertaEmbeddings pt por por Living Individual 390 pt.embed.gs_all biobert_embeddings_all Embeddings Portuguese BertEmbeddings pt por por Living Individual 391 pt.stopwords stopwords_iso Stop Words Removal Portuguese StopWordsCleaner pt por por Living Individual 392 pt.embed.gs_clinical biobert_embeddings_clinical Embeddings Portuguese BertEmbeddings pt por por Living Individual 393 pt.embed.gs_biomedical biobert_embeddings_biomedical Embeddings Portuguese BertEmbeddings pt por por Living Individual 394 pt.lemma lemma_bosque Lemmatization Portuguese LemmatizerModel pt por por Living Individual 395 pt.lemma lemma_bosque Lemmatization Portuguese LemmatizerModel pt por por Living Individual 396 pt.embed.bert_base_portuguese_cased_finetuned_tcu_acordaos bert_embeddings_bert_base_portuguese_cased_finetuned_tcu_acordaos Embeddings Portuguese BertEmbeddings pt por por Living Individual 397 pt.ner.satellite_instrument_roberta_NER roberta_ner_satellite_instrument_roberta_NER Named Entity Recognition Portuguese RoBertaForTokenClassification pt por por Living Individual 398 pt.embed.bert_small_gl_cased bert_embeddings_bert_small_gl_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 399 pt.embed.bert_large_cased_pt_lenerbr bert_embeddings_bert_large_cased_pt_lenerbr Embeddings Portuguese BertEmbeddings pt por por Living Individual 400 pt.embed.bert_large_portuguese_cased bert_embeddings_bert_large_portuguese_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 401 pt.embed.bert_base_cased_pt_lenerbr bert_embeddings_bert_base_cased_pt_lenerbr Embeddings Portuguese BertEmbeddings pt por por Living Individual 402 pt.embed.bert_base_portuguese_cased_finetuned_peticoes bert_embeddings_bert_base_portuguese_cased_finetuned_peticoes Embeddings Portuguese BertEmbeddings pt por por Living Individual 403 pt.embed.bert_base_portuguese_cased bert_embeddings_bert_base_portuguese_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 404 pt.embed.bert_base_pt_cased bert_embeddings_bert_base_pt_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 405 pt.embed.bert_base_gl_cased bert_embeddings_bert_base_gl_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 406 rm.embed.w2v_cc_300d w2v_cc_300d Embeddings Romansh WordEmbeddingsModel rm roh roh Living Individual 407 ru.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_ru_cased Embeddings Russian DistilBertEmbeddings ru rus rus Living Individual 408 ru.pos pos_syntagrus Part of Speech Tagging Russian PerceptronModel ru rus rus Living Individual 409 ru.lemma lemma_gsd Lemmatization Russian LemmatizerModel ru rus rus Living Individual 410 ru.lemma lemma_gsd Lemmatization Russian LemmatizerModel ru rus rus Living Individual 411 ru.embed.ruRoberta_large roberta_embeddings_ruRoberta_large Embeddings Russian RoBertaEmbeddings ru rus rus Living Individual 412 ru.pos pos_syntagrus Part of Speech Tagging Russian PerceptronModel ru rus rus Living Individual 413 ru.stopwords stopwords_iso Stop Words Removal Russian StopWordsCleaner ru rus rus Living Individual 414 ru.embed.roberta_base_russian_v0 roberta_embeddings_roberta_base_russian_v0 Embeddings Russian RoBertaEmbeddings ru rus rus Living Individual 415 ru.embed.bert_base_ru_cased bert_embeddings_bert_base_ru_cased Embeddings Russian BertEmbeddings ru rus rus Living Individual 416 ru.embed.w2v_cc_300d w2v_cc_300d Embeddings Russian WordEmbeddingsModel ru rus rus Living Individual 417 sco.embed.w2v_cc_300d w2v_cc_300d Embeddings Scots WordEmbeddingsModel nan sco sco Living Individual 418 sr.lemma lemma_spacylookup Lemmatization Serbian LemmatizerModel sr srp srp Living Individual 419 sr.embed.w2v_cc_300d w2v_cc_300d Embeddings Serbian WordEmbeddingsModel sr srp srp Living Individual 420 sr.lemma lemma_spacylookup Lemmatization Serbian LemmatizerModel sr srp srp Living Individual 421 sr.stopwords stopwords_iso Stop Words Removal Serbian StopWordsCleaner sr srp srp Living Individual 422 scn.embed.w2v_cc_300d w2v_cc_300d Embeddings Sicilian WordEmbeddingsModel nan scn scn Living Individual 423 sd.embed.w2v_cc_300d w2v_cc_300d Embeddings Sindhi WordEmbeddingsModel sd snd snd Living Individual 424 si.stopwords stopwords_iso Stop Words Removal Sinhala, Sinhalese StopWordsCleaner si sin sin Living Individual 425 si.embed.w2v_cc_300d w2v_cc_300d Embeddings Sinhala, Sinhalese WordEmbeddingsModel si sin sin Living Individual 426 sk.stopwords stopwords_iso Stop Words Removal Slovak StopWordsCleaner sk 639-2/T: slk639-2/B: slo slk Living Individual 427 sk.lemma lemma_snk Lemmatization Slovak LemmatizerModel sk 639-2/T: slk639-2/B: slo slk Living Individual 428 sk.embed.w2v_cc_300d w2v_cc_300d Embeddings Slovak WordEmbeddingsModel sk 639-2/T: slk639-2/B: slo slk Living Individual 429 sl.lemma lemma_sst Lemmatization Slovenian LemmatizerModel sl slv slv Living Individual 430 sl.stopwords stopwords_iso Stop Words Removal Slovenian StopWordsCleaner sl slv slv Living Individual 431 sl.pos pos_sst Part of Speech Tagging Slovenian PerceptronModel sl slv slv Living Individual 432 sl.embed.w2v_cc_300d w2v_cc_300d Embeddings Slovenian WordEmbeddingsModel sl slv slv Living Individual 433 so.embed.w2v_cc_300d w2v_cc_300d Embeddings Somali WordEmbeddingsModel so som som Living Individual 434 su.embed.w2v_cc_300d w2v_cc_300d Embeddings Sundanese WordEmbeddingsModel su sun sun Living Individual 435 su.embed.sundanese_roberta_base roberta_embeddings_sundanese_roberta_base Embeddings Sundanese RoBertaEmbeddings su sun sun Living Individual 436 sv.stopwords stopwords_iso Stop Words Removal Swedish StopWordsCleaner sv swe swe Living Individual 437 sv.embed.w2v_cc_300d w2v_cc_300d Embeddings Swedish WordEmbeddingsModel sv swe swe Living Individual 438 sv.lemma lemma_lines Lemmatization Swedish LemmatizerModel sv swe swe Living Individual 439 sv.lemma lemma_lines Lemmatization Swedish LemmatizerModel sv swe swe Living Individual 440 tl.lemma lemma_spacylookup Lemmatization Tagalog LemmatizerModel tl tgl tgl Living Individual 441 tl.embed.w2v_cc_300d w2v_cc_300d Embeddings Tagalog WordEmbeddingsModel tl tgl tgl Living Individual 442 tl.stopwords stopwords_iso Stop Words Removal Tagalog StopWordsCleaner tl tgl tgl Living Individual 443 tl.embed.roberta_tagalog_large roberta_embeddings_roberta_tagalog_large Embeddings Tagalog RoBertaEmbeddings tl tgl tgl Living Individual 444 tl.embed.roberta_tagalog_base roberta_embeddings_roberta_tagalog_base Embeddings Tagalog RoBertaEmbeddings tl tgl tgl Living Individual 445 tg.embed.w2v_cc_300d w2v_cc_300d Embeddings Tajik WordEmbeddingsModel tg tgk tgk Living Individual 446 ta.stopwords stopwords_iso Stop Words Removal Tamil StopWordsCleaner ta tam tam Living Individual 447 ta.embed.w2v_cc_300d w2v_cc_300d Embeddings Tamil WordEmbeddingsModel ta tam tam Living Individual 448 ta.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Tamil BertEmbeddings ta tam tam Living Individual 449 tt.stopwords stopwords_iso Stop Words Removal Tatar StopWordsCleaner tt tat tat Living Individual 450 tt.embed.w2v_cc_300d w2v_cc_300d Embeddings Tatar WordEmbeddingsModel tt tat tat Living Individual 451 te.embed.indic_transformers_te_bert bert_embeddings_indic_transformers_te_bert Embeddings Telugu BertEmbeddings te tel tel Living Individual 452 te.embed.telugu_bertu bert_embeddings_telugu_bertu Embeddings Telugu BertEmbeddings te tel tel Living Individual 453 te.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Telugu BertEmbeddings te tel tel Living Individual 454 te.embed.indic_transformers_te_roberta roberta_embeddings_indic_transformers_te_roberta Embeddings Telugu RoBertaEmbeddings te tel tel Living Individual 455 te.stopwords stopwords_iso Stop Words Removal Telugu StopWordsCleaner te tel tel Living Individual 456 te.lemma lemma_mtg Lemmatization Telugu LemmatizerModel te tel tel Living Individual 457 te.embed.w2v_cc_300d w2v_cc_300d Embeddings Telugu WordEmbeddingsModel te tel tel Living Individual 458 th.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_th_cased Embeddings Thai DistilBertEmbeddings th tha tha Living Individual 459 th.stopwords stopwords_iso Stop Words Removal Thai StopWordsCleaner th tha tha Living Individual 460 th.embed.w2v_cc_300d w2v_cc_300d Embeddings Thai WordEmbeddingsModel th tha tha Living Individual 461 ti.stopwords stopwords_iso Stop Words Removal Tigrinya StopWordsCleaner ti tir tir Living Individual 462 als.embed.w2v_cc_300d w2v_cc_300d Embeddings Tosk Albanian WordEmbeddingsModel nan nan als Living Individual 463 tn.stopwords stopwords_iso Stop Words Removal Tswana StopWordsCleaner tn tsn tsn Living Individual 464 tr.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_tr_cased Embeddings Turkish DistilBertEmbeddings tr tur tur Living Individual 465 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 466 tr.stopwords stopwords_iso Stop Words Removal Turkish StopWordsCleaner tr tur tur Living Individual 467 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 468 tr.pos pos_boun Part of Speech Tagging Turkish PerceptronModel tr tur tur Living Individual 469 tr.embed.w2v_cc_300d w2v_cc_300d Embeddings Turkish WordEmbeddingsModel tr tur tur Living Individual 470 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 471 tr.pos pos_boun Part of Speech Tagging Turkish PerceptronModel tr tur tur Living Individual 472 tr.pos pos_boun Part of Speech Tagging Turkish PerceptronModel tr tur tur Living Individual 473 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 474 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 475 tk.embed.w2v_cc_300d w2v_cc_300d Embeddings Turkmen WordEmbeddingsModel tk tuk tuk Living Individual 476 ug.embed.w2v_cc_300d w2v_cc_300d Embeddings Uighur, Uyghur WordEmbeddingsModel ug uig uig Living Individual 477 uk.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_uk_cased Embeddings Ukrainian DistilBertEmbeddings uk ukr ukr Living Individual 478 uk.embed.ukr_roberta_base roberta_embeddings_ukr_roberta_base Embeddings Ukrainian RoBertaEmbeddings uk ukr ukr Living Individual 479 uk.stopwords stopwords_iso Stop Words Removal Ukrainian StopWordsCleaner uk ukr ukr Living Individual 480 uk.embed.w2v_cc_300d w2v_cc_300d Embeddings Ukrainian WordEmbeddingsModel uk ukr ukr Living Individual 481 uk.pos.bert_large_slavic_cyrillic_upos bert_pos_bert_large_slavic_cyrillic_upos Part of Speech Tagging Ukrainian BertForTokenClassification uk ukr ukr Living Individual 482 uk.pos.bert_base_slavic_cyrillic_upos bert_pos_bert_base_slavic_cyrillic_upos Part of Speech Tagging Ukrainian BertForTokenClassification uk ukr ukr Living Individual 483 hsb.embed.w2v_cc_300d w2v_cc_300d Embeddings Upper Sorbian WordEmbeddingsModel nan hsb hsb Living Individual 484 ur.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_ur_cased Embeddings Urdu DistilBertEmbeddings ur urd urd Living Individual 485 ur.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Urdu BertEmbeddings ur urd urd Living Individual 486 ur.embed.roberta_urdu_small roberta_embeddings_roberta_urdu_small Embeddings Urdu RoBertaEmbeddings ur urd urd Living Individual 487 ur.lemma lemma_udtb Lemmatization Urdu LemmatizerModel ur urd urd Living Individual 488 ur.lemma lemma_udtb Lemmatization Urdu LemmatizerModel ur urd urd Living Individual 489 ur.pos pos_udtb Part of Speech Tagging Urdu PerceptronModel ur urd urd Living Individual 490 ur.embed.w2v_cc_300d w2v_cc_300d Embeddings Urdu WordEmbeddingsModel ur urd urd Living Individual 491 ur.stopwords stopwords_iso Stop Words Removal Urdu StopWordsCleaner ur urd urd Living Individual 492 vec.embed.w2v_cc_300d w2v_cc_300d Embeddings Venetian WordEmbeddingsModel nan nan vec Living Individual 493 vi.stopwords stopwords_iso Stop Words Removal Vietnamese StopWordsCleaner vi vie vie Living Individual 494 vi.embed.w2v_cc_300d w2v_cc_300d Embeddings Vietnamese WordEmbeddingsModel vi vie vie Living Individual 495 vls.embed.w2v_cc_300d w2v_cc_300d Embeddings Vlaams WordEmbeddingsModel nan nan vls Living Individual 496 wa.embed.w2v_cc_300d w2v_cc_300d Embeddings Walloon WordEmbeddingsModel wa wln wln Living Individual 497 war.embed.w2v_cc_300d w2v_cc_300d Embeddings Waray (Philippines) WordEmbeddingsModel nan war war Living Individual 498 hyw.pos pos_armtdp Part of Speech Tagging Western Armenian PerceptronModel nan nan hyw Living Individual 499 hyw.lemma lemma_armtdp Lemmatization Western Armenian LemmatizerModel nan nan hyw Living Individual 500 fy.embed.w2v_cc_300d w2v_cc_300d Embeddings Western Frisian WordEmbeddingsModel fy fry fry Living Individual 501 pnb.embed.w2v_cc_300d w2v_cc_300d Embeddings Western Panjabi WordEmbeddingsModel nan nan pnb Living Individual 502 wo.pos pos_wtb Part of Speech Tagging Wolof PerceptronModel wo wol wol Living Individual 503 sah.embed.w2v_cc_300d w2v_cc_300d Embeddings Yakut WordEmbeddingsModel nan sah sah Living Individual 504 yo.embed.w2v_cc_300d w2v_cc_300d Embeddings Yoruba WordEmbeddingsModel yo yor yor Living Individual 505 zea.embed.w2v_cc_300d w2v_cc_300d Embeddings Zeeuws WordEmbeddingsModel nan nan zea Living Individual 506 sq.stopwords stopwords_iso Stop Words Removal Albanian StopWordsCleaner sq 639-2/T: sqi639-2/B: alb sqi Living Macrolanguage 507 sq.embed.w2v_cc_300d w2v_cc_300d Embeddings Albanian WordEmbeddingsModel sq 639-2/T: sqi639-2/B: alb sqi Living Macrolanguage 508 ar.embed.distilbert distilbert_embeddings_distilbert_base_ar_cased Embeddings Arabic DistilBertEmbeddings ar ara ara Living Macrolanguage 509 ar.embed.albert albert_embeddings_albert_base_arabic Embeddings Arabic AlbertEmbeddings ar ara ara Living Macrolanguage 510 ar.embed.albert_xlarge_arabic albert_embeddings_albert_xlarge_arabic Embeddings Arabic AlbertEmbeddings ar ara ara Living Macrolanguage 511 ar.embed.albert_large_arabic albert_embeddings_albert_large_arabic Embeddings Arabic AlbertEmbeddings ar ara ara Living Macrolanguage 512 ar.pos.arabic_camelbert_msa_pos_msa bert_pos_bert_base_arabic_camelbert_msa_pos_msa Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 513 ar.pos.arabic_camelbert_mix_pos_egy bert_pos_bert_base_arabic_camelbert_mix_pos_egy Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 514 ar.pos.arabic_camelbert_da_pos_glf bert_pos_bert_base_arabic_camelbert_da_pos_glf Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 515 ar.pos.arabic_camelbert_ca_pos_glf bert_pos_bert_base_arabic_camelbert_ca_pos_glf Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 516 ar.pos.arabic_camelbert_msa_pos_egy bert_pos_bert_base_arabic_camelbert_msa_pos_egy Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 517 ar.pos.arabic_camelbert_ca_pos_egy bert_pos_bert_base_arabic_camelbert_ca_pos_egy Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 518 ar.pos.arabic_camelbert_msa_pos_glf bert_pos_bert_base_arabic_camelbert_msa_pos_glf Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 519 ar.pos.arabic_camelbert_mix_pos_glf bert_pos_bert_base_arabic_camelbert_mix_pos_glf Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 520 ar.pos.arabic_camelbert_da_pos_egy bert_pos_bert_base_arabic_camelbert_da_pos_egy Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 521 ar.stopwords stopwords_iso Stop Words Removal Arabic StopWordsCleaner ar ara ara Living Macrolanguage 522 ar.embed.multi_dialect_bert_base_arabic bert_embeddings_multi_dialect_bert_base_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 523 ar.ner.arabic_camelbert_da_ner bert_ner_bert_base_arabic_camelbert_da_ner Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 524 ar.ner.arabic_camelbert_mix_ner bert_ner_bert_base_arabic_camelbert_mix_ner Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 525 ar.pos pos_padt Part of Speech Tagging Arabic PerceptronModel ar ara ara Living Macrolanguage 526 ar.ner.multilingual_cased_ner_hrl bert_ner_bert_base_multilingual_cased_ner_hrl Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 527 ar.ner.arabic_camelbert_msa_ner bert_ner_bert_base_arabic_camelbert_msa_ner Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 528 ar.ner.ANER bert_ner_ANER Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 529 ar.ner.arabert_ner bert_ner_arabert_ner Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 530 ar.lemma lemma_padt Lemmatization Arabic LemmatizerModel ar ara ara Living Macrolanguage 531 ar.pos.arabic_camelbert_mix_pos_msa bert_pos_bert_base_arabic_camelbert_mix_pos_msa Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 532 ar.embed.mbert_ar_c19 bert_embeddings_mbert_ar_c19 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 533 ar.embed.bert_base_arabic_camelbert_msa_half bert_embeddings_bert_base_arabic_camelbert_msa_half Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 534 ar.embed.bert_large_arabertv02 bert_embeddings_bert_large_arabertv02 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 535 ar.embed.AraBertMo_base_V1 bert_embeddings_AraBertMo_base_V1 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 536 ar.embed.DarijaBERT bert_embeddings_DarijaBERT Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 537 ar.embed.bert_base_arabertv02 bert_embeddings_bert_base_arabertv02 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 538 ar.embed.arabert_c19 bert_embeddings_arabert_c19 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 539 ar.embed.bert_base_arabic_camelbert_msa bert_embeddings_bert_base_arabic_camelbert_msa Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 540 ar.embed.bert_base_arabertv2 bert_embeddings_bert_base_arabertv2 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 541 ar.embed.bert_base_arabic bert_embeddings_bert_base_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 542 ar.embed.Ara_DialectBERT bert_embeddings_Ara_DialectBERT Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 543 ar.embed.MARBERT bert_embeddings_MARBERT Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 544 ar.embed.bert_base_arabic_camelbert_msa_eighth bert_embeddings_bert_base_arabic_camelbert_msa_eighth Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 545 ar.embed.MARBERTv2 bert_embeddings_MARBERTv2 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 546 ar.embed.bert_large_arabertv2 bert_embeddings_bert_large_arabertv2 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 547 ar.embed.bert_base_arabert bert_embeddings_bert_base_arabert Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 548 ar.embed.bert_base_arabertv01 bert_embeddings_bert_base_arabertv01 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 549 ar.embed.bert_mini_arabic bert_embeddings_bert_mini_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 550 ar.embed.bert_large_arabic bert_embeddings_bert_large_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 551 ar.embed.bert_large_arabertv02_twitter bert_embeddings_bert_large_arabertv02_twitter Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 552 ar.embed.dziribert bert_embeddings_dziribert Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 553 ar.embed.bert_base_arabertv02_twitter bert_embeddings_bert_base_arabertv02_twitter Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 554 ar.embed.bert_medium_arabic bert_embeddings_bert_medium_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 555 ar.pos.arabic_camelbert_da_pos_msa bert_pos_bert_base_arabic_camelbert_da_pos_msa Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 556 ar.embed.bert_base_qarib bert_embeddings_bert_base_qarib Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 557 ar.embed.bert_base_qarib60_860k bert_embeddings_bert_base_qarib60_860k Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 558 ar.embed.bert_base_qarib60_1790k bert_embeddings_bert_base_qarib60_1790k Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 559 ar.embed.bert_base_arabic_camelbert_msa_sixteenth bert_embeddings_bert_base_arabic_camelbert_msa_sixteenth Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 560 ar.embed.bert_base_arabic_camelbert_mix bert_embeddings_bert_base_arabic_camelbert_mix Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 561 ar.embed.bert_base_arabic_camelbert_msa_quarter bert_embeddings_bert_base_arabic_camelbert_msa_quarter Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 562 az.embed.w2v_cc_300d w2v_cc_300d Embeddings Azerbaijani WordEmbeddingsModel az aze aze Living Macrolanguage 563 az.stopwords stopwords_iso Stop Words Removal Azerbaijani StopWordsCleaner az aze aze Living Macrolanguage 564 zh.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_zh_cased Embeddings Chinese DistilBertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 565 zh.embed.wobert_chinese_plus_base bert_embeddings_wobert_chinese_plus_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 566 zh.embed.bert_base_chinese_jinyong bert_embeddings_bert_base_chinese_jinyong Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 567 zh.embed.rbt3 bert_embeddings_rbt3 Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 568 zh.embed.jdt_fin_roberta_wwm bert_embeddings_jdt_fin_roberta_wwm Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 569 zh.embed.mengzi_oscar_base bert_embeddings_mengzi_oscar_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 570 zh.embed.roberta_base_wechsel_chinese roberta_embeddings_roberta_base_wechsel_chinese Embeddings Chinese RoBertaEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 571 zh.embed.sikubert bert_embeddings_sikubert Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 572 zh.embed.jdt_fin_roberta_wwm_large bert_embeddings_jdt_fin_roberta_wwm_large Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 573 zh.embed.rbtl3 bert_embeddings_rbtl3 Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 574 zh.embed.macbert4csc_base_chinese bert_embeddings_macbert4csc_base_chinese Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 575 zh.pos.chinese_roberta_large_upos bert_pos_chinese_roberta_large_upos Part of Speech Tagging Chinese BertForTokenClassification zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 576 zh.pos.chinese_roberta_base_upos bert_pos_chinese_roberta_base_upos Part of Speech Tagging Chinese BertForTokenClassification zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 577 zh.pos.chinese_bert_wwm_ext_upos bert_pos_chinese_bert_wwm_ext_upos Part of Speech Tagging Chinese BertForTokenClassification zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 578 zh.pos pos_gsdsimp Part of Speech Tagging Chinese PerceptronModel zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 579 zh.pos pos_gsdsimp Part of Speech Tagging Chinese PerceptronModel zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 580 zh.stopwords stopwords_iso Stop Words Removal Chinese StopWordsCleaner zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 581 zh.pos.bert_base_chinese_pos bert_pos_bert_base_chinese_pos Part of Speech Tagging Chinese BertForTokenClassification zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 582 zh.embed.rbt6 bert_embeddings_rbt6 Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 583 zh.embed.sikuroberta bert_embeddings_sikuroberta Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 584 zh.embed.uer_large bert_embeddings_uer_large Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 585 zh.embed.env_bert_chinese bert_embeddings_env_bert_chinese Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 586 zh.embed.chinese_roberta_wwm_ext bert_embeddings_chinese_roberta_wwm_ext Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 587 zh.embed.chinese_macbert_base bert_embeddings_chinese_macbert_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 588 zh.embed.bert_base_zh_cased bert_embeddings_bert_base_zh_cased Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 589 zh.embed.bert_large_chinese bert_embeddings_bert_large_chinese Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 590 zh.embed.chinese_roberta_wwm_large_ext_fix_mlm bert_embeddings_chinese_roberta_wwm_large_ext_fix_mlm Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 591 zh.embed.chinese_roberta_wwm_ext_large bert_embeddings_chinese_roberta_wwm_ext_large Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 592 zh.embed.chinese_bert_wwm_ext bert_embeddings_chinese_bert_wwm_ext Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 593 zh.embed.chinese_macbert_large bert_embeddings_chinese_macbert_large Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 594 zh.embed.mengzi_oscar_base_retrieval bert_embeddings_mengzi_oscar_base_retrieval Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 595 zh.embed.mengzi_bert_base_fin bert_embeddings_mengzi_bert_base_fin Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 596 zh.embed.wobert_chinese_base bert_embeddings_wobert_chinese_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 597 zh.embed.wobert_chinese_plus bert_embeddings_wobert_chinese_plus Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 598 zh.embed.rbt4 bert_embeddings_rbt4 Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 599 zh.embed.mengzi_oscar_base_caption bert_embeddings_mengzi_oscar_base_caption Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 600 zh.embed.mengzi_bert_base bert_embeddings_mengzi_bert_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 601 zh.embed.w2v_cc_300d w2v_cc_300d Embeddings Chinese WordEmbeddingsModel zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 602 et.stopwords stopwords_iso Stop Words Removal Estonian StopWordsCleaner et est est Living Macrolanguage 603 et.pos pos_edt Part of Speech Tagging Estonian PerceptronModel et est est Living Macrolanguage 604 et.embed.w2v_cc_300d w2v_cc_300d Embeddings Estonian WordEmbeddingsModel et est est Living Macrolanguage 605 et.lemma lemma_ewt Lemmatization Estonian LemmatizerModel et est est Living Macrolanguage 606 et.lemma lemma_ewt Lemmatization Estonian LemmatizerModel et est est Living Macrolanguage 607 lv.stopwords stopwords_iso Stop Words Removal Latvian StopWordsCleaner lv lav lav Living Macrolanguage 608 lv.pos pos_lvtb Part of Speech Tagging Latvian PerceptronModel lv lav lav Living Macrolanguage 609 mg.embed.w2v_cc_300d w2v_cc_300d Embeddings Malagasy WordEmbeddingsModel mg mlg mlg Living Macrolanguage 610 ms.embed.albert albert_embeddings_albert_large_bahasa_cased Embeddings Malay (macrolanguage) AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 611 ms.embed.distilbert distilbert_embeddings_malaysian_distilbert_small Embeddings Malay (macrolanguage) DistilBertEmbeddings ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 612 ms.embed.albert_tiny_bahasa_cased albert_embeddings_albert_tiny_bahasa_cased Embeddings Malay (macrolanguage) AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 613 ms.embed.albert_base_bahasa_cased albert_embeddings_albert_base_bahasa_cased Embeddings Malay (macrolanguage) AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 614 ms.embed.w2v_cc_300d w2v_cc_300d Embeddings Malay (macrolanguage) WordEmbeddingsModel ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 615 mn.embed.w2v_cc_300d w2v_cc_300d Embeddings Mongolian WordEmbeddingsModel mn mon mon Living Macrolanguage 616 ne.embed.w2v_cc_300d w2v_cc_300d Embeddings Nepali (macrolanguage) WordEmbeddingsModel ne nep nep Living Macrolanguage 617 ne.stopwords stopwords_iso Stop Words Removal Nepali (macrolanguage) StopWordsCleaner ne nep nep Living Macrolanguage 618 no.lemma lemma_nynorsk Lemmatization Norwegian LemmatizerModel no nor nor Living Macrolanguage 619 no.pos pos_bokmaal Part of Speech Tagging Norwegian PerceptronModel no nor nor Living Macrolanguage 620 no.pos pos_bokmaal Part of Speech Tagging Norwegian PerceptronModel no nor nor Living Macrolanguage 621 no.pos pos_bokmaal Part of Speech Tagging Norwegian PerceptronModel no nor nor Living Macrolanguage 622 no.embed.w2v_cc_300d w2v_cc_300d Embeddings Norwegian WordEmbeddingsModel no nor nor Living Macrolanguage 623 no.lemma lemma_nynorsk Lemmatization Norwegian LemmatizerModel no nor nor Living Macrolanguage 624 or.embed.w2v_cc_300d w2v_cc_300d Embeddings Oriya (macrolanguage) WordEmbeddingsModel or ori ori Living Macrolanguage 625 ps.embed.w2v_cc_300d w2v_cc_300d Embeddings Pashto, Pushto WordEmbeddingsModel ps pus pus Living Macrolanguage 626 fa.embed.albert albert_embeddings_albert_fa_base_v2 Embeddings Persian AlbertEmbeddings fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 627 fa.embed.distilbert_fa_zwnj_base distilbert_embeddings_distilbert_fa_zwnj_base Embeddings Persian DistilBertEmbeddings fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 628 fa.embed.albert_fa_zwnj_base_v2 albert_embeddings_albert_fa_zwnj_base_v2 Embeddings Persian AlbertEmbeddings fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 629 fa.embed.roberta_fa_zwnj_base roberta_embeddings_roberta_fa_zwnj_base Embeddings Persian RoBertaEmbeddings fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 630 fa.ner.roberta_fa_zwnj_base_ner roberta_ner_roberta_fa_zwnj_base_ner Named Entity Recognition Persian RoBertaForTokenClassification fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 631 fa.pos pos_perdt Part of Speech Tagging Persian PerceptronModel fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 632 fa.stopwords stopwords_iso Stop Words Removal Persian StopWordsCleaner fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 633 qu.embed.w2v_cc_300d w2v_cc_300d Embeddings Quechua WordEmbeddingsModel qu que que Living Macrolanguage 634 sc.embed.w2v_cc_300d w2v_cc_300d Embeddings Sardinian WordEmbeddingsModel sc srd srd Living Macrolanguage 635 sh.embed.w2v_cc_300d w2v_cc_300d Embeddings Serbo-Croatian WordEmbeddingsModel sh nan nan Living Macrolanguage 636 sw.embed.w2v_cc_300d w2v_cc_300d Embeddings Swahili (macrolanguage) WordEmbeddingsModel sw swa swa Living Macrolanguage 637 uz.embed.w2v_cc_300d w2v_cc_300d Embeddings Uzbek WordEmbeddingsModel uz uzb uzb Living Macrolanguage 638 yi.embed.w2v_cc_300d w2v_cc_300d Embeddings Yiddish WordEmbeddingsModel yi yid yid Living Macrolanguage 639 qhe.lemma lemma_hiencs Lemmatization Reserved for local use LemmatizerModel nan qhe qhe nan Local 640 qtd.pos pos_sagt Part of Speech Tagging Reserved for local use PerceptronModel nan qtd qtd nan Local All Healthcare Powered by the amazing Spark NLP for Healthcare 3.5.2 and Spark NLP for Healthcare 3.5.1 releases. Number NLU Reference Spark NLP Reference Task Language Name(s) Annotator Class ISO-639-1 ISO-639-2/639-5 ISO-639-3 Language Type Scope 0 en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm Named Entity Recognition English MedicalNerModel en eng eng Living Individual 1 en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm Named Entity Recognition English MedicalNerModel en eng eng Living Individual 2 en.resolve.rxnorm_action_treatment sbiobertresolve_rxnorm_action_treatment Entity Resolution English SentenceEntityResolverModel en eng eng Living Individual 3 en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition English MedicalBertForTokenClassifier en eng eng Living Individual 4 en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition English MedicalBertForTokenClassifier en eng eng Living Individual 5 pt.med_ner.deid.subentity ner_deid_subentity De-identification Portuguese MedicalNerModel pt por por Living Individual 6 pt.med_ner.deid.generic ner_deid_generic De-identification Portuguese MedicalNerModel pt por por Living Individual 7 pt.med_ner.deid ner_deid_generic De-identification Portuguese MedicalNerModel pt por por Living Individual NLU Version 3.4.3 Zero-Shot-Relation-Extraction, DeBERTa for Sequence Classification, 150+ new models, 60+ Languages in John Snow Labs NLU 3.4.3 We are very excited to announce NLU 3.4.3 has been released! This release features new models for Zero-Shot-Relation-Extraction, DeBERTa for Sequence Classification, Deidentification in French and Italian and Lemmatizers, Parts of Speech Taggers, and Word2Vec Embeddings for over 66 languages, with 20 languages being covered for the first time by NLU, including ancient and exotic languages like Ancient Greek, Old Russian, Old French and much more. Once again we would like to thank our community to make this release possible. NLU for Healthcare On the healthcare NLP side, a new ZeroShotRelationExtractionModel is available, which can extract relations between clinical entities in an unsupervised fashion, no training required! Additionally, New French and Italian Deidentification models are available for clinical and healthcare domains. Powerd by the fantastic Spark NLP for helathcare 3.5.0 release Zero-Shot Relation Extraction Zero-shot Relation Extraction to extract relations between clinical entities with no training dataset import nlu pipe = nlu.load(&#39;med_ner.clinical relation.zeroshot_biobert&#39;) # Configure relations to extract pipe[&#39;zero_shot_relation_extraction&#39;].setRelationalCategories({ &quot;CURE&quot;: [&quot; cures .&quot;], &quot;IMPROVE&quot;: [&quot; improves .&quot;, &quot; cures .&quot;], &quot;REVEAL&quot;: [&quot; reveals .&quot;]}) .setMultiLabel(False) df = pipe.predict(&quot;Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer.&quot;) df[ &#39;relation&#39;, &#39;relation_confidence&#39;, &#39;relation_entity1&#39;, &#39;relation_entity1_class&#39;, &#39;relation_entity2&#39;, &#39;relation_entity2_class&#39;,] # Results in following table : relation relation_confidence relation_entity1 relation_entity1_class relation_entity2 relation_entity2_class REVEAL 0.976004 An MRI test TEST cancer PROBLEM IMPROVE 0.988195 Paracetamol TREATMENT sickness PROBLEM IMPROVE 0.992962 Paracetamol TREATMENT headache PROBLEM New Healthcare Models overview Language NLU Reference Spark NLP Reference Task Annotator Class en en.relation.zeroshot_biobert re_zeroshot_biobert Relation Extraction ZeroShotRelationExtractionModel fr fr.med_ner.deid_generic ner_deid_generic De-identification MedicalNerModel fr fr.med_ner.deid_subentity ner_deid_subentity De-identification MedicalNerModel it it.med_ner.deid_generic ner_deid_generic Named Entity Recognition MedicalNerModel it it.med_ner.deid_subentity ner_deid_subentity Named Entity Recognition MedicalNerModel NLU general On the general NLP side we have new transformer based DeBERTa v3 sequence classifiers models fine-tuned in Urdu, French and English for Sentiment and News classification. Additionally, 100+ Part Of Speech Taggers and Lemmatizers for 66 Languages and for 7 languages new word2vec embeddings, including hi,azb,bo,diq,cy,es,it, powered by the amazing Spark NLP 3.4.3 release New Languages covered: First time languages covered by NLU are : South Azerbaijani, Tibetan, Dimli, Central Kurdish, Southern Altai, Scottish Gaelic,Faroese,Literary Chinese,Ancient Greek, Gothic, Old Russian, Church Slavic, Old French,Uighur,Coptic,Croatian, Belarusian, Serbian and their respective ISO-639-3 and ISO 630-2 codes are : azb,bo,diq,ckb, lt gd, fo,lzh,grc,got,orv,cu,fro,qtd,ug,cop,hr,be,qhe,sr New NLP Models Overview Language NLU Reference Spark NLP Reference Task Annotator Class en en.classify.sentiment.imdb.deberta deberta_v3_xsmall_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification en en.classify.sentiment.imdb.deberta.small deberta_v3_small_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification en en.classify.sentiment.imdb.deberta.base deberta_v3_base_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification en en.classify.sentiment.imdb.deberta.large deberta_v3_large_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification en en.classify.news.deberta deberta_v3_xsmall_sequence_classifier_ag_news Text Classification DeBertaForSequenceClassification en en.classify.news.deberta.small deberta_v3_small_sequence_classifier_ag_news Text Classification DeBertaForSequenceClassification ur ur.classify.sentiment.imdb mdeberta_v3_base_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification fr fr.classify.allocine mdeberta_v3_base_sequence_classifier_allocine Text Classification DeBertaForSequenceClassification ur ur.embed.bert_cased bert_embeddings_bert_base_ur_cased Embeddings BertEmbeddings fr fr.embed.bert_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings BertEmbeddings de de.embed.medbert bert_embeddings_German_MedBERT Embeddings BertEmbeddings ar ar.embed.arbert bert_embeddings_ARBERT Embeddings BertEmbeddings bn bn.embed.bangala_bert bert_embeddings_bangla_bert_base Embeddings BertEmbeddings zh zh.embed.bert_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings BertEmbeddings hi hi.embed.bert_hi_cased bert_embeddings_bert_base_hi_cased Embeddings BertEmbeddings it it.embed.bert_it_cased bert_embeddings_bert_base_it_cased Embeddings BertEmbeddings ko ko.embed.bert bert_embeddings_bert_base Embeddings BertEmbeddings tr tr.embed.bert_cased bert_embeddings_bert_base_tr_cased Embeddings BertEmbeddings vi vi.embed.bert_cased bert_embeddings_bert_base_vi_cased Embeddings BertEmbeddings hif hif.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel azb azb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel bo bo.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel diq diq.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel cy cy.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel es es.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel it it.embed.word2vec w2v_cc_300d Embeddings WordEmbeddingsModel af af.lemma lemma Lemmatization LemmatizerModel lt lt.lemma lemma_alksnis Lemmatization LemmatizerModel nl nl.lemma lemma Lemmatization LemmatizerModel gd gd.lemma lemma_arcosg Lemmatization LemmatizerModel es es.lemma lemma Lemmatization LemmatizerModel ca ca.lemma lemma Lemmatization LemmatizerModel el el.lemma.gdt lemma_gdt Lemmatization LemmatizerModel en en.lemma.atis lemma_atis Lemmatization LemmatizerModel tr tr.lemma.boun lemma_boun Lemmatization LemmatizerModel da da.lemma.ddt lemma_ddt Lemmatization LemmatizerModel cs cs.lemma.cac lemma_cac Lemmatization LemmatizerModel en en.lemma.esl lemma_esl Lemmatization LemmatizerModel bg bg.lemma.btb lemma_btb Lemmatization LemmatizerModel id id.lemma.csui lemma_csui Lemmatization LemmatizerModel gl gl.lemma.ctg lemma_ctg Lemmatization LemmatizerModel cy cy.lemma.ccg lemma_ccg Lemmatization LemmatizerModel fo fo.lemma.farpahc lemma_farpahc Lemmatization LemmatizerModel tr tr.lemma.atis lemma_atis Lemmatization LemmatizerModel ga ga.lemma.idt lemma_idt Lemmatization LemmatizerModel ja ja.lemma.gsdluw lemma_gsdluw Lemmatization LemmatizerModel es es.lemma.gsd lemma_gsd Lemmatization LemmatizerModel en en.lemma.gum lemma_gum Lemmatization LemmatizerModel zh zh.lemma.gsd lemma_gsd Lemmatization LemmatizerModel lv lv.lemma.lvtb lemma_lvtb Lemmatization LemmatizerModel hi hi.lemma.hdtb lemma_hdtb Lemmatization LemmatizerModel pt pt.lemma.gsd lemma_gsd Lemmatization LemmatizerModel de de.lemma.gsd lemma_gsd Lemmatization LemmatizerModel nl nl.lemma.lassysmall lemma_lassysmall Lemmatization LemmatizerModel lzh lzh.lemma.kyoto lemma_kyoto Lemmatization LemmatizerModel zh zh.lemma.gsdsimp lemma_gsdsimp Lemmatization LemmatizerModel he he.lemma.htb lemma_htb Lemmatization LemmatizerModel fr fr.lemma.gsd lemma_gsd Lemmatization LemmatizerModel ro ro.lemma.nonstandard lemma_nonstandard Lemmatization LemmatizerModel ja ja.lemma.gsd lemma_gsd Lemmatization LemmatizerModel it it.lemma.isdt lemma_isdt Lemmatization LemmatizerModel de de.lemma.hdt lemma_hdt Lemmatization LemmatizerModel is is.lemma.modern lemma_modern Lemmatization LemmatizerModel la la.lemma.ittb lemma_ittb Lemmatization LemmatizerModel fr fr.lemma.partut lemma_partut Lemmatization LemmatizerModel pcm pcm.lemma.nsc lemma_nsc Lemmatization LemmatizerModel pl pl.lemma.pdb lemma_pdb Lemmatization LemmatizerModel grc grc.lemma.perseus lemma_perseus Lemmatization LemmatizerModel cs cs.lemma.pdt lemma_pdt Lemmatization LemmatizerModel fa fa.lemma.perdt lemma_perdt Lemmatization LemmatizerModel got got.lemma.proiel lemma_proiel Lemmatization LemmatizerModel fr fr.lemma.rhapsodie lemma_rhapsodie Lemmatization LemmatizerModel it it.lemma.partut lemma_partut Lemmatization LemmatizerModel en en.lemma.partut lemma_partut Lemmatization LemmatizerModel no no.lemma.nynorsklia lemma_nynorsklia Lemmatization LemmatizerModel orv orv.lemma.rnc lemma_rnc Lemmatization LemmatizerModel cu cu.lemma.proiel lemma_proiel Lemmatization LemmatizerModel la la.lemma.perseus lemma_perseus Lemmatization LemmatizerModel fr fr.lemma.parisstories lemma_parisstories Lemmatization LemmatizerModel fro fro.lemma.srcmf lemma_srcmf Lemmatization LemmatizerModel vi vi.lemma.vtb lemma_vtb Lemmatization LemmatizerModel qtd qtd.lemma.sagt lemma_sagt Lemmatization LemmatizerModel ro ro.lemma.rrt lemma_rrt Lemmatization LemmatizerModel hu hu.lemma.szeged lemma_szeged Lemmatization LemmatizerModel ug ug.lemma.udt lemma_udt Lemmatization LemmatizerModel wo wo.lemma.wtb lemma_wtb Lemmatization LemmatizerModel cop cop.lemma.scriptorium lemma_scriptorium Lemmatization LemmatizerModel ru ru.lemma.syntagrus lemma_syntagrus Lemmatization LemmatizerModel ru ru.lemma.taiga lemma_taiga Lemmatization LemmatizerModel fr fr.lemma.sequoia lemma_sequoia Lemmatization LemmatizerModel la la.lemma.udante lemma_udante Lemmatization LemmatizerModel ro ro.lemma.simonero lemma_simonero Lemmatization LemmatizerModel it it.lemma.vit lemma_vit Lemmatization LemmatizerModel hr hr.lemma.set lemma_set Lemmatization LemmatizerModel fa fa.lemma.seraji lemma_seraji Lemmatization LemmatizerModel tr tr.lemma.tourism lemma_tourism Lemmatization LemmatizerModel ta ta.lemma.ttb lemma_ttb Lemmatization LemmatizerModel sl sl.lemma.ssj lemma_ssj Lemmatization LemmatizerModel sv sv.lemma.talbanken lemma_talbanken Lemmatization LemmatizerModel uk uk.lemma.iu lemma_iu Lemmatization LemmatizerModel te te.pos pos_mtg Part of Speech Tagging PerceptronModel te te.pos pos_mtg Part of Speech Tagging PerceptronModel ta ta.pos pos_ttb Part of Speech Tagging PerceptronModel ta ta.pos pos_ttb Part of Speech Tagging PerceptronModel cs cs.pos pos_ud_pdt Part of Speech Tagging PerceptronModel cs cs.pos pos_ud_pdt Part of Speech Tagging PerceptronModel bg bg.pos pos_btb Part of Speech Tagging PerceptronModel bg bg.pos pos_btb Part of Speech Tagging PerceptronModel af af.pos pos_afribooms Part of Speech Tagging PerceptronModel af af.pos pos_afribooms Part of Speech Tagging PerceptronModel af af.pos pos_afribooms Part of Speech Tagging PerceptronModel es es.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel en en.pos.ewt pos_ewt Part of Speech Tagging PerceptronModel gd gd.pos.arcosg pos_arcosg Part of Speech Tagging PerceptronModel el el.pos.gdt pos_gdt Part of Speech Tagging PerceptronModel hy hy.pos.armtdp pos_armtdp Part of Speech Tagging PerceptronModel pt pt.pos.bosque pos_bosque Part of Speech Tagging PerceptronModel tr tr.pos.framenet pos_framenet Part of Speech Tagging PerceptronModel cs cs.pos.cltt pos_cltt Part of Speech Tagging PerceptronModel eu eu.pos.bdt pos_bdt Part of Speech Tagging PerceptronModel et et.pos.ewt pos_ewt Part of Speech Tagging PerceptronModel da da.pos.ddt pos_ddt Part of Speech Tagging PerceptronModel cy cy.pos.ccg pos_ccg Part of Speech Tagging PerceptronModel lt lt.pos.alksnis pos_alksnis Part of Speech Tagging PerceptronModel nl nl.pos.alpino pos_alpino Part of Speech Tagging PerceptronModel fi fi.pos.ftb pos_ftb Part of Speech Tagging PerceptronModel tr tr.pos.atis pos_atis Part of Speech Tagging PerceptronModel ca ca.pos.ancora pos_ancora Part of Speech Tagging PerceptronModel gl gl.pos.ctg pos_ctg Part of Speech Tagging PerceptronModel de de.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel fr fr.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel ja ja.pos.gsdluw pos_gsdluw Part of Speech Tagging PerceptronModel it it.pos.isdt pos_isdt Part of Speech Tagging PerceptronModel be be.pos.hse pos_hse Part of Speech Tagging PerceptronModel nl nl.pos.lassysmall pos_lassysmall Part of Speech Tagging PerceptronModel sv sv.pos.lines pos_lines Part of Speech Tagging PerceptronModel uk uk.pos.iu pos_iu Part of Speech Tagging PerceptronModel fr fr.pos.parisstories pos_parisstories Part of Speech Tagging PerceptronModel en en.pos.partut pos_partut Part of Speech Tagging PerceptronModel la la.pos.ittb pos_ittb Part of Speech Tagging PerceptronModel lzh lzh.pos.kyoto pos_kyoto Part of Speech Tagging PerceptronModel id id.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel he he.pos.htb pos_htb Part of Speech Tagging PerceptronModel tr tr.pos.kenet pos_kenet Part of Speech Tagging PerceptronModel de de.pos.hdt pos_hdt Part of Speech Tagging PerceptronModel qhe qhe.pos.hiencs pos_hiencs Part of Speech Tagging PerceptronModel la la.pos.llct pos_llct Part of Speech Tagging PerceptronModel en en.pos.lines pos_lines Part of Speech Tagging PerceptronModel pcm pcm.pos.nsc pos_nsc Part of Speech Tagging PerceptronModel ko ko.pos.kaist pos_kaist Part of Speech Tagging PerceptronModel pt pt.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel hi hi.pos.hdtb pos_hdtb Part of Speech Tagging PerceptronModel is is.pos.modern pos_modern Part of Speech Tagging PerceptronModel en en.pos.gum pos_gum Part of Speech Tagging PerceptronModel fro fro.pos.srcmf pos_srcmf Part of Speech Tagging PerceptronModel sl sl.pos.ssj pos_ssj Part of Speech Tagging PerceptronModel ru ru.pos.taiga pos_taiga Part of Speech Tagging PerceptronModel grc grc.pos.perseus pos_perseus Part of Speech Tagging PerceptronModel sr sr.pos.set pos_set Part of Speech Tagging PerceptronModel orv orv.pos.rnc pos_rnc Part of Speech Tagging PerceptronModel ug ug.pos.udt pos_udt Part of Speech Tagging PerceptronModel got got.pos.proiel pos_proiel Part of Speech Tagging PerceptronModel sv sv.pos.talbanken pos_talbanken Part of Speech Tagging PerceptronModel sv sv.pos.talbanken pos_talbanken Part of Speech Tagging PerceptronModel pl pl.pos.pdb pos_pdb Part of Speech Tagging PerceptronModel fa fa.pos.seraji pos_seraji Part of Speech Tagging PerceptronModel tr tr.pos.penn pos_penn Part of Speech Tagging PerceptronModel hu hu.pos.szeged pos_szeged Part of Speech Tagging PerceptronModel sk sk.pos.snk pos_snk Part of Speech Tagging PerceptronModel sk sk.pos.snk pos_snk Part of Speech Tagging PerceptronModel ro ro.pos.simonero pos_simonero Part of Speech Tagging PerceptronModel it it.pos.postwita pos_postwita Part of Speech Tagging PerceptronModel gl gl.pos.treegal pos_treegal Part of Speech Tagging PerceptronModel cs cs.pos.pdt pos_pdt Part of Speech Tagging PerceptronModel ro ro.pos.rrt pos_rrt Part of Speech Tagging PerceptronModel orv orv.pos.torot pos_torot Part of Speech Tagging PerceptronModel hr hr.pos.set pos_set Part of Speech Tagging PerceptronModel la la.pos.proiel pos_proiel Part of Speech Tagging PerceptronModel fr fr.pos.partut pos_partut Part of Speech Tagging PerceptronModel it it.pos.vit pos_vit Part of Speech Tagging PerceptronModel Bugfixes Improved Error Messages and integrated detection and stopping of endless loops which could occur during construction of nlu pipelines Additional NLU resources 140+ NLU Tutorials NLU in Action Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.4.2 Multilingual DeBERTa Transformer Embeddings for 100+ Languages, Spanish Deidentification and NER for Randomized Clinical Trials - John Snow Labs NLU 3.4.2 We are very excited NLU 3.4.2 has been released. On the open source side we have 5 new DeBERTa Transformer models for English and Multi-Lingual for 100+ languages. DeBERTa improves over BERT and RoBERTa by introducing two novel techniques. For the healthcare side we have new NER models for randomized clinical trials (RCT) which can detect entities of type BACKGROUND, CONCLUSIONS, METHODS, OBJECTIVE, RESULTS from clinical text. Additionally, new Spanish Deidentification NER models for entities like STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL and many more. New Open Source Models Integrates models from Spark NLP 3.4.2 release Language NLU Reference Spark NLP Reference Task Annotator Class en en.embed.deberta_v3_xsmall deberta_v3_xsmall Embeddings DeBertaEmbeddings en en.embed.deberta_v3_small deberta_v3_small Embeddings DeBertaEmbeddings en en.embed.deberta_v3_base deberta_v3_base Embeddings DeBertaEmbeddings en en.embed.deberta_v3_large deberta_v3_large Embeddings DeBertaEmbeddings xx xx.embed.mdeberta_v3_base mdeberta_v3_base Embeddings DeBertaEmbeddings New Healthcare Models Integrates models from Spark NLP For Healthcare 3.4.2 release Language NLU Reference Spark NLP Reference Task Annotator Class en en.med_ner.clinical_trials bert_sequence_classifier_rct_biobert Text Classification MedicalBertForSequenceClassification es es.med_ner.deid.generic.roberta ner_deid_generic_roberta_augmented De-identification MedicalNerModel es es.med_ner.deid.subentity.roberta ner_deid_subentity_roberta_augmented De-identification MedicalNerModel en en.med_ner.deid.generic_augmented ner_deid_generic_augmented [‘Named Entity Recognition’, ‘De-identification’] MedicalNerModel en en.med_ner.deid.subentity_augmented ner_deid_subentity_augmented [‘Named Entity Recognition’, ‘De-identification’] MedicalNerModel Additional NLU resources 140+ NLU Tutorials NLU in Action Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.4.1 22 New models for 23 languages including various African and Indian languages, Medical Spanish models and more in NLU 3.4.1 We are very excited to announce the release of NLU 3.4.1 which features 22 new models for 23 languages where the The open-source side covers new Embeddings for Vietnamese and English Clinical domains and Multilingual Embeddings for 12 Indian and 9 African Languages. Additionally, there are new Sequence classifiers for Multilingual NER for 9 African languages, German Sentiment Classifiers and English Emotion and Typo Classifiers. The healthcare side covers Medical Spanish models, Classifiers for Drugs, Gender, the Pico Framework, and Relation Extractors for Adverse Drug events and Temporality. Finally, Spark 3.2.X is now supported and bugs related to Databricks environments have been fixed. General NLU Improvements Support for Spark 3.2.x New Open Source Models Based on the amazing 3.4.1 Spark NLP Release integrates new Multilingual embeddings for 12 Major Indian languages, embeddings for Vietnamese, French, and English Clinical domains. Additionally new Multilingual NER model for 9 African languages, English 6 Class Emotion classifier and Typo detectors. New Embeddings Multilingual ALBERT - IndicBert model pretrained exclusively on 12 major Indian languages with size smaller and performance on par or better than competing models. Languages covered are Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu. Available with xx.embed.albert.indic Fine tuned Vietnamese DistilBERT Base cased embeddings. Available with vi.embed.distilbert.cased Clinical Longformer Embeddings which consistently out-performs ClinicalBERT for various downstream tasks and on datasets. Available with en.embed.longformer.clinical Fine tuned Static French Word2Vec Embeddings in 3 sizes, 200d, 300d and 100d. Available with fr.embed.word2vec_wiki_1000, fr.embed.word2vec_wac_200 and fr.embed.w2v_cc_300d New Transformer based Token and Sequence Classifiers Multilingual NER Distilbert model which detects entities DATE, LOC, ORG, PER for the languages 9 African languages (Hausa, Igbo, Kinyarwanda, Luganda, Nigerian, Pidgin, Swahili, Wolof, and Yorùbá). Available with xx.ner.masakhaner.distilbert German News Sentiment Classifier available with de.classify.news_sentiment.bert English Emotion Classifier for 6 Classes available with en.classify.emotion.bert **English Typo Detector **: available with en.classify.typos.distilbert Language NLU Reference Spark NLP Reference Task Annotator Class xx xx.embed.albert.indic albert_indic Embeddings AlbertEmbeddings xx xx.ner.masakhaner.distilbert xlm_roberta_large_token_classifier_masakhaner Named Entity Recognition DistilBertForTokenClassification en en.embed.longformer.clinical clinical_longformer Embeddings LongformerEmbeddings en en.classify.emotion.bert bert_sequence_classifier_emotion Text Classification BertForSequenceClassification de de.classify.news_sentiment.bert bert_sequence_classifier_news_sentiment Sentiment Analysis BertForSequenceClassification en en.classify.typos.distilbert distilbert_token_classifier_typo_detector Named Entity Recognition DistilBertForTokenClassification fr fr.embed.word2vec_wiki_1000 word2vec_wiki_1000 Embeddings WordEmbeddingsModel fr fr.embed.word2vec_wac_200 word2vec_wac_200 Embeddings WordEmbeddingsModel fr fr.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel vi vi.embed.distilbert.cased distilbert_base_cased Embeddings DistilBertEmbeddings New Healthcare Models Integrated from the amazing 3.4.1 Spark NLP For Healthcare Release. which makes 2 new Annotator Classes available, MedicalBertForSequenceClassification and MedicalDistilBertForSequenceClassification, various medical Spanish models, RxNorm Resolvers, Transformer based sequence classifiers for Drugs, Gender and the PICO framework, and Relation extractors for Temporality and Causality of Drugs and Adverse Events. New Medical Spanish Models Spanish Word2Vec Embeddings available with es.embed.sciwiki_300d Spanish PHI Deidentification NER models with two different subsets of entities extracted, available with ner_deid_generic and ner_deid_subentity New Resolvers RxNorm resolvers with augmented concept data available with en.med_ner.supplement_clinical New Transformer based Sequence Classifiers Adverse Drug Event Classifier Biobert based available with en.classify.ade.seq_biobert Patient Gender Classifier Biobert and Distilbert based available with en.classify.gender.seq_biobert and available with en.classify.ade.seq_distilbert PiCO Framework Classifier available with en.classify.pico.seq_biobert New Relation Extractors Temporal Relation Extractor available with en.relation.temporal_events_clinical Adverse Drug Event Relation Extractors one version Biobert Embeddings and one non-DL version available with en.relation.adverse_drug_events.clinical available with en.relation.adverse_drug_events.clinical.biobert Language NLU Reference Spark NLP Reference Task Annotator Class es es.embed.sciwiki_300d embeddings_sciwiki_300d Embeddings WordEmbeddingsModel es es.med_ner.deid.generic ner_deid_generic De-identification MedicalNerModel es es.med_ner.deid.subentity ner_deid_subentity De-identification MedicalNerModel en en.med_ner.supplement_clinical ner_supplement_clinical Named Entity Recognition MedicalNerModel en en.resolve.rxnorm.augmented_re sbiobertresolve_rxnorm_augmented_re Entity Resolution SentenceEntityResolverModel en en.classify.ade.seq_biobert bert_sequence_classifier_ade Text Classification MedicalBertForSequenceClassification en en.classify.gender.seq_biobert bert_sequence_classifier_gender_biobert Text Classification MedicalBertForSequenceClassification en en.classify.pico.seq_biobert bert_sequence_classifier_pico_biobert Text Classification MedicalBertForSequenceClassification en en.classify.ade.seq_distilbert distilbert_sequence_classifier_ade Text Classification MedicalDistilBertForSequenceClassification en en.relation.temporal_events_clinical re_temporal_events_clinical Relation Extraction RelationExtractionModel en en.relation.adverse_drug_events.clinical re_ade_clinical Relation Extraction RelationExtractionModel en en.relation.adverse_drug_events.clinical.biobert redl_ade_biobert Relation Extraction RelationExtractionDLModel Bugfixes Fixed bug that caused non-default output level of components to be sentence Fixed a bug that caused nlu references pointing to pretrained pipelines in spark nlp to crash in Databricks environments Additional NLU resources 140+ NLU Tutorials NLU in Action Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.4.0 1 line to OCR for images, PDFS and DOCX, Text Generation with GPT2 and new T5 models, Sequence Classification with XlmRoBerta, RoBerta, Xlnet, Longformer and Albert, Transformer based medical NER with MedicalBertForTokenClassifier, 80 new models, 20+ new languages including various African and Scandinavian and much more in John Snow Labs NLU 3.4.0 ! We are incredibly excited to announce John Snow Labs NLU 3.4.0 has been released! This release features 11 new annotator classes and 80 new models, including 3 OCR Transformers which enable you to extract text from various file types, support for GPT2 and new pretrained T5 models for Text Generation and dozens more of new transformer based models for Token and Sequence Classification. This includes 8 new Sequence classifier models which can be pretrained in Huggingface and imported into Spark NLP and NLU. Finally, the NLU tutorial page of the 140+ notebooks has been updated New NLU OCR Features 3 new OCR based spells are supported, which enable extracting text from files of type JPEG, PNG, BMP, WBMP, GIF, JPG, TIFF, DOCX, PDF in just 1 line of code. You need a Spark OCR license for using these, which is available for free here and refer to the new OCR tutorial notebook Find more details on the NLU OCR documentation page New NLU Healthcare Features The healthcare side features a new MedicalBertForTokenClassifier annotator which is a Bert based model for token classification problems like Named Entity Recognition, Parts of Speech and much more. Overall there are 28 new models which include German De-Identification models, English NER models for extracting Drug Development Trials, Clinical Abbreviations and Acronyms, NER models for chemical compounds/drugs and genes/proteins, updated MedicalBertForTokenClassifier NER models for the medical domains Adverse drug Events, Anatomy, Chemicals, Genes,Proteins, Cellular/Molecular Biology, Drugs, Bacteria, De-Identification and general Medical and Clinical Named Entities. For Entity Relation Extraction between entity pairs new models for interaction between Drugs and Proteins. For Entity Resolution new models for resolving Clinical Abbreviations and Acronyms to their full length names and also a model for resolving Drug Substance Entities to the categories Clinical Drug, Pharmacologic Substance, Antibiotic, Hazardous or Poisonous Substance and new resolvers for LOINC and SNOMED terminologies. New NLU Open source Features On the open source side we have new support for Open Ai’s GPT2 for various text sequence to sequence problems and additionally the following new Transformer models are supported : RoBertaForSequenceClassification, XlmRoBertaForSequenceClassification, LongformerForSequenceClassification, AlbertForSequenceClassification, XlnetForSequenceClassification, Word2Vec with various pre-trained weights for various problems! New GPT2 models for generating text conditioned on some input, New T5 style transfer models for active to passive, formal to informal, informal to formal, passive to active sequence to sequence generation. Additionally, a new T5 model for generating SQL code from natural language input is provided. On top of this dozens new Transformer based Sequence Classifiers and Token Classifiers have been released, this is includes for Token Classifier the following models : Multi-Lingual general NER models for 10 African Languages (Amharic, Hausa, Igbo, Kinyarwanda, Luganda, Nigerian, Pidgin, Swahilu, Wolof, and Yorùbá), 10 high resourced languages (10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese), 6 Scandinavian languages (Danish, Norwegian-Bokmål, Norwegian-Nynorsk, Swedish, Icelandic, Faroese) , Uni-Lingual NER models for general entites in the language Chinese, Hindi, Islandic, Indonesian and finally English NER models for extracting entities related to Stocks Ticker Symbols, Restaurants, Time. For Sequence Classification new models for classifying Toxicity in Russian text and English models for Movie Reviews, News Categorization, Sentimental Tone and General Sentiment New NLU OCR Models The following Transformers have been integrated from Spark OCR NLU Spell Transformer Class nlu.load(img2text) ImageToText nlu.load(pdf2text) PdfToText nlu.load(doc2text) DocToText New Open Source Models Integration for the 49 new models from the colossal Spark NLP 3.4.0 release Language NLU Reference Spark NLP Reference Task Annotator Class en en.gpt2.distilled gpt2_distilled Text Generation GPT2Transformer en en.gpt2 gpt2 Text Generation GPT2Transformer en en.gpt2.medium gpt2_medium Text Generation GPT2Transformer en en.gpt2.large gpt_large Text Generation GPT2Transformer en en.t5.active_to_passive_styletransfer t5_active_to_passive_styletransfer Text Generation T5Transformer en en.t5.formal_to_informal_styletransfer t5_formal_to_informal_styletransfer Text Generation T5Transformer en en.t5.grammar_error_corrector t5_grammar_error_corrector Text Generation T5Transformer en en.t5.informal_to_formal_styletransfer t5_informal_to_formal_styletransfer Text Generation T5Transformer en en.t5.passive_to_active_styletransfer t5_passive_to_active_styletransfer Text Generation T5Transformer en en.t5.wikiSQL t5_small_wikiSQL Text Generation T5Transformer xx xx.ner.masakhaner xlm_roberta_large_token_classifier_masakhaner Named Entity Recognition XlmRoBertaForTokenClassification xx xx.ner.high_resourced_lang xlm_roberta_large_token_classifier_hrl Named Entity Recognition XlmRoBertaForTokenClassification xx xx.ner.scandinavian bert_token_classifier_scandi_ner Named Entity Recognition BertForTokenClassification en en.embed.electra.medical electra_medal_acronym Embeddings BertEmbeddings en en.ner.restaurant nerdl_restaurant_100d Named Entity Recognition NerDLModel en en.embed.word2vec.gigaword_wiki word2vec_gigaword_wiki_300 Embeddings Word2VecModel en en.embed.word2vec.gigaword word2vec_gigaword_300 Embeddings Word2VecModel en en.classify.xlm_roberta.imdb xlm_roberta_base_sequence_classifier_imdb Text Classification XlmRoBertaForSequenceClassification en en.classify.xlm_roberta.ag_news xlm_roberta_base_sequence_classifier_ag_news Text Classification XlmRoBertaForSequenceClassification en en.classify.roberta.imdb roberta_base_sequence_classifier_imdb Text Classification RoBertaForSequenceClassification en en.classify.roberta.ag_news roberta_base_sequence_classifier_ag_news Text Classification RoBertaForSequenceClassification en en.classify.albert.ag_news albert_base_sequence_classifier_ag_news Text Classification AlbertForSequenceClassification en en.classify.albert.imdb albert_base_sequence_classifier_imdb Text Classification AlbertForSequenceClassification en en.classify.ag_news.longformer longformer_base_sequence_classifier_ag_news Text Classification LongformerForSequenceClassification en en.classify.imdb.xlnet xlnet_base_sequence_classifier_imdb Text Classification XlnetForSequenceClassification en en.classify.finance_sentiment bert_sequence_classifier_finbert_tone Sentiment Analysis BertForSequenceClassification en en.classify.imdb.longformer longformer_base_sequence_classifier_imdb Text Classification LongformerForSequenceClassification en en.classify.ag_news.longformer longformer_base_sequence_classifier_ag_news Text Classification LongformerForSequenceClassification en en.ner.time roberta_token_classifier_timex_semeval Named Entity Recognition RoBertaForTokenClassification en en.ner.stocks_ticker roberta_token_classifier_ticker Named Entity Recognition RoBertaForTokenClassification ru ru.classify.toxic bert_sequence_classifier_toxicity Text Classification BertForSequenceClassification it it.classify.sentiment bert_sequence_classifier_sentiment Sentiment Analysis BertForSequenceClassification es es.ner wikiner_6B_100 Named Entity Recognition NerDLModel is is.ner roberta_token_classifier_icelandic_ner Named Entity Recognition RoBertaForTokenClassification id id.pos roberta_token_classifier_pos_tagger Part of Speech Tagging RoBertaForTokenClassification tr tr.ner turkish_ner_840B_300 Named Entity Recognition NerDLModel de de.ner xlm_roberta_large_token_classifier_conll03 Named Entity Recognition XlmRoBertaForTokenClassification hi hi.ner bert_token_classifier_hi_en_ner Named Entity Recognition BertForTokenClassification nl nl.ner wikiner_6B_100 Named Entity Recognition NerDLModel zh zh.ner bert_token_classifier_chinese_ner Named Entity Recognition BertForTokenClassification fr fr.classify.xlm_roberta.allocine xlm_roberta_base_sequence_classifier_allocine Text Classification XlmRoBertaForSequenceClassification ur ur.classify.fakenews classifierdl_urduvec_fakenews Text Classification ClassifierDLModel ur ur.classify.news classifierdl_bert_news Text Classification ClassifierDLModel fi fi.embed_sentence.bert.uncased bert_base_finnish_uncased Embeddings BertSentenceEmbeddings fi fi.embed_sentence.bert bert_base_finnish_uncased Embeddings BertSentenceEmbeddings fi fi.embed_sentence.bert.cased bert_base_finnish_cased Embeddings BertSentenceEmbeddings te te.embed.distilbert distilbert_uncased Embeddings DistilBertEmbeddings sw sw.embed.xlm_roberta xlm_roberta_base_finetuned_swahili Embeddings XlmRoBertaEmbeddings New Healthcare Models Integration for the 28 new models from the amazing Spark NLP for healthcare 3.4.0 release Language NLU Reference Spark NLP Reference Task Annotator Class en en.med_ner.chemprot.bert bert_token_classifier_ner_chemprot Named Entity Recognition MedicalBertForTokenClassifier en en.med_ner.chemprot.bert bert_token_classifier_ner_chemprot Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_bacteria bert_token_classifier_ner_bacteria Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_bacteria bert_token_classifier_ner_bacteria Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_anatomy bert_token_classifier_ner_anatomy Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_anatomy bert_token_classifier_ner_anatomy Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_drugs bert_token_classifier_ner_drugs Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_drugs bert_token_classifier_ner_drugs Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl_slim bert_token_classifier_ner_jsl_slim Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl_slim bert_token_classifier_ner_jsl_slim Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_deid bert_token_classifier_ner_deid Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_deid bert_token_classifier_ner_deid Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_clinical bert_token_classifier_ner_clinical Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_clinical bert_token_classifier_ner_clinical Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl bert_token_classifier_ner_jsl Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl bert_token_classifier_ner_jsl Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl bert_token_classifier_ner_jsl Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_chemical bert_token_classifier_ner_chemicals Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_chemical bert_token_classifier_ner_chemicals Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.bionlp bert_token_classifier_ner_bionlp Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.bionlp bert_token_classifier_ner_bionlp Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.cellular bert_token_classifier_ner_cellular Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.cellular bert_token_classifier_ner_cellular Named Entity Recognition MedicalBertForTokenClassifier en en.med_ner.abbreviation_clinical ner_abbreviation_clinical Named Entity Recognition MedicalNerModel en en.med_ner.drugprot_clinical ner_drugprot_clinical Named Entity Recognition MedicalNerModel en en.ner.drug_development_trials bert_token_classifier_drug_development_trials Named Entity Recognition BertForTokenClassification en en.med_ner.chemprot ner_chemprot_biobert Named Entity Recognition MedicalNerModel en en.relation.drugprot redl_drugprot_biobert Relation Extraction RelationExtractionDLModel en en.relation.drugprot.clinical re_drugprot_clinical Relation Extraction RelationExtractionModel en en.resolve.clinical_abbreviation_acronym sbiobertresolve_clinical_abbreviation_acronym Entity Resolution SentenceEntityResolverModel en en.resolve.clinical_abbreviation_acronym sbiobertresolve_clinical_abbreviation_acronym Entity Resolution SentenceEntityResolverModel en en.resolve.umls_drug_substance sbiobertresolve_umls_drug_substance Entity Resolution SentenceEntityResolverModel en en.resolve.loinc_cased sbiobertresolve_loinc_cased Entity Resolution SentenceEntityResolverModel en en.resolve.loinc_uncased sbluebertresolve_loinc_uncased Entity Resolution SentenceEntityResolverModel en en.embed_sentence.biobert.rxnorm sbiobert_jsl_rxnorm_cased Entity Resolution BertSentenceEmbeddings en en.embed_sentence.bert_uncased.rxnorm sbert_jsl_medium_rxnorm_uncased Embeddings BertSentenceEmbeddings en en.embed_sentence.bert_uncased.rxnorm sbert_jsl_medium_rxnorm_uncased Embeddings BertSentenceEmbeddings en en.resolve.snomed_drug sbiobertresolve_snomed_drug Entity Resolution SentenceEntityResolverModel de de.med_ner.deid_subentity ner_deid_subentity Named Entity Recognition MedicalNerModel de de.med_ner.deid_generic ner_deid_generic Named Entity Recognition MedicalNerModel de de.embed.w2v w2v_cc_300d Embeddings WordEmbeddingsModel Additional NLU resources NLU OCR tutorial notebook 140+ NLU Tutorials NLU in Action Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.3.1 48 new Transformer based models in 9 new languages, including NER for Finance, Industry, Politcal Policies, COVID and Chemical Trials, various clinical and medical domains in Spanish and English and much more in NLU 3.3.1 We are incredibly excited to announce NLU 3.3.1 has been released with 48 new models in 9 languages! It comes with 2 new types of state-of-the-art models,distilBERT and BERT for sequence classification with various pre-trained weights, state-of-the-art bert based classifiers for problems in the domains of Finance, Sentiment Classification, Industry, News, and much more. On the healthcare side, NLU features 22 new models in for English and Spanish with with entity Resolver Models for LOINC, MeSH, NDC and SNOMED and UMLS Diseases, NER models for Biomarkers, NIHSS-Guidelines, COVID Trials , Chemical Trials, Bert based Token Classifier models for biological, genetical,cancer, cellular terms, Bert for Sequence Classification models for clinical question vs statement classification and finally Spanish Clinical NER and Resolver Models Once again, we would like to thank our community for making another amazing release possible! New Open Source Models and Features Integrates the amazing Spark NLP 3.3.3 and 3.3.2 releases, featuring: New state-of-the-art fine-tuned BERT models for Sequence Classification in English, French, German, Spanish, Japanese, Turkish, Russian, and multilingual languages. DistilBertForSequenceClassification models in English, French and Urdu Word2Vec models. classify.distilbert_sequence.banking77 : Banking NER model trained on BANKING77 dataset, which provides a very fine-grained set of intents in a banking domain. It comprises 13,083 customer service queries labeled with 77 intents. It focuses on fine-grained single-domain intent detection. Can extract entities like activate_my_card, age_limit, apple_pay_or_google_pay, atm_support, automatic_top_up, balance_not_updated_after_bank_transfer, balance_not_updated_after_cheque_or_cash_deposit, beneficiary_not_allowed, cancel_transfer, card_about_to_expire, card_acceptance, card_arrival, card_delivery_estimate, card_linking, card_not_working, card_payment_fee_charged, card_payment_not_recognised, card_payment_wrong_exchange_rate, card_swallowed, cash_withdrawal_charge, cash_withdrawal_not_recognised, change_pin, compromised_card, contactless_not_working, country_support, declined_card_payment, declined_cash_withdrawal, declined_transfer, direct_debit_payment_not_recognised, disposable_card_limits, edit_personal_details, exchange_charge, exchange_rate, exchange_via_app, extra_charge_on_statement, failed_transfer, fiat_currency_support, get_disposable_virtual_card, get_physical_card, getting_spare_card, getting_virtual_card, lost_or_stolen_card, lost_or_stolen_phone, order_physical_card, passcode_forgotten, pending_card_payment, pending_cash_withdrawal, pending_top_up, pending_transfer, pin_blocked, receiving_money, classify.distilbert_sequence.industry : Industry NER model which can extract entities like Advertising, Aerospace &amp; Defense, Apparel Retail, Apparel, Accessories &amp; Luxury Goods, Application Software, Asset Management &amp; Custody Banks, Auto Parts &amp; Equipment, Biotechnology, Building Products, Casinos &amp; Gaming, Commodity Chemicals, Communications Equipment, Construction &amp; Engineering, Construction Machinery &amp; Heavy Trucks, Consumer Finance, Data Processing &amp; Outsourced Services, Diversified Metals &amp; Mining, Diversified Support Services, Electric Utilities, Electrical Components &amp; Equipment, Electronic Equipment &amp; Instruments, Environmental &amp; Facilities Services, Gold, Health Care Equipment, Health Care Facilities, Health Care Services. xx.classify.bert_sequence.sentiment : Multi-Lingual Sentiment Classifier This a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5). This model is intended for direct use as a sentiment analysis model for product reviews in any of the six languages above, or for further finetuning on related sentiment analysis tasks. distilbert_sequence.policy : Policy Classifier This model was trained on 129.669 manually annotated sentences to classify text into one of seven political categories: ‘Economy’, ‘External Relations’, ‘Fabric of Society’, ‘Freedom and Democracy’, ‘Political System’, ‘Welfare and Quality of Life’ or ‘Social Groups’. classify.bert_sequence.dehatebert_mono : Hate Speech Classifier This model was trained on 129.669 manually annotated sentences to classify text into one of seven political categories: ‘Economy’, ‘External Relations’, ‘Fabric of Society’, ‘Freedom and Democracy’, ‘Political System’, ‘Welfare and Quality of Life’ or ‘Social Groups’. Complete List of Open Source Models : | Language | NLU Reference | Spark NLP Reference | Task | |:———–|:——————————————————————————————————————————————————-|:————————————————————————————————————————————————————-|:——————–| | en | en.classify.bert_sequence.imdb_large | bert_large_sequence_classifier_imdb | Text Classification | | en | en.classify.bert_sequence.imdb | bert_base_sequence_classifier_imdb | Text Classification | | en | en.classify.bert_sequence.ag_news | bert_base_sequence_classifier_ag_news | Text Classification | | en | en.classify.bert_sequence.dbpedia_14 | bert_base_sequence_classifier_dbpedia_14 | Text Classification | | en | en.classify.bert_sequence.finbert | bert_sequence_classifier_finbert | Text Classification | | en | en.classify.bert_sequence.dehatebert_mono | bert_sequence_classifier_dehatebert_mono | Text Classification | | tr | tr.classify.bert_sequence.sentiment | bert_sequence_classifier_turkish_sentiment | Text Classification | | de | de.classify.bert_sequence.sentiment | bert_sequence_classifier_sentiment | Text Classification | | ru | ru.classify.bert_sequence.sentiment | bert_sequence_classifier_rubert_sentiment | Text Classification | | ja | ja.classify.bert_sequence.sentiment | bert_sequence_classifier_japanese_sentiment | Text Classification | | es | es.classify.bert_sequence.sentiment | bert_sequence_classifier_beto_sentiment_analysis | Text Classification | | es | es.classify.bert_sequence.emotion | bert_sequence_classifier_beto_emotion_analysis | Text Classification | | xx | xx.classify.bert_sequence.sentiment | bert_sequence_classifier_multilingual_sentiment | Text Classification | | en | en.classify.distilbert_sequence.sst2 | distilbert_sequence_classifier_sst2 | Text Classification | | en | en.classify.distilbert_sequence.policy | distilbert_sequence_classifier_policy | Text Classification | | en | en.classify.distilbert_sequence.industry | distilbert_sequence_classifier_industry | Text Classification | | en | en.classify.distilbert_sequence.emotion | distilbert_sequence_classifier_emotion | Text Classification | | en | en.classify.distilbert_sequence.banking77 | distilbert_sequence_classifier_banking77 | Text Classification | | en | en.classify.distilbert_sequence.imdb | distilbert_base_sequence_classifier_imdb | Text Classification | | en | en.classify.distilbert_sequence.amazon_polarity | distilbert_base_sequence_classifier_amazon_polarity | Text Classification | | en | en.classify.distilbert_sequence.ag_news | distilbert_base_sequence_classifier_ag_news | Text Classification | | fr | fr.classify.distilbert_sequence.allocine | distilbert_multilingual_sequence_classifier_allocine | Text Classification | | ur | ur.classify.distilbert_sequence.imdb | distilbert_base_sequence_classifier_imdb | Text Classification | | en | en.embed_sentence.doc2vec | doc2vec_gigaword_300 | Embeddings | | en | en.embed_sentence.doc2vec.gigaword_300 | doc2vec_gigaword_300 | Embeddings | | en | en.embed_sentence.doc2vec.gigaword_wiki_300 | doc2vec_gigaword_wiki_300 | Embeddings | New Healthcare models and Features Integrates the incredible Spark NLP for Healthcare releases 3.3.4, 3.3.2 and 3.3.1, featuring: New Clinical NER Models for protected health information(PHI), ner_biomarker for extracting extract biomarkers, therapies, oncological, and other general concepts Oncogenes, Tumor_Finding, UnspecificTherapy, Ethnicity, Age, ResponseToTreatment, Biomarker, HormonalTherapy, Staging, Drug, CancerDx, Radiotherapy, CancerSurgery, TargetedTherapy, PerformanceStatus, CancerModifier, Radiological_Test_Result, Biomarker_Measurement, Metastasis, Radiological_Test, Chemotherapy, Test, Dosage, Test_Result, Immunotherapy, Date, Gender, Prognostic_Biomarkers, Duration, Predictive_Biomarkers ner_nihss : NER model that can identify entities according to NIHSS guidelines for clinical stroke assessment to evaluate neurological status in acute stroke patients 11_ExtinctionInattention, 6b_RightLeg, 1c_LOCCommands, 10_Dysarthria, NIHSS, 5_Motor, 8_Sensory, 4_FacialPalsy, 6_Motor, 2_BestGaze, Measurement, 6a_LeftLeg, 5b_RightArm, 5a_LeftArm, 1b_LOCQuestions, 3_Visual, 9_BestLanguage, 7_LimbAtaxia, 1a_LOC . redl_nihss_biobert : relation extraction model that can relate scale items and their measurements according to NIHSS guidelines. es.med_ner.roberta_ner_diag_proc : New Spanish Clinical NER Models for extracting the entities DIAGNOSTICO, PROCEDIMIENTO es.resolve.snomed: New Spanish SNOMED Entity Resolvers bert_sequence_classifier_question_statement_clinical:New Clinical Question vs Statement for BertForSequenceClassification model med_ner.covid_trials : This model is trained to extract covid-specific medical entities in clinical trials. It supports the following entities ranging from virus type to trial design: Stage, Severity, Virus, Trial_Design, Trial_Phase, N_Patients, Institution, Statistical_Indicator, Section_Header, Cell_Type, Cellular_component, Viral_components, Physiological_reaction, Biological_molecules, Admission_Discharge, Age, BMI, Cerebrovascular_Disease, Date, Death_Entity, Diabetes, Disease_Syndrome_Disorder, Dosage, Drug_Ingredient, Employment, Frequency, Gender, Heart_Disease, Hypertension, Obesity, Pulse, Race_Ethnicity, Respiration, Route, Smoking, Time, Total_Cholesterol, Treatment, VS_Finding, Vaccine . med_ner.chemd : This model extract the names of chemical compounds and drugs in medical texts. The entities that can be detected are as follows : SYSTEMATIC, IDENTIFIERS, FORMULA, TRIVIAL, ABBREVIATION, FAMILY, MULTIPLE . For reference click here . https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4331685/ bert_token_classifier_ner_bionlp : This model is BERT-based version of ner_bionlp model and can detect biological and genetics terms in cancer-related texts. (Amino_acid, Anatomical_system, Cancer, Cell, Cellular_component, Developing_anatomical_Structure, Gene_or_gene_product, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism, Organism_subdivision, Simple_chemical, Tissue bert_token_classifier_ner_cellular : This model is BERT-based version of ner_cellular model and can detect molecular biology-related terms (DNA, Cell_type, Cell_line, RNA, Protein) in medical texts. We have updated med_ner.jsl.enriched model by enriching the training data using clinical trials data to make it more robust. This model is capable of predicting up to 87 different entities and is based on ner_jsl model. Here are the entities this model can detect; Social_History_Header, Oncology_Therapy, Blood_Pressure, Respiration, Performance_Status, Family_History_Header, Dosage, Clinical_Dept, Diet, Procedure, HDL, Weight, Admission_Discharge, LDL, Kidney_Disease, Oncological, Route, Imaging_Technique, Puerperium, Overweight, Temperature, Diabetes, Vaccine, Age, Test_Result, Employment, Time, Obesity, EKG_Findings, Pregnancy, Communicable_Disease, BMI, Strength, Tumor_Finding, Section_Header, RelativeDate, ImagingFindings, Death_Entity, Date, Cerebrovascular_Disease, Treatment, Labour_Delivery, Pregnancy_Delivery_Puerperium, Direction, Internal_organ_or_component, Psychological_Condition, Form, Medical_Device, Test, Symptom, Disease_Syndrome_Disorder, Staging, Birth_Entity, Hyperlipidemia, O2_Saturation, Frequency, External_body_part_or_region, Drug_Ingredient, Vital_Signs_Header, Substance_Quantity, Race_Ethnicity, VS_Finding, Injury_or_Poisoning, Medical_History_Header, Alcohol, Triglycerides, Total_Cholesterol, Sexually_Active_or_Sexual_Orientation, Female_Reproductive_Status, Relationship_Status, Drug_BrandName, RelativeTime, Duration, Hypertension, Metastasis, Gender, Oxygen_Therapy, Pulse, Heart_Disease, Modifier, Allergen, Smoking, Substance, Cancer_Modifier, Fetus_NewBorn, Height classify.bert_sequence.question_statement_clinical : This model classifies sentences into one of these two classes: question (interrogative sentence) or statement (declarative sentence) and trained with BertForSequenceClassification. This model is at first trained on SQuAD and SPAADIA dataset and then fine tuned on the clinical visit documents and MIMIC-III dataset annotated in-house. Using this model, you can find the question statements and exclude &amp; utilize in the downstream tasks such as NER and relation extraction models. classify.token_bert.ner_chemical : This model is BERT-based version of ner_chemicals model and can detect chemical compounds (CHEM) in the medical texts. resolve.umls_disease_syndrome : This model is trained on the Disease or Syndrome category using sbiobert_base_cased_mli embeddings. Complete List of Healthcare Models : Language NLU Reference Spark NLP Reference Task en en.med_ner.deid_subentity_augmented_i2b2 ner_deid_subentity_augmented_i2b2 Named Entity Recognition en en.med_ner.biomarker ner_biomarker Named Entity Recognition en en.med_ner.nihss ner_nihss Named Entity Recognition en en.extract_relation.nihss redl_nihss_biobert Relation Extraction en en.resolve.mesh sbiobertresolve_mesh Entity Resolution en en.resolve.mli sbiobert_base_cased_mli Embeddings en en.resolve.ndc sbiobertresolve_ndc Entity Resolution en en.resolve.loinc.augmented sbiobertresolve_loinc_augmented Entity Resolution en en.resolve.clinical_snomed_procedures_measurements sbiobertresolve_clinical_snomed_procedures_measurements Entity Resolution es es.embed.roberta_base_biomedical roberta_base_biomedical Embeddings es es.med_ner.roberta_ner_diag_proc roberta_ner_diag_proc Named Entity Recognition es es.resolve.snomed robertaresolve_snomed Entity Resolution en en.med_ner.covid_trials ner_covid_trials Named Entity Recognition en en.classify.token_bert.bionlp bert_token_classifier_ner_bionlp Named Entity Recognition en en.classify.token_bert.cellular bert_token_classifier_ner_cellular Named Entity Recognition en en.classify.token_bert.chemicals bert_token_classifier_ner_chemicals Named Entity Recognition en en.resolve.rxnorm_augmented sbiobertresolve_rxnorm_augmented Entity Resolution en en.resolve.rxnorm_augmented sbiobertresolve_rxnorm_augmented Entity Resolution en en.resolve.rxnorm_augmented sbiobertresolve_rxnorm_augmented Entity Resolution en en.resolve.umls_disease_syndrome sbiobertresolve_umls_disease_syndrome Entity Resolution en en.resolve.umls_clinical_drugs sbiobertresolve_umls_clinical_drugs Entity Resolution en en.classify.bert_sequence.question_statement_clinical bert_sequence_classifier_question_statement_clinical Text Classification NLU Version 3.3.0 2000%+ Speedup on small data, 63 new models for 100+ Languages with 6 new supported Transformer classes including BERT, XLM-RoBERTa, alBERT, Longformer, XLnet based models, 48 NER profiling helathcare pipelines and much more in John Snow Labs NLU 3.3.0 We are incredibly excited to announce NLU 3.3.0 has been released! It comes with a up to 2000%+ speedup on small datasets, 6 new Types of Deep Learning transformer models, including RoBertaForTokenClassification,XlmRoBertaForTokenClassification,AlbertForTokenClassification,LongformerForTokenClassification,XlnetForTokenClassification,XlmRoBertaSentenceEmbeddings. In total there are 63 NLP Models 6 New Languages Supported which are Igbo, Ganda, Dholuo, Naija, Wolof,Kinyarwanda with their corresponding ISO codes ig, lg, lou, pcm, wo,rw with New SOTA XLM-RoBERTa models in Luganda, Kinyarwanda, Igbo, Hausa, and Amharic languages and 2 new Multilingual Embeddings with 100+ supported languages via XLM-Roberta are available. On the healthcare NLP side we are glad to announce 18 new NLP for Healthcare models including NER Profiling pretrained pipelines to run 48 different Clinical NER and 21 Different Biobert Models At Once Over the Input Text New BERT-Based Deidentification NER Model, Sentence Entity Resolver Models For German Language New Spell Checker Model For Drugs , 3 New Sentence Entity Resolver Models (3-char ICD10CM, RxNorm_NDC, HCPCS) 5 New Clinical NER Models (Trained By BertForTokenClassification Approach) ,Radiology NER Model Trained On cheXpert Datasetand New UMLS Sentence Entity Resolver Models Additionally 2 new tutorials are avaiable, NLU &amp; Streamlit Crashcourse and NLU for Healthcare Crashcourse of every of the 50 + healthcare Domains and 200+ healthcare models New Features and Improvements 2000%+ Speedup prediction for small datasets NLU pipelines now predict up to 2000% faster by optimizing integration with Spark NLP’s light pipelines. NLU will configure usage of this automatically, but it can be turned off as well via multithread=False 50x faster saving of NLU Pipelines Up to 50x faster saving Spark NLP/ NLU models and pipelines! We have improved the way we package TensorFlow SavedModel while saving Spark NLP models &amp; pipelines. For instance, it used to take up to 10 minutes to save the xlm_roberta_base model before Spark NLP 3.3.0, and now it only takes up to 15 seconds! New Annotator Classes Integrated The following new transformer classes are available with various pretrained weights in 1 line of code : RoBertaForTokenClassification XlmRoBertaForTokenClassification AlbertForTokenClassification LongformerForTokenClassification XlnetForTokenClassification XlmRoBertaSentenceEmbeddings New Transformer Models The following models are available from the amazing Spark NLP 3.3.0 and 3.3.1 releases which includes NLP models for Yiddish, Ukrainian, Telugu, Tamil, Somali, Sindhi, Russian, Punjabi, Nepali, Marathi, Malayalam, Kannada, Indonesian, Gujrati, Bosnian, Igbo, Ganda, Dholuo, Naija, Wolof,Kinyarwanda Language NLU Reference Spark NLP Reference Task   ig ig.embed.xlm_roberta xlm_roberta_base_finetuned_igbo Embeddings   ig ig.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_igbo Embeddings   lg lg.embed.xlm_roberta xlm_roberta_base_finetuned_luganda Embeddings   lg lg.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_luganda Embeddings   wo wo.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_wolof Embeddings   wo wo.embed.xlm_roberta xlm_roberta_base_finetuned_wolof Embeddings   rw rw.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_kinyarwanda Embeddings   rw rw.embed.xlm_roberta xlm_roberta_base_finetuned_kinyarwanda Embeddings   sw sw.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_swahili Embeddings   sw sw.embed.xlm_roberta xlm_roberta_base_finetuned_swahili Embeddings   ha ha.embed.xlm_roberta xlm_roberta_base_finetuned_hausa Embeddings   ha ha.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_hausa Embeddings   am am.embed.xlm_roberta xlm_roberta_base_finetuned_amharic Embeddings   am am.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_amharic Embeddings   yo yo.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_yoruba Embeddings   yo yo.embed.xlm_roberta xlm_roberta_base_finetuned_yoruba Embeddings   fa fa.classify.token_roberta_token_classifier_zwnj_base_ner roberta_token_classifier_zwnj_base_ner Named Entity Recognition   yi detect_sentence sentence_detector_dl Sentence Detection   uk detect_sentence sentence_detector_dl Sentence Detection   te detect_sentence sentence_detector_dl Sentence Detection   ta detect_sentence sentence_detector_dl Sentence Detection   so detect_sentence sentence_detector_dl Sentence Detection   sd detect_sentence sentence_detector_dl Sentence Detection   ru detect_sentence sentence_detector_dl Sentence Detection   pa detect_sentence sentence_detector_dl Sentence Detection   ne detect_sentence sentence_detector_dl Sentence Detection   mr detect_sentence sentence_detector_dl Sentence Detection   ml detect_sentence sentence_detector_dl Sentence Detection   kn detect_sentence sentence_detector_dl Sentence Detection   id detect_sentence sentence_detector_dl Sentence Detection   gu detect_sentence sentence_detector_dl Sentence Detection   bs detect_sentence sentence_detector_dl Sentence Detection   en en.classify.token_roberta_large_token_classifier_conll03 roberta_large_token_classifier_conll03 Named Entity Recognition   en en.classify.token_roberta_base_token_classifier_ontonotes roberta_base_token_classifier_ontonotes Named Entity Recognition   en en.classify.token_roberta_base_token_classifier_conll03 roberta_base_token_classifier_conll03 Named Entity Recognition   en en.classify.token_distilroberta_base_token_classifier_ontonotes distilroberta_base_token_classifier_ontonotes Named Entity Recognition   en en.classify.token_albert_large_token_classifier_conll03 albert_large_token_classifier_conll03 Named Entity Recognition   en en.classify.token_albert_base_token_classifier_conll03 albert_base_token_classifier_conll03 Named Entity Recognition   en en.classify.token_xlnet_base_token_classifier_conll03 xlnet_base_token_classifier_conll03 Named Entity Recognition   en en.classify.token_roberta.large_token_classifier_ontonotes roberta_large_token_classifier_ontonotes Named Entity Recognition   en en.classify.token_albert.xlarge_token_classifier_conll03 albert_xlarge_token_classifier_conll03 Named Entity Recognition   en en.classify.token_xlnet.large_token_classifier_conll03 xlnet_large_token_classifier_conll03 Named Entity Recognition   en en.classify.token_longformer.base_token_classifier_conll03 longformer_base_token_classifier_conll03 Named Entity Recognition   xx xx.classify.token_xlm_roberta.token_classifier_ner_40_lang xlm_roberta_token_classifier_ner_40_lang Named Entity Recognition   xx xx.embed.xlm_roberta_large xlm_roberta_large Embeddings   New Healthcare models The following models are available from the amazing Spark NLP for Healthcare releases 3.3.0, 3.2.3, 3.3.1, which includes 48 Multi-NER tuning pipelines, BERT-based DEidentification, German NER resolvers, Spell Checkers for Drugs, 5 ner NER models trained via BErtForTokenClassification, NER models for Radiology CID10CM, RxNORM NDC and HCPCSS models and UMLS sentence resolver models Language NLU Reference Spark NLP Reference Task de de.resolve.snomed sbertresolve_snomed Entity Resolution de de.resolve.icd10gm sbertresolve_icd10gm Entity Resolution en en.med_ner.profiling_clinical ner_profiling_clinical Pipeline Healthcare en en.med_ner.profiling_biobert ner_profiling_biobert Pipeline Healthcare en en.med_ner.chexpert ner_chexpert Named Entity Recognition en en.classify.token_bert.ner_bacteria bert_token_classifier_ner_bacteria Named Entity Recognition en en.classify.token_bert.ner_anatomy bert_token_classifier_ner_anatomy Named Entity Recognition en en.classify.token_bert.ner_drugs bert_token_classifier_ner_drugs Named Entity Recognition en en.classify.token_bert.ner_jsl_slim bert_token_classifier_ner_jsl_slim Named Entity Recognition en en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition en en.resolve.rxnorm_ndc sbiobertresolve_rxnorm_ndc Entity Resolution en en.resolve.icd10cm_generalised sbiobertresolve_icd10cm_generalised Entity Resolution en en.resolve.hcpcs sbiobertresolve_hcpcs Entity Resolution en en.spell.drug_norvig spellcheck_drug_norvig Spell Check en en.classify.token_bert.ner_deid bert_token_classifier_ner_deid Named Entity Recognition en en.classify.token_bert.ner_chemical bert_token_classifier_ner_chemicals Named Entity Recognition en en.resolve.umls_disease_syndrome sbiobertresolve_umls_disease_syndrome Entity Resolution en en.resolve.umls_clinical_drugs sbiobertresolve_umls_clinical_drugs Entity Resolution Updated Model Names The nlu model references have been updated to better reflect their use-cases. en.classify.token_bert.conll03 en.classify.token_bert.large_conll03 en.classify.token_bert.ontonote en.classify.token_bert.large_ontonote en.classify.token_bert.few_nerd en.classify.token_bert.classifier_ner_btc es.classify.token_bert.spanish_ner ja.classify.token_bert.classifier_ner_ud_gsd fa.classify.token_bert.parsbert_armanner fa.classify.token_bert.parsbert_ner fa.classify.token_bert.parsbert_peymaner sv.classify.token_bert.swedish_ner tr.classify.token_bert.turkish_ner en.classify.token_bert.ner_clinical en.classify.token_bert.ner_jsl New Tutorial Videos NLU &amp; Streamlit Crashcourse NLU for Healthcare Crashcourse of every of the 50 + healthcare Domains and 200+ healthcare models Optional get_embeddings parameter for pipelines NLU pipelines can now be forced to not return embeddings via get_embeddings parameter. Updated Compatibility Docs Added documentation section regarding compatibility of NLU, Spark NLP and Spark NLP for healthcare Bugfixes Fixed a bug with Pyspark versions 3.0 and below that caused failure of predicting with pipeline Fixed a bug that caused the results of TokenClassifier Models to not be properly extracted Additional NLU ressources 140+ NLU Tutorials Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.2.1 27 new models in 7 Languages, including Japanese NER, resolution models for SNOMED, ICDO, CPT and RxNorm codes and much more in NLU 3.2.1 We are very excited to announce NLU 3.2.1! This release comes with models 27 new models for 7 languages which are transformer based. New NER-Classifiers, BertSentenceEmbeddings, BertEmbeddings and BertForTokenClassificationEmbeddings for Japanese, German, Dutch, Swedish, Spanish, French and English. For healthcare there are new Entity Resolvers and MedicalNerModels for Snomed Conditions, Cpt Measurements, Icd0, Rxnorm Dispositions, Posology and Deidentification. Finally, a new tutorial notebook and a webinar are available, which showcase almost every feature of NLU for the over 50 Domains in Healthcare/Clinical/Biomedical/etc.. New Transformer Models Models in Japanese, German, Dutch, Swedish, Spanish, French and English from the great Spark NLP 3.2.3 release nlu.load() Refrence Spark NLP Refrence Annotater class Language en.embed.bert.base_uncased_legal bert_base_uncased_legal BertEmbeddings en en.embed_sentence.bert.base_uncased_legal sent_bert_base_uncased_legal BertSentenceEmbeddings en en.embed.token_bert.classifier_ner_btc bert_token_classifier_ner_btc BertForTokenClassification en es.embed.bert.base_uncased bert_base_uncased BertEmbeddings es es.embed.bert.base_cased bert_base_cased BertEmbeddings es es.embed_sentence.bert.base_uncased sent_bert_base_uncased BertSentenceEmbeddings es es.embed_sentence.bert.base_cased sent_bert_base_cased BertSentenceEmbeddings es el.embed.bert.base_uncased bert_base_uncased BertEmbeddings el el.embed_sentence.bert.base_uncased sent_bert_base_uncased BertSentenceEmbeddings el sv.embed.bert.base_cased bert_base_cased BertEmbeddings sv sv.embed_sentence.bert.base_cased sent_bert_base_cased BertSentenceEmbeddings sv nl.embed_sentence.bert.base_cased sent_bert_base_cased BertSentenceEmbeddings nl nl.embed.bert.base_cased bert_base_cased BertEmbeddings nl fr.classify.sentiment.bert classifierdl_bert_sentiment ClassifierDLModel fr ja.embed.glove.cc_300d japanese_cc_300d WordEmbeddingsModel ja ja.ner.ud_gsd_cc_300d ner_ud_gsd_cc_300d NerDLModel ja ja.ner.ud_gsd_xlm_roberta_base ner_ud_gsd_xlm_roberta_base NerDLModel ja ja.embed.token_bert.classifier_ner_ud_gsd bert_token_classifier_ner_ud_gsd BertForTokenClassification ja de.embed_sentence.bert.base_cased sent_bert_base_cased BertSentenceEmbeddings de de.classify.sentiment.bert classifierdl_bert_sentiment ClassifierDLModel de New Healthcare Transformer Models Models for Snomed Conditions, Cpt Measurements, Icd0, Rxnorm Dispositions, Posology and Deidentification from the amazing Spark NLP 3.2.2 for Healthcare Release nlu.load() Refrences Spark NLP Refrence Annotater class Language en.resolve.snomed_conditions sbertresolve_snomed_conditions SentenceEntityResolverModel en en.resolve.cpt.procedures_measurements sbiobertresolve_cpt_procedures_measurements_augmented SentenceEntityResolverModel en en.resolve.icdo.base sbiobertresolve_icdo_base SentenceEntityResolverModel en en.resolve.rxnorm.disposition.sbert sbertresolve_rxnorm_disposition SentenceEntityResolverModel en en.resolve.rxnorm_disposition.sbert sbertresolve_rxnorm_disposition SentenceEntityResolverModel en en.med_ner.posology.experimental ner_posology_experimental MedicalNerModel en en.med_ner.deid.subentity_augmented ner_deid_subentity_augmented MedicalNerModel en New Notebooks NLU Healthcare Overview and Crashcourse Enhancements Columns of the Pandas DataFrame returned by NLU will now be sorted alphabetically Bugfixes Fixed a bug that caused output levels no beeing inferred properly Fixed a bug that caused SentenceResolver visualizations not to appear. NLU Version 3.2.0 100+ Transformers Models in 40+ languages, 3-D Streamlit Entity-Embedding-Manifold visualizations, Multi-Lingual NER, Longformers, TokenDistilBERT, Trainable Sentence Resolvers, 7% less memory usage and much more in NLU 3.2.0 We are extremely excited to announce the release of NLU 3.2.0 which marks the 1-year anniversary of the birth of this magical library. This release packs features and improvements in every division of NLU’s aspects, 89 new NLP models with new Models including Longformer, TokenBert, TokenDistilBert and Multi-Lingual NER for 40+ Languages. 12 new Healthcare models with trainable sentence resolvers and models Adverse Drug Relations, Clinical Token Bert Models, NER Models for Radiology, Drugs, Posology, Administration Cycles, RXNorm, and new Medical Assertion models. New Streamlit visualizations enable you to see Entities in 3-D, 2-D, and 1-D Manifolds which are applicable to Entities and their Embeddings, Detected by Named-Entity-Recognizer models. Finally, a ~7% decrease in Memory consumption in NLU’s core which benefits every computation, achieved by leveraging Pyarrow. We are incredibly thankful to our community, which helped us come this far, and are looking forward to another magical year of NLU! Streamlit Entity Manifold visualization function pipe.viz_streamlit_entity_embed_manifold Visualize recognized entities by NER models via their Entity Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 10+ Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms. You can pick additional NER models and compare them via the GUI dropdown on the left. Reduces Dimensionality of high dimensional Entity Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 330+ Named Entity Recognizer models Gemerates NUM-DIMENSIONS * NUM-NER-MODELS * NUM-DIMENSION-REDUCTION-ALGOS plots nlu.load(&#39;ner&#39;).viz_streamlit_sentence_embed_manifold([&#39;Hello From John Snow Labs&#39;, &#39;Peter loves to visit New York&#39;]) or just run streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/09_entity_embedding_manifolds.py function parameters pipe.viz_streamlit_sentence_embed_manifold | Argument | Type | Default |Description | |—————————-|————|———————————————————–|———————————————————| |default_texts| List[str] |”Donald Trump likes to visit New York”, “Angela Merkel likes to visit Berlin!”, ‘Peter hates visiting Paris’)| List of strings to apply classifiers, embeddings, and manifolds to. | | title | str | &#39;NLU ❤️ Streamlit - Prototype your NLP startup in 0 lines of code🚀&#39; | Title of the Streamlit app |sub_title| Optional[str] | “Apply any of the 10+ Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Entity Embeddings to 1-D, 2-D and 3-D “ | Sub title of the Streamlit app | |default_algos_to_apply| List[str] | [&quot;TSNE&quot;, &quot;PCA&quot;] | A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;, | |target_dimensions| List[int] | (1,2,3) | Defines the target dimension embeddings will be reduced to | |show_algo_select| bool | True | Show selector for Manifold and Matrix Decomposition Algorithms | | set_wide_layout_CSS | bool | True | Whether to inject custom CSS or not.| |num_cols | int | 2 | How many columns should for the layout in streamlit when rendering the similarity matrixes.| | key | str | &quot;NLU_streamlit&quot; | Key for the Streamlit elements drawn | | show_logo | bool | True | Show logo | | display_infos | bool | False | Display additonal information about ISO codes and the NLU namespace structure.| | n_jobs | Optional[int] | 3| False | How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. | Sentence Entity Resolver Training Sentence Entity Resolver Training Tutorial Notebook Named Entities are sub pieces in textual data which are labeled with classes. These classes and strings are still ambiguous though and it is not possible to group semantically identically entities without any definition of terminology. With the Sentence Resolver you can train a state-of-the-art deep learning architecture to map entities to their unique terminological representation. Train a Sentence resolver on a dataset with columns named y , _y and text. y is a label, _y is an extra identifier label, text is the raw text import pandas as pd import nlu dataset = pd.DataFrame({ &#39;text&#39;: [&#39;The Tesla company is good to invest is&#39;, &#39;TSLA is good to invest&#39;,&#39;TESLA INC. we should buy&#39;,&#39;PUT ALL MONEY IN TSLA inc!!&#39;], &#39;y&#39;: [&#39;23&#39;,&#39;23&#39;,&#39;23&#39;,&#39;23&#39;], &#39;_y&#39;: [&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;], }) trainable_pipe = nlu.load(&#39;train.resolve_sentence&#39;) fitted_pipe = trainable_pipe.fit(dataset) res = fitted_pipe.predict(dataset) fitted_pipe.predict([&quot;Peter told me to buy Tesla &quot;, &#39;I have money to loose, is TSLA a good option?&#39;])   sentence_resolution_resolve_sentence_confidence sentence_resolution_resolve_sentence_code sentence_resolution_resolve_sentence sentence 0 ‘1.0000’ ‘23’ ‘TESLA’ ‘The Tesla company is good to invest is’ 1 ‘1.0000’ ‘23’ ‘TESLA’ ‘TSLA is good to invest’ 2 ‘1.0000’ ‘23’ ‘TESLA’ ‘TESLA INC. we should buy’ 3 ‘1.0000’ ‘23’ ‘TESLA’ ‘PUT ALL MONEY IN TSLA inc!!’ Alternatively you can also use non-default healthcare embeddings. trainable_pipe = nlu.load(&#39;en.embed.glove.biovec train.resolve_sentence&#39;) Transformer Models New models from the spectacular Spark NLP 3.2.0 + releases are integrated. 89 new models in total, with new LongFormer, TokenBert, TokenDistilBert and Multi-Lingual NER for 40+ languages. The supported languages with their ISO 639-1 code are : af, ar, bg, bn, de, el, en, es, et, eu, fa, fi, fr, he, hi, hu, id, it, ja, jv, ka, kk, ko, ml, mr, ms, my, nl, pt, ru, sw, ta, te, th, tl, tr, ur, vi, yo, and zh nlu.load() Refrence Spark NLP Refrence Annotator Class language en.embed.longformer longformer_base_4096 LongformerEmbeddings en en.embed.longformer.large longformer_large_4096 LongformerEmbeddings en en.ner.ontonotes_roberta_base ner_ontonotes_roberta_base NerDLModel en en.ner.ontonotes_roberta_large ner_ontonotes_roberta_large NerDLModel en en.ner.ontonotes_distilbert_base_cased ner_ontonotes_distilbert_base_cased NerDLModel en en.ner.conll_bert_base_cased ner_conll_bert_base_cased NerDLModel en en.ner.conll_distilbert_base_cased ner_conll_distilbert_base_cased NerDLModel en en.ner.conll_roberta_base ner_conll_roberta_base NerDLModel en en.ner.conll_roberta_large ner_conll_roberta_large NerDLModel en en.ner.conll_xlm_roberta_base ner_conll_xlm_roberta_base NerDLModel en en.ner.conll_longformer_large_4096 ner_conll_longformer_large_4096 NerDLModel en en.embed.token_bert.conll03 bert_base_token_classifier_conll03 NerDLModel en en.embed.token_bert.large_conll03 bert_large_token_classifier_conll03 NerDLModel en en.embed.token_bert.ontonote bert_base_token_classifier_ontonote NerDLModel en en.embed.token_bert.large_ontonote bert_large_token_classifier_ontonote NerDLModel en en.embed.token_bert.few_nerd bert_base_token_classifier_few_nerd NerDLModel en fa.embed.token_bert.parsbert_armanner bert_token_classifier_parsbert_armanner NerDLModel fa fa.embed.token_bert.parsbert_ner bert_token_classifier_parsbert_ner NerDLModel fa fa.embed.token_bert.parsbert_peymaner bert_token_classifier_parsbert_peymaner NerDLModel fa tr.embed.token_bert.turkish_ner bert_token_classifier_turkish_ner NerDLModel tr es.embed.token_bert.spanish_ner bert_token_classifier_spanish_ner NerDLModel es sv.embed.token_bert.swedish_ner bert_token_classifier_swedish_ner NerDLModel sv en.ner.fewnerd nerdl_fewnerd_100d NerDLModel en en.ner.fewnerd_subentity nerdl_fewnerd_subentity_100d NerDLModel en en.ner.movie ner_mit_movie_complex_bert_base_cased NerDLModel en en.ner.movie_complex ner_mit_movie_complex_bert_base_cased NerDLModel en en.ner.movie_simple ner_mit_movie_complex_bert_base_cased NerDLModel en en.ner.mit_movie_complex_bert ner_mit_movie_complex_bert_base_cased NerDLModel en en.ner.mit_movie_complex_distilbert ner_mit_movie_complex_distilbert_base_cased NerDLModel en en.ner.mit_movie_simple ner_mit_movie_simple_distilbert_base_cased NerDLModel en en.embed_sentence.bert_use_cmlm_en_base sent_bert_use_cmlm_en_base BertSentenceEmbeddings en en.embed_sentence.bert_use_cmlm_en_large sent_bert_use_cmlm_en_large BertSentenceEmbeddings en xx.ner.xtreme_glove_840B_300 ner_xtreme_glove_840B_300 NerDLModel xx xx.ner.xtreme_xlm_roberta_xtreme_base ner_xtreme_xlm_roberta_xtreme_base NerDLModel xx xx.ner.wikiner_glove_840B_300 ner_wikiner_glove_840B_300 NerDLModel xx xx.ner.wikiner_xlm_roberta_base ner_wikiner_xlm_roberta_base NerDLModel xx xx.embed_sentence.bert_use_cmlm_multi_base_br sent_bert_use_cmlm_multi_base_br BertSentenceEmbeddings xx xx.embed_sentence.bert_use_cmlm_multi_base sent_bert_use_cmlm_multi_base BertSentenceEmbeddings xx xx.embed.xlm_roberta_xtreme_base xlm_roberta_xtreme_base XlmRoBertaEmbeddings xx xx.embed.bert_base_multilingual_cased bert_base_multilingual_cased Embeddings xx xx.embed.bert_base_multilingual_uncased bert_base_multilingual_uncased Embeddings xx xx.af.translate_to.ru opus_tatoeba_af_ru Translation xx xx.he.translate_to.fr opus_tatoeba_he_fr Translation xx xx.it.translate_to.he opus_tatoeba_it_he Translation xx xx.cs.translate_to.sv opus_mt_cs_sv Translation xx tr.classify.cyberbullying classifierdl_berturk_cyberbullying Pipelines tr zh.embed.xlnet chinese_xlnet_base Embeddings zh de.classify.news classifierdl_bert_news Pipelines de tr.classify.berturk_cyberbullying classifierdl_berturk_cyberbullying_pipeline Pipelines tr de.classify.bert_news classifierdl_bert_news_pipeline Pipelines de en.classify.electra_questionpair classifierdl_electra_questionpair_pipeline Pipelines en tr.classify.bert_news classifierdl_bert_news_pipeline Pipelines tr en.ner.conll_elmo ner_conll_elmo NerDLModel en en.ner.conll_albert_base_uncased ner_conll_albert_base_uncased NerDLModel en en.ner.conll_albert_large_uncased ner_conll_albert_large_uncased NerDLModel en en.ner.conll_xlnet_base_cased ner_conll_xlnet_base_cased NerDLModel en xx.embed.bert.muril bert_muril BertEmbeddings xx en.embed.bert.wiki_books_sst2 bert_wiki_books_sst2 BertEmbeddings en en.embed.bert.wiki_books_squad2 bert_wiki_books_squad2 BertEmbeddings en en.embed.bert.wiki_books_qqp bert_wiki_books_qqp BertEmbeddings en en.embed.bert.wiki_books_qnli bert_wiki_books_qnli BertEmbeddings en en.embed.bert.wiki_books_mnli bert_wiki_books_mnli BertEmbeddings en en.embed.bert.wiki_books bert_wiki_books BertEmbeddings en en.embed.bert.pubmed_squad2 bert_pubmed_squad2 BertEmbeddings en en.embed.bert.pubmed bert_pubmed BertEmbeddings en en.embed_sentence.bert.wiki_books_sst2 sent_bert_wiki_books_sst2 BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books_squad2 sent_bert_wiki_books_squad2 BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books_qqp sent_bert_wiki_books_qqp BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books_qnli sent_bert_wiki_books_qnli BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books_mnli sent_bert_wiki_books_mnli BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books sent_bert_wiki_books BertSentenceEmbeddings en en.embed_sentence.bert.pubmed_squad2 sent_bert_pubmed_squad2 BertSentenceEmbeddings en en.embed_sentence.bert.pubmed sent_bert_pubmed BertSentenceEmbeddings en xx.embed_sentence.bert.muril sent_bert_muril BertSentenceEmbeddings xx yi.detect_sentence sentence_detector_dl SentenceDetectorDLModel yi uk.detect_sentence sentence_detector_dl SentenceDetectorDLModel uk te.detect_sentence sentence_detector_dl SentenceDetectorDLModel te ta.detect_sentence sentence_detector_dl SentenceDetectorDLModel ta so.detect_sentence sentence_detector_dl SentenceDetectorDLModel so sd.detect_sentence sentence_detector_dl SentenceDetectorDLModel sd ru.detect_sentence sentence_detector_dl SentenceDetectorDLModel ru pa.detect_sentence sentence_detector_dl SentenceDetectorDLModel pa ne.detect_sentence sentence_detector_dl SentenceDetectorDLModel ne mr.detect_sentence sentence_detector_dl SentenceDetectorDLModel mr ml.detect_sentence sentence_detector_dl SentenceDetectorDLModel ml kn.detect_sentence sentence_detector_dl SentenceDetectorDLModel kn bs.detect_sentence sentence_detector_dl SentenceDetectorDLModel bs id.detect_sentence sentence_detector_dl SentenceDetectorDLModel id gu.detect_sentence sentence_detector_dl SentenceDetectorDLModel gu New Healthcare Transformer Models 12 new models from the amazing Spark NLP for Healthcare 3.2.0+ releases, including models for genetic variants, radiology, assertion, rxnorm, adverse drugs and new clinical tokenbert models that improves accuracy by 4% compared to the previous models. nlu.load() Refrence Spark NLP Refrence Annotator Class en.med_ner.radiology.wip_greedy_biobert jsl_rd_ner_wip_greedy_biobert MedicalNerModel en.med_ner.genetic_variants ner_genetic_variants MedicalNerModel en.med_ner.jsl_slim ner_jsl_slim MedicalNerModel en.med_ner.jsl_greedy_biobert ner_jsl_greedy_biobert MedicalNerModel en.embed.token_bert.ner_clinical bert_token_classifier_ner_clinical MedicalNerModel en.embed.token_bert.ner_jsl bert_token_classifier_ner_jsl MedicalNerModel en.relation.ade redl_ade_biobert RelationExtractionDLModel en.relation.ade_clinical re_ade_clinical RelationExtractionDLModel en.relation.ade_biobert re_ade_biobert RelationExtractionDLModel en.resolve.rxnorm_disposition sbiobertresolve_rxnorm_disposition SentenceEntityResolverModel en.assert.jsl assertion_jsl AssertionDLModel en.assert.jsl_large assertion_jsl_large AssertionDLModel PyArrow Memory Optimizations Optimized integration with Pyarrow to share memory between the Python Virtual Machine and Java Virtual Machine which yields around 7% less memory consumption on average in all computations. This improvement will take effect for everyone using the default pyspark installation, which comes with a compatible Pyarrow Version. If you manually install or upgrade Pyarrow, please refer to the official Spark docs and make sure you have a Pyarrow version installed that works with your Pyspark version. New Notebooks Sentence Resolution Training Notebook Benchmark Notebook Bugfixes Fixed a bug that caused the similarity matrix calculations to generate NaNs and crash Additional NLU ressources 140+ NLU Tutorials Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.1.1 Sentence Embedding Visualizations, 20+ New Models, 2 New Trainable Models, Drug Normalizer and more in John Snow Labs NLU 3.1.1 We are very excited to announce NLU 3.1.1 has been released! It features a new Sentence Embedding visualization component for Streamlit which supports all 10+ previous dimension reduction techniques. Additionally, all embedding visualizations now support Latent Dirichlet Allocation for dimension reduction. Finally, 2 new trainable models for NER and chunk resolution are supported, a new drug normalizer algorithm has been added, 20+ new pre-trained models including Multi-Lingual, German, various healthcare models and improved NER defaults when using licensed models that have NER dependencies. Streamlit Sentence Embedding visualization via Manifold and Matrix Decomposition algorithms function pipe.viz_streamlit_sentence_embed_manifold Visualize Sentence Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 12 Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms. Additionally, you can color the lower dimensional points with a label that has been previously assigned to the text by specifying a list of nlu references in the additional_classifiers_for_coloring parameter. You can also select additional classifiers via the GUI. Reduces Dimensionality of high dimensional Sentence Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 100+ Sentence Embedding models Color points by classifying with any of the 100+ Document Classifiers Gemerates NUM-DIMENSIONS * NUM-EMBEDDINGS * NUM-DIMENSION-REDUCTION-ALGOS plots text= &quot;&quot;&quot;You can visualize any of the 100 + Sentence Embeddings with 10+ dimension reduction algorithms and view the results in 3D, 2D, and 1D which can be colored by various classifier labels! &quot;&quot;&quot; nlu.load(&#39;embed_sentence.bert&#39;).viz_streamlit_sentence_embed_manifold(text) function parameters pipe.viz_streamlit_sentence_embed_manifold | Argument | Type | Default |Description | |—————————-|————|———————————————————–|———————————————————| |default_texts| List[str] | (“Donald Trump likes to party!”, “Angela Merkel likes to party!”, ‘Peter HATES TO PARTTY!!!! :(‘) | List of strings to apply classifiers, embeddings, and manifolds to. | | text | Optional[str] | &#39;Billy likes to swim&#39; | Text to predict classes for. | |sub_title| Optional[str] | “Apply any of the 11 Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Sentence Embeddings to 1-D, 2-D and 3-D “ | Sub title of the Streamlit app | |default_algos_to_apply| List[str] | [&quot;TSNE&quot;, &quot;PCA&quot;] | A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;, | |target_dimensions| List[int] | (1,2,3) | Defines the target dimension embeddings will be reduced to | |show_algo_select| bool | True | Show selector for Manifold and Matrix Decomposition Algorithms | |show_embed_select| bool | True | Show selector for Embedding Selection | |show_color_select| bool | True | Show selector for coloring plots | |display_embed_information | bool | True | Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more.| | set_wide_layout_CSS | bool | True | Whether to inject custom CSS or not.| |num_cols | int | 2 | How many columns should for the layout in streamlit when rendering the similarity matrixes.| | key | str | &quot;NLU_streamlit&quot; | Key for the Streamlit elements drawn | |additional_classifiers_for_coloring | List[str]|[&#39;sentiment.imdb&#39;] | List of additional NLU references to load for generting hue colors | | show_model_select | bool | True | Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click | | model_select_position | str | &#39;side&#39; | Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info | | show_logo | bool | True | Show logo | | display_infos | bool | False | Display additonal information about ISO codes and the NLU namespace structure.| | n_jobs | Optional[int] | 3| False | How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. | General Streamlit enhancements Support for Latent Dirichlet Allocation The Latent Dirichlet Allocation algorithm is now supported for the Word Embedding Visualizations and the Sentence Embedding Visualizations Normalization of Vectors before calculating sentence similarity. WordEmbedding vectors will now be normalized before calculating similarity scores, which bounds each similarity between 0 and 1 Control order of plots You can now control the order in Which visualizations appear in the main GUI Sentence Embedding Visualization Chunk Entity Resolver Training Chunk Entity Resolver Training Tutorial Notebook Named Entities are sub pieces in textual data which are labeled with classes. These classes and strings are still ambigous though and it is not possible to group semantically identically entities without any definition of terminology. With the Chunk Resolver you can train a state-of-the-art deep learning architecture to map entities to their unique terminological representation. Train a chunk resolver on a dataset with columns named y , _y and text. y is a label, _y is an extra identifier label, text is the raw text import pandas as pd dataset = pd.DataFrame({ &#39;text&#39;: [&#39;The Tesla company is good to invest is&#39;, &#39;TSLA is good to invest&#39;,&#39;TESLA INC. we should buy&#39;,&#39;PUT ALL MONEY IN TSLA inc!!&#39;], &#39;y&#39;: [&#39;23&#39;,&#39;23&#39;,&#39;23&#39;,&#39;23&#39;] &#39;_y&#39;: [&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;], }) trainable_pipe = nlu.load(&#39;train.resolve_chunks&#39;) fitted_pipe = trainable_pipe.fit(dataset) res = fitted_pipe.predict(dataset) fitted_pipe.predict([&quot;Peter told me to buy Tesla &quot;, &#39;I have money to loose, is TSLA a good option?&#39;]) entity_resolution_confidence entity_resolution_code entity_resolution document ‘1.0000’ ‘23’ ‘TESLA’ Peter told me to buy Tesla ‘1.0000’ ‘23’ ‘TESLA’ I have money to loose, is TSLA a good option? Train with default glove embeddings untrained_chunk_resolver = nlu.load(&#39;train.resolve_chunks&#39;) trained_chunk_resolver = untrained_chunk_resolver.fit(df) trained_chunk_resolver.predict(df) Train with custom embeddings # Use BIo GLove untrained_chunk_resolver = nlu.load(&#39;en.embed.glove.biovec train.resolve_chunks&#39;) trained_chunk_resolver = untrained_chunk_resolver.fit(df) trained_chunk_resolver.predict(df) Rule based NER with Context Matcher Rule based NER with context matching tutorial notebook Define a rule-based NER algorithm by providing Regex Patterns and resolution mappings. The confidence value is computed using a heuristic approach based on how many matches it has. A dictionary can be provided with setDictionary to map extracted entities to a unified representation. The first column of the dictionary file should be the representation with the following columns the possible matches. import nlu import json # Define helper functions to write NER rules to file &quot;&quot;&quot;Generate json with dict contexts at target path&quot;&quot;&quot; def dump_dict_to_json_file(dict, path): with open(path, &#39;w&#39;) as f: json.dump(dict, f) &quot;&quot;&quot;Dump raw text file &quot;&quot;&quot; def dump_file_to_csv(data,path): with open(path, &#39;w&#39;) as f:f.write(data) sample_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting. Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Twenty days ago. Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . At birth the typical boy is growing slightly faster than the typical girl, but the velocities become equal at about seven months, and then the girl grows faster until four years. From then until adolescence no differences in velocity can be detected. 21-02-2020 21/04/2020 &quot;&quot;&quot; # Define Gender NER matching rules gender_rules = { &quot;entity&quot;: &quot;Gender&quot;, &quot;ruleScope&quot;: &quot;sentence&quot;, &quot;completeMatchRegex&quot;: &quot;true&quot; } # Define dict data in csv format gender_data = &#39;&#39;&#39;male,man,male,boy,gentleman,he,him female,woman,female,girl,lady,old-lady,she,her neutral,neutral&#39;&#39;&#39; # Dump configs to file dump_dict_to_json_file(gender_data, &#39;gender.csv&#39;) dump_dict_to_json_file(gender_rules, &#39;gender.json&#39;) gender_NER_pipe = nlu.load(&#39;match.context&#39;) gender_NER_pipe.print_info() gender_NER_pipe[&#39;context_matcher&#39;].setJsonPath(&#39;gender.json&#39;) gender_NER_pipe[&#39;context_matcher&#39;].setDictionary(&#39;gender.csv&#39;, options={&quot;delimiter&quot;:&quot;,&quot;}) gender_NER_pipe.predict(sample_text) context_match context_match_confidence female 0.13 she 0.13 she 0.13 she 0.13 she 0.13 boy 0.13 girl 0.13 girl 0.13 Context Matcher Parameters You can define the following parameters in your rules.json file to define the entities to be matched Parameter Type Description entity str The name of this rule regex Optional[str] Regex Pattern to extract candidates contextLength Optional[int] defines the maximum distance a prefix and suffix words can be away from the word to match,whereas context are words that must be immediately after or before the word to match prefix Optional[List[str]] Words preceding the regex match, that are at most contextLength characters aways regexPrefix Optional[str] RegexPattern of words preceding the regex match, that are at most contextLength characters aways suffix Optional[List[str]] Words following the regex match, that are at most contextLength characters aways regexSuffix Optional[str] RegexPattern of words following the regex match, that are at most contextLength distance aways context Optional[List[str]] list of words that must be immediatly before/after a match contextException Optional[List[str]] ?? List of words that may not be immediatly before/after a match exceptionDistance Optional[int] Distance exceptions must be away from a match regexContextException Optional[str] Regex Pattern of exceptions that may not be within exceptionDistance range of the match matchScope Optional[str] Either token or sub-token to match on character basis completeMatchRegex Optional[str] Wether to use complete or partial matching, either &quot;true&quot; or &quot;false&quot; ruleScope str currently only sentence supported Drug Normalizer Drug Normalizer tutorial notebook Normalize raw text from clinical documents, e.g. scraped web pages or xml documents. Removes all dirty characters from text following one or more input regex patterns. Can apply unwanted character removal which a specific policy. Can apply lower case normalization. Parameters are lowercase: whether to convert strings to lowercase. Default is False. policy: rule to remove patterns from text. Valid policy values are: all abbreviations, dosages Defaults is all. abbreviation policy used to expend common drugs abbreviations, dosages policy used to convert drugs dosages and values to the standard form (see examples below). data = [&quot;Agnogenic one half cup&quot;,&quot;adalimumab 54.5 + 43.2 gm&quot;,&quot;aspirin 10 meq/ 5 ml oral sol&quot;,&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec&quot;,&quot;Sodium Chloride/Potassium Chloride 13bag&quot;] nlu.load(&#39;norm_drugs&#39;).predict(data) drug_norm text Agnogenic 0.5 oral solution Agnogenic one half cup adalimumab 97700 mg adalimumab 54.5 + 43.2 gm aspirin 2 meq/ml oral solution aspirin 10 meq/ 5 ml oral sol interferon alfa - 2b 10000000 unt ( 1 ml ) injection interferon alfa-2b 10 million unit ( 1 ml ) injec Sodium Chloride / Potassium Chloride 13 bag Sodium Chloride/Potassium Chloride 13bag New NLU Spells These new magical 1-liners which get new the folowing models Open Source NLU Spells NLU Spell Spark NLP Model nlu.load(‘de.ner.wikiner.6B_100’) wikiner_6B_100 nlu.load(‘xx.embed.glove.glove_6B_100’) glove_6B_100 Healthcare NLU spells NLU Spell Spark NLP Model nlu.load(‘en.resolve.snomed_body_structure_med’) sbertresolve_snomed_bodyStructure_med nlu.load(‘en.resolve.snomed_body_structure’) sbiobertresolve_snomed_bodyStructure nlu.load(‘en.resolve.icdo_augmented’) sbiobertresolve_icdo_augmented nlu.load(‘en.embed_sentence.biobert.jsl_cased’) sbiobert_jsl_cased nlu.load(‘en.embed_sentence.biobert.jsl_umls_cased’) sbiobert_jsl_umls_cased nlu.load(‘en.embed_sentence.bert.jsl_medium_uncased’) sbert_jsl_medium_uncased nlu.load(‘en.embed_sentence.bert.jsl_medium_umls_uncased’) sbert_jsl_medium_umls_uncased nlu.load(‘en.embed_sentence.bert.jsl_mini_uncased’) sbert_jsl_mini_uncased nlu.load(‘en.embed_sentence.bert.jsl_mini_umlsuncased’) sbert_jsl_mini_umls_uncasedjsl_tiny_uncased nlu.load(‘en.embed_sentence.bert.jsl_tiny_uncased’) sbert_jsl_tiny_uncased nlu.load(‘en.embed_sentence.bert.jsl_tiny_umls_uncased’) sbert_jsl_tiny_umls_uncased nlu.load(‘en.resolve.icd10cm.slim_billable_hcc’) sbiobertresolve_icd10cm_slim_billable_hcc nlu.load(‘en.resolve.icd10cm.slim_billable_hcc_med’) sbertresolve_icd10cm_slim_billable_hcc_med nlu.load(‘med_ner.deid.generic_augmented’) ner_deid_generic_augmented nlu.load(‘med_ner.deid.subentity_augmented’) ner_deid_subentity_augmented nlu.load(‘en.assert.radiology’) assertion_dl_radiology nlu.load(‘en.relation.test_result_date’) re_test_result_date nlu.load(‘en.med_ner.admission_events’) ner_events_admission_clinical nlu.load(‘en.classify.ade.clinicalbert’) classifierdl_ade_clinicalbert nlu.load(‘en.recognize_entities.posology’) recognize_entities_posology nlu.load(‘en.embed_sentence.bluebert_cased_mli’) spark_name Improved NER defaults When loading licensed models that require a NER features like Assertion, Relation, Resolution, nlu will now use the en.med_ner model which maps to the Spark NLP model jsl_ner_wip_clinical as default. See https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html for more infos on this model. New Notebooks Rule based NER with context matching tutorial notebook Drug Normalizer tutorial notebook Generic Deep Learning Tensorflow Classifier Additional NLU ressources 140+ NLU Tutorials Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.3 NLU Version 3.1.0 2600+ New Models for 200+ Languages and 10+ Dimension Reduction Algorithms for Streamlit Word-Embedding visualizations in 3-D We are extremely excited to announce the release of NLU 3.1 ! This is our biggest release so far and it comes with over 2600+ new models in 200+ languages, including DistilBERT, RoBERTa, and XLM-RoBERTa and Huggingface based Embeddings from the incredible Spark-NLP 3.1.0 release, new Streamlit Visualizations for visualizing Word Embeddings in 3-D, 2-D, and 1-D, New Healthcare pipelines for healthcare code mappings and finally confidence extraction for open source NER models. Additionally, the NLU Namespace has been renamed to the NLU Spellbook, to reflect the magicalness of each 1-liners represented by them! Streamlit Word Embedding visualization via Manifold and Matrix Decomposition algorithms function pipe.viz_streamlit_word_embed_manifold Visualize Word Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 11 Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms. Additionally, you can color the lower dimensional points with a label that has been previously assigned to the text by specifying a list of nlu references in the additional_classifiers_for_coloring parameter. Reduces Dimensionality of high dimensional Word Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 100+ Word Embedding models Color points by classifying with any of the 100+ Parts of Speech Classifiers or Document Classifiers Gemerates NUM-DIMENSIONS * NUM-EMBEDDINGS * NUM-DIMENSION-REDUCTION-ALGOS plots nlu.load(&#39;bert&#39;,verbose=True).viz_streamlit_word_embed_manifold(default_texts=THE_MATRIX_ARCHITECT_SCRIPT.split(&#39; n&#39;),default_algos_to_apply=[&#39;TSNE&#39;],MAX_DISPLAY_NUM=5) function parameters pipe.viz_streamlit_word_embed_manifold Argument Type Default Description default_texts List[str] (“Donald Trump likes to party!”, “Angela Merkel likes to party!”, ‘Peter HATES TO PARTTY!!!! :(‘) List of strings to apply classifiers, embeddings, and manifolds to. text Optional[str] &#39;Billy likes to swim&#39; Text to predict classes for. sub_title Optional[str] Apply any of the 11 Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Word Embeddings to 1-D, 2-D and 3-D Sub title of the Streamlit app default_algos_to_apply List[str] [&quot;TSNE&quot;, &quot;PCA&quot;] A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39; target_dimensions List[int] (1,2,3) Defines the target dimension embeddings will be reduced to show_algo_select bool True Show selector for Manifold and Matrix Decomposition Algorithms show_embed_select bool True Show selector for Embedding Selection show_color_select bool True Show selector for coloring plots MAX_DISPLAY_NUM int 100 Cap maximum number of Tokens displayed display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more. set_wide_layout_CSS bool True Whether to inject custom CSS or not. num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn additional_classifiers_for_coloring List[str] [&#39;pos&#39;, &#39;sentiment.imdb&#39;] List of additional NLU references to load for generting hue colors show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. n_jobs Optional[int] False How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. Larger Example showcasing more dimension reduction techniques on a larger corpus : Supported Manifold Algorithms TSNE ISOMAP LLE Spectral Embedding MDS Supported Matrix Decomposition Algorithms PCA Truncated SVD aka LSA DictionaryLearning FactorAnalysis FastICA KernelPCA New Healthcare Pipelines Five new healthcare code mapping pipelines: nlu.load(en.resolve.icd10cm.umls): This pretrained pipeline maps ICD10CM codes to UMLS codes without using any text data. You’ll just feed white space-delimited ICD10CM codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;icd10cm&#39;: [&#39;M89.50&#39;, &#39;R82.2&#39;, &#39;R09.01&#39;],&#39;umls&#39;: [&#39;C4721411&#39;, &#39;C0159076&#39;, &#39;C0004044&#39;]} nlu.load(en.resolve.mesh.umls): This pretrained pipeline maps MeSH codes to UMLS codes without using any text data. You’ll just feed white space-delimited MeSH codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;mesh&#39;: [&#39;C028491&#39;, &#39;D019326&#39;, &#39;C579867&#39;],&#39;umls&#39;: [&#39;C0970275&#39;, &#39;C0886627&#39;, &#39;C3696376&#39;]} nlu.load(en.resolve.rxnorm.umls): This pretrained pipeline maps RxNorm codes to UMLS codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;rxnorm&#39;: [&#39;1161611&#39;, &#39;315677&#39;, &#39;343663&#39;],&#39;umls&#39;: [&#39;C3215948&#39;, &#39;C0984912&#39;, &#39;C1146501&#39;]} nlu.load(en.resolve.rxnorm.mesh): This pretrained pipeline maps RxNorm codes to MeSH codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding MeSH codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;rxnorm&#39;: [&#39;1191&#39;, &#39;6809&#39;, &#39;47613&#39;],&#39;mesh&#39;: [&#39;D001241&#39;, &#39;D008687&#39;, &#39;D019355&#39;]} nlu.load(en.resolve.snomed.umls): This pretrained pipeline maps SNOMED codes to UMLS codes without using any text data. You’ll just feed white space-delimited SNOMED codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;snomed&#39;: [&#39;733187009&#39;, &#39;449433008&#39;, &#39;51264003&#39;],&#39;umls&#39;: [&#39;C4546029&#39;, &#39;C3164619&#39;, &#39;C0271267&#39;]} In the following table the NLU and Spark-NLP references are listed: NLU Reference Spark NLP Reference en.resolve.icd10cm.umls icd10cm_umls_mapping en.resolve.mesh.umls mesh_umls_mapping en.resolve.rxnorm.umls rxnorm_umls_mapping en.resolve.rxnorm.mesh rxnorm_mesh_mapping en.resolve.snomed.umls snomed_umls_mapping en.explain_doc.carp explain_clinical_doc_carp en.explain_doc.era explain_clinical_doc_era New Open Source Models and Pipelines nlu.load() Refrence Spark NLP Refrence en.embed.distilbert distilbert_base_cased en.embed.distilbert.base distilbert_base_cased en.embed.distilbert.base.uncased distilbert_base_uncased en.embed.distilroberta distilroberta_base en.embed.roberta roberta_base en.embed.roberta.base roberta_base en.embed.roberta.large roberta_large xx.marian opus_mt_en_fr xx.embed.distilbert. distilbert_base_multilingual_cased xx.embed.xlm xlm_roberta_base xx.embed.xlm.base xlm_roberta_base xx.embed.xlm.twitter twitter_xlm_roberta_base zh.embed.bert bert_base_chinese zh.embed.bert.wwm chinese_bert_wwm de.embed.bert bert_base_german_cased de.embed.bert.uncased bert_base_german_uncased nl.embed.bert bert_base_dutch_cased it.embed.bert bert_base_italian_cased tr.embed.bert bert_base_turkish_cased tr.embed.bert.uncased bert_base_turkish_uncased xx.fr.marian.translate_to.bcl opus_mt_bcl_fr xx.tr.marian.translate_to.ar opus_mt_ar_tr xx.sv.marian.translate_to.af opus_mt_af_sv xx.de.marian.translate_to.ar opus_mt_ar_de xx.fr.marian.translate_to.bi opus_mt_bi_fr xx.es.marian.translate_to.bi opus_mt_bi_es xx.fi.marian.translate_to.af opus_mt_af_fi xx.fi.marian.translate_to.crs opus_mt_crs_fi xx.fi.marian.translate_to.bem opus_mt_bem_fi xx.sv.marian.translate_to.bem opus_mt_bem_sv xx.it.marian.translate_to.ca opus_mt_ca_it xx.fr.marian.translate_to.ca opus_mt_ca_fr xx.es.marian.translate_to.bcl opus_mt_bcl_es xx.uk.marian.translate_to.ca opus_mt_ca_uk xx.fr.marian.translate_to.bem opus_mt_bem_fr xx.de.marian.translate_to.af opus_mt_af_de xx.nl.marian.translate_to.af opus_mt_af_nl xx.fr.marian.translate_to.ase opus_mt_ase_fr xx.es.marian.translate_to.az opus_mt_az_es xx.es.marian.translate_to.chk opus_mt_chk_es xx.sv.marian.translate_to.ceb opus_mt_ceb_sv xx.es.marian.translate_to.ceb opus_mt_ceb_es xx.es.marian.translate_to.aed opus_mt_aed_es xx.pl.marian.translate_to.ar opus_mt_ar_pl xx.es.marian.translate_to.bem opus_mt_bem_es xx.eo.marian.translate_to.af opus_mt_af_eo xx.fr.marian.translate_to.cs opus_mt_cs_fr xx.fi.marian.translate_to.bcl opus_mt_bcl_fi xx.es.marian.translate_to.crs opus_mt_crs_es xx.sv.marian.translate_to.bi opus_mt_bi_sv xx.de.marian.translate_to.bg opus_mt_bg_de xx.ru.marian.translate_to.ar opus_mt_ar_ru xx.es.marian.translate_to.bg opus_mt_bg_es xx.uk.marian.translate_to.cs opus_mt_cs_uk xx.sv.marian.translate_to.bzs opus_mt_bzs_sv xx.es.marian.translate_to.be opus_mt_be_es xx.es.marian.translate_to.bzs opus_mt_bzs_es xx.fr.marian.translate_to.af opus_mt_af_fr xx.pt.marian.translate_to.ca opus_mt_ca_pt xx.fr.marian.translate_to.chk opus_mt_chk_fr xx.de.marian.translate_to.ase opus_mt_ase_de xx.it.marian.translate_to.ar opus_mt_ar_it xx.fi.marian.translate_to.ceb opus_mt_ceb_fi xx.cpp.marian.translate_to.cpp opus_mt_cpp_cpp xx.fr.marian.translate_to.ber opus_mt_ber_fr xx.ru.marian.translate_to.bg opus_mt_bg_ru xx.es.marian.translate_to.ase opus_mt_ase_es xx.es.marian.translate_to.af opus_mt_af_es xx.it.marian.translate_to.bg opus_mt_bg_it xx.sv.marian.translate_to.am opus_mt_am_sv xx.eo.marian.translate_to.ar opus_mt_ar_eo xx.fr.marian.translate_to.ceb opus_mt_ceb_fr xx.es.marian.translate_to.ca opus_mt_ca_es xx.fi.marian.translate_to.bzs opus_mt_bzs_fi xx.de.marian.translate_to.crs opus_mt_crs_de xx.fi.marian.translate_to.cs opus_mt_cs_fi xx.afa.marian.translate_to.afa opus_mt_afa_afa xx.sv.marian.translate_to.bg opus_mt_bg_sv xx.tr.marian.translate_to.bg opus_mt_bg_tr xx.fr.marian.translate_to.crs opus_mt_crs_fr xx.sv.marian.translate_to.ase opus_mt_ase_sv xx.de.marian.translate_to.cs opus_mt_cs_de xx.eo.marian.translate_to.cs opus_mt_cs_eo xx.sv.marian.translate_to.chk opus_mt_chk_sv xx.sv.marian.translate_to.bcl opus_mt_bcl_sv xx.fr.marian.translate_to.ar opus_mt_ar_fr xx.ru.marian.translate_to.af opus_mt_af_ru xx.he.marian.translate_to.ar opus_mt_ar_he xx.fi.marian.translate_to.bg opus_mt_bg_fi xx.es.marian.translate_to.ber opus_mt_ber_es xx.es.marian.translate_to.ar opus_mt_ar_es xx.uk.marian.translate_to.bg opus_mt_bg_uk xx.fr.marian.translate_to.bzs opus_mt_bzs_fr xx.el.marian.translate_to.ar opus_mt_ar_el xx.nl.marian.translate_to.ca opus_mt_ca_nl xx.de.marian.translate_to.bcl opus_mt_bcl_de xx.eo.marian.translate_to.bg opus_mt_bg_eo xx.de.marian.translate_to.efi opus_mt_efi_de xx.bzs.marian.translate_to.de opus_mt_de_bzs xx.fj.marian.translate_to.de opus_mt_de_fj xx.fi.marian.translate_to.da opus_mt_da_fi xx.no.marian.translate_to.da opus_mt_da_no xx.cs.marian.translate_to.de opus_mt_de_cs xx.efi.marian.translate_to.de opus_mt_de_efi xx.gil.marian.translate_to.de opus_mt_de_gil xx.bcl.marian.translate_to.de opus_mt_de_bcl xx.pag.marian.translate_to.de opus_mt_de_pag xx.kg.marian.translate_to.de opus_mt_de_kg xx.fi.marian.translate_to.efi opus_mt_efi_fi xx.is.marian.translate_to.de opus_mt_de_is xx.fr.marian.translate_to.da opus_mt_da_fr xx.pl.marian.translate_to.de opus_mt_de_pl xx.ln.marian.translate_to.de opus_mt_de_ln xx.pap.marian.translate_to.de opus_mt_de_pap xx.vi.marian.translate_to.de opus_mt_de_vi xx.no.marian.translate_to.de opus_mt_de_no xx.eo.marian.translate_to.el opus_mt_el_eo xx.af.marian.translate_to.de opus_mt_de_af xx.es.marian.translate_to.ee opus_mt_ee_es xx.eo.marian.translate_to.de opus_mt_de_eo xx.bi.marian.translate_to.de opus_mt_de_bi xx.mt.marian.translate_to.de opus_mt_de_mt xx.lt.marian.translate_to.de opus_mt_de_lt xx.bg.marian.translate_to.de opus_mt_de_bg xx.hil.marian.translate_to.de opus_mt_de_hil xx.eu.marian.translate_to.de opus_mt_de_eu xx.da.marian.translate_to.de opus_mt_de_da xx.ms.marian.translate_to.de opus_mt_de_ms xx.he.marian.translate_to.de opus_mt_de_he xx.et.marian.translate_to.de opus_mt_de_et xx.es.marian.translate_to.de opus_mt_de_es xx.fr.marian.translate_to.el opus_mt_el_fr xx.fr.marian.translate_to.ee opus_mt_ee_fr xx.el.marian.translate_to.de opus_mt_de_el xx.sv.marian.translate_to.el opus_mt_el_sv xx.es.marian.translate_to.csn opus_mt_csn_es xx.tl.marian.translate_to.de opus_mt_de_tl xx.pon.marian.translate_to.de opus_mt_de_pon xx.fr.marian.translate_to.efi opus_mt_efi_fr xx.uk.marian.translate_to.de opus_mt_de_uk xx.ar.marian.translate_to.el opus_mt_el_ar xx.fi.marian.translate_to.el opus_mt_el_fi xx.ig.marian.translate_to.de opus_mt_de_ig xx.guw.marian.translate_to.de opus_mt_de_guw xx.iso.marian.translate_to.de opus_mt_de_iso xx.sv.marian.translate_to.efi opus_mt_efi_sv xx.ha.marian.translate_to.de opus_mt_de_ha xx.fr.marian.translate_to.de opus_mt_de_fr xx.gaa.marian.translate_to.de opus_mt_de_gaa xx.nso.marian.translate_to.de opus_mt_de_nso xx.ht.marian.translate_to.de opus_mt_de_ht xx.nl.marian.translate_to.de opus_mt_de_nl xx.sv.marian.translate_to.ee opus_mt_ee_sv xx.fi.marian.translate_to.ee opus_mt_ee_fi xx.de.marian.translate_to.ee opus_mt_ee_de xx.eo.marian.translate_to.da opus_mt_da_eo xx.es.marian.translate_to.csg opus_mt_csg_es xx.de.marian.translate_to.da opus_mt_da_de xx.ar.marian.translate_to.de opus_mt_de_ar xx.hu.marian.translate_to.de opus_mt_de_hu xx.ca.marian.translate_to.de opus_mt_de_ca xx.pis.marian.translate_to.de opus_mt_de_pis xx.ho.marian.translate_to.de opus_mt_de_ho xx.de.marian.translate_to.de opus_mt_de_de xx.lua.marian.translate_to.de opus_mt_de_lua xx.loz.marian.translate_to.de opus_mt_de_loz xx.crs.marian.translate_to.de opus_mt_de_crs xx.es.marian.translate_to.da opus_mt_da_es xx.ee.marian.translate_to.de opus_mt_de_ee xx.it.marian.translate_to.de opus_mt_de_it xx.ilo.marian.translate_to.de opus_mt_de_ilo xx.ny.marian.translate_to.de opus_mt_de_ny xx.fi.marian.translate_to.de opus_mt_de_fi xx.ase.marian.translate_to.de opus_mt_de_ase xx.hr.marian.translate_to.de opus_mt_de_hr xx.sl.marian.translate_to.fi opus_mt_fi_sl xx.sk.marian.translate_to.fi opus_mt_fi_sk xx.ru.marian.translate_to.es opus_mt_es_ru xx.sn.marian.translate_to.fi opus_mt_fi_sn xx.pl.marian.translate_to.eo opus_mt_eo_pl xx.cs.marian.translate_to.es opus_mt_es_cs xx.wls.marian.translate_to.fi opus_mt_fi_wls xx.gaa.marian.translate_to.fi opus_mt_fi_gaa xx.is.marian.translate_to.fi opus_mt_fi_is xx.ha.marian.translate_to.es opus_mt_es_ha xx.nl.marian.translate_to.es opus_mt_es_nl xx.ha.marian.translate_to.fi opus_mt_fi_ha xx.fj.marian.translate_to.fi opus_mt_fi_fj xx.ber.marian.translate_to.es opus_mt_es_ber xx.ho.marian.translate_to.fi opus_mt_fi_ho xx.ny.marian.translate_to.fi opus_mt_fi_ny xx.sl.marian.translate_to.es opus_mt_es_sl xx.ts.marian.translate_to.fi opus_mt_fi_ts xx.el.marian.translate_to.eo opus_mt_eo_el xx.war.marian.translate_to.fi opus_mt_fi_war xx.cs.marian.translate_to.fi opus_mt_fi_cs xx.loz.marian.translate_to.es opus_mt_es_loz xx.mk.marian.translate_to.fi opus_mt_fi_mk xx.bg.marian.translate_to.es opus_mt_es_bg xx.srn.marian.translate_to.fi opus_mt_fi_srn xx.is.marian.translate_to.es opus_mt_es_is xx.hu.marian.translate_to.eo opus_mt_eo_hu xx.tw.marian.translate_to.fi opus_mt_fi_tw xx.mt.marian.translate_to.fi opus_mt_fi_mt xx.fr.marian.translate_to.es opus_mt_es_fr xx.yo.marian.translate_to.es opus_mt_es_yo xx.xh.marian.translate_to.fi opus_mt_fi_xh xx.lv.marian.translate_to.fi opus_mt_fi_lv xx.de.marian.translate_to.fi opus_mt_fi_de xx.ve.marian.translate_to.es opus_mt_es_ve xx.es.marian.translate_to.fi opus_mt_fi_es xx.eo.marian.translate_to.es opus_mt_es_eo xx.cs.marian.translate_to.eo opus_mt_eo_cs xx.mt.marian.translate_to.es opus_mt_es_mt xx.el.marian.translate_to.es opus_mt_es_el xx.ee.marian.translate_to.es opus_mt_es_ee xx.de.marian.translate_to.eu opus_mt_eu_de xx.et.marian.translate_to.es opus_mt_es_et xx.fi.marian.translate_to.et opus_mt_et_fi xx.wls.marian.translate_to.es opus_mt_es_wls xx.mg.marian.translate_to.fi opus_mt_fi_mg xx.eu.marian.translate_to.es opus_mt_es_eu xx.lua.marian.translate_to.es opus_mt_es_lua xx.pon.marian.translate_to.es opus_mt_es_pon xx.mfe.marian.translate_to.fi opus_mt_fi_mfe xx.he.marian.translate_to.eo opus_mt_eo_he xx.id.marian.translate_to.es opus_mt_es_id xx.xh.marian.translate_to.es opus_mt_es_xh xx.ar.marian.translate_to.es opus_mt_es_ar xx.crs.marian.translate_to.es opus_mt_es_crs xx.es.marian.translate_to.eu opus_mt_eu_es xx.tpi.marian.translate_to.fi opus_mt_fi_tpi xx.pis.marian.translate_to.fi opus_mt_fi_pis xx.vi.marian.translate_to.es opus_mt_es_vi xx.es.marian.translate_to.et opus_mt_et_es xx.rw.marian.translate_to.fi opus_mt_fi_rw xx.gl.marian.translate_to.es opus_mt_es_gl xx.pt.marian.translate_to.eo opus_mt_eo_pt xx.he.marian.translate_to.fi opus_mt_fi_he xx.af.marian.translate_to.fi opus_mt_fi_af xx.ru.marian.translate_to.fi opus_mt_fi_ru xx.ve.marian.translate_to.fi opus_mt_fi_ve xx.ca.marian.translate_to.es opus_mt_es_ca xx.tr.marian.translate_to.fi opus_mt_fi_tr xx.ht.marian.translate_to.fi opus_mt_fi_ht xx.nl.marian.translate_to.fi opus_mt_fi_nl xx.iso.marian.translate_to.fi opus_mt_fi_iso xx.fi.marian.translate_to.es opus_mt_es_fi xx.da.marian.translate_to.eo opus_mt_eo_da xx.ln.marian.translate_to.es opus_mt_es_ln xx.csn.marian.translate_to.es opus_mt_es_csn xx.pon.marian.translate_to.fi opus_mt_fi_pon xx.af.marian.translate_to.eo opus_mt_eo_af xx.bzs.marian.translate_to.fi opus_mt_fi_bzs xx.no.marian.translate_to.es opus_mt_es_no xx.es.marian.translate_to.es opus_mt_es_es xx.lua.marian.translate_to.fi opus_mt_fi_lua xx.yua.marian.translate_to.es opus_mt_es_yua xx.ru.marian.translate_to.eu opus_mt_eu_ru xx.tpi.marian.translate_to.es opus_mt_es_tpi xx.lue.marian.translate_to.fi opus_mt_fi_lue xx.sv.marian.translate_to.eo opus_mt_eo_sv xx.niu.marian.translate_to.es opus_mt_es_niu xx.tiv.marian.translate_to.fi opus_mt_fi_tiv xx.pag.marian.translate_to.es opus_mt_es_pag xx.run.marian.translate_to.fi opus_mt_fi_run xx.ty.marian.translate_to.es opus_mt_es_ty xx.gil.marian.translate_to.es opus_mt_es_gil xx.ln.marian.translate_to.fi opus_mt_fi_ln xx.ty.marian.translate_to.fi opus_mt_fi_ty xx.prl.marian.translate_to.es opus_mt_es_prl xx.kg.marian.translate_to.es opus_mt_es_kg xx.rw.marian.translate_to.es opus_mt_es_rw xx.kqn.marian.translate_to.fi opus_mt_fi_kqn xx.sq.marian.translate_to.fi opus_mt_fi_sq xx.sw.marian.translate_to.fi opus_mt_fi_sw xx.csg.marian.translate_to.es opus_mt_es_csg xx.ro.marian.translate_to.es opus_mt_es_ro xx.ee.marian.translate_to.fi opus_mt_fi_ee xx.ilo.marian.translate_to.fi opus_mt_fi_ilo xx.eo.marian.translate_to.fi opus_mt_fi_eo xx.iso.marian.translate_to.es opus_mt_es_iso xx.bem.marian.translate_to.fi opus_mt_fi_bem xx.tn.marian.translate_to.fi opus_mt_fi_tn xx.da.marian.translate_to.es opus_mt_es_da xx.es.marian.translate_to.eo opus_mt_eo_es xx.ru.marian.translate_to.eo opus_mt_eo_ru xx.rn.marian.translate_to.es opus_mt_es_rn xx.lt.marian.translate_to.es opus_mt_es_lt xx.guw.marian.translate_to.es opus_mt_es_guw xx.tvl.marian.translate_to.es opus_mt_es_tvl xx.fr.marian.translate_to.et opus_mt_et_fr xx.ht.marian.translate_to.es opus_mt_es_ht xx.mos.marian.translate_to.fi opus_mt_fi_mos xx.ase.marian.translate_to.es opus_mt_es_ase xx.crs.marian.translate_to.fi opus_mt_fi_crs xx.bcl.marian.translate_to.fi opus_mt_fi_bcl xx.tvl.marian.translate_to.fi opus_mt_fi_tvl xx.lus.marian.translate_to.fi opus_mt_fi_lus xx.he.marian.translate_to.es opus_mt_es_he xx.pis.marian.translate_to.es opus_mt_es_pis xx.it.marian.translate_to.es opus_mt_es_it xx.fi.marian.translate_to.eo opus_mt_eo_fi xx.tw.marian.translate_to.es opus_mt_es_tw xx.aed.marian.translate_to.es opus_mt_es_aed xx.bzs.marian.translate_to.es opus_mt_es_bzs xx.nso.marian.translate_to.fi opus_mt_fi_nso xx.gaa.marian.translate_to.es opus_mt_es_gaa xx.zai.marian.translate_to.es opus_mt_es_zai xx.no.marian.translate_to.fi opus_mt_fi_no xx.uk.marian.translate_to.fi opus_mt_fi_uk xx.sg.marian.translate_to.es opus_mt_es_sg xx.ilo.marian.translate_to.es opus_mt_es_ilo xx.bg.marian.translate_to.eo opus_mt_eo_bg xx.pap.marian.translate_to.fi opus_mt_fi_pap xx.ho.marian.translate_to.es opus_mt_es_ho xx.toi.marian.translate_to.fi opus_mt_fi_toi xx.st.marian.translate_to.es opus_mt_es_st xx.to.marian.translate_to.fi opus_mt_fi_to xx.kg.marian.translate_to.fi opus_mt_fi_kg xx.sv.marian.translate_to.fi opus_mt_fi_sv xx.tll.marian.translate_to.fi opus_mt_fi_tll xx.ceb.marian.translate_to.es opus_mt_es_ceb xx.ig.marian.translate_to.es opus_mt_es_ig xx.sv.marian.translate_to.et opus_mt_et_sv xx.af.marian.translate_to.es opus_mt_es_af xx.pl.marian.translate_to.es opus_mt_es_pl xx.ro.marian.translate_to.eo opus_mt_eo_ro xx.tn.marian.translate_to.es opus_mt_es_tn xx.sm.marian.translate_to.fi opus_mt_fi_sm xx.mk.marian.translate_to.es opus_mt_es_mk xx.id.marian.translate_to.fi opus_mt_fi_id xx.hr.marian.translate_to.fi opus_mt_fi_hr xx.sg.marian.translate_to.fi opus_mt_fi_sg xx.hil.marian.translate_to.fi opus_mt_fi_hil xx.nl.marian.translate_to.eo opus_mt_eo_nl xx.pap.marian.translate_to.es opus_mt_es_pap xx.fr.marian.translate_to.fi opus_mt_fi_fr xx.bi.marian.translate_to.es opus_mt_es_bi xx.fi.marian.translate_to.fi opus_mt_fi_fi xx.nso.marian.translate_to.es opus_mt_es_nso xx.et.marian.translate_to.fi opus_mt_fi_et xx.uk.marian.translate_to.es opus_mt_es_uk xx.sh.marian.translate_to.eo opus_mt_eo_sh xx.lu.marian.translate_to.fi opus_mt_fi_lu xx.gil.marian.translate_to.fi opus_mt_fi_gil xx.ro.marian.translate_to.fi opus_mt_fi_ro xx.it.marian.translate_to.eo opus_mt_eo_it xx.hu.marian.translate_to.fi opus_mt_fi_hu xx.bcl.marian.translate_to.es opus_mt_es_bcl xx.fse.marian.translate_to.fi opus_mt_fi_fse xx.hil.marian.translate_to.es opus_mt_es_hil xx.ig.marian.translate_to.fi opus_mt_fi_ig xx.tl.marian.translate_to.es opus_mt_es_tl xx.pag.marian.translate_to.fi opus_mt_fi_pag xx.guw.marian.translate_to.fi opus_mt_fi_guw xx.swc.marian.translate_to.es opus_mt_es_swc xx.swc.marian.translate_to.fi opus_mt_fi_swc xx.lg.marian.translate_to.fi opus_mt_fi_lg xx.srn.marian.translate_to.es opus_mt_es_srn xx.hr.marian.translate_to.es opus_mt_es_hr xx.sm.marian.translate_to.es opus_mt_es_sm xx.de.marian.translate_to.es opus_mt_es_de xx.st.marian.translate_to.fi opus_mt_fi_st xx.fr.marian.translate_to.eo opus_mt_eo_fr xx.de.marian.translate_to.et opus_mt_et_de xx.niu.marian.translate_to.fi opus_mt_fi_niu xx.el.marian.translate_to.fi opus_mt_fi_el xx.efi.marian.translate_to.fi opus_mt_fi_efi xx.war.marian.translate_to.es opus_mt_es_war xx.mfs.marian.translate_to.es opus_mt_es_mfs xx.bg.marian.translate_to.fi opus_mt_fi_bg xx.lus.marian.translate_to.es opus_mt_es_lus xx.de.marian.translate_to.eo opus_mt_eo_de xx.it.marian.translate_to.fi opus_mt_fi_it xx.efi.marian.translate_to.es opus_mt_es_efi xx.ny.marian.translate_to.es opus_mt_es_ny xx.fj.marian.translate_to.es opus_mt_es_fj xx.ru.marian.translate_to.et opus_mt_et_ru xx.mh.marian.translate_to.fi opus_mt_fi_mh xx.es.marian.translate_to.ig opus_mt_ig_es xx.sv.marian.translate_to.hu opus_mt_hu_sv xx.lue.marian.translate_to.fr opus_mt_fr_lue xx.fi.marian.translate_to.ha opus_mt_ha_fi xx.ca.marian.translate_to.it opus_mt_it_ca xx.de.marian.translate_to.ilo opus_mt_ilo_de xx.it.marian.translate_to.he opus_tatoeba_it_he xx.loz.marian.translate_to.fr opus_mt_fr_loz xx.ms.marian.translate_to.fr opus_mt_fr_ms xx.uk.marian.translate_to.it opus_mt_it_uk xx.gaa.marian.translate_to.fr opus_mt_fr_gaa xx.pap.marian.translate_to.fr opus_mt_fr_pap xx.fi.marian.translate_to.ilo opus_mt_ilo_fi xx.lg.marian.translate_to.fr opus_mt_fr_lg xx.it.marian.translate_to.is opus_mt_is_it xx.ms.marian.translate_to.it opus_mt_it_ms xx.es.marian.translate_to.fr opus_mt_fr_es xx.ar.marian.translate_to.he opus_mt_he_ar xx.ro.marian.translate_to.fr opus_mt_fr_ro xx.ru.marian.translate_to.fr opus_mt_fr_ru xx.fi.marian.translate_to.ht opus_mt_ht_fi xx.bg.marian.translate_to.it opus_mt_it_bg xx.mh.marian.translate_to.fr opus_mt_fr_mh xx.to.marian.translate_to.fr opus_mt_fr_to xx.sl.marian.translate_to.fr opus_mt_fr_sl xx.fr.marian.translate_to.gil opus_mt_gil_fr xx.es.marian.translate_to.hr opus_mt_hr_es xx.ilo.marian.translate_to.fr opus_mt_fr_ilo xx.ee.marian.translate_to.fr opus_mt_fr_ee xx.sv.marian.translate_to.he opus_mt_he_sv xx.fr.marian.translate_to.ha opus_mt_ha_fr xx.gil.marian.translate_to.fr opus_mt_fr_gil xx.fi.marian.translate_to.id opus_mt_id_fi xx.iir.marian.translate_to.iir opus_mt_iir_iir xx.pl.marian.translate_to.fr opus_mt_fr_pl xx.tw.marian.translate_to.fr opus_mt_fr_tw xx.sv.marian.translate_to.gaa opus_mt_gaa_sv xx.ar.marian.translate_to.it opus_mt_it_ar xx.es.marian.translate_to.gil opus_mt_gil_es xx.ase.marian.translate_to.fr opus_mt_fr_ase xx.fr.marian.translate_to.gaa opus_mt_gaa_fr xx.lus.marian.translate_to.fr opus_mt_fr_lus xx.fr.marian.translate_to.iso opus_mt_iso_fr xx.sm.marian.translate_to.fr opus_mt_fr_sm xx.mfe.marian.translate_to.fr opus_mt_fr_mfe xx.af.marian.translate_to.fr opus_mt_fr_af xx.de.marian.translate_to.ig opus_mt_ig_de xx.es.marian.translate_to.id opus_mt_id_es xx.kqn.marian.translate_to.fr opus_mt_fr_kqn xx.zne.marian.translate_to.fi opus_mt_fi_zne xx.rw.marian.translate_to.fr opus_mt_fr_rw xx.ny.marian.translate_to.fr opus_mt_fr_ny xx.ig.marian.translate_to.fr opus_mt_fr_ig xx.ur.marian.translate_to.hi opus_mt_hi_ur xx.lt.marian.translate_to.it opus_mt_it_lt xx.srn.marian.translate_to.fr opus_mt_fr_srn xx.tiv.marian.translate_to.fr opus_mt_fr_tiv xx.war.marian.translate_to.fr opus_mt_fr_war xx.fr.marian.translate_to.is opus_mt_is_fr xx.de.marian.translate_to.gaa opus_mt_gaa_de xx.kwy.marian.translate_to.fr opus_mt_fr_kwy xx.sv.marian.translate_to.gil opus_mt_gil_sv xx.hr.marian.translate_to.fr opus_mt_fr_hr xx.fr.marian.translate_to.ig opus_mt_ig_fr xx.sv.marian.translate_to.ht opus_mt_ht_sv xx.de.marian.translate_to.fr opus_mt_fr_de xx.fiu.marian.translate_to.fiu opus_mt_fiu_fiu xx.wls.marian.translate_to.fr opus_mt_fr_wls xx.eo.marian.translate_to.hu opus_mt_hu_eo xx.guw.marian.translate_to.fr opus_mt_fr_guw xx.de.marian.translate_to.is opus_mt_is_de xx.tvl.marian.translate_to.fr opus_mt_fr_tvl xx.zne.marian.translate_to.fr opus_mt_fr_zne xx.ha.marian.translate_to.fr opus_mt_fr_ha xx.fi.marian.translate_to.guw opus_mt_guw_fi xx.es.marian.translate_to.is opus_mt_is_es xx.sv.marian.translate_to.it opus_mt_it_sv xx.uk.marian.translate_to.fr opus_mt_fr_uk xx.uk.marian.translate_to.hu opus_mt_hu_uk xx.mt.marian.translate_to.fr opus_mt_fr_mt xx.gem.marian.translate_to.gem opus_mt_gem_gem xx.fr.marian.translate_to.fj opus_mt_fj_fr xx.fi.marian.translate_to.gil opus_mt_gil_fi xx.fr.marian.translate_to.hu opus_mt_hu_fr xx.bcl.marian.translate_to.fr opus_mt_fr_bcl xx.gmq.marian.translate_to.gmq opus_mt_gmq_gmq xx.kg.marian.translate_to.fr opus_mt_fr_kg xx.sn.marian.translate_to.fr opus_mt_fr_sn xx.bg.marian.translate_to.fr opus_mt_fr_bg xx.fr.marian.translate_to.guw opus_mt_guw_fr xx.ts.marian.translate_to.fr opus_mt_fr_ts xx.pis.marian.translate_to.fr opus_mt_fr_pis xx.bi.marian.translate_to.fr opus_mt_fr_bi xx.ln.marian.translate_to.fr opus_mt_fr_ln xx.de.marian.translate_to.hil opus_mt_hil_de xx.nso.marian.translate_to.fr opus_mt_fr_nso xx.es.marian.translate_to.iso opus_mt_iso_es xx.crs.marian.translate_to.fr opus_mt_fr_crs xx.niu.marian.translate_to.fr opus_mt_fr_niu xx.fr.marian.translate_to.ht opus_mt_ht_fr xx.fi.marian.translate_to.he opus_mt_he_fi xx.gmw.marian.translate_to.gmw opus_mt_gmw_gmw xx.fr.marian.translate_to.hr opus_mt_hr_fr xx.sg.marian.translate_to.fr opus_mt_fr_sg xx.pon.marian.translate_to.fr opus_mt_fr_pon xx.fi.marian.translate_to.gaa opus_mt_gaa_fi xx.pag.marian.translate_to.fr opus_mt_fr_pag xx.fi.marian.translate_to.is opus_mt_is_fi xx.sk.marian.translate_to.fr opus_mt_fr_sk xx.yap.marian.translate_to.fr opus_mt_fr_yap xx.es.marian.translate_to.ha opus_mt_ha_es xx.no.marian.translate_to.fr opus_mt_fr_no xx.ine.marian.translate_to.ine opus_mt_ine_ine xx.fr.marian.translate_to.id opus_mt_id_fr xx.bzs.marian.translate_to.fr opus_mt_fr_bzs xx.he.marian.translate_to.fr opus_tatoeba_he_fr xx.sv.marian.translate_to.fr opus_mt_fr_sv xx.uk.marian.translate_to.he opus_mt_he_uk xx.fr.marian.translate_to.it opus_mt_it_fr xx.fi.marian.translate_to.ig opus_mt_ig_fi xx.vi.marian.translate_to.fr opus_mt_fr_vi xx.fi.marian.translate_to.fse opus_mt_fse_fi xx.es.marian.translate_to.guw opus_mt_guw_es xx.tll.marian.translate_to.fr opus_mt_fr_tll xx.lua.marian.translate_to.fr opus_mt_fr_lua xx.yap.marian.translate_to.fi opus_mt_fi_yap xx.es.marian.translate_to.gaa opus_mt_gaa_es xx.sv.marian.translate_to.ig opus_mt_ig_sv xx.ht.marian.translate_to.fr opus_mt_fr_ht xx.el.marian.translate_to.fr opus_mt_fr_el xx.inc.marian.translate_to.inc opus_mt_inc_inc xx.swc.marian.translate_to.fr opus_mt_fr_swc xx.ar.marian.translate_to.fr opus_mt_fr_ar xx.es.marian.translate_to.ilo opus_mt_ilo_es xx.fi.marian.translate_to.hr opus_mt_hr_fi xx.tpi.marian.translate_to.fr opus_mt_fr_tpi xx.ve.marian.translate_to.fr opus_mt_fr_ve xx.sv.marian.translate_to.guw opus_mt_guw_sv xx.sv.marian.translate_to.iso opus_mt_iso_sv xx.sv.marian.translate_to.is opus_mt_is_sv xx.tum.marian.translate_to.fr opus_mt_fr_tum xx.es.marian.translate_to.ht opus_mt_ht_es xx.ho.marian.translate_to.fr opus_mt_fr_ho xx.efi.marian.translate_to.fr opus_mt_fr_efi xx.es.marian.translate_to.gl opus_mt_gl_es xx.ru.marian.translate_to.he opus_mt_he_ru xx.fi.marian.translate_to.hil opus_mt_hil_fi xx.eo.marian.translate_to.he opus_mt_he_eo xx.lu.marian.translate_to.fr opus_mt_fr_lu xx.sv.marian.translate_to.ha opus_mt_ha_sv xx.rnd.marian.translate_to.fr opus_mt_fr_rnd xx.st.marian.translate_to.fr opus_mt_fr_st xx.tl.marian.translate_to.fr opus_mt_fr_tl xx.bem.marian.translate_to.fr opus_mt_fr_bem xx.eo.marian.translate_to.is opus_mt_is_eo xx.is.marian.translate_to.it opus_mt_it_is xx.hu.marian.translate_to.fr opus_mt_fr_hu xx.yo.marian.translate_to.fi opus_mt_fi_yo xx.iso.marian.translate_to.fr opus_mt_fr_iso xx.de.marian.translate_to.it opus_mt_it_de xx.ty.marian.translate_to.fr opus_mt_fr_ty xx.hil.marian.translate_to.fr opus_mt_fr_hil xx.eo.marian.translate_to.it opus_mt_it_eo xx.sv.marian.translate_to.hr opus_mt_hr_sv xx.ber.marian.translate_to.fr opus_mt_fr_ber xx.de.marian.translate_to.guw opus_mt_guw_de xx.fi.marian.translate_to.hu opus_mt_hu_fi xx.es.marian.translate_to.it opus_mt_it_es xx.de.marian.translate_to.hu opus_mt_hu_de xx.fj.marian.translate_to.fr opus_mt_fr_fj xx.sv.marian.translate_to.id opus_mt_id_sv xx.xh.marian.translate_to.fr opus_mt_fr_xh xx.yo.marian.translate_to.fr opus_mt_fr_yo xx.ca.marian.translate_to.fr opus_mt_fr_ca xx.es.marian.translate_to.he opus_mt_he_es xx.de.marian.translate_to.he opus_mt_he_de xx.pt.marian.translate_to.gl opus_mt_gl_pt xx.ru.marian.translate_to.hy opus_mt_hy_ru xx.mos.marian.translate_to.fr opus_mt_fr_mos xx.ceb.marian.translate_to.fr opus_mt_fr_ceb xx.sh.marian.translate_to.ja opus_mt_ja_sh xx.bg.marian.translate_to.ja opus_mt_ja_bg xx.sv.marian.translate_to.ja opus_mt_ja_sv xx.ru.marian.translate_to.lv opus_mt_lv_ru xx.fr.marian.translate_to.ms opus_mt_ms_fr xx.sv.marian.translate_to.mt opus_mt_mt_sv xx.da.marian.translate_to.ja opus_mt_ja_da xx.de.marian.translate_to.niu opus_mt_niu_de xx.es.marian.translate_to.niu opus_mt_niu_es xx.sv.marian.translate_to.lus opus_mt_lus_sv xx.sv.marian.translate_to.lg opus_mt_lg_sv xx.sv.marian.translate_to.pon opus_mt_pon_sv xx.ru.marian.translate_to.lt opus_mt_lt_ru xx.fi.marian.translate_to.lg opus_mt_lg_fi xx.sv.marian.translate_to.kg opus_mt_kg_sv xx.fr.marian.translate_to.nl opus_mt_nl_fr xx.ms.marian.translate_to.ms opus_mt_ms_ms xx.es.marian.translate_to.lg opus_mt_lg_es xx.fr.marian.translate_to.lu opus_mt_lu_fr xx.fr.marian.translate_to.loz opus_mt_loz_fr xx.ca.marian.translate_to.nl opus_mt_nl_ca xx.sv.marian.translate_to.lue opus_mt_lue_sv xx.vi.marian.translate_to.ja opus_mt_ja_vi xx.fr.marian.translate_to.ja opus_mt_ja_fr xx.fi.marian.translate_to.pap opus_mt_pap_fi xx.pl.marian.translate_to.lt opus_mt_lt_pl xx.de.marian.translate_to.ny opus_mt_ny_de xx.fr.marian.translate_to.lue opus_mt_lue_fr xx.gl.marian.translate_to.pt opus_mt_pt_gl xx.fr.marian.translate_to.pap opus_mt_pap_fr xx.uk.marian.translate_to.pl opus_mt_pl_uk xx.fi.marian.translate_to.niu opus_mt_niu_fi xx.ar.marian.translate_to.ja opus_mt_ja_ar xx.es.marian.translate_to.mh opus_mt_mh_es xx.ar.marian.translate_to.pl opus_mt_pl_ar xx.de.marian.translate_to.pag opus_mt_pag_de xx.es.marian.translate_to.no opus_mt_no_es xx.es.marian.translate_to.mfs opus_mt_mfs_es xx.fr.marian.translate_to.pis opus_mt_pis_fr xx.eo.marian.translate_to.pt opus_mt_pt_eo xx.de.marian.translate_to.lt opus_mt_lt_de xx.fr.marian.translate_to.ln opus_mt_ln_fr xx.es.marian.translate_to.pag opus_mt_pag_es xx.fi.marian.translate_to.nl opus_mt_nl_fi xx.vi.marian.translate_to.it opus_mt_it_vi xx.fi.marian.translate_to.ko opus_mt_ko_fi xx.de.marian.translate_to.nso opus_mt_nso_de xx.fr.marian.translate_to.niu opus_mt_niu_fr xx.ca.marian.translate_to.pt opus_mt_pt_ca xx.fr.marian.translate_to.kwy opus_mt_kwy_fr xx.ru.marian.translate_to.no opus_mt_no_ru xx.fi.marian.translate_to.pon opus_mt_pon_fi xx.fi.marian.translate_to.lu opus_mt_lu_fi xx.es.marian.translate_to.ko opus_mt_ko_es xx.es.marian.translate_to.ny opus_mt_ny_es xx.itc.marian.translate_to.itc opus_mt_itc_itc xx.es.marian.translate_to.ja opus_mt_ja_es xx.fr.marian.translate_to.mk opus_mt_mk_fr xx.it.marian.translate_to.ms opus_mt_ms_it xx.sv.marian.translate_to.lu opus_mt_lu_sv xx.fr.marian.translate_to.nso opus_mt_nso_fr xx.uk.marian.translate_to.pt opus_mt_pt_uk xx.no.marian.translate_to.no opus_mt_no_no xx.sv.marian.translate_to.lua opus_mt_lua_sv xx.es.marian.translate_to.pl opus_mt_pl_es xx.es.marian.translate_to.lu opus_mt_lu_es xx.fr.marian.translate_to.lus opus_mt_lus_fr xx.tr.marian.translate_to.ja opus_mt_ja_tr xx.fi.marian.translate_to.pag opus_mt_pag_fi xx.fr.marian.translate_to.kqn opus_mt_kqn_fr xx.fi.marian.translate_to.ja opus_mt_ja_fi xx.af.marian.translate_to.nl opus_mt_nl_af xx.sv.marian.translate_to.pag opus_mt_pag_sv xx.sv.marian.translate_to.nl opus_mt_nl_sv xx.uk.marian.translate_to.no opus_mt_no_uk xx.es.marian.translate_to.lua opus_mt_lua_es xx.fi.marian.translate_to.mt opus_mt_mt_fi xx.eo.marian.translate_to.lt opus_mt_lt_eo xx.de.marian.translate_to.no opus_mt_no_de xx.eo.marian.translate_to.pl opus_mt_pl_eo xx.es.marian.translate_to.loz opus_mt_loz_es xx.ru.marian.translate_to.ja opus_mt_ja_ru xx.sv.marian.translate_to.pl opus_mt_pl_sv xx.fi.marian.translate_to.mh opus_mt_mh_fi xx.hu.marian.translate_to.ja opus_mt_ja_hu xx.fi.marian.translate_to.mk opus_mt_mk_fi xx.es.marian.translate_to.lue opus_mt_lue_es xx.sv.marian.translate_to.lt opus_mt_lt_sv xx.fr.marian.translate_to.pon opus_mt_pon_fr xx.es.marian.translate_to.pap opus_mt_pap_es xx.es.marian.translate_to.ln opus_mt_ln_es xx.de.marian.translate_to.loz opus_mt_loz_de xx.ru.marian.translate_to.ka opus_mt_ka_ru xx.sv.marian.translate_to.kwy opus_mt_kwy_sv xx.fi.marian.translate_to.lv opus_mt_lv_fi xx.pl.marian.translate_to.ja opus_mt_ja_pl xx.hu.marian.translate_to.ko opus_mt_ko_hu xx.de.marian.translate_to.ja opus_mt_ja_de xx.de.marian.translate_to.ko opus_mt_ko_de xx.es.marian.translate_to.kg opus_mt_kg_es xx.de.marian.translate_to.pap opus_mt_pap_de xx.fi.marian.translate_to.no opus_mt_no_fi xx.fi.marian.translate_to.lue opus_mt_lue_fi xx.no.marian.translate_to.pl opus_mt_pl_no xx.fr.marian.translate_to.mt opus_mt_mt_fr xx.es.marian.translate_to.mg opus_mt_mg_es xx.es.marian.translate_to.pis opus_mt_pis_es xx.fr.marian.translate_to.pl opus_mt_pl_fr xx.sv.marian.translate_to.ko opus_mt_ko_sv xx.sv.marian.translate_to.loz opus_mt_loz_sv xx.fi.marian.translate_to.loz opus_mt_loz_fi xx.pl.marian.translate_to.no opus_mt_no_pl xx.nl.marian.translate_to.ja opus_mt_ja_nl xx.de.marian.translate_to.pl opus_mt_pl_de xx.lt.marian.translate_to.pl opus_mt_pl_lt xx.ru.marian.translate_to.ko opus_mt_ko_ru xx.fr.marian.translate_to.lv opus_mt_lv_fr xx.he.marian.translate_to.ja opus_mt_ja_he xx.sv.marian.translate_to.niu opus_mt_niu_sv xx.de.marian.translate_to.ms opus_mt_ms_de xx.es.marian.translate_to.lt opus_mt_lt_es xx.sv.marian.translate_to.no opus_mt_no_sv xx.nl.marian.translate_to.no opus_mt_no_nl xx.fi.marian.translate_to.lua opus_mt_lua_fi xx.fr.marian.translate_to.lt opus_mt_lt_fr xx.ms.marian.translate_to.ja opus_mt_ja_ms xx.es.marian.translate_to.kqn opus_mt_kqn_es xx.fr.marian.translate_to.lg opus_mt_lg_fr xx.es.marian.translate_to.mk opus_mt_mk_es xx.da.marian.translate_to.no opus_mt_no_da xx.it.marian.translate_to.lt opus_mt_lt_it xx.es.marian.translate_to.prl opus_mt_prl_es xx.fr.marian.translate_to.lua opus_mt_lua_fr xx.es.marian.translate_to.nso opus_mt_nso_es xx.sv.marian.translate_to.lv opus_mt_lv_sv xx.fi.marian.translate_to.pis opus_mt_pis_fi xx.es.marian.translate_to.pon opus_mt_pon_es xx.fr.marian.translate_to.ko opus_mt_ko_fr xx.de.marian.translate_to.ln opus_mt_ln_de xx.uk.marian.translate_to.nl opus_mt_nl_uk xx.eo.marian.translate_to.nl opus_mt_nl_eo xx.es.marian.translate_to.lv opus_mt_lv_es xx.tr.marian.translate_to.lt opus_mt_lt_tr xx.es.marian.translate_to.mt opus_mt_mt_es xx.fi.marian.translate_to.lus opus_mt_lus_fi xx.tl.marian.translate_to.pt opus_mt_pt_tl xx.no.marian.translate_to.nl opus_mt_nl_no xx.sv.marian.translate_to.kqn opus_mt_kqn_sv xx.pt.marian.translate_to.ja opus_mt_ja_pt xx.fi.marian.translate_to.nso opus_mt_nso_fi xx.fr.marian.translate_to.kg opus_mt_kg_fr xx.sv.marian.translate_to.pis opus_mt_pis_sv xx.is.marian.translate_to.sv opus_mt_sv_is xx.sla.marian.translate_to.sla opus_mt_sla_sla xx.sv.marian.translate_to.srn opus_mt_srn_sv xx.niu.marian.translate_to.sv opus_mt_sv_niu xx.to.marian.translate_to.sv opus_mt_sv_to xx.guw.marian.translate_to.sv opus_mt_sv_guw xx.sn.marian.translate_to.sv opus_mt_sv_sn xx.sv.marian.translate_to.rnd opus_mt_rnd_sv xx.tum.marian.translate_to.sv opus_mt_sv_tum xx.mos.marian.translate_to.sv opus_mt_sv_mos xx.srn.marian.translate_to.sv opus_mt_sv_srn xx.ht.marian.translate_to.sv opus_mt_sv_ht xx.no.marian.translate_to.ru opus_mt_ru_no xx.sl.marian.translate_to.sv opus_mt_sv_sl xx.fr.marian.translate_to.sv opus_mt_sv_fr xx.uk.marian.translate_to.ru opus_mt_ru_uk xx.tiv.marian.translate_to.sv opus_mt_sv_tiv xx.es.marian.translate_to.ru opus_mt_ru_es xx.pag.marian.translate_to.sv opus_mt_sv_pag xx.gaa.marian.translate_to.sv opus_mt_sv_gaa xx.kqn.marian.translate_to.sv opus_mt_sv_kqn xx.fr.marian.translate_to.sg opus_mt_sg_fr xx.st.marian.translate_to.sv opus_mt_sv_st xx.ase.marian.translate_to.sv opus_mt_sv_ase xx.es.marian.translate_to.rn opus_mt_rn_es xx.ru.marian.translate_to.sl opus_mt_sl_ru xx.lu.marian.translate_to.sv opus_mt_sv_lu xx.eu.marian.translate_to.ru opus_mt_ru_eu xx.no.marian.translate_to.sv opus_mt_sv_no xx.sq.marian.translate_to.sv opus_mt_sv_sq xx.da.marian.translate_to.ru opus_mt_ru_da xx.ny.marian.translate_to.sv opus_mt_sv_ny xx.kg.marian.translate_to.sv opus_mt_sv_kg xx.pis.marian.translate_to.sv opus_mt_sv_pis xx.sv.marian.translate_to.sk opus_mt_sk_sv xx.lus.marian.translate_to.sv opus_mt_sv_lus xx.fi.marian.translate_to.sl opus_mt_sl_fi xx.tn.marian.translate_to.sv opus_mt_sv_tn xx.fr.marian.translate_to.srn opus_mt_srn_fr xx.lv.marian.translate_to.sv opus_mt_sv_lv xx.uk.marian.translate_to.sl opus_mt_sl_uk xx.sg.marian.translate_to.sv opus_mt_sv_sg xx.he.marian.translate_to.sv opus_mt_sv_he xx.eo.marian.translate_to.ru opus_mt_ru_eo xx.fr.marian.translate_to.ru opus_mt_ru_fr xx.lv.marian.translate_to.ru opus_mt_ru_lv xx.lua.marian.translate_to.sv opus_mt_sv_lua xx.ar.marian.translate_to.ru opus_mt_ru_ar xx.tll.marian.translate_to.sv opus_mt_sv_tll xx.lue.marian.translate_to.sv opus_mt_sv_lue xx.bi.marian.translate_to.sv opus_mt_sv_bi xx.hu.marian.translate_to.sv opus_mt_sv_hu xx.bzs.marian.translate_to.sv opus_mt_sv_bzs xx.ru.marian.translate_to.sv opus_mt_sv_ru xx.eo.marian.translate_to.ro opus_mt_ro_eo xx.es.marian.translate_to.st opus_mt_st_es xx.mt.marian.translate_to.sv opus_mt_sv_mt xx.af.marian.translate_to.sv opus_mt_sv_af xx.ts.marian.translate_to.sv opus_mt_sv_ts xx.af.marian.translate_to.ru opus_tatoeba_af_ru xx.efi.marian.translate_to.sv opus_mt_sv_efi xx.es.marian.translate_to.sv opus_mt_sv_es xx.fi.marian.translate_to.sk opus_mt_sk_fi xx.fr.marian.translate_to.rw opus_mt_rw_fr xx.sv.marian.translate_to.run opus_mt_run_sv xx.th.marian.translate_to.sv opus_mt_sv_th xx.ln.marian.translate_to.sv opus_mt_sv_ln xx.es.marian.translate_to.sk opus_mt_sk_es xx.lt.marian.translate_to.ru opus_mt_ru_lt xx.mfe.marian.translate_to.sv opus_mt_sv_mfe xx.cs.marian.translate_to.sv opus_mt_sv_cs xx.vi.marian.translate_to.ru opus_mt_ru_vi xx.ee.marian.translate_to.sv opus_mt_sv_ee xx.bg.marian.translate_to.ru opus_mt_ru_bg xx.nso.marian.translate_to.sv opus_mt_sv_nso xx.mh.marian.translate_to.sv opus_mt_sv_mh xx.iso.marian.translate_to.sv opus_mt_sv_iso xx.fi.marian.translate_to.st opus_mt_st_fi xx.bg.marian.translate_to.sv opus_mt_sv_bg xx.sv.marian.translate_to.sq opus_mt_sq_sv xx.sv.marian.translate_to.sn opus_mt_sn_sv xx.de.marian.translate_to.rn opus_mt_rn_de xx.pon.marian.translate_to.sv opus_mt_sv_pon xx.ha.marian.translate_to.sv opus_mt_sv_ha xx.fi.marian.translate_to.ru opus_mt_ru_fi xx.sk.marian.translate_to.sv opus_mt_sv_sk xx.es.marian.translate_to.run opus_mt_run_es xx.et.marian.translate_to.ru opus_mt_ru_et xx.swc.marian.translate_to.sv opus_mt_sv_swc xx.hil.marian.translate_to.sv opus_mt_sv_hil xx.ro.marian.translate_to.sv opus_mt_sv_ro xx.fr.marian.translate_to.rnd opus_mt_rnd_fr xx.kwy.marian.translate_to.sv opus_mt_sv_kwy xx.uk.marian.translate_to.sh opus_mt_sh_uk xx.sm.marian.translate_to.sv opus_mt_sv_sm xx.sv.marian.translate_to.rw opus_mt_rw_sv xx.et.marian.translate_to.sv opus_mt_sv_et xx.eo.marian.translate_to.sv opus_mt_sv_eo xx.rnd.marian.translate_to.sv opus_mt_sv_rnd xx.eo.marian.translate_to.sh opus_mt_sh_eo xx.ru.marian.translate_to.rn opus_mt_rn_ru xx.rw.marian.translate_to.sv opus_mt_sv_rw xx.fr.marian.translate_to.sn opus_mt_sn_fr xx.ig.marian.translate_to.sv opus_mt_sv_ig xx.fj.marian.translate_to.sv opus_mt_sv_fj xx.sl.marian.translate_to.ru opus_mt_ru_sl xx.ho.marian.translate_to.sv opus_mt_sv_ho xx.sv.marian.translate_to.sl opus_mt_sl_sv xx.pap.marian.translate_to.sv opus_mt_sv_pap xx.fr.marian.translate_to.sl opus_mt_sl_fr xx.es.marian.translate_to.sl opus_mt_sl_es xx.run.marian.translate_to.sv opus_mt_sv_run xx.el.marian.translate_to.sv opus_mt_sv_el xx.gil.marian.translate_to.sv opus_mt_sv_gil xx.crs.marian.translate_to.sv opus_mt_sv_crs xx.fr.marian.translate_to.sk opus_mt_sk_fr xx.es.marian.translate_to.sq opus_mt_sq_es xx.sv.marian.translate_to.sg opus_mt_sg_sv xx.es.marian.translate_to.srn opus_mt_srn_es xx.fr.marian.translate_to.ro opus_mt_ro_fr xx.fr.marian.translate_to.rn opus_mt_rn_fr xx.fr.marian.translate_to.st opus_mt_st_fr xx.es.marian.translate_to.rw opus_mt_rw_es xx.hr.marian.translate_to.sv opus_mt_sv_hr xx.es.marian.translate_to.sm opus_mt_sm_es xx.es.marian.translate_to.ssp opus_mt_ssp_es xx.nl.marian.translate_to.sv opus_mt_sv_nl xx.bem.marian.translate_to.sv opus_mt_sv_bem xx.sem.marian.translate_to.sem opus_mt_sem_sem xx.sv.marian.translate_to.sv opus_mt_sv_sv xx.sv.marian.translate_to.st opus_mt_st_sv xx.lg.marian.translate_to.sv opus_mt_sv_lg xx.bcl.marian.translate_to.sv opus_mt_sv_bcl xx.toi.marian.translate_to.sv opus_mt_sv_toi xx.id.marian.translate_to.sv opus_mt_sv_id xx.he.marian.translate_to.ru opus_mt_ru_he xx.ceb.marian.translate_to.sv opus_mt_sv_ceb xx.tw.marian.translate_to.sv opus_mt_sv_tw xx.chk.marian.translate_to.sv opus_mt_sv_chk xx.fr.marian.translate_to.sm opus_mt_sm_fr xx.tvl.marian.translate_to.sv opus_mt_sv_tvl xx.es.marian.translate_to.sg opus_mt_sg_es xx.ilo.marian.translate_to.sv opus_mt_sv_ilo xx.sv.marian.translate_to.ro opus_mt_ro_sv xx.fi.marian.translate_to.sg opus_mt_sg_fi xx.hy.marian.translate_to.ru opus_mt_ru_hy xx.fi.marian.translate_to.ro opus_mt_ro_fi xx.tpi.marian.translate_to.sv opus_mt_sv_tpi xx.fi.marian.translate_to.sv opus_mt_sv_fi xx.sv.marian.translate_to.ru opus_mt_ru_sv xx.es.marian.translate_to.toi opus_mt_toi_es xx.no.marian.translate_to.uk opus_mt_uk_no xx.ar.marian.translate_to.tr opus_mt_tr_ar xx.he.marian.translate_to.uk opus_mt_uk_he xx.sv.marian.translate_to.tvl opus_mt_tvl_sv xx.uk.marian.translate_to.sv opus_mt_sv_uk xx.fr.marian.translate_to.tvl opus_mt_tvl_fr xx.bg.marian.translate_to.uk opus_mt_uk_bg xx.fi.marian.translate_to.toi opus_mt_toi_fi xx.ca.marian.translate_to.uk opus_mt_uk_ca xx.fr.marian.translate_to.uk opus_mt_uk_fr xx.eo.marian.translate_to.tr opus_mt_tr_eo xx.uk.marian.translate_to.tr opus_mt_tr_uk xx.es.marian.translate_to.tl opus_mt_tl_es xx.es.marian.translate_to.tr opus_mt_tr_es xx.it.marian.translate_to.uk opus_mt_uk_it xx.fi.marian.translate_to.uk opus_mt_uk_fi xx.lt.marian.translate_to.tr opus_mt_tr_lt xx.es.marian.translate_to.swc opus_mt_swc_es xx.umb.marian.translate_to.sv opus_mt_sv_umb xx.sv.marian.translate_to.tw opus_mt_tw_sv xx.urj.marian.translate_to.urj opus_mt_urj_urj xx.yap.marian.translate_to.sv opus_mt_sv_yap xx.fr.marian.translate_to.ty opus_mt_ty_fr xx.fr.marian.translate_to.swc opus_mt_swc_fr xx.pt.marian.translate_to.tl opus_mt_tl_pt xx.tr.marian.translate_to.uk opus_mt_uk_tr xx.sv.marian.translate_to.tr opus_mt_tr_sv xx.fi.marian.translate_to.tvl opus_mt_tvl_fi xx.es.marian.translate_to.tn opus_mt_tn_es xx.fi.marian.translate_to.swc opus_mt_swc_fi xx.fr.marian.translate_to.toi opus_mt_toi_fr xx.fi.marian.translate_to.ts opus_mt_ts_fi xx.de.marian.translate_to.uk opus_mt_uk_de xx.sv.marian.translate_to.uk opus_mt_uk_sv xx.fi.marian.translate_to.tw opus_mt_tw_fi xx.sv.marian.translate_to.to opus_mt_to_sv xx.sv.marian.translate_to.tll opus_mt_tll_sv xx.fr.marian.translate_to.th opus_mt_th_fr xx.es.marian.translate_to.ty opus_mt_ty_es xx.fr.marian.translate_to.tw opus_mt_tw_fr xx.fr.marian.translate_to.to opus_mt_to_fr xx.sl.marian.translate_to.uk opus_mt_uk_sl xx.xh.marian.translate_to.sv opus_mt_sv_xh xx.war.marian.translate_to.sv opus_mt_sv_war xx.hu.marian.translate_to.uk opus_mt_uk_hu xx.ru.marian.translate_to.uk opus_mt_uk_ru xx.sv.marian.translate_to.tn opus_mt_tn_sv xx.fr.marian.translate_to.tum opus_mt_tum_fr xx.sv.marian.translate_to.toi opus_mt_toi_sv xx.sv.marian.translate_to.ty opus_mt_ty_sv xx.fr.marian.translate_to.tr opus_mt_tr_fr xx.fr.marian.translate_to.tn opus_mt_tn_fr xx.cs.marian.translate_to.uk opus_mt_uk_cs xx.fr.marian.translate_to.ts opus_mt_ts_fr xx.sv.marian.translate_to.swc opus_mt_swc_sv xx.es.marian.translate_to.to opus_mt_to_es xx.es.marian.translate_to.uk opus_mt_uk_es xx.nl.marian.translate_to.uk opus_mt_uk_nl xx.zne.marian.translate_to.sv opus_mt_sv_zne xx.es.marian.translate_to.tvl opus_mt_tvl_es xx.pt.marian.translate_to.uk opus_mt_uk_pt xx.fr.marian.translate_to.tiv opus_mt_tiv_fr xx.fr.marian.translate_to.tll opus_mt_tll_fr xx.sh.marian.translate_to.uk opus_mt_uk_sh xx.wls.marian.translate_to.sv opus_mt_sv_wls xx.ve.marian.translate_to.sv opus_mt_sv_ve xx.es.marian.translate_to.tum opus_mt_tum_es xx.fi.marian.translate_to.tll opus_mt_tll_fi xx.es.marian.translate_to.tw opus_mt_tw_es xx.sv.marian.translate_to.tiv opus_mt_tiv_sv xx.fi.marian.translate_to.ty opus_mt_ty_fi xx.pl.marian.translate_to.uk opus_mt_uk_pl xx.sv.marian.translate_to.tpi opus_mt_tpi_sv xx.az.marian.translate_to.tr opus_mt_tr_az xx.es.marian.translate_to.tll opus_mt_tll_es xx.ty.marian.translate_to.sv opus_mt_sv_ty xx.tzo.marian.translate_to.es opus_mt_es_tzo xx.sv.marian.translate_to.crs opus_mt_crs_sv xx.es.marian.translate_to.zai opus_mt_zai_es xx.niu.marian.translate_to.de opus_mt_de_niu xx.sv.marian.translate_to.nso opus_mt_nso_sv xx.fr.marian.translate_to.bg opus_mt_bg_fr xx.es.marian.translate_to.lus opus_mt_lus_es xx.es.marian.translate_to.nl opus_mt_nl_es xx.fr.marian.translate_to.yo opus_mt_yo_fr xx.sv.marian.translate_to.ilo opus_mt_ilo_sv xx.es.marian.translate_to.ts opus_mt_ts_es xx.run.marian.translate_to.fr opus_mt_fr_run xx.to.marian.translate_to.es opus_mt_es_to xx.ceb.marian.translate_to.fi opus_mt_fi_ceb xx.it.marian.translate_to.ja opus_mt_ja_it xx.es.marian.translate_to.sn opus_mt_sn_es xx.yo.marian.translate_to.sv opus_mt_sv_yo xx.tr.marian.translate_to.az opus_mt_az_tr xx.fr.marian.translate_to.no opus_mt_no_fr xx.tn.marian.translate_to.fr opus_mt_fr_tn xx.id.marian.translate_to.fr opus_mt_fr_id xx.de.marian.translate_to.ca opus_mt_ca_de xx.sv.marian.translate_to.tum opus_mt_tum_sv xx.ru.marian.translate_to.da opus_mt_da_ru xx.de.marian.translate_to.tl opus_mt_tl_de xx.eo.marian.translate_to.fr opus_mt_fr_eo xx.vi.marian.translate_to.zh opus_mt_zh_vi xx.es.marian.translate_to.vi opus_mt_vi_es xx.es.marian.translate_to.mfe opus_mt_mfe_es xx.fi.marian.translate_to.iso opus_mt_iso_fi xx.es.marian.translate_to.tzo opus_mt_tzo_es xx.sn.marian.translate_to.es opus_mt_es_sn xx.es.marian.translate_to.xh opus_mt_xh_es xx.sv.marian.translate_to.zne opus_mt_zne_sv xx.sv.marian.translate_to.ts opus_mt_ts_sv xx.it.marian.translate_to.zh opus_mt_zh_it xx.uk.marian.translate_to.zh opus_mt_zh_uk xx.fi.marian.translate_to.yo opus_mt_yo_fi xx.sv.marian.translate_to.war opus_mt_war_sv xx.sv.marian.translate_to.yo opus_mt_yo_sv xx.tll.marian.translate_to.es opus_mt_es_tll xx.nl.marian.translate_to.zh opus_mt_zh_nl xx.fr.marian.translate_to.wls opus_mt_wls_fr xx.it.marian.translate_to.vi opus_mt_vi_it xx.bg.marian.translate_to.zh opus_mt_zh_bg xx.sv.marian.translate_to.xh opus_mt_xh_sv xx.es.marian.translate_to.zne opus_mt_zne_es xx.zlw.marian.translate_to.zlw opus_mt_zlw_zlw xx.sv.marian.translate_to.yap opus_mt_yap_sv xx.he.marian.translate_to.zh opus_mt_zh_he xx.fr.marian.translate_to.xh opus_mt_xh_fr xx.fi.marian.translate_to.war opus_mt_war_fi xx.sv.marian.translate_to.zh opus_mt_zh_sv xx.zls.marian.translate_to.zls opus_mt_zls_zls xx.fi.marian.translate_to.zne opus_mt_zne_fi xx.es.marian.translate_to.ve opus_mt_ve_es xx.de.marian.translate_to.vi opus_mt_vi_de xx.eo.marian.translate_to.vi opus_mt_vi_eo xx.sv.marian.translate_to.wls opus_mt_wls_sv xx.es.marian.translate_to.war opus_mt_war_es xx.ru.marian.translate_to.vi opus_mt_vi_ru xx.ms.marian.translate_to.zh opus_mt_zh_ms xx.fr.marian.translate_to.zne opus_mt_zne_fr xx.fr.marian.translate_to.yap opus_mt_yap_fr xx.de.marian.translate_to.zh opus_mt_zh_de xx.es.marian.translate_to.yo opus_mt_yo_es xx.es.marian.translate_to.vsl opus_mt_vsl_es xx.zle.marian.translate_to.zle opus_mt_zle_zle xx.fr.marian.translate_to.vi opus_mt_vi_fr xx.fr.marian.translate_to.war opus_mt_war_fr xx.fi.marian.translate_to.zh opus_mt_zh_fi xx.he.marian.translate_to.it opus_tatoeba_he_it xx.es.marian.translate_to.zh opus_tatoeba_es_zh xx.es.translate_to.af translate_af_es xx.nl.translate_to.af translate_af_nl xx.eo.translate_to.af translate_af_eo xx.afa.translate_to.afa translate_afa_afa xx.sv.translate_to.af translate_af_sv xx.es.translate_to.aed translate_aed_es xx.fr.translate_to.af translate_af_fr xx.fi.translate_to.af translate_af_fi xx.de.translate_to.af translate_af_de xx.ru.translate_to.af translate_af_ru xx.es.translate_to.az translate_az_es xx.de.translate_to.bcl translate_bcl_de xx.sv.translate_to.bem translate_bem_sv xx.tr.translate_to.az translate_az_tr xx.sv.translate_to.bcl translate_bcl_sv xx.es.translate_to.ar translate_ar_es xx.es.translate_to.bem translate_bem_es xx.ru.translate_to.ar translate_ar_ru xx.es.translate_to.be translate_be_es xx.fr.translate_to.bem translate_bem_fr xx.he.translate_to.ar translate_ar_he xx.es.translate_to.bcl translate_bcl_es xx.es.translate_to.ase translate_ase_es xx.de.translate_to.ar translate_ar_de xx.pl.translate_to.ar translate_ar_pl xx.tr.translate_to.ar translate_ar_tr xx.sv.translate_to.ase translate_ase_sv xx.fi.translate_to.bcl translate_bcl_fi xx.el.translate_to.ar translate_ar_el xx.fr.translate_to.bcl translate_bcl_fr xx.fi.translate_to.bem translate_bem_fi xx.fr.translate_to.ase translate_ase_fr xx.fr.translate_to.ar translate_ar_fr xx.eo.translate_to.ar translate_ar_eo xx.it.translate_to.ar translate_ar_it xx.sv.translate_to.am translate_am_sv xx.de.translate_to.ase translate_ase_de xx.uk.translate_to.bg translate_bg_uk xx.it.translate_to.bg translate_bg_it xx.sv.translate_to.bzs translate_bzs_sv xx.pt.translate_to.ca translate_ca_pt xx.es.translate_to.ber translate_ber_es xx.it.translate_to.ca translate_ca_it xx.eo.translate_to.bg translate_bg_eo xx.sv.translate_to.ceb translate_ceb_sv xx.fr.translate_to.bi translate_bi_fr xx.sv.translate_to.bg translate_bg_sv xx.fr.translate_to.ca translate_ca_fr xx.tr.translate_to.bg translate_bg_tr xx.es.translate_to.ceb translate_ceb_es xx.de.translate_to.ca translate_ca_de xx.fi.translate_to.ceb translate_ceb_fi xx.es.translate_to.ca translate_ca_es xx.es.translate_to.bg translate_bg_es xx.uk.translate_to.ca translate_ca_uk xx.sv.translate_to.bi translate_bi_sv xx.sv.translate_to.chk translate_chk_sv xx.fr.translate_to.ceb translate_ceb_fr xx.es.translate_to.bzs translate_bzs_es xx.de.translate_to.crs translate_crs_de xx.nl.translate_to.ca translate_ca_nl xx.es.translate_to.chk translate_chk_es xx.fr.translate_to.ber translate_ber_fr xx.fi.translate_to.bzs translate_bzs_fi xx.es.translate_to.crs translate_crs_es xx.fi.translate_to.bg translate_bg_fi xx.cpp.translate_to.cpp translate_cpp_cpp xx.de.translate_to.bg translate_bg_de xx.es.translate_to.bi translate_bi_es xx.fr.translate_to.bzs translate_bzs_fr xx.fr.translate_to.bg translate_bg_fr xx.fr.translate_to.chk translate_chk_fr xx.ru.translate_to.bg translate_bg_ru xx.fi.translate_to.cs translate_cs_fi xx.ha.translate_to.de translate_de_ha xx.ee.translate_to.de translate_de_ee xx.eo.translate_to.de translate_de_eo xx.gil.translate_to.de translate_de_gil xx.fj.translate_to.de translate_de_fj xx.fr.translate_to.de translate_de_fr xx.sv.translate_to.cs translate_cs_sv xx.es.translate_to.csn translate_csn_es xx.ru.translate_to.da translate_da_ru xx.no.translate_to.da translate_da_no xx.iso.translate_to.de translate_de_iso xx.eu.translate_to.de translate_de_eu xx.nl.translate_to.de translate_de_nl xx.ilo.translate_to.de translate_de_ilo xx.hr.translate_to.de translate_de_hr xx.mt.translate_to.de translate_de_mt xx.es.translate_to.da translate_da_es xx.ar.translate_to.de translate_de_ar xx.is.translate_to.de translate_de_is xx.sv.translate_to.crs translate_crs_sv xx.fr.translate_to.da translate_da_fr xx.gaa.translate_to.de translate_de_gaa xx.niu.translate_to.de translate_de_niu xx.da.translate_to.de translate_de_da xx.de.translate_to.da translate_da_de xx.ase.translate_to.de translate_de_ase xx.ig.translate_to.de translate_de_ig xx.lua.translate_to.de translate_de_lua xx.de.translate_to.de translate_de_de xx.bi.translate_to.de translate_de_bi xx.fr.translate_to.cs translate_cs_fr xx.ms.translate_to.de translate_de_ms xx.fi.translate_to.crs translate_crs_fi xx.eo.translate_to.da translate_da_eo xx.af.translate_to.de translate_de_af xx.uk.translate_to.cs translate_cs_uk xx.bg.translate_to.de translate_de_bg xx.no.translate_to.de translate_de_no xx.de.translate_to.cs translate_cs_de xx.it.translate_to.de translate_de_it xx.ho.translate_to.de translate_de_ho xx.ln.translate_to.de translate_de_ln xx.guw.translate_to.de translate_de_guw xx.efi.translate_to.de translate_de_efi xx.hil.translate_to.de translate_de_hil xx.cs.translate_to.de translate_de_cs xx.es.translate_to.csg translate_csg_es xx.es.translate_to.de translate_de_es xx.bcl.translate_to.de translate_de_bcl xx.ht.translate_to.de translate_de_ht xx.loz.translate_to.de translate_de_loz xx.kg.translate_to.de translate_de_kg xx.eo.translate_to.cs translate_cs_eo xx.el.translate_to.de translate_de_el xx.fi.translate_to.de translate_de_fi xx.he.translate_to.de translate_de_he xx.bzs.translate_to.de translate_de_bzs xx.fr.translate_to.crs translate_crs_fr xx.crs.translate_to.de translate_de_crs xx.fi.translate_to.da translate_da_fi xx.hu.translate_to.de translate_de_hu xx.et.translate_to.de translate_de_et xx.lt.translate_to.de translate_de_lt xx.ca.translate_to.de translate_de_ca xx.pl.translate_to.de translate_de_pl xx.sv.translate_to.el translate_el_sv xx.de.translate_to.ee translate_ee_de xx.pag.translate_to.de translate_de_pag xx.ar.translate_to.el translate_el_ar xx.nso.translate_to.de translate_de_nso xx.pon.translate_to.de translate_de_pon xx.pap.translate_to.de translate_de_pap xx.fr.translate_to.efi translate_efi_fr xx.pis.translate_to.de translate_de_pis xx.de.translate_to.efi translate_efi_de xx.eo.translate_to.el translate_el_eo xx.fi.translate_to.ee translate_ee_fi xx.es.translate_to.ee translate_ee_es xx.fr.translate_to.ee translate_ee_fr xx.fi.translate_to.efi translate_efi_fi xx.fr.translate_to.el translate_el_fr xx.tl.translate_to.de translate_de_tl xx.ny.translate_to.de translate_de_ny xx.uk.translate_to.de translate_de_uk xx.sv.translate_to.efi translate_efi_sv xx.sv.translate_to.ee translate_ee_sv xx.vi.translate_to.de translate_de_vi xx.fi.translate_to.el translate_el_fi xx.cs.translate_to.eo translate_eo_cs xx.bzs.translate_to.es translate_es_bzs xx.he.translate_to.eo translate_eo_he xx.hu.translate_to.eo translate_eo_hu xx.ro.translate_to.eo translate_eo_ro xx.ber.translate_to.es translate_es_ber xx.ca.translate_to.es translate_es_ca xx.bcl.translate_to.es translate_es_bcl xx.ceb.translate_to.es translate_es_ceb xx.da.translate_to.eo translate_eo_da xx.bi.translate_to.es translate_es_bi xx.ee.translate_to.es translate_es_ee xx.ru.translate_to.eo translate_eo_ru xx.csg.translate_to.es translate_es_csg xx.fi.translate_to.eo translate_eo_fi xx.it.translate_to.eo translate_eo_it xx.nl.translate_to.eo translate_eo_nl xx.et.translate_to.es translate_es_et xx.bg.translate_to.es translate_es_bg xx.de.translate_to.eo translate_eo_de xx.ar.translate_to.es translate_es_ar xx.cs.translate_to.es translate_es_cs xx.aed.translate_to.es translate_es_aed xx.ase.translate_to.es translate_es_ase xx.el.translate_to.es translate_es_el xx.eo.translate_to.es translate_es_eo xx.af.translate_to.eo translate_eo_af xx.af.translate_to.es translate_es_af xx.pl.translate_to.eo translate_eo_pl xx.de.translate_to.es translate_es_de xx.es.translate_to.eo translate_eo_es xx.da.translate_to.es translate_es_da xx.crs.translate_to.es translate_es_crs xx.pt.translate_to.eo translate_eo_pt xx.eu.translate_to.es translate_es_eu xx.es.translate_to.es translate_es_es xx.csn.translate_to.es translate_es_csn xx.sv.translate_to.eo translate_eo_sv xx.efi.translate_to.es translate_es_efi xx.sh.translate_to.eo translate_eo_sh xx.bg.translate_to.eo translate_eo_bg xx.fr.translate_to.eo translate_eo_fr xx.el.translate_to.eo translate_eo_el xx.pl.translate_to.es translate_es_pl xx.ro.translate_to.es translate_es_ro xx.is.translate_to.es translate_es_is xx.ln.translate_to.es translate_es_ln xx.to.translate_to.es translate_es_to xx.no.translate_to.es translate_es_no xx.nl.translate_to.es translate_es_nl xx.pag.translate_to.es translate_es_pag xx.tvl.translate_to.es translate_es_tvl xx.fr.translate_to.es translate_es_fr xx.he.translate_to.es translate_es_he xx.lus.translate_to.es translate_es_lus xx.hil.translate_to.es translate_es_hil xx.ny.translate_to.es translate_es_ny xx.pap.translate_to.es translate_es_pap xx.id.translate_to.es translate_es_id xx.wls.translate_to.es translate_es_wls xx.gaa.translate_to.es translate_es_gaa xx.nso.translate_to.es translate_es_nso xx.mk.translate_to.es translate_es_mk xx.mt.translate_to.es translate_es_mt xx.pis.translate_to.es translate_es_pis xx.gl.translate_to.es translate_es_gl xx.sn.translate_to.es translate_es_sn xx.hr.translate_to.es translate_es_hr xx.swc.translate_to.es translate_es_swc xx.lua.translate_to.es translate_es_lua xx.it.translate_to.es translate_es_it xx.fj.translate_to.es translate_es_fj xx.gil.translate_to.es translate_es_gil xx.sm.translate_to.es translate_es_sm xx.guw.translate_to.es translate_es_guw xx.kg.translate_to.es translate_es_kg xx.tl.translate_to.es translate_es_tl xx.rn.translate_to.es translate_es_rn xx.mfs.translate_to.es translate_es_mfs xx.iso.translate_to.es translate_es_iso xx.loz.translate_to.es translate_es_loz xx.tpi.translate_to.es translate_es_tpi xx.ha.translate_to.es translate_es_ha xx.ht.translate_to.es translate_es_ht xx.uk.translate_to.es translate_es_uk xx.tw.translate_to.es translate_es_tw xx.st.translate_to.es translate_es_st xx.sg.translate_to.es translate_es_sg xx.ilo.translate_to.es translate_es_ilo xx.ru.translate_to.es translate_es_ru xx.yo.translate_to.es translate_es_yo xx.pon.translate_to.es translate_es_pon xx.niu.translate_to.es translate_es_niu xx.lt.translate_to.es translate_es_lt xx.ty.translate_to.es translate_es_ty xx.ig.translate_to.es translate_es_ig xx.tzo.translate_to.es translate_es_tzo xx.rw.translate_to.es translate_es_rw xx.war.translate_to.es translate_es_war xx.tll.translate_to.es translate_es_tll xx.prl.translate_to.es translate_es_prl xx.xh.translate_to.es translate_es_xh xx.yua.translate_to.es translate_es_yua xx.ho.translate_to.es translate_es_ho xx.ve.translate_to.es translate_es_ve xx.sl.translate_to.es translate_es_sl xx.tn.translate_to.es translate_es_tn xx.vi.translate_to.es translate_es_vi xx.srn.translate_to.es translate_es_srn xx.fi.translate_to.es translate_es_fi xx.lua.translate_to.fi translate_fi_lua xx.ny.translate_to.fi translate_fi_ny xx.pon.translate_to.fi translate_fi_pon xx.crs.translate_to.fi translate_fi_crs xx.nso.translate_to.fi translate_fi_nso xx.iso.translate_to.fi translate_fi_iso xx.kqn.translate_to.fi translate_fi_kqn xx.gaa.translate_to.fi translate_fi_gaa xx.ru.translate_to.eu translate_eu_ru xx.eo.translate_to.fi translate_fi_eo xx.ig.translate_to.fi translate_fi_ig xx.bem.translate_to.fi translate_fi_bem xx.es.translate_to.et translate_et_es xx.fj.translate_to.fi translate_fi_fj xx.et.translate_to.fi translate_fi_et xx.bcl.translate_to.fi translate_fi_bcl xx.fi.translate_to.fi translate_fi_fi xx.el.translate_to.fi translate_fi_el xx.efi.translate_to.fi translate_fi_efi xx.ht.translate_to.fi translate_fi_ht xx.ceb.translate_to.fi translate_fi_ceb xx.lg.translate_to.fi translate_fi_lg xx.pap.translate_to.fi translate_fi_pap xx.kg.translate_to.fi translate_fi_kg xx.ee.translate_to.fi translate_fi_ee xx.lv.translate_to.fi translate_fi_lv xx.fr.translate_to.et translate_et_fr xx.de.translate_to.et translate_et_de xx.bzs.translate_to.fi translate_fi_bzs xx.mos.translate_to.fi translate_fi_mos xx.zh.translate_to.es translate_es_zh xx.id.translate_to.fi translate_fi_id xx.gil.translate_to.fi translate_fi_gil xx.pis.translate_to.fi translate_fi_pis xx.no.translate_to.fi translate_fi_no xx.it.translate_to.fi translate_fi_it xx.es.translate_to.fi translate_fi_es xx.ha.translate_to.fi translate_fi_ha xx.fr.translate_to.fi translate_fi_fr xx.de.translate_to.fi translate_fi_de xx.bg.translate_to.fi translate_fi_bg xx.zai.translate_to.es translate_es_zai xx.hil.translate_to.fi translate_fi_hil xx.cs.translate_to.fi translate_fi_cs xx.es.translate_to.eu translate_eu_es xx.ilo.translate_to.fi translate_fi_ilo xx.pag.translate_to.fi translate_fi_pag xx.ln.translate_to.fi translate_fi_ln xx.sv.translate_to.et translate_et_sv xx.niu.translate_to.fi translate_fi_niu xx.hr.translate_to.fi translate_fi_hr xx.de.translate_to.eu translate_eu_de xx.lus.translate_to.fi translate_fi_lus xx.ru.translate_to.et translate_et_ru xx.af.translate_to.fi translate_fi_af xx.mh.translate_to.fi translate_fi_mh xx.guw.translate_to.fi translate_fi_guw xx.mfe.translate_to.fi translate_fi_mfe xx.ho.translate_to.fi translate_fi_ho xx.fse.translate_to.fi translate_fi_fse xx.lu.translate_to.fi translate_fi_lu xx.hu.translate_to.fi translate_fi_hu xx.mk.translate_to.fi translate_fi_mk xx.nl.translate_to.fi translate_fi_nl xx.mg.translate_to.fi translate_fi_mg xx.mt.translate_to.fi translate_fi_mt xx.he.translate_to.fi translate_fi_he xx.fi.translate_to.et translate_et_fi xx.is.translate_to.fi translate_fi_is xx.lue.translate_to.fi translate_fi_lue xx.guw.translate_to.fr translate_fr_guw xx.ber.translate_to.fr translate_fr_ber xx.uk.translate_to.fi translate_fi_uk xx.efi.translate_to.fr translate_fr_efi xx.tr.translate_to.fi translate_fi_tr xx.tn.translate_to.fi translate_fi_tn xx.es.translate_to.fr translate_fr_es xx.srn.translate_to.fi translate_fi_srn xx.bcl.translate_to.fr translate_fr_bcl xx.sl.translate_to.fi translate_fi_sl xx.ht.translate_to.fr translate_fr_ht xx.zne.translate_to.fi translate_fi_zne xx.de.translate_to.fr translate_fr_de xx.war.translate_to.fi translate_fi_war xx.tpi.translate_to.fi translate_fi_tpi xx.ca.translate_to.fr translate_fr_ca xx.yap.translate_to.fi translate_fi_yap xx.sn.translate_to.fi translate_fi_sn xx.hr.translate_to.fr translate_fr_hr xx.gil.translate_to.fr translate_fr_gil xx.id.translate_to.fr translate_fr_id xx.sv.translate_to.fi translate_fi_sv xx.toi.translate_to.fi translate_fi_toi xx.sk.translate_to.fi translate_fi_sk xx.he.translate_to.fr translate_fr_he xx.sq.translate_to.fi translate_fi_sq xx.ve.translate_to.fi translate_fi_ve xx.tw.translate_to.fi translate_fi_tw xx.tvl.translate_to.fi translate_fi_tvl xx.hil.translate_to.fr translate_fr_hil xx.sw.translate_to.fi translate_fi_sw xx.eo.translate_to.fr translate_fr_eo xx.xh.translate_to.fi translate_fi_xh xx.bi.translate_to.fr translate_fr_bi xx.ru.translate_to.fi translate_fi_ru xx.ceb.translate_to.fr translate_fr_ceb xx.ig.translate_to.fr translate_fr_ig xx.el.translate_to.fr translate_fr_el xx.sm.translate_to.fi translate_fi_sm xx.to.translate_to.fi translate_fi_to xx.ase.translate_to.fr translate_fr_ase xx.yo.translate_to.fi translate_fi_yo xx.sg.translate_to.fi translate_fi_sg xx.rw.translate_to.fi translate_fi_rw xx.ts.translate_to.fi translate_fi_ts xx.wls.translate_to.fi translate_fi_wls xx.ho.translate_to.fr translate_fr_ho xx.tll.translate_to.fi translate_fi_tll xx.st.translate_to.fi translate_fi_st xx.fiu.translate_to.fiu translate_fiu_fiu xx.ro.translate_to.fi translate_fi_ro xx.tiv.translate_to.fi translate_fi_tiv xx.ha.translate_to.fr translate_fr_ha xx.ee.translate_to.fr translate_fr_ee xx.gaa.translate_to.fr translate_fr_gaa xx.hu.translate_to.fr translate_fr_hu xx.ty.translate_to.fi translate_fi_ty xx.fr.translate_to.fj translate_fj_fr xx.run.translate_to.fi translate_fi_run xx.bem.translate_to.fr translate_fr_bem xx.bzs.translate_to.fr translate_fr_bzs xx.fj.translate_to.fr translate_fr_fj xx.ar.translate_to.fr translate_fr_ar xx.swc.translate_to.fi translate_fi_swc xx.crs.translate_to.fr translate_fr_crs xx.bg.translate_to.fr translate_fr_bg xx.af.translate_to.fr translate_fr_af xx.loz.translate_to.fr translate_fr_loz xx.st.translate_to.fr translate_fr_st xx.tn.translate_to.fr translate_fr_tn xx.srn.translate_to.fr translate_fr_srn xx.to.translate_to.fr translate_fr_to xx.sk.translate_to.fr translate_fr_sk xx.tum.translate_to.fr translate_fr_tum xx.ts.translate_to.fr translate_fr_ts xx.iso.translate_to.fr translate_fr_iso xx.sv.translate_to.fr translate_fr_sv xx.mt.translate_to.fr translate_fr_mt xx.pap.translate_to.fr translate_fr_pap xx.wls.translate_to.fr translate_fr_wls xx.lua.translate_to.fr translate_fr_lua xx.ro.translate_to.fr translate_fr_ro xx.tll.translate_to.fr translate_fr_tll xx.ilo.translate_to.fr translate_fr_ilo xx.ve.translate_to.fr translate_fr_ve xx.ny.translate_to.fr translate_fr_ny xx.tpi.translate_to.fr translate_fr_tpi xx.uk.translate_to.fr translate_fr_uk xx.ln.translate_to.fr translate_fr_ln xx.mfe.translate_to.fr translate_fr_mfe xx.lue.translate_to.fr translate_fr_lue xx.mos.translate_to.fr translate_fr_mos xx.pon.translate_to.fr translate_fr_pon xx.tvl.translate_to.fr translate_fr_tvl xx.run.translate_to.fr translate_fr_run xx.pag.translate_to.fr translate_fr_pag xx.sg.translate_to.fr translate_fr_sg xx.no.translate_to.fr translate_fr_no xx.ty.translate_to.fr translate_fr_ty xx.tl.translate_to.fr translate_fr_tl xx.sl.translate_to.fr translate_fr_sl xx.tiv.translate_to.fr translate_fr_tiv xx.rw.translate_to.fr translate_fr_rw xx.lus.translate_to.fr translate_fr_lus xx.swc.translate_to.fr translate_fr_swc xx.sm.translate_to.fr translate_fr_sm xx.pl.translate_to.fr translate_fr_pl xx.kg.translate_to.fr translate_fr_kg xx.niu.translate_to.fr translate_fr_niu xx.lg.translate_to.fr translate_fr_lg xx.ms.translate_to.fr translate_fr_ms xx.nso.translate_to.fr translate_fr_nso xx.war.translate_to.fr translate_fr_war xx.xh.translate_to.fr translate_fr_xh xx.pis.translate_to.fr translate_fr_pis xx.tw.translate_to.fr translate_fr_tw xx.kwy.translate_to.fr translate_fr_kwy xx.rnd.translate_to.fr translate_fr_rnd xx.vi.translate_to.fr translate_fr_vi xx.lu.translate_to.fr translate_fr_lu xx.mh.translate_to.fr translate_fr_mh xx.ru.translate_to.fr translate_fr_ru xx.sn.translate_to.fr translate_fr_sn xx.kqn.translate_to.fr translate_fr_kqn xx.ar.translate_to.he translate_he_ar xx.de.translate_to.he translate_he_de xx.es.translate_to.gil translate_gil_es xx.de.translate_to.gaa translate_gaa_de xx.fr.translate_to.hu translate_hu_fr xx.fr.translate_to.gil translate_gil_fr xx.de.translate_to.guw translate_guw_de xx.fr.translate_to.ht translate_ht_fr xx.uk.translate_to.he translate_he_uk xx.fi.translate_to.hu translate_hu_fi xx.uk.translate_to.hu translate_hu_uk xx.zne.translate_to.fr translate_fr_zne xx.sv.translate_to.gaa translate_gaa_sv xx.es.translate_to.guw translate_guw_es xx.gmq.translate_to.gmq translate_gmq_gmq xx.fi.translate_to.hil translate_hil_fi xx.fi.translate_to.guw translate_guw_fi xx.es.translate_to.he translate_he_es xx.ur.translate_to.hi translate_hi_ur xx.de.translate_to.hil translate_hil_de xx.gmw.translate_to.gmw translate_gmw_gmw xx.fi.translate_to.gaa translate_gaa_fi xx.fi.translate_to.he translate_he_fi xx.eo.translate_to.hu translate_hu_eo xx.fi.translate_to.ht translate_ht_fi xx.yo.translate_to.fr translate_fr_yo xx.sv.translate_to.hr translate_hr_sv xx.fr.translate_to.ha translate_ha_fr xx.fi.translate_to.ha translate_ha_fi xx.sv.translate_to.ha translate_ha_sv xx.pt.translate_to.gl translate_gl_pt xx.fr.translate_to.guw translate_guw_fr xx.es.translate_to.ht translate_ht_es xx.de.translate_to.hu translate_hu_de xx.sv.translate_to.ht translate_ht_sv xx.es.translate_to.hr translate_hr_es xx.fr.translate_to.gaa translate_gaa_fr xx.ru.translate_to.he translate_he_ru xx.es.translate_to.gl translate_gl_es xx.ru.translate_to.hy translate_hy_ru xx.fi.translate_to.gil translate_gil_fi xx.sv.translate_to.hu translate_hu_sv xx.sv.translate_to.gil translate_gil_sv xx.fi.translate_to.fse translate_fse_fi xx.gem.translate_to.gem translate_gem_gem xx.es.translate_to.ha translate_ha_es xx.it.translate_to.he translate_he_it xx.sv.translate_to.guw translate_guw_sv xx.sv.translate_to.he translate_he_sv xx.yap.translate_to.fr translate_fr_yap xx.fr.translate_to.hr translate_hr_fr xx.eo.translate_to.he translate_he_eo xx.es.translate_to.gaa translate_gaa_es xx.fi.translate_to.hr translate_hr_fi xx.fr.translate_to.he translate_he_fr xx.fi.translate_to.ilo translate_ilo_fi xx.sv.translate_to.iso translate_iso_sv xx.he.translate_to.ja translate_ja_he xx.fi.translate_to.id translate_id_fi xx.de.translate_to.ja translate_ja_de xx.he.translate_to.it translate_it_he xx.it.translate_to.ja translate_ja_it xx.is.translate_to.it translate_it_is xx.bg.translate_to.ja translate_ja_bg xx.de.translate_to.ig translate_ig_de xx.bg.translate_to.it translate_it_bg xx.es.translate_to.id translate_id_es xx.fr.translate_to.id translate_id_fr xx.es.translate_to.ja translate_ja_es xx.sv.translate_to.ja translate_ja_sv xx.es.translate_to.iso translate_iso_es xx.es.translate_to.ilo translate_ilo_es xx.it.translate_to.is translate_is_it xx.sv.translate_to.it translate_it_sv xx.sv.translate_to.is translate_is_sv xx.ru.translate_to.ja translate_ja_ru xx.es.translate_to.kg translate_kg_es xx.fi.translate_to.ig translate_ig_fi xx.fr.translate_to.iso translate_iso_fr xx.de.translate_to.ko translate_ko_de xx.sv.translate_to.ilo translate_ilo_sv xx.es.translate_to.is translate_is_es xx.da.translate_to.ja translate_ja_da xx.nl.translate_to.ja translate_ja_nl xx.inc.translate_to.inc translate_inc_inc xx.de.translate_to.is translate_is_de xx.fr.translate_to.is translate_is_fr xx.lt.translate_to.it translate_it_lt xx.sv.translate_to.ig translate_ig_sv xx.de.translate_to.ilo translate_ilo_de xx.ar.translate_to.it translate_it_ar xx.fr.translate_to.kg translate_kg_fr xx.vi.translate_to.ja translate_ja_vi xx.ru.translate_to.ka translate_ka_ru xx.uk.translate_to.it translate_it_uk xx.vi.translate_to.it translate_it_vi xx.ms.translate_to.it translate_it_ms xx.ar.translate_to.ja translate_ja_ar xx.eo.translate_to.is translate_is_eo xx.ca.translate_to.it translate_it_ca xx.sh.translate_to.ja translate_ja_sh xx.fi.translate_to.ja translate_ja_fi xx.iir.translate_to.iir translate_iir_iir xx.itc.translate_to.itc translate_itc_itc xx.ms.translate_to.ja translate_ja_ms xx.fr.translate_to.it translate_it_fr xx.fr.translate_to.ja translate_ja_fr xx.pt.translate_to.ja translate_ja_pt xx.eo.translate_to.it translate_it_eo xx.fi.translate_to.iso translate_iso_fi xx.pl.translate_to.ja translate_ja_pl xx.tr.translate_to.ja translate_ja_tr xx.es.translate_to.ig translate_ig_es xx.fr.translate_to.ig translate_ig_fr xx.sv.translate_to.id translate_id_sv xx.hu.translate_to.ja translate_ja_hu xx.sv.translate_to.kg translate_kg_sv xx.es.translate_to.it translate_it_es xx.ine.translate_to.ine translate_ine_ine xx.de.translate_to.it translate_it_de xx.fi.translate_to.is translate_is_fi xx.es.translate_to.mk translate_mk_es xx.es.translate_to.lue translate_lue_es xx.es.translate_to.lv translate_lv_es xx.fi.translate_to.lue translate_lue_fi xx.es.translate_to.ln translate_ln_es xx.fr.translate_to.loz translate_loz_fr xx.sv.translate_to.kwy translate_kwy_sv xx.es.translate_to.lus translate_lus_es xx.fr.translate_to.lv translate_lv_fr xx.fr.translate_to.lu translate_lu_fr xx.de.translate_to.lt translate_lt_de xx.tr.translate_to.lt translate_lt_tr xx.fr.translate_to.lus translate_lus_fr xx.es.translate_to.mg translate_mg_es xx.sv.translate_to.lua translate_lua_sv xx.fr.translate_to.lg translate_lg_fr xx.fr.translate_to.kwy translate_kwy_fr xx.es.translate_to.lt translate_lt_es xx.sv.translate_to.ko translate_ko_sv xx.es.translate_to.kqn translate_kqn_es xx.fr.translate_to.ko translate_ko_fr xx.sv.translate_to.kqn translate_kqn_sv xx.fi.translate_to.ko translate_ko_fi xx.es.translate_to.mh translate_mh_es xx.fr.translate_to.lua translate_lua_fr xx.it.translate_to.lt translate_lt_it xx.sv.translate_to.lt translate_lt_sv xx.es.translate_to.lu translate_lu_es xx.fi.translate_to.lua translate_lua_fi xx.fr.translate_to.kqn translate_kqn_fr xx.de.translate_to.loz translate_loz_de xx.fr.translate_to.ms translate_ms_fr xx.fr.translate_to.lt translate_lt_fr xx.ru.translate_to.lv translate_lv_ru xx.ms.translate_to.ms translate_ms_ms xx.sv.translate_to.lus translate_lus_sv xx.fr.translate_to.lue translate_lue_fr xx.fi.translate_to.lu translate_lu_fi xx.eo.translate_to.lt translate_lt_eo xx.fi.translate_to.mk translate_mk_fi xx.es.translate_to.ko translate_ko_es xx.sv.translate_to.lue translate_lue_sv xx.pl.translate_to.lt translate_lt_pl xx.es.translate_to.mfe translate_mfe_es xx.fi.translate_to.loz translate_loz_fi xx.sv.translate_to.loz translate_loz_sv xx.ru.translate_to.ko translate_ko_ru xx.fi.translate_to.lg translate_lg_fi xx.fi.translate_to.mh translate_mh_fi xx.sv.translate_to.lv translate_lv_sv xx.hu.translate_to.ko translate_ko_hu xx.es.translate_to.lua translate_lua_es xx.fi.translate_to.lv translate_lv_fi xx.ru.translate_to.lt translate_lt_ru xx.de.translate_to.ms translate_ms_de xx.fi.translate_to.lus translate_lus_fi xx.es.translate_to.lg translate_lg_es xx.de.translate_to.ln translate_ln_de xx.es.translate_to.mfs translate_mfs_es xx.fr.translate_to.mk translate_mk_fr xx.fr.translate_to.ln translate_ln_fr xx.es.translate_to.loz translate_loz_es xx.sv.translate_to.lu translate_lu_sv xx.it.translate_to.ms translate_ms_it xx.sv.translate_to.lg translate_lg_sv xx.ar.translate_to.pl translate_pl_ar xx.fr.translate_to.ro translate_ro_fr xx.sv.translate_to.niu translate_niu_sv xx.eo.translate_to.pl translate_pl_eo xx.nl.translate_to.no translate_no_nl xx.es.translate_to.no translate_no_es xx.es.translate_to.pag translate_pag_es xx.ru.translate_to.rn translate_rn_ru xx.sv.translate_to.pag translate_pag_sv xx.uk.translate_to.pt translate_pt_uk xx.uk.translate_to.pl translate_pl_uk xx.de.translate_to.pl translate_pl_de xx.sv.translate_to.nl translate_nl_sv xx.fr.translate_to.no translate_no_fr xx.es.translate_to.niu translate_niu_es xx.uk.translate_to.no translate_no_uk xx.lt.translate_to.pl translate_pl_lt xx.tl.translate_to.pt translate_pt_tl xx.gl.translate_to.pt translate_pt_gl xx.da.translate_to.ru translate_ru_da xx.da.translate_to.no translate_no_da xx.uk.translate_to.nl translate_nl_uk xx.sv.translate_to.pon translate_pon_sv xx.fr.translate_to.pis translate_pis_fr xx.fr.translate_to.niu translate_niu_fr xx.af.translate_to.nl translate_nl_af xx.fi.translate_to.nso translate_nso_fi xx.fi.translate_to.pon translate_pon_fi xx.de.translate_to.pap translate_pap_de xx.de.translate_to.rn translate_rn_de xx.es.translate_to.pon translate_pon_es xx.es.translate_to.pis translate_pis_es xx.ca.translate_to.pt translate_pt_ca xx.sv.translate_to.rnd translate_rnd_sv xx.sv.translate_to.pl translate_pl_sv xx.ru.translate_to.no translate_no_ru xx.fi.translate_to.niu translate_niu_fi xx.de.translate_to.pag translate_pag_de xx.fr.translate_to.pl translate_pl_fr xx.fi.translate_to.no translate_no_fi xx.pl.translate_to.no translate_no_pl xx.de.translate_to.nso translate_nso_de xx.fr.translate_to.rn translate_rn_fr xx.sv.translate_to.nso translate_nso_sv xx.sv.translate_to.ro translate_ro_sv xx.no.translate_to.pl translate_pl_no xx.fr.translate_to.nl translate_nl_fr xx.es.translate_to.nso translate_nso_es xx.no.translate_to.nl translate_nl_no xx.fi.translate_to.pis translate_pis_fi xx.ca.translate_to.nl translate_nl_ca xx.es.translate_to.nl translate_nl_es xx.es.translate_to.ny translate_ny_es xx.fr.translate_to.pap translate_pap_fr xx.fi.translate_to.nl translate_nl_fi xx.sv.translate_to.no translate_no_sv xx.fr.translate_to.pon translate_pon_fr xx.fr.translate_to.rnd translate_rnd_fr xx.es.translate_to.pap translate_pap_es xx.es.translate_to.prl translate_prl_es xx.eo.translate_to.ro translate_ro_eo xx.sv.translate_to.pis translate_pis_sv xx.af.translate_to.ru translate_ru_af xx.fr.translate_to.nso translate_nso_fr xx.eo.translate_to.pt translate_pt_eo xx.ar.translate_to.ru translate_ru_ar xx.fr.translate_to.mt translate_mt_fr xx.es.translate_to.rn translate_rn_es xx.sv.translate_to.mt translate_mt_sv xx.de.translate_to.niu translate_niu_de xx.es.translate_to.mt translate_mt_es xx.es.translate_to.pl translate_pl_es xx.fi.translate_to.pag translate_pag_fi xx.de.translate_to.no translate_no_de xx.de.translate_to.ny translate_ny_de xx.fi.translate_to.mt translate_mt_fi xx.no.translate_to.no translate_no_no xx.eo.translate_to.nl translate_nl_eo xx.bg.translate_to.ru translate_ru_bg xx.fi.translate_to.pap translate_pap_fi xx.fi.translate_to.ro translate_ro_fi xx.sv.translate_to.st translate_st_sv xx.kg.translate_to.sv translate_sv_kg xx.sv.translate_to.sq translate_sq_sv xx.ee.translate_to.sv translate_sv_ee xx.es.translate_to.srn translate_srn_es xx.lv.translate_to.ru translate_ru_lv xx.cs.translate_to.sv translate_sv_cs xx.ha.translate_to.sv translate_sv_ha xx.kqn.translate_to.sv translate_sv_kqn xx.fr.translate_to.rw translate_rw_fr xx.fr.translate_to.sn translate_sn_fr xx.eu.translate_to.ru translate_ru_eu xx.fi.translate_to.st translate_st_fi xx.efi.translate_to.sv translate_sv_efi xx.ho.translate_to.sv translate_sv_ho xx.id.translate_to.sv translate_sv_id xx.eo.translate_to.sv translate_sv_eo xx.guw.translate_to.sv translate_sv_guw xx.sv.translate_to.sk translate_sk_sv xx.fr.translate_to.srn translate_srn_fr xx.ceb.translate_to.sv translate_sv_ceb xx.es.translate_to.sq translate_sq_es xx.sv.translate_to.rw translate_rw_sv xx.is.translate_to.sv translate_sv_is xx.es.translate_to.sm translate_sm_es xx.bcl.translate_to.sv translate_sv_bcl xx.kwy.translate_to.sv translate_sv_kwy xx.es.translate_to.run translate_run_es xx.el.translate_to.sv translate_sv_el xx.es.translate_to.sk translate_sk_es xx.iso.translate_to.sv translate_sv_iso xx.lu.translate_to.sv translate_sv_lu xx.af.translate_to.sv translate_sv_af xx.bg.translate_to.sv translate_sv_bg xx.fr.translate_to.sm translate_sm_fr xx.hr.translate_to.sv translate_sv_hr xx.sv.translate_to.sn translate_sn_sv xx.no.translate_to.ru translate_ru_no xx.fr.translate_to.sg translate_sg_fr xx.es.translate_to.sl translate_sl_es xx.bzs.translate_to.sv translate_sv_bzs xx.fr.translate_to.st translate_st_fr xx.hu.translate_to.sv translate_sv_hu xx.sv.translate_to.sg translate_sg_sv xx.sem.translate_to.sem translate_sem_sem xx.uk.translate_to.sh translate_sh_uk xx.ln.translate_to.sv translate_sv_ln xx.fi.translate_to.sk translate_sk_fi xx.ht.translate_to.sv translate_sv_ht xx.es.translate_to.st translate_st_es xx.fr.translate_to.ru translate_ru_fr xx.chk.translate_to.sv translate_sv_chk xx.fr.translate_to.sk translate_sk_fr xx.lg.translate_to.sv translate_sv_lg xx.sv.translate_to.srn translate_srn_sv xx.crs.translate_to.sv translate_sv_crs xx.uk.translate_to.ru translate_ru_uk xx.et.translate_to.ru translate_ru_et xx.et.translate_to.sv translate_sv_et xx.es.translate_to.rw translate_rw_es xx.sla.translate_to.sla translate_sla_sla xx.ru.translate_to.sl translate_sl_ru xx.fj.translate_to.sv translate_sv_fj xx.es.translate_to.sn translate_sn_es xx.lua.translate_to.sv translate_sv_lua xx.hil.translate_to.sv translate_sv_hil xx.es.translate_to.ru translate_ru_es xx.lue.translate_to.sv translate_sv_lue xx.gaa.translate_to.sv translate_sv_gaa xx.hy.translate_to.ru translate_ru_hy xx.bem.translate_to.sv translate_sv_bem xx.sv.translate_to.run translate_run_sv xx.gil.translate_to.sv translate_sv_gil xx.lus.translate_to.sv translate_sv_lus xx.he.translate_to.ru translate_ru_he xx.vi.translate_to.ru translate_ru_vi xx.he.translate_to.sv translate_sv_he xx.sv.translate_to.ru translate_ru_sv xx.fi.translate_to.ru translate_ru_fi xx.es.translate_to.sv translate_sv_es xx.es.translate_to.sg translate_sg_es xx.eo.translate_to.ru translate_ru_eo xx.lv.translate_to.sv translate_sv_lv xx.fi.translate_to.sg translate_sg_fi xx.es.translate_to.ssp translate_ssp_es xx.ilo.translate_to.sv translate_sv_ilo xx.fi.translate_to.sv translate_sv_fi xx.lt.translate_to.ru translate_ru_lt xx.bi.translate_to.sv translate_sv_bi xx.sv.translate_to.sl translate_sl_sv xx.fr.translate_to.sv translate_sv_fr xx.uk.translate_to.sl translate_sl_uk xx.fi.translate_to.sl translate_sl_fi xx.sl.translate_to.ru translate_ru_sl xx.ig.translate_to.sv translate_sv_ig xx.ase.translate_to.sv translate_sv_ase xx.eo.translate_to.sh translate_sh_eo xx.fr.translate_to.sl translate_sl_fr xx.es.translate_to.tl translate_tl_es xx.sv.translate_to.tw translate_tw_sv xx.lt.translate_to.tr translate_tr_lt xx.fi.translate_to.tll translate_tll_fi xx.sn.translate_to.sv translate_sv_sn xx.tn.translate_to.sv translate_sv_tn xx.sv.translate_to.toi translate_toi_sv xx.uk.translate_to.sv translate_sv_uk xx.tiv.translate_to.sv translate_sv_tiv xx.sk.translate_to.sv translate_sv_sk xx.ty.translate_to.sv translate_sv_ty xx.es.translate_to.toi translate_toi_es xx.rw.translate_to.sv translate_sv_rw xx.ny.translate_to.sv translate_sv_ny xx.rnd.translate_to.sv translate_sv_rnd xx.es.translate_to.tn translate_tn_es xx.sv.translate_to.tn translate_tn_sv xx.es.translate_to.tvl translate_tvl_es xx.pon.translate_to.sv translate_sv_pon xx.ve.translate_to.sv translate_sv_ve xx.fr.translate_to.tvl translate_tvl_fr xx.es.translate_to.tum translate_tum_es xx.run.translate_to.sv translate_sv_run xx.de.translate_to.tl translate_tl_de xx.fi.translate_to.tw translate_tw_fi xx.es.translate_to.ty translate_ty_es xx.fr.translate_to.toi translate_toi_fr xx.sv.translate_to.tll translate_tll_sv xx.sg.translate_to.sv translate_sv_sg xx.az.translate_to.tr translate_tr_az xx.es.translate_to.ts translate_ts_es xx.fr.translate_to.ts translate_ts_fr xx.fr.translate_to.th translate_th_fr xx.zne.translate_to.sv translate_sv_zne xx.tw.translate_to.sv translate_sv_tw xx.mh.translate_to.sv translate_sv_mh xx.pag.translate_to.sv translate_sv_pag xx.fr.translate_to.tum translate_tum_fr xx.no.translate_to.sv translate_sv_no xx.ts.translate_to.sv translate_sv_ts xx.mt.translate_to.sv translate_sv_mt xx.yo.translate_to.sv translate_sv_yo xx.fr.translate_to.to translate_to_fr xx.sv.translate_to.sv translate_sv_sv xx.fi.translate_to.toi translate_toi_fi xx.ro.translate_to.sv translate_sv_ro xx.es.translate_to.tw translate_tw_es xx.niu.translate_to.sv translate_sv_niu xx.uk.translate_to.tr translate_tr_uk xx.to.translate_to.sv translate_sv_to xx.fi.translate_to.ts translate_ts_fi xx.tll.translate_to.sv translate_sv_tll xx.fr.translate_to.tll translate_tll_fr xx.pt.translate_to.tl translate_tl_pt xx.nso.translate_to.sv translate_sv_nso xx.sq.translate_to.sv translate_sv_sq xx.sv.translate_to.tpi translate_tpi_sv xx.yap.translate_to.sv translate_sv_yap xx.sv.translate_to.tr translate_tr_sv xx.fr.translate_to.swc translate_swc_fr xx.nl.translate_to.sv translate_sv_nl xx.fi.translate_to.ty translate_ty_fi xx.fr.translate_to.tr translate_tr_fr xx.sv.translate_to.tum translate_tum_sv xx.swc.translate_to.sv translate_sv_swc xx.fi.translate_to.swc translate_swc_fi xx.eo.translate_to.tr translate_tr_eo xx.xh.translate_to.sv translate_sv_xh xx.sv.translate_to.tvl translate_tvl_sv xx.sl.translate_to.sv translate_sv_sl xx.tum.translate_to.sv translate_sv_tum xx.es.translate_to.to translate_to_es xx.fr.translate_to.tn translate_tn_fr xx.sv.translate_to.ty translate_ty_sv xx.sv.translate_to.swc translate_swc_sv xx.mos.translate_to.sv translate_sv_mos xx.ar.translate_to.tr translate_tr_ar xx.ru.translate_to.sv translate_sv_ru xx.srn.translate_to.sv translate_sv_srn xx.pis.translate_to.sv translate_sv_pis xx.pap.translate_to.sv translate_sv_pap xx.tvl.translate_to.sv translate_sv_tvl xx.sv.translate_to.to translate_to_sv xx.th.translate_to.sv translate_sv_th xx.war.translate_to.sv translate_sv_war xx.sv.translate_to.ts translate_ts_sv xx.fr.translate_to.tw translate_tw_fr xx.st.translate_to.sv translate_sv_st xx.fr.translate_to.tiv translate_tiv_fr xx.tpi.translate_to.sv translate_sv_tpi xx.fi.translate_to.tvl translate_tvl_fi xx.fr.translate_to.ty translate_ty_fr xx.sm.translate_to.sv translate_sv_sm xx.es.translate_to.swc translate_swc_es xx.sv.translate_to.tiv translate_tiv_sv xx.toi.translate_to.sv translate_sv_toi xx.mfe.translate_to.sv translate_sv_mfe xx.wls.translate_to.sv translate_sv_wls xx.umb.translate_to.sv translate_sv_umb xx.es.translate_to.tr translate_tr_es xx.es.translate_to.tll translate_tll_es xx.pt.translate_to.uk translate_uk_pt xx.it.translate_to.zh translate_zh_it xx.no.translate_to.uk translate_uk_no xx.sh.translate_to.uk translate_uk_sh xx.sv.translate_to.wls translate_wls_sv xx.pl.translate_to.uk translate_uk_pl xx.es.translate_to.yo translate_yo_es xx.es.translate_to.war translate_war_es xx.sv.translate_to.zh translate_zh_sv xx.tr.translate_to.uk translate_uk_tr xx.fi.translate_to.war translate_war_fi xx.de.translate_to.zh translate_zh_de xx.uk.translate_to.zh translate_zh_uk xx.eo.translate_to.vi translate_vi_eo xx.bg.translate_to.zh translate_zh_bg xx.es.translate_to.zne translate_zne_es xx.fr.translate_to.uk translate_uk_fr xx.zls.translate_to.zls translate_zls_zls xx.fr.translate_to.yo translate_yo_fr xx.bg.translate_to.uk translate_uk_bg xx.fr.translate_to.xh translate_xh_fr xx.ca.translate_to.uk translate_uk_ca xx.fi.translate_to.zh translate_zh_fi xx.es.translate_to.zai translate_zai_es xx.es.translate_to.uk translate_uk_es xx.nl.translate_to.uk translate_uk_nl xx.sv.translate_to.yap translate_yap_sv xx.he.translate_to.uk translate_uk_he xx.sl.translate_to.uk translate_uk_sl xx.es.translate_to.ve translate_ve_es xx.zlw.translate_to.zlw translate_zlw_zlw xx.es.translate_to.tzo translate_tzo_es xx.hu.translate_to.uk translate_uk_hu xx.de.translate_to.vi translate_vi_de xx.fi.translate_to.yo translate_yo_fi xx.ru.translate_to.uk translate_uk_ru xx.ms.translate_to.zh translate_zh_ms xx.urj.translate_to.urj translate_urj_urj xx.it.translate_to.uk translate_uk_it xx.sv.translate_to.war translate_war_sv xx.fr.translate_to.wls translate_wls_fr xx.zle.translate_to.zle translate_zle_zle xx.vi.translate_to.zh translate_zh_vi xx.es.translate_to.vsl translate_vsl_es xx.fi.translate_to.zne translate_zne_fi xx.fi.translate_to.uk translate_uk_fi xx.ru.translate_to.vi translate_vi_ru xx.nl.translate_to.zh translate_zh_nl xx.sv.translate_to.xh translate_xh_sv xx.es.translate_to.xh translate_xh_es xx.he.translate_to.zh translate_zh_he xx.fr.translate_to.war translate_war_fr xx.fr.translate_to.zne translate_zne_fr xx.sv.translate_to.yo translate_yo_sv xx.fr.translate_to.vi translate_vi_fr xx.it.translate_to.vi translate_vi_it xx.sv.translate_to.zne translate_zne_sv xx.fr.translate_to.yap translate_yap_fr xx.cs.translate_to.uk translate_uk_cs xx.es.translate_to.vi translate_vi_es xx.de.translate_to.uk translate_uk_de xx.sv.translate_to.uk translate_uk_sv Bugfixes Fixed bugs that occured when loading a model from disk. 140+ NLU Tutorials Streamlit visualizations docs The complete list of all 1100+ models &amp; pipelines in 192+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.3 NLU Version 3.0.2 This release contains examples and tutorials on how to visualize the 1000+ state-of-the-art NLP models provided by NLU in just 1 line of code in streamlit. It includes simple 1-liners you can sprinkle into your Streamlit app to for features like Dependency Trees, Named Entities (NER), text classification results, semantic simmilarity, embedding visualizations via ELMO, BERT, ALBERT, XLNET and much more . Additionally, improvements for T5, various resolvers have been added and models Farsi, Hebrew, Korean, and Turkish This is the ultimate NLP research tool. You can visualize and compare the results of hundreds of context aware deep learning embeddings and compare them with classical vanilla embeddings like Glove and can see with your own eyes how context is encoded by transformer models like BERT or XLNETand many more ! Besides that, you can also compare the results of the 200+ NER models John Snow Labs provides and see how peformances changes with varrying ebeddings, like Contextual, Static and Domain Specific Embeddings. Install For detailed instructions refer to the NLU install documentation here You need Open JDK 8 installed and the following python packages pip install nlu streamlit pyspark==3.0.1 sklearn plotly Problems? Connect with us on Slack! Impatient and want some action? Just run this Streamlit app, you can use it to generate python code for each NLU-Streamlit building block streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/01_dashboard.py Quick Starter cheat sheet - All you need to know in 1 picture for NLU + Streamlit For NLU models to load, see the NLU Namespace or the John Snow Labs Modelshub or go straight to the source. Examples Just try out any of these. You can use the first example to generate python-code snippets which you can recycle as building blocks in your streamlit apps! Example: 01_dashboard streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/01_dashboard.py Example: 02_NER streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/02_NER.py Example: 03_text_similarity_matrix streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/03_text_similarity_matrix.py Example: 04_dependency_tree streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/04_dependency_tree.py Example: 05_classifiers streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/05_classifiers.py Example: 06_token_features streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/06_token_features.py How to use NLU? All you need to know about NLU is that there is the nlu.load() method which returns a NLUPipeline object which has a .predict() that works on most common data types in the pydata stack like Pandas dataframes . Ontop of that, there are various visualization methods a NLUPipeline provides easily integrate in Streamlit as re-usable components. viz() method Overview of NLU + Streamlit buildingblocks Method Description nlu.load(&#39;&lt;Model&gt;&#39;).predict(data) Load any of the 1000+ models by providing the model name any predict on most Pythontic data strucutres like Pandas, strings, arrays of strings and more nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit(data) Display full NLU exploration dashboard, that showcases every feature avaiable with dropdown selectors for 1000+ models nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_similarity([string1, string2]) Display similarity matrix and scalar similarity for every word embedding loaded and 2 strings. nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_ner(data) Visualize predicted NER tags from Named Entity Recognizer model nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_dep_tree(data) Visualize Dependency Tree together with Part of Speech labels nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_classes(data) Display all extracted class features and confidences for every classifier loaded in pipeline nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_token(data) Display all detected token features and informations in Streamlit nlu.load(&#39;&lt;Model&gt;&#39;).viz(data, write_to_streamlit=True) Display the raw visualization without any UI elements. See viz docs for more info. By default all aplicable nlu model references will be shown. nlu.enable_streamlit_caching() Enable caching the nlu.load() call. Once enabled, the nlu.load() method will automatically cached. This is recommended to run first and for large peformance gans Detailed visualizer information and API docs function pipe.viz_streamlit Display a highly configurable UI that showcases almost every feature available for Streamlit visualization with model selection dropdowns in your applications. Ths includes : Similarity Matrix &amp; Scalars &amp; Embedding Information for any of the 100+ Word Embedding Models NER visualizations for any of the 200+ Named entity recognizers Labled &amp; Unlabled Dependency Trees visualizations with Part of Speech Tags for any of the 100+ Part of Speech Models Token informations predicted by any of the 1000+ models Classification results predicted by any of the 100+ models classification models Pipeline Configuration &amp; Model Information &amp; Link to John Snow Labs Modelshub for all loaded pipelines Auto generate Python code that can be copy pasted to re-create the individual Streamlit visualization blocks. NlLU takes the first model specified as nlu.load() for the first visualization run. Once the Streamlit app is running, additional models can easily be added via the UI. It is recommended to run this first, since you can generate Python code snippets to recreate individual Streamlit visualization blocks nlu.load(&#39;ner&#39;).viz_streamlit([&#39;I love NLU and Streamlit!&#39;,&#39;I hate buggy software&#39;]) function parameters pipe.viz_streamlit Argument Type Default Description text Union [str, List[str], pd.DataFrame, pd.Series] &#39;NLU and Streamlit go together like peanutbutter and jelly&#39; Default text for the Classification, Named Entitiy Recognizer, Token Information and Dependency Tree visualizations similarity_texts Union[List[str],Tuple[str,str]] (&#39;Donald Trump Likes to part&#39;, &#39;Angela Merkel likes to party&#39;) Default texts for the Text similarity visualization. Should contain exactly 2 strings which will be compared token embedding wise. For each embedding active, a token wise similarity matrix and a similarity scalar model_selection List[str] [] List of nlu references to display in the model selector, see the NLU Namespace or the John Snow Labs Modelshub or go straight to the source for more info title str &#39;NLU ❤️ Streamlit - Prototype your NLP startup in 0 lines of code🚀&#39; Title of the Streamlit app sub_title str &#39;Play with over 1000+ scalable enterprise NLP models&#39; Sub title of the Streamlit app visualizers List[str] ( &quot;dependency_tree&quot;, &quot;ner&quot;, &quot;similarity&quot;, &quot;token_information&quot;, &#39;classification&#39;) Define which visualizations should be displayed. By default all visualizations are displayed. show_models_info bool True Show information for every model loaded in the bottom of the Streamlit app. show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click show_viz_selection bool False Show a selector in the sidebar which lets you configure which visualizations are displayed. show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_code_snippets bool False Display Python code snippets above visualizations that can be used to re-create the visualization num_similarity_cols int 2 How many columns should for the layout in Streamlit when rendering the similarity matrixes. function pipe.viz_streamlit_classes Visualize the predicted classes and their confidences and additional metadata to streamlit. Aplicable with any of the 100+ classifiers nlu.load(&#39;sentiment&#39;).viz_streamlit_classes([&#39;I love NLU and Streamlit!&#39;,&#39;I love buggy software&#39;, &#39;Sign up now get a chance to win 1000$ !&#39;, &#39;I am afraid of Snakes&#39;,&#39;Unicorns have been sighted on Mars!&#39;,&#39;Where is the next bus stop?&#39;]) function parameters pipe.viz_streamlit_classes Argument Type Default Description text Union[str,list,pd.DataFrame, pd.Series, pyspark.sql.DataFrame ] &#39;I love NLU and Streamlit and sunny days!&#39; Text to predict classes for. Will predict on each input of the iteratable or dataframe if type is not str. output_level Optional[str] document Outputlevel of NLU pipeline, see pipe.predict() docsmore info include_text_col bool True Whether to include a e text column in the output table or just the prediction data title Optional[str] Text Classification Title of the Streamlit building block that will be visualized to screen metadata bool False whether to output addition metadata or not, see pipe.predict(meta=true) docs for more info positions bool False whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. function pipe.viz_streamlit_ner Visualize the predicted classes and their confidences and additional metadata to Streamlit. Aplicable with any of the 250+ NER models. You can filter which NER tags to highlight via the dropdown in the main window. Basic usage nlu.load(&#39;ner&#39;).viz_streamlit_ner(&#39;Donald Trump from America and Angela Merkel from Germany dont share many views&#39;) Example for coloring # Color all entities of class GPE black nlu.load(&#39;ner&#39;).viz_streamlit_ner(&#39;Donald Trump from America and Angela Merkel from Germany dont share many views&#39;,colors={&#39;PERSON&#39;:&#39;#6e992e&#39;, &#39;GPE&#39;:&#39;#000000&#39;}) function parameters pipe.viz_streamlit_ner Argument Type Default Description text str &#39;Donald Trump from America and Anegela Merkel from Germany do not share many views&#39; Text to predict classes for. ner_tags Optional[List[str]] None Tags to display. By default all tags will be displayed show_label_select bool True Whether to include the label selector show_table bool True Whether show to predicted pandas table or not title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen sub_title Optional[str] &#39;&quot;Recognize various Named Entities (NER) in text entered and filter them. You can select from over 100 languages in the dropdown. On the left side.&quot;,&#39; Sub-title of the Streamlit building block that will be visualized to screen colors Dict[str,str] {} Dict with KEY=ENTITY_LABEL and VALUE=COLOR_AS_HEX_CODE,which will change color of highlighted entities.See custom color labels docs for more info. set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_text_input bool True Show text input field to input text in show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. function pipe.viz_streamlit_dep_tree Visualize a typed dependency tree, the relations between tokens and part of speech tags predicted. Aplicable with any of the 100+ Part of Speech(POS) models and dep tree model nlu.load(&#39;dep.typed&#39;).viz_streamlit_dep_tree(&#39;POS tags define a grammatical label for each token and the Dependency Tree classifies Relations between the tokens&#39;) function parameters pipe.viz_streamlit_dep_tree Argument Type Default Description text str &#39;Billy likes to swim&#39; Text to predict classes for. title Optional[str] &#39;Dependency Parse Tree &amp; Part-of-speech tags&#39; Title of the Streamlit building block that will be visualized to screen set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. function pipe.viz_streamlit_token Visualize predicted token and text features for every model loaded. You can use this with any of the 1000+ models and select them from the left dropdown. nlu.load(&#39;stemm pos spell&#39;).viz_streamlit_token(&#39;I liek pentut buttr and jelly !&#39;) function parameters pipe.viz_streamlit_token Argument Type Default Description text str &#39;NLU and Streamlit are great!&#39; Text to predict token information for. title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen show_feature_select bool True Whether to include the token feature selector features Optional[List[str]] None Features to to display. By default all Features will be displayed metadata bool False Whether to output addition metadata or not, see pipe.predict(meta=true) docs for more info output_level Optional[str] &#39;token&#39; Outputlevel of NLU pipeline, see pipe.predict() docsmore info positions bool False Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. function pipe.viz_streamlit_similarity Displays a similarity matrix, where x-axis is every token in the first text and y-axis is every token in the second text. Index i,j in the matrix describes the similarity of token-i to token-j based on the loaded embeddings and distance metrics, based on Sklearns Pariwise Metrics.. See this article for more elaboration on similarities Displays a dropdown selectors from which various similarity metrics and over 100 embeddings can be selected. -There will be one similarity matrix per metric and embedding pair selected. num_plots = num_metric*num_embeddings Also displays embedding vector information. Applicable with any of the 100+ Word Embedding models nlu.load(&#39;bert&#39;).viz_streamlit_word_similarity([&#39;I love love loooove NLU! &lt;3&#39;,&#39;I also love love looove Streamlit! &lt;3&#39;]) function parameters pipe.viz_streamlit_similarity Argument Type Default Description texts str &#39;Donald Trump from America and Anegela Merkel from Germany do not share many views.&#39; Text to predict token information for. title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen similarity_matrix bool None Whether to display similarity matrix or not show_algo_select bool True Whether to show dist algo select or not show_table bool True Whether show to predicted pandas table or not threshold float 0.5 Threshold for displaying result red on screen set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info write_raw_pandas bool False Write the raw pandas similarity df to streamlit display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more. dist_metrics List[str] [&#39;cosine&#39;] Which distance metrics to apply. If multiple are selected, there will be multiple plots for each embedding and metric. num_plots = num_metric*num_embeddings. Can use multiple at the same time, any of of cityblock,cosine,euclidean,l2,l1,manhattan,nan_euclidean. Provided via Sklearn metrics.pairwise package num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes. display_scalar_similarities bool False Display scalar simmilarities in an additional field. display_similarity_summary bool False Display summary of all similarities for all embeddings and metrics. show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. ## In addition have added some new features to our T5 Transformer annotator to help with longer and more accurate text generation, trained some new multi-lingual models and pipelines in Farsi, Hebrew, Korean, and Turkish. T5 Model Improvements Add 6 new features to T5Transformer for longer and better text generation doSample: Whether or not to use sampling; use greedy decoding otherwise temperature: The value used to module the next token probabilities topK: The number of highest probability vocabulary tokens to keep for top-k-filtering topP: If set to float &lt; 1, only the most probable tokens with probabilities that add up to top_p or higher are kept for generation repetitionPenalty: The parameter for repetition penalty. 1.0 means no penalty. See CTRL: A Conditional Transformer Language Model for Controllable Generation paper for more details noRepeatNgramSize: If set to int &gt; 0, all ngrams of that size can only occur once New Open Source Model in NLU 3.0.2 New multilingual models and pipelines for Farsi, Hebrew, Korean, and Turkish Model NLU Reference Spark NLP Reference Lang ClassifierDLModel tr.classify.news classifierdl_bert_news tr UniversalSentenceEncoder xx.use.multi tfhub_use_multi xx UniversalSentenceEncoder xx.use.multi_lg tfhub_use_multi_lg xx Pipeline NLU Reference Spark NLP Reference Lang PretrainedPipeline fa.ner.dl recognize_entities_dl fa PretrainedPipeline he.explain_document explain_document_lg he PretrainedPipeline ko.explain_document explain_document_lg ko New Healthcare Models in NLU 3.0.2 Five new resolver models: en.resolve.umls: This model returns CUI (concept unique identifier) codes for Clinical Findings, Medical Devices, Anatomical Structures and Injuries &amp; Poisoning terms. en.resolve.umls.findings: This model returns CUI (concept unique identifier) codes for 200K concepts from clinical findings. en.resolve.loinc: Map clinical NER entities to LOINC codes using sbiobert. en.resolve.loinc.bluebert: Map clinical NER entities to LOINC codes using sbluebert. en.resolve.HPO: This model returns Human Phenotype Ontology (HPO) codes for phenotypic abnormalities encountered in human diseases. It also returns associated codes from the following vocabularies for each HPO code: Related NLU Notebook Model NLU Reference Spark NLP Reference Resolver en.resolve.umls sbiobertresolve_umls_major_concepts Resolver en.resolve.umls.findings sbiobertresolve_umls_findings Resolver en.resolve.loinc sbiobertresolve_loinc Resolver en.resolve.loinc.biobert sbiobertresolve_loinc Resolver en.resolve.loinc.bluebert sbluebertresolve_loinc Resolver en.resolve.HPO sbiobertresolve_HPO en.resolve.HPO nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.HPO&#39;).viz(&quot;&quot;&quot;These disorders include cancer, bipolar disorder, schizophrenia, autism, Cri-du-chat syndrome, myopia, cortical cataract-linked Alzheimer&#39;s disease, and infectious diseases&quot;&quot;&quot;) en.resolve.loinc.bluebert nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.loinc.bluebert&#39;).viz(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;) en.resolve.umls.findings nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.umls.findings&#39;).viz(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot; ) en.resolve.umls nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.umls&#39;).viz(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;) en.resolve.loinc nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.loinc&#39;).predict(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;) en.resolve.loinc.biobert nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.loinc.biobert&#39;).predict(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;) 140+ tutorials New Streamlit visualizations docs The complete list of all 1100+ models &amp; pipelines in 192+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.1 NLU Version 3.0.1 We are very excited to announce NLU 3.0.1 has been released! This is one of the most visually appealing releases, with the integration of the Spark-NLP-Display library and visualizations for dependency trees, entity resolution, entity assertion, relationship between entities and named entity recognition. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+ Finally, new multilingual models for Afrikaans, Welsh, Maltese, Tamil, andVietnamese are now available. New Features and Enhancements 1 line to visualization for NER, Dependency, Resolution, Assertion and Relation via Spark-NLP-Display integration Improved column naming schema Over 140 + NLU tutorial Notebooks updated and improved to reflect latest changes in NLU 3.0.0 + New multilingual models for Afrikaans, Welsh, Maltese, Tamil, andVietnamese Improved Column Name generation NLU categorized each internal component now with boolean labels for name_deductable and always_name_deductable . Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the pipe and there are multiple components of same type, i.e. multiple NER models, NLU will deduct a base name for the final output columns from the NLU reference each NER model is pointing to. If on the other hand, there is only one NER model in the pipeline, only the default ner column prefixed will be generated. For some components, like embeddings and classifiers are now defined as always_name_deductable, for those NLU will always try to infer a meaningful base name for the output columns. Newly trained component output columns will now be prefixed with trained_&lt;type&gt; , for types pos , ner, cLassifier, sentiment and multi_classifier Enhanced offline mode You can still load a model from a path as usual with nlu.load(path=model_path) and output columns will be suffixed with from_disk You can now optionally also specify request parameter during load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of from_disk, i.e. by calling nlu.load(request =&#39;en.embed_sentence.biobert.pubmed_pmc_base_cased&#39;, path=model_path) NLU visualization The latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if Spark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don’t need to worry about anything! See the visualization tutorial notebook and visualization docs for more info. NER visualization Applicable to any of the 100+ NER models! See here for an overview nlu.load(&#39;ner&#39;).viz(&quot;Donald Trump from America and Angela Merkel from Germany don&#39;t share many oppinions.&quot;) Dependency tree visualization Visualizes the structure of the labeled dependency tree and part of speech tags nlu.load(&#39;dep.typed&#39;).viz(&quot;Billy went to the mall&quot;) #Bigger Example nlu.load(&#39;dep.typed&#39;).viz(&quot;Donald Trump from America and Angela Merkel from Germany don&#39;t share many oppinions but they both love John Snow Labs software&quot;) Assertion status visualization Visualizes asserted statuses and entities. Applicable to any of the 10 + Assertion models! See here for an overview nlu.load(&#39;med_ner.clinical assert&#39;).viz(&quot;The MRI scan showed no signs of cancer in the left lung&quot;) #bigger example data =&#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.&#39; nlu.load(&#39;med_ner.clinical assert&#39;).viz(data) Relationship between entities visualization Visualizes the extracted entities between relationship. Applicable to any of the 20 + Relation Extractor models See here for an overview nlu.load(&#39;med_ner.jsl.wip.clinical relation.temporal_events&#39;).viz(&#39;The patient developed cancer after a mercury poisoning in 1999 &#39;) # bigger example data = &#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed&#39; pipe = nlu.load(&#39;med_ner.jsl.wip.clinical relation.clinical&#39;).viz(data) Entity Resolution visualization for chunks Visualizes resolutions of entities Applicable to any of the 100+ Resolver models See here for an overview nlu.load(&#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&#39;).viz(&quot;He took Prevacid 30 mg daily&quot;) # bigger example data = &quot;This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret &#39;s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .&quot; nlu.load(&#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&#39;).viz(data) Entity Resolution visualization for sentences Visualizes resolutions of entities in sentences Applicable to any of the 100+ Resolver models See here for an overview nlu.load(&#39;med_ner.jsl.wip.clinical resolve.icd10cm&#39;).viz(&#39;She was diagnosed with a respiratory congestion&#39;) # bigger example data = &#39;The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion&#39; nlu.load(&#39;med_ner.jsl.wip.clinical resolve.icd10cm&#39;).viz(data) Configure visualizations Define custom colors for labels Some entity and relation labels will be highlighted with a pre-defined color, which you can find here. For labels that have no color defined, a random color will be generated. You can define colors for labels manually, by specifying via the viz_colors parameter and defining hex color codes in a dictionary that maps labels to colors . data = &#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&#39; # Define custom colors for labels viz_colors={&#39;STRENGTH&#39;:&#39;#800080&#39;, &#39;DRUG_BRANDNAME&#39;:&#39;#77b5fe&#39;, &#39;GENDER&#39;:&#39;#77ffe&#39;} nlu.load(&#39;med_ner.jsl.wip.clinical&#39;).viz(data,viz_colors =viz_colors) Filter entities that get highlighted By default every entity class will be visualized. The labels_to_viz can be used to define a set of labels to highlight. Applicable for ner, resolution and assert. data = &#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&#39; # Filter wich NER label to viz labels_to_viz=[&#39;SYMPTOM&#39;] nlu.load(&#39;med_ner.jsl.wip.clinical&#39;).viz(data,labels_to_viz=labels_to_viz) New models New multilingual models for Afrikaans, Welsh, Maltese, Tamil, andVietnamese nlu.load() Refrence Spark NLP Refrence vi.lemma lemma mt.lemma lemma ta.lemma lemma af.lemma lemma af.pos pos_afribooms cy.lemma lemma Reworked and updated NLU tutorial notebooks All of the 140+ NLU tutorial Notebooks have been updated and reworked to reflect the latest changes in NLU 3.0.0+ Bugfixes Fixed a bug that caused resolution algorithms output level to be inferred incorrectly Fixed a bug that caused stranger cols got dropped Fixed a bug that caused endings to miss when .predict(position=True) was specified Fixed a bug that caused pd.Series to be converted incorrectly internally Fixed a bug that caused output level transformations to crash Fixed a bug that caused verbose mode not to turn of properly after turning it on. fixed a bug that caused some models to crash when loaded for HDD 140+ updates tutorials Updated visualization docs Models Hub with new models Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line!aaa * Install NLU on Google Colab : ! wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : ! wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.3 200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support in NLU 3.0 Release and much more We are incredible excited to announce the release of NLU 3.0.0 which makes most of John Snow Labs medical healthcare model available in just 1 line of code in NLU. These models are the most accurate in their domains and highly scalable in Spark clusters. In addition, Spark 3.0.X and Spark 3.1.X is now supported, together with Python3.8 This is enabled by the the amazing Spark NLP3.0.1 and Spark NLP for Healthcare 3.0.1 releases. New Features Over 200 new models for the healthcare domain 6 new classes of models, Assertion, Sentence/Chunk Resolvers, Relation Extractors, Medical NER models, De-Identificator Models Spark 3.0.X and 3.1.X support Python 3.8 Support New Output level relation 1 Line to install NLU just run !wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash Various new EMR and Databricks versions supported GPU Mode, more then 600% speedup by enabling GPU mode. Authorized mode for licensed features New Documentation NLU for Healthcare Examples Instrunctions to authorize your environment to use Licensed features New Notebooks Medical Named Entity Extraction (NER) notebook Relation extraction notebook Entity Resolution overview notebook Assertion overview notebook De-Identification overview notebook Graph NLU tutorial for the GRAPH+AI Summit hosted by Tigergraph AssertionDLModels Language nlu.load() reference Spark NLP Model reference English assert assertion_dl English assert.biobert assertion_dl_biobert English assert.healthcare assertion_dl_healthcare English assert.large assertion_dl_large New Word Embeddings Language nlu.load() reference Spark NLP Model reference English embed.glove.clinical embeddings_clinical English embed.glove.biovec embeddings_biovec English embed.glove.healthcare embeddings_healthcare English embed.glove.healthcare_100d embeddings_healthcare_100d English en.embed.glove.icdoem embeddings_icdoem English en.embed.glove.icdoem_2ng embeddings_icdoem_2ng Sentence Entity resolvers Language nlu.load() reference Spark NLP Model reference English embed_sentence.biobert.mli sbiobert_base_cased_mli English resolve sbiobertresolve_cpt English resolve.cpt sbiobertresolve_cpt English resolve.cpt.augmented sbiobertresolve_cpt_augmented English resolve.cpt.procedures_augmented sbiobertresolve_cpt_procedures_augmented English resolve.hcc.augmented sbiobertresolve_hcc_augmented English resolve.icd10cm sbiobertresolve_icd10cm English resolve.icd10cm.augmented sbiobertresolve_icd10cm_augmented English resolve.icd10cm.augmented_billable sbiobertresolve_icd10cm_augmented_billable_hcc English resolve.icd10pcs sbiobertresolve_icd10pcs English resolve.icdo sbiobertresolve_icdo English resolve.rxcui sbiobertresolve_rxcui English resolve.rxnorm sbiobertresolve_rxnorm English resolve.snomed sbiobertresolve_snomed_auxConcepts English resolve.snomed.aux_concepts sbiobertresolve_snomed_auxConcepts English resolve.snomed.aux_concepts_int sbiobertresolve_snomed_auxConcepts_int English resolve.snomed.findings sbiobertresolve_snomed_findings English resolve.snomed.findings_int sbiobertresolve_snomed_findings_int RelationExtractionModel Language nlu.load() reference Spark NLP Model reference English relation.posology posology_re English relation redl_bodypart_direction_biobert English relation.bodypart.direction redl_bodypart_direction_biobert English relation.bodypart.problem redl_bodypart_problem_biobert English relation.bodypart.procedure redl_bodypart_procedure_test_biobert English relation.chemprot redl_chemprot_biobert English relation.clinical redl_clinical_biobert English relation.date redl_date_clinical_biobert English relation.drug_drug_interaction redl_drug_drug_interaction_biobert English relation.humen_phenotype_gene redl_human_phenotype_gene_biobert English relation.temporal_events redl_temporal_events_biobert NERDLModels Language nlu.load() reference Spark NLP Model reference English med_ner.ade.clinical ner_ade_clinical English med_ner.ade.clinical_bert ner_ade_clinicalbert English med_ner.ade.ade_healthcare ner_ade_healthcare English med_ner.anatomy ner_anatomy English med_ner.anatomy.biobert ner_anatomy_biobert English med_ner.anatomy.coarse ner_anatomy_coarse English med_ner.anatomy.coarse_biobert ner_anatomy_coarse_biobert English med_ner.aspect_sentiment ner_aspect_based_sentiment English med_ner.bacterial_species ner_bacterial_species English med_ner.bionlp ner_bionlp English med_ner.bionlp.biobert ner_bionlp_biobert English med_ner.cancer ner_cancer_genetics Englishs med_ner.cellular ner_cellular English med_ner.cellular.biobert ner_cellular_biobert English med_ner.chemicals ner_chemicals English med_ner.chemprot ner_chemprot_biobert English med_ner.chemprot.clinical ner_chemprot_clinical English med_ner.clinical ner_clinical English med_ner.clinical.biobert ner_clinical_biobert English med_ner.clinical.noncontrib ner_clinical_noncontrib English med_ner.diseases ner_diseases English med_ner.diseases.biobert ner_diseases_biobert English med_ner.diseases.large ner_diseases_large English med_ner.drugs ner_drugs English med_ner.drugsgreedy ner_drugs_greedy English med_ner.drugs.large ner_drugs_large English med_ner.events_biobert ner_events_biobert English med_ner.events_clinical ner_events_clinical English med_ner.events_healthcre ner_events_healthcare English med_ner.financial_contract ner_financial_contract English med_ner.healthcare ner_healthcare English med_ner.human_phenotype.gene_biobert ner_human_phenotype_gene_biobert English med_ner.human_phenotype.gene_clinical ner_human_phenotype_gene_clinical English med_ner.human_phenotype.go_biobert ner_human_phenotype_go_biobert English med_ner.human_phenotype.go_clinical ner_human_phenotype_go_clinical English med_ner.jsl ner_jsl English med_ner.jsl.biobert ner_jsl_biobert English med_ner.jsl.enriched ner_jsl_enriched English med_ner.jsl.enriched_biobert ner_jsl_enriched_biobert English med_ner.measurements ner_measurements_clinical English med_ner.medmentions ner_medmentions_coarse English med_ner.posology ner_posology English med_ner.posology.biobert ner_posology_biobert English med_ner.posology.greedy ner_posology_greedy English med_ner.posology.healthcare ner_posology_healthcare English med_ner.posology.large ner_posology_large English med_ner.posology.large_biobert ner_posology_large_biobert English med_ner.posology.small ner_posology_small English med_ner.radiology ner_radiology English med_ner.radiology.wip_clinical ner_radiology_wip_clinical English med_ner.risk_factors ner_risk_factors English med_ner.risk_factors.biobert ner_risk_factors_biobert English med_ner.i2b2 nerdl_i2b2 English med_ner.tumour nerdl_tumour_demo English med_ner.jsl.wip.clinical jsl_ner_wip_clinical English med_ner.jsl.wip.clinical.greedy jsl_ner_wip_greedy_clinical English med_ner.jsl.wip.clinical.modifier jsl_ner_wip_modifier_clinical English med_ner.jsl.wip.clinical.rd jsl_rd_ner_wip_greedy_clinical De-Identification Models Language nlu.load() reference Spark NLP Model reference English med_ner.deid.augmented ner_deid_augmented English med_ner.deid.biobert ner_deid_biobert English med_ner.deid.enriched ner_deid_enriched English med_ner.deid.enriched_biobert ner_deid_enriched_biobert English med_ner.deid.large ner_deid_large English med_ner.deid.sd ner_deid_sd English med_ner.deid.sd_large ner_deid_sd_large English med_ner.deid nerdl_deid English med_ner.deid.synthetic ner_deid_synthetic English med_ner.deid.dl ner_deidentify_dl English en.de_identify deidentify_rb English de_identify.rules deid_rules English de_identify.clinical deidentify_enriched_clinical English de_identify.large deidentify_large English de_identify.rb deidentify_rb English de_identify.rb_no_regex deidentify_rb_no_regex Chunk resolvers Language nlu.load() reference Spark NLP Model reference English resolve_chunk.athena_conditions chunkresolve_athena_conditions_healthcare English resolve_chunk.cpt_clinical chunkresolve_cpt_clinical English resolve_chunk.icd10cm.clinical chunkresolve_icd10cm_clinical English resolve_chunk.icd10cm.diseases_clinical chunkresolve_icd10cm_diseases_clinical English resolve_chunk.icd10cm.hcc_clinical chunkresolve_icd10cm_hcc_clinical English resolve_chunk.icd10cm.hcc_healthcare chunkresolve_icd10cm_hcc_healthcare English resolve_chunk.icd10cm.injuries chunkresolve_icd10cm_injuries_clinical English resolve_chunk.icd10cm.musculoskeletal chunkresolve_icd10cm_musculoskeletal_clinical English resolve_chunk.icd10cm.neoplasms chunkresolve_icd10cm_neoplasms_clinical English resolve_chunk.icd10cm.poison chunkresolve_icd10cm_poison_ext_clinical English resolve_chunk.icd10cm.puerile chunkresolve_icd10cm_puerile_clinical English resolve_chunk.icd10pcs.clinical chunkresolve_icd10pcs_clinical English resolve_chunk.icdo.clinical chunkresolve_icdo_clinical English resolve_chunk.loinc chunkresolve_loinc_clinical English resolve_chunk.rxnorm.cd chunkresolve_rxnorm_cd_clinical English resolve_chunk.rxnorm.in chunkresolve_rxnorm_in_clinical English resolve_chunk.rxnorm.in_healthcare chunkresolve_rxnorm_in_healthcare English resolve_chunk.rxnorm.sbd chunkresolve_rxnorm_sbd_clinical English resolve_chunk.rxnorm.scd chunkresolve_rxnorm_scd_clinical English resolve_chunk.rxnorm.scdc chunkresolve_rxnorm_scdc_clinical English resolve_chunk.rxnorm.scdc_healthcare chunkresolve_rxnorm_scdc_healthcare English resolve_chunk.rxnorm.xsmall.clinical chunkresolve_rxnorm_xsmall_clinical English resolve_chunk.snomed.findings chunkresolve_snomed_findings_clinical New Classifiers Language nlu.load() reference Spark NLP Model reference English classify.icd10.clinical classifier_icd10cm_hcc_clinical English classify.icd10.healthcare classifier_icd10cm_hcc_healthcare English classify.ade.biobert classifierdl_ade_biobert English classify.ade.clinical classifierdl_ade_clinicalbert English classify.ade.conversational classifierdl_ade_conversational_biobert English classify.gender.biobert classifierdl_gender_biobert English classify.gender.sbert classifierdl_gender_sbert English classify.pico classifierdl_pico_biobert German Medical models nlu.load() reference Spark NLP Model reference [embed] w2v_cc_300d [embed.w2v] w2v_cc_300d [resolve_chunk] chunkresolve_ICD10GM [resolve_chunk.icd10gm] chunkresolve_ICD10GM resolve_chunk.icd10gm.2021 chunkresolve_ICD10GM_2021 med_ner.legal ner_legal med_ner ner_healthcare med_ner.healthcare ner_healthcare med_ner.healthcare_slim ner_healthcare_slim med_ner.traffic ner_traffic Spanish Medical models nlu.load() reference Spark NLP Model reference embed.scielo.150d embeddings_scielo_150d embed.scielo.300d embeddings_scielo_300d embed.scielo.50d embeddings_scielo_50d embed.scielowiki.150d embeddings_scielowiki_150d embed.scielowiki.300d embeddings_scielowiki_300d embed.scielowiki.50d embeddings_scielowiki_50d embed.sciwiki.150d embeddings_sciwiki_150d embed.sciwiki.300d embeddings_sciwiki_300d embed.sciwiki.50d embeddings_sciwiki_50d med_ner ner_diag_proc med_ner.neoplasm ner_neoplasms med_ner.diag_proc ner_diag_proc GPU Mode You can now enable NLU GPU mode by setting gpu=true while loading a model. I.e. nlu.load(&#39;train.sentiment&#39; gpu=True) . If must resart you kernel, if you already loaded a nlu pipeline withouth GPU mode. Output Level Relation This new output level is used for relation extractors and will give you 1 row per relation extracted. Bug fixes Fixed a bug that caused loading NLU models in offline mode not to work in some occasions Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.3 Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github Suggestions or Questions? Contact us in Slack! NLU Version 1.1.3 Intent and Action Classification, analyze Chinese News and the Crypto market, train a classifier that understands 100+ languages, translate between 200 + languages, answer questions, summarize text, and much more in NLU 1.1.3 We are very excited to announce that the latest NLU release comes with a new pretrained Intent Classifier and NER Action Extractor for text related to music, restaurants, and movies trained on the SNIPS dataset. Make sure to check out the models hub and the easy 1-liners for more info! In addition to that, new NER and Embedding models for Bengali are now available Finally, there is a new NLU Webinar with 9 accompanying tutorial notebooks which teach you a lot of things and is segmented into the following parts : Part1: Easy 1 Liners Spell checking/Sentiment/POS/NER/ BERTtology embeddings Part2: Data analysis and NLP tasks on Crypto News Headline dataset Preprocessing and extracting Emotions, Keywords, Named Entities and visualize them Part3: NLU Multi-Lingual 1 Liners with Microsoft’s Marian Models Translate between 200+ languages (and classify lang afterward) Part 4: Data analysis and NLP tasks on Chinese News Article Dataset Word Segmentation, Lemmatization, Extract Keywords, Named Entities and translate to english Part 5: Train a sentiment Classifier that understands 100+ Languages Train on a french sentiment dataset and predict the sentiment of 100+ languages with language-agnostic BERT Sentence Embedding Part 6: Question answering, Summarization, Squad and more with Google’s T5 T5 Question answering and 18 + other NLP tasks (SQUAD / GLUE / SUPER GLUE) New Models NLU 1.1.3 New Non-English Models Language nlu.load() reference Spark NLP Model reference Type Bengali bn.ner.cc_300d bengaliner_cc_300d NerDLModel Bengali bn.embed bengali_cc_300d NerDLModel Bengali bn.embed.cc_300d bengali_cc_300d Word Embeddings Model (Alias) Bengali bn.embed.glove bengali_cc_300d Word Embeddings Model (Alias) NLU 1.1.3 New English Models Language nlu.load() reference Spark NLP Model reference Type English en.classify.snips nerdl_snips_100d NerDLModel English en.ner.snips classifierdl_use_snips ClassifierDLModel New NLU Webinar State-of-the-art Natural Language Processing for 200+ Languages with 1 Line of code Talk Abstract Learn to harness the power of 1,000+ production-grade &amp; scalable NLP models for 200+ languages - all available with just 1 line of Python code by leveraging the open-source NLU library, which is powered by the widely popular Spark NLP. John Snow Labs has delivered over 80 releases of Spark NLP to date, making it the most widely used NLP library in the enterprise and providing the AI community with state-of-the-art accuracy and scale for a variety of common NLP tasks. The most recent releases include pre-trained models for over 200 languages - including languages that do not use spaces for word segmentation algorithms like Chinese, Japanese, and Korean, and languages written from right to left like Arabic, Farsi, Urdu, and Hebrew. All software and models are free and open source under an Apache 2.0 license. This webinar will show you how to leverage the multi-lingual capabilities of Spark NLP &amp; NLU - including automated language detection for up to 375 languages, and the ability to perform translation, named entity recognition, stopword removal, lemmatization, and more in a variety of language families. We will create Python code in real-time and solve these problems in just 30 minutes. The notebooks will then be made freely available online. You can watch the video here, NLU 1.1.3 New Notebooks and tutorials New Webinar Notebooks NLU basics, easy 1-liners (Spellchecking, sentiment, NER, POS, BERT Analyze Crypto News dataset with Keyword extraction, NER, Emotional distribution, and stemming Translate Crypto News dataset between 300 Languages with the Marian Model (German, French, Hebrew examples) Translate Crypto News dataset between 300 Languages with the Marian Model (Hindi, Russian, Chinese examples) Analyze Chinese News Headlines with Chinese Word Segmentation, Lemmatization, NER, and Keyword extraction Train a Sentiment Classifier that will understand 100+ languages on just a French Dataset with the powerful Language Agnostic Bert Embeddings Summarize text and Answer Questions with T5 Solve any task in 1 line from SQUAD, GLUE and SUPER GLUE with T5 Overview of models for various languages New easy NLU 1-liners in NLU 1.1.3 Detect actions in general commands related to music, restaurant, movies. nlu.load(&quot;en.classify.snips&quot;).predict(&quot;book a spot for nona gray myrtle and alison at a top-rated brasserie that is distant from wilson av on nov the 4th 2030 that serves ouzeri&quot;,output_level = &quot;document&quot;) outputs : ner_confidence entities document Entities_Classes [1.0, 1.0, 0.9997000098228455, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9990000128746033, 1.0, 1.0, 1.0, 0.9965000152587891, 0.9998999834060669, 0.9567000269889832, 1.0, 1.0, 1.0, 0.9980000257492065, 0.9991999864578247, 0.9988999962806702, 1.0, 1.0, 0.9998999834060669] [‘nona gray myrtle and alison’, ‘top-rated’, ‘brasserie’, ‘distant’, ‘wilson av’, ‘nov the 4th 2030’, ‘ouzeri’] book a spot for nona gray myrtle and alison at a top-rated brasserie that is distant from wilson av on nov the 4th 2030 that serves ouzeri [‘party_size_description’, ‘sort’, ‘restaurant_type’, ‘spatial_relation’, ‘poi’, ‘timeRange’, ‘cuisine’] Named Entity Recognition (NER) Model in Bengali (bengaliner_cc_300d) # Bengali for: &#39;Iajuddin Ahmed passed Matriculation from Munshiganj High School in 1947 and Intermediate from Munshiganj Horganga College in 1950.&#39; nlu.load(&quot;bn.ner.cc_300d&quot;).predict(&quot;১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন&quot;,output_level = &quot;document&quot;) outputs : ner_confidence entities Entities_Classes document [0.9987999796867371, 0.9854000210762024, 0.8604000210762024, 0.6686999797821045, 0.5289999842643738, 0.7009999752044678, 0.7684999704360962, 0.9979000091552734, 0.9976000189781189, 0.9930999875068665, 0.9994000196456909, 0.9879000186920166, 0.7407000064849854, 0.9215999841690063, 0.7657999992370605, 0.39419999718666077, 0.9124000072479248, 0.9932000041007996, 0.9919999837875366, 0.995199978351593, 0.9991999864578247] [‘সালে’, ‘ইয়াজউদ্দিন আহম্মেদ’, ‘মুন্সিগঞ্জ উচ্চ বিদ্যালয়’, ‘সালে’, ‘মুন্সিগঞ্জ হরগঙ্গা কলেজ’] [‘TIME’, ‘PER’, ‘ORG’, ‘TIME’, ‘ORG’] ১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন Identify intent in general text - SNIPS dataset nlu.load(&quot;en.ner.snips&quot;).predict(&quot;I want to bring six of us to a bistro in town that serves hot chicken sandwich that is within the same area&quot;,output_level = &quot;document&quot;) outputs : document snips snips_confidence I want to bring six of us to a bistro in town that serves hot chicken sandwich that is within the same area BookRestaurant 1 Word Embeddings for Bengali (bengali_cc_300d) # Bengali for : &#39;Iajuddin Ahmed passed Matriculation from Munshiganj High School in 1947 and Intermediate from Munshiganj Horganga College in 1950.&#39; nlu.load(&quot;bn.embed&quot;).predict(&quot;১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন&quot;,output_level = &quot;document&quot;) outputs : document bn_embed_embeddings ১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন [-0.0828 0.0683 0.0215 … 0.0679 -0.0484…] NLU 1.1.3 Enhancements Added automatic conversion to Sentence Embeddings of Word Embeddings when there is no Sentence Embedding Avaiable and a model needs the converted version to run. NLU 1.1.3 Bug Fixes Fixed a bug that caused ur.sentiment NLU pipeline to build incorrectly Fixed a bug that caused sentiment.imdb.glove NLU pipeline to build incorrectly Fixed a bug that caused en.sentiment.glove.imdb NLU pipeline to build incorrectly Fixed a bug that caused Spark 2.3.X environments to crash. NLU Installation # PyPi !pip install nlu pyspark==2.4.7 #Conda # Install NLU from Anaconda/Conda conda install -os_components johnsnowlabs nlu Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github Suggestions or Questions? Contact us in Slack! NLU Version 1.1.2 Hindi WordEmbeddings , Bengali Named Entity Recognition (NER), 30+ new models, analyze Crypto news with John Snow Labs NLU 1.1.2 We are very happy to announce NLU 1.1.2 has been released with the integration of 30+ models and pipelines Bengali Named Entity Recognition, Hindi Word Embeddings, and state-of-the-art transformer based OntoNotes models and pipelines from the incredible Spark NLP 2.7.3 Release in addition to a few bugfixes. In addition to that, there is a new NLU Webinar video showcasing in detail how to use NLU to analyze a crypto news dataset to extract keywords unsupervised and predict sentimential/emotional distributions of the dataset and much more! Python’s NLU library: 1,000+ models, 200+ Languages, State of the Art Accuracy, 1 Line of code - NLU NYC/DC NLP Meetup Webinar Using just 1 line of Python code by leveraging the NLU library, which is powered by the award-winning Spark NLP. This webinar covers, using live coding in real-time, how to deliver summarization, translation, unsupervised keyword extraction, emotion analysis, question answering, spell checking, named entity recognition, document classification, and other common NLP tasks. T his is all done with a single line of code, that works directly on Python strings or pandas data frames. Since NLU is based on Spark NLP, no code changes are required to scale processing to multi-core or cluster environment - integrating natively with Ray, Dask, or Spark data frames. The recent releases for Spark NLP and NLU include pre-trained models for over 200 languages and language detection for 375 languages. This includes 20 languages families; non-Latin alphabets; languages that do not use spaces for word segmentation like Chinese, Japanese, and Korean; and languages written from right to left like Arabic, Farsi, Urdu, and Hebrew. We’ll also cover some of the algorithms and models that are included. The code notebooks will be freely available online. NLU 1.1.2 New Non-English Models Language nlu.load() reference Spark NLP Model reference Type Bengali bn.ner ner_jifs_glove_840B_300d Word Embeddings Model (Alias) Bengali bn.ner.glove ner_jifs_glove_840B_300d Word Embeddings Model (Alias) Hindi hi.embed hindi_cc_300d NerDLModel Bengali bn.lemma lemma Lemmatizer Japanese ja.lemma lemma Lemmatizer Bihari bh.lemma lemma Lemma Amharic am.lemma lemma Lemma NLU 1.1.2 New English Models and Pipelines Language nlu.load() reference Spark NLP Model reference Type English en.ner.onto.bert.small_l2_128 onto_small_bert_L2_128 NerDLModel English en.ner.onto.bert.small_l4_256 onto_small_bert_L4_256 NerDLModel English en.ner.onto.bert.small_l4_512 onto_small_bert_L4_512 NerDLModel English en.ner.onto.bert.small_l8_512 onto_small_bert_L8_512 NerDLModel English en.ner.onto.bert.cased_base onto_bert_base_cased NerDLModel English en.ner.onto.bert.cased_large onto_bert_large_cased NerDLModel English en.ner.onto.electra.uncased_small onto_electra_small_uncased NerDLModel English en.ner.onto.electra.uncased_base onto_electra_base_uncased NerDLModel English en.ner.onto.electra.uncased_large onto_electra_large_uncased NerDLModel English en.ner.onto.bert.tiny onto_recognize_entities_bert_tiny Pipeline English en.ner.onto.bert.mini onto_recognize_entities_bert_mini Pipeline English en.ner.onto.bert.small onto_recognize_entities_bert_small Pipeline English en.ner.onto.bert.medium onto_recognize_entities_bert_medium Pipeline English en.ner.onto.bert.base onto_recognize_entities_bert_base Pipeline English en.ner.onto.bert.large onto_recognize_entities_bert_large Pipeline English en.ner.onto.electra.small onto_recognize_entities_electra_small Pipeline English en.ner.onto.electra.base onto_recognize_entities_electra_base Pipeline English en.ner.onto.large onto_recognize_entities_electra_large Pipeline New Tutorials and Notebooks NYC/DC NLP Meetup Webinar video analyze Crypto News, Unsupervised Keywords, Translate between 300 Languages, Question Answering, Summerization, POS, NER in 1 line of code in almost just 20 minutes NLU basics POS/NER/Sentiment Classification/BERTology Embeddings Explore Crypto Newsarticle dataset, unsupervised Keyword extraction, Stemming, Emotion/Sentiment distribution Analysis Translate between more than 300 Languages in 1 line of code with the Marian Models New NLU 1.1.2 Models Showcase Notebooks, Bengali NER, Hindi Embeddings, 30 new_models NLU 1.1.2 Bug Fixes Fixed a bug that caused NER confidences not beeing extracted Fixed a bug that caused nlu.load(‘spell’) to crash Fixed a bug that caused Uralic/Estonian/ET language models not to be loaded properly New Easy NLU 1-liners in 1.1.2 Named Entity Recognition for Bengali (GloVe 840B 300d) #Bengali for : It began to be widely used in the United States in the early &#39;90s. nlu.load(&quot;bn.ner&quot;).predict(&quot;৯০ এর দশকের শুরুর দিকে বৃহৎ আকারে মার্কিন যুক্তরাষ্ট্রে এর প্রয়োগের প্রক্রিয়া শুরু হয়&#39;&quot;) output : entities token Entities_classes ner_confidence [‘মার্কিন যুক্তরাষ্ট্রে’] ৯০ [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] এর [‘LOC’] 0.9999 [‘মার্কিন যুক্তরাষ্ট্রে’] দশকের [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] শুরুর [‘LOC’] 0.9969 [‘মার্কিন যুক্তরাষ্ট্রে’] দিকে [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] বৃহৎ [‘LOC’] 0.9994 [‘মার্কিন যুক্তরাষ্ট্রে’] আকারে [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] মার্কিন [‘LOC’] 0.9602 [‘মার্কিন যুক্তরাষ্ট্রে’] যুক্তরাষ্ট্রে [‘LOC’] 0.4134 [‘মার্কিন যুক্তরাষ্ট্রে’] এর [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] প্রয়োগের [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] প্রক্রিয়া [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] শুরু [‘LOC’] 0.9999 [‘মার্কিন যুক্তরাষ্ট্রে’] হয় [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] ’ [‘LOC’] 1 Bengali Lemmatizer #Bengali for : One morning in the marble-decorated building of Vaidyanatha, an obese monk was engaged in the enchantment of Duis and the milk service of one and a half Vaidyanatha. Give me two to eat nlu.load(&quot;bn.lemma&quot;).predict(&quot;একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও&quot;) output : lemma document [‘একদিন’, ‘প্রাতঃ’, ‘বৈদ্যনাথ’, ‘মার্বলমণ্ডিত’, ‘দালান’, ‘এক’, ‘স্থূলউদর’, ‘সন্ন্যাসী’, ‘দুইসের’, ‘মোহনভোগ’, ‘এবং’, ‘দেড়সের’, ‘দুগ্ধ’, ‘সেবা’, ‘নিযুক্ত’, ‘আছে’, ‘বৈদ্যনাথ’, ‘গা’, ‘একখান’, ‘চাদর’, ‘দেওয়া’, ‘জোড়কর’, ‘একান্ত’, ‘বিনীতভাব’, ‘ভূতল’, ‘বসা’, ‘ভক্তিভরা’, ‘পবিত্র’, ‘ভোজনব্যাপার’, ‘নিরীক্ষণ’, ‘করা’, ‘এমন’, ‘সময়’, ‘কোনোমত’, ‘দ্বারী’, ‘দৃষ্টি’, ‘এড়ানো’, ‘জীর্ণদেহ’, ‘বালক’, ‘সহিত’, ‘এক’, ‘অতি’, ‘শীর্ণকায়া’, ‘রমণী’, ‘গৃহ’, ‘প্রবেশ’, ‘বিশ্বাস’, ‘ক্ষীণস্বর’, ‘কহা’, ‘বাবু’, ‘দুই’, ‘খাওয়া’, ‘দাওয়া’] একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও Japanese Lemmatizer #Japanese for : Some residents were uncomfortable with this, but it seems that no one is now openly protesting or protesting. nlu.load(&quot;ja.lemma&quot;).predict(&quot;これに不快感を示す住民はいましたが,現在,表立って反対や抗議の声を挙げている住民はいないようです。&quot;) output : lemma document [‘これ’, ‘にる’, ‘不快’, ‘感’, ‘を’, ‘示す’, ‘住民’, ‘はる’, ‘いる’, ‘まする’, ‘たる’, ‘がる’, ‘,’, ‘現在’, ‘,’, ‘表立つ’, ‘てる’, ‘反対’, ‘やる’, ‘抗議’, ‘のる’, ‘声’, ‘を’, ‘挙げる’, ‘てる’, ‘いる’, ‘住民’, ‘はる’, ‘いる’, ‘なぐ’, ‘よう’, ‘です’, ‘。’] これに不快感を示す住民はいましたが,現在,表立って反対や抗議の声を挙げている住民はいないようです。 Amharic Lemmatizer #Aharic for : Bookmark the permalink. nlu.load(&quot;am.lemma&quot;).predict(&quot;መጽሐፉን መጽሐፍ ኡ ን አስያዛት አስያዝ ኧ ኣት ።&quot;) output : lemma document [‘’, ‘መጽሐፍ’, ‘ኡ’, ‘ን’, ‘’, ‘አስያዝ’, ‘ኧ’, ‘ኣት’, ‘።’] መጽሐፉን መጽሐፍ ኡ ን አስያዛት አስያዝ ኧ ኣት ። Bhojpuri Lemmatizer #Bhojpuri for : In this event, participation of World Bhojpuri Conference, Purvanchal Ekta Manch, Veer Kunwar Singh Foundation, Purvanchal Bhojpuri Mahasabha, and Herf - Media. nlu.load(&quot;bh.lemma&quot;).predict(&quot;एह आयोजन में विश्व भोजपुरी सम्मेलन , पूर्वांचल एकता मंच , वीर कुँवर सिंह फाउन्डेशन , पूर्वांचल भोजपुरी महासभा , अउर हर्फ - मीडिया के सहभागिता बा ।&quot;) output : lemma document [‘एह’, ‘आयोजन’, ‘में’, ‘विश्व’, ‘भोजपुरी’, ‘सम्मेलन’, ‘COMMA’, ‘पूर्वांचल’, ‘एकता’, ‘मंच’, ‘COMMA’, ‘वीर’, ‘कुँवर’, ‘सिंह’, ‘फाउन्डेशन’, ‘COMMA’, ‘पूर्वांचल’, ‘भोजपुरी’, ‘महासभा’, ‘COMMA’, ‘अउर’, ‘हर्फ’, ‘-‘, ‘मीडिया’, ‘को’, ‘सहभागिता’, ‘बा’, ‘।’] एह आयोजन में विश्व भोजपुरी सम्मेलन , पूर्वांचल एकता मंच , वीर कुँवर सिंह फाउन्डेशन , पूर्वांचल भोजपुरी महासभा , अउर हर्फ - मीडिया के सहभागिता बा । Named Entity Recognition - BERT Tiny (OntoNotes) nlu.load(&quot;en.ner.onto.bert.small_l2_128&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.8536999821662903, 0.7195000052452087, 0.746…] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] Named Entity Recognition - BERT Mini (OntoNotes) nlu.load(&quot;en.ner.onto.bert.small_l4_256&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.835099995136261, 0.40450000762939453, 0.331…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s and 1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘ORG’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘GPE’, ‘GPE’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - BERT Small (OntoNotes) nlu.load(&quot;en.ner.onto.bert.small_l4_512&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.964900016784668, 0.8299000263214111, 0.9607…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘the 1970s and 1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - BERT Medium (OntoNotes) nlu.load(&quot;en.ner.onto.bert.small_l8_512&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.916700005531311, 0.5873000025749207, 0.8816…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘the 1970s and 1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - BERT Base (OntoNotes) nlu.load(&quot;en.ner.onto.bert.cased_base&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.504800021648407, 0.47290000319480896, 0.462…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘the 1970s and 1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - BERT Large (OntoNotes) nlu.load(&quot;en.ner.onto.electra.uncased_small&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.7213000059127808, 0.6384000182151794, 0.731…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - ELECTRA Small (OntoNotes) nlu.load(&quot;en.ner.onto.electra.uncased_small&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence Entities_classes entities [0.8496000170707703, 0.4465999901294708, 0.568…] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] Named Entity Recognition - ELECTRA Base (OntoNotes) nlu.load(&quot;en.ner.onto.electra.uncased_base&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadellabase.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.5134000182151794, 0.9419000148773193, 0.802…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘the 1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - ELECTRA Large (OntoNotes) nlu.load(&quot;en.ner.onto.electra.uncased_large&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadellabase.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.8442000150680542, 0.26840001344680786, 0.57…] [‘William Henry Gates’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Gates co-founded’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’, ‘largest’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’, ‘GPE’] Recognize Entities OntoNotes - BERT Tiny nlu.load(&quot;en.ner.onto.bert.tiny&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.994700014591217, 0.9412999749183655, 0.9685…] [‘Johnson’, ‘first’, ‘2001’, ‘Parliament’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘ORG’, ‘DATE’, ‘GPE’, ‘DATE’] Recognize Entities OntoNotes - BERT Mini nlu.load(&quot;en.ner.onto.bert.mini&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.996399998664856, 0.9733999967575073, 0.8766…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’] Recognize Entities OntoNotes - BERT Small nlu.load(&quot;en.ner.onto.bert.small&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9987999796867371, 0.9610000252723694, 0.998…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’, ‘Parliament’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’, ‘ORG’] Recognize Entities OntoNotes - BERT Medium nlu.load(&quot;en.ner.onto.bert.medium&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9969000220298767, 0.8575999736785889, 0.995…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’] Recognize Entities OntoNotes - BERT Base nlu.load(&quot;en.ner.onto.bert.base&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.996999979019165, 0.933899998664856, 0.99930…] [‘Johnson’, ‘first’, ‘2001’, ‘Parliament’, ‘eight years’, ‘London’, ‘2008 to 2016’, ‘Parliament’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘ORG’, ‘DATE’, ‘GPE’, ‘DATE’, ‘ORG’] Recognize Entities OntoNotes - BERT Large nlu.load(&quot;en.ner.onto.bert.large&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9786999821662903, 0.9549000263214111, 0.998…] [‘Johnson’, ‘first’, ‘2001’, ‘Parliament’, ‘eight years’, ‘London’, ‘2008 to 2016’, ‘Parliament’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘ORG’, ‘DATE’, ‘GPE’, ‘DATE’, ‘ORG’] Recognize Entities OntoNotes - ELECTRA Small nlu.load(&quot;en.ner.onto.electra.small&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9952999949455261, 0.8589000105857849, 0.996…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’] Recognize Entities OntoNotes - ELECTRA Base nlu.load(&quot;en.ner.onto.electra.base&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9987999796867371, 0.9474999904632568, 0.999…] [‘Johnson’, ‘first’, ‘2001’, ‘Parliament’, ‘eight years’, ‘London’, ‘2008’, ‘2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘ORG’, ‘DATE’, ‘GPE’, ‘DATE’, ‘DATE’] Recognize Entities OntoNotes - ELECTRA Large nlu.load(&quot;en.ner.onto.large&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9998000264167786, 0.9613999724388123, 0.998…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’] NLU Installation # PyPi !pip install nlu pyspark==2.4.7 #Conda # Install NLU from Anaconda/Conda conda install -os_components johnsnowlabs nlu Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github NLU Version 1.1.1 We are very excited to release NLU 1.1.1! This release features 3 new tutorial notebooks for Open/Closed book question answering with Google’s T5, Intent classification and Aspect Based NER. In Addition NLU 1.1.0 comes with 25+ pretrained models and pipelines in Amharic, Bengali, Bhojpuri, Japanese, and Korean languages from the amazing Spark2.7.2 release Finally NLU now supports running on Spark 2.3 clusters. NLU 1.1.1 New Non-English Models Language nlu.load() reference Spark NLP Model reference Type Arabic ar.ner arabic_w2v_cc_300d Named Entity Recognizer Arabic ar.embed.aner aner_cc_300d Word Embedding Arabic ar.embed.aner.300d aner_cc_300d Word Embedding (Alias) Bengali bn.stopwords stopwords_bn Stopwords Cleaner Bengali bn.pos pos_msri Part of Speech Thai th.segment_words wordseg_best Word Segmenter Thai th.pos pos_lst20 Part of Speech Thai th.sentiment sentiment_jager_use Sentiment Classifier Thai th.classify.sentiment sentiment_jager_use Sentiment Classifier (Alias) Chinese zh.pos.ud_gsd_trad pos_ud_gsd_trad Part of Speech Chinese zh.segment_words.gsd wordseg_gsd_ud_trad Word Segmenter Bihari bh.pos pos_ud_bhtb Part of Speech Amharic am.pos pos_ud_att Part of Speech NLU 1.1.1 New English Models and Pipelines Language nlu.load() reference Spark NLP Model reference Type English en.sentiment.glove analyze_sentimentdl_glove_imdb Sentiment Classifier English en.sentiment.glove.imdb analyze_sentimentdl_glove_imdb Sentiment Classifier (Alias) English en.classify.sentiment.glove.imdb analyze_sentimentdl_glove_imdb Sentiment Classifier (Alias) English en.classify.sentiment.glove analyze_sentimentdl_glove_imdb Sentiment Classifier (Alias) English en.classify.trec50.pipe classifierdl_use_trec50_pipeline Language Classifier English en.ner.onto.large onto_recognize_entities_electra_large Named Entity Recognizer English en.classify.questions.atis classifierdl_use_atis Intent Classifier English en.classify.questions.airline classifierdl_use_atis Intent Classifier (Alias) English en.classify.intent.atis classifierdl_use_atis Intent Classifier (Alias) English en.classify.intent.airline classifierdl_use_atis Intent Classifier (Alias) English en.ner.atis nerdl_atis_840b_300d Aspect based NER English en.ner.airline nerdl_atis_840b_300d Aspect based NER (Alias) English en.ner.aspect.airline nerdl_atis_840b_300d Aspect based NER (Alias) English en.ner.aspect.atis nerdl_atis_840b_300d Aspect based NER (Alias) New Easy NLU 1-liner Examples : Extract aspects and entities from airline questions (ATIS dataset) nlu.load(&quot;en.ner.atis&quot;).predict(&quot;i want to fly from baltimore to dallas round trip&quot;) output: [&quot;baltimore&quot;,&quot; dallas&quot;, &quot;round trip&quot;] Intent Classification for Airline Traffic Information System queries (ATIS dataset) nlu.load(&quot;en.classify.questions.atis&quot;).predict(&quot;what is the price of flight from newyork to washington&quot;) output: &quot;atis_airfare&quot; Recognize Entities OntoNotes - ELECTRA Large nlu.load(&quot;en.ner.onto.large&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London.&quot;) output: [&quot;Johnson&quot;, &quot;first&quot;, &quot;2001&quot;, &quot;eight years&quot;, &quot;London&quot;] Question classification of open-domain and fact-based questions Pipeline - TREC50 nlu.load(&quot;en.classify.trec50.component_list&quot;).predict(&quot;When did the construction of stone circles begin in the UK? &quot;) output: LOC_other Traditional Chinese Word Segmentation # &#39;However, this treatment also creates some problems&#39; in Chinese nlu.load(&quot;zh.segment_words.gsd&quot;).predict(&quot;然而，這樣的處理也衍生了一些問題。&quot;) output: [&quot;然而&quot;,&quot;,&quot;,&quot;這樣&quot;,&quot;的&quot;,&quot;處理&quot;,&quot;也&quot;,&quot;衍生&quot;,&quot;了&quot;,&quot;一些&quot;,&quot;問題&quot;,&quot;。&quot;] Part of Speech for Traditional Chinese # &#39;However, this treatment also creates some problems&#39; in Chinese nlu.load(&quot;zh.pos.ud_gsd_trad&quot;).predict(&quot;然而，這樣的處理也衍生了一些問題。&quot;) Output: Token POS 然而 ADV ， PUNCT 這樣 PRON 的 PART 處理 NOUN 也 ADV 衍生 VERB 了 PART 一些 ADJ 問題 NOUN 。 PUNCT Thai Word Segment Recognition # &#39;Mona Lisa is a 16th-century oil painting created by Leonardo held at the Louvre in Paris&#39; in Thai nlu.loadnlu.load(&quot;th.segment_words&quot;).predict(&quot;Mona Lisa เป็นภาพวาดสีน้ำมันในศตวรรษที่ 16 ที่สร้างโดย Leonardo จัดขึ้นที่พิพิธภัณฑ์ลูฟร์ในปารีส&quot;) Output: token M o n a Lisa เป็น ภาพ ว า ด สีน้ำ มัน ใน ศตวรรษ ที่ 16 ที่ สร้าง โ ด ย L e o n a r d o จัด ขึ้น ที่ พิพิธภัณฑ์ ลูฟร์ ใน ปารีส Part of Speech for Bengali (POS) # &#39;The village is also called &#39;Mod&#39; in Tora language&#39; in Behgali nlu.load(&quot;bn.pos&quot;).predict(&quot;বাসস্থান-ঘরগৃহস্থালি তোড়া ভাষায় গ্রামকেও বলে ` মোদ &#39; ৷&quot;) Output: token pos বাসস্থান-ঘরগৃহস্থালি NN তোড়া NNP ভাষায় NN গ্রামকেও NN বলে VM ` SYM মোদ NN ’ SYM ৷ SYM Stop Words Cleaner for Bengali # &#39;This language is not enough&#39; in Bengali df = nlu.load(&quot;bn.stopwords&quot;).predict(&quot;এই ভাষা যথেষ্ট নয়&quot;) Output: cleanTokens token ভাষা এই যথেষ্ট ভাষা নয় যথেষ্ট None নয় Part of Speech for Bengali # &#39;The people of Ohu know that the foundation of Bhojpuri was shaken&#39; in Bengali nlu.load(&#39;bh.pos&#39;).predict(&quot;ओहु लोग के मालूम बा कि श्लील होखते भोजपुरी के नींव हिल जाई&quot;) Output: pos token DET ओहु NOUN लोग ADP के NOUN मालूम VERB बा SCONJ कि ADJ श्लील VERB होखते PROPN भोजपुरी ADP के NOUN नींव VERB हिल AUX जाई Amharic Part of Speech (POS) # &#39; &quot;Son, finish the job,&quot; he said.&#39; in Amharic nlu.load(&#39;am.pos&#39;).predict(&#39;ልጅ ኡ ን ሥራ ው ን አስጨርስ ኧው ኣል ኧሁ ።&quot;&#39;) Output: pos token NOUN ልጅ DET ኡ PART ን NOUN ሥራ DET ው PART ን VERB አስጨርስ PRON ኧው AUX ኣል PRON ኧሁ PUNCT ። NOUN ” Thai Sentiment Classification # &#39;I love peanut butter and jelly!&#39; in thai nlu.load(&#39;th.classify.sentiment&#39;).predict(&#39;ฉันชอบเนยถั่วและเยลลี่!&#39;)[[&#39;sentiment&#39;,&#39;sentiment_confidence&#39;]] Output: sentiment sentiment_confidence positive 0.999998 Arabic Named Entity Recognition (NER) # &#39;In 1918, the forces of the Arab Revolt liberated Damascus with the help of the British&#39; in Arabic nlu.load(&#39;ar.ner&#39;).predict(&#39;في عام 1918 حررت قوات الثورة العربية دمشق بمساعدة من الإنكليز&#39;,output_level=&#39;chunk&#39;)[[&#39;entities_confidence&#39;,&#39;ner_confidence&#39;,&#39;entities&#39;]] Output: entity_class ner_confidence entities ORG [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] قوات الثورة العربية LOC [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] دمشق PER [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] الإنكليز NLU 1.1.1 Enhancements : Spark 2.3 compatibility New NLU Notebooks and Tutorials Open and Closed book question Ansering Aspect based NER for Airline ATIS Intent Classification for Airline emssages ATIS Installation # PyPi !pip install nlu pyspark==2.4.7 #Conda # Install NLU from Anaconda/Conda conda install -os_components johnsnowlabs nlu Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github NLU Version 1.1.0 We are incredibly excited to release NLU 1.1.0! This release integrates the 720+ new models from the latest Spark-NLP 2.7.0 + releases. You can now achieve state-of-the-art results with Sequence2Sequence transformers for problems like text summarization, question answering, translation between 192+ languages and extract Named Entity in various Right to Left written languages like Korean, Japanese, Chinese and many more in 1 line of code! These new features are possible because of the integration of the Google’s T5 models and Microsoft’s Marian models transformers NLU 1.1.0 has over 720+ new pretrained models and pipelines while extending the support of multi-lingual models to 192+ languages such as Chinese, Japanese, Korean, Arabic, Persian, Urdu, and Hebrew. NLU 1.1.0 New Features 720+ new models you can find an overview of all NLU models here and further documentation in the models hub NEW: Introducing MarianTransformer annotator for machine translation based on MarianNMT models. Marian is an efficient, free Neural Machine Translation framework mainly being developed by the Microsoft Translator team (646+ pretrained models &amp; pipelines in 192+ languages) NEW: Introducing T5Transformer annotator for Text-To-Text Transfer Transformer (Google T5) models to achieve state-of-the-art results on multiple NLP tasks such as Translation, Summarization, Question Answering, Sentence Similarity, and so on NEW: Introducing brand new and refactored language detection and identification models. The new LanguageDetectorDL is faster, more accurate, and supports up to 375 languages NEW: Introducing WordSegmenter model for word segmentation of languages without any rule-based tokenization such as Chinese, Japanese, or Korean NEW: Introducing DocumentNormalizer component for cleaning content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters NLU 1.1.0 New Notebooks, Tutorials and Articles Translate between 192+ languages with marian Try out the 18 Tasks like Summarization Question Answering and more on T5 Tokenize, extract POS and NER in Chinese Tokenize, extract POS and NER in Korean Tokenize, extract POS and NER in Japanese Normalize documents Aspect based sentiment NER sentiment for restaurants NLU 1.1.0 New Training Tutorials Binary Classifier training Jupyter tutorials 2 class Finance News sentiment classifier training 2 class Reddit comment sentiment classifier training 2 class Apple Tweets sentiment classifier training 2 class IMDB Movie sentiment classifier training 2 class twitter classifier training Multi Class text Classifier training Jupyter tutorials 5 class WineEnthusiast Wine review classifier training 3 class Amazon Phone review classifier training 5 class Amazon Musical Instruments review classifier training 5 class Tripadvisor Hotel review classifier training 5 class Phone review classifier training NLU 1.1.0 New Medium Tutorials 1 line to Glove Word Embeddings with NLU with t-SNE plots 1 line to Xlnet Word Embeddings with NLU with t-SNE plots 1 line to AlBERT Word Embeddings with NLU with t-SNE plots 1 line to CovidBERT Word Embeddings with NLU with t-SNE plots 1 line to Electra Word Embeddings with NLU with t-SNE plots 1 line to BioBERT Word Embeddings with NLU with t-SNE plots Translation Translation example You can translate between more than 192 Languages pairs with the Marian Models You need to specify the language your data is in as start_language and the language you want to translate to as target_language. The language references must be ISO language codes nlu.load(&#39;&lt;start_language&gt;.translate.&lt;target_language&gt;&#39;) Translate Turkish to English: nlu.load(&#39;tr.translate_to.fr&#39;) Translate English to French: nlu.load(&#39;en.translate_to.fr&#39;) Translate French to Hebrew: nlu.load(&#39;en.translate_to.fr&#39;) translate_pipe = nlu.load(&#39;en.translate_to.fr&#39;) df = translate_pipe.predict(&#39;Billy likes to go to the mall every sunday&#39;) df sentence translation Billy likes to go to the mall every sunday Billy geht gerne jeden Sonntag ins Einkaufszentrum Overview of every task available with T5 The T5 model is trained on various datasets for 17 different tasks which fall into 8 categories. Text summarization Question answering Translation Sentiment analysis Natural Language inference Coreference resolution Sentence Completion Word sense disambiguation Every T5 Task with explanation: Task Name Explanation 1.CoLA Classify if a sentence is gramaticaly correct 2.RTE Classify whether if a statement can be deducted from a sentence 3.MNLI Classify for a hypothesis and premise whether they contradict or contradict each other or neither of both (3 class). 4.MRPC Classify whether a pair of sentences is a re-phrasing of each other (semantically equivalent) 5.QNLI Classify whether the answer to a question can be deducted from an answer candidate. 6.QQP Classify whether a pair of questions is a re-phrasing of each other (semantically equivalent) 7.SST2 Classify the sentiment of a sentence as positive or negative 8.STSB Classify the sentiment of a sentence on a scale from 1 to 5 (21 Sentiment classes) 9.CB Classify for a premise and a hypothesis whether they contradict each other or not (binary). 10.COPA Classify for a question, premise, and 2 choices which choice the correct choice is (binary). 11.MultiRc Classify for a question, a paragraph of text, and an answer candidate, if the answer is correct (binary), 12.WiC Classify for a pair of sentences and a disambigous word if the word has the same meaning in both sentences. 13.WSC/DPR Predict for an ambiguous pronoun in a sentence what it is referring to. 14.Summarization Summarize text into a shorter representation. 15.SQuAD Answer a question for a given context. 16.WMT1. Translate English to German 17.WMT2. Translate English to French 18.WMT3. Translate English to Romanian refer to this notebook to see how to use every T5 Task. Question Answering Question answering example Predict an answer to a question based on input context. This is based on SQuAD - Context based question answering Predicted Answer Question Context carbon monoxide What does increased oxygen concentrations in the patient’s lungs displace? Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment. pie What did Joey eat for breakfast? Once upon a time, there was a squirrel named Joey. Joey loved to go outside and play with his cousin Jimmy. Joey and Jimmy played silly games together, and were always laughing. One day, Joey and Jimmy went swimming together 50 at their Aunt Julie’s pond. Joey woke up early in the morning to eat some food before they left. Usually, Joey would eat cereal, fruit (a pear), or oatmeal for breakfast. After he ate, he and Jimmy went to the pond. On their way there they saw their friend Jack Rabbit. They dove into the water and swam for several hours. The sun was out, but the breeze was cold. Joey and Jimmy got out of the water and started walking home. Their fur was wet, and the breeze chilled them. When they got home, they dried off, and Jimmy put on his favorite purple shirt. Joey put on a blue shirt with red and green dots. The two squirrels ate some food that Joey’s mom, Jasmine, made and went off to bed,’ # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;question &#39;) # define Data, add additional tags between sentences data = [&#39;&#39;&#39; What does increased oxygen concentrations in the patient’s lungs displace? context: Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment. &#39;&#39;&#39;] #Predict on text data with T5 t5.predict(data) How to configure T5 task parameter for Squad Context based question answering and pre-process data .setTask(&#39;question:) and prefix the context which can be made up of multiple sentences with context: Example pre-processed input for T5 Squad Context based question answering: question: What does increased oxygen concentrations in the patient’s lungs displace? context: Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment. Text Summarization Summarization example Summarizes a paragraph into a shorter version with the same semantic meaning, based on Text summarization # Set the task on T5 pipe = nlu.load(&#39;summarize&#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; The belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . &#39;&#39;&#39;, &#39;&#39;&#39; Calculus, originally called infinitesimal calculus or &quot;the calculus of infinitesimals&quot;, is the mathematical study of continuous change, in the same way that geometry is the study of shape and algebra is the study of generalizations of arithmetic operations. It has two major branches, differential calculus and integral calculus; the former concerns instantaneous rates of change, and the slopes of curves, while integral calculus concerns accumulation of quantities, and areas under or between curves. These two branches are related to each other by the fundamental theorem of calculus, and they make use of the fundamental notions of convergence of infinite sequences and infinite series to a well-defined limit.[1] Infinitesimal calculus was developed independently in the late 17th century by Isaac Newton and Gottfried Wilhelm Leibniz.[2][3] Today, calculus has widespread uses in science, engineering, and economics.[4] In mathematics education, calculus denotes courses of elementary mathematical analysis, which are mainly devoted to the study of functions and limits. The word calculus (plural calculi) is a Latin word, meaning originally &quot;small pebble&quot; (this meaning is kept in medicine – see Calculus (medicine)). Because such pebbles were used for calculation, the meaning of the word has evolved and today usually means a method of computation. It is therefore used for naming specific methods of calculation and related theories, such as propositional calculus, Ricci calculus, calculus of variations, lambda calculus, and process calculus.&#39;&#39;&#39; ] #Predict on text data with T5 pipe.predict(data) Predicted summary Text manchester united face newcastle in the premier league on wednesday . louis van gaal’s side currently sit two points clear of liverpool in fourth . the belgian duo took to the dance floor on monday night with some friends . the belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . Binary Sentence similarity/ Paraphrasing Binary sentence similarity example Classify whether one sentence is a re-phrasing or similar to another sentence This is a sub-task of GLUE and based on MRPC - Binary Paraphrasing/ sentence similarity classification t5 = nlu.load(&#39;en.t5.base&#39;) # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;mrpc &#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , &quot; Rumsfeld said . sentence2: Rather , the US acted because the administration saw &quot; existing evidence in a new light , through the prism of our experience on September 11 &quot; &#39;&#39;&#39; , &#39;&#39;&#39; sentence1: I like to eat peanutbutter for breakfast sentence2: I like to play football. &#39;&#39;&#39; ] #Predict on text data with T5 t5.predict(data) | Sentence1 | Sentence2 | prediction| |————|————|———-| |We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , “ Rumsfeld said .| Rather , the US acted because the administration saw “ existing evidence in a new light , through the prism of our experience on September 11 “ . | equivalent | | I like to eat peanutbutter for breakfast| I like to play football | not_equivalent | How to configure T5 task for MRPC and pre-process text .setTask(&#39;mrpc sentence1:) and prefix second sentence with sentence2: Example pre-processed input for T5 MRPC - Binary Paraphrasing/ sentence similarity mrpc sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , &quot; Rumsfeld said . sentence2: Rather , the US acted because the administration saw &quot; existing evidence in a new light , through the prism of our experience on September 11&quot;, Regressive Sentence similarity/ Paraphrasing Measures how similar two sentences are on a scale from 0 to 5 with 21 classes representing a regressive label. This is a sub-task of GLUE and based onSTSB - Regressive semantic sentence similarity . t5 = nlu.load(&#39;en.t5.base&#39;) # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;stsb &#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; sentence1: What attributes would have made you highly desirable in ancient Rome? sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?&#39; &#39;&#39;&#39; , &#39;&#39;&#39; sentence1: What was it like in Ancient rome? sentence2: What was Ancient rome like? &#39;&#39;&#39;, &#39;&#39;&#39; sentence1: What was live like as a King in Ancient Rome?? sentence2: What was Ancient rome like? &#39;&#39;&#39; ] #Predict on text data with T5 t5.predict(data) Question1 Question2 prediction What attributes would have made you highly desirable in ancient Rome? How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER? 0 What was it like in Ancient rome? What was Ancient rome like? 5.0 What was live like as a King in Ancient Rome?? What is it like to live in Rome? 3.2 How to configure T5 task for stsb and pre-process text .setTask(&#39;stsb sentence1:) and prefix second sentence with sentence2: Example pre-processed input for T5 STSB - Regressive semantic sentence similarity stsb sentence1: What attributes would have made you highly desirable in ancient Rome? sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?&#39;, Grammar Checking Grammar checking with T5 example Judges if a sentence is grammatically acceptable. Based on CoLA - Binary Grammatical Sentence acceptability classification pipe = nlu.load(&#39;grammar_correctness&#39;) # Set the task on T5 pipe[&#39;t5&#39;].setTask(&#39;cola sentence: &#39;) # define Data data = [&#39;Anna and Mike is going skiing and they is liked is&#39;,&#39;Anna and Mike like to dance&#39;] #Predict on text data with T5 pipe.predict(data) |sentence | prediction| |————|————| | Anna and Mike is going skiing and they is liked is | unacceptable | | Anna and Mike like to dance | acceptable | Document Normalization Document Normalizer example The DocumentNormalizer extracts content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters pipe = nlu.load(&#39;norm_document&#39;) data = &#39;&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;&#39; df = pipe.predict(data,output_level=&#39;document&#39;) df |text|normalized_text| |——|————-| | &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; |Example This is an example of a simple HTML page with one paragraph.| Word Segmenter Word Segmenter Example The WordSegmenter segments languages without any rule-based tokenization such as Chinese, Japanese, or Korean pipe = nlu.load(&#39;ja.segment_words&#39;) # japanese for &#39;Donald Trump and Angela Merkel dont share many opinions&#39; ja_data = [&#39;ドナルド・トランプとアンゲラ・メルケルは多くの意見を共有していません&#39;] df = pipe.predict(ja_data, output_level=&#39;token&#39;) df token ドナルド ・ トランプ と アンゲラ ・ メルケル は 多く の 意見 を 共有 し て い ませ ん Installation # PyPi !pip install nlu pyspark==2.4.7 #Conda # Install NLU from Anaconda/Conda conda install -os_components johnsnowlabs nlu Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github NLU Version 1.0.6 Trainable Multi Label Classifiers, predict Stackoverflow Tags and much more in 1 Line of with NLU 1.0.6 We are glad to announce NLU 1.0.6 has been released! NLU 1.0.6 comes with the Multi Label classifier, it can learn to map strings to multiple labels. The Multi Label Classifier is using Bidirectional GRU and CNNs inside TensorFlow and supports up to 100 classes. NLU 1.0.6 New Features Multi Label Classifier The Multi Label Classifier learns a 1 to many mapping between text and labels. This means it can predict multiple labels at the same time for a given input string. This is very helpful for tasks similar to content tag prediction (HashTags/RedditTags/YoutubeTags/Toxic/E2e etc..) Support up to 100 classes Pre-trained Multi Label Classifiers are already avaiable as Toxic and E2E classifiers Multi Label Classifier Train Multi Label Classifier on E2E dataset Demo Train Multi Label Classifier on Stack Overflow Question Tags dataset Demo This model can predict multiple labels for one sentence. To train the Multi Label text classifier model, you must pass a dataframe with a text column and a y column for the label. The y label must be a string column where each label is seperated with a seperator. By default, , is assumed as line seperator. If your dataset is using a different label seperator, you must configure the label_seperator parameter while calling the fit() method. By default Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings for training. fitted_pipe = nlu.load(&#39;train.multi_classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) If you add a nlu sentence embeddings reference, before the train reference, NLU will use that Sentence embeddings instead of the default USE. #Train on BERT sentence emebddings fitted_pipe = nlu.load(&#39;embed_sentence.bert train.multi_classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Configure a custom line seperator #Use ; as label seperator fitted_pipe = nlu.load(&#39;embed_sentence.electra train.multi_classifier&#39;).fit(train_df, label_seperator=&#39;;&#39;) preds = fitted_pipe.predict(train_df) NLU 1.0.6 Enhancements Improved outputs for Toxic and E2E Classifier. by default, all predicted classes and their confidences which are above the threshold will be returned inside of a list in the Pandas dataframe by configuring meta=True, the confidences for all classes will be returned. NLU Version 1.0.6 Train Multi Label Classifier on E2E dataset Train Multi Label Classifier on Stack Overflow Question Tags dataset NLU 1.0.6 Bug-fixes Fixed a bug that caused en.ner.dl.bert to be inaccessible Fixed a bug that caused pt.ner.large to be inaccessible Fixed a bug that caused USE embeddings not properly beeing configured to document level output when using multiple embeddings at the same time NLU Version 1.0.5 Trainable Part of Speech Tagger (POS), Sentiment Classifier with BERT/USE/ELECTRA sentence embeddings in 1 Line of code! Latest NLU Release 1.0.5 We are glad to announce NLU 1.0.5 has been released! This release comes with a trainable Sentiment classifier and a Trainable Part of Speech (POS) models! These Neural Network Architectures achieve the state of the art (SOTA) on most binary Sentiment analysis and Part of Speech Tagging tasks! You can train the Sentiment Model on any of the 100+ Sentence Embeddings which include BERT, ELECTRA, USE, Multi Lingual BERT Sentence Embeddings and many more! Leverage this and achieve the state of the art in any of your datasets, all of this in just 1 line of Python code NLU 1.0.5 New Features Trainable Sentiment DL classifier Trainable POS NLU 1.0.5 New Notebooks and Tutorials Sentiment Classification Training Demo Part Of Speech Tagger Training demo Sentiment Classifier Training Sentiment Classification Training Demo To train the Binary Sentiment classifier model, you must pass a dataframe with a ‘text’ column and a ‘y’ column for the label. By default Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings. fitted_pipe = nlu.load(&#39;train.sentiment&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) If you add a nlu sentence embeddings reference, before the train reference, NLU will use that Sentence embeddings instead of the default USE. #Train Classifier on BERT sentence embeddings fitted_pipe = nlu.load(&#39;embed_sentence.bert train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) #Train Classifier on ELECTRA sentence embeddings fitted_pipe = nlu.load(&#39;embed_sentence.electra train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Part Of Speech Tagger Training Part Of Speech Tagger Training demo fitted_pipe = nlu.load(&#39;train.pos&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) NLU 1.0.5 Installation changes Starting from version 1.0.5 NLU will not automatically install pyspark for users anymore. This enables easier customizing the Pyspark version which makes it easier to use in various cluster enviroments. To install NLU from now on, please run pip install nlu pyspark==2.4.7 or install any pyspark&gt;=2.4.0 with pyspark&lt;3 NLU 1.0.5 Improvements Improved Databricks path handling for loading and storing models. NLU Version 1.0.4 John Snow Labs NLU 1.0.4 : Trainable Named Entity Recognizer (NER) , achieve SOTA in 1 line of code and easy scaling to 100’s of Spark nodes We are glad to announce NLU 1.0.4 releases the State of the Art breaking Neural Network architecture for NER, Char CNNs - BiLSTM - CRF! #fit and predict in 1 line! nlu.load(&#39;train.ner&#39;).fit(dataset).predict(dataset) #fit and predict in 1 line with BERT! nlu.load(&#39;bert train.ner&#39;).fit(dataset).predict(dataset) #fit and predict in 1 line with ALBERT! nlu.load(&#39;albert train.ner&#39;).fit(dataset).predict(dataset) #fit and predict in 1 line with ELMO! nlu.load(&#39;elmo train.ner&#39;).fit(dataset).predict(dataset) Any NLU pipeline stored can now be loaded as pyspark ML pipeline # Ready for big Data with Spark distributed computing import pyspark nlu_pipe.save(path) pyspark_pipe = pyspark.ml.PipelineModel.load(stored_model_path) pyspark_pipe.transform(spark_df) NLU 1.0.4 New Features Trainable Named Entity Recognizer NLU pipeline loadable as Spark pipelines NLU 1.0.4 New Notebooks,Tutorials and Docs NER training demo Multi Class Text Classifier Training Demo updated to showcase usage of different Embeddings New Documentation Page on how to train Models with NLU Databricks Notebook showcasing Scaling with NLU NLU 1.0.4 Bug Fixes Fixed a bug that NER token confidences do not appear. They now appear when nlu.load(‘ner’).predict(df, meta=True) is called. Fixed a bug that caused some Spark NLP models to not be loaded properly in offline mode NLU Version 1.0.3 We are happy to announce NLU 1.0.3 comes with a lot new features, training classifiers, saving them and loading them offline, enabling running NLU with no internet connection, new notebooks and articles! NLU 1.0.3 New Features Train a Deep Learning classifier in 1 line! The popular ClassifierDL which can achieve state of the art results on any multi class text classification problem is now trainable! All it takes is just nlu.load(‘train.classifier).fit(dataset) . Your dataset can be a Pandas/Spark/Modin/Ray/Dask dataframe and needs to have a column named x for text data and a column named y for labels Saving pipelines to HDD is now possible with nlu.save(path) Loading pipelines from disk now possible with nlu.load(path=path). NLU offline mode: Loading from disk makes running NLU offline now possible, since you can load pipelines/models from your local hard drive instead of John Snow Labs AWS servers. NLU 1.0.3 New Notebooks and Tutorials New colab notebook showcasing nlu training, saving and loading from disk Sentence Similarity with BERT, Electra and Universal Sentence Encoder Medium Tutorial Sentence Similarity with BERT, Electra and Universal Sentence Encoder Train a Deep Learning Classifier Sentence Detector Notebook Updated New Workshop video NLU 1.0.3 Bug fixes Sentence Detector bugfix NLU Version 1.0.2 We are glad to announce nlu 1.0.2 is released! NLU 1.0.2 Enhancements More semantically concise output levels sentence and document enforced : If a pipe is set to output_level=’document’ : Every Sentence Embedding will generate 1 Embedding per Document/row in the input Dataframe, instead of 1 embedding per sentence. Every Classifier will classify an entire Document/row Each row in the output DF is a 1 to 1 mapping of the original input DF. 1 to 1 mapping from input to output. If a pipe is set to output_level=’sentence’ : Every Sentence Embedding will generate 1 Embedding per Sentence, Every Classifier will classify exactly one sentence Each row in the output DF can is mapped to one row in the input DF, but one row in the input DF can have multiple corresponding rows in the output DF. 1 to N mapping from input to output. Improved generation of column names for classifiers. based on input nlu reference Improved generation of column names for embeddings, based on input nlu reference Improved automatic output level inference Various test updates Integration of CI pipeline with Github Actions New Documentation is out! Check it out here : https://nlp.johnsnowlabs.com/ NLU Version 1.0.1 NLU 1.0.1 Bugfixes Fixed bug that caused NER pipelines to crash in NLU when input string caused the NER model to predict without additional metadata NLU Version 1.0.0 Automatic to Numpy conversion of embeddings Added various testing classes New 6 embeddings at once notebook with t-SNE and Medium article Integration of Spark NLP 2.6.2 enhancements and bugfixes https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.2 Updated old T-SNE notebooks with more elegant and simpler generation of t-SNE embeddings NLU Version 0.2.1 Various bugfixes Improved output column names when using multiple classifirs at once NLU Version 0.2.0 Improved output column names classifiers NLU Version 0.1.0 We are glad to announce that NLU 0.1 has been released! NLU makes the 350+ models and annotators in Spark NLPs arsenal available in just 1 line of python code and it works with Pandas dataframes! A picture says more than a 1000 words, so here is a demo clip of the 12 coolest features in NLU, all just in 1 line! NLU in action What does NLU 0.1 include? NLU provides everything a data scientist might want to wish for in one line of code! 350 + pre-trained models 100+ of the latest NLP word embeddings ( BERT, ELMO, ALBERT, XLNET, GLOVE, BIOBERT, ELECTRA, COVIDBERT) and different variations of them 50+ of the latest NLP sentence embeddings ( BERT, ELECTRA, USE) and different variations of them 50+ Classifiers (NER, POS, Emotion, Sarcasm, Questions, Spam) 40+ Supported Languages Labeled and Unlabeled Dependency parsing Various Text Cleaning and Pre-Processing methods like Stemming, Lemmatizing, Normalizing, Filtering, Cleaning pipelines and more NLU 0.1 Features Google Collab Notebook Demos Named Entity Recognition (NER) NER pretrained on ONTO Notes NER pretrained on CONLL NER pretrained on ONTO Notes NER pretrained on CONLL Part of speech (POS) POS pretrained on ANC dataset Classifiers Unsupervised Keyword Extraction with YAKE Toxic Text Classifier Twitter Sentiment Classifier Movie Review Sentiment Classifier Sarcasm Classifier 50 Class Questions Classifier 20 Class Languages Classifier Fake News Classifier E2E Classifier Cyberbullying Classifier Spam Classifier Word and Sentence Embeddings BERT Word Embeddings and T-SNE plotting BERT Sentence Embeddings and T-SNE plotting ALBERT Word Embeddings and T-SNE plotting ELMO Word Embeddings and T-SNE plotting XLNET Word Embeddings and T-SNE plotting ELECTRA Word Embeddings and T-SNE plotting COVIDBERT Word Embeddings and T-SNE plotting BIOBERT Word Embeddings and T-SNE plotting GLOVE Word Embeddings and T-SNE plotting USE Sentence Embeddings and T-SNE plotting Depenency Parsing Untyped Dependency Parsing Typed Dependency Parsing Text Pre Processing and Cleaning Tokenization Stopwords removal Stemming Lemmatization Normalizing Spellchecking Sentence Detecting Chunkers N Gram Entity Chunking Matchers Date Matcher",
    "url": "/docs/en/jsl/release_notes",
    "relUrl": "/docs/en/jsl/release_notes"
  },
  "1351": {
    "id": "1351",
    "title": "Release Notes",
    "content": "5.3.2 Release date: 30-08-2023 NLP Lab 5.3 - A Leap Forward in Pre-Annotation through ChatGPT-Powered Entity Recognition We’re excited to present NLP Lab 5.3, an exciting update that marks our foray into integrating Large Language Models (LLMs) into our platform. Leading the charge is the integration with ChatGPT family of models, the first in a series of LLM integrations we have planned for the future. This not only sets the stage for a new era of enhanced pre-annotation capabilities but also underscores our commitment to staying at the forefront of NLP innovation. By weaving ChatGPT’s prowess into our ecosystem, we’re offering users an expanded range of prompt possibilities and a refined entity extraction process. But that’s not all! Beyond the ChatGPT integration, we’ve made a series of enhancements across the board. From a revamped taxonomy customization experience for section-based projects to thoughtful improvements in OCR text formatting, every change in this release is designed to improve your annotation experience. Whether you’re a seasoned NLP Lab user or just getting started, we believe this update will offer you a blend of familiarity and fresh innovation, ensuring a smoother, more productive annotation journey. Dive into the details below to discover all that NLP Lab 5.3 has in store for you. Entity Extraction and Pre-Annotation via GPT Prompting The highlight of this release is the integration with an external service provider, Open AI, to expand and deepen the range of prompts available for pre-annotation (in addition to the Zero Shot entity and relation prompts already supported). This feature:. Broadens Prompt Possibilities: By integrating with Open AI LLM models, users can tap into a more diverse set of prompts, leveraging external expertise to craft pre-annotations, as an alternative pre-annotation solution or when pre-trained models are not available. Efficient Entity Extraction: As current LLMs, GPT family included, are not very good at entity recognition tasks, NLP Lab included a post-processing step on the result provided by LLM. This improves entity identification and helps precisely locate the entities in the given text. These entities, carefully curated and aligned with NLP Lab pre-annotation requirements pave the way for a more efficient and streamlined annotation experience. The following sections explain in detail how to define and use GPT prompts. Setting Up the Integration with Open AI service Integrating “ChatGPT” into the NLP Lab has been designed to be a straightforward process, ensuring users can harness the power of external expertise seamlessly. It consists of three easy steps: Integrations Page: Navigate to the Integrations Page located within the System Settings. This is the hub where all external service providers, including Open AI’s GPT Models, can be defined and managed. Define the Service Provider: To initiate the integration, users are required to provide specific details: Service Provider Name: This is the identifier for the external service, which in this case would be “ChatGPT” or any other name you prefer to use. Secret Key: Every external service comes with a unique Secret Key that ensures secure communication between the platforms. Enter the Secret Key associated with your Open AI subscription here. To ensure the integration process is error-free, users can validate the provided Secret Key directly within the form. This validation step ensures that the connection is secure and that the key is correct. Project Association: Once a successful connection with “ChatGPT” (or any external LLM service provider) is established, it doesn’t end there. The integrated service will now be available for association with selected projects. This means users can decide which projects will benefit from the “ChatGPT” integration and enable it accordingly. The Open AI integration allows users to tap into a vast reservoir of external expertise, enhancing the depth and breadth of their projects. We’ve ensured that the integration process is as intuitive as possible, allowing users to focus on what truly matters: crafting refined and effective pre-annotations. ChatGPT Prompt Definition and Testing Users can generate LLM prompts on the dedicated Prompt page from the Hub of Resources. For ChatGPT Prompts, NLP Lab offers a dedicated definition interface. Here’s what to expect when creating a new LLM prompt: Name the Prompt: Within this new tab, users will first be asked to provide a name for their prompt. This name will be used for pre-annotating identified entities. At this point, we recommend creating one prompt per target entity. Select the Service Provider: Next, users can choose the specific service provider they’ve previously set up via the Integrations Page. Test in Real-time: A standout feature is the ability to test ChatGPT prompts at creation time. As you craft your prompt, you can immediately see how it performs on some test data. This not only allows for immediate feedback but also ensures that the final prompt aligns perfectly with the user’s objectives. This streamlined approach ensures that integrating and testing external prompts is as intuitive and efficient as possible. Consistent Workflow with LLM Prompts Even with the introduction of new features in NLP Lab’s 5.3.0 release, users can take comfort in the consistent experience offered when working with prompts. The addition of external service provider prompts brings a fresh layer to the annotation process, yet the core workflow you’re familiar with stays the same. Familiarity Amidst Innovation: Despite the new integrations, the process of using available prompts remains as straightforward as ever. Whether you’re working with traditional prompts or the newly introduced ones, the experience is smooth and consistent. Seamless Transition: Our commitment to user-centric design means that even as we innovate, we prioritize the ease of use you’ve come to expect. Transitioning to or incorporating external prompts is made effortless, with the interface and steps for prompt creation, selection, and integration remaining intuitive and unchanged. With NLP Lab 5.3.0, you get the best of both worlds: exciting new features and the comfort of a familiar workflow. Note: Pre-annotation of tasks using LLM Prompts does not require the deployment of the pre-annotation server. The pop-up to deploy the pre-annotation server is only shown if the project configuration consists of both LLM prompts and spark NLP models. Improvements Enhanced Taxonomy to Section Mapping NLP Labs 5.3.0 brings significant upgrades to the taxonomy customization experience when dealing with Section-based projects. Revamped Viewing Experience for Taxonomy Elements: We’ve reimagined the way users view “Labels to Sections” associations: At-a-Glance Overview: Gone are the days of manually selecting each label to view its associations. Now, users can instantly see the complete mapping of Labels to Sections, providing a holistic view of the project’s current configuration. Efficient Updates: This consolidated view enables users to quickly grasp their current setup and make any necessary adjustments with ease, making the entire process more user-centric. Bulk Association of “Labels/Choices to Section: A standout enhancement is the ability to associate “Labels/Choices” to sections in bulk. Unlike the previous version, where users could only associate one label at a time, this update allows for simultaneous selection and association of multiple labels to various sections. This enhancement not only streamlines the project configuration and annotation process but also offers a more intuitive user experience, saving valuable time and effort. To facilitate these new features, we have made minor adjustments to the project configuration page in NLP Labs. Under the “Customize Labels” tab, you can now find a new button named “Associate Sections”. Clicking on this button allows users to quickly access the tabular form of the mapping, making it easier to manage Labels/Choices linkage with specific sections. For both “Labels” and “Choices”, we have provided the dedicated “Associate Sections” button on their respective configuration tabs. These new improvements are supported in all section-based annotation-enabled projects, including Visual NER projects. Section-Based Annotation: automatically disregard empty sections In earlier iterations of the section-based annotation project feature, users noticed that some empty sections were marked as relevant when automatically splitting content into paragraphs. Recognizing this issue, version 5.3.0 brings a thoughtful enhancement: sections without any textual content are now automatically disregarded. This ensures a more streamlined annotation process, omitting empty sections like the examples provided below. Updated Pre-annotation Status indicator on task page In the past, the pre-annotate status exclusively indicated whether a prediction was marked as “generated,” “not generated,” or if the pre-annotation process had encountered a failure. With the integration of pre-annotations derived from ChatGPT, the updated approach to preannotation status will encompass statuses for both SparkNLP predictions and ChatGPT predictions. Specifically, for projects involving both SparkNLP models and prompts generated through ChatGPT as an external provider, a revamped pre-annotation circle has been reimagined as a ring divided into two halves. The first half of the ring will showcase the pre-annotation status derived from SparkNLP, while the second half will depict the status of predictions stemming from ChatGPT. Enhanced Formatting for OCR Text For text projects using PDF/Image processing via Visual NLP, we’re excited to introduce an enhanced format feature. Once this feature is activated, the imported text is reformatted to offer better clarity and spacing within the annotation interface. Our goal with this enhancement is to foster a clearer, more spacious workspace, ensuring precision and ease during text annotation. Tags Definition Button was moved on the Tasks Page In version 5.3.0, the “Add More” option for task tags was moved. Based on user feedback, we’ve moved the “Add More” button to a more accessible location at the top of the Tags dropdown list. Along with its new position, the button now sports a “+” icon and a refreshed design, while retaining its original functionality. Importantly, the button’s functionality remains consistent with its previous purpose. Bug Fixes For HTML sources projects replace the dialogue in PREVIEWS with the JSL link The preview format for HTML Dialogues &amp; Conversations projects has been enhanced to feature a JSL link in place of the traditional ‘Dialogues’. Tags are not consistently assigned to Tasks Previously, tasks generated from external providers lacked assigned tags, posing challenges for users in distinguishing imported tasks’ sources. To address this, tags are now consistently assigned when clicking on the edges of tag options or the color indicators instead of only being assigned when clicking directly on the tag name. Model evaluation starts before the required resources are available when the maximum server count is reached In the previous version, model evaluations would commence even if the necessary resources were unavailable or if the maximum server count had been reached. To address this, a new approach has been implemented. When a model evaluation is in progress, a dedicated server is generated on the cluster page. This server is designed to be automatically removed once the evaluation concludes. Furthermore, should the maximum server count be reached and a user initiates an evaluation, an error message indicating “Maximum Model Server Limit Reached” will be displayed. Additionally, users have the option to delete an evaluation server from the cluster page. This action results in the evaluation being aborted on the Train page, accompanied by a notification banner indicating the aborted evaluation. For all Search Fields, White Space before/after the “search keyword” causes the search action to return no results Previously, in all Search Fields, having white space before or after the “search keyword” resulted in the search action yielding no results. Consequently, a change has been implemented to ensure that search results are displayed accurately regardless of any leading/trailing whitespace around the search keyword. This enhancement is universally applicable to all search fields within the application. The duplication error for Section Field does not resolve if the user changes/deletes the value of the other duplicate field Previously, if a Section-based Rule with a duplicate name was added, the error would still show as if the first originally named rule was edited to a different name. With Version 5.3.0, the duplication error will now be resolved if any of the rules that fall under the duplication case are edited to be unique. Incorrect active section name is shown in the top bar for pages without relevant section In the case of a multi-page task that does not have relevant sections, the previously active section will no longer appear at the page’s top. Additionally, if a page contains no pertinent sections, the Active tab on the task’s upper part will be displayed in a subdued manner. Tasks imported in Visual NER Project are not visible until the tasks page is refreshed The issue of the OCR task imported in Visual NER projects not appearing on the Tasks page and the Import button staying disabled until manually refreshed has been resolved in this version. Clicking on undo button in the playground resets every detail of the rule deployed Previously, using the Undo button in the playground didn’t restore rules to their original state after modifications. The Undo action cleared all aspects (suffix, rule type, content length) from deployed playground rules. This problem has now been addressed. Section Based Annotation: Merger of consecutive sections of the same name Previously, when the option “Merge Consecutive sections of the same type” was chosen, any two sections created by the rule that appeared consecutively were combined into a single section. This approach posed a challenge as it could result in an elongated chain of sections if all sections were consecutive. With the recent improvement, only the relevant sections with matching section names are merged. For instance, if there are sections named S1, S1, S3, S1, S2, S2 created consecutively, only the first occurrence of S1 and the final instance of S2 will be merged into a single section, while S3 will remain unaffected. Section Based Annotation: Model is redeployed if the same classifier is modified for the same project The sections classifier no longer undergoes redeployment each time classifier options are modified for the same model. Additionally, the section classifier remains unaffected when an additional classifier rule using the same classifier is introduced. Consequently, in scenarios involving task importation, newly added classifier rules are integrated into the new tasks. However, the section classifier is automatically deployed in situations where a new classifier server is added and the previous one is subsequently removed. “Filter pre-annotations according to my latest completion” shows predictions for deleted sections in SBA-enabled project There was an inconsistency when applying “Filter pre-annotations according to my latest completion” for SBA enabled task. The problem of the filter not functioning correctly, resulting in predictions for deleted sections, has been resolved in version 5.3.0. RE prompts using NER Prompts cannot be deployed in the playground Previously, errors were encountered in the playground when deploying the Relation prompt using the NER prompt in the playground. With this update, these issues have been resolved. Generate Synthetic Text: Unable to import generated text if the SBA project has Classification Rules There was a singular case for Section-based Projects, where adding classification section-based rules to create sections prevented the import of the generated synthetic text. In version 5.3.0, this has been fixed and now users can import the synthetic tasks after or even while the classification model for the section rules is being deployed. Validation missing when deleting section rule which is already associated with label/choice in the Configuration &gt; Customize Labels page Previously, when a user tried to delete the section rule that was associated with label/choice, there was no warning suggesting user that the section is linked to labels/choices in the configuration. The issue has now been resolved and users are given a warning dialog box about the link between the section and the labels/choices and he/she can either proceed and delete the section or cancel it and make necessary changes in configuration. Filter XML code does not filter labels for the NER project Before, the Filter XML function failed to filter the label/assertion list effectively. This issue has now been resolved. When a project’s taxonomy contains a substantial number of NER/Assertion labels, the display of the taxonomy consumes significant screen space, impeding annotators’ navigation through the labels. To address this, Annotation Lab has introduced a search feature for labels within NER projects, offering an autocomplete search option. For incorporating the search bar targeting NER Labels or Choices, utilize the Filter tag as exemplified in the subsequent XML configuration. This filtering mechanism is also applicable to Visual NER filters. Versions 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/release_notes",
    "relUrl": "/docs/en/alab/release_notes"
  },
  "1352": {
    "id": "1352",
    "title": "NLP Server release notes 0.4.0",
    "content": "0.4.0 Highlights This version of NLP Server offers support for licensed models and annotators. Users can now upload a Spark NLP for Healthcare license file and get access to a wide range of additional annotators and transformers. A valid license key also gives access to more than 400 state-of-the-art healthcare models. Those can be used via easy to learn NLU spells or via API calls. NLP Server now supports better handling of large amounts of data to quickly analyze via UI by offering support for uploading CSV files. Support for floating licenses. Users can now take advantage of the floating license flexibility and use those inside of the NLP Server. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_4_0",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_4_0"
  },
  "1353": {
    "id": "1353",
    "title": "NLP Server release notes 0.5.0",
    "content": "0.5.0 Highlights Support for easy license import from my.johnsnowlabs.com. Visualize annotation results with Spark NLP Display. Examples of results obtained using popular spells on sample texts have been added to the UI. Performance improvement when previewing the annotations. Support for 22 new models for 23 languages including various African and Indian languages as well as Medical Spanish models powered by NLU 3.4.1 Various bug fixes Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_5_0",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_5_0"
  },
  "1354": {
    "id": "1354",
    "title": "NLP Server release notes 0.6.0",
    "content": "0.6.0 Fields Details Name NLP Server Version 0.6.0 Type Minor Release Date 2022-04-06 Overview We are excited to release NLP Server v0.6.0! This new release comes with exciting new features and improvements that extend and enhance the capabilities of the NLP Server. This release comes with the ability to share the models with the Annotation Lab. This will enable easy access to custom models uploaded to or trained with the Annotation Lab or to pre-trained models downloaded to Annotation Lab from the NLP Models Hub. As such the NLP Server becomes an easy and quick tool for testing our trained models locally on your own infrastructure with zero data sharing. Another important feature we have introduced is the support for Spark OCR spells. Now we can upload images, PDFs, or other documents to the NLP Server and run OCR spells on top of it. The results of the processed documents are also available for export. The release also includes a few improvements to the existing features and some bug fixes. Key Information For a smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications NLP Server is now available on Azure Marketplace as well as on AWS marketplace. Major Features and Improvements Support for custom models trained with the Annotation Lab Models trained with the Annotation Lab are now available as “custom” spells in the NLP Server. Similarly, models manually uploaded to the Annotation Lab, or downloaded from the NLP Models Hub are also made available for use in the NLP Server. This is only supported in a docker setup at present when both tools are deployed in the same machine. Support for Spark OCR spells OCR spells are now supported by NLP Server in the presence of a valid OCR license. Users can upload an image, PDF, or other supported document format and run the OCR spells on it. The processed results are also available for download as a text document. It is also possible to upload multiple files at once for OCR operation. These files can be images, PDFs, word documents, or a zipped file. Other Improvements Now users can chain multiple spells together to analyze the input data. The order of operation on the input data will be in the sequence of the spell chain from left to right. NLP Server now supports more than 5000+ models in 250+ languages powered by NLU. Bug Fixes Not found error seen when running predictions using certain spells. The prediction job runs in an infinite loop when using certain spells. For input data having new line characters JSON exception was seen when processing the output from NLU. Incorrect license information was seen in the license popup. Spell field cleared abruptly when typing the spells. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_6_0",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_6_0"
  },
  "1355": {
    "id": "1355",
    "title": "NLP Server release notes 0.6.1",
    "content": "0.6.1 Fields Details Name NLP Server Version 0.6.1 Type Patch Release Date 2022-05-06 Overview We are excited to release NLP Server v0.6.1! We are continually committed towards improving the experience for our users and making our product reliable and easy to use. This release focuses on improving the stability of the NLP Server and cleaning up some annoying bugs. To enhance the user experience, the product now provides interactive and informative responses to the users. The improvements and bug fixes are mentioned in their respective sections below. Key Information For smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications. NLP Server is available on both AWS and Azure marketplace. Improvements Support for new models for Lemmatizers, Parts of Speech Taggers, and Word2Vec Embeddings for over 66 languages, with 20 languages being covered for the first time by NLP Server, including ancient and exotic languages like Ancient Greek, Old Russian, Old French and much more. Bug Fixes The prediction job runs in an infinite loop when using certain spells. Now after 3 retries it aborts the process and informs users appropriately. Issue when running lang spell for language classification. The prediction job runs in an infinite loop when incorrect data format is selected for a given input data. The API request for processing spell didn’t work when format parameter was not provided. Now it uses a default value in such case. Users were unable to login to their MYJSL account from NLP Server. Proper response when there is issue in internet connectivity when running spell. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_6_1",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_6_1"
  },
  "1356": {
    "id": "1356",
    "title": "NLP Server release notes 0.7.0",
    "content": "0.7.0 Fields Details Name NLP Server Version 0.7.0 Type Minor Release Date 2022-06-07 Overview We are excited to release NLP Server v0.7.0! This new release comes with an exciting new feature of table extraction from various file formats. Table extraction feature enables extracting tabular content from the document. This extracted content is available as JSON and hence can again be processed with different spells for further predictions. The various supported files formats are documents (pdf, doc, docx), slides (ppt, pptx), and zipped content containing the mentioned formats. The improvements are mentioned in their respective sections below. Key Information For smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications. NLP Server is available on both AWS and Azure marketplace. Major Features and Improvements Support for Table extraction NLP Server now supports extracting tabular content from various file types. The currently supported file types are documents (pdf, doc, docx), slides (ppt, pptx), and zipped content containing any of the mentioned formats. These extracted contents are available as JSON output from both UI and API that can easily be converted to suitable Data Frames (e.g., pandas DF) for further processing. The output of the table extraction process can also be viewed in the NLP Server UI as a flat table. Currently, if multiple tables are extracted from the document, then only one of the tables selected randomly will be shown as a preview in the UI. However, upon downloading all the extracted tables are exported in separate JSON dumps combined in a single zipped file. For this version, the table extraction on PDF files is successful only if the PDF contains necessary metadata about the table content. Other Improvements Support for over 600 new models, and over 75 new languages including ancient, dead, and extinct languages. Transformer-based embeddings and token classifiers are powered by state-of-the-art CamemBertEmbeddings and DeBertaForTokenClassification based architectures. Added Portuguese De-identification models, NER models for Gene detection, and RxNorm Sentence resolution model for mapping and extracting pharmaceutical actions as well as treatments. JSON payload is now supported in the request body when using create result API. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_7_0",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_7_0"
  },
  "1357": {
    "id": "1357",
    "title": "NLP Server release notes 0.7.1",
    "content": "0.7.1 Fields Details Name NLP Server Version 0.7.1 Type Patch Release Date 2022-06-17 Overview We are excited to release NLP Server v0.7.1! We are committed to continuously improve the experience for our users and make our product reliable and easy to use. This release focuses on solving a few bugs and improving the stability of the NLP Server. Key Information For smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications. NLP Server is available on both AWS and Azure marketplaces. Bug Fixes Issue when running NER ONTO spell. Issue when running dep spell. Since the spell was broken it is temporarily blacklisted. Document normalizer included the HTML, XML tags to the output even after normalization. Issue when running language translation spells &lt;from_lang&gt;.translate_to.&lt;to_lang&gt;. Upon cancelation of custom model uploading job exception was seen in the logs. Some few UI related issues and abnormalities during operation. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_7_1",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_7_1"
  },
  "1358": {
    "id": "1358",
    "title": "Spark NLP release notes 1.0.0",
    "content": "1.0.0 Release date: 12-02-2020 Overview Spark NLP OCR functionality was reimplemented as set of Spark ML transformers and moved to separate Spark OCR library. New Features Added extraction coordinates of each symbol in ImageToText Added ImageDrawRegions transformer Added ImageToPdf transformer Added ImageMorphologyOpening transformer Added ImageRemoveObjects transformer Added ImageAdaptiveThresholding transformer Enhancements Reimplement main functionality as Spark ML transformers Moved DrawRectangle functionality to PdfDrawRegions transformer Added ‘start’ function with support SparkMonitor initialization Moved PositionFinder to Spark OCR Bugfixes Fixed bug with transforming complex pdf to image Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_0_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_0_0"
  },
  "1359": {
    "id": "1359",
    "title": "Spark NLP release notes 1.10.0",
    "content": "1.10.0 Release date: 20-01-2021 Overview Support Microsoft Docx documents. New Features Added DocToText transformer for extract text from DOCX documents. Added DocToTextTable transformer for extract table data from DOCX documents. Added DocToPdf transformer for convert DOCX documents to PDF format. Bugfixes Fixed issue with loading model data on some cluster configurations Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_10_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_10_0"
  },
  "1360": {
    "id": "1360",
    "title": "Spark NLP release notes 1.11.0",
    "content": "1.11.0 Release date: 25-02-2021 Overview Support German, French, Spanish and Russian languages. Improving PositionsFinder and ImageToText for better support de-identification. New Features Loading model data from S3 in ImageToText. Added support German, French, Spanish, Russian languages in ImageToText. Added different OCR model types: Base, Best, Fast in ImageToText. Enhancements Added spaces symbols to the output positions in the ImageToText transformer. Eliminate python-levensthein from dependencies for simplify installation. Bugfixes Fixed issue with extracting coordinates in in ImageToText. Fixed loading model data on cluster in yarn mode. New notebooks Languages Support Image DeIdentification Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_11_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_11_0"
  },
  "1361": {
    "id": "1361",
    "title": "Spark NLP release notes 1.1.0",
    "content": "1.1.0 Release date: 03-03-2020 Overview This release contains improvements for preprocessing image before run OCR and added possibility to store results to PDF for keep original formatting. New Features Added auto calculation maximum size of objects for removing in ImageRemoveObjects. This improvement avoids to remove . and affect symbols with dots (i, !, ?). Added minSizeFont param to ImageRemoveObjects transformer for activate this functional. Added ocrParams parameter to ImageToText transformer for set any ocr params. Added extraction font size in ImageToText Added TextToPdf transformer for render text with positions to pdf file. Enhancements Added setting resolution in ImageToText. And added ignoreResolution param with default true value to ImageToText transformer for back compatibility. Added parsing resolution from image metadata in BinaryToImage transformer. Added storing resolution in PdfToImage transformer. Added resolution field to Image schema. Updated ‘start’ function for set ‘PYSPARK_PYTHON’ env variable. Improve auto-scaling/skew correction: improved access to images values removing unnecessary copies of images adding more test cases improving auto-correlation in auto-scaling. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_1_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_1_0"
  },
  "1362": {
    "id": "1362",
    "title": "Spark NLP release notes 1.1.1",
    "content": "1.1.1 Release date: 06-03-2020 Overview Integration with license server. Enhancements Added license validation. License can be set in following waysq: Environment variable. Set variable ‘JSL_OCR_LICENSE’. System property. Set property ‘jsl.sparkocr.settings.license’. Application.conf file. Set property ‘jsl.sparkocr.settings.license’. Added auto renew license using jsl license server. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_1_1",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_1_1"
  },
  "1363": {
    "id": "1363",
    "title": "Spark NLP release notes 1.1.2",
    "content": "1.1.2 Release date: 09-03-2020 Overview Minor improvements and fixes Enhancements Improved messages during license validation Bugfixes Fixed dependencies issue Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_1_2",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_1_2"
  },
  "1364": {
    "id": "1364",
    "title": "Spark NLP release notes 1.2.0",
    "content": "1.2.0 Release date: 08-04-2020 Overview Improved support Databricks and processing selectable pdfs. Enhancements Adapted Spark OCR for run on Databricks. Added rewriting positions in ImageToText when run together with PdfToText. Added ‘positionsCol’ param to ImageToText. Improved support Spark NLP. Changed start function. New Features Added showImage implicit to Dataframe for display images in Scala Databricks notebooks. Added display_images function for display images in Python Databricks notebooks. Added propagation selectable pdf file in TextToPdf. Added ‘inputContent’ param to ‘TextToPdf’. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_2_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_2_0"
  },
  "1365": {
    "id": "1365",
    "title": "Spark NLP release notes 1.3.0",
    "content": "1.3.0 Release date: 22-05-2020 Overview New functionality for de-identification problem. Enhancements Renamed TesseractOCR to ImageToText. Simplified installation. Added check license from SPARK_NLP_LICENSE env varibale. New Features Support storing for binaryFormat. Added support storing Image and PDF files. Support selectable pdf for TextToPdf transformer. Added UpdateTextPosition transformer. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_3_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_3_0"
  },
  "1366": {
    "id": "1366",
    "title": "Spark NLP release notes 1.4.0",
    "content": "1.4.0 Release date: 23-06-2020 Overview Added support Dicom format and improved support image morphological operations. Enhancements Updated start function. Improved support Spark NLP internal. ImageMorphologyOpening and ImageErosion are removed. Improved existing transformers for support de-identification Dicom documents. Added possibility to draw filled rectangles to ImageDrawRegions. New Features Support reading and writing Dicom documents. Added ImageMorphologyOperation transformer which support: erosion, dilation, opening and closing operations. Bugfixes Fixed issue in ImageToText related to extraction coordinates. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_4_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_4_0"
  },
  "1367": {
    "id": "1367",
    "title": "Spark NLP release notes 1.5.0",
    "content": "1.5.0 Release date: 22-07-2020 Overview FoundationOne report parsing support. Enhancements Optimized memory usage during image processing New Features Added FoundationOneReportParser which support parsing patient info, genomic and biomarker findings. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_5_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_5_0"
  },
  "1368": {
    "id": "1368",
    "title": "Spark NLP release notes 1.6.0",
    "content": "1.6.0 Release date: 05-09-2020 Overview Support parsing data from tables for selectable PDFs. New Features Added PdfToTextTable transformer for extract tables from Pdf document per each page. Added ImageCropper transformer for crop images. Added ImageBrandsToText transformer for detect text in defined areas. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_6_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_6_0"
  },
  "1369": {
    "id": "1369",
    "title": "Spark NLP release notes 1.7.0",
    "content": "1.7.0 Release date: 22-09-2020 Overview Support Spark 2.3.3. Bugfixes Restored read JPEG2000 image Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_7_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_7_0"
  },
  "1370": {
    "id": "1370",
    "title": "Spark NLP release notes 1.8.0",
    "content": "1.8.0 Release date: 20-11-2020 Overview Optimisation performance for processing multipage PDF documents. Support up to 10k pages per document. New Features Added ImageAdaptiveBinarizer Scala transformer with support: Gaussian local thresholding Otsu thresholding Sauvola local thresholding Added possibility to split pdf to small documents for optimize processing in PdfToImage. Enhancements Added applying binarization in PdfToImage for optimize memory usage. Added pdfCoordinates param to the ImageToText transformer. Added ‘total_pages’ field to the PdfToImage transformer. Added different splitting strategies to the PdfToImage transformer. Simplified paging PdfToImage when run it with splitting to small PDF. Added params to the PdfToText for disable extra functionality. Added master_url param to the python start function. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_8_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_8_0"
  },
  "1371": {
    "id": "1371",
    "title": "Spark NLP release notes 1.9.0",
    "content": "1.9.0 Release date: 11-12-2020 Overview Extension of FoundationOne report parser and support HOCR output format. New Features Added ImageToHocr transformer for recognize text from image and store it to HOCR format. Added parsing gene lists from ‘Appendix’ in FoundationOneReportParser transformer. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_9_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_9_0"
  },
  "1372": {
    "id": "1372",
    "title": "NLP Lab Release Notes 2.0.1",
    "content": "2.0.1 Highlights Inter-Annotation Agreement Charts. To get a measure of how well multiple annotators can make the same annotation decision for a certain category, we are shipping seven different charts. To see these charts users can click on the third tab “Inter-Annotator Agreement” of the Analytics Dashboard of NER projects. There are dropdown boxes to change annotators for comparison purposes. It is also possible to download the data of some charts in CSV format by clicking the download button present at the bottom right corner of each of them. Updated CONLL Export. In previous versions, numerous files were created based on Tasks and Completions. There were issues in the Header and no sentences were detected. Also, some punctuations were not correctly exported or were missing. The new CONLL export implementation results in a single file and fixes all the above issues. As in previous versions, if only Starred completions are needed in the exported file, users can select the “Only ground truth” checkbox. Search tasks by label. Now, it is possible to list the tasks based on some annotation criteria. Examples of supported queries: “label: ABC”, “label: ABC=DEF”, “choice: Mychoice”, “label: ABC=DEF”. Validation of labels and models is done beforehand. An error message is shown if the label is incompatible with models. Transfer Learning support for Training Models. Now its is possible to continue model training from an already available model. If a Medical NER model is present in the system, the project owner or manager can go to Advanced Options settings of the Training section in the Setup Page and choose it to Fine Tune the model. When Fine Tuning is enabled, the embeddings that were used to train the model need to be present in the system. If present, it will be automatically selected, otherwise users need to go to the Models Hub page and download or upload it. Training Community Models without the need of License. In previous versions, Annotation Lab didn’t allow training without the presence of Spark NLP for Healthcare license. But now the training with community embeddings is allowed even without the presence of Valid license. Support for custom training scripts. If users want to change the default Training script present within the Annotation Lab, they can upload their own training pipeline. In the Training section of the Project Setup Page, only admin users can upload the training scripts. At the moment we are supporting the NER custom training script only. Users can now see a proper message on the Modelshub page when annotationlab is not connected to the internet (AWS S3 to be more precise). This happens in air-gapped environments or some issues in the enterprise network. Users now have the option to download the trained models from the Models Hub page. The download option is available under the overflow menu of each Model on the “Available Models” tab. Training Live Logs are improved in terms of content and readability. Not all Embeddings present in the Models Hub are supported by NER and Assertion Status Training. These are now properly validated from the UI. Conflict when trying to use deleted embeddings. The existence of the embeddings in training as well as in deployment is ensured and a readable message is shown to users. Support for adding custom CA certificate chain. Follow the instructions described in instruction.md file present in the installation artifact. Bug fixes When multiple paged OCR file was imported using Spark OCR, the task created did not have pagination. Due to a bug in the Assertion Status script, the training was not working at all. Any AdminUser could delete the main “admin” user as well as itself. We have added proper validation to avoid such situations. Read more Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_0_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_0_1"
  },
  "1373": {
    "id": "1373",
    "title": "NLP Lab Release Notes 2.1.0",
    "content": "2.1.0 Highlights A new project configuration “Visual NER Labeling” was added, which provides the skeleton for text annotation on scanned images. Project Owners or Project Manager can train open-source models too. The UI components and navigation of Annotation Lab - as a SPA - continues to improve its performance. The application has an increased performance (security and bug fixes, general optimizations). More models &amp; embeddings included in the Annotation Lab image used for deployments. This should reduce the burden for system admins during the installation in air-gapped or enterprise environments. Easier way to add relations. Project Owners and Managers can see the proper status of tasks, taking into account their own completions. Security Fixes. We understand and take the security issues as the highest priority. On every release, we run our artifacts and images through series of security testings (Static Code analysis, PenTest, Images Vulnerabilities Test, AWS AMI Scan Test). This version resolves a few critical issues that were recently identified in Python Docker image we use. We have upgraded it to a higher version. Along with this upgrade, we have also refactored our codebase to pass our standard Static Code Analysis. Bug fixes An issue with using Uploaded models was fixed so any uploaded models can be loaded in Project Config and used for preannotation. Issues related to error messages when uploading a valid Spark OCR license and when trying to train NER models while Spark OCR license was expired are now fixed. The issue with exporting annotations in COCO format for image projects was fixed. Project Owners and Managers should be able to export COCO format which also includes images used for annotations. The bug reports related to unexpected scrolling of the Labeling page, issues in Swagger documentation, and typos in some hover texts are now fixed. Read more Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_1_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_1_0"
  },
  "1374": {
    "id": "1374",
    "title": "NLP Lab Release Notes 2.2.20",
    "content": "2.2.2 Highlights Support for pretrained Relation Extraction and Assertion Status models. A valid Spark NLP for HealthCare License is needed to download pretrained models via the Models Hub page. After download, they can be added to the Project Config and used for preannotations. Support for uploading local images. Until this version, only images from remote URLs could be uploaded for Image projects. With this version the Annotation Lab supports uploading images from you local storage/computer. It is possible to either import one image or multiple images by zipping them together. The maximum image file size is 16 MB. If you need to upload files exceding the default configuration, please contact your system administrator who will change the limit size in the installation artifact and run the upgrade script. Improved support for Visual NER projects. A sample task can be imported from the Import page by clicking the “Add Sample Task” button. Also default config for the Visual NER project contains zoom feature which supports maximum possible width for low resolution images when zooming. Improved Relation Labeling. Creating numerous relations in a single task can look a bit clumsy. The limited space in Labeling screen, the relation arrows and different relation types all at once could create difficulty to visualize them properly. We improved the UX for this feature: Spaces between two lines if relations are present Ability to Filter by certain relations When hovered on one relation, only that is focused Miscellaneous. Generally when a first completion in a task is submitted, it is very likely for that completion to be the ground truth for that task. Starting with this version, the first submitted completion gets automatically starred. Hitting submit button on next completion, annotator are asked to either just submit or submit and star it. Bug fixes On restart of the Annotation Lab machine/VM all Downloaded models (from Models Hub) compatible with Spark NLP 3.1 version were deleted. We have now fixed this issue. Going forward, it is user’s responsibility to remove any incompatible models. Those will only be marked as “Incompatible” in Models Hub. This version also fixes some reported issues in training logs. The CONLL exports were including Assertion Status labels too. Going forward Assertion Status labels will be excluded given correct Project Config is setup. Read more Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_2_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_2_2"
  },
  "1375": {
    "id": "1375",
    "title": "NLP Lab Release Notes 2.3.0",
    "content": "2.3.0 Highlights Multipage PDF annotation. Annotation Lab 2.3.0 supports the complete flow of import, annotation, and export for multi-page PDF files. Users have two options for importing a new PDF file into the Visual NER project: Import PDF file from local storage Add a link to the PDF file in the file attribute. After import, the user can see a task on the task page with a file name. On the labeling page, the user can view the PDF file with pagination so that the user can annotate the PDF one page at a time. After completing the annotation, the user can submit a task and it is ready to be exported to JSON and the user can import this exported file into any Visual NER project. [Note: Export in COCO format is not yet supported for PDF file] Redesign of the Project Setup Page. With the addition of many new features on every release, the Project Setup page became crowded and difficult to digest by users. In this release we have split its main components into multiple tabs: Project Description, Sharing, Configuration, and Training. Train and Test Dataset. Project Owner/Manager can tag the tasks that will be used for train and for test purposes. For this, two predefined tags will be available in all projects: Train and Test. Enhanced Relation Annotation. The user experience while annotating relations on the Labeling page has been improved. Annotators can now select the desired relation(s) by clicking the plus “+” sign present next to the relations arrow. Other UX improvements: Multiple items selection with Shift Key in Models Hub and Tasks page, Click instead of hover on more options in Models Hub and Tasks page, Tabbed View on the ModelsHub page. Bug fixes Validations related to Training Settings across different types of projects were fixed. It is not very common to upload an expired license given a valid license is already present. But in case users did that there was an issue while using a license in the spark session because only the last uploaded license was used. Now it has been fixed to use any valid license no matter the order of upload. Sometimes search and filters in the ModelsHub page were not working. Also, there was an issue while removing defined labels on the Upload Models Form. Both of these issues are fixed. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_3_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_3_0"
  },
  "1376": {
    "id": "1376",
    "title": "NLP Lab Release Notes 2.4.0",
    "content": "2.4.0 Annotation Lab v2.4.0 adds relation creation features for Visual NER projects and redesigns the Spark NLP Pipeline Config on the Project Setup Page. Several bug fixes and stabilizations are also included. Following are the highlights: Highlights Relations on Visual NER Projects. Annotators can create relations between annotated tokens/regions in Visual NER projects. This functionality is similar to what we already had in text-based projects. It is also possible to assign relation labels using the contextual widget (the “+” sign displayed next to the relation arrow). SparkNLP Pipeline Config page was redesigned. The SparkNLP Pipeline Config in the Setup Page was redesigned to ease filtering, collapsing, and expanding models and labels. For a more intuitive use, the Add Label button was moved to the top right side of the tab and no longer scrolls with the config list. This version also adds many improvements to the new Setup Page. The Training and Active Learning Tabs are only available to projects for which Annotation Lab supports training. When unsaved changes are present in the configuration, the user cannot move to the Training and Active Learning Tab and/or Training cannot be started. When the OCR server was not deployed, imports in the Visual NER project were failing. With this release, when a valid Spark OCR license is present, the OCR server is deployed and the import of pdf and image files is executed. Bug fixes When a login session is timed out and cookies are expired, users had to refresh the page to get the login screen. This known issue has been fixed and the user will be redirected to the login page. When a task was assigned to an annotator who does not have completions for it, the task status was shown incorrectly. This was fixed in this version. While preannotating tasks with some specific types of models, only the first few lines were annotated. We have fixed the Spark NLP pipeline for such models and now the entire document gets preannotations. When Spark NLP for Healthcare license was expired, the deployment was allowed but it used to fail. Now a proper message is shown to Project Owners/Managers and the deployment is not started in such cases. Inconsistencies were present in training logs and some embeddings were not successfully used for models training. Along with these fixes, several UI bugs are also fixed in this release. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_4_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_4_0"
  },
  "1377": {
    "id": "1377",
    "title": "Spark NLP for Healthcare Release Notes 2.4.0",
    "content": "2.4.0 Overview We are glad to announce Spark NLP for Healthcare 2.4.0. This is an important release because of several refactorizations achieved in the core library, plus the introduction of several state of the art algorithms, new features and enhancements. We have included several architecture and performance improvements, that aim towards making the library more robust in terms of storage handling for Big Data. In the NLP aspect, we have introduced a ContextualParser, DocumentLogRegClassifier and a ChunkEntityResolverSelector. These last two Annotators also target performance time and memory consumption by lowering the order of computation and data loaded to memory in each step when designed following a hierarchical pattern. We have put a big effort on this one, so please enjoy and share your comments. Your words are always welcome through all our different channels. Thank you very much for your important doubts, bug reports and feedback; they are always welcome and much appreciated. New Features BigChunkEntityResolver Annotator: New experimental approach to reduce memory consumption at expense of disk IO. ContextualParser Annotator: New entity parser that works based on context parameters defined in a JSON file. ChunkEntityResolverSelector Annotator: New AnnotatorModel that takes advantage of the RecursivePipelineModel + LazyAnnotator pattern to annotate with different LazyAnnotators at runtime. DocumentLogregClassifier Annotator: New Annotator that provides a wrapped TFIDF Vectorizer + LogReg Classifier for TOKEN AnnotatorTypes (either at Document level or Chunk level) Enhancements normalizedColumn Param is no longer required in ChunkEntityResolver Annotator (defaults to the labelCol Param value). ChunkEntityResolverMetadata now has more data to infer whether the match is meaningful or not. Bugfixes Fixed a bug on ContextSpellChecker Annotator where unrecognized tokens would cause an exception if not in vocabulary. Fixed a bug on ChunkEntityResolver Annotator where undetermined results were coming out of negligible confidence scores for matches. Fixed a bug on ChunkEntityResolver Annotator where search would fail if the neighbours Param was grater than the number of nodes in the tree. Now it returns up to the number of nodes in the tree. Deprecations OCR Moves to its own JSL Spark OCR project. Infrastructure Spark NLP License is now required to utilize the library. Please follow the instructions on the shared email. Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_0"
  },
  "1378": {
    "id": "1378",
    "title": "Spark NLP for Healthcare Release Notes 2.4.1",
    "content": "2.4.1 Overview Introducing Spark NLP for Healthcare 2.4.1 after all the feedback we received in the form of issues and suggestions on our different communication channels. Even though 2.4.0 was very stable, version 2.4.1 is here to address minor bug fixes that we summarize in the following lines. Bugfixes Changing the license Spark property key to be “jsl” instead of “sparkjsl” as the latter generates inconsistencies Fix the alignment logic for tokens and chunks in the ChunkEntityResolverSelector because when tokens and chunks did not have the same begin-end indexes the resolution was not executed Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_1"
  },
  "1379": {
    "id": "1379",
    "title": "Spark NLP for Healthcare Release Notes 2.4.2",
    "content": "2.4.2 Overview We are glad to announce Spark NLP for Healthcare 2.4.2. As a new feature we are happy to introduce our new Disambiguation Annotator, which will let the users resolve different kind of entities based on Knowledge bases provided in the form of Records in a RocksDB database. We also enhanced / fixed DocumentLogRegClassifier, ChunkEntityResolverModel and ChunkEntityResolverSelector Annotators. New Features Disambiguation Annotator (NerDisambiguator and NerDisambiguatorModel) which accepts annotator types CHUNK and SENTENCE_EMBEDDINGS and returns DISAMBIGUATION annotator type. This output annotation type includes all the matches in the result and their similarity scores in the metadata. Enhancements ChunkEntityResolver Annotator now supports both EUCLIDEAN and COSINE distance for the KNN search and WMD calculation. Bugfixes Fixed a bug in DocumentLogRegClassifier Annotator to support its serialization to disk. Fixed a bug in ChunkEntityResolverSelector Annotator to group by both SENTENCE and CHUNK at the time of forwarding tokens and embeddings to the lazy annotators. Fixed a bug in ChunkEntityResolverModel in which the same exact embeddings was not included in the neighbours. Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_2"
  },
  "1380": {
    "id": "1380",
    "title": "Spark NLP for Healthcare Release Notes 2.4.5",
    "content": "2.4.5 Overview We are glad to announce Spark NLP for Healthcare 2.4.5. As a new feature we are happy to introduce our new EnsembleEntityResolver which allows our Entity Resolution architecture to scale up in multiple orders of magnitude and handle datasets of millions of records on a sub-log computation increase We also enhanced our ChunkEntityResolverModel with 5 new distance calculations with weighting-array and aggregation-strategy params that results in more levers to finetune its performance against a given dataset. New Features EnsembleEntityResolver consisting of an integrated TFIDF-Logreg classifier in the first layer + Multiple ChunkEntityResolvers in the second layer (one per each class) Five (5) new distances calculations for ChunkEntityResolver, namely: Token Based: TFIDF-Cosine, Jaccard, SorensenDice Character Based: JaroWinkler and Levenshtein Weight parameter that works as a multiplier for each distance result to be considered during their aggregation Three (3) aggregation strategies for the enabled distance in a particular instance, namely: AVERAGE, MAX and MIN Enhancements ChunkEntityResolver can now compute distances over all the neighbours found and return the metadata just for the best alternatives that meet the threshold; before it would calculate them over the neighbours and return them all in the metadata ChunkEntityResolver now has an extramassPenalty parameter to accoun for penalization of token-length difference in compared strings Metadata for the ChunkEntityResolver has been updated accordingly to reflect all new features StringDistances class has been included in utils to aid in the calculation and organization of different types of distances for Strings HasFeaturesJsl trait has been included to support the serialization of Features including [T] &lt;: AnnotatorModel[T] types Bugfixes Frequency calculation for WMD in ChunkEntityResolver has been adjusted to account for real word count representation AnnotatorType for DocumentLogRegClassifier has been changed to CATEGORY to align with classifiers in Open Source library Deprecations Legacy EntityResolver{Approach, Model} classes have been deprecated in favor of ChunkEntityResolver classes ChunkEntityResolverSelector classes has been deprecated in favor of EnsembleEntityResolver Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_5",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_5"
  },
  "1381": {
    "id": "1381",
    "title": "Spark NLP for Healthcare Release Notes 2.4.6",
    "content": "2.4.6 Overview We release Spark NLP for Healthcare 2.4.6 to fix some minor bugs. Bugfixes Updated IDF value calculation to be probabilistic based log[(N - df_t) / df_t + 1] as opposed to log[N / df_t] TFIDF cosine distance was being calculated with the rooted norms rather than with the original squared norms Validation of label cols is now performed at the beginning of EnsembleEntityResolver Environment Variable for License value named jsl.settings.license Now DocumentLogRegClassifier can be serialized from Python (bug introduced with the implementation of RecursivePipelines, LazyAnnotator attribute) Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_6",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_6"
  },
  "1382": {
    "id": "1382",
    "title": "NLP Lab Release Notes 2.5.0",
    "content": "2.5.0 Annotation Lab v2.5.0 introduces support for rule based annotations, new search feature and COCO format export for Visual NER projects. It also includes fixes for the recently identified security issues and other known bugs. Below are the highlights of this release. Highlights Rule Based Annotations. Spark NLP for Healthcare supports rule-based annotations via the ContextualParser Annotator. In this release Annotationlab adds support for creating and using ContextualParser rules in NER project. Any user with admin privilegis can see rules under the Available Rules tab on the Models Hub page and can create new rules using the + Add Rule button. After adding a rule on Models Hub page, the Project Owner or Manager can add the rule to the configuration of the project where he wants to use it. This can be done via the Rules tab from the Project Setup page under the Project Configuration tab. A valid Spark NLP for Healthcare licence is required to deploy rules from project config. Two types of rules are supported:1. Regex Based: User can enter the Regex which matches to the entities of the required label; and 2. Dictionary Based: User can create a dictionary of labels and user can upload the CSV of the list of entity that comes under the label. Search through Visual NER Projects. For the Visual NER Projects, it is now possible to search for a keyword inside of image/pdf based tasks using the search box available on the top of the Labeling page. Currently, the search is performed on the current page only. Furthermore, we have also extended the keyword-based task search already available for text-based projects for Visual NER Projects. On the Tasks page, use the search bar on the upper right side of the screen like you would do in other text-based projects, to identify all image/pdf tasks containing a given text. COCO export for pdf tasks in Visual NER Projects. Up until now, the COCO format export was limited to simple image documents. With version 2.5.0, this functionality is extended to single-page or multi-page pdf documents. In Classification Project, users are now able to use different layouts for the list of choices: layout=&quot;select&quot;: It will change choices from list of choices inline to dropdown layout. Possible values are &quot;select&quot;, &quot;inline&quot;, &quot;vertical&quot; choice=&quot;multiple&quot;: Allow user to select multiple values from dropdown. Possible values are: &quot;single&quot;, &quot;single-radio&quot;, &quot;multiple&quot; Better Toasts, Confirmation-Boxes and Masking UI on potentially longer operations. Security Fixes Annotationlab v2.5.0 got different Common Vulnerabilities and Exposures(CVE) issues fixed. As always, in this release we performed security scans to detect CVE issues, upgraded python packages to eliminate known vulnerabilities and also we made sure the CVE-2021-44228 (Log4j2 issue) is not present in any images used by Annotation Lab. A reported issue when logout endpoint was sometimes redirected to insecure http after access token expired was also fixed. Bug Fixes The Filters option in the Models Hub page was not working properly. Now the “Free/Licensed” filter can be selected/deselected without getting any error. After creating relations and saving/updating annotations for the Visual NER projects with multi-paged pdf files, the annotations and relations were not saved. An issue with missing text tokens in the exported JSON file for the Visual NER projects also have been fixed. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_5_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_5_0"
  },
  "1383": {
    "id": "1383",
    "title": "Spark NLP for Healthcare Release Notes 2.5.0",
    "content": "2.5.0 Overview We are happy to bring you Spark NLP for Healthcare 2.5.0 with new Annotators, Models and Data Readers. Model composition and iteration is now faster with readers and annotators designed for real world tasks. We introduce ChunkMerge annotator to combine all CHUNKS extracted by different Entity Extraction Annotators. We also introduce an Annotation Reader for JSL AI Platform’s Annotation Tool. This release is also the first one to support the models: ner_large_clinical, ner_events_clinical, assertion_dl_large, chunkresolve_loinc_clinical, deidentify_large And of course we have fixed some bugs. New Features AnnotationToolJsonReader is a new class that imports a JSON from AI Platform’s Annotation Tool an generates NER and Assertion training datasets ChunkMerge Annotator is a new functionality that merges two columns of CHUNKs handling overlaps with a very straightforward logic: max coverage, max # entities ChunkMerge Annotator handles inputs from NerDLModel, RegexMatcher, ContextualParser, TextMatcher A DeIdentification pretrained model can now work in ‘mask’ or ‘obfuscate’ mode Enhancements DeIdentification Annotator has a more consistent API: mode param with values (‘mask’l’obfuscate’) to drive its behavior dateFormats param a list of string values to to select which dateFormats to obfuscate (and which to just mask) DeIdentification Annotator no longer automatically obfuscates dates. Obfuscation is now driven by mode and dateFormats params A DeIdentification pretrained model can now work in ‘mask’ or ‘obfuscate’ mode Bugfixes DeIdentification Annotator now correctly deduplicates protected entities coming from NER / Regex DeIdentification Annotator now indexes chunks correctly after merging them AssertionDLApproach Annotator can now be trained with the graph in any folder specified by setting graphFolder param AssertionDLApproach now has the setClasses param setter in Python wrapper JVM Memory and Kryo Max Buffer size increased to 32G and 2000M respectively in sparknlp_jsl.start(secret) function Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_0"
  },
  "1384": {
    "id": "1384",
    "title": "Spark NLP for Healthcare Release Notes 2.5.2",
    "content": "2.5.2 Overview We are really happy to bring you Spark NLP for Healthcare 2.5.2, with a couple new features and several enhancements in our existing annotators. This release was mainly dedicated to generate adoption in our AnnotationToolJsonReader, a connector that provide out-of-the-box support for out Annotation Tool and our practices. Also the ChunkMerge annotator has ben provided with extra functionality to remove entire entity types and to modify some chunk’s entity type We also dedicated some time in finalizing some refactorization in DeIdentification annotator, mainly improving type consistency and case insensitive entity dictionary for obfuscation. Thanks to the community for all the feedback and suggestions, it’s really comfortable to navigate together towards common functional goals that keep us agile in the SotA. New Features Brand new IOBTagger Annotator NerDL Metrics provides an intuitive DataFrame API to calculate NER metrics at tag (token) and entity (chunk) level Enhancements AnnotationToolJsonReader includes parameters for document cleanup, sentence boundaries and tokenizer split chars AnnotationToolJsonReader uses the task title if present and uses IOBTagger annotator AnnotationToolJsonReader has improved alignment in assertion train set generation by using an alignTol parameter as tollerance in chunk char alignment DeIdentification refactorization: Improved typing and replacement logic, case insensitive entities for obfuscation ChunkMerge Annotator now handles: Drop all chunks for an entity Replace entity name Change entity type for a specific (chunk, entity) pair Drop specific (chunk, entity) pairs caseSensitive param to EnsembleEntityResolver Output logs for AssertionDLApproach loss Disambiguator is back with improved dependency management Bugfixes Bugfix in python when Annotators shared domain parts across public and internal Bugfix in python when ChunkMerge annotator was loaded from disk ChunkMerge now weights the token coverage correctly when multiple multi-token entities overlap Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_2"
  },
  "1385": {
    "id": "1385",
    "title": "Spark NLP for Healthcare Release Notes 2.5.3",
    "content": "2.5.3 Overview We are pleased to announce the release of Spark NLP for Healthcare 2.5.3. This time we include four (4) new Annotators: FeatureAssembler, GenericClassifier, Yake Keyword Extractor and NerConverterInternal. We also include helper classes to read datasets from CodiEsp and Cantemist Spanish NER Challenges. This is also the first release to support the following models: ner_diag_proc (spanish), ner_neoplasms (spanish), ner_deid_enriched (english). We have also included Bugifxes and Enhancements for AnnotationToolJsonReader and ChunkMergeModel. New Features FeatureAssembler Transformer: Receives a list of column names containing numerical arrays and concatenates them to form one single feature_vector annotation GenericClassifier Annotator: Receives a feature_vector annotation and outputs a category annotation Yake Keyword Extraction Annotator: Receives a token annotation and outputs multi-token keyword annotations NerConverterInternal Annotator: Similar to it’s open source counterpart in functionality, performs smarter extraction for complex tokenizations and confidence calculation Readers for CodiEsp and Cantemist Challenges Enhancements AnnotationToolJsonReader includes parameter for preprocessing pipeline (from Document Assembling to Tokenization) AnnotationToolJsonReader includes parameter to discard specific entity types Bugfixes ChunkMergeModel now prioritizes highest number of different entities when coverage is the same Models We have 2 new spanish models for Clinical Entity Recognition: ner_diag_proc and ner_neoplasms We have a new english Named Entity Recognition model for deidentification: ner_deid_enriched Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_3"
  },
  "1386": {
    "id": "1386",
    "title": "Spark NLP for Healthcare Release Notes 2.5.5",
    "content": "2.5.5 Overview We are very happy to release Spark NLP for Healthcare 2.5.5 with a new state-of-the-art RelationExtraction annotator to identify relationships between entities coming from our pretrained NER models. This is also the first release to support Relation Extraction with the following two (2) models: re_clinical and re_posology in the clinical/models repository. We also include multiple bug fixes as usual. New Features RelationExtraction annotator that receives WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY and returns the CATEGORY of the relationship and a confidence score. Enhancements AssertionDL Annotator now keeps logs of the metrics while training DeIdentification now has a default behavior of merging entities close in Levenshtein distance with setConsistentObfuscation and setSameEntityThreshold params. DeIdentification now has a specific parameter setObfuscateDate to obfuscate dates (which will be otherwise just masked). The only formats obfuscated when the param is true will be the ones present in dateFormats param. NerConverterInternal now has a greedyMode param that will merge all contiguous tags of the same type regardless of boundary tags like “B”,”E”,”S”. AnnotationToolJsonReader includes mergeOverlapping parameter to merge (or not) overlapping entities from the Annotator jsons i.e. not included in the assertion list. Bugfixes DeIdentification documentation bug fix (typo) DeIdentification training bug fix in obfuscation dictionary IOBTagger now has the correct output type NAMED_ENTITY Deprecations EnsembleEntityResolver has been deprecated Models We have 2 new english Relationship Extraction model for Clinical and Posology NERs: re_clinical: with ner_clinical and embeddings_clinical re_posology: with ner_posology and embeddings_clinical Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_5",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_5"
  },
  "1387": {
    "id": "1387",
    "title": "NLP Lab Release Notes 2.6.0",
    "content": "2.6.0 Annotation Lab v2.6.0 improves the performance of the Project Setup page, adds a “View as” option in the Labeling Page, improves the layout of OCR-ed documents, adds the option to stop training and model server deployment from UI. Many more cool features are also delivered in this version to enhance usability and stabilize the product. Here are details of features and bug fixes included in this release. Highlights Performance improvement in Setup page. In previous versions of Annotation Lab, changes in Project Configuration would take a long time to validate if that project included a high volume of completions. The configuration validation time is now almost instant, even for projects with thousand of tasks. Multiple tests were conducted on projects with more than 13K+ tasks and thousands of extractions per task. For all of those test situations, the validation of the Project Configuration took under 2 seconds. Those tests results were replicated for all types of projects including NER, Image, Audio, Classification, and HTML projects. New “View as” option in the labeling screen. When a user has multiple roles (Manager, Annotator, Reviewer), the Labeling Page should present and render different content and specific UX, depending on the role impersonated by the user. For a better user experience, this version adds a “View as” switch in the Labeling Page. Once the “View as” option is used to select a certain role, the selection is preserved even when the tab is closed or refreshed. OCR Layout improvement. In previous versions of the Annotation Lab, layout was not preserved in OCRed tasks. Recognized texts would be placed in a top to bottom approach without considering the paragraph each token belonged to. From this version on, we are using layout-preserving transformers from Spark OCR. As a result, tokens that belong to the same paragraph are now grouped together, producing more meaningful output. Ability to stop training and model server deployment. Up until now, training and model server deployment could be stopped by system admins only. This version of Annotation Lab provides Project Owners/Managers with the option to stop these processes simply by clicking a button in the UI. This option is necessary in many cases, such as when a manager/project owner starts the training process on a big project that takes a lot of resources and time, blocking access to preannotations to the other projects. Display meaningful message when training fails due to memory issues. In case the training of a model fails due to memory issues, the reason for the failure are available via the UI (i.e. out of memory error). Allow combining NER labels and Classification classes from Spark NLP pipeline config. The earlier version had an issue with adding choice from the predefined classification model to an existing NER project. This issue has been fixed in this version. Bug Fixes Previously there was a UI reloading issue when a User was removed from the “Annotators” user group, which has now been fixed. The user can log in without the reloading issue, a warning is shown in UI regarding the missing annotator privilege. Also, setting up the HTML NER Tagging project was not possible in the earlier version which has been fixed in this release. On the labeling page, the renamed title of the next served task was not displayed. Similarly, in the Import page, the count of the tasks imported was missing in the Import Status dialog box. Now both these issues are fixed. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_6_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_6_0"
  },
  "1388": {
    "id": "1388",
    "title": "Spark NLP for Healthcare Release Notes 2.6.0",
    "content": "2.6.0 Overview We are honored to announce that Spark NLP Enterprise 2.6.0 has been released. The first time ever, we release three pretrained clinical pipelines to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases. The first time ever, we are releasing 3 licensed German models for healthcare and Legal domains. Models Pretrained Pipelines: The first time ever, we release three pretrained clinical pipelines to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases and you can use them as easy as follows: pipeline = PretrainedPipeline(&#39;explain_clinical_doc_carp&#39;, &#39;en&#39;, &#39;clinical/models&#39;) pipeline.annotate(&#39;my string&#39;) Pipeline descriptions: explain_clinical_doc_carp a pipeline with ner_clinical, assertion_dl, re_clinical and ner_posology. It will extract clinical and medication entities, assign assertion status and find relationships between clinical entities. explain_clinical_doc_era a pipeline with ner_clinical_events, assertion_dl and re_temporal_events_clinical. It will extract clinical entities, assign assertion status and find temporal relationships between clinical entities. recognize_entities_posology a pipeline with ner_posology. It will only extract medication entities. More information and examples are available here: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb. Pretrained Named Entity Recognition and Relationship Extraction Models (English) RE models: re_temporal_events_clinical re_temporal_events_enriched_clinical re_human_phenotype_gene_clinical re_drug_drug_interaction_clinical re_chemprot_clinical NER models: ner_human_phenotype_gene_clinical ner_human_phenotype_go_clinical ner_chemprot_clinical More information and examples here: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb Pretrained Named Entity Recognition and Relationship Extraction Models (German) The first time ever, we are releasing 3 licensed German models for healthcare and Legal domains. German Clinical NER model for 19 clinical entities German Legal NER model for 19 legal entities German ICD-10GM More information and examples here: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/14.German_Healthcare_Models.ipynb https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/15.German_Legal_Model.ipynb Other Pretrained Models We now have Named Entity Disambiguation model out of the box. Disambiguation models map words of interest, such as names of persons, locations and companies, from an input text document to corresponding unique entities in a target Knowledge Base (KB). https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/12.Named_Entity_Disambiguation.ipynb Due to ongoing requests about Clinical Entity Resolvers, we release a notebook to let you see how to train an entity resolver using an open source dataset based on Snomed. https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.Snomed_Entity_Resolver_Model_Training.ipynb Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_6_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_6_0"
  },
  "1389": {
    "id": "1389",
    "title": "Spark NLP for Healthcare Release Notes 2.6.2",
    "content": "2.6.2 Overview We are very happy to announce that version 2.6.2 of Spark NLP Enterprise is ready to be installed and used. We are making available Named Entity Recognition, Sentence Classification and Entity Resolution models to analyze Adverse Drug Events in natural language text from clinical domains. Models NERs We are pleased to announce that we have a brand new named entity recognition (NER) model for Adverse Drug Events (ADE) to extract ADE and DRUG entities from a given text. ADE NER will have four versions in the library, trained with different size of word embeddings: ner_ade_bioert (768d Bert embeddings) ner_ade_clinicalbert (768d Bert embeddings) ner_ade_clinical (200d clinical embeddings) ner_ade_healthcare (100d healthcare embeddings) More information and examples here We are also releasing our first clinical pretrained classifier for ADE classification tasks. This new ADE classifier is trained on various ADE datasets, including the mentions in tweets to represent the daily life conversations as well. So it works well on the texts coming from academic context, social media and clinical notes. It’s trained with Clinical Biobert embeddings, which is the most powerful contextual language model in the clinical domain out there. Classifiers ADE classifier will have two versions in the library, trained with different Bert embeddings: classifierdl_ade_bioert (768d BioBert embeddings) classifierdl_adee_clinicalbert (768d ClinicalBert embeddings) More information and examples here Pipeline By combining ADE NER and Classifier, we are releasing a new pretrained clinical pipeline for ADE tasks to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases and you can use them as easy as follows: pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) pipeline.annotate(&#39;my string&#39;) explain_clinical_doc_ade is bundled with ner_ade_clinicalBert, and classifierdl_ade_clinicalBert. It can extract ADE and DRUG clinical entities, and then assign ADE status to a text (True means ADE, False means not related to ADE). More information and examples here Entity Resolver We are releasing the first Entity Resolver for Athena (Automated Terminology Harmonization, Extraction and Normalization for Analytics, https://athena.ohdsi.org/) to extract concept ids via standardized medical vocabularies. For now, it only supports conditions section and can be used to map the clinical conditions with the corresponding standard terminology and then get the concept ids to store them in various database schemas. It is named as chunkresolve_athena_conditions_healthcare. We added slim versions of several clinical NER models that are trained with 100d healthcare word embeddings, which is lighter and smaller in size. ner_healthcare assertion_dl_healthcare ner_posology_healthcare ner_events_healthcare Graph Builder Spark NLP Licensed version has several DL based annotators (modules) such as NerDL, AssertionDL, RelationExtraction and GenericClassifier, and they are all based on Tensorflow (tf) with custom graphs. In order to make the creating and customizing the tf graphs for these models easier for our licensed users, we added a graph builder to the Python side of the library. Now you can customize your graphs and use them in the respected models while training a new DL model. from sparknlp_jsl.training import tf_graph tf_graph.build(&quot;relation_extraction&quot;,build_params={&quot;input_dim&quot;: 6000, &quot;output_dim&quot;: 3, &#39;batch_norm&#39;:1, &quot;hidden_layers&quot;: [300, 200], &quot;hidden_act&quot;: &quot;relu&quot;, &#39;hidden_act_l2&#39;:1}, model_location=&quot;.&quot;, model_filename=&quot;re_with_BN&quot;) More information and examples here Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_6_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_6_2"
  },
  "1390": {
    "id": "1390",
    "title": "NLP Lab Release Notes 2.7.0",
    "content": "2.7.0 Release date: 17-02-2022 Annotation Lab 2.7.0 is here! This is another feature reach release from John Snow Labs - Annotation Lab Team. It is powered by the latest Spark NLP and Spark NLP for Healthcare libraries and offers improved support for Rule Base Annotation. With the upgrade of Spark NLP libraries, the Models Hub page inside the application gets more than 100 new models for English along with the introduction of Spanish and German models. In Visual NER projects it is now easier to annotate cross line chunks. As always, there are many security and stabilizations shipped. Highlights Annotation Lab 2.7.0 includes Spark NLP 3.4.1 and Spark NLP for Healthcare. Model training is now significantly faster and issues related to Rule-based annotation have been solved. The Models Hub has increased the list of models and old incompatible models are now marked as “incompatible”. If there are any incompatible models downloaded on the machine, we recommend deleting them. Spanish and German Models have been added to Models Hub. In previous versions of the Annotation Lab, the Models Hub only offered English language models. But from version 2.7.0, models for two other languages are included as well, namely Spanish and German. It is possible to download or upload these models and use them for preannotation, in the same way as for English language models. Rule-Based Annotation improvement. Rule-based annotation, introduced in 2.6.0 with limited options, was improved in this release. The Rule creation UI form was simplified and extended, and help tips were added on each field. While creating a rule, the user can define the scope of the rule as being sentence or document. A new toggle parameter Complete Match Regex is added to the rules. It can be toggled on to preannotate the entity that exactly matches the regex or dictionary value regardless of the Match Scope. Also case-sensitive is always true (and hence the toggle is hidden in this case) for REGEX while the case-sensitive toggle for dictionary can be toggled on or off. Users can now download the uploaded dictionary of an existing rule. In the previous release, if a dictionary-based rule was defined with an invalid CSV file, the preannotation server would crash and would only recover when the rule was removed from the configuration. This issue has been fixed and it is also possible to upload both vertical and horizontal CSV files consisting of multi-token dictionary values. Flexible annotations for Visual NER Projects. The chunk annotation feature added to Visual NER projects, allows the annotation of several consecutive tokens as one chunk. It also supports multiple lines selection. Users can now select multiple tokens and annotate them together in Visual NER Projects. The label assigned to a connected group can be updated. This change will apply to all regions in the group. Constraints for relation labeling can be defined. While annotating projects with Relations between Entities, defining constraints (the direction, the domain, the co-domain) of relations is important. Annotation Lab 2.7.0 offers a way to define such constraints by editing the Project Configuration. The Project Owner or Project Managers can specify which Relation needs to be bound to which Labels and in which direction. This will hide some Relations in Labeling Page for NER Labels which will simplify the annotation process and will avoid the creation of any incorrect relations in the scope of the project. Security Security issues related to SQL Injection Vulnerability and Host Header Attack were fixed in this release. Bug Fixes Issues related to chunk annotation; Incorrect bounding boxes, Multiple stacking of bounding boxes, Inconsistent IDs of the regions, unchanged labels of one connected region to other were identified and fixed and annotators can now select multiple tokens at once and annotate them as a single chunk In the previous release, after an Assertion Status model was trained, it would get deployed without the NER model and hence the preannotation was not working as expected. Going forward, the trained Assertion Model cannot be deployed for projects without a NER model. For this to happen, the “Yes” button in the confirmation box for deploying an assertion model right after training is enabled only when the Project Configuration consists of at least one NER model. A bug in the default Project templates (Project Setup page) was preventing users to create projects using “Conditional classification” and “Pairwise comparison” templates. These default Project templates can be used with no trouble as any other 40+ default templates. Reviewers were able to view unassigned submitted tasks via the “Next” button on the Labeling page. This bug is also fixed now and the reviewers can only see tasks that are assigned to them both on the Task List page or while navigating through the “Next” button. For better user experience, the labeling page has been optimized and the tasks on the page render quicker than in previous versions. When adding a user to the UserAdmins group, the delay in enabling the checkbox has been fixed. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_0"
  },
  "1391": {
    "id": "1391",
    "title": "Spark NLP for Healthcare Release Notes 2.7.0",
    "content": "2.7.0 We are glad to announce that Spark NLP for Healthcare 2.7 has been released ! In this release, we introduce the following features: 1. Text2SQL Text2SQL Annotator that translates natural language text into SQL queries against a predefined database schema, which is one of the most sought-after features of NLU. With the help of a pretrained text2SQL model, you will be able to query your database without writing a SQL query: Example 1 Query: What is the name of the nurse who has the most appointments? Generated SQL query from the model: SELECT T1.Name FROM Nurse AS T1 JOIN Appointment AS T2 ON T1.EmployeeID = T2.PrepNurse GROUP BY T2.prepnurse ORDER BY count(*) DESC LIMIT 1 Response:   Name 0 Carla Espinosa Example 2 Query: How many patients do each physician take care of? List their names and number of patients they take care of. Generated SQL query from the model: SELECT T1.Name, count(*) FROM Physician AS T1 JOIN Patient AS T2 ON T1.EmployeeID = T2.PCP GROUP BY T1.Name Response:   Name count(*) 0 Christopher Turk 1 1 Elliot Reid 2 2 John Dorian 1 For now, it only comes with one pretrained model (trained on Spider dataset) and new pretrained models will be released soon. Check out the Colab notebook to see more examples and run on your data. 2. SentenceEntityResolvers In addition to ChunkEntityResolvers, we now release our first BioBert-based entity resolvers using the SentenceEntityResolver annotator. It’s fully trainable and comes with several pretrained entity resolvers for the following medical terminologies: CPT: biobertresolve_cpt ICDO: biobertresolve_icdo ICD10CM: biobertresolve_icd10cm ICD10PCS: biobertresolve_icd10pcs LOINC: biobertresolve_loinc SNOMED_CT (findings): biobertresolve_snomed_findings SNOMED_INT (clinical_findings): biobertresolve_snomed_findings_int RXNORM (branded and clinical drugs): biobertresolve_rxnorm_bdcd Example: text = &#39;He has a starvation ketosis but nothing significant for dry oral mucosa&#39; df = get_icd10_codes (light_pipeline_icd10, &#39;icd10cm_code&#39;, text)   chunks begin end code 0 a starvation ketosis 7 26 E71121 1 dry oral mucosa 66 80 K136 Check out the Colab notebook to see more examples and run on your data. You can also train your own entity resolver using any medical terminology like MedRa and UMLS. Check this notebook to learn more about training from scratch. 3. ChunkMerge Annotator In order to use multiple NER models in the same pipeline, Spark NLP Healthcare has ChunkMerge Annotator that is used to return entities from each NER model by overlapping. Now it has a new parameter to avoid merging overlapping entities (setMergeOverlapping) to return all the entities regardless of char indices. It will be quite useful to analyze what every NER module returns on the same text. 4. Starting SparkSession We now support starting SparkSession with a different version of the open source jar and not only the one it was built against by sparknlp_jsl.start(secret, public=&quot;x.x.x&quot;) for extreme cases. 5. Biomedical NERs We are releasing 3 new biomedical NER models trained with clinical embeddings (all one single entity models) ner_bacterial_species (comprising of Linneaus and Species800 datasets) ner_chemicals (general purpose and bio chemicals, comprising of BC4Chem and BN5CDR-Chem) ner_diseases_large (comprising of ner_disease, NCBI_Disease and BN5CDR-Disease) We are also releasing the biobert versions of the several clinical NER models stated below: ner_clinical_biobert ner_anatomy_biobert ner_bionlp_biobert ner_cellular_biobert ner_deid_biobert ner_diseases_biobert ner_events_biobert ner_jsl_biobert ner_chemprot_biobert ner_human_phenotype_gene_biobert ner_human_phenotype_go_biobert ner_posology_biobert ner_risk_factors_biobert Metrics (micro averages excluding O’s):   model_name clinical_glove_micro biobert_micro 0 ner_chemprot_clinical 0.816 0.803 1 ner_bionlp 0.748 0.808 2 ner_deid_enriched 0.934 0.918 3 ner_posology 0.915 0.911 4 ner_events_clinical 0.801 0.809 5 ner_clinical 0.873 0.884 6 ner_posology_small 0.941   7 ner_human_phenotype_go_clinical 0.922 0.932 8 ner_drugs 0.964   9 ner_human_phenotype_gene_clinical 0.876 0.870 10 ner_risk_factors 0.728   11 ner_cellular 0.813 0.812 12 ner_posology_large 0.921   13 ner_anatomy 0.851 0.831 14 ner_deid_large 0.942   15 ner_diseases 0.960 0.966 In addition to these, we release two new German NER models: ner_healthcare_slim (‘TIME_INFORMATION’, ‘MEDICAL_CONDITION’, ‘BODY_PART’, ‘TREATMENT’, ‘PERSON’, ‘BODY_PART’) ner_traffic (extract entities regarding traffic accidents e.g. date, trigger, location etc.) 6. PICO Classifier Successful evidence-based medicine (EBM) applications rely on answering clinical questions by analyzing large medical literature databases. In order to formulate a well-defined, focused clinical question, a framework called PICO is widely used, which identifies the sentences in a given medical text that belong to the four components: Participants/Problem (P) (e.g., diabetic patients), Intervention (I) (e.g., insulin), Comparison (C) (e.g., placebo) and Outcome (O) (e.g., blood glucose levels). Spark NLP now introduces a pretrained PICO Classifier that is trained with Biobert embeddings. Example: text = “There appears to be no difference in smoking cessation effectiveness between 1mg and 0.5mg varenicline.” pico_lp_pipeline.annotate(text)[&#39;class&#39;][0] ans: CONCLUSIONS Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_0"
  },
  "1392": {
    "id": "1392",
    "title": "NLP Lab Release Notes 2.7.1",
    "content": "2.7.1 Release date: 22-02-2022 Annotation Lab v2.7.1 introduces an upgrade to K3s v1.22.4 and support for Redhat. It also includes improvements and fixes for identified bug. Below are the highlights of this release. Highlights For new installations, Annotation Lab is now installed on top of K3s v1.22.4. In near future we will provide similar support for existing installations. AWS market place also runs using the upgraded version. With this release Annotation lab can be installed on RedHat servers. Annotation lab 2.7.1 included release version of Spark NLP 3.4.1 and Spark NLP for Healthcare Bug Fixes In the previous release, saving Visual NER project configuration took a long time. With this release, the issue has been fixed and the Visual NER project can be created instantly. Due to a bug in Relation Constraint, all the relations we visible when the UI was refreshed. This issue has been resolved and only a valid list of relations is shown after the UI is refreshed. Previously, labels with spaces at the end were considered different. This has been fixed such that the label name with or without space at the end is treated as the same label. Importing multiple images as a zip file was not working correctly in the case of Visual NER. This issue was fixed. This version also fixes issues in Transfer Learning/Fine Tuning some NER models. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_1"
  },
  "1393": {
    "id": "1393",
    "title": "Spark NLP for Healthcare Release Notes 2.7.1",
    "content": "2.7.1 We are glad to announce that Spark NLP for Healthcare 2.7.1 has been released ! In this release, we introduce the following features: 1. Sentence BioBert and Bluebert Transformers that are fine tuned on MedNLI dataset. Sentence Transformers offers a framework that provides an easy method to compute dense vector representations for sentences and paragraphs (also known as sentence embeddings). The models are based on BioBert and BlueBert, and are tuned specifically to meaningful sentence embeddings such that sentences with similar meanings are close in vector space. These are the first PyTorch based models we managed to port into Spark NLP. Here is how you can load these: sbiobert_embeddins = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) sbluebert_embeddins = BertSentenceEmbeddings .pretrained(&quot;sbluebert_base_cased_mli&quot;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) 2. SentenceEntityResolvers powered by s-Bert embeddings. The advent of s-Bert sentence embeddings changed the landscape of Clinical Entity Resolvers completely in Spark NLP. Since s-Bert is already tuned on MedNLI (medical natural language inference) dataset, it is now capable of populating the chunk embeddings in a more precise way than before. Using sbiobert_base_cased_mli, we trained the following Clinical Entity Resolvers: sbiobertresolve_icd10cm sbiobertresolve_icd10pcs sbiobertresolve_snomed_findings (with clinical_findings concepts from CT version) sbiobertresolve_snomed_findings_int (with clinical_findings concepts from INT version) sbiobertresolve_snomed_auxConcepts (with Morph Abnormality, Procedure, Substance, Physical Object, Body Structure concepts from CT version) sbiobertresolve_snomed_auxConcepts_int (with Morph Abnormality, Procedure, Substance, Physical Object, Body Structure concepts from INT version) sbiobertresolve_rxnorm sbiobertresolve_icdo sbiobertresolve_cpt Code sample: (after getting the chunk from ChunkConverter) c2doc = Chunk2Doc().setInputCols(&quot;ner_chunk&quot;).setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) snomed_ct_resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_snomed_findings&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_ct_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) Output:   chunks begin end code resolutions 2 COPD 113 116 13645005 copd - chronic obstructive pulmonary disease 8 PTCA 324 327 373108000 post percutaneous transluminal coronary angioplasty (finding) 16 close monitoring 519 534 417014005 on examination - vigilance See the notebook for details. 3. We are releasing the following pretrained clinical NER models: ner_drugs_large (trained with medications dataset, and extracts drugs with the dosage, strength, form and route at once as a single entity; entities: drug) ner_deid_sd_large (extracts PHI entities, trained with augmented dataset) ner_anatomy_coarse (trained with enriched anatomy NER dataset; entities: anatomy) ner_anatomy_coarse_biobert chunkresolve_ICD10GM_2021 (German ICD10GM resolver) We are also releasing two new NER models: ner_aspect_based_sentiment (extracts positive, negative and neutral aspects about restaurants from the written feedback given by reviewers. ) ner_financial_contract (extract financial entities from contracts. See the notebook for details.) Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_1"
  },
  "1394": {
    "id": "1394",
    "title": "NLP Lab Release Notes 2.7.2",
    "content": "2.7.2 Release date: 28-02-2022 Annotation Lab v2.7.2 includes Visual NER improvements Bug Fixes The text token in Visual NER project were missing in some cases when the labeling setting “Select regions after creating” was disabled. Now the setting is always enabled when labeling a Visual NER project. Previously, without any changes made by the user on the configuration page “unsaved changes” message used to pop up. Now, the message only pops up when there is an unsaved configuration change. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_2"
  },
  "1395": {
    "id": "1395",
    "title": "Spark NLP for Healthcare Release Notes 2.7.2",
    "content": "2.7.2 We are glad to announce that Spark NLP for Healthcare 2.7.2 has been released ! In this release, we introduce the following features: Far better accuracy for resolving medication terms to RxNorm codes: ondansetron 8 mg tablet&#39; -&gt; &#39;312086 Far better accuracy for resolving diagnosis terms to ICD-10-CM codes: TIA -&gt; transient ischemic attack (disorder) ‘S0690’ New ability to map medications to pharmacological actions (PA): &#39;metformin&#39; -&gt; ‘Hypoglycemic Agents’ 2 new greedy named entity recognition models for medication details: ner_drugs_greedy: ‘magnesium hydroxide 100mg/1ml PO’ ` ner_posology _greedy: ‘12 units of insulin lispro’ ` New model to classify the gender of a patient in a given medical note: &#39;58yo patient with a family history of breast cancer&#39; -&gt; ‘female’ And starting customized spark sessions with rich parameters params = {&quot;spark.driver.memory&quot;:&quot;32G&quot;, &quot;spark.kryoserializer.buffer.max&quot;:&quot;2000M&quot;, &quot;spark.driver.maxResultSize&quot;:&quot;2000M&quot;} spark = sparknlp_jsl.start(secret, params=params) State-of-the-art accuracy is achieved using new healthcare-tuned BERT Sentence Embeddings (s-Bert). The following sections include more details, metrics, and examples. Named Entity Recognizers for Medications A new medication NER (ner_drugs_greedy) that joins the drug entities with neighboring entities such as dosage, route, form and strength; and returns a single entity drug. This greedy NER model would be highly useful if you want to extract a drug with its context and then use it to get a RxNorm code (drugs may get different RxNorm codes based on the dosage and strength information). Metrics label tp fp fn prec rec f1 I-DRUG 37423 4179 3773 0.899 0.908 0.904 B-DRUG 29699 2090 1983 0.934 0.937 0.936 A new medication NER (ner_posology_greedy) that joins the drug entities with neighboring entities such as dosage, route, form and strength. It also returns all the other medication entities even if not related to (or joined with) a drug. Now we have five different medication-related NER models. You can see the outputs from each model below: Text = ‘‘The patient was prescribed 1 capsule of Advil 10 mg for 5 days and magnesium hydroxide 100mg/1ml suspension PO. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.’’ a. ner_drugs_greedy   chunks begin end entities 0 1 capsule of Advil 10 mg 27 50 DRUG 1 magnesium hydroxide 100mg/1ml PO 67 98 DRUG 2 40 units of insulin glargine 168 195 DRUG 3 12 units of insulin lispro 207 232 DRUG b. ner_posology_greedy   chunks begin end entities 0 1 capsule of Advil 10 mg 27 50 DRUG 1 magnesium hydroxide 100mg/1ml PO 67 98 DRUG 2 for 5 days 52 61 DURATION 3 40 units of insulin glargine 168 195 DRUG 4 at night 197 204 FREQUENCY 5 12 units of insulin lispro 207 232 DRUG 6 with meals 234 243 FREQUENCY 7 metformin 1000 mg 250 266 DRUG 8 two times a day 268 282 FREQUENCY c. ner_drugs   chunks begin end entities 0 Advil 40 44 DrugChem 1 magnesium hydroxide 67 85 DrugChem 2 metformin 261 269 DrugChem d.ner_posology   chunks begin end entities 0 1 27 27 DOSAGE 1 capsule 29 35 FORM 2 Advil 40 44 DRUG 3 10 mg 46 50 STRENGTH 4 for 5 days 52 61 DURATION 5 magnesium hydroxide 67 85 DRUG 6 100mg/1ml 87 95 STRENGTH 7 PO 97 98 ROUTE 8 40 units 168 175 DOSAGE 9 insulin glargine 180 195 DRUG 10 at night 197 204 FREQUENCY 11 12 units 207 214 DOSAGE 12 insulin lispro 219 232 DRUG 13 with meals 234 243 FREQUENCY 14 metformin 250 258 DRUG 15 1000 mg 260 266 STRENGTH 16 two times a day 268 282 FREQUENCY e. ner_drugs_large   chunks begin end entities 0 Advil 10 mg 40 50 DRUG 1 magnesium hydroxide 100mg/1ml PO. 67 99 DRUG 2 insulin glargine 180 195 DRUG 3 insulin lispro 219 232 DRUG 4 metformin 1000 mg 250 266 DRUG Patient Gender Classification This model detects the gender of the patient in the clinical document. It can classify the documents into Female, Male and Unknown. We release two models: ‘Classifierdl_gender_sbert’ (more accurate, works with licensed sbiobert_base_cased_mli) ‘Classifierdl_gender_biobert’ (works with biobert_pubmed_base_cased) The models are trained on more than four thousands clinical documents (radiology reports, pathology reports, clinical visits etc.), annotated internally. Metrics (Classifierdl_gender_sbert)   precision recall f1-score support Female 0.9224 0.8954 0.9087 239 Male 0.7895 0.8468 0.8171 124 Text= ‘‘social history: shows that does not smoke cigarettes or drink alcohol, lives in a nursing home. family history: shows a family history of breast cancer.’’ gender_classifier.annotate(text)[&#39;class&#39;][0] &gt;&gt; `Female` See this Colab notebook for further details. a. classifierdl_gender_sbert document = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) .setMaxSentenceLength(512) gender_classifier = ClassifierDLModel .pretrained(&#39;classifierdl_gender_sbert&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;document&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;class&quot;) gender_pred_pipeline = Pipeline( stages = [ document, sbert_embedder, gender_classifier ]) b. classifierdl_gender_biobert documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) clf_tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) biobert_embeddings = BertEmbeddings().pretrained(&#39;biobert_pubmed_base_cased&#39;) .setInputCols([&quot;document&quot;,&#39;token&#39;]) .setOutputCol(&quot;bert_embeddings&quot;) biobert_embeddings_avg = SentenceEmbeddings() .setInputCols([&quot;document&quot;, &quot;bert_embeddings&quot;]) .setOutputCol(&quot;sentence_bert_embeddings&quot;) .setPoolingStrategy(&quot;AVERAGE&quot;) genderClassifier = ClassifierDLModel.pretrained(&#39;classifierdl_gender_biobert&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;document&quot;, &quot;sentence_bert_embeddings&quot;]) .setOutputCol(&quot;gender&quot;) gender_pred_pipeline = Pipeline( stages = [ documentAssembler, clf_tokenizer, biobert_embeddings, biobert_embeddings_avg, genderClassifier ]) New ICD10CM and RxCUI resolvers powered by s-Bert embeddings The advent of s-Bert sentence embeddings changed the landscape of Clinical Entity Resolvers completely in Spark NLP. Since s-Bert is already tuned on MedNLI (medical natural language inference) dataset, it is now capable of populating the chunk embeddings in a more precise way than before. We now release two new resolvers: sbiobertresolve_icd10cm_augmented (augmented with synonyms, four times richer than previous resolver accuracy: 73% for top-1 (exact match), 89% for top-5 (previous accuracy was 59% and 64% respectively) sbiobertresolve_rxcui (extract RxNorm concept unique identifiers to map with ATC or durg families) accuracy: 71% for top-1 (exact match), 72% for top-5 (previous accuracy was 22% and 41% respectively) a. ICD10CM augmented resolver Text = “This is an 82 year old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret&#39;s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU . “   chunk begin end code term 0 hypertension 66 77 I10 hypertension 1 chronic renal insufficiency 81 107 N189 chronic renal insufficiency 2 COPD 111 114 J449 copd - chronic obstructive pulmonary disease 3 gastritis 118 126 K2970 gastritis 4 TIA 134 136 S0690 transient ischemic attack (disorder) 5 a non-ST elevation MI 180 200 I219 silent myocardial infarction (disorder) 6 Guaiac positive stools 206 227 K921 guaiac-positive stools 7 mid LAD lesion 330 343 I2102 stemi involving left anterior descending coronary artery 8 hypotension 360 370 I959 hypotension 9 bradycardia 376 386 O9941 bradycardia b. RxCUI resolver Text= “He was seen by the endocrinology service and she was discharged on 50 mg of eltrombopag oral at night, 5 mg amlodipine with meals, and metformin 1000 mg two times a day . “   chunk begin end code term 0 50 mg of eltrombopag oral 67 91 825427 eltrombopag 50 MG Oral Tablet 1 5 mg amlodipine 103 117 197361 amlodipine 5 MG Oral Tablet 2 metformin 1000 mg 135 151 861004 metformin hydrochloride 1000 MG Oral Tablet Using this new resolver and some other resources like Snomed Resolver, RxTerm, MESHPA and ATC dictionary, you can link the drugs to the pharmacological actions (PA), ingredients and the disease treated with that. Code sample: (after getting the chunk from ChunkConverter) c2doc = Chunk2Doc().setInputCols(&quot;ner_chunk&quot;).setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) icd10_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;icd10cm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) See the notebook for details. Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_2"
  },
  "1396": {
    "id": "1396",
    "title": "Spark NLP for Healthcare Release Notes 2.7.3",
    "content": "2.7.3 We are glad to announce that Spark NLP for Healthcare 2.7.3 has been released! Highlights: Introducing a brand-new RelationExtractionDL Annotator – Achieving SOTA results in clinical relation extraction using BioBert. Massive Improvements &amp; feature enhancements in De-Identification module: Introduction of faker augmentation in Spark NLP for Healthcare to generate random data for obfuscation in de-identification module. Brand-new annotator for Structured De-Identification. Drug Normalizer: Normalize medication-related phrases (dosage, form and strength) and abbreviations in text and named entities extracted by NER models. Confidence scores in assertion output : just like NER output, assertion models now also support confidence scores for each prediction. Cosine similarity metrics in entity resolvers to get more informative and semantically correct results. AuxLabel in the metadata of entity resolvers to return additional mappings. New Relation Extraction models to extract relations between body parts and clinical entities. New Entity Resolver models to extract billable medical codes. New Clinical Pretrained NER models. Bug fixes &amp; general improvements. Matching the version with Spark NLP open-source v2.7.3. 1. Improvements in De-Identification Module: Integration of faker library to automatically generate random data like names, dates, addresses etc so users dont have to specify dummy data (custom obfuscation files can still be used). It also improves the obfuscation results due to a bigger pool of random values. How to use: Set the flag setObfuscateRefSource to faker deidentification = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) For more details: Check out this notebook 2. Structured De-Identification Module: Introduction of a new annotator to handle de-identification of structured data. it allows users to define a mapping of columns and their obfuscation policy. Users can also provide dummy data and map them to columns they want to replace values in. How to use: obfuscator = StructuredDeidentification (spark,{&quot;NAME&quot;:&quot;PATIENT&quot;,&quot;AGE&quot;:&quot;AGE&quot;}, obfuscateRefSource = &quot;faker&quot;) obfuscator_df = obfuscator.obfuscateColumns(df) obfuscator_df.select(&quot;NAME&quot;,&quot;AGE&quot;).show(truncate=False) Example: Input Data: Name Age Cecilia Chapman 83 Iris Watson 9 Bryar Pitts 98 Theodore Lowe 16 Calista Wise 76 Deidentified: Name Age Menne Erdôs 20 Longin Robinson 31 Flynn Fiedlerová 50 John Wakeland 21 Vanessa Andersson 12 For more details: Check out this notebook. 3. Introducing SOTA relation extraction model using BioBert A brand-new end-to-end trained BERT model, resulting in massive improvements. Another new annotator (ReChunkFilter) is also developed for this new model to allow syntactic features work well with BioBert to extract relations. How to use: re_ner_chunk_filter = RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setRelationPairs(pairs) .setMaxSyntacticDistance(4) re_model = RelationExtractionDLModel() .pretrained(“redl_temporal_events_biobert”, &quot;en&quot;, &quot;clinical/models&quot;) .setPredictionThreshold(0.9) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) Benchmarks: on benchmark datasets model Spark NLP ML model Spark NLP DL model benchmark re_temporal_events_clinical 68.29 71.0 80.2 1 re_clinical 56.45 69.2 68.2 2 re_human_pheotype_gene_clinical - 87.9 67.2 3 re_drug_drug_interaction - 72.1 83.8 4 re_chemprot 76.69 94.1 83.64 5 on in-house annotations model Spark NLP ML model Spark NLP DL model re_bodypart_problem 84.58 85.7 re_bodypart_procedure 61.0 63.3 re_date_clinical 83.0 84.0 re_bodypart_direction 93.5 92.5 For more details: Check out the notebook or modelshub. 4. Drug Normalizer: Standardize units of drugs and handle abbreviations in raw text or drug chunks identified by any NER model. This normalization significantly improves performance of entity resolvers. How to use: drug_normalizer = DrugNormalizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;document_normalized&quot;) .setPolicy(&quot;all&quot;) #all/abbreviations/dosages Examples: drug_normalizer.transform(&quot;adalimumab 54.5 + 43.2 gm”) &gt;&gt;&gt; &quot;adalimumab 97700 mg&quot; Changes: combine 54.5 + 43.2 and normalize gm to mg drug_normalizer.transform(&quot;Agnogenic one half cup”) &gt;&gt;&gt; &quot;Agnogenic 0.5 oral solution&quot; Changes: replace one half to the 0.5, normalize cup to the oral solution drug_normalizer.transform(&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec”) &gt;&gt;&gt; &quot;interferon alfa - 2b 10000000 unt ( 1 ml ) injection &quot; Changes: convert 10 million unit to the 10000000 unt, replace injec with injection For more details: Check out this notebook 5. Assertion models to support confidence in output: Just like NER output, assertion models now also provides confidence scores for each prediction. chunks entities assertion confidence a headache PROBLEM present 0.9992 anxious PROBLEM conditional 0.9039 alopecia PROBLEM absent 0.9992 pain PROBLEM absent 0.9238 .setClasses() method is deprecated in AssertionDLApproach and users do not need to specify number of classes while training, as it will be inferred from the dataset. 6. New Relation Extraction Models: We are also releasing new relation extraction models to link the clinical entities to body parts and dates. These models are trained using binary relation extraction approach for better accuracy. - re_bodypart_direction : Relation Extraction between Body Part and Direction entities. Example: Text: “MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” relations entity1 chunk1 entity2 chunk2 confidence 1 Direction upper bodyPart brain stem 0.999 0 Direction upper bodyPart cerebellum 0.999 0 Direction upper bodyPart basil ganglia 0.999 0 bodyPart brain stem Direction left 0.999 0 bodyPart brain stem Direction right 0.999 1 Direction left bodyPart cerebellum 1.0 0 Direction left bodyPart basil ganglia 0.976 0 bodyPart cerebellum Direction right 0.953 1 Direction right bodyPart basil ganglia 1.0 - re_bodypart_problem : Relation Extraction between Body Part and Problem entities. Example: Text: “No neurologic deficits other than some numbness in his left hand.” relation entity1 chunk1 entity2 chunk2 confidence 0 Symptom neurologic deficits bodyPart hand 1 1 Symptom numbness bodyPart hand 1 - re_bodypart_proceduretest : Relation Extraction between Body Part and Procedure, Test entities. Example: Text: “TECHNIQUE IN DETAIL: After informed consent was obtained from the patient and his mother, the chest was scanned with portable ultrasound.” relation entity1 chunk1 entity2 chunk2 confidence 1 bodyPart chest Test portable ultrasound 0.999 -re_date_clinical : Relation Extraction between Date and different clinical entities. Example: Text: “This 73 y/o patient had CT on 1/12/95, with progressive memory and cognitive decline since 8/11/94.” relations entity1 chunk1 entity2 chunk2 confidence 1 Test CT Date 1/12/95 1.0 1 Symptom progressive memory and cognitive decline Date 8/11/94 1.0 How to use: re_model = RelationExtractionModel() .pretrained(&quot;re_bodypart_direction&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([‘Internal_organ_or_component’, ‘Direction’]) For more details: Check out the notebook or modelshub. New matching scheme for entity resolvers - improved accuracy: Adding the option to use cosine similarity to resolve entities and find closest matches, resulting in better, more semantically correct results. 7. New Resolver Models using JSL SBERT: sbiobertresolve_icd10cm_augmented sbiobertresolve_cpt_augmented sbiobertresolve_cpt_procedures_augmented sbiobertresolve_icd10cm_augmented_billable_hcc sbiobertresolve_hcc_augmented Returning auxilary columns mapped to resolutions: Chunk entity resolver and sentence entity resolver now returns auxilary data that is mapped the resolutions during training. This will allow users to get multiple resolutions with single model without using any other annotator in the pipeline (In order to get billable codes otherwise there needs to be other modules in the same pipeline) Example: sbiobertresolve_icd10cm_augmented_billable_hcc Input Text: “bladder cancer” idx chunks code resolutions all_codes billable hcc_status hcc_score all_distances 0 bladder cancer C679 [‘bladder cancer’, ‘suspected bladder cancer’, ‘cancer in situ of urinary bladder’, ‘tumor of bladder neck’, ‘malignant tumour of bladder neck’] [‘C679’, ‘Z126’, ‘D090’, ‘D494’, ‘C7911’] [‘1’, ‘1’, ‘1’, ‘1’, ‘1’] [‘1’, ‘0’, ‘0’, ‘0’, ‘1’] [‘11’, ‘0’, ‘0’, ‘0’, ‘8’] [‘0.0000’, ‘0.0904’, ‘0.0978’, ‘0.1080’, ‘0.1281’] sbiobertresolve_cpt_augmented Input Text: “ct abdomen without contrast” idx cpt code distance resolutions 0 74150 0.0802 Computed tomography, abdomen; without contrast material 1 65091 0.1312 Evisceration of ocular contents; without implant 2 70450 0.1323 Computed tomography, head or brain; without contrast material 3 74176 0.1333 Computed tomography, abdomen and pelvis; without contrast material 4 74185 0.1343 Magnetic resonance imaging without contrast 5 77059 0.1343 Magnetic resonance imaging without contrast 8. New Pretrained Clinical NER Models NER Radiology Input Text: “Bilateral breast ultrasound was subsequently performed, which demonstrated an ovoid mass measuring approximately 0.5 x 0.5 x 0.4 cm in diameter located within the anteromedial aspect of the left shoulder. This mass demonstrates isoechoic echotexture to the adjacent muscle, with no evidence of internal color flow. This may represent benign fibrous tissue or a lipoma.” idx chunks entities 0 Bilateral Direction 1 breast BodyPart 2 ultrasound ImagingTest 3 ovoid mass ImagingFindings 4 0.5 x 0.5 x 0.4 Measurements 5 cm Units 6 anteromedial aspect Direction 7 left Direction 8 shoulder BodyPart 9 mass ImagingFindings 10 isoechoic echotexture ImagingFindings 11 muscle BodyPart 12 internal color flow ImagingFindings 13 benign fibrous tissue ImagingFindings 14 lipoma Disease_Syndrome_Disorder Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_3"
  },
  "1397": {
    "id": "1397",
    "title": "Spark NLP for Healthcare Release Notes 2.7.4",
    "content": "2.7.4 We are glad to announce that Spark NLP for Healthcare 2.7.4 has been released! Highlights: Introducing a new annotator to extract chunks with NER tags using regex-like patterns: NerChunker. Introducing two new annotators to filter chunks: ChunkFilterer and AssertionFilterer. Ability to change the entity type in NerConverterInternal without using ChunkMerger (setReplaceDict). In DeIdentification model, ability to use faker and static look-up lists at the same time randomly in Obfuscation mode. New De-Identification NER model, augmented with synthetic datasets to detect uppercased name entities. Bug fixes &amp; general improvements. 1. NerChunker: Similar to what we used to do in POSChunker with POS tags, now we can also extract phrases that fits into a known pattern using the NER tags. NerChunker would be quite handy to extract entity groups with neighboring tokens when there is no pretrained NER model to address certain issues. Lets say we want to extract clinical findings and body parts together as a single chunk even if there are some unwanted tokens between. How to use: ner_model = NerDLModel.pretrained(&quot;ner_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) ner_chunker = NerChunker(). .setInputCols([&quot;sentence&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers([&quot;&lt;IMAGINGFINDINGS&gt;*&lt;BODYPART&gt;&quot;]) text = &#39;She has cystic cyst on her kidney.&#39; &gt;&gt; ner tags: [(cystic, B-IMAGINGFINDINGS), (cyst,I-IMAGINGFINDINGS), (kidney, B-BODYPART) &gt;&gt; ner_chunk: [&#39;cystic cyst on her kidney&#39;] 2. ChunkFilterer: ChunkFilterer will allow you to filter out named entities by some conditions or predefined look-up lists, so that you can feed these entities to other annotators like Assertion Status or Entity Resolvers. It can be used with two criteria: isin and regex. How to use: ner_model = NerDLModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) chunk_filterer = ChunkFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;) .setOutputCol(&quot;chunk_filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList([&#39;severe fever&#39;,&#39;sore throat&#39;]) text = &#39;Patient with severe fever, sore throat, stomach pain, and a headache.&#39; &gt;&gt; ner_chunk: [&#39;severe fever&#39;,&#39;sore throat&#39;,&#39;stomach pain&#39;,&#39;headache&#39;] &gt;&gt; chunk_filtered: [&#39;severe fever&#39;,&#39;sore throat&#39;] 3. AssertionFilterer: AssertionFilterer will allow you to filter out the named entities by the list of acceptable assertion statuses. This annotator would be quite handy if you want to set a white list for the acceptable assertion statuses like present or conditional; and do not want absent conditions get out of your pipeline. How to use: clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_dl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) assertion_filterer = AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;assertion_filtered&quot;) .setWhiteList([&quot;present&quot;]) text = &#39;Patient with severe fever and sore throat, but no stomach pain.&#39; &gt;&gt; ner_chunk: [&#39;severe fever&#39;,&#39;sore throat&#39;,&#39;stomach pain&#39;,&#39;headache&#39;] &gt;&gt; assertion_filtered: [&#39;severe fever&#39;,&#39;sore throat&#39;] Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_4",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_4"
  },
  "1398": {
    "id": "1398",
    "title": "Spark NLP for Healthcare Release Notes 2.7.5",
    "content": "2.7.5 We are glad to announce that Spark NLP for Healthcare 2.7.5 has been released! Highlights: New pretrained Relation Extraction model to link clinical tests to test results and dates to clinical entities: re_test_result_date Adding two new Admission and Discharge entities to ner_events_clinical and renaming it to ner_events_admission_clinical Improving ner_deid_enriched NER model to cover Doctor and Patient name entities in various context and notations. Bug fixes &amp; general improvements. 1. re_test_result_date : text = “Hospitalized with pneumonia in June, confirmed by a positive PCR of any specimen, evidenced by SPO2 &lt;/= 93% or PaO2/FiO2 &lt; 300 mmHg”   Chunk-1 Entity-1 Chunk-2 Entity-2 Relation 0 pneumonia Problem june Date is_date_of 1 PCR Test positive Test_Result is_result_of 2 SPO2 Test 93% Test_Result is_result_of 3 PaO2/FiO2 Test 300 mmHg Test_Result is_result_of 2. ner_events_admission_clinical : ner_events_clinical NER model is updated &amp; improved to include Admission and Discharge entities. text =”She is diagnosed as cancer in 1991. Then she was admitted to Mayo Clinic in May 2000 and discharged in October 2001”   chunk entity 0 diagnosed OCCURRENCE 1 cancer PROBLEM 2 1991 DATE 3 admitted ADMISSION 4 Mayo Clinic CLINICAL_DEPT 5 May 2000 DATE 6 discharged DISCHARGE 7 October 2001 DATE 3. Improved ner_deid_enriched : PHI NER model is retrained to cover Doctor and Patient name entities even there is a punctuation between tokens as well as all upper case or lowercased. text =”A . Record date : 2093-01-13 , DAVID HALE , M.D . , Name : Hendrickson , Ora MR . # 7194334 Date : 01/13/93 PCP : Oliveira , 25 month years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street”   chunk entity 0 2093-01-13 MEDICALRECORD 1 DAVID HALE DOCTOR 2 Hendrickson , Ora PATIENT 3 7194334 MEDICALRECORD 4 01/13/93 DATE 5 Oliveira DOCTOR 6 25 AGE 7 2079-11-09 MEDICALRECORD 8 Cocke County Baptist Hospital HOSPITAL 9 0295 Keats Street STREET Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_5",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_5"
  },
  "1399": {
    "id": "1399",
    "title": "Spark NLP for Healthcare Release Notes 2.7.6",
    "content": "2.7.6 We are glad to announce that Spark NLP for Healthcare 2.7.6 has been released! Highlights: New pretrained Radiology Assertion Status model to assign Confirmed, Suspected, Negative assertion scopes to imaging findings or any clinical tests. Obfuscating the same sensitive information (patient or doctor name) with the same fake names across the same clinical note. Version compatibility checker for the pretrained clinical models and builds to keep up with the latest development efforts in production. Adding more English names to faker module in Deidentification. Updated &amp; improved clinical SentenceDetectorDL model. New upgrades on ner_deid_large and ner_deid_enriched NER models to cover more use cases with better resolutions. Adding more examples to workshop repo for Scala users to practice more on healthcare annotators. Bug fixes &amp; general improvements. 1. Radiology Assertion Status Model We trained a new assertion model to assign Confirmed, Suspected, Negative assertion scopes to imaging findings or any clinical tests. It will try to assign these statuses to any named entity you would feed to the assertion annotater in the same pipeline. radiology_assertion = AssertionDLModel.pretrained(&quot;assertion_dl_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) text = Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion. No right-sided pleural effusion or pneumothorax is definitively seen. There are mildly displaced fractures of the left lateral 8th and likely 9th ribs. sentences chunk ner_label sent_id assertion Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion. Blunting ImagingFindings 0 Confirmed Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion. effusion ImagingFindings 0 Suspected No right-sided pleural effusion or pneumothorax is definitively seen. effusion ImagingFindings 1 Negative No right-sided pleural effusion or pneumothorax is definitively seen. pneumothorax ImagingFindings 1 Negative There are mildly displaced fractures of the left lateral 8th and likely 9th ribs. displaced fractures ImagingFindings 2 Confirmed You can also use this with AssertionFilterer to return clinical findings from a note only when it is i.e. confirmed or suspected. assertion_filterer = AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;assertion_filtered&quot;) .setWhiteList([&quot;confirmed&quot;,&quot;suspected&quot;]) &gt;&gt; [&quot;displaced fractures&quot;, &quot;effusion&quot;] 2. Obfuscating with the same fake name across the same note: obfuscation = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setSameEntityThreshold(0.8) .setObfuscateRefSource(&quot;faker&quot;) text =&#39;&#39;&#39; Provider: David Hale, M.D. Pt: Jessica Parker David told Jessica that she will need to visit the clinic next month.&#39;&#39;&#39;   sentence obfuscated 0 Provider: David Hale, M.D. Provider: Dennis Perez, M.D. 1 Pt: Jessica Parker Pt: Gerth Bayer 2 David told Jessica that she will need to visit the clinic next month. Dennis told Gerth that she will need to visit the clinic next month. 3. Library Version Compatibility Table : We are releasing the version compatibility table to help users get to see which Spark NLP licensed version is built against which core (open source) version. We are going to release a detailed one after running some tests across the jars from each library. Healthcare Public 2.7.6 2.7.4 2.7.5 2.7.4 2.7.4 2.7.3 2.7.3 2.7.3 2.7.2 2.6.5 2.7.1 2.6.4 2.7.0 2.6.3 2.6.2 2.6.2 2.6.0 2.6.0 2.5.5 2.5.5 2.5.3 2.5.3 2.5.2 2.5.2 2.5.0 2.5.0 2.4.7 2.4.5 2.4.6 2.4.5 2.4.5 2.4.5 2.4.2 2.4.2 2.4.1 2.4.1 2.4.0 2.4.0 2.3.6 2.3.6 2.3.5 2.3.5 2.3.4 2.3.4 4. Pretrained Models Version Control : Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models, especially for the users using our models locally in air-gapped networks. We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. This is an highly experimental feature of which we plan to improve and add more capability later on. from sparknlp_jsl.check_compatibility import Compatibility checker = sparknlp_jsl.Compatibility() result = checker.find_version(aws_access_key_id=license_keys[&#39;AWS_ACCESS_KEY_ID&#39;], aws_secret_access_key=license_keys[&#39;AWS_SECRET_ACCESS_KEY&#39;], metadata_path=None, model = &#39;all&#39; , # or a specific model name target_version=&#39;all&#39;, cache_pretrained_path=&#39;/home/ubuntu/cache_pretrained&#39;) &gt;&gt; result[&#39;outdated_models&#39;] [{&#39;model_name&#39;: &#39;clinical_ner_assertion&#39;, &#39;current_version&#39;: &#39;2.4.0&#39;, &#39;latest_version&#39;: &#39;2.6.4&#39;}, {&#39;model_name&#39;: &#39;jsl_rd_ner_wip_greedy_clinical&#39;, &#39;current_version&#39;: &#39;2.6.1&#39;, &#39;latest_version&#39;: &#39;2.6.2&#39;}, {&#39;model_name&#39;: &#39;ner_anatomy&#39;, &#39;current_version&#39;: &#39;2.4.2&#39;, &#39;latest_version&#39;: &#39;2.6.4&#39;}, {&#39;model_name&#39;: &#39;ner_aspect_based_sentiment&#39;, &#39;current_version&#39;: &#39;2.6.2&#39;, &#39;latest_version&#39;: &#39;2.7.2&#39;}, {&#39;model_name&#39;: &#39;ner_bionlp&#39;, &#39;current_version&#39;: &#39;2.4.0&#39;, &#39;latest_version&#39;: &#39;2.7.0&#39;}, {&#39;model_name&#39;: &#39;ner_cellular&#39;, &#39;current_version&#39;: &#39;2.4.2&#39;, &#39;latest_version&#39;: &#39;2.5.0&#39;}] &gt;&gt; result[&#39;version_comparison_dict&#39;] [{&#39;clinical_ner_assertion&#39;: {&#39;current_version&#39;: &#39;2.4.0&#39;, &#39;latest_version&#39;: &#39;2.6.4&#39;}}, {&#39;jsl_ner_wip_clinical&#39;: {&#39;current_version&#39;: &#39;2.6.5&#39;, &#39;latest_version&#39;: &#39;2.6.1&#39;}}, {&#39;jsl_ner_wip_greedy_clinical&#39;: {&#39;current_version&#39;: &#39;2.6.5&#39;, &#39;latest_version&#39;: &#39;2.6.5&#39;}}, {&#39;jsl_ner_wip_modifier_clinical&#39;: {&#39;current_version&#39;: &#39;2.6.4&#39;, &#39;latest_version&#39;: &#39;2.6.4&#39;}}, {&#39;jsl_rd_ner_wip_greedy_clinical&#39;: {&#39;current_version&#39;: &#39;2.6.1&#39;,&#39;latest_version&#39;: &#39;2.6.2&#39;}}] 5. Updated Pretrained Models: (requires fresh .pretraned()) ner_deid_large ner_deid_enriched Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_6",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_6"
  },
  "1400": {
    "id": "1400",
    "title": "NLP Lab Release Notes 2.8.0",
    "content": "2.8.0 Release date: 19-03-2022 Annotation Lab 2.8.0 simplifies the annotation workflows, adds dynamic pagination features, supports cross-page NER annotation and relation definition for text projects, adds UI features for infrastructure configuration and backup, updates the way the analytics dashboards are processed, offers improved support for rules and support for model training in German and Spanish. Highlights New features offered by Annotation Lab: Dynamic Task Pagination replaced the &lt;pagebreak&gt; style pagination. Cross Page Annotation is now supported for NER and Relation annotations. Simplified workflow are now supported for simpler projects. Furthermore, overall work progress has been added on the Labeling Page. Infrastucture used for preannotation and training can now be configured from the Annotation Lab UI. Support for training German and Spanish models. Some changes in Analytics Dashboard were implemented. By default, the Analytics dashboard page is now disabled. Users can request Admin to enable the Analytics page. The refresh of the charts is done manually. Import &amp; Export Rules from the Model Hub page. Download model dependencies is now automatic. The project configuration box can now be edited in full screen mode. Trim leading and ending spaces in annotated chunks. Reserved words cannot be used in project names. Task numbering now start from 1. ‘a’ was removed as hotkey for VisualNER multi-chunk selection. Going forward only use ‘shift’ key for chunk selection. Only alphanumeric characters can be used as the Task Tag Names. Allow the export of tasks without completions. Bug Fixes On the Labeling Page, the following issues related to completions were identified and fixed: In the Visual NER Project, when an annotator clicks on the Next button to load the next available task, the PDF was not correctly loaded and the text selection doesn’t work properly. Shortcut keys were not working when creating new completions. It happened that completions were no longer visible after creating relations. Previously, after each project configuration edit, when validating the correctness of the configuration the cursor position was reset to the end of the config file. The user had to manually move the cursor back to its previous position to continue editing. Now, the cursor position is saved so that the editing can continue with ease. Removing a user from the “UserAdmins” group was not possible. This has been fixed. Any user can be added or removed from the “UserAdmins”. In previous versions, choosing an already existing name for the current project did not show any error messages. Now, an error message appears on the right side of the screen asking users to choose another name for the project. In the previous version, when a user was deleted and a new user with the same name was created through Keycloak, on the next login the UI did not load. Now, this issue was fixed. Validations were added to Swagger API for completions data such that random values could not be added to completion data via API. Previously, when a rule was edited, previously deployed preannotation pipelines using the edited rules were not updated to use the latest version of the rule. Now the user is notified about the edited rule via an alert message “Redeploy preannotation server to apply these changes” on the rule edit form so that the users can redeploy the preannotation model. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_8_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_8_0"
  },
  "1401": {
    "id": "1401",
    "title": "NLP Lab Release Notes 3.0.0",
    "content": "3.0.0 Release date: 06-04-2022 We are very excited to release Annotation Lab 3.0.0 with support for Floating Licenses and for parallel training and preannotation jobs, created on demand by Project Owners and Managers across various projects. Below are more details about the release. Highlights Annotation Lab now supports floating licenses with different scopes (ocr: training, ocr: inference, healthcare: inference, healthcare: training). Depending on the scope of the available license, users can perform model training and/or deploy preannotation servers. Licenses are a must only for training Spark NLP for Healthcare models and for deploying Spark NLP for Healthcare models as preannotation servers. Parallel Trainings and Preannotations. Annotation Lab now offers support for running model training and document preannotation across multiple projects and/or teams in parallel. If the infrastructure dedicated to the Annotation Lab includes sufficient resources, each team/project can run smoothly without being blocked. On demand deployment of preannotation servers and training jobs: Deploy a new training job Deploy a new preannotation server The infrastucture page now hosts a new tab for managing preannotation, training and OCR servers. New options available on preannotate action. Updates for the license page. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_0_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_0_0"
  },
  "1402": {
    "id": "1402",
    "title": "Spark NLP release notes 3.0.0",
    "content": "3.0.0 Release date: 02-04-2021 Overview We are very excited to release Spark OCR 3.0.0! Spark OCR 3.0.0 extends the support for Apache Spark 3.0.x and 3.1.x major releases on Scala 2.12 with both Hadoop 2.7. and 3.2. We will support all 4 major Apache Spark and PySpark releases of 2.3.x, 2.4.x, 3.0.x, and 3.1.x. Spark OCR started to support Tensorflow models. First model is VisualDocumentClassifier. New Features Support for Apache Spark and PySpark 3.0.x on Scala 2.12 Support for Apache Spark and PySpark 3.1.x on Scala 2.12 Support 9x new Databricks runtimes: Databricks 7.3 Databricks 7.3 ML GPU Databricks 7.4 Databricks 7.4 ML GPU Databricks 7.5 Databricks 7.5 ML GPU Databricks 7.6 Databricks 7.6 ML GPU Databricks 8.0 Databricks 8.0 ML (there is no GPU in 8.0) Databricks 8.1 Support 2x new EMR 6.x: EMR 6.1.0 (Apache Spark 3.0.0 / Hadoop 3.2.1) EMR 6.2.0 (Apache Spark 3.0.1 / Hadoop 3.2.1) VisualDocumentClassifier model for classification documents using text and layout data. Added support Vietnamese language. New notebooks Visual Document Classifier Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_0_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_0_0"
  },
  "1403": {
    "id": "1403",
    "title": "Spark NLP for Healthcare Release Notes 3.0.0",
    "content": "3.0.0 We are very excited to announce that Spark NLP for Healthcare 3.0.0 has been released! This has been one of the biggest releases we have ever done and we are so proud to share this with our customers. Highlights: Spark NLP for Healthcare 3.0.0 extends the support for Apache Spark 3.0.x and 3.1.x major releases on Scala 2.12 with both Hadoop 2.7. and 3.2. We now support all 4 major Apache Spark and PySpark releases of 2.3.x, 2.4.x, 3.0.x, and 3.1.x helping the customers to migrate from earlier Apache Spark versions to newer releases without being worried about Spark NLP support. Highlights: Support for Apache Spark and PySpark 3.0.x on Scala 2.12 Support for Apache Spark and PySpark 3.1.x on Scala 2.12 Migrate to TensorFlow v2.3.1 with native support for Java to take advantage of many optimizations for CPU/GPU and new features/models introduced in TF v2.x A brand new MedicalNerModel annotator to train &amp; load the licensed clinical NER models. Two times faster NER and Entity Resolution due to new batch annotation technique. Welcoming 9x new Databricks runtimes to our Spark NLP family: Databricks 7.3 Databricks 7.3 ML GPU Databricks 7.4 Databricks 7.4 ML GPU Databricks 7.5 Databricks 7.5 ML GPU Databricks 7.6 Databricks 7.6 ML GPU Databricks 8.0 Databricks 8.0 ML (there is no GPU in 8.0) Databricks 8.1 Beta Welcoming 2x new EMR 6.x series to our Spark NLP family: EMR 6.1.0 (Apache Spark 3.0.0 / Hadoop 3.2.1) EMR 6.2.0 (Apache Spark 3.0.1 / Hadoop 3.2.1) Starting Spark NLP for Healthcare 3.0.0 the default packages for CPU and GPU will be based on Apache Spark 3.x and Scala 2.12. Deprecated Text2SQL annotator is deprecated and will not be maintained going forward. We are working on a better and faster version of Text2SQL at the moment and will announce soon. 1. MedicalNerModel Annotator Starting Spark NLP for Healthcare 3.0.0, the licensed clinical and biomedical pretrained NER models will only work with this brand new annotator called MedicalNerModel and will not work with NerDLModel in open source version. In order to make this happen, we retrained all the clinical NER models (more than 80) and uploaded to models hub. Example: clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) 2. Speed Improvements A new batch annotation technique implemented in Spark NLP 3.0.0 for NerDLModel,BertEmbeddings, and BertSentenceEmbeddings annotators will be reflected in MedicalNerModel and it improves prediction/inferencing performance radically. From now on the batchSize for these annotators means the number of rows that can be fed into the models for prediction instead of sentences per row. You can control the throughput when you are on accelerated hardware such as GPU to fully utilise it. Here are the overall speed comparison: Now, NER inference and Entity Resolution are two times faster on CPU and three times faster on GPU. 3. JSL Clinical NER Model We are releasing the richest clinical NER model ever, spanning over 80 entities. It has been under development for the last 6 months and we manually annotated more than 4000 clinical notes to cover such a high number of entities in a single model. It has 4 variants at the moment: jsl_ner_wip_clinical jsl_ner_wip_greedy_clinical jsl_ner_wip_modifier_clinical jsl_rd_ner_wip_greedy_clinical Entities: Kidney_Disease, HDL, Diet, Test, Imaging_Technique, Triglycerides, Obesity, Duration, Weight, Social_History_Header, ImagingTest, Labour_Delivery, Disease_Syndrome_Disorder, Communicable_Disease, Overweight, Units, Smoking, Score, Substance_Quantity, Form, Race_Ethnicity, Modifier, Hyperlipidemia, ImagingFindings, Psychological_Condition, OtherFindings, Cerebrovascular_Disease, Date, Test_Result, VS_Finding, Employment, Death_Entity, Gender, Oncological, Heart_Disease, Medical_Device, Total_Cholesterol, ManualFix, Time, Route, Pulse, Admission_Discharge, RelativeDate, O2_Saturation, Frequency, RelativeTime, Hypertension, Alcohol, Allergen, Fetus_NewBorn, Birth_Entity, Age, Respiration, Medical_History_Header, Oxygen_Therapy, Section_Header, LDL, Treatment, Vital_Signs_Header, Direction, BMI, Pregnancy, Sexually_Active_or_Sexual_Orientation, Symptom, Clinical_Dept, Measurements, Height, Family_History_Header, Substance, Strength, Injury_or_Poisoning, Relationship_Status, Blood_Pressure, Drug, Temperature, EKG_Findings, Diabetes, BodyPart, Vaccine, Procedure, Dosage 4. JSL Clinical Assertion Model We are releasing a brand new clinical assertion model, supporting 8 assertion statuses. jsl_assertion_wip Assertion Labels : Present, Absent, Possible, Planned, Someoneelse, Past, Family, Hypotetical 5. Library Version Compatibility Table : Spark NLP for Healthcare 3.0.0 is compatible with Spark NLP 3.0.1 6. Pretrained Models Version Control (Beta): Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models, especially for the users using our models locally in air-gapped networks. We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. You will not need to specify your AWS credentials from now on. This is the second version of the model checker we released with 2.7.6 and will replace that soon. from sparknlp_jsl.compatibility_beta import CompatibilityBeta compatibility = CompatibilityBeta(spark) print(compatibility.findVersion(&quot;ner_deid&quot;)) 7. Updated Pretrained Models: (requires fresh .pretraned()) None Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_0"
  },
  "1404": {
    "id": "1404",
    "title": "NLP Lab Release Notes 3.0.1",
    "content": "3.0.1 Release date: 12-04-2022 Annotation Lab v3.0.1 includes some CVE issues are fixed along with application bug fixes Bug Fixes When licensed model is trained, label “label” was added to prediction entities Expired license icon is seen after the user enters new floating license In airgaped machine, deployed licensed preannotation server is shown as open source in active-servers page Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_0_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_0_1"
  },
  "1405": {
    "id": "1405",
    "title": "Spark NLP for Healthcare Release Notes 3.0.1",
    "content": "3.0.1 We are very excited to announce that Spark NLP for Healthcare 3.0.1 has been released! Highlights: Fixed problem in Assertion Status internal tokenization (reported in Spark-NLP #2470). Fixes in the internal implementation of DeIdentificationModel/Obfuscator. Being able to disable the use of regexes in the Deidentification process Other minor bug fixes &amp; general improvements. DeIdentificationModel Annotator New seed parameter. Now we have the possibility of using a seed to guide the process of obfuscating entities and returning the same result across different executions. To make that possible a new method setSeed(seed:Int) was introduced. Example: Return obfuscated documents in a repeatable manner based on the same seed. Scala deIdentification = DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(true) Python de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(True) This seed controls how the obfuscated values are picked from a set of obfuscation candidates. Fixing the seed allows the process to be replicated. Example: Given the following input to the deidentification: &quot;David Hale was in Cocke County Baptist Hospital. David Hale&quot; If the annotator is set up with a seed of 10: Scala val deIdentification = new DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(true) Python de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(True) The result will be the following for any execution, &quot;Brendan Kitten was in New Megan.Brendan Kitten&quot; Now if we set up a seed of 32, Scala val deIdentification = new DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(32) .setIgnoreRegex(true) Python de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(True) The result will be the following for any execution, &quot;Louise Pear was in Lake Edward.Louise Pear&quot; New ignoreRegex parameter. You can now choose to completely disable the use of regexes in the deidentification process by setting the setIgnoreRegex param to True. Example: Scala DeIdentificationModel.setIgnoreRegex(true) Python DeIdentificationModel().setIgnoreRegex(True) The default value for this param is False meaning that regexes will be used by default. New supported entities for Deidentification &amp; Obfuscation: We added new entities to the default supported regexes: SSN - Social security number. PASSPORT - Passport id. DLN - Department of Labor Number. NPI - National Provider Identifier. C_CARD - The id number for credits card. IBAN - International Bank Account Number. DEA - DEA Registration Number, which is an identifier assigned to a health care provider by the United States Drug Enforcement Administration. We also introduced new Obfuscator cases for these new entities. Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_1"
  },
  "1406": {
    "id": "1406",
    "title": "Spark NLP for Healthcare Release Notes 3.0.2",
    "content": "3.0.2 We are very excited to announce that Spark NLP for Healthcare 3.0.2 has been released! This release includes bug fixes and some compatibility improvements. Highlights Dictionaries for Obfuscator were augmented with more than 10K names. Improved support for spark 2.3 and spark 2.4. Bug fixes in DrugNormalizer. New Features Provide confidence scores for all available tags in MedicalNerModel, MedicalNerModel before 3.0.2 [[named_entity, 0, 9, B-PROBLEM, [word -&gt; Pneumonia, confidence -&gt; 0.9998], []] Now in Spark NLP for Healthcare 3.0.2 [[named_entity, 0, 9, B-PROBLEM, [B-PROBLEM -&gt; 0.9998, I-TREATMENT -&gt; 0.0, I-PROBLEM -&gt; 0.0, I-TEST -&gt; 0.0, B-TREATMENT -&gt; 1.0E-4, word -&gt; Pneumonia, B-TEST -&gt; 0.0], []] Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_2"
  },
  "1407": {
    "id": "1407",
    "title": "Spark NLP for Healthcare Release Notes 3.0.3",
    "content": "3.0.3 We are glad to announce that Spark NLP for Healthcare 3.0.3 has been released! Highlights Five new entity resolution models to cover UMLS, HPO and LIONC terminologies. New feature for random displacement of dates on deidentification model. Five new pretrained pipelines to map terminologies across each other (from UMLS to ICD10, from RxNorm to MeSH etc.) AnnotationToolReader support for Spark 2.3. The tool that helps model training on Spark-NLP to leverage data annotated using JSL Annotation Tool now has support for Spark 2.3. Updated documentation (Scaladocs) covering more APIs, and examples. Five new resolver models: sbiobertresolve_umls_major_concepts: This model returns CUI (concept unique identifier) codes for Clinical Findings, Medical Devices, Anatomical Structures and Injuries &amp; Poisoning terms. sbiobertresolve_umls_findings: This model returns CUI (concept unique identifier) codes for 200K concepts from clinical findings. sbiobertresolve_loinc: Map clinical NER entities to LOINC codes using sbiobert. sbluebertresolve_loinc: Map clinical NER entities to LOINC codes using sbluebert. sbiobertresolve_HPO: This model returns Human Phenotype Ontology (HPO) codes for phenotypic abnormalities encountered in human diseases. It also returns associated codes from the following vocabularies for each HPO code: * MeSH (Medical Subject Headings) * SNOMED * UMLS (Unified Medical Language System ) * ORPHA (international reference resource for information on rare diseases and orphan drugs) * OMIM (Online Mendelian Inheritance in Man) Related Notebook: Resolver Models New feature on Deidentification Module isRandomDateDisplacement(True): Be able to apply a random displacement on obfuscation dates. The randomness is based on the seed. Fix random dates when the format is not correct. Now you can repeat an execution using a seed for dates. Random dates will be based on the seed. Five new healthcare code mapping pipelines: icd10cm_umls_mapping: This pretrained pipeline maps ICD10CM codes to UMLS codes without using any text data. You’ll just feed white space-delimited ICD10CM codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;icd10cm&#39;: [&#39;M89.50&#39;, &#39;R82.2&#39;, &#39;R09.01&#39;], &#39;umls&#39;: [&#39;C4721411&#39;, &#39;C0159076&#39;, &#39;C0004044&#39;]} mesh_umls_mapping: This pretrained pipeline maps MeSH codes to UMLS codes without using any text data. You’ll just feed white space-delimited MeSH codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;mesh&#39;: [&#39;C028491&#39;, &#39;D019326&#39;, &#39;C579867&#39;], &#39;umls&#39;: [&#39;C0970275&#39;, &#39;C0886627&#39;, &#39;C3696376&#39;]} rxnorm_umls_mapping: This pretrained pipeline maps RxNorm codes to UMLS codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;rxnorm&#39;: [&#39;1161611&#39;, &#39;315677&#39;, &#39;343663&#39;], &#39;umls&#39;: [&#39;C3215948&#39;, &#39;C0984912&#39;, &#39;C1146501&#39;]} rxnorm_mesh_mapping: This pretrained pipeline maps RxNorm codes to MeSH codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding MeSH codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;rxnorm&#39;: [&#39;1191&#39;, &#39;6809&#39;, &#39;47613&#39;], &#39;mesh&#39;: [&#39;D001241&#39;, &#39;D008687&#39;, &#39;D019355&#39;]} snomed_umls_mapping: This pretrained pipeline maps SNOMED codes to UMLS codes without using any text data. You’ll just feed white space-delimited SNOMED codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;snomed&#39;: [&#39;733187009&#39;, &#39;449433008&#39;, &#39;51264003&#39;], &#39;umls&#39;: [&#39;C4546029&#39;, &#39;C3164619&#39;, &#39;C0271267&#39;]} Related Notebook: Healthcare Code Mapping Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_3"
  },
  "1408": {
    "id": "1408",
    "title": "Spark NLP release notes 3.10.0",
    "content": "3.10.0 Release date: 10-01-2022 Overview Form recognition using LayoutLMv2 and text detection. New Features Added VisualDocumentNERv2 transformer Added DL based ImageTextDetector transformer Support rotated regions in ImageSplitRegions Support rotated regions in ImageDrawRegions New Models LayoutLMv2 fine-tuned on FUNSD dataset Text detection model based on CRAFT architecture New notebooks Text Detection Visual Document NER v2 Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_10_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_10_0"
  },
  "1409": {
    "id": "1409",
    "title": "Spark NLP release notes 3.11.0",
    "content": "3.11.0 Release date: 28-02-2022 Overview We are glad to announce that Spark OCR 3.11.0 has been released!. This release comes with new models, new features, bug fixes, and notebook examples. New Features Added ImageTextDetectorV2 Python Spark-OCR Transformer for detecting printed and handwritten text using CRAFT architecture with Refiner Net. Added ImageTextRecognizerV2 Python Spark-OCR Transformer for recognizing printed and handwritten text based on Deep Learning Transformer Architecture. Added FormRelationExtractor for detecting relations between key and value entities in forms. Added the capability of fine tuning VisualDocumentNerV2 models for key-value pairs extraction. New Models ImageTextDetectorV2: this extends the ImageTextDetectorV1 character level text detection model with a refiner net architecture. ImageTextRecognizerV2: Text recognition for printed text based on the Deep Learning Transformer Architecture. New notebooks SparkOcrImageToTextV2 ImageTextDetectorV2 Visual Document NER v2 SparkOcrFormRecognition SparkOCRVisualDocumentNERv2FineTune Creating Rest a API with Synapse to extract text from images, SparkOcrRestApi Creating Rest a API with Synapse to extract text from PDFs, SparkOcrRestApiPdf Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_11_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_11_0"
  },
  "1410": {
    "id": "1410",
    "title": "Spark NLP release notes 3.12.0",
    "content": "3.12.0 Release date: 14-04-2022 Overview We’re glad to announce that Spark OCR 3.12.0 has been released! This release comes with new models for Handwritten Text Recognition, Spark 3.2 support, bug fixes, and notebook examples. New Features Added to the ImageTextDetectorV2: New parameter ‘mergeIntersects’: merge bounding boxes corresponding to detected text regions, when multiple bounding boxes that belong to the same text line overlap. New parameter ‘forceProcessing’: now you can force processing of the results to avoid repeating the computation of results in pipelines where the same results are consumed by different transformers. New feature: sizeThreshold parameter sets the expected size for the recognized text. From now on, text size will be automatically detected when sizeThreshold is set to -1. Added to the ImageToTextV2: New parameter ‘usePandasUdf’: support PandasUdf to allow batch processing internally. New support for formatted output, and HOCR. ocr.setOutputFormat(OcrOutputFormat.HOCR) ocr.setOutputFormat(OcrOutputFormat.FORMATTED_TEXT) Support for Spark 3.2: We added support for the latest Spark version, check installation instructions below. Known problems &amp; workarounds: SPARK-38330: S3 access issues, there’s a workaround using the following settings, //Scala spark.sparkContext.hadoopConfiguration.set(&quot;fs.s3a.path.style.access&quot;, &quot;true&quot;) #Python spark.sparkContext._jsc.hadoopConfiguration().set(&quot;fs.s3a.path.style.access&quot;, &quot;true&quot;) SPARK-37577: changes in default behavior of query optimizer, it is already handled in start() function, or if you start the context manually, setting the following Spark properties, #Python spark.conf.set(&quot;spark.sql.optimizer.expression.nestedPruning.enabled&quot;, False) spark.conf.set(&quot;spark.sql.optimizer.nestedSchemaPruning.enabled&quot;, False) Improved documentation on the website. New Models ocr_small_printed: Text recognition small model for printed text based on ImageToTextV2 ocr_small_handwritten: Text recognition small model for handwritten text based on ImageToTextV2 ocr_base_handwritten: Text recognition base model for handwritten text based on ImageToTextV2 Bug Fixes display_table() function failing to display tables coming from digital PDFs. New notebooks SparkOcrImageToTextV2OutputFormats.ipynb, different output formats for ImageToTextV2. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_12_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_12_0"
  },
  "1411": {
    "id": "1411",
    "title": "Spark NLP release notes 3.13.0",
    "content": "3.13.0 Release date: 25-05-2022 We are glad to announce that Spark OCR 3.13.0 has been released!. This release focuses around VisualDocumentNer models, adding ability to fine-tune, fixing bugs, and to leverage the Annotation Lab to generate training data. New Features VisualDocumentNerV21: Now you can fine tune models VisualDocumentNerV21 models on your own dataset. AlabReaders: New class to allow training data from the Annotation Lab to be imported into Spark OCR. Currently, the reader supports Visual Ner only. Bug Fixes Feature extraction on VisualDocumentNer has been improved. New notebooks SparkOcrFormRecognitionFineTuning.ipynb, end to end example on Visual Document Ner Fine-Tuning. Databricks notebooks on Github Spark-OCR Workshop repository have been updated, and fixed. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_13_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_13_0"
  },
  "1412": {
    "id": "1412",
    "title": "Spark NLP release notes 3.14.0",
    "content": "3.14.0 Release date: 13-06-2022 Overview We are glad to announce that Spark OCR 3.14.0 has been released!. This release focuses around Visual Document Classification models, native Image Preprocessing on the JVM, and bug fixes. New Features VisualDocumentClassifierv2: New annotator for classifying documents based on multimodal(text + images) features. VisualDocumentClassifierv3: New annotator for classifying documents based on image features. ImageTransformer: New transformer that provides different image transformations on the JVM. Supported transforms are Scaling, Adaptive Thresholding, Median Blur, Dilation, Erosion, and Object Removal. New notebooks SparkOCRVisualDocumentClassifierv2.ipynb, example of Visual Document Classification using multimodal (text + visual) features. SparkOCRVisualDocumentClassifierv3.ipynb, example of Visual Document Classification using only visual features. SparkOCRCPUImageOperations.ipynb, example of ImageTransformer. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_14_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_14_0"
  },
  "1413": {
    "id": "1413",
    "title": "NLP Lab Release Notes 3.1.0",
    "content": "3.1.0 Release date: 04-05-2022 We are very excited to release Annotation Lab v3.1.0 which includes support for training large documents, improvements for Visual NER Projects, security fixes and stabilizations. Here are the highlights: Highlights Support Training of large documents. Spark NLP feature called Memory Optimization Approach is enabled when the training data is greater then 5MB which enables training of model on machines with lower memory resources. Improvements in Visual NER Projects: Users can provide title in the input JSON along with the URL for tasks to import. This sets the title of the task accordingly. JSON export for the Visual NER projects contains both chunk and token-level annotations. Sample tasks can be imported into the Visual NER project using any available OCR server (created by another project). Multi-chunk annotation can be done without changing the start token when the end token is the last word on the document. For Visual NER project, users can export tasks in the VOC format for multi-page tasks with/without completions. During restoring backup file in the previous versions, the SECRETS (kubernetes) of the old machine needed manual transfer to the target machine. With v3.1.0, all the SECRETS are backed-up automatically along with database backup and hence they are restored without any hassle. Integration with my.johnsnowlabs.com, this means the available licenses can be easily imported by Admin users of Annotation Lab without having to download or copy them manually. The maximum number of words/tokens that can be set in a single page in labeling screen is now limited to 1000. For a large number of multiple relations, the previous version of Annotation Lab used Prev and Next identifiers which was not optimal for mapping to the correct pairs. For increased usability and clarity , the pair connections now use numerical values. While creating new (Contextual Parser) Rules using dictionary, the uploaded CSV file is validated based on: CSV should not contain any null values, CSV should either be a single row or single column. Admin users are now able to remove unused licenses. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_1_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_1_0"
  },
  "1414": {
    "id": "1414",
    "title": "Spark NLP release notes 3.1.0",
    "content": "3.1.0 Release date: 16-04-2021 Overview Image processing on GPU. It is in 3.5 times faster than on CPU. More details please read in GPU image preprocessing in Spark OCR New Features GPUImageTransformer with support: scaling, erosion, delation, Otsu and Huang thresholding. Added display_images util function for displaying images from Spark DataFrame in Jupyter notebooks. Enhancements Improve display_image util function. Bug fixes Fixed issue with extra dependencies in start function New notebooks GPU image processing Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_1_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_1_0"
  },
  "1415": {
    "id": "1415",
    "title": "Spark NLP for Healthcare Release Notes 3.1.0",
    "content": "3.1.0 We are glad to announce that Spark NLP for Healthcare 3.1.0 has been released! Highlights Improved load time &amp; memory consumption for SentenceResolver models. New JSL Bert Models. JSL SBert Model Speed Benchmark. New ICD10CM resolver models. New Deidentification NER models. New column returned in DeidentificationModel New Reidentification feature New Deidentification Pretrained Pipelines Chunk filtering based on confidence Extended regex dictionary fuctionallity in Deidentification Enhanced RelationExtractionDL Model to create and identify relations between entities across the entire document MedicalNerApproach can now accept a graph file directly. MedicalNerApproach can now accept a user-defined name for log file. More improvements in Scaladocs. Bug fixes in Deidentification module. New notebooks. Sentence Resolver Models load time improvement Sentence resolver models now have faster load times, with a speedup of about 6X when compared to previous versions. Also, the load process now is more memory friendly meaning that the maximum memory required during load time is smaller, reducing the chances of OOM exceptions, and thus relaxing hardware requirements. New JSL SBert Models We trained new sBert models in TF2 and fined tuned on MedNLI, NLI and UMLS datasets with various parameters to cover common NLP tasks in medical domain. You can find the details in the following table. sbiobert_jsl_cased sbiobert_jsl_umls_cased sbert_jsl_medium_uncased sbert_jsl_medium_umls_uncased sbert_jsl_mini_uncased sbert_jsl_mini_umls_uncased sbert_jsl_tiny_uncased sbert_jsl_tiny_umls_uncased JSL SBert Model Speed Benchmark JSL SBert Model Base Model Is Cased Train Datasets Inference speed (100 rows) sbiobert_jsl_cased biobert_v1.1_pubmed Cased medNLI, allNLI 274,53 sbiobert_jsl_umls_cased biobert_v1.1_pubmed Cased medNLI, allNLI, umls 274,52 sbert_jsl_medium_uncased uncased_L-8_H-512_A-8 Uncased medNLI, allNLI 80,40 sbert_jsl_medium_umls_uncased uncased_L-8_H-512_A-8 Uncased medNLI, allNLI, umls 78,35 sbert_jsl_mini_uncased uncased_L-4_H-256_A-4 Uncased medNLI, allNLI 10,68 sbert_jsl_mini_umls_uncased uncased_L-4_H-256_A-4 Uncased medNLI, allNLI, umls 10,29 sbert_jsl_tiny_uncased uncased_L-2_H-128_A-2 Uncased medNLI, allNLI 4,54 sbert_jsl_tiny_umls_uncased uncased_L-2_H-128_A-2 Uncased medNLI, allNL, umls 4,54 New ICD10CM resolver models: These models map clinical entities and concepts to ICD10 CM codes using sentence bert embeddings. They also return the official resolution text within the brackets inside the metadata. Both models are augmented with synonyms, and previous augmentations are flexed according to cosine distances to unnormalized terms (ground truths). sbiobertresolve_icd10cm_slim_billable_hcc: Trained with classic sbiobert mli. (sbiobert_base_cased_mli) Models Hub Page : https://nlp.johnsnowlabs.com/2021/05/25/sbiobertresolve_icd10cm_slim_billable_hcc_en.html sbertresolve_icd10cm_slim_billable_hcc_med: Trained with new jsl sbert(sbert_jsl_medium_uncased) Models Hub Page : https://nlp.johnsnowlabs.com/2021/05/25/sbertresolve_icd10cm_slim_billable_hcc_med_en.html Example: ‘bladder cancer’ sbiobertresolve_icd10cm_augmented_billable_hcc chunks code all_codes resolutions all_distances 100x Loop(sec) bladder cancer C679 [C679, Z126, D090, D494, C7911] [bladder cancer, suspected bladder cancer, cancer in situ of urinary bladder, tumor of bladder neck, malignant tumour of bladder neck] [0.0000, 0.0904, 0.0978, 0.1080, 0.1281] 26,9 ` sbiobertresolve_icd10cm_slim_billable_hcc` chunks code all_codes resolutions all_distances 100x Loop(sec) bladder cancer D090 [D090, D494, C7911, C680, C679] [cancer in situ of urinary bladder [Carcinoma in situ of bladder], tumor of bladder neck [Neoplasm of unspecified behavior of bladder], malignant tumour of bladder neck [Secondary malignant neoplasm of bladder], carcinoma of urethra [Malignant neoplasm of urethra], malignant tumor of urinary bladder [Malignant neoplasm of bladder, unspecified]] [0.0978, 0.1080, 0.1281, 0.1314, 0.1284] 20,9 sbertresolve_icd10cm_slim_billable_hcc_med chunks code all_codes resolutions all_distances 100x Loop(sec) bladder cancer C671 [C671, C679, C61, C672, C673] [bladder cancer, dome [Malignant neoplasm of dome of bladder], cancer of the urinary bladder [Malignant neoplasm of bladder, unspecified], prostate cancer [Malignant neoplasm of prostate], cancer of the urinary bladder] [0.0894, 0.1051, 0.1184, 0.1180, 0.1200] 12,8 New Deidentification NER Models We trained four new NER models to find PHI data (protected health information) that may need to be deidentified. ner_deid_generic_augmented and ner_deid_subentity_augmented models are trained with a combination of 2014 i2b2 Deid dataset and in-house annotations as well as some augmented version of them. Compared to the same test set coming from 2014 i2b2 Deid dataset, we achieved a better accuracy and generalisation on some entity labels as summarised in the following tables. We also trained the same models with glove_100d embeddings to get more memory friendly versions. ner_deid_generic_augmented : Detects PHI 7 entities (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID). Models Hub Page : https://nlp.johnsnowlabs.com/2021/06/01/ner_deid_generic_augmented_en.html entity ner_deid_large (v3.0.3 and before) ner_deid_generic_augmented (v3.1.0) CONTACT 0.8695 0.9592 NAME 0.9452 0.9648 DATE 0.9778 0.9855 LOCATION 0.8755 0.923 ner_deid_subentity_augmented: Detects PHI 23 entities (MEDICALRECORD, ORGANIZATION, DOCTOR, USERNAME, PROFESSION, HEALTHPLAN, URL, CITY, DATE, LOCATION-OTHER, STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL, EMAIL, IDNUM, SREET, BIOID, FAX, AGE) Models Hub Page : https://nlp.johnsnowlabs.com/2021/09/03/ner_deid_subentity_augmented_en.html entity ner_deid_enriched (v3.0.3 and before) ner_deid_subentity_augmented (v3.1.0) HOSPITAL 0.8519 0.8983 DATE 0.9766 0.9854 CITY 0.7493 0.8075 STREET 0.8902 0.9772 ZIP 0.8 0.9504 PHONE 0.8615 0.9502 DOCTOR 0.9191 0.9347 AGE 0.9416 0.9469 ner_deid_generic_glove: Small version of ner_deid_generic_augmented and detects 7 entities. ner_deid_subentity_glove: Small version of ner_deid_subentity_augmented and detects 23 entities. Example: Scala ... val deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) ... val nlpPipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, deid_ner, ner_converter)) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) val result = pipeline.fit(Seq.empty[&quot;A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 -year-old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227.&quot;].toDS.toDF(&quot;text&quot;)).transform(data) Python ... deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, deid_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame(pd.DataFrame({&quot;text&quot;: [&quot;&quot;&quot;A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 -year-old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227.&quot;&quot;&quot;]}))) Results: +--+-+ |chunk |ner_label | +--+-+ |2093-01-13 |DATE | |David Hale |DOCTOR | |Hendrickson, Ora |PATIENT | |7194334 |MEDICALRECORD| |01/13/93 |DATE | |Oliveira |DOCTOR | |25-year-old |AGE | |1-11-2000 |DATE | |Cocke County Baptist Hospital|HOSPITAL | |0295 Keats Street. |STREET | |(302) 786-5227 |PHONE | |Brothers Coal-Mine |ORGANIZATION | +--+-+ New column returned in DeidentificationModel DeidentificationModel now can return a new column to save the mappings between the mask/obfuscated entities and original entities. This column is optional and you can set it up with the .setReturnEntityMappings(True) method. The default value is False. Also, the name for the column can be changed using the following method; .setMappingsColumn(&quot;newAlternativeName&quot;) The new column will produce annotations with the following structure, Annotation( type: chunk, begin: 17, end: 25, result: 47, metadata:{ originalChunk -&gt; 01/13/93 //Original text of the chunk chunk -&gt; 0 // The number of the chunk in the sentence beginOriginalChunk -&gt; 95 // Start index of the original chunk endOriginalChunk -&gt; 102 // End index of the original chunk entity -&gt; AGE // Entity of the chunk sentence -&gt; 2 // Number of the sentence } ) New Reidentification feature With the new ReidetificationModel, the user can go back to the original sentences using the mappings columns and the deidentification sentences. Example: Scala val redeidentification = new ReIdentification() .setInputCols(Array(&quot;mappings&quot;, &quot;deid_chunks&quot;)) .setOutputCol(&quot;original&quot;) Python reDeidentification = ReIdentification() .setInputCols([&quot;mappings&quot;,&quot;deid_chunks&quot;]) .setOutputCol(&quot;original&quot;) New Deidentification Pretrained Pipelines We developed a clinical_deidentification pretrained pipeline that can be used to deidentify PHI information from medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate AGE, CONTACT, DATE, ID, LOCATION, NAME, PROFESSION, CITY, COUNTRY, DOCTOR, HOSPITAL, IDNUM, MEDICALRECORD, ORGANIZATION, PATIENT, PHONE, PROFESSION, STREET, USERNAME, ZIP, ACCOUNT, LICENSE, VIN, SSN, DLN, PLATE, IPADDR entities. Models Hub Page : clinical_deidentification There is also a lightweight version of the same pipeline trained with memory efficient glove_100dembeddings. Here are the model names: clinical_deidentification clinical_deidentification_glove Example: Python: from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;en&quot;, &quot;clinical/models&quot;) deid_pipeline.annotate(&quot;Record date : 2093-01-13, David Hale, M.D. IP: 203.120.223.13. The driver&#39;s license no:A334455B. the SSN:324598674 and e-mail: hale@gmail.com. Name : Hendrickson, Ora MR. # 719435 Date : 01/13/93. PCP : Oliveira, 25 years-old. Record date : 2079-11-09, Patient&#39;s VIN : 1HGBH41JXMN109286.&quot;) Scala: import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline val deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;,&quot;en&quot;,&quot;clinical/models&quot;) val result = deid_pipeline.annotate(&quot;Record date : 2093-01-13, David Hale, M.D. IP: 203.120.223.13. The driver&#39;s license no:A334455B. the SSN:324598674 and e-mail: hale@gmail.com. Name : Hendrickson, Ora MR. # 719435 Date : 01/13/93. PCP : Oliveira, 25 years-old. Record date : 2079-11-09, Patient&#39;s VIN : 1HGBH41JXMN109286.&quot;) Result: {&#39;sentence&#39;: [&#39;Record date : 2093-01-13, David Hale, M.D.&#39;, &#39;IP: 203.120.223.13.&#39;, &#39;The driver&#39;s license no:A334455B.&#39;, &#39;the SSN:324598674 and e-mail: hale@gmail.com.&#39;, &#39;Name : Hendrickson, Ora MR. # 719435 Date : 01/13/93.&#39;, &#39;PCP : Oliveira, 25 years-old.&#39;, &#39;Record date : 2079-11-09, Patient&#39;s VIN : 1HGBH41JXMN109286.&#39;], &#39;masked&#39;: [&#39;Record date : &lt;DATE&gt;, &lt;DOCTOR&gt;, M.D.&#39;, &#39;IP: &lt;IPADDR&gt;.&#39;, &#39;The driver&#39;s license &lt;DLN&gt;.&#39;, &#39;the &lt;SSN&gt; and e-mail: &lt;EMAIL&gt;.&#39;, &#39;Name : &lt;PATIENT&gt; MR. # &lt;MEDICALRECORD&gt; Date : &lt;DATE&gt;.&#39;, &#39;PCP : &lt;DOCTOR&gt;, &lt;AGE&gt; years-old.&#39;, &#39;Record date : &lt;DATE&gt;, Patient&#39;s VIN : &lt;VIN&gt;.&#39;], &#39;obfuscated&#39;: [&#39;Record date : 2093-01-18, Dr Alveria Eden, M.D.&#39;, &#39;IP: 001.001.001.001.&#39;, &#39;The driver&#39;s license K783518004444.&#39;, &#39;the SSN-400-50-8849 and e-mail: Merilynn@hotmail.com.&#39;, &#39;Name : Charls Danger MR. # J3366417 Date : 01-18-1974.&#39;, &#39;PCP : Dr Sina Sewer, 55 years-old.&#39;, &#39;Record date : 2079-11-23, Patient&#39;s VIN : 6ffff55gggg666777.&#39;], &#39;ner_chunk&#39;: [&#39;2093-01-13&#39;, &#39;David Hale&#39;, &#39;no:A334455B&#39;, &#39;SSN:324598674&#39;, &#39;Hendrickson, Ora&#39;, &#39;719435&#39;, &#39;01/13/93&#39;, &#39;Oliveira&#39;, &#39;25&#39;, &#39;2079-11-09&#39;, &#39;1HGBH41JXMN109286&#39;]} Chunk filtering based on confidence We added a new annotator ChunkFiltererApproach that allows to load a csv with both entities and confidence thresholds. This annotator will produce a ChunkFilterer model. You can load the dictionary with the following property setEntitiesConfidenceResource(). An example dictionary is: TREATMENT,0.7 With that dictionary, the user can filter the chunks corresponding to treatment entities which have confidence lower than 0.7. Example: We have a ner_chunk column and sentence column with the following data: Ner_chunk |[{chunk, 141, 163, the genomicorganization, {entity -&gt; TREATMENT, sentence -&gt; 0, chunk -&gt; 0, confidence -&gt; 0.57785}, []}, {chunk, 209, 267, a candidate gene forType II diabetes mellitus, {entity -&gt; PROBLEM, sentence -&gt; 0, chunk -&gt; 1, confidence -&gt; 0.6614286}, []}, {chunk, 394, 408, byapproximately, {entity -&gt; TREATMENT, sentence -&gt; 1, chunk -&gt; 2, confidence -&gt; 0.7705}, []}, {chunk, 478, 508, single nucleotide polymorphisms, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 3, confidence -&gt; 0.7204666}, []}, {chunk, 559, 581, aVal366Ala substitution, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 4, confidence -&gt; 0.61505}, []}, {chunk, 588, 601, an 8 base-pair, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 5, confidence -&gt; 0.29226667}, []}, {chunk, 608, 625, insertion/deletion, {entity -&gt; PROBLEM, sentence -&gt; 3, chunk -&gt; 6, confidence -&gt; 0.9841}, []}]| +- Sentence [{document, 0, 298, The human KCNJ9 (Kir 3.3, GIRK3) is a member of the G-protein-activated inwardly rectifying potassium (GIRK) channel family.Here we describe the genomicorganization of the KCNJ9 locus on chromosome 1q21-23 as a candidate gene forType II diabetes mellitus in the Pima Indian population., {sentence -&gt; 0}, []}, {document, 300, 460, The gene spansapproximately 7.6 kb and contains one noncoding and two coding exons ,separated byapproximately 2.2 and approximately 2.6 kb introns, respectively., {sentence -&gt; 1}, []}, {document, 462, 601, We identified14 single nucleotide polymorphisms (SNPs), including one that predicts aVal366Ala substitution, and an 8 base-pair, {sentence -&gt; 2}, []}, {document, 603, 626, (bp) insertion/deletion., {sentence -&gt; 3}, []}] We can filter the entities using the following annotator: chunker_filter = ChunkFiltererApproach().setInputCols(&quot;sentence&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;regex&quot;) .setRegex([&quot;.*&quot;]) .setEntitiesConfidenceResource(&quot;entities_confidence.csv&quot;) Where entities-confidence.csv has the following data: TREATMENT,0.7 PROBLEM,0.9 We can use that chunk_filter: chunker_filter.fit(data).transform(data) Producing the following entities: |[{chunk, 394, 408, byapproximately, {entity -&gt; TREATMENT, sentence -&gt; 1, chunk -&gt; 2, confidence -&gt; 0.7705}, []}, {chunk, 478, 508, single nucleotide polymorphisms, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 3, confidence -&gt; 0.7204666}, []}, {chunk, 608, 625, insertion/deletion, {entity -&gt; PROBLEM, sentence -&gt; 3, chunk -&gt; 6, confidence -&gt; 0.9841}, []}]| As you can see, only the treatment entities with confidence score of more than 0.7, and the problem entities with confidence score of more than 0.9 have been kept in the output. Extended regex dictionary fuctionallity in Deidentification The RegexPatternsDictionary can now use a regex that spawns the 2 previous token and the 2 next tokens. That feature is implemented using regex groups. Examples: Given the sentence The patient with ssn 123123123 we can use the following regex to capture the entitty ssn ( d{9}) Given the sentence The patient has 12 years we can use the following regex to capture the entitty ( d{2}) years Enhanced RelationExtractionDL Model to create and identify relations between entities across the entire document A new option has been added to RENerChunksFilter to support pairing entities from different sentences using .setDocLevelRelations(True), to pass to the Relation Extraction Model. The RelationExtractionDL Model has also been updated to process document-level relations. How to use: re_dl_chunks = RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setDocLevelRelations(True) .setMaxSyntacticDistance(7) .setOutputCol(&quot;redl_ner_chunks&quot;) Examples: Given a document containing multiple sentences: John somkes cigrettes. He also consumes alcohol., now we can generate relation pairs across sentences and relate alcohol with John . Set NER graph explicitely in MedicalNerApproach Now MedicalNerApproach can receives the path to the graph directly. When a graph location is provided through this method, previous graph search behavior is disabled. MedicalNerApproach.setGraphFile(graphFilePath) MedicalNerApproach can now accept a user-defined name for log file. Now MedicalNerApproach can accept a user-defined name for the log file. If not such a name is provided, the conventional naming will take place. MedicalNerApproach.setLogPrefix(&quot;oncology_ner&quot;) This will result in oncology_ner_20210605_141701.log filename being used, in which the 20210605_141701 is a timestamp. New Notebooks A new notebook to reproduce our peer-reviewed NER paper (https://arxiv.org/abs/2011.06315) New databricks case study notebooks. In these notebooks, we showed the examples of how to work with oncology notes dataset and OCR on databricks for both DBr and community edition versions. Updated Resolver Models We updated sbiobertresolve_snomed_findings and sbiobertresolve_cpt_procedures_augmented resolver models to reflect the latest changes in the official terminologies. Getting Started with Spark NLP for Healthcare Notebook in Databricks We prepared a new notebook for those who want to get started with Spark NLP for Healthcare in Databricks : Getting Started with Spark NLP for Healthcare Notebook Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_0"
  },
  "1416": {
    "id": "1416",
    "title": "NLP Lab Release Notes 3.1.1",
    "content": "3.1.1 Release date: 09-05-2022 We are very excited to announce the release of Annotation Lab v3.1.1 which includes Support excel import, CVE fixes and stabilization. Here are the highlights: Highlights Fix more CVEs of docker images Change ClusterRole and ClusterRolebinding to Role and Rolebinding for backup When a trained model is deployed by active learning, “active-learning” is seen in Deployedby column Fix for visibility icon used for connected words Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_1_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_1_1"
  },
  "1417": {
    "id": "1417",
    "title": "Spark NLP for Healthcare Release Notes 3.1.1",
    "content": "3.1.1 We are glad to announce that Spark NLP for Healthcare 3.1.1 has been released! Highlights MedicalNerModel new parameter includeAllConfidenceScores. MedicalNerModel new parameter inferenceBatchSize. New Resolver Models Updated Resolver Models Getting Started with Spark NLP for Healthcare Notebook in Databricks MedicalNer new parameter includeAllConfidenceScores You can now customize whether you will require confidence score for every token(both entities and non-entities) at the output of the MedicalNerModel, or just for the tokens recognized as entities. MedicalNerModel new parameter inferenceBatchSize You can now control the batch size used during inference as a separate parameter from the one you used during training of the model. This can be useful in the situation in which the hardware on which you run inference has different capacity. For example, when you have lower available memory during inference, you can reduce the batch size. New Resolver Models We trained three new sentence entity resolver models. sbertresolve_snomed_bodyStructure_med and sbiobertresolve_snomed_bodyStructure models map extracted medical (anatomical structures) entities to Snomed codes (body structure version). sbertresolve_snomed_bodyStructure_med : Trained with using sbert_jsl_medium_uncased embeddings. sbiobertresolve_snomed_bodyStructure : Trained with using sbiobert_base_cased_mli embeddings. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) jsl_sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbert_jsl_medium_uncased&#39;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_snomed_bodyStructure_med, &quot;en&quot;, &quot;clinical/models) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) snomed_pipelineModel = PipelineModel( stages = [ documentAssembler, jsl_sbert_embedder, snomed_resolver]) snomed_lp = LightPipeline(snomed_pipelineModel) result = snomed_lp.fullAnnotate(&quot;Amputation stump&quot;) Result: | | chunks | code | resolutions | all_codes | all_distances | |:|:--|:|:|:|:-| | 0 | amputation stump | 38033009 | [Amputation stump, Amputation stump of upper limb, Amputation stump of left upper limb, Amputation stump of lower limb, Amputation stump of left lower limb, Amputation stump of right upper limb, Amputation stump of right lower limb, ...]| [&#39;38033009&#39;, &#39;771359009&#39;, &#39;771364008&#39;, &#39;771358001&#39;, &#39;771367001&#39;, &#39;771365009&#39;, &#39;771368006&#39;, ...] | [&#39;0.0000&#39;, &#39;0.0773&#39;, &#39;0.0858&#39;, &#39;0.0863&#39;, &#39;0.0905&#39;, &#39;0.0911&#39;, &#39;0.0972&#39;, ...] | sbiobertresolve_icdo_augmented : This model maps extracted medical entities to ICD-O codes using sBioBert sentence embeddings. This model is augmented using the site information coming from ICD10 and synonyms coming from SNOMED vocabularies. It is trained with a dataset that is 20x larger than the previous version of ICDO resolver. Given the oncological entity found in the text (via NER models like ner_jsl), it returns top terms and resolutions along with the corresponding ICD-10 codes to present more granularity with respect to body parts mentioned. It also returns the original histological behavioral codes and descriptions in the aux metadata. Example: ... chunk2doc = Chunk2Doc().setInputCols(&quot;ner_chunk&quot;).setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) icdo_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icdo_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunk2doc, sbert_embedder, icdo_resolver]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) results = model.transform(spark.createDataFrame([[&quot;The patient is a very pleasant 61-year-old female with a strong family history of colon polyps. The patient reports her first polyps noted at the age of 50. We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma. She also has history of several malignancies in the family. Her father died of a brain tumor at the age of 81. Her sister died at the age of 65 breast cancer. She has two maternal aunts with history of lung cancer both of whom were smoker. Also a paternal grandmother who was diagnosed with leukemia at 86 and a paternal grandfather who had B-cell lymphoma.&quot;]]).toDF(&quot;text&quot;)) Result: +--+--++--+-+-+-+ | chunk|begin|end| entity| code| all_k_resolutions| all_k_codes| +--+--++--+-+-+-+ | mesothelioma| 255|266|Oncological|9971/3||C38.3|malignant mediastinal ...|9971/3||C38.3:::8854/3...| |several malignancies| 293|312|Oncological|8894/3||C39.8|overlapping malignant ...|8894/3||C39.8:::8070/2...| | brain tumor| 350|360|Oncological|9562/0||C71.9|cancer of the brain:::...|9562/0||C71.9:::9070/3...| | breast cancer| 413|425|Oncological|9691/3||C50.9|carcinoma of breast:::...|9691/3||C50.9:::8070/2...| | lung cancer| 471|481|Oncological|8814/3||C34.9|malignant tumour of lu...|8814/3||C34.9:::8550/3...| | leukemia| 560|567|Oncological|9670/3||C80.9|anemia in neoplastic d...|9670/3||C80.9:::9714/3...| | B-cell lymphoma| 610|624|Oncological|9818/3||C77.9|secondary malignant ne...|9818/3||C77.9:::9655/3...| +--+--++--+-+-+-+ Updated Resolver Models We updated sbiobertresolve_snomed_findings and sbiobertresolve_cpt_procedures_augmented resolver models to reflect the latest changes in the official terminologies. Getting Started with Spark NLP for Healthcare Notebook in Databricks We prepared a new notebook for those who want to get started with Spark NLP for Healthcare in Databricks : Getting Started with Spark NLP for Healthcare Notebook Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_1"
  },
  "1418": {
    "id": "1418",
    "title": "Spark NLP for Healthcare Release Notes 3.1.2",
    "content": "3.1.2 We are glad to announce that Spark NLP for Healthcare 3.1.2 has been released!. This release comes with new features, new models, bug fixes, and examples. Highlights Support for Fine-tuning of Ner models. More builtin(pre-defined) graphs for MedicalNerApproach. Date Normalizer. New Relation Extraction Models for ADE. Bug Fixes. Support for user-defined Custom Transformer. Java Workshop Examples. Deprecated Compatibility class in Python. Support for Fine Tuning of Ner models Users can now resume training/fine-tune existing(already trained) Spark NLP MedicalNer models on new data. Users can simply provide the path to any existing MedicalNer model and train it further on the new dataset: ner_tagger = MedicalNerApproach().setPretrainedModelPath(&quot;/path/to/trained/medicalnermodel&quot;) If the new dataset contains new tags/labels/entities, users can choose to override existing tags with the new ones. The default behaviour is to reset the list of existing tags and generate a new list from the new dataset. It is also possible to preserve the existing tags by setting the ‘overrideExistingTags’ parameter: ner_tagger = MedicalNerApproach() .setPretrainedModelPath(&quot;/path/to/trained/medicalnermodel&quot;) .setOverrideExistingTags(False) Setting overrideExistingTags to false is intended to be used when resuming trainig on the same, or very similar dataset (i.e. with the same tags or with just a few different ones). If tags overriding is disabled, and new tags are found in the training set, then the approach will try to allocate them to unused output nodes, if any. It is also possible to override specific tags of the old model by mapping them to new tags: ner_tagger = MedicalNerApproach() .setPretrainedModelPath(&quot;/path/to/trained/medicalnermodel&quot;) .setOverrideExistingTags(False) .setTagsMapping(&quot;B-PER,B-VIP&quot;, &quot;I-PER,I-VIP&quot;) In this case, the new tags B-VIP and I-VIP will replace the already trained tags ‘B-PER’ and ‘I-PER’. Unmapped old tags will remain in use and unmapped new tags will be allocated to new outpout nodes, if any. Jupyter Notebook: [Finetuning Medical NER Model Notebook] (https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.5.Resume_MedicalNer_Model_Training.ipynb) More builtin graphs for MedicalNerApproach Seventy new TensorFlow graphs have been added to the library of available graphs which are used to train MedicalNer models. The graph with the optimal set of parameters is automatically chosen by MedicalNerApproach. DateNormalizer New annotator that normalize dates to the format YYYY/MM/DD. This annotator identifies dates in chunk annotations, and transform these dates to the format YYYY/MM/DD. Both the input and output formats for the annotator are chunk. Example: sentences = [ [&#39;08/02/2018&#39;], [&#39;11/2018&#39;], [&#39;11/01/2018&#39;], [&#39;12Mar2021&#39;], [&#39;Jan 30, 2018&#39;], [&#39;13.04.1999&#39;], [&#39;3April 2020&#39;], [&#39;next monday&#39;], [&#39;today&#39;], [&#39;next week&#39;], ] df = spark.createDataFrame(sentences).toDF(&quot;text&quot;) document_assembler = DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;document&#39;) chunksDF = document_assembler.transform(df) aa = map_annotations_col(chunksDF.select(&quot;document&quot;), lambda x: [Annotation(&#39;chunk&#39;, a.begin, a.end, a.result, a.metadata, a.embeddings) for a in x], &quot;document&quot;, &quot;chunk_date&quot;, &quot;chunk&quot;) dateNormalizer = DateNormalizer().setInputCols(&#39;chunk_date&#39;).setOutputCol(&#39;date&#39;).setAnchorDateYear(2021).setAnchorDateMonth(2).setAnchorDateDay(27) dateDf = dateNormalizer.transform(aa) dateDf.select(&quot;date.result&quot;,&quot;text&quot;).show() +--+-+ |text | date | +--+-+ |08/02/2018 |2018/08/02| |11/2018 |2018/11/DD| |11/01/2018 |2018/11/01| |12Mar2021 |2021/03/12| |Jan 30, 2018|2018/01/30| |13.04.1999 |1999/04/13| |3April 2020 |2020/04/03| |next Monday |2021/06/19| |today |2021/06/12| |next week |2021/06/19| +--+-+ New Relation Extraction Models for ADE We are releasing new Relation Extraction models for ADE (Adverse Drug Event). This model is available in both RelationExtraction and Bert based RelationExtractionDL versions, and is capabale of linking drugs with ADE mentions. Example ade_re_model = new RelationExtractionModel().pretrained(&#39;ner_ade_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunk&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setPredictionThreshold(0.5) .setRelationPairs([&#39;ade-drug&#39;, &#39;drug-ade&#39;]) pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, pos_tagger, words_embedder, ner_tagger, ner_converter, dependency_parser, re_ner_chunk_filter, re_model]) text =&quot;&quot;&quot;A 30 year old female presented with tense bullae due to excessive use of naproxin, and leg cramps relating to oxaprozin.&quot;&quot;&quot; p_model = pipeline.fit(spark.createDataFrame([[text]]).toDF(&quot;text&quot;)) result = p_model.transform(data) Results | | chunk1 | entity1 | chunk2 | entity2 | result | |:|:--|:--|:--|:-|--:| | 0 | tense bullae | ADE | naproxin | DRUG | 1 | | 1 | tense bullae | ADE | oxaprozin | DRUG | 0 | | 2 | naproxin | DRUG | leg cramps | ADE | 0 | | 3 | leg cramps | ADE | oxaprozin | DRUG | 1 | Benchmarking Model: re_ade_clinical precision recall f1-score support 0 0.85 0.89 0.87 1670 1 0.88 0.84 0.86 1673 micro avg 0.87 0.87 0.87 3343 macro avg 0.87 0.87 0.87 3343 weighted avg 0.87 0.87 0.87 3343 Model: redl_ade_biobert Relation Recall Precision F1 Support 0 0.894 0.946 0.919 1011 1 0.963 0.926 0.944 1389 Avg. 0.928 0.936 0.932 Weighted Avg. 0.934 0.934 0.933 Bug Fixes RelationExtractionDLModel had an issue(BufferOverflowException) on versions 3.1.0 and 3.1.1, which is fixed with this release. Some pretrained RelationExtractionDLModels got outdated after release 3.0.3, new updated models were created, tested and made available to be used with versions 3.0.3, and later. Some SentenceEntityResolverModels which did not work with Spark 2.4/2.3 were fixed. Support for user-defined Custom Transformer. Utility classes to define custom transformers in python are included in this release. This allows users to define functions in Python to manipulate Spark-NLP annotations. This new Transformers can be added to pipelines like any of the other models you’re already familiar with. Example how to use the custom transformer. def myFunction(annotations): # lower case the content of the annotations return [a.copy(a.result.lower()) for a in annotations] custom_transformer = CustomTransformer(f=myFunction).setInputCol(&quot;ner_chunk&quot;).setOutputCol(&quot;custom&quot;) outputDf = custom_transformer.transform(outdf).select(&quot;custom&quot;).toPandas() Java Workshop Examples Add Java examples in the workshop repository. https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/java/healthcare Deprecated Compatibility class in Python Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models and versions, especially for the users using our models locally in air-gapped networks. We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. You will not need to specify your AWS credentials from now on. This new class is now replacing the previous Compatibility class written in Python and CompatibilityBeta class written in Scala. from sparknlp_jsl.compatibility import Compatibility compatibility = Compatibility(spark) print(compatibility.findVersion(&#39;sentence_detector_dl_healthcare&#39;)) Output [{&#39;name&#39;: &#39;sentence_detector_dl_healthcare&#39;, &#39;sparkVersion&#39;: &#39;2.4&#39;, &#39;version&#39;: &#39;2.6.0&#39;, &#39;language&#39;: &#39;en&#39;, &#39;date&#39;: &#39;2020-09-13T14:44:42.565&#39;, &#39;readyToUse&#39;: &#39;true&#39;}, {&#39;name&#39;: &#39;sentence_detector_dl_healthcare&#39;, &#39;sparkVersion&#39;: &#39;2.4&#39;, &#39;version&#39;: &#39;2.7.0&#39;, &#39;language&#39;: &#39;en&#39;, &#39;date&#39;: &#39;2021-03-16T08:42:34.391&#39;, &#39;readyToUse&#39;: &#39;true&#39;}] Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_2"
  },
  "1419": {
    "id": "1419",
    "title": "Spark NLP for Healthcare Release Notes 3.1.3",
    "content": "3.1.3 We are glad to announce that Spark NLP for Healthcare 3.1.3 has been released!. This release comes with new features, new models, bug fixes, and examples. Highlights New Relation Extraction model and a Pretrained pipeline for extracting and linking ADEs New Entity Resolver model for SNOMED codes ChunkConverter Annotator BugFix: getAnchorDateMonth method in DateNormalizer. BugFix: character map in MedicalNerModel fine-tuning. New Relation Extraction model and a Pretrained pipeline for extracting and linking ADEs We are releasing a new Relation Extraction Model for ADEs. This model is trained using Bert Word embeddings (biobert_pubmed_base_cased), and is capable of linking ADEs and Drugs. Example: re_model = RelationExtractionModel() .pretrained(&quot;re_ade_biobert&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(3) #default: 0 .setPredictionThreshold(0.5) #default: 0.5 .setRelationPairs([&quot;ade-drug&quot;, &quot;drug-ade&quot;]) # Possible relation pairs. Default: All Relations. nlp_pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, words_embedder, pos_tagger, ner_tagger, ner_chunker, dependency_parser, re_model]) light_pipeline = LightPipeline(nlp_pipeline.fit(spark.createDataFrame([[&#39;&#39;]]).toDF(&quot;text&quot;))) text =&quot;&quot;&quot;Been taking Lipitor for 15 years , have experienced sever fatigue a lot!!! . Doctor moved me to voltaren 2 months ago , so far , have only experienced cramps&quot;&quot;&quot; annotations = light_pipeline.fullAnnotate(text) We also have a new pipeline comprising of all models related to ADE(Adversal Drug Event) as part of this release. This pipeline includes classification, NER, assertion and relation extraction models. Users can now use this pipeline to get classification result, ADE and Drug entities, assertion status for ADE entities, and relations between ADE and Drug entities. Example: pretrained_ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) result = pretrained_ade_pipeline.fullAnnotate(&quot;&quot;&quot;Been taking Lipitor for 15 years , have experienced sever fatigue a lot!!! . Doctor moved me to voltaren 2 months ago , so far , have only experienced cramps&quot;&quot;&quot;)[0] Results: Class: True NER_Assertion: | | chunk | entitiy | assertion | |-|-||-| | 0 | Lipitor | DRUG | - | | 1 | sever fatigue | ADE | Conditional | | 2 | voltaren | DRUG | - | | 3 | cramps | ADE | Conditional | Relations: | | chunk1 | entitiy1 | chunk2 | entity2 | relation | |-|-||-||-| | 0 | sever fatigue | ADE | Lipitor | DRUG | 1 | | 1 | cramps | ADE | Lipitor | DRUG | 0 | | 2 | sever fatigue | ADE | voltaren | DRUG | 0 | | 3 | cramps | ADE | voltaren | DRUG | 1 | New Entity Resolver model for SNOMED codes We are releasing a new SentenceEntityResolver model for SNOMED codes. This model also includes AUX SNOMED concepts and can find codes for Morph Abnormality, Procedure, Substance, Physical Object, and Body Structure entities. In the metadata, the all_k_aux_labels can be divided to get further information: ground truth, concept, and aux . In the example shared below the ground truth is Atherosclerosis, concept is Observation, and aux is Morph Abnormality. Example: snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_snomed_findings_aux_concepts&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) snomed_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, snomed_resolver]) snomed_lp = LightPipeline(snomed_pipelineModel) result = snomed_lp.fullAnnotate(&quot;atherosclerosis&quot;) Results: | | chunks | code | resolutions | all_codes | all_k_aux_labels | all_distances | |:|:-|:|:-|:|:|:| | 0 | atherosclerosis | 38716007 | [atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis artery, coronary atherosclerosis, coronary atherosclerosis, coronary atherosclerosis, coronary atherosclerosis, coronary atherosclerosis, arteriosclerosis, carotid atherosclerosis, cardiovascular arteriosclerosis, aortic atherosclerosis, aortic atherosclerosis, atherosclerotic ischemic disease] | [38716007, 155382007, 155414001, 195251000, 266318005, 194848007, 441574008, 443502000, 41702007, 266231003, 155316000, 194841001, 28960008, 300920004, 39468009, 155415000, 195252007, 129573006] | &#39;Atherosclerosis&#39;, &#39;Observation&#39;, &#39;Morph Abnormality&#39; | [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0280, 0.0451, 0.0451, 0.0451, 0.0451, 0.0451, 0.0462, 0.0477, 0.0466, 0.0490, 0.0490, 0.0485 | ChunkConverter Annotator Allows to use RegexMather chunks as NER chunks and feed the output to the downstream annotators like RE or Deidentification. document_assembler = DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;document&#39;) sentence_detector = SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) regex_matcher = RegexMatcher() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;regex&quot;) .setExternalRules(path=&quot;../src/test/resources/regex-matcher/rules.txt&quot;,delimiter=&quot;,&quot;) chunkConverter = ChunkConverter().setInputCols(&quot;regex&quot;).setOutputCol(&quot;chunk&quot;) Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_3"
  },
  "1420": {
    "id": "1420",
    "title": "NLP Lab Release Notes 3.2.0",
    "content": "3.2.0 Release date: 31-05-2022 We are very excited to announce the release of Annotation Lab v3.2.0 which includes new and exciting features such as Project cloning and Project backup, Evaluation of Pretrained Models, and Search feature in the Visual NER Project. Support for Multiple files import, ability to view statuses of Model Servers and Training Jobs, and prioritization of completions for CONLL export. Spark NLP and Spark OCR libraries were also upgraded, and some security fixes and stabilizations were also implemented. Here are the highlights: Highlights Import/export of an entire Project. All project-related items (tasks, project configuration, project members, task assignments) can be imported/exported. In addition, users can also clone an existing project. Evaluate Named Entity Models. Project Owner and/or Manager can now test and evaluate annotated tasks against the Pretrained NER models in the Training &amp; Active Learning Settings tab, configured NER models will be tested against the tasks tagged as test. Statuses of Training and Preannotation Server. A new column, status, is added to the server page that gives the status of training and preannotation servers. Also if any issues are encountered during server initialization, those are displayed on mouse-over the status value. Import Multiple Files. Project Owners or Managers can now upload multiple files at once in bulk. Prioritize Annotators For Data Export. When multiple completions are available for the same task, the CONLL export will include completions from higher priority members. Network Policies have been implemented which specify how a pod is allowed to communicate with various network “entities” over the network. The entities that are required to function in Annotation Lab were clearly identified and only traffic coming from them is now allowed. Support for airgap licenses with scope. Previously airgap licenses with scopes were missrecognized as floating licenses. Upgraded Spark NLP and Spark NLP for Health Care v3.4.1 and Spark OCR v3.12.0 Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_2_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_2_0"
  },
  "1421": {
    "id": "1421",
    "title": "Spark NLP release notes 3.2.0",
    "content": "3.2.0 Release date: 28-05-2021 Overview Multi-modal visual document understanding, built on the LayoutLM architecture. It achieves new state-of-the-art accuracy in several downstream tasks, including form understanding and receipt understanding. New Features VisualDocumentNER is a DL model for NER problem using text and layout data. Currently available pre-trained model on the SROIE dataset. Enhancements Added support SPARK_OCR_LICENSE env key for read license. Update dependencies and sync Spark versions with Spark NLP. Bugfixes Fixed an issue that some ImageReaderSpi plugins are unavailable in the fat jar. New notebooks Visual Document NER Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_2_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_2_0"
  },
  "1422": {
    "id": "1422",
    "title": "Spark NLP for Healthcare Release Notes 3.2.0",
    "content": "3.2.0 We are glad to announce that Spark NLP Healthcare 3.2.0 has been released!. Highlights New Sentence Boundary Detection Model for Healthcare text New Assertion Status Models New Sentence Entity Resolver Model Finetuning Sentence Entity Resolvers with Your Data New Clinical NER Models New CMS-HCC risk-adjustment score calculation module New Embedding generation module for entity resolution New Sentence Boundary Detection Model for Healthcare text We are releasing an updated Sentence Boundary detection model to identify complex sentences containing multiple measurements, and punctuations. This model is trained on an in-house dataset. Example: Python: ... documenter = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencerDL = SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) text = &quot;&quot;&quot;He was given boluses of MS04 with some effect.he has since been placed on a PCA . He takes 80 mg. of ativan at home ativan for anxiety, with 20 meq kcl po, 30 mmol K-phos iv and 2 gms mag so4 iv. Size: Prostate gland measures 10x1.1x 4.9 cm (LS x AP x TS). Estimated volume is 51.9 ml. and is mildly enlarged in size.Normal delineation pattern of the prostate gland is preserved. &quot;&quot;&quot; sd_model = LightPipeline(PipelineModel(stages=[documenter, sentencerDL])) result = sd_model.fullAnnotate(text) Results: | s.no | sentences | |--:|:| | 0 | He was given boluses of MS04 with some effect. | | 1 | he has since been placed on a PCA . | | 2 | He takes 80 mg. of ativan at home ativan for anxiety, | | | with 20 meq kcl po, 30 mmol K-phos iv and 2 gms mag so4 iv. | | 3 | Size: Prostate gland measures 10x1.1x 4.9 cm (LS x AP x TS). | | 4 | Estimated volume is | | | 51.9 ml. and is mildly enlarged in size. | | 5 | Normal delineation pattern of the prostate gland is preserved. | New Assertion Status Models We are releasing two new Assertion Status Models based on the BiLSTM architecture. Apart from what we released in other assertion models, an in-house annotations on a curated dataset (6K clinical notes) is used to augment the base assertion dataset (2010 i2b2/VA). assertion_jsl: This model can classify the assertions made on given medical concepts as being Present, Absent, Possible, Planned, Someoneelse, Past, Family, None, Hypotetical. assertion_jsl_large: This model can classify the assertions made on given medical concepts as being present, absent, possible, planned, someoneelse, past. assertion_dl vs assertion_jsl: chunks entities assertion_dl assertion_jsl Mesothelioma PROBLEM present Present CVA PROBLEM absent Absent cancer PROBLEM associated_with_someone_else Family her INR TEST present Planned Amiodarone TREATMENT hypothetical Hypothetical lymphadenopathy PROBLEM absent Absent stage III disease PROBLEM possible Possible IV piggyback TREATMENT conditional Past Example: Python: ... clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) nlpPipeline = Pipeline(stages=[documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, clinical_assertion]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) result = model.transform(spark.createDataFrame([[&quot;The patient is a 41-year-old and has a nonproductive cough that started last week. She has had right-sided chest pain radiating to her back with fever starting today. She has no nausea. She has a history of pericarditis and pericardectomy in May 2006 and developed cough with right-sided chest pain, and went to an urgent care center and Chest x-ray revealed right-sided pleural effusion. In family history, her father has a colon cancer history.&quot;]], [&quot;text&quot;]) Results: +-+--++-+-++ |chunk |begin|end|ner_label |sent_id|assertion| +-+--++-+-++ |nonproductive cough|35 |53 |Symptom |0 |Present | |last week |68 |76 |RelativeDate |0 |Past | |chest pain |103 |112|Symptom |1 |Present | |fever |141 |145|VS_Finding |1 |Present | |today |156 |160|RelativeDate |1 |Present | |nausea |174 |179|Symptom |2 |Absent | |pericarditis |203 |214|Disease_Syndrome_Disorder|3 |Past | |pericardectomy |220 |233|Procedure |3 |Past | |May 2006 |238 |245|Date |3 |Past | |cough |261 |265|Symptom |3 |Past | |chest pain |284 |293|Symptom |3 |Past | |Chest x-ray |334 |344|Test |3 |Past | |pleural effusion |367 |382|Disease_Syndrome_Disorder|3 |Past | |colon cancer |421 |432|Oncological |4 |Family | +-+--++-+-++ New Sentence Entity Resolver Model We are releasing sbiobertresolve_rxnorm_disposition model that maps medication entities (like drugs/ingredients) to RxNorm codes and their dispositions using sbiobert_base_cased_mli Sentence Bert Embeddings. In the result, look for the aux_label parameter in the metadata to get dispositions that were divided by |. Example: Python: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_disposition&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, rxnorm_resolver ]) rxnorm_lp = LightPipeline(pipelineModel) result = rxnorm_lp.fullAnnotate(&quot;belimumab 80 mg/ml injectable solution&quot;) Results: | | chunks | code | resolutions | all_codes | all_k_aux_labels | all_distances | |:|:--|:--|:--|:--|:--|:-| | 0 |belimumab 80 mg/ml injectable solution | 1092440 | [belimumab 80 mg/ml injectable solution, belimumab 80 mg/ml injectable solution [benlysta], ifosfamide 80 mg/ml injectable solution, belimumab 80 mg/ml [benlysta], belimumab 80 mg/ml, ...]| [1092440, 1092444, 107034, 1092442, 1092438, ...] | [Immunomodulator, Immunomodulator, Alkylating agent, Immunomodulator, Immunomodulator, ...] | [0.0000, 0.0145, 0.0479, 0.0619, 0.0636, ...] | Finetuning Sentence Entity Resolvers with Your Data Instead of starting from scratch when training a new Sentence Entity Resolver model, you can train a new model by adding your new data to the pretrained model. There’s a new method setPretrainedModelPath(path), which allows you to point the training process to an existing model, and allows you to initialize your model with the data from the pretrained model. When both the new data and the pretrained model contain the same code, you will see both of the results at the top. Here is a sample notebook : Finetuning Sentence Entity Resolver Model Notebook Example: In the example below, we changed the code of sepsis to X1234 and re-retrain the main ICD10-CM model with this new dataset. So we want to see the X1234 code as a result in the all_codes. Python: ... bertExtractor = SentenceEntityResolverApproach() .setNeighbours(50) .setThreshold(1000) .setInputCols(&quot;sentence_embeddings&quot;) .setNormalizedCol(&quot;description_normalized&quot;) # concept_name .setLabelCol(&quot;code&quot;) # concept_code .setOutputCol(&quot;recognized_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) .setCaseSensitive(False) .setUseAuxLabel(True) # if exist .setPretrainedModelPath(&quot;path_to_a_pretrained_model&quot;) new_model = bertExtractor.fit(&quot;new_dataset&quot;) new_model.save(&quot;models/new_resolver_model&quot;) # save and use later ... resolver_model = SentenceEntityResolverModel.load(&quot;models/new_resolver_model&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;output_code&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, sentence_embedder, resolver_model]) light_model = LightPipeline(pipelineModel) light_model.fullAnnotate(&quot;sepsis&quot;) Main Model Results: chunks begin end code all_codes resolutions all_k_aux_labels all_distances sepsis 0 5 A4189 [A4189, L419, A419, A267, E771, …] [sepsis [Other specified sepsis], parapsoriasis [Parapsoriasis, unspecified], postprocedural sepsis [Sepsis, unspecified organism], erysipelothrix sepsis [Erysipelothrix sepsis], fucosidosis [Defects in glycoprotein degradation], … ] [1|1|2, 1|1|2, 1|1|2, 1|1|2, 1|1|23, …] [0.0000, 0.2079, 0.2256, 0.2359, 0.2399,…] Re-Trained Model Results: chunks begin end code all_codes resolutions all_k_aux_labels all_distances sepsis 0 5 X1234 [X1234, A4189, A419, L419, A267, …] [sepsis [Sepsis, new resolution], sepsis [Other specified sepsis], SEPSIS [Sepsis, unspecified organism], parapsoriasis [Parapsoriasis, unspecified], erysipelothrix sepsis [Erysipelothrix sepsis], … ] [1|1|74, 1|1|2, 1|1|2, 1|1|2, 1|1|2, …] [0.0000, 0.0000, 0.0000, 0.2079, 0.2359, …] New Clinical NER Models ner_jsl_slim: This model is trained based on ner_jsl model with more generalized entities. (Death_Entity, Medical_Device, Vital_Sign, Alergen, Drug, Clinical_Dept, Lifestyle, Symptom, Body_Part, Physical_Measurement, Admission_Discharge, Date_Time, Age, Birth_Entity, Header, Oncological, Substance_Quantity, Test_Result, Test, Procedure, Treatment, Disease_Syndrome_Disorder, Pregnancy_Newborn, Demographics) ner_jsl vs ner_jsl_slim: chunks ner_jsl ner_jsl_slim Description: Section_Header Header atrial fibrillation Heart_Disease Disease_Syndrome_Disorder August 24, 2007 Date Date_Time transpleural fluoroscopy Procedure Test last week RelativeDate Date_Time She Gender Demographics fever VS_Finding Vital_Sign PAST MEDICAL HISTORY: Medical_History_Header Header Pericardial window Internal_organ_or_component Body_Part FAMILY HISTORY: Family_History_Header Header CVA Cerebrovascular_Disease Disease_Syndrome_Disorder diabetes Diabetes Disease_Syndrome_Disorder married Relationship_Status Demographics alcohol Alcohol Lifestyle illicit drug Substance Lifestyle Coumadin Drug_BrandName Drug Blood pressure 123/95 Blood_Pressure Vital_Sign heart rate 83 Pulse Vital_Sign anticoagulated Drug_Ingredient Drug Example: Python: ... embeddings_clinical = WordEmbeddingsModel().pretrained(&#39;embeddings_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&#39;sentence&#39;, &#39;token&#39;]) .setOutputCol(&#39;embeddings&#39;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings_clinical, clinical_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame([[&quot;HISTORY: 30-year-old female presents for digital bilateral mammography secondary to a soft tissue lump palpated by the patient in the upper right shoulder. The patient has a family history of breast cancer within her mother at age 58. Patient denies personal history of breast cancer.&quot;]], [&quot;text&quot;])) Results: | | chunk | entity | |:|:--|:-| | 0 | HISTORY: | Header | | 1 | 30-year-old | Age | | 2 | female | Demographics | | 3 | mammography | Test | | 4 | soft tissue lump | Symptom | | 5 | shoulder | Body_Part | | 6 | breast cancer | Oncological | | 7 | her mother | Demographics | | 8 | age 58 | Age | | 9 | breast cancer | Oncological | ner_jsl_biobert : This model is the BioBert version of ner_jsl model and trained with biobert_pubmed_base_cased embeddings. ner_jsl_greedy_biobert : This model is the BioBert version of ner_jsl_greedy models and trained with biobert_pubmed_base_cased embeddings. Example: Python: ... embeddings_clinical = BertEmbeddings.pretrained(&#39;biobert_pubmed_base_cased&#39;) .setInputCols([&#39;sentence&#39;, &#39;token&#39;]) .setOutputCol(&#39;embeddings&#39;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_jsl_greedy_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings_clinical, clinical_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame([[&quot;The patient is a 21-day-old Caucasian male here for 2 days of congestion - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild problems with his breathing while feeding (but negative for any perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol. Baby also has had some decreased p.o. intake. His normal breast-feeding is down from 20 minutes q.2h. to 5 to 10 minutes secondary to his respiratory congestion. He sleeps well, but has been more tired and has been fussy over the past 2 days. The parents noticed no improvement with albuterol treatments given in the ER. His urine output has also decreased; normally he has 8 to 10 wet and 5 dirty diapers per 24 hours, now he has down to 4 wet diapers per 24 hours. Mom denies any diarrhea. His bowel movements are yellow colored and soft in nature.&quot;]], [&quot;text&quot;])) Results: | | chunk | entity | |:|:--|:--| | 0 | 21-day-old | Age | | 1 | Caucasian | Race_Ethnicity | | 2 | male | Gender | | 3 | for 2 days | Duration | | 4 | congestion | Symptom | | 5 | mom | Gender | | 6 | suctioning yellow discharge | Symptom | | 7 | nares | External_body_part_or_region | | 8 | she | Gender | | 9 | mild problems with his breathing while feeding | Symptom | | 10 | perioral cyanosis | Symptom | | 11 | retractions | Symptom | | 12 | One day ago | RelativeDate | | 13 | mom | Gender | | 14 | tactile temperature | Symptom | | 15 | Tylenol | Drug | | 16 | Baby | Age | | 17 | decreased p.o. intake | Symptom | | 18 | His | Gender | | 19 | breast-feeding | External_body_part_or_region | | 20 | q.2h | Frequency | | 21 | to 5 to 10 minutes | Duration | | 22 | his | Gender | | 23 | respiratory congestion | Symptom | | 24 | He | Gender | | 25 | tired | Symptom | | 26 | fussy | Symptom | | 27 | over the past 2 days | RelativeDate | | 28 | albuterol | Drug | | 29 | ER | Clinical_Dept | | 30 | His | Gender | | 31 | urine output has also decreased | Symptom | | 32 | he | Gender | | 33 | per 24 hours | Frequency | | 34 | he | Gender | | 35 | per 24 hours | Frequency | | 36 | Mom | Gender | | 37 | diarrhea | Symptom | | 38 | His | Gender | | 39 | bowel | Internal_organ_or_component | New CMS-HCC risk-adjustment score calculation module We are releasing a new module to calculate medical risk adjusment score by using the Centers for Medicare &amp; Medicaid Service (CMS) risk adjustment model. The main input to this model are ICD codes of the diseases. After getting ICD codes of diseases by Spark NLP Healthcare ICD resolvers, risk score can be calculated by this module in spark environment. Current supported version for the model is CMS-HCC V24. The model needs following parameters in order to calculate the risk score: ICD Codes Age Gender The eligibility segment of the patient Original reason for entitlement If the patient is in Medicaid or not If the patient is disabled or not Example: Python: sample_patients.show() Results: +-++++ |Patient_ID|ICD_codes |Age|Gender| +-++++ |101 |[E1169, I5030, I509, E852] |64 |F | |102 |[G629, D469, D6181] |77 |M | |103 |[D473, D473, D473, M069, C969]|16 |F | +-++++ Python: from sparknlp_jsl.functions import profile df = df.withColumn(&quot;hcc_profile&quot;, profile(df.ICD_codes, df.Age, df.Gender)) df = df.withColumn(&quot;hcc_profile&quot;, F.from_json(F.col(&quot;hcc_profile&quot;), schema)) df= df.withColumn(&quot;risk_score&quot;, df.hcc_profile.getItem(&quot;risk_score&quot;)) .withColumn(&quot;hcc_lst&quot;, df.hcc_profile.getItem(&quot;hcc_map&quot;)) .withColumn(&quot;parameters&quot;, df.hcc_profile.getItem(&quot;parameters&quot;)) .withColumn(&quot;details&quot;, df.hcc_profile.getItem(&quot;details&quot;)) df.select(&#39;Patient_ID&#39;, &#39;risk_score&#39;,&#39;ICD_codes&#39;, &#39;Age&#39;, &#39;Gender&#39;).show(truncate=False ) df.show(truncate=100, vertical=True) Results: +-+-++++ |Patient_ID|risk_score|ICD_codes |Age|Gender| +-+-++++ |101 |0.827 |[E1169, I5030, I509, E852] |64 |F | |102 |1.845 |[G629, D469, D6181] |77 |M | |103 |1.288 |[D473, D473, D473, M069, C969]|16 |F | +-+-++++ RECORD 0- Patient_ID | 101 ICD_codes | [E1169, I5030, I509, E852] Age | 64 Gender | F Eligibility_Segment | CNA OREC | 0 Medicaid | false Disabled | false hcc_profile | {{&quot;CNA_HCC18&quot;:0.302,&quot;CNA_HCC85&quot;:0.331,&quot;CNA_HCC23&quot;:0.194,&quot;CNA_D3&quot;:0.0,&quot;CNA_HCC85_gDiabetesMellit&quot;:... risk_score | 0.827 hcc_lst | {&quot;E1169&quot;:[&quot;HCC18&quot;],&quot;I5030&quot;:[&quot;HCC85&quot;],&quot;I509&quot;:[&quot;HCC85&quot;],&quot;E852&quot;:[&quot;HCC23&quot;]} parameters | {&quot;elig&quot;:&quot;CNA&quot;,&quot;age&quot;:64,&quot;sex&quot;:&quot;F&quot;,&quot;origds&quot;:&#39;0&#39;,&quot;disabled&quot;:false,&quot;medicaid&quot;:false} details | {&quot;CNA_HCC18&quot;:0.302,&quot;CNA_HCC85&quot;:0.331,&quot;CNA_HCC23&quot;:0.194,&quot;CNA_D3&quot;:0.0,&quot;CNA_HCC85_gDiabetesMellit&quot;:0.0} -RECORD 1- Patient_ID | 102 ICD_codes | [G629, D469, D6181] Age | 77 Gender | M Eligibility_Segment | CNA OREC | 0 Medicaid | false Disabled | false hcc_profile | {{&quot;CNA_M75_79&quot;:0.473,&quot;CNA_D1&quot;:0.0,&quot;CNA_HCC46&quot;:1.372}, [&quot;D1&quot;,&quot;HCC46&quot;], {&quot;D469&quot;:[&quot;HCC46&quot;]}, {&quot;elig&quot;... risk_score | 1.845 hcc_lst | {&quot;D469&quot;:[&quot;HCC46&quot;]} parameters | {&quot;elig&quot;:&quot;CNA&quot;,&quot;age&quot;:77,&quot;sex&quot;:&quot;M&quot;,&quot;origds&quot;:&#39;0&#39;,&quot;disabled&quot;:false,&quot;medicaid&quot;:false} details | {&quot;CNA_M75_79&quot;:0.473,&quot;CNA_D1&quot;:0.0,&quot;CNA_HCC46&quot;:1.372} -RECORD 2- Patient_ID | 103 ICD_codes | [D473, D473, D473, M069, C969] Age | 16 Gender | F Eligibility_Segment | CNA OREC | 0 Medicaid | false Disabled | false hcc_profile | {{&quot;CNA_HCC10&quot;:0.675,&quot;CNA_HCC40&quot;:0.421,&quot;CNA_HCC48&quot;:0.192,&quot;CNA_D3&quot;:0.0}, [&quot;HCC10&quot;,&quot;HCC40&quot;,&quot;HCC48&quot;,&quot;... risk_score | 1.288 hcc_lst | {&quot;D473&quot;:[&quot;HCC48&quot;],&quot;M069&quot;:[&quot;HCC40&quot;],&quot;C969&quot;:[&quot;HCC10&quot;]} parameters | {&quot;elig&quot;:&quot;CNA&quot;,&quot;age&quot;:16,&quot;sex&quot;:&quot;F&quot;,&quot;origds&quot;:&#39;0&#39;,&quot;disabled&quot;:false,&quot;medicaid&quot;:false} details | {&quot;CNA_HCC10&quot;:0.675,&quot;CNA_HCC40&quot;:0.421,&quot;CNA_HCC48&quot;:0.192,&quot;CNA_D3&quot;:0.0} Here is a sample notebook : Calculating Medicare Risk Adjustment Score New Embedding generation module for entity resolution We are releasing a new annotator BertSentenceChunkEmbeddings to let users aggregate sentence embeddings and ner chunk embeddings to get more specific and accurate resolution codes. It works by averaging context and chunk embeddings to get contextual information. This is specially helpful when ner chunks do not have additional information (like body parts or severity) as explained in the example below. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model. The setChunkWeight parameter can be used to control the influence of surrounding context. Example below shows the comparison of old vs new approach. Sample Notebook: Improved_Entity_Resolution_with_SentenceChunkEmbeddings Example: Python: ... sentence_chunk_embeddings = BertSentenceChunkEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_chunk_embeddings&quot;) .setChunkWeight(0.5) resolver = SentenceEntityResolverModel.pretrained(&#39;sbiobertresolve_icd10cm&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence_chunk_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) text = &quot;&quot;&quot;A 20 year old female patient badly tripped while going down stairs. She complains of right leg pain. Her x-ray showed right hip fracture. Hair line fractures also seen on the left knee joint. She also suffered from trauma and slight injury on the head. OTHER CONDITIONS: She was also recently diagnosed with diabetes, which is of type 2. &quot;&quot;&quot; nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings_clinical, clinical_ner, ner_converter, sentence_chunk_embeddings, resolver]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results: | | chunk | entity | code_with_old_approach | resolutions_with_old_approach | code_with_new_approach | resolutions_with_new_approach | |:|:--|:--|:--|:--|:--|:-| | 0 | leg pain | Symptom | R1033 | Periumbilical pain | M79661 | Pain in right lower leg | | 1 | hip fracture | Injury_or_Poisoning | M84459S | Pathological fracture, hip, unspecified, sequela | M84451S | Pathological fracture, right femur, sequela | | 2 | Hair line fractures | Injury_or_Poisoning | S070XXS | Crushing injury of face, sequela | S92592P | Other fracture of left lesser toe(s), subsequent encounter for fracture with malunion | | 3 | trauma | Injury_or_Poisoning | T794XXS | Traumatic shock, sequela | S0083XS | Contusion of other part of head, sequela | | 4 | slight injury | Injury_or_Poisoning | B03 | Smallpox | S0080XD | Unspecified superficial injury of other part of head, subsequent encounter | | 5 | diabetes | Diabetes | E118 | Type 2 diabetes mellitus with unspecified complications | E1169 | Type 2 diabetes mellitus with other specified complication | To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_0"
  },
  "1423": {
    "id": "1423",
    "title": "Spark NLP for Healthcare Release Notes 3.2.1",
    "content": "3.2.1 We are glad to announce that Spark NLP Healthcare 3.2.1 has been released!. Highlights Deprecated ChunkEntityResolver. New BERT-Based NER Models HCC module added support for versions v22 and v23. Updated Notebooks for resolvers and graph builders. New TF Graph Builder. New BERT-Based NER Models We have two new BERT-based token classifier NER models. These models are the first clinical NER models that use the BertForTokenCLassification approach that was introduced in Spark NLP 3.2.0. bert_token_classifier_ner_clinical: This model is BERT-based version of ner_clinical model. This new model is 4% better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture. Metrics: precision recall f1-score support PROBLEM 0.88 0.92 0.90 30276 TEST 0.91 0.86 0.88 17237 TREATMENT 0.87 0.88 0.88 17298 O 0.97 0.97 0.97 202438 accuracy 0.95 267249 macro avg 0.91 0.91 0.91 267249 weighted avg 0.95 0.95 0.95 267249 Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter ]) p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) text = &#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . The β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day . It was determined that all SGLT2 inhibitors should be discontinued indefinitely . She had close follow-up with endocrinology post discharge .&#39; res = p_model.transform(spark.createDataFrame([[text]]).toDF(&quot;text&quot;)).collect() res[0][&#39;label&#39;] bert_token_classifier_ner_jsl: This model is BERT-based version of ner_jsl model. This new model is better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture. Metrics: precision recall f1-score support Admission_Discharge 0.84 0.97 0.90 415 Age 0.96 0.96 0.96 2434 Alcohol 0.75 0.83 0.79 145 Allergen 0.33 0.16 0.22 25 BMI 1.00 0.77 0.87 26 Birth_Entity 1.00 0.17 0.29 12 Blood_Pressure 0.86 0.88 0.87 597 Cerebrovascular_Disease 0.74 0.77 0.75 266 Clinical_Dept 0.90 0.92 0.91 2385 Communicable_Disease 0.70 0.59 0.64 85 Date 0.95 0.98 0.96 1438 Death_Entity 0.83 0.83 0.83 59 Diabetes 0.95 0.95 0.95 350 Diet 0.60 0.49 0.54 229 Direction 0.88 0.90 0.89 6187 Disease_Syndrome_Disorder 0.90 0.89 0.89 13236 Dosage 0.57 0.49 0.53 263 Drug 0.91 0.93 0.92 15926 Duration 0.82 0.85 0.83 1218 EKG_Findings 0.64 0.70 0.67 325 Employment 0.79 0.85 0.82 539 External_body_part_or_region 0.84 0.84 0.84 4805 Family_History_Header 1.00 1.00 1.00 889 Fetus_NewBorn 0.57 0.56 0.56 341 Form 0.53 0.43 0.48 81 Frequency 0.87 0.90 0.88 1718 Gender 0.98 0.98 0.98 5666 HDL 0.60 1.00 0.75 6 Heart_Disease 0.88 0.88 0.88 2295 Height 0.89 0.96 0.92 134 Hyperlipidemia 1.00 0.95 0.97 194 Hypertension 0.95 0.98 0.97 566 ImagingFindings 0.66 0.64 0.65 601 Imaging_Technique 0.62 0.67 0.64 108 Injury_or_Poisoning 0.85 0.83 0.84 1680 Internal_organ_or_component 0.90 0.91 0.90 21318 Kidney_Disease 0.89 0.89 0.89 446 LDL 0.88 0.97 0.92 37 Labour_Delivery 0.82 0.71 0.76 306 Medical_Device 0.89 0.93 0.91 12852 Medical_History_Header 0.96 0.97 0.96 1013 Modifier 0.68 0.60 0.64 1398 O2_Saturation 0.84 0.82 0.83 199 Obesity 0.96 0.98 0.97 130 Oncological 0.88 0.96 0.92 1635 Overweight 0.80 0.80 0.80 10 Oxygen_Therapy 0.91 0.92 0.92 231 Pregnancy 0.81 0.83 0.82 439 Procedure 0.91 0.91 0.91 14410 Psychological_Condition 0.81 0.81 0.81 354 Pulse 0.85 0.95 0.89 389 Race_Ethnicity 1.00 1.00 1.00 163 Relationship_Status 0.93 0.91 0.92 57 RelativeDate 0.83 0.86 0.84 1562 RelativeTime 0.74 0.79 0.77 431 Respiration 0.99 0.95 0.97 221 Route 0.68 0.69 0.69 597 Section_Header 0.97 0.98 0.98 28580 Sexually_Active_or_Sexual_Orientation 1.00 0.64 0.78 14 Smoking 0.83 0.90 0.86 225 Social_History_Header 0.95 0.99 0.97 825 Strength 0.71 0.55 0.62 227 Substance 0.85 0.81 0.83 193 Substance_Quantity 0.00 0.00 0.00 28 Symptom 0.84 0.86 0.85 23092 Temperature 0.94 0.97 0.96 410 Test 0.84 0.88 0.86 9050 Test_Result 0.84 0.84 0.84 2766 Time 0.90 0.81 0.86 140 Total_Cholesterol 0.69 0.95 0.80 73 Treatment 0.73 0.72 0.73 506 Triglycerides 0.83 0.80 0.81 30 VS_Finding 0.76 0.77 0.76 588 Vaccine 0.70 0.84 0.76 92 Vital_Signs_Header 0.95 0.98 0.97 2223 Weight 0.88 0.89 0.88 306 O 0.97 0.96 0.97 253164 accuracy 0.94 445974 macro avg 0.82 0.82 0.81 445974 weighted avg 0.94 0.94 0.94 445974 Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter ]) p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) text = &#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . The β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day . It was determined that all SGLT2 inhibitors should be discontinued indefinitely . She had close follow-up with endocrinology post discharge .&#39; res = p_model.transform(spark.createDataFrame([[text]]).toDF(&quot;text&quot;)).collect() res[0][&#39;label&#39;] HCC module added support for versions v22 and v23 Now we can use the version 22 and the version 23 for the new HCC module to calculate CMS-HCC Risk Adjustment score. Added the following parameters elig, orec and medicaid on the profiles functions. These parameters may not be stored in clinical notes, and may require to be imported from other sources. elig : The eligibility segment of the patient. Allowed values are as follows: - &quot;CFA&quot;: Community Full Benefit Dual Aged - &quot;CFD&quot;: Community Full Benefit Dual Disabled - &quot;CNA&quot;: Community NonDual Aged - &quot;CND&quot;: Community NonDual Disabled - &quot;CPA&quot;: Community Partial Benefit Dual Aged - &quot;CPD&quot;: Community Partial Benefit Dual Disabled - &quot;INS&quot;: Long Term Institutional - &quot;NE&quot;: New Enrollee - &quot;SNPNE&quot;: SNP NE orec: Original reason for entitlement code. - &quot;0&quot;: Old age and survivor&#39;s insurance - &quot;1&quot;: Disability insurance benefits - &quot;2&quot;: End-stage renal disease - &quot;3&quot;: Both DIB and ESRD medicaid: If the patient is in Medicaid or not. Required parameters should be stored in Spark dataframe. df.show(truncate=False) +++++--+-+--+ |hcc_profileV24 |icd10_code |age|gender|eligibility|orec|medicaid| +++++--+-+--+ |{&quot;hcc_lst&quot;:[...|[E1169, I5030, I509, E852] |64 |F |CFA |0 |true | |{&quot;hcc_lst&quot;:[...|[G629, D469, D6181] |77 |M |CND |1 |false | |{&quot;hcc_lst&quot;:[...|[D473, D473, D473, M069, C969]|16 |F |CPA |3 |true | +++++--+-+--+ The content of the hcc_profileV24 column is a JSON-parsable string, like in the following example, { &quot;hcc_lst&quot;: [ &quot;HCC18&quot;, &quot;HCC85_gDiabetesMellit&quot;, &quot;HCC85&quot;, &quot;HCC23&quot;, &quot;D3&quot; ], &quot;details&quot;: { &quot;CNA_HCC18&quot;: 0.302, &quot;CNA_HCC85&quot;: 0.331, &quot;CNA_HCC23&quot;: 0.194, &quot;CNA_D3&quot;: 0.0, &quot;CNA_HCC85_gDiabetesMellit&quot;: 0.0 }, &quot;hcc_map&quot;: { &quot;E1169&quot;: [ &quot;HCC18&quot; ], &quot;I5030&quot;: [ &quot;HCC85&quot; ], &quot;I509&quot;: [ &quot;HCC85&quot; ], &quot;E852&quot;: [ &quot;HCC23&quot; ] }, &quot;risk_score&quot;: 0.827, &quot;parameters&quot;: { &quot;elig&quot;: &quot;CNA&quot;, &quot;age&quot;: 56, &quot;sex&quot;: &quot;F&quot;, &quot;origds&quot;: false, &quot;disabled&quot;: false, &quot;medicaid&quot;: false } } We can import different CMS-HCC model versions as seperate functions and use them in the same program. from sparknlp_jsl.functions import profile,profileV22,profileV23 df = df.withColumn(&quot;hcc_profileV24&quot;, profile(df.icd10_code, df.age, df.gender, df.eligibility, df.orec, df.medicaid )) df.withColumn(&quot;hcc_profileV22&quot;, profileV22(df.codes, df.age, df.sex,df.elig,df.orec,df.medicaid)) df.withColumn(&quot;hcc_profileV23&quot;, profileV23(df.codes, df.age, df.sex,df.elig,df.orec,df.medicaid)) df.show(truncate=False) +-++++--+-+--+ |risk_score|icd10_code |age|gender|eligibility|orec|medicaid| +-++++--+-+--+ |0.922 |[E1169, I5030, I509, E852] |64 |F |CFA |0 |true | |3.566 |[G629, D469, D6181] |77 |M |CND |1 |false | |1.181 |[D473, D473, D473, M069, C969]|16 |F |CPA |3 |true | +-++++--+-+--+ Updated Notebooks for resolvers and graph builders We have updated the resolver notebooks on spark-nlp-workshop repo with new BertSentenceChunkEmbeddings annotator. This annotator lets users aggregate sentence embeddings and ner chunk embeddings to get more specific and accurate resolution codes. It works by averaging context and chunk embeddings to get contextual information. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model. The setChunkWeight parameter can be used to control the influence of surrounding context. Example below shows the comparison of old vs new approach. text ner_chunk entity icd10_code all_codes resolutions icd10_code_SCE all_codes_SCE resolutions_SCE Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection. a respiratory tract infection PROBLEM J988 [J988, J069, A499, J22, J209,…] [respiratory tract infection, upper respiratory tract infection, bacterial respiratory infection, acute respiratory infection, bronchial infection,…] Z870 [Z870, Z8709, J470, J988, A499,… [history of acute lower respiratory tract infection (situation), history of acute lower respiratory tract infection, bronchiectasis with acute lower respiratory infection, rti - respiratory tract infection, bacterial respiratory infection,… Here are the updated resolver notebooks: 3.Clinical_Entity_Resolvers.ipynb 24.Improved_Entity_Resolvers_in_SparkNLP_with_sBert.ipynb You can also check for more examples of this annotator: 24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb We have updated TF Graph builder notebook to show how to create TF graphs with TF2.x. Here is the updated notebook: 17.Graph_builder_for_DL_models.ipynb To see more, please check: Spark NLP Healthcare Workshop Repo New TF Graph Builder TF graph builder to create graphs and train DL models for licensed annotators (MedicalNer, Relation Extraction, Assertion and Generic Classifier) is made compatible with TF2.x. To see how to create TF Graphs, you can check here: 17.Graph_builder_for_DL_models.ipynb Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_1"
  },
  "1424": {
    "id": "1424",
    "title": "Spark NLP for Healthcare Release Notes 3.2.2",
    "content": "3.2.2 We are glad to announce that Spark NLP Healthcare 3.2.2 has been released!. Highlights New NER Model For Detecting Drugs, Posology, and Administration Cycles New Sentence Entity Resolver Models New Router Annotator To Use Multiple Resolvers Optimally In the Same Pipeline Re-Augmented Deidentification NER Model New NER Model For Detecting Drugs, Posology, and Administration Cycles We are releasing a new NER posology model ner_posology_experimental. This model is based on the original ner_posology_large model, but trained with additional clinical trials data to detect experimental drugs, experiment cycles, cycle counts, and cycles numbers. Supported Entities: Administration, Cyclenumber, Strength, Cycleday, Duration, Cyclecount, Route, Form, Frequency, Cyclelength, Drug, Dosage Example: ... word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_posology_experimental&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter]) model = nlp_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame([[&quot;Y-90 Humanized Anti-Tac: 10 mCi (if a bone marrow transplant was part of the patient&#39;s previous therapy) or 15 mCi of yttrium labeled anti-TAC; followed by calcium trisodium Inj (Ca DTPA).. n nCalcium-DTPA: Ca-DTPA will be administered intravenously on Days 1-3 to clear the radioactive agent from the body.&quot;]]).toDF(&quot;text&quot;)) Results: | | chunk | begin | end | entity | |:|:-|--:|:|:| | 0 | Y-90 Humanized Anti-Tac | 0 | 22 | Drug | | 1 | 10 mCi | 25 | 30 | Dosage | | 2 | 15 mCi | 108 | 113 | Dosage | | 3 | yttrium labeled anti-TAC | 118 | 141 | Drug | | 4 | calcium trisodium Inj | 156 | 176 | Drug | | 5 | Calcium-DTPA | 191 | 202 | Drug | | 6 | Ca-DTPA | 205 | 211 | Drug | | 7 | intravenously | 234 | 246 | Route | | 8 | Days 1-3 | 251 | 258 | Cycleday | New Sentence Entity Resolver Models We have two new sentence entity resolver models trained with using sbert_jsl_medium_uncased embeddings. sbertresolve_rxnorm_disposition : This model maps medication entities (like drugs/ingredients) to RxNorm codes and their dispositions using sbert_jsl_medium_uncased Sentence Bert Embeddings. If you look for a faster inference with just drug names (excluding dosage and strength), this version of RxNorm model would be a better alternative. In the result, look for the aux_label parameter in the metadata to get dispositions divided by |. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbert_jsl_medium_uncased&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_rxnorm_disposition&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) rxnorm_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, rxnorm_resolver]) rxnorm_lp = LightPipeline(rxnorm_pipelineModel) rxnorm_lp = LightPipeline(pipelineModel) result = rxnorm_lp.fullAnnotate(&quot;alizapride 25 mg/ml&quot;) Result: | | chunks | code | resolutions | all_codes | all_k_aux_labels | all_distances | |:|:-|:-|:|:-|:|:--| | 0 |alizapride 25 mg/ml | 330948 | [alizapride 25 mg/ml, alizapride 50 mg, alizapride 25 mg/ml oral solution, adalimumab 50 mg/ml, adalimumab 100 mg/ml [humira], adalimumab 50 mg/ml [humira], alirocumab 150 mg/ml, ...]| [330948, 330949, 249531, 358817, 1726845, 576023, 1659153, ...] | [Dopamine receptor antagonist, Dopamine receptor antagonist, Dopamine receptor antagonist, -, -, -, -, ...] | [0.0000, 0.0936, 0.1166, 0.1525, 0.1584, 0.1567, 0.1631, ...] | sbertresolve_snomed_conditions : This model maps clinical entities (domain: Conditions) to Snomed codes using sbert_jsl_medium_uncased Sentence Bert Embeddings. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbert_jsl_medium_uncased&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_snomed_conditions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) snomed_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, snomed_resolver ]) snomed_lp = LightPipeline(snomed_pipelineModel) result = snomed_lp.fullAnnotate(&quot;schizophrenia&quot;) Result: | | chunks | code | resolutions | all_codes | all_distances | |:|:--|:|:-|:|:--| | 0 | schizophrenia | 58214004 | [schizophrenia, chronic schizophrenia, borderline schizophrenia, schizophrenia, catatonic, subchronic schizophrenia, ...]| [58214004, 83746006, 274952002, 191542003, 191529003, 16990005, ...] | 0.0000, 0.0774, 0.0838, 0.0927, 0.0970, 0.0970, ...] | New Router Annotator To Use Multiple Resolvers Optimally In the Same Pipeline Normally, when we need to use more than one sentence entity resolver models in the same pipeline, we used to hit BertSentenceEmbeddings annotator more than once given the number of different resolver models in the same pipeline. Now we are introducing a solution with the help of Router annotator that could allow us to feed all the NER chunks to BertSentenceEmbeddings at once and then route the output of Sentence Embeddings to different resolver models needed. You can find an example of how to use this annotator in the updated 3.Clinical_Entity_Resolvers.ipynb Notebook Example: ... # to get PROBLEM entitis clinical_ner = MedicalNerModel().pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;clinical_ner&quot;) clinical_ner_chunk = NerConverter() .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;clinical_ner&quot;) .setOutputCol(&quot;clinical_ner_chunk&quot;) .setWhiteList([&quot;PROBLEM&quot;]) # to get DRUG entities posology_ner = MedicalNerModel().pretrained(&quot;ner_posology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;posology_ner&quot;) posology_ner_chunk = NerConverter() .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;posology_ner&quot;) .setOutputCol(&quot;posology_ner_chunk&quot;) .setWhiteList([&quot;DRUG&quot;]) # merge the chunks into a single ner_chunk chunk_merger = ChunkMergeApproach() .setInputCols(&quot;clinical_ner_chunk&quot;,&quot;posology_ner_chunk&quot;) .setOutputCol(&quot;final_ner_chunk&quot;) .setMergeOverlapping(False) # convert chunks to doc to get sentence embeddings of them chunk2doc = Chunk2Doc().setInputCols(&quot;final_ner_chunk&quot;).setOutputCol(&quot;final_chunk_doc&quot;) sbiobert_embeddings = BertSentenceEmbeddings.pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;final_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) # filter PROBLEM entity embeddings router_sentence_icd10 = Router() .setInputCols(&quot;sbert_embeddings&quot;) .setFilterFieldsElements([&quot;PROBLEM&quot;]) .setOutputCol(&quot;problem_embeddings&quot;) # filter DRUG entity embeddings router_sentence_rxnorm = Router() .setInputCols(&quot;sbert_embeddings&quot;) .setFilterFieldsElements([&quot;DRUG&quot;]) .setOutputCol(&quot;drug_embeddings&quot;) # use problem_embeddings only icd_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_slim_billable_hcc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;problem_embeddings&quot;]) .setOutputCol(&quot;icd10cm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) # use drug_embeddings only rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;drug_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, clinical_ner_chunk, posology_ner, posology_ner_chunk, chunk_merger, chunk2doc, sbiobert_embeddings, router_sentence_icd10, router_sentence_rxnorm, icd_resolver, rxnorm_resolver ]) Re-Augmented Deidentification NER Model We re-augmented ner_deid_subentity_augmented deidentification NER model improving the previous metrics by 2%. Example: ... deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, deid_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame(pd.DataFrame({&quot;text&quot;: [&quot;&quot;&quot;A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 -year-old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227.&quot;&quot;&quot;]}))) Results: +--+-+ |chunk |ner_label | +--+-+ |2093-01-13 |DATE | |David Hale |DOCTOR | |Hendrickson, Ora |PATIENT | |7194334 |MEDICALRECORD| |01/13/93 |DATE | |Oliveira |DOCTOR | |25-year-old |AGE | |1-11-2000 |DATE | |Cocke County Baptist Hospital|HOSPITAL | |0295 Keats Street. |STREET | |(302) 786-5227 |PHONE | |Brothers Coal-Mine |ORGANIZATION | +--+-+ To see more, please check: Spark NLP Healthcare Workshop Repo Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_2"
  },
  "1425": {
    "id": "1425",
    "title": "Spark NLP for Healthcare Release Notes 3.2.3",
    "content": "3.2.3 We are glad to announce that Spark NLP Healthcare 3.2.3 has been released!. Highlights New BERT-Based Deidentification NER Model New Sentence Entity Resolver Models For German Language New Spell Checker Model For Drugs Allow To Use Disambiguator Pretrained Model Allow To Use Seeds in StructuredDeidentification Added Compatibility with Tensorflow 1.15 For Graph Generation. New Setup Videos New BERT-Based Deidentification NER Model We have a new bert_token_classifier_ner_deid model that is BERT-based version of ner_deid_subentity_augmented and annotates text to find protected health information that may need to be de-identified. It can detect 23 different entities (MEDICALRECORD, ORGANIZATION, DOCTOR, USERNAME, PROFESSION, HEALTHPLAN, URL, CITY, DATE, LOCATION-OTHER, STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL, EMAIL, IDNUM, SREET, BIOID, FAX, AGE). Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_deid&quot;, &quot;en&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, tokenizer, tokenClassifier, ner_converter]) p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) text = &quot;&quot;&quot;A. Record date : 2093-01-13, David Hale, M.D. Name : Hendrickson, Ora MR. # 7194334. PCP : Oliveira, non-smoking. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227. Patient&#39;s complaints first surfaced when he started working for Brothers Coal-Mine.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [text]}))) Results: +--+-+ |chunk |ner_label | +--+-+ |2093-01-13 |DATE | |David Hale |DOCTOR | |Hendrickson, Ora |PATIENT | |7194334 |MEDICALRECORD| |Oliveira |PATIENT | |Cocke County Baptist Hospital|HOSPITAL | |0295 Keats Street |STREET | |302) 786-5227 |PHONE | |Brothers Coal-Mine |ORGANIZATION | +--+-+ New Sentence Entity Resolver Models For German Language We are releasing two new Sentence Entity Resolver Models for German language that use sent_bert_base_cased (de) embeddings. sbertresolve_icd10gm : This model maps extracted medical entities to ICD10-GM codes for the German language. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;de&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) icd10gm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_icd10gm&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;icd10gm_code&quot;) icd10gm_pipelineModel = PipelineModel( stages = [documentAssembler, sbert_embedder, icd10gm_resolver]) icd_lp = LightPipeline(icd10gm_pipelineModel) icd_lp.fullAnnotate(&quot;Dyspnoe&quot;) Results : chunk code resolutions all_codes all_distances Dyspnoe C671 Dyspnoe, Schlafapnoe, Dysphonie, Frühsyphilis, Hyperzementose, Hypertrichose, … [R06.0, G47.3, R49.0, A51, K03.4, L68, …] [0.0000, 2.5602, 3.0529, 3.3310, 3.4645, 3.7148, …] sbertresolve_snomed : This model maps extracted medical entities to SNOMED codes for the German language. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;de&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_snomed&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) snomed_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, snomed_resolver]) snomed_lp = LightPipeline(snomed_pipelineModel) snomed_lp.fullAnnotate(&quot;Bronchialkarzinom &quot;) Results : chunk code resolutions all_codes all_distances Bronchialkarzinom 22628 Bronchialkarzinom, Bronchuskarzinom, Rektumkarzinom, Klavikulakarzinom, Lippenkarzinom, Urothelkarzinom, … [22628, 111139, 18116, 107569, 18830, 22909, …] [0.0000, 0.0073, 0.0090, 0.0098, 0.0098, 0.0102, …] New Spell Checker Model For Drugs We are releasing new spellcheck_drug_norvig model that detects and corrects spelling errors of drugs in a text based on the Norvig’s approach. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) spell = NorvigSweetingModel.pretrained(&quot;spellcheck_drug_norvig&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;spell&quot;) pipeline = Pipeline( stages = [documentAssembler, tokenizer, spell]) model = pipeline.fit(spark.createDataFrame([[&#39;&#39;]]).toDF(&#39;text&#39;)) lp = LightPipeline(model) lp.annotate(&quot;You have to take Neutrcare and colfosrinum and a bit of Fluorometholne &amp; Ribotril&quot;) Results : Original text : You have to take Neutrcare and colfosrinum and a bit of fluorometholne &amp; Ribotril Corrected text : You have to take Neutracare and colforsinum and a bit of fluorometholone &amp; Rivotril Allow to use Disambiguator pretrained model. Now we can use the NerDisambiguatorModel as a pretrained model to disambiguate person entities. text = &quot;The show also had a contestant named Brad Pitt&quot; + &quot;who later defeated Christina Aguilera on the way to become Female Vocalist Champion in the 1989 edition of Star Search in the United States. &quot; data = SparkContextForTest.spark.createDataFrame([ [text]]) .toDF(&quot;text&quot;).cache() da = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sd = SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) tk = Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) emb = WordEmbeddingsModel.pretrained().setOutputCol(&quot;embs&quot;) semb = SentenceEmbeddings().setInputCols(&quot;sentence&quot;, &quot;embs&quot;).setOutputCol(&quot;sentence_embeddings&quot;) ner = NerDLModel.pretrained().setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;).setOutputCol(&quot;ner&quot;) nc = NerConverter().setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;).setOutputCol(&quot;ner_chunk&quot;).setWhiteList([&quot;PER&quot;]) NerDisambiguatorModel.pretrained().setInputCols(&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;).setOutputCol(&quot;disambiguation&quot;) pl = Pipeline().setStages([da, sd, tk, emb, semb, ner, nc, disambiguator]) data = pl.fit(data).transform(data) data.select(&quot;disambiguation&quot;).show(10, False) +-+ |disambiguation | +-+ |[[disambiguation, 65, 82, https://en.wikipedia.org/?curid=144171, https://en.wikipedia.org/?curid=6636454, [chunk -&gt; Christina Aguilera, titles -&gt; christina aguilera ::::: christina aguilar, links -&gt; https://en.wikipedia.org/?curid=144171 ::::: https://en.wikipedia.org/?curid=6636454, beginInText -&gt; 65, scores -&gt; 0.9764155197864447, 0.9727793647472524, categories -&gt; Musicians, Singers, Actors, Businesspeople, Musicians, Singers, ids -&gt; 144171, 6636454, endInText -&gt; 82], []]]| +-+ - Allow to use seeds in StructuredDeidentification Now, we can use a seed for a specific column. The seed is used to randomly select the entities used during obfuscation mode. By providing the same seed, you can replicate the same mapping multiple times. df = spark.createDataFrame([ [&quot;12&quot;, &quot;12&quot;, &quot;Juan García&quot;], [&quot;24&quot;, &quot;56&quot;, &quot;Will Smith&quot;], [&quot;56&quot;, &quot;32&quot;, &quot;Pedro Ximénez&quot;] ]).toDF(&quot;ID1&quot;, &quot;ID2&quot;, &quot;NAME&quot;) obfuscator = StructuredDeidentification(spark=spark, columns={&quot;ID1&quot;: &quot;ID&quot;, &quot;ID2&quot;: &quot;ID&quot;, &quot;NAME&quot;: &quot;PATIENT&quot;}, columnsSeed={&quot;ID1&quot;: 23, &quot;ID2&quot;: 23}, obfuscateRefSource=&quot;faker&quot;) result = obfuscator.obfuscateColumns(df) result.show(truncate=False) +-+-+-+ |ID1 |ID2 |NAME | +-+-+-+ |[D3379888]|[D3379888]|[Raina Cleaves] | |[R8448971]|[M8851891]|[Jennell Barre] | |[M8851891]|[L5448098]|[Norene Salines]| +-+-+-+ Here, you can see that as we have provided the same seed `23` for columns `ID1`, and `ID2`, the number `12` which is appears twice in the first row is mapped to the same randomly generated id `D3379888` each time. Added compatibility with Tensorflow 1.15 for graph generation Some users reported problems while using graphs generated by Tensorflow 2.x. We provide compatibility with Tensorflow 1.15 in the tf_graph_1x module, that can be used like this, from sparknlp_jsl.training import tf_graph_1x In next releases, we will provide full support for graph generation using Tensorflow 2.x. New Setup Videos Now we have videos showing how to setup Spark NLP, Spark NLP for Healthcare and Spark OCR on UBUNTU. How to Setup Spark NLP on UBUNTU How to Setup Spark NLP for HEALTHCARE on UBUNTU How to Setup Spark OCR on UBUNTU To see more, please check: Spark NLP Healthcare Workshop Repo Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_3"
  },
  "1426": {
    "id": "1426",
    "title": "NLP Lab Release Notes 3.3.0",
    "content": "3.3.0 Release date: 21-06-2022 We are very excited to announce the release of Annotation Lab v3.3.0 which includes a highly requested new feature for displaying the confidence scores for NER preannotations as well as the ability to filter preannotations by confidence. Also, benchmarking data can now be checked for some of the models on the Models Hub page. This version also includes IAA charts for Visual NER Projects, upgrades of the Spark NLP libraries and fixes for some of the identified Common Vulnerabilities and Exposures (CVEs). Below are more details on the release content. Highlights Confidence Scores for Preannotations, When running preannotations on a Text project, one extra piece of information is now present for the automatic annotations - the confidence score. This score is used to show the confidence the model has for each of the labeled chunks. It is calculated based on the benchmarking information of the model used to preannotate and on the score of each prediction. The confidence score is available when working on Named Entity Recognition, Relation, Assertion, and Classification projects and is also generated when using NER Rules. On the Labeling screen, when selecting the Prediction widget, users can see that all preannotation in the Results section now have a score assigned to them. IAA charts are now available for Visual NER Projects, IAA (Inter-Annotator Agreement) charts were available only for text-based projects. With this release, Annotation Lab supports IAA charts for Visual NER project as well. Auto-save completions, the work of annotators is automatically saved behind the scenes. This way, the user does not risk losing his/her work in case of unforeseen events and does not have to frequently hit the Save/Update button. Improvement of UX for Active Learning, information about the previously triggered Active learning is displayed along with the number of completions required for the next training. Also when the conditions that trigger active learning for a project using a healthcare model are met and all available licenses are in use, an error message appears on the Training and Active Learning page informing the user to make room for the new training server Support for BertForSequenceClassification and MedicalBertForSequenceClassification models, From this version on, support was added for BertForTokenClassification, MedicalBertForTokenClassifier, BertForSequenceClassification and MedicalBertForSequenceClassification. Upgraded Spark NLP and Spark NLP for Health Care v3.5.3 and Spark OCR v3.13.0. With this we have also updated the list of supported models into the Models Hub page. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_3_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_3_0"
  },
  "1427": {
    "id": "1427",
    "title": "Spark NLP release notes 3.3.0",
    "content": "3.3.0 Release date: 14-06-2021 Overview Table detection and recognition for scanned documents. For table detection we added ImageTableDetector. It’s based on CascadeTabNet which used Cascade mask Region-based CNN High-Resolution Network (Cascade mask R-CNN HRNet). The model was pre-trained on the COCO dataset and fine-tuned on ICDAR 2019 competitions dataset for table detection. It demonstrates state of the art results for ICDAR 2013 and TableBank. And top results for ICDAR 2019. More details please read in Table Detection &amp; Extraction in Spark OCR New Features ImageTableDetector is a DL model for detect tables on the image. ImageTableCellDetector is a transformer for detect regions of cells in the table image. ImageCellsToTextTable is a transformer for extract text from the detected cells. New notebooks Image Table Detection example Image Cell Recognition example Image Table Recognition Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_3_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_3_0"
  },
  "1428": {
    "id": "1428",
    "title": "Spark NLP for Healthcare Release Notes 3.3.0",
    "content": "3.3.0 We are glad to announce that Spark NLP Healthcare 3.3.0 has been released!. Highlights NER Finder Pretrained Pipelines to Run Run 48 different Clinical NER and 21 Different Biobert Models At Once Over the Input Text 3 New Sentence Entity Resolver Models (3-char ICD10CM, RxNorm_NDC, HCPCS) Updated UMLS Entity Resolvers (Dropping Invalid Codes) 5 New Clinical NER Models (Trained By BertForTokenClassification Approach) Radiology NER Model Trained On cheXpert Dataset New Speed Benchmarks on Databricks NerConverterInternal Fixes Simplified Setup and Recommended Use of start() Function NER Evaluation Metrics Fix New Notebooks (Including How to Use SparkNLP with Neo4J) NER Finder Pretrained Pipelines to Run Run 48 different Clinical NER and 21 Different Biobert Models At Once Over the Input Text We are releasing two new NER Pretrained Pipelines that can be used to explore all the available pretrained NER models at once. You can check NER Profiling Notebook to see how to use these pretrained pipelines. ner_profiling_clinical : When you run this pipeline over your text, you will end up with the predictions coming out of each of the 48 pretrained clinical NER models trained with embeddings_clinical. Clinical NER Model List ner_ade_clinical ner_posology_greedy ner_risk_factors jsl_ner_wip_clinical ner_human_phenotype_gene_clinical jsl_ner_wip_greedy_clinical ner_cellular ner_cancer_genetics jsl_ner_wip_modifier_clinical ner_drugs_greedy ner_deid_sd_large ner_diseases nerdl_tumour_demo ner_deid_subentity_augmented ner_jsl_enriched ner_genetic_variants ner_bionlp ner_measurements_clinical ner_diseases_large ner_radiology ner_deid_augmented ner_anatomy ner_chemprot_clinical ner_posology_experimental ner_drugs ner_deid_sd ner_posology_large ner_deid_large ner_posology ner_deidentify_dl ner_deid_enriched ner_bacterial_species ner_drugs_large ner_clinical_large jsl_rd_ner_wip_greedy_clinical ner_medmentions_coarse ner_radiology_wip_clinical ner_clinical ner_chemicals ner_deid_synthetic ner_events_clinical ner_posology_small ner_anatomy_coarse ner_human_phenotype_go_clinical ner_jsl_slim ner_jsl ner_jsl_greedy ner_events_admission_clinical ner_profiling_biobert : When you run this pipeline over your text, you will end up with the predictions coming out of each of the 21 pretrained clinical NER models trained with biobert_pubmed_base_cased. BioBert NER Model List ner_cellular_biobert ner_diseases_biobert ner_events_biobert ner_bionlp_biobert ner_jsl_greedy_biobert ner_jsl_biobert ner_anatomy_biobert ner_jsl_enriched_biobert ner_human_phenotype_go_biobert ner_deid_biobert ner_deid_enriched_biobert ner_clinical_biobert ner_anatomy_coarse_biobert ner_human_phenotype_gene_biobert ner_posology_large_biobert jsl_rd_ner_wip_greedy_biobert ner_posology_biobert jsl_ner_wip_greedy_biobert ner_chemprot_biobert ner_ade_biobert ner_risk_factors_biobert You can also check Models Hub page for more information about all these NER models and more. Example : from sparknlp.pretrained import PretrainedPipeline ner_profiling_pipeline = PretrainedPipeline(&#39;ner_profiling_biobert&#39;, &#39;en&#39;, &#39;clinical/models&#39;) result = ner_profiling_pipeline.annotate(&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .&quot;) Results : sentence : [&#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .&#39;] token : [&#39;A&#39;, &#39;28-year-old&#39;, &#39;female&#39;, &#39;with&#39;, &#39;a&#39;, &#39;history&#39;, &#39;of&#39;, &#39;gestational&#39;, &#39;diabetes&#39;, &#39;mellitus&#39;, &#39;diagnosed&#39;, &#39;eight&#39;, &#39;years&#39;, &#39;prior&#39;, &#39;to&#39;, &#39;presentation&#39;, &#39;and&#39;, &#39;subsequent&#39;, &#39;type&#39;, &#39;two&#39;, &#39;diabetes&#39;, &#39;mellitus&#39;, &#39;(&#39;, &#39;T2DM&#39;, &#39;),&#39;, &#39;one&#39;, &#39;prior&#39;, &#39;episode&#39;, &#39;of&#39;, &#39;HTG-induced&#39;, &#39;pancreatitis&#39;, &#39;three&#39;, &#39;years&#39;, &#39;prior&#39;, &#39;to&#39;, &#39;presentation&#39;, &#39;,&#39;, &#39;associated&#39;, &#39;with&#39;, &#39;an&#39;, &#39;acute&#39;, &#39;hepatitis&#39;, &#39;,&#39;, &#39;and&#39;, &#39;obesity&#39;, &#39;with&#39;, &#39;a&#39;, &#39;body&#39;, &#39;mass&#39;, &#39;index&#39;, &#39;(&#39;, &#39;BMI&#39;, &#39;)&#39;, &#39;of&#39;, &#39;33.5&#39;, &#39;kg/m2&#39;, &#39;,&#39;, &#39;presented&#39;, &#39;with&#39;, &#39;a&#39;, &#39;one-week&#39;, &#39;history&#39;, &#39;of&#39;, &#39;polyuria&#39;, &#39;,&#39;, &#39;polydipsia&#39;, &#39;,&#39;, &#39;poor&#39;, &#39;appetite&#39;, &#39;,&#39;, &#39;and&#39;, &#39;vomiting&#39;, &#39;.&#39;] ner_cellular_biobert_chunks : [] ner_diseases_biobert_chunks : [&#39;gestational diabetes mellitus&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;hepatitis&#39;, &#39;obesity&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_events_biobert_chunks : [&#39;gestational diabetes mellitus&#39;, &#39;eight years&#39;, &#39;presentation&#39;, &#39;type two diabetes mellitus ( T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;three years&#39;, &#39;presentation&#39;, &#39;an acute hepatitis&#39;, &#39;obesity&#39;, &#39;a body mass index&#39;, &#39;BMI&#39;, &#39;presented&#39;, &#39;a one-week&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_bionlp_biobert_chunks : [] ner_jsl_greedy_biobert_chunks : [&#39;28-year-old&#39;, &#39;female&#39;, &#39;gestational diabetes mellitus&#39;, &#39;eight years prior&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;three years prior&#39;, &#39;acute hepatitis&#39;, &#39;obesity&#39;, &#39;body mass index&#39;, &#39;BMI ) of 33.5 kg/m2&#39;, &#39;one-week&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_jsl_biobert_chunks : [&#39;28-year-old&#39;, &#39;female&#39;, &#39;gestational diabetes mellitus&#39;, &#39;eight years prior&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;three years prior&#39;, &#39;acute&#39;, &#39;hepatitis&#39;, &#39;obesity&#39;, &#39;body mass index&#39;, &#39;BMI ) of 33.5 kg/m2&#39;, &#39;one-week&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_anatomy_biobert_chunks : [&#39;body&#39;] ner_jsl_enriched_biobert_chunks : [&#39;28-year-old&#39;, &#39;female&#39;, &#39;gestational diabetes mellitus&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;acute&#39;, &#39;hepatitis&#39;, &#39;obesity&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_human_phenotype_go_biobert_chunks : [&#39;obesity&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;] ner_deid_biobert_chunks : [&#39;eight years&#39;, &#39;three years&#39;] ner_deid_enriched_biobert_chunks : [] ner_clinical_biobert_chunks : [&#39;gestational diabetes mellitus&#39;, &#39;subsequent type two diabetes mellitus ( T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;an acute hepatitis&#39;, &#39;obesity&#39;, &#39;a body mass index ( BMI )&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_anatomy_coarse_biobert_chunks : [&#39;body&#39;] ner_human_phenotype_gene_biobert_chunks : [&#39;obesity&#39;, &#39;mass&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;vomiting&#39;] ner_posology_large_biobert_chunks : [] jsl_rd_ner_wip_greedy_biobert_chunks : [&#39;gestational diabetes mellitus&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;acute hepatitis&#39;, &#39;obesity&#39;, &#39;body mass index&#39;, &#39;33.5&#39;, &#39;kg/m2&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_posology_biobert_chunks : [] jsl_ner_wip_greedy_biobert_chunks : [&#39;28-year-old&#39;, &#39;female&#39;, &#39;gestational diabetes mellitus&#39;, &#39;eight years prior&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;three years prior&#39;, &#39;acute hepatitis&#39;, &#39;obesity&#39;, &#39;body mass index&#39;, &#39;BMI ) of 33.5 kg/m2&#39;, &#39;one-week&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_chemprot_biobert_chunks : [] ner_ade_biobert_chunks : [&#39;pancreatitis&#39;, &#39;acute hepatitis&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_risk_factors_biobert_chunks : [&#39;diabetes mellitus&#39;, &#39;subsequent type two diabetes mellitus&#39;, &#39;obesity&#39;] 3 New Sentence Entity Resolver Models (3-char ICD10CM, RxNorm_NDC, HCPCS) sbiobertresolve_hcpcs : This model maps extracted medical entities to Healthcare Common Procedure Coding System (HCPCS) codes using sbiobert_base_cased_mli sentence embeddings. It also returns the domain information of the codes in the all_k_aux_labels parameter in the metadata of the result. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) hcpcs_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_hcpcs&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;hcpcs_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) hcpcs_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, hcpcs_resolver]) res = hcpcs_pipelineModel.transform(spark.createDataFrame([[&quot;Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, unilateral, any size, any type&quot;]]).toDF(&quot;text&quot;)) Results : ner_chunk hcpcs_code all_codes all_resolutions domain Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, unilateral, any size, any type L8001 [L8001, L8002, L8000, L8033, L8032, …] ‘Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, unilateral, any size, any type’, ‘Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, bilateral, any size, any type’, ‘Breast prosthesis, mastectomy bra, without integrated breast prosthesis form, any size, any type’, ‘Nipple prosthesis, custom fabricated, reusable, any material, any type, each’, … Device, Device, Device, Device, Device, … sbiobertresolve_icd10cm_generalised : This model maps medical entities to 3 digit ICD10CM codes (according to ICD10 code structure the first three characters represent general type of the injury or disease). Difference in results (compared with sbiobertresolve_icd10cm) can be observed in the example below. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) icd_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_generalised&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;icd_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) icd_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, icd_resolver]) res = icd_pipelineModel.transform(spark.createDataFrame([[&quot;82 - year-old male with a history of hypertension , chronic renal insufficiency , COPD , and gastritis&quot;]]).toDF(&quot;text&quot;)) Results : | | chunk | entity | code_3char | code_desc_3char | code_full | code_full_description | distance | all_k_resolutions_3char | all_k_codes_3char | |:|:-|:--|:--|:-|:-|:|-:|:|:--| | 0 | hypertension | SYMPTOM | I10 | hypertension | I150 | Renovascular hypertension | 0 | [hypertension, hypertension (high blood pressure), h/o: hypertension, ...] | [I10, I15, Z86, Z82, I11, R03, Z87, E27] | | 1 | chronic renal insufficiency | SYMPTOM | N18 | chronic renal impairment | N186 | End stage renal disease | 0.014 | [chronic renal impairment, renal insufficiency, renal failure, anaemi ...] | [N18, P96, N19, D63, N28, Z87, N17, N25, R94] | | 2 | COPD | SYMPTOM | J44 | chronic obstructive lung disease (disorder) | I2781 | Cor pulmonale (chronic) | 0.1197 | [chronic obstructive lung disease (disorder), chronic obstructive pul ...] | [J44, Z76, J81, J96, R06, I27, Z87] | | 3 | gastritis | SYMPTOM | K29 | gastritis | K5281 | Eosinophilic gastritis or gastroenteritis | 0 | gastritis:::bacterial gastritis:::parasitic gastritis | [K29, B96, K93] | sbiobertresolve_rxnorm_ndc : This model maps DRUG entities to rxnorm codes and their National Drug Codes (NDC) using sbiobert_base_cased_mli sentence embeddings. You can find all NDC codes of drugs seperated by | in the all_k_aux_labels parameter of the metadata. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) rxnorm_ndc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_ndc&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) rxnorm_ndc_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, rxnorm_ndc_resolver]) res = rxnorm_ndc_pipelineModel.transform(spark.createDataFrame([[&quot;activated charcoal 30000 mg powder for oral suspension&quot;]]).toDF(&quot;text&quot;)) Results : chunk rxnorm_code all_codes resolutions all_k_aux_labels all_distances activated charcoal 30000 mg powder for oral suspension 1440919 1440919, 808917, 1088194, 1191772, 808921,… activated charcoal 30000 MG Powder for Oral Suspension, Activated Charcoal 30000 MG Powder for Oral Suspension, wheat dextrin 3000 MG Powder for Oral Solution [Benefiber], cellulose 3000 MG Oral Powder [Unifiber], fosfomycin 3000 MG Powder for Oral Solution [Monurol] … 69784030828, 00395052791, 08679001362|86790016280|00067004490, 46017004408|68220004416, 00456430001,… 0.0000, 0.0000, 0.1128, 0.1148, 0.1201,… Updated UMLS Entity Resolvers (Dropping Invalid Codes) UMLS model sbiobertresolve_umls_findings and sbiobertresolve_umls_major_concepts were updated by dropping the invalid codes using the latest UMLS release done May 2021. 5 New Clinical NER Models (Trained By BertForTokenClassification Approach) We are releasing four new BERT-based NER models. bert_token_classifier_ner_ade : This model is BERT-Based version of ner_ade_clinical model and performs 5% better. It can detect drugs and adverse reactions of drugs in reviews, tweets, and medical texts using DRUG and ADE labels. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_ade&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, tokenizer, tokenClassifier, ner_converter]) p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;Been taking Lipitor for 15 years , have experienced severe fatigue a lot!!! . Doctor moved me to voltaren 2 months ago , so far , have only experienced cramps&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +--++ |chunk |ner_label| +--++ |Lipitor |DRUG | |severe fatigue|ADE | |voltaren |DRUG | |cramps |ADE | +--++ bert_token_classifier_ner_jsl_slim : This model is BERT-Based version of ner_jsl_slim model and 2% better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture. It can detect Death_Entity, Medical_Device, Vital_Sign, Alergen, Drug, Clinical_Dept, Lifestyle, Symptom, Body_Part, Physical_Measurement, Admission_Discharge, Date_Time, Age, Birth_Entity, Header, Oncological, Substance_Quantity, Test_Result, Test, Procedure, Treatment, Disease_Syndrome_Disorder, Pregnancy_Newborn, Demographics entities. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, sentence_detector, tokenizer, tokenClassifier, ner_converter]) p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;HISTORY: 30-year-old female presents for digital bilateral mammography secondary to a soft tissue lump palpated by the patient in the upper right shoulder. The patient has a family history of breast cancer within her mother at age 58. Patient denies personal history of breast cancer.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-++ |chunk |ner_label | +-++ |HISTORY: |Header | |30-year-old |Age | |female |Demographics| |mammography |Test | |soft tissue lump|Symptom | |shoulder |Body_Part | |breast cancer |Oncological | |her mother |Demographics| |age 58 |Age | |breast cancer |Oncological | +-++ bert_token_classifier_ner_drugs : This model is BERT-based version of ner_drugs model and detects drug chemicals. This new model is 3% better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_drugs&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter]) model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;The human KCNJ9 (Kir 3.3, GIRK3) is a member of the G-protein-activated inwardly rectifying potassium (GIRK) channel family. Here we describe the genomicorganization of the KCNJ9 locus on chromosome 1q21-23 as a candidate gene forType II diabetes mellitus in the Pima Indian population. The gene spansapproximately 7.6 kb and contains one noncoding and two coding exons separated byapproximately 2.2 and approximately 2.6 kb introns, respectively. We identified14 single nucleotide polymorphisms (SNPs), including one that predicts aVal366Ala substitution, and an 8 base-pair (bp) insertion/deletion. Ourexpression studies revealed the presence of the transcript in various humantissues including pancreas, and two major insulin-responsive tissues: fat andskeletal muscle. The characterization of the KCNJ9 gene should facilitate furtherstudies on the function of the KCNJ9 protein and allow evaluation of thepotential role of the locus in Type II diabetes.BACKGROUND: At present, it is one of the most important issues for the treatment of breast cancer to develop the standard therapy for patients previously treated with anthracyclines and taxanes. With the objective of determining the usefulnessof vinorelbine monotherapy in patients with advanced or recurrent breast cancerafter standard therapy, we evaluated the efficacy and safety of vinorelbine inpatients previously treated with anthracyclines and taxanes.&quot;&quot;&quot; result = model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +--++ |chunk |ner_label| +--++ |potassium |DrugChem | |nucleotide |DrugChem | |anthracyclines|DrugChem | |taxanes |DrugChem | |vinorelbine |DrugChem | |vinorelbine |DrugChem | |anthracyclines|DrugChem | |taxanes |DrugChem | +--++ bert_token_classifier_ner_anatomy : This model is BERT-Based version of ner_anatomy model and 3% better. It can detect Anatomical_system, Cell, Cellular_component, Developing_anatomical_structure, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism_subdivision, Organism_substance, Pathological_formation, Tissue entities. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_anatomy&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter]) pp_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;This is an 11-year-old female who comes in for two different things. 1. She was seen by the allergist. No allergies present, so she stopped her Allegra, but she is still real congested and does a lot of snorting. They do not notice a lot of snoring at night though, but she seems to be always like that. 2. On her right great toe, she has got some redness and erythema. Her skin is kind of peeling a little bit, but it has been like that for about a week and a half now. nGeneral: Well-developed female, in no acute distress, afebrile. nHEENT: Sclerae and conjunctivae clear. Extraocular muscles intact. TMs clear. Nares patent. A little bit of swelling of the turbinates on the left. Oropharynx is essentially clear. Mucous membranes are moist. nNeck: No lymphadenopathy. nChest: Clear. nAbdomen: Positive bowel sounds and soft. nDermatologic: She has got redness along her right great toe, but no bleeding or oozing. Some dryness of her skin. Her toenails themselves are very short and even on her left foot and her left great toe the toenails are very short.&quot;&quot;&quot; result = pp_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-+-+ |chunk |ner_label | +-+-+ |great toe |Multi-tissue_structure| |skin |Organ | |conjunctivae |Multi-tissue_structure| |Extraocular muscles|Multi-tissue_structure| |Nares |Multi-tissue_structure| |turbinates |Multi-tissue_structure| |Oropharynx |Multi-tissue_structure| |Mucous membranes |Tissue | |Neck |Organism_subdivision | |bowel |Organ | |great toe |Multi-tissue_structure| |skin |Organ | |toenails |Organism_subdivision | |foot |Organism_subdivision | |great toe |Multi-tissue_structure| |toenails |Organism_subdivision | +-+-+ bert_token_classifier_ner_bacteria : This model is BERT-Based version of ner_bacterial_species model and detects different types of species of bacteria in clinical texts using SPECIES label. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_bacteria&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, tokenizer, tokenClassifier, ner_converter]) p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;Based on these genetic and phenotypic properties, we propose that strain SMSP (T) represents a novel species of the genus Methanoregula, for which we propose the name Methanoregula formicica sp. nov., with the type strain SMSP (T) (= NBRC 105244 (T) = DSM 22288 (T)).&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +--++ |chunk |ner_label| +--++ |SMSP (T) |SPECIES | |Methanoregula formicica|SPECIES | |SMSP (T) |SPECIES | +--++ Radiology NER Model Trained On cheXpert Dataset Ner NER model ner_chexpert trained on Radiology Chest reports to extract anatomical sites and observation entities. The model achieves 92.8% and 77.4% micro and macro f1 scores on the cheXpert dataset. Example : ... embeddings_clinical = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_chexpert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings_clinical, clinical_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) EXAMPLE_TEXT = &quot;&quot;&quot;FINAL REPORT HISTORY : Chest tube leak , to assess for pneumothorax . FINDINGS : In comparison with study of ___ , the endotracheal tube and Swan - Ganz catheter have been removed . The left chest tube remains in place and there is no evidence of pneumothorax. Mild atelectatic changes are seen at the left base.&quot;&quot;&quot; results = model.transform(spark.createDataFrame([[EXAMPLE_TEXT]]).toDF(&quot;text&quot;)) Results : | | chunk | label | |:|:-|:--| | 0 | endotracheal tube | OBS | | 1 | Swan - Ganz catheter | OBS | | 2 | left chest | ANAT | | 3 | tube | OBS | | 4 | in place | OBS | | 5 | pneumothorax | OBS | | 6 | Mild atelectatic changes | OBS | | 7 | left base | ANAT | New Speed Benchmarks on Databricks We prepared a speed benchmark table by running a NER pipeline on various number of cluster configurations (worker number, driver node, specs etc) and also writing the results to parquet or delta formats. You can find all the details of these tries in here : Speed Benchmark Table NerConverterInternal Fixes Now NerConverterInternal can deal with tags that have some dash (-) charachter like B-GENE-N and B-GENE-Y. Simplified Setup and Recommended Use of start() Function Starting with this release, we are shipping AWS credentials inside Spark NLP Healthcare’s license. This removes the requirement of setting the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables. To use this feature, you just need to make sure that you always call the start() function at the beginning of your program, from sparknlp_jsl import start spark = start() import com.johnsnowlabs.util.start val spark = start() If for some reason you don’t want to use this mechanism, the keys will continue to be shipped separately, and the environment variables will continue to work as they did in the past. Ner Evaluation Metrics Fix Bug fixed in the NerDLMetrics package. Previously, the full_chunk option was using greedy approach to merge chunks for a strict evaluation, which has been fixed to merge chunks using IOB scheme to get accurate entities boundaries and metrics. Also, the tag option has been fixed to get metrics that align with the default NER logs. New Notebooks Clinical Relation Extraction Knowledge Graph with Neo4j Notebook NER Profiling Pretrained Pipelines Notebook New Databricks Detecting Adverse Drug Events From Conversational Texts case study notebook. To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_0"
  },
  "1429": {
    "id": "1429",
    "title": "NLP Lab Release Notes 3.3.1",
    "content": "3.3.1 Release date: 24-06-2022 We are very excited to announce the release of Annotation Lab v3.3.1 which includes updated Active Learning messages, bug fixed for importing dictionary rule, NER projects and Visual NER projects . Here are the highlights: Highlights Updated Active Learning statuses Fix for importing Visual NER task exported before v3.2.0. Fix for import of project from Windows OS Fix for import of dictionary rules Fix for show Score text is Results widget on the labeling page when the confidence score is null Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_3_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_3_1"
  },
  "1430": {
    "id": "1430",
    "title": "Spark NLP for Healthcare Release Notes 3.3.1",
    "content": "3.3.1 We are glad to announce that Spark NLP Healthcare 3.3.1 has been released!. Highlights New ChunkKeyPhraseExtraction Annotator New BERT-Based NER Models New UMLS Sentence Entity Resolver Models Updated RxNorm Entity Resolver Model (Dropping Invalid Codes) New showVersion() Method in Compatibility Class New Docker Images for Spark NLP for Healthcare and Spark OCR New and Updated Deidentification() Parameters New Python API Documentation Updated Spark NLP For Healthcare Notebooks and New Notebooks New ChunkKeyPhraseExtraction Annotator We are releasing ChunkKeyPhraseExtraction annotator that leverages Sentence BERT embeddings to select keywords and key phrases that are most similar to a document. This annotator can be fed by either the output of NER model, NGramGenerator or YAKE, and could be used to generate similarity scores for each NER chunk that is coming out of any (clinical) NER model. That is, you can now sort your clinical entities by the importance of them with respect to document or sentence that they live in. Additionally, you can also use this new annotator to grab new clinical chunks that are missed by a pretrained NER model as well as summarizing the whole document into a few important sentences or phrases. You can find more examples in ChunkKeyPhraseExtraction notebook Example : ... ngram_ner_key_phrase_extractor = ChunkKeyPhraseExtraction.pretrained(&quot;sbert_jsl_medium_uncased &quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setTopN(5) .setDivergence(0.4) .setInputCols([&quot;sentences&quot;, &quot;merged_chunks&quot;]) .setOutputCol(&quot;key_phrases&quot;) ... text = &quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection. She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly, her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were: serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27. Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia .&quot; textDF = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) ngram_ner_results = ngram_ner_pipeline.transform(textDF) Results : +--++-+-+--+ |key_phrase |source|DocumentSimilarity |MMRScore |sentence| +--++-+-+--+ |type two diabetes mellitus|NER |0.7639750686118073 |0.4583850593816694 |0 | |HTG-induced pancreatitis |ngrams|0.66933222897749 |0.10416352343367463|0 | |vomiting |ngrams|0.5824238088130589 |0.14864183399720493|0 | |history polyuria |ngrams|0.46337313737310987|0.0959500325843913 |0 | |28-year-old female |ngrams|0.31692529374916967|0.10043002919664669|0 | +--++-+-+--+ New BERT-Based NER Models We have two new BERT-Based token classifier NER models. bert_token_classifier_ner_chemicals : This model is BERT-based version of ner_chemicals model and can detect chemical compounds (CHEM) in the medical texts. Metrics : precision recall f1-score support B-CHEM 0.94 0.92 0.93 30731 I-CHEM 0.95 0.93 0.94 31270 accuracy 0.99 62001 macro avg 0.96 0.95 0.96 62001 weighted avg 0.99 0.93 0.96 62001 Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_chemicals&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... test_sentence = &quot;&quot;&quot;The results have shown that the product p - choloroaniline is not a significant factor in chlorhexidine - digluconate associated erosive cystitis. A high percentage of kanamycin - colistin and povidone - iodine irrigations were associated with erosive cystitis.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame([[test_sentence]]).toDF(&quot;text&quot;)) Results : +++ |chunk |ner_label| +++ |p - choloroaniline |CHEM | |chlorhexidine - digluconate|CHEM | |kanamycin |CHEM | |colistin |CHEM | |povidone - iodine |CHEM | +++ bert_token_classifier_ner_chemprot : This model is BERT-based version of ner_chemprot_clinical model and can detect chemical compounds and genes (CHEMICAL, GENE-Y, GENE-N) in the medical texts. Metrics : precision recall f1-score support B-CHEMICAL 0.80 0.79 0.80 8649 B-GENE-N 0.53 0.56 0.54 2752 B-GENE-Y 0.71 0.73 0.72 5490 I-CHEMICAL 0.82 0.79 0.81 1313 I-GENE-N 0.62 0.62 0.62 1993 I-GENE-Y 0.75 0.72 0.74 2420 accuracy 0.96 22617 macro avg 0.75 0.74 0.75 22617 weighted avg 0.83 0.73 0.78 22617 Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_chemprot&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... test_sentence = &quot;Keratinocyte growth factor and acidic fibroblast growth factor are mitogens for primary cultures of mammary epithelium.&quot; result = p_model.transform(spark.createDataFrame([[test_sentence]]).toDF(&quot;text&quot;)) Results : +-++ |chunk |ner_label| +-++ |Keratinocyte growth factor |GENE-Y | |acidic fibroblast growth factor|GENE-Y | +-++ New UMLS Sentence Entity Resolver Models We are releasing two new UMLS Sentence Entity Resolver models trained on 2021AB UMLS dataset and map clinical entities to UMLS CUI codes. sbiobertresolve_umls_disease_syndrome : This model is trained on the Disease or Syndrome category using sbiobert_base_cased_mli embeddings. Example : ... resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_umls_disease_syndrome&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... data = spark.createDataFrame([[&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;]]).toDF(&quot;text&quot;) results = model.fit(data).transform(data) Results : | | chunk | code | code_description | all_k_codes | all_k_codes_desc | |:|:--|:|:--|:-|:| | 0 | gestational diabetes mellitus | C0085207 | gestational diabetes mellitus | [&#39;C0085207&#39;, &#39;C0032969&#39;, &#39;C2063017&#39;, &#39;C1283034&#39;, &#39;C0271663&#39;] | [&#39;gestational diabetes mellitus&#39;, &#39;pregnancy diabetes mellitus&#39;, &#39;pregnancy complicated by diabetes mellitus&#39;, &#39;maternal diabetes mellitus&#39;, &#39;gestational diabetes mellitus, a2&#39;] | | 1 | subsequent type two diabetes mellitus | C0348921 | pre-existing type 2 diabetes mellitus | [&#39;C0348921&#39;, &#39;C1719939&#39;, &#39;C0011860&#39;, &#39;C0877302&#39;, &#39;C0271640&#39;] | [&#39;pre-existing type 2 diabetes mellitus&#39;, &#39;disorder associated with type 2 diabetes mellitus&#39;, &#39;diabetes mellitus, type 2&#39;, &#39;insulin-requiring type 2 diabetes mellitus&#39;, &#39;secondary diabetes mellitus&#39;] | | 2 | HTG-induced pancreatitis | C0376670 | alcohol-induced pancreatitis | [&#39;C0376670&#39;, &#39;C1868971&#39;, &#39;C4302243&#39;, &#39;C0267940&#39;, &#39;C2350449&#39;] | [&#39;alcohol-induced pancreatitis&#39;, &#39;toxic pancreatitis&#39;, &#39;igg4-related pancreatitis&#39;, &#39;hemorrhage pancreatitis&#39;, &#39;graft pancreatitis&#39;] | | 3 | an acute hepatitis | C0019159 | acute hepatitis | [&#39;C0019159&#39;, &#39;C0276434&#39;, &#39;C0267797&#39;, &#39;C1386146&#39;, &#39;C2063407&#39;] | [&#39;acute hepatitis a&#39;, &#39;acute hepatitis a&#39;, &#39;acute hepatitis&#39;, &#39;acute infectious hepatitis&#39;, &#39;acute hepatitis e&#39;] | | 4 | obesity | C0028754 | obesity | [&#39;C0028754&#39;, &#39;C0342940&#39;, &#39;C0342942&#39;, &#39;C0857116&#39;, &#39;C1561826&#39;] | [&#39;obesity&#39;, &#39;abdominal obesity&#39;, &#39;generalized obesity&#39;, &#39;obesity gross&#39;, &#39;overweight and obesity&#39;] | | 5 | polyuria | C0018965 | hematuria | [&#39;C0018965&#39;, &#39;C0151582&#39;, &#39;C3888890&#39;, &#39;C0268556&#39;, &#39;C2936921&#39;] | [&#39;hematuria&#39;, &#39;uricosuria&#39;, &#39;polyuria-polydipsia syndrome&#39;, &#39;saccharopinuria&#39;, &#39;saccharopinuria&#39;] | | 6 | polydipsia | C0268813 | primary polydipsia | [&#39;C0268813&#39;, &#39;C0030508&#39;, &#39;C3888890&#39;, &#39;C0393777&#39;, &#39;C0206085&#39;] | [&#39;primary polydipsia&#39;, &#39;parasomnia&#39;, &#39;polyuria-polydipsia syndrome&#39;, &#39;hypnogenic paroxysmal dystonias&#39;, &#39;periodic hypersomnias&#39;] | | 7 | poor appetite | C0003123 | lack of appetite | [&#39;C0003123&#39;, &#39;C0011168&#39;, &#39;C0162429&#39;, &#39;C1282895&#39;, &#39;C0039338&#39;] | [&#39;lack of appetite&#39;, &#39;poor swallowing&#39;, &#39;poor nutrition&#39;, &#39;neurologic unpleasant taste&#39;, &#39;taste dis&#39;] | | 8 | vomiting | C0152164 | periodic vomiting | [&#39;C0152164&#39;, &#39;C0267172&#39;, &#39;C0152517&#39;, &#39;C0011119&#39;, &#39;C0152227&#39;] | [&#39;periodic vomiting&#39;, &#39;habit vomiting&#39;, &#39;viral vomiting&#39;, &#39;choking&#39;, &#39;tearing&#39;] | sbiobertresolve_umls_clinical_drugs : This model is trained on the Clinical Drug category using sbiobert_base_cased_mli embeddings. Example : ... resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_umls_clinical_drugs&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... data = spark.createDataFrame([[&quot;&quot;&quot;She was immediately given hydrogen peroxide 30 mg to treat the infection on her leg, and has been advised Neosporin Cream for 5 days. She has a history of taking magnesium hydroxide 100mg/1ml and metformin 1000 mg.&quot;&quot;&quot;]]).toDF(&quot;text&quot;) results = model.fit(data).transform(data) Results : | | chunk | code | code_description | all_k_codes | all_k_codes_desc | |:|:|:|:|:-|:-| | 0 | hydrogen peroxide 30 mg | C1126248 | hydrogen peroxide 30 mg/ml | [&#39;C1126248&#39;, &#39;C0304655&#39;, &#39;C1605252&#39;, &#39;C0304656&#39;, &#39;C1154260&#39;] | [&#39;hydrogen peroxide 30 mg/ml&#39;, &#39;hydrogen peroxide solution 30%&#39;, &#39;hydrogen peroxide 30 mg/ml [proxacol]&#39;, &#39;hydrogen peroxide 30 mg/ml cutaneous solution&#39;, &#39;benzoyl peroxide 30 mg/ml&#39;] | | 1 | Neosporin Cream | C0132149 | neosporin cream | [&#39;C0132149&#39;, &#39;C0358174&#39;, &#39;C0357999&#39;, &#39;C0307085&#39;, &#39;C0698810&#39;] | [&#39;neosporin cream&#39;, &#39;nystan cream&#39;, &#39;nystadermal cream&#39;, &#39;nupercainal cream&#39;, &#39;nystaform cream&#39;] | | 2 | magnesium hydroxide 100mg/1ml | C1134402 | magnesium hydroxide 100 mg | [&#39;C1134402&#39;, &#39;C1126785&#39;, &#39;C4317023&#39;, &#39;C4051486&#39;, &#39;C4047137&#39;] | [&#39;magnesium hydroxide 100 mg&#39;, &#39;magnesium hydroxide 100 mg/ml&#39;, &#39;magnesium sulphate 100mg/ml injection&#39;, &#39;magnesium sulfate 100 mg&#39;, &#39;magnesium sulfate 100 mg/ml&#39;] | | 3 | metformin 1000 mg | C0987664 | metformin 1000 mg | [&#39;C0987664&#39;, &#39;C2719784&#39;, &#39;C0978482&#39;, &#39;C2719786&#39;, &#39;C4282269&#39;] | [&#39;metformin 1000 mg&#39;, &#39;metformin hydrochloride 1000 mg&#39;, &#39;metformin hcl 1000mg tab&#39;, &#39;metformin hydrochloride 1000 mg [fortamet]&#39;, &#39;metformin hcl 1000mg sa tab&#39;] | Updated RxNorm Entity Resolver Model (Dropping Invalid Codes) sbiobertresolve_rxnorm model was updated by dropping invalid codes using 02 August 2021 RxNorm dataset. New showVersion() Method in Compatibility Class We added the .showVersion() method in our Compatibility class that shows the name of the models and the version in a pretty way. compatibility = Compatibility() compatibility.showVersion(&#39;sentence_detector_dl_healthcare&#39;) After the execution you will see the following table, ++++ | Pipeline/Model | lang | version | ++++ | sentence_detector_dl_healthcare | en | 2.6.0 | | sentence_detector_dl_healthcare | en | 2.7.0 | | sentence_detector_dl_healthcare | en | 3.2.0 | ++++ New Docker Images for Spark NLP for Healthcare and Spark OCR We are releasing new Docker Images for Spark NLP for Healthcare and Spark OCR containing a jupyter environment. Users having a valid license can run the image on their local system, and connect to pre-configured jupyter instance without installing the library on their local system. Spark NLP for Healthcare Docker Image For running Spark NLP for Healthcare inside a container: Instructions: Spark NLP for Healthcare Docker Image Video Instructions: Youtube Video Spark NLP for Healthcare &amp; OCR Docker Image For users who want to run Spark OCR and then feed the output of OCR pipeline to healthcare modules to process further: Instructions: Spark NLP for Healthcare &amp; OCR Docker Image New and Updated Deidentification() Parameters New Parameter : setBlackList() : List of entities ignored for masking or obfuscation.The default values are: SSN, PASSPORT, DLN, NPI, C_CARD, IBAN, DEA. Updated Parameter : .setObfuscateRefSource() : It was set faker as default. New Python API Documentation We have new Spark NLP for Healthcare Python API Documentation . This page contains information how to use the library with Python examples. Updated Spark NLP For Healthcare Notebooks and New Notebooks New BertForTokenClassification NER Model Training with Transformers Notebook for showing how to train a BertForTokenClassification NER model with transformers and then import into Spark NLP. New ChunkKeyPhraseExtraction notebook for showing how to get chunk key phrases using ChunkKeyPhraseExtraction. Updated all Spark NLP For Healthcare Notebooks with v3.3.0 by adding the new features. To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_1"
  },
  "1431": {
    "id": "1431",
    "title": "Spark NLP for Healthcare Release Notes 3.3.2",
    "content": "3.3.2 We are glad to announce that Spark NLP Healthcare 3.3.2 has been released!. Highlights New Clinical NER Models and Spanish NER Model New BERT-Based Clinical NER Models Updated Clinical NER Model New NER Model Class Distribution Feature New RxNorm Sentence Entity Resolver Model New Spanish SNOMED Sentence Entity Resolver Model New Clinical Question vs Statement BertForSequenceClassification model New Sentence Entity Resolver Fine-Tune Features (Overwriting and Drop Code) Updated ICD10CM Entity Resolver Models Updated NER Profiling Pretrained Pipelines New ChunkSentenceSplitter Annotator Updated Spark NLP For Healthcare Notebooks and New Notebooks New Clinical NER Models (including a new Spanish one) We are releasing three new clinical NER models trained by MedicalNerApproach(). roberta_ner_diag_proc : This models leverages Spanish Roberta Biomedical Embeddings (roberta_base_biomedical) to extract two entities, Diagnosis and Procedures (DIAGNOSTICO, PROCEDIMIENTO). It’s a renewed version of ner_diag_proc_es, available here, that was trained with embeddings_scielowiki_300d embeddings instead. Example : ... embeddings = RoBertaEmbeddings.pretrained(&quot;roberta_base_biomedical&quot;, &quot;es&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner = MedicalNerModel.pretrained(&quot;roberta_ner_diag_proc&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&#39;sentence&#39;, &#39;token&#39;, &#39;ner&#39;]) .setOutputCol(&#39;ner_chunk&#39;) pipeline = Pipeline(stages = [ documentAssembler, sentenceDetector, tokenizer, embeddings, ner, ner_converter]) empty = spark.createDataFrame([[&#39;&#39;]]).toDF(&quot;text&quot;) p_model = pipeline.fit(empty) test_sentence = &#39;Mujer de 28 años con antecedentes de diabetes mellitus gestacional diagnosticada ocho años antes de la presentación y posterior diabetes mellitus tipo dos (DM2), un episodio previo de pancreatitis inducida por HTG tres años antes de la presentación, asociado con una hepatitis aguda, y obesidad con un índice de masa corporal (IMC) de 33,5 kg / m2, que se presentó con antecedentes de una semana de poliuria, polidipsia, falta de apetito y vómitos. Dos semanas antes de la presentación, fue tratada con un ciclo de cinco días de amoxicilina por una infección del tracto respiratorio. Estaba tomando metformina, glipizida y dapagliflozina para la DM2 y atorvastatina y gemfibrozil para la HTG. Había estado tomando dapagliflozina durante seis meses en el momento de la presentación. El examen físico al momento de la presentación fue significativo para la mucosa oral seca; significativamente, su examen abdominal fue benigno sin dolor a la palpación, protección o rigidez. Los hallazgos de laboratorio pertinentes al ingreso fueron: glucosa sérica 111 mg / dl, bicarbonato 18 mmol / l, anión gap 20, creatinina 0,4 mg / dl, triglicéridos 508 mg / dl, colesterol total 122 mg / dl, hemoglobina glucosilada (HbA1c) 10%. y pH venoso 7,27. La lipasa sérica fue normal a 43 U / L. Los niveles séricos de acetona no pudieron evaluarse ya que las muestras de sangre se mantuvieron hemolizadas debido a una lipemia significativa. La paciente ingresó inicialmente por cetosis por inanición, ya que refirió una ingesta oral deficiente durante los tres días Previous a la admisión. Sin embargo, la química sérica obtenida seis horas después de la presentación reveló que su glucosa era de 186 mg / dL, la brecha aniónica todavía estaba elevada a 21, el bicarbonato sérico era de 16 mmol / L, el nivel de triglicéridos alcanzó un máximo de 2050 mg / dL y la lipasa fue de 52 U / L. Se obtuvo el nivel de β-hidroxibutirato y se encontró que estaba elevado a 5,29 mmol / L; la muestra original se centrifugó y la capa de quilomicrones se eliminó antes del análisis debido a la interferencia de la turbidez causada por la lipemia nuevamente. El paciente fue tratado con un goteo de insulina para euDKA y HTG con una reducción de la brecha aniónica a 13 y triglicéridos a 1400 mg / dL, dentro de las 24 horas. Se pensó que su euDKA fue precipitada por su infección del tracto respiratorio en el contexto del uso del inhibidor de SGLT2. La paciente fue atendida por el servicio de endocrinología y fue dada de alta con 40 unidades de insulina glargina por la noche, 12 unidades de insulina lispro con las comidas y metformina 1000 mg dos veces al día. Se determinó que todos los inhibidores de SGLT2 deben suspenderse indefinidamente. Tuvo un seguimiento estrecho con endocrinología post alta.&#39; res = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +++ | text|ner_label | +++ | diabetes mellitus gestacional|DIAGNOSTICO| | diabetes mellitus tipo dos|DIAGNOSTICO| | DM2|DIAGNOSTICO| | pancreatitis inducida por HTG|DIAGNOSTICO| | hepatitis aguda|DIAGNOSTICO| | obesidad|DIAGNOSTICO| | índice de masa corporal|DIAGNOSTICO| | IMC|DIAGNOSTICO| | poliuria|DIAGNOSTICO| | polidipsia|DIAGNOSTICO| | vómitos|DIAGNOSTICO| |infección del tracto respiratorio|DIAGNOSTICO| | DM2|DIAGNOSTICO| | HTG|DIAGNOSTICO| | dolor|DIAGNOSTICO| | rigidez|DIAGNOSTICO| | cetosis|DIAGNOSTICO| |infección del tracto respiratorio|DIAGNOSTICO| ++--+ ner_covid_trials : This model is trained to extract covid-specific medical entities in clinical trials. It supports the following entities ranging from virus type to trial design: Stage, Severity, Virus, Trial_Design, Trial_Phase, N_Patients, Institution, Statistical_Indicator, Section_Header, Cell_Type, Cellular_component, Viral_components, Physiological_reaction, Biological_molecules, Admission_Discharge, Age, BMI, Cerebrovascular_Disease, Date, Death_Entity, Diabetes, Disease_Syndrome_Disorder, Dosage, Drug_Ingredient, Employment, Frequency, Gender, Heart_Disease, Hypertension, Obesity, Pulse, Race_Ethnicity, Respiration, Route, Smoking, Time, Total_Cholesterol, Treatment, VS_Finding, Vaccine . Example : ... covid_ner = MedicalNerModel.pretrained(&#39;ner_covid_trials&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = covid_model.transform(spark.createDataFrame(pd.DataFrame({&quot;text&quot;: [&quot;&quot;&quot;In December 2019 , a group of patients with the acute respiratory disease was detected in Wuhan , Hubei Province of China . A month later , a new beta-coronavirus was identified as the cause of the 2019 coronavirus infection . SARS-CoV-2 is a coronavirus that belongs to the group of β-coronaviruses of the subgenus Coronaviridae . The SARS-CoV-2 is the third known zoonotic coronavirus disease after severe acute respiratory syndrome ( SARS ) and Middle Eastern respiratory syndrome ( MERS ). The diagnosis of SARS-CoV-2 recommended by the WHO , CDC is the collection of a sample from the upper respiratory tract ( nasal and oropharyngeal exudate ) or from the lower respiratory tract such as expectoration of endotracheal aspirate and bronchioloalveolar lavage and its analysis using the test of real-time polymerase chain reaction ( qRT-PCR ).&quot;&quot;&quot;]}))) Results : | | chunk | begin | end | entity | |:|:|--:|:|:--| | 0 | December 2019 | 3 | 15 | Date | | 1 | acute respiratory disease | 48 | 72 | Disease_Syndrome_Disorder | | 2 | beta-coronavirus | 146 | 161 | Virus | | 3 | 2019 coronavirus infection | 198 | 223 | Disease_Syndrome_Disorder | | 4 | SARS-CoV-2 | 227 | 236 | Virus | | 5 | coronavirus | 243 | 253 | Virus | | 6 | β-coronaviruses | 284 | 298 | Virus | | 7 | subgenus Coronaviridae | 307 | 328 | Virus | | 8 | SARS-CoV-2 | 336 | 345 | Virus | | 9 | zoonotic coronavirus disease | 366 | 393 | Disease_Syndrome_Disorder | | 10 | severe acute respiratory syndrome | 401 | 433 | Disease_Syndrome_Disorder | | 11 | SARS | 437 | 440 | Disease_Syndrome_Disorder | | 12 | Middle Eastern respiratory syndrome | 448 | 482 | Disease_Syndrome_Disorder | | 13 | MERS | 486 | 489 | Disease_Syndrome_Disorder | | 14 | SARS-CoV-2 | 511 | 520 | Virus | | 15 | WHO | 541 | 543 | Institution | | 16 | CDC | 547 | 549 | Institution | ner_chemd_clinical : This model extract the names of chemical compounds and drugs in medical texts. The entities that can be detected are as follows : SYSTEMATIC, IDENTIFIERS, FORMULA, TRIVIAL, ABBREVIATION, FAMILY, MULTIPLE . For reference click here . Example : ... chemd_ner = MedicalNerModel.pretrained(&#39;ner_chemd&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = chemd_model.transform(spark.createDataFrame(pd.DataFrame({&quot;text&quot;: [&quot;&quot;&quot;Isolation, Structure Elucidation, and Iron-Binding Properties of Lystabactins, Siderophores Isolated from a Marine Pseudoalteromonas sp. The marine bacterium Pseudoalteromonas sp. S2B, isolated from the Gulf of Mexico after the Deepwater Horizon oil spill, was found to produce lystabactins A, B, and C (1-3), three new siderophores. The structures were elucidated through mass spectrometry, amino acid analysis, and NMR. The lystabactins are composed of serine (Ser), asparagine (Asn), two formylated/hydroxylated ornithines (FOHOrn), dihydroxy benzoic acid (Dhb), and a very unusual nonproteinogenic amino acid, 4,8-diamino-3-hydroxyoctanoic acid (LySta). The iron-binding properties of the compounds were investigated through a spectrophotometric competition.&quot;&quot;&quot;]}))) Results : +-++ |chunk |ner_label | +-++ |Lystabactins |FAMILY | |lystabactins A, B, and C |MULTIPLE | |amino acid |FAMILY | |lystabactins |FAMILY | |serine |TRIVIAL | |Ser |FORMULA | |asparagine |TRIVIAL | |Asn |FORMULA | |formylated/hydroxylated ornithines|FAMILY | |FOHOrn |FORMULA | |dihydroxy benzoic acid |SYSTEMATIC | |amino acid |FAMILY | |4,8-diamino-3-hydroxyoctanoic acid|SYSTEMATIC | |LySta |ABBREVIATION| +-++ New BERT-Based Clinical NER Models We have two new BERT-Based token classifier NER models. bert_token_classifier_ner_bionlp : This model is BERT-based version of ner_bionlp model and can detect biological and genetics terms in cancer-related texts. (Amino_acid, Anatomical_system, Cancer, Cell, Cellular_component, Developing_anatomical_Structure, Gene_or_gene_product, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism, Organism_subdivision, Simple_chemical, Tissue) Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... test_sentence = &quot;&quot;&quot;Both the erbA IRES and the erbA/myb virus constructs transformed erythroid cells after infection of bone marrow or blastoderm cultures. The erbA/myb IRES virus exhibited a 5-10-fold higher transformed colony forming efficiency than the erbA IRES virus in the blastoderm assay.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-+-+ |chunk |ner_label | +-+-+ |erbA IRES |Organism | |erbA/myb virus |Organism | |erythroid cells |Cell | |bone marrow |Multi-tissue_structure| |blastoderm cultures|Cell | |erbA/myb IRES virus|Organism | |erbA IRES virus |Organism | |blastoderm |Cell | +-+-+ bert_token_classifier_ner_cellular : This model is BERT-based version of ner_cellular model and can detect molecular biology-related terms (DNA, Cell_type, Cell_line, RNA, Protein) in medical texts. Metrics : precision recall f1-score support B-DNA 0.87 0.77 0.82 1056 B-RNA 0.85 0.79 0.82 118 B-cell_line 0.66 0.70 0.68 500 B-cell_type 0.87 0.75 0.81 1921 B-protein 0.90 0.85 0.88 5067 I-DNA 0.93 0.86 0.90 1789 I-RNA 0.92 0.84 0.88 187 I-cell_line 0.67 0.76 0.71 989 I-cell_type 0.92 0.76 0.84 2991 I-protein 0.94 0.80 0.87 4774 accuracy 0.80 19392 macro avg 0.76 0.81 0.78 19392 weighted avg 0.89 0.80 0.85 19392 Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_cellular&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... test_sentence = &quot;&quot;&quot;Detection of various other intracellular signaling proteins is also described. Genetic characterization of transactivation of the human T-cell leukemia virus type 1 promoter: Binding of Tax to Tax-responsive element 1 is mediated by the cyclic AMP-responsive members of the CREB/ATF family of transcription factors. To achieve a better understanding of the mechanism of transactivation by Tax of human T-cell leukemia virus type 1 Tax-responsive element 1 (TRE-1), we developed a genetic approach with Saccharomyces cerevisiae. We constructed a yeast reporter strain containing the lacZ gene under the control of the CYC1 promoter associated with three copies of TRE-1. Expression of either the cyclic AMP response element-binding protein (CREB) or CREB fused to the GAL4 activation domain (GAD) in this strain did not modify the expression of the reporter gene. Tax alone was also inactive.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-++ |chunk |ner_label| +-++ |intracellular signaling proteins |protein | |human T-cell leukemia virus type 1 promoter|DNA | |Tax |protein | |Tax-responsive element 1 |DNA | |cyclic AMP-responsive members |protein | |CREB/ATF family |protein | |transcription factors |protein | |Tax |protein | |human T-cell leukemia virus type 1 |DNA | |Tax-responsive element 1 |DNA | |TRE-1 |DNA | |lacZ gene |DNA | |CYC1 promoter |DNA | |TRE-1 |DNA | |cyclic AMP response element-binding protein|protein | |CREB |protein | |CREB |protein | |GAL4 activation domain |protein | |GAD |protein | |reporter gene |DNA | |Tax |protein | +-++ Updated Clinical NER Model We have updated ner_jsl_enriched model by enriching the training data using clinical trials data to make it more robust. This model is capable of predicting up to 87 different entities and is based on ner_jsl model. Here are the entities this model can detect; Social_History_Header, Oncology_Therapy, Blood_Pressure, Respiration, Performance_Status, Family_History_Header, Dosage, Clinical_Dept, Diet, Procedure, HDL, Weight, Admission_Discharge, LDL, Kidney_Disease, Oncological, Route, Imaging_Technique, Puerperium, Overweight, Temperature, Diabetes, Vaccine, Age, Test_Result, Employment, Time, Obesity, EKG_Findings, Pregnancy, Communicable_Disease, BMI, Strength, Tumor_Finding, Section_Header, RelativeDate, ImagingFindings, Death_Entity, Date, Cerebrovascular_Disease, Treatment, Labour_Delivery, Pregnancy_Delivery_Puerperium, Direction, Internal_organ_or_component, Psychological_Condition, Form, Medical_Device, Test, Symptom, Disease_Syndrome_Disorder, Staging, Birth_Entity, Hyperlipidemia, O2_Saturation, Frequency, External_body_part_or_region, Drug_Ingredient, Vital_Signs_Header, Substance_Quantity, Race_Ethnicity, VS_Finding, Injury_or_Poisoning, Medical_History_Header, Alcohol, Triglycerides, Total_Cholesterol, Sexually_Active_or_Sexual_Orientation, Female_Reproductive_Status, Relationship_Status, Drug_BrandName, RelativeTime, Duration, Hypertension, Metastasis, Gender, Oxygen_Therapy, Pulse, Heart_Disease, Modifier, Allergen, Smoking, Substance, Cancer_Modifier, Fetus_NewBorn, Height . Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_jsl_enriched&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = model.transform(spark.createDataFrame([[&quot;The patient is a 21-day-old Caucasian male here for 2 days of congestion - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild problems with his breathing while feeding (but negative for any perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol. Baby also has had some decreased p.o. intake. His normal breast-feeding is down from 20 minutes q.2h. to 5 to 10 minutes secondary to his respiratory congestion. He sleeps well, but has been more tired and has been fussy over the past 2 days. The parents noticed no improvement with albuterol treatments given in the ER. His urine output has also decreased; normally he has 8 to 10 wet and 5 dirty diapers per 24 hours, now he has down to 4 wet diapers per 24 hours. Mom denies any diarrhea. His bowel movements are yellow colored and soft in nature.&quot;]], [&quot;text&quot;])) Results : | | chunk | begin | end | entity | |:|:|--:|:|:--| | 0 | 21-day-old | 17 | 26 | Age | | 1 | Caucasian | 28 | 36 | Race_Ethnicity | | 2 | male | 38 | 41 | Gender | | 3 | 2 days | 52 | 57 | Duration | | 4 | congestion | 62 | 71 | Symptom | | 5 | mom | 75 | 77 | Gender | | 6 | suctioning yellow discharge | 88 | 114 | Symptom | | 7 | nares | 135 | 139 | External_body_part_or_region | | 8 | she | 147 | 149 | Gender | | 9 | mild | 168 | 171 | Modifier | | 10 | problems with his breathing while feeding | 173 | 213 | Symptom | | 11 | perioral cyanosis | 237 | 253 | Symptom | | 12 | retractions | 258 | 268 | Symptom | | 13 | One day ago | 272 | 282 | RelativeDate | | 14 | mom | 285 | 287 | Gender | | 15 | tactile temperature | 304 | 322 | Symptom | | 16 | Tylenol | 345 | 351 | Drug_BrandName | | 17 | Baby | 354 | 357 | Age | | 18 | decreased p.o. intake | 377 | 397 | Symptom | | 19 | His | 400 | 402 | Gender | | 20 | q.2h | 450 | 453 | Frequency | | 21 | 5 to 10 minutes | 459 | 473 | Duration | | 22 | his | 488 | 490 | Gender | | 23 | respiratory congestion | 492 | 513 | Symptom | | 24 | He | 516 | 517 | Gender | | 25 | tired | 550 | 554 | Symptom | | 26 | fussy | 569 | 573 | Symptom | | 27 | over the past 2 days | 575 | 594 | RelativeDate | | 28 | albuterol | 637 | 645 | Drug_Ingredient | | 29 | ER | 671 | 672 | Clinical_Dept | | 30 | His | 675 | 677 | Gender | | 31 | urine output has also decreased | 679 | 709 | Symptom | | 32 | he | 721 | 722 | Gender | | 33 | per 24 hours | 760 | 771 | Frequency | | 34 | he | 778 | 779 | Gender | | 35 | per 24 hours | 807 | 818 | Frequency | | 36 | Mom | 821 | 823 | Gender | | 37 | diarrhea | 836 | 843 | Symptom | | 38 | His | 846 | 848 | Gender | | 39 | bowel | 850 | 854 | Internal_organ_or_component | New NER Model Class Distribution Feature getTrainingClassDistribution : This parameter returns the distribution of labels used when training the NER model. Example: ner_model.getTrainingClassDistribution() &gt;&gt; {&#39;B-Disease&#39;: 2536, &#39;O&#39;: 31659, &#39;I-Disease&#39;: 2960} New RxNorm Sentence Entity Resolver Model sbiobertresolve_rxnorm_augmented : This model maps clinical entities and concepts (like drugs/ingredients) to RxNorm codes using sbiobert_base_cased_mli Sentence Bert Embeddings. It trained on the augmented version of the dataset which is used in previous RxNorm resolver models. Additionally, this model returns concept classes of the drugs in all_k_aux_labels column. New Spanish SNOMED Sentence Entity Resolver Model robertaresolve_snomed : This models leverages Spanish Roberta Biomedical Embeddings (roberta_base_biomedical) at sentence-level to map ner chunks into Spanish SNOMED codes. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) word_embeddings = RoBertaEmbeddings.pretrained(&quot;roberta_base_biomedical&quot;, &quot;es&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;roberta_embeddings&quot;) ner = MedicalNerModel.pretrained(&quot;roberta_ner_diag_proc&quot;,&quot;es&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;roberta_embeddings&quot;) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) c2doc = Chunk2Doc() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;ner_chunk_doc&quot;) chunk_embeddings = SentenceEmbeddings() .setInputCols([&quot;ner_chunk_doc&quot;, &quot;roberta_embeddings&quot;]) .setOutputCol(&quot;chunk_embeddings&quot;) .setPoolingStrategy(&quot;AVERAGE&quot;) er = SentenceEntityResolverModel.pretrained(&quot;robertaresolve_snomed&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;chunk_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) snomed_training_pipeline = Pipeline(stages = [ documentAssembler, sentenceDetector, tokenizer, word_embeddings, ner, ner_converter, c2doc, chunk_embeddings, er]) empty = spark.createDataFrame([[&#39;&#39;]]).toDF(&quot;text&quot;) p_model = snomed_pipeline .fit(empty) test_sentence = &#39;Mujer de 28 años con antecedentes de diabetes mellitus gestacional diagnosticada ocho años antes de la presentación y posterior diabetes mellitus tipo dos (DM2), un episodio previo de pancreatitis inducida por HTG tres años antes de la presentación, asociado con una hepatitis aguda, y obesidad con un índice de masa corporal (IMC) de 33,5 kg / m2, que se presentó con antecedentes de una semana de poliuria, polidipsia, falta de apetito y vómitos. Dos semanas antes de la presentación, fue tratada con un ciclo de cinco días de amoxicilina por una infección del tracto respiratorio. Estaba tomando metformina, glipizida y dapagliflozina para la DM2 y atorvastatina y gemfibrozil para la HTG. Había estado tomando dapagliflozina durante seis meses en el momento de la presentación. El examen físico al momento de la presentación fue significativo para la mucosa oral seca; significativamente, su examen abdominal fue benigno sin dolor a la palpación, protección o rigidez. Los hallazgos de laboratorio pertinentes al ingreso fueron: glucosa sérica 111 mg / dl, bicarbonato 18 mmol / l, anión gap 20, creatinina 0,4 mg / dl, triglicéridos 508 mg / dl, colesterol total 122 mg / dl, hemoglobina glucosilada (HbA1c) 10%. y pH venoso 7,27. La lipasa sérica fue normal a 43 U / L. Los niveles séricos de acetona no pudieron evaluarse ya que las muestras de sangre se mantuvieron hemolizadas debido a una lipemia significativa. La paciente ingresó inicialmente por cetosis por inanición, ya que refirió una ingesta oral deficiente durante los tres días Previous a la admisión. Sin embargo, la química sérica obtenida seis horas después de la presentación reveló que su glucosa era de 186 mg / dL, la brecha aniónica todavía estaba elevada a 21, el bicarbonato sérico era de 16 mmol / L, el nivel de triglicéridos alcanzó un máximo de 2050 mg / dL y la lipasa fue de 52 U / L. Se obtuvo el nivel de β-hidroxibutirato y se encontró que estaba elevado a 5,29 mmol / L; la muestra original se centrifugó y la capa de quilomicrones se eliminó antes del análisis debido a la interferencia de la turbidez causada por la lipemia nuevamente. El paciente fue tratado con un goteo de insulina para euDKA y HTG con una reducción de la brecha aniónica a 13 y triglicéridos a 1400 mg / dL, dentro de las 24 horas. Se pensó que su euDKA fue precipitada por su infección del tracto respiratorio en el contexto del uso del inhibidor de SGLT2. La paciente fue atendida por el servicio de endocrinología y fue dada de alta con 40 unidades de insulina glargina por la noche, 12 unidades de insulina lispro con las comidas y metformina 1000 mg dos veces al día. Se determinó que todos los inhibidores de SGLT2 deben suspenderse indefinidamente. Tuvo un seguimiento estrecho con endocrinología post alta.&#39; res = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-+-+-+--+ | | ner_chunk | entity | snomed_code| |-+-+-+--| | 0 | diabetes mellitus gestacional | DIAGNOSTICO | 11687002 | | 1 | diabetes mellitus tipo dos ( | DIAGNOSTICO | 44054006 | | 2 | pancreatitis | DIAGNOSTICO | 75694006 | | 3 | HTG | DIAGNOSTICO | 266569009 | | 4 | hepatitis aguda | DIAGNOSTICO | 37871000 | | 5 | obesidad | DIAGNOSTICO | 5476005 | | 6 | índice de masa corporal | DIAGNOSTICO | 162859006 | | 7 | poliuria | DIAGNOSTICO | 56574000 | | 8 | polidipsia | DIAGNOSTICO | 17173007 | | 9 | falta de apetito | DIAGNOSTICO | 49233005 | | 10 | vómitos | DIAGNOSTICO | 422400008 | | 11 | infección | DIAGNOSTICO | 40733004 | | 12 | HTG | DIAGNOSTICO | 266569009 | | 13 | dolor | DIAGNOSTICO | 22253000 | | 14 | rigidez | DIAGNOSTICO | 271587009 | | 15 | cetosis | DIAGNOSTICO | 2538008 | | 16 | infección | DIAGNOSTICO | 40733004 | +-+-+-+--+ New Clinical Question vs Statement BertForSequenceClassification model bert_sequence_classifier_question_statement_clinical : This model classifies sentences into one of these two classes: question (interrogative sentence) or statement (declarative sentence) and trained with BertForSequenceClassification. This model is at first trained on SQuAD and SPAADIA dataset and then fine tuned on the clinical visit documents and MIMIC-III dataset annotated in-house. Using this model, you can find the question statements and exclude &amp; utilize in the downstream tasks such as NER and relation extraction models. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) seq = BertForSequenceClassification.pretrained(&#39;bert_sequence_classifier_question_statement_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;label&quot;) .setCaseSensitive(True) pipeline = Pipeline(stages = [ documentAssembler, sentenceDetector, tokenizer, seq]) test_sentences = [&quot;&quot;&quot;Hello I am going to be having a baby throughand have just received my medical results before I have my tubes tested. I had the tests on day 23 of my cycle. My progresterone level is 10. What does this mean? What does progesterone level of 10 indicate? Your progesterone report is perfectly normal. We expect this result on day 23rd of the cycle.So there&#39;s nothing to worry as it&#39;s perfectly alright&quot;&quot;&quot;] res = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: test_sentences}))) Results : +--++ |sentence |label | +--++ |Hello I am going to be having a baby throughand have just received my medical results before I have my tubes tested.|statement| |I had the tests on day 23 of my cycle. |statement| |My progresterone level is 10. |statement| |What does this mean? |question | |What does progesterone level of 10 indicate? |question | |Your progesterone report is perfectly normal. We expect this result on day 23rd of the cycle. |statement| |So there&#39;s nothing to worry as it&#39;s perfectly alright |statement| +--+ Metrics : precision recall f1-score support question 0.97 0.94 0.96 243 statement 0.98 0.99 0.99 729 accuracy 0.98 972 macro avg 0.98 0.97 0.97 972 weighted avg 0.98 0.98 0.98 972 New Sentence Entity Resolver Fine-Tune Features (Overwriting and Drop Code) .setOverwriteExistingCode() : This parameter provides overwriting codes over the existing codes if in pretrained Sentence Entity Resolver Model. For example, you want to add a new term to a pretrained resolver model, and if the code of term already exists in the pretrained model, when you .setOverwriteExistingCode(True), it removes all the same codes and their descriptions from the model, then you will have just the new term with its code in the fine-tuned model. .setDropCodesList() : This parameter drops list of codes from a pretrained Sentence Entity Resolver Model. For more examples, please check Fine-Tuning Sentence Entity Resolver Notebook Updated ICD10CM Entity Resolver Models We have updated sbiobertresolve_icd10cm_augmented model with ICD10CM 2022 Dataset and sbiobertresolve_icd10cm_augmented_billable_hcc model by dropping invalid codes. Updated NER Profiling Pretrained Pipelines We have updated ner_profiling_clinical and ner_profiling_biobert pretrained pipelines by adding new clinical NER models and NER model outputs to the previous versions. In this way, you can see all the NER labels of tokens. For examples, please check NER Profiling Pretrained Pipeline Notebook. New ChunkSentenceSplitter Annotator We are releasing ChunkSentenceSplitter annotator that splits documents or sentences by chunks provided. Splitted parts can be named with the splitting chunks. By using this annotator, you can do some some tasks like splitting clinical documents according into sections in accordance with CDA (Clinical Document Architecture). Example : ... ner_converter = NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;Header&quot;]) chunkSentenceSplitter = ChunkSentenceSplitter() .setInputCols(&quot;ner_chunk&quot;,&quot;document&quot;) .setOutputCol(&quot;paragraphs&quot;) .setGroupBySentences(True) .setDefaultEntity(&quot;Intro&quot;) .setInsertChunk(False) ... text = [&quot;&quot;&quot;INTRODUCTION: Right pleural effusion and suspected malignant mesothelioma. PREOPERATIVE DIAGNOSIS: Right pleural effusion and suspected malignant mesothelioma. POSTOPERATIVE DIAGNOSIS: Right pleural effusion, suspected malignant mesothelioma. PROCEDURE: Right VATS pleurodesis and pleural biopsy.&quot;&quot;&quot;] results = pipeline_model.transform(df) Results : +-++ | result|entity| +-++ |INTRODUCTION: Right pleural effusion and suspected malignant mesoth...|Header| |PREOPERATIVE DIAGNOSIS: Right pleural effusion and suspected malig...|Header| |POSTOPERATIVE DIAGNOSIS: Right pleural effusion, suspected malignan...|Header| | PROCEDURE: Right VATS pleurodesis and pleural biopsy|Header| +-++ By using .setInsertChunk() parameter you can remove the chunk from splitted parts. Example : chunkSentenceSplitter = ChunkSentenceSplitter() .setInputCols(&quot;ner_chunk&quot;,&quot;document&quot;) .setOutputCol(&quot;paragraphs&quot;) .setGroupBySentences(True) .setDefaultEntity(&quot;Intro&quot;) .setInsertChunk(False) paragraphs = chunkSentenceSplitter.transform(results) df = paragraphs.selectExpr(&quot;explode(paragraphs) as result&quot;) .selectExpr(&quot;result.result&quot;, &quot;result.metadata.entity&quot;, &quot;result.metadata.splitter_chunk&quot;) Results : +--+++ | result|entity| splitter_chunk| +--+++ | Right pleural effusion and suspected malignant...|Header| INTRODUCTION:| | Right pleural effusion and suspected malignan...|Header| PREOPERATIVE DIAGNOSIS:| | Right pleural effusion, suspected malignant me...|Header|POSTOPERATIVE DIAGNOSIS:| | Right VATS pleurodesis and pleural biopsy|Header| PROCEDURE:| +--+++ Updated Spark NLP For Healthcare Notebooks NER Profiling Pretrained Pipeline Notebook . Fine-Tuning Sentence Entity Resolver Notebook To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_2"
  },
  "1432": {
    "id": "1432",
    "title": "Spark NLP for Healthcare Release Notes 3.3.4",
    "content": "3.3.4 We are glad to announce that Spark NLP Healthcare 3.3.4 has been released! Highlights New Clinical NER Models New NER Model Finder Pretrained Pipeline New Relation Extraction Model New LOINC, MeSH, NDC and SNOMED Entity Resolver Models Updated RxNorm Sentence Entity Resolver Model New Shift Days Feature in StructuredDeid Deidentification Module New Multiple Chunks Merge Ability in ChunkMergeApproach New setBlackList Feature in ChunkMergeApproach New setBlackList Feature in NerConverterInternal New setLabelCasing Feature in MedicalNerModel New Update Models Functionality New and Updated Notebooks New Clinical NER Models We have three new clinical NER models. ner_deid_subentity_augmented_i2b2 : This model annotates text to find protected health information(PHI) that may need to be removed. It is trained with 2014 i2b2 dataset (no augmentation applied) and can detect MEDICALRECORD, ORGANIZATION, DOCTOR, USERNAME, PROFESSION, HEALTHPLAN, URL, CITY, DATE, LOCATION-OTHER, STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL, EMAIL, IDNUM, SREET, BIOID, FAX, AGE entities. Example : ... deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented_i2b2&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 years old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227. Patient&#39;s complaints first surfaced when he started working for Brothers Coal-Mine.&quot;]], [&quot;text&quot;])) Results : +--+-+ |chunk |ner_label | +--+-+ |2093-01-13 |DATE | |David Hale |DOCTOR | |Hendrickson, Ora |PATIENT | |7194334 |MEDICALRECORD| |01/13/93 |DATE | |Oliveira |DOCTOR | |25 |AGE | |1-11-2000 |DATE | |Cocke County Baptist Hospital|HOSPITAL | |0295 Keats Street |STREET | |(302) 786-5227 |PHONE | |Brothers Coal-Mine Corp |ORGANIZATION | +--+-+ ner_biomarker : This model is trained to extract biomarkers, therapies, oncological, and other general concepts from text. Following are the entities it can detect: Oncogenes, Tumor_Finding, UnspecificTherapy, Ethnicity, Age, ResponseToTreatment, Biomarker, HormonalTherapy, Staging, Drug, CancerDx, Radiotherapy, CancerSurgery, TargetedTherapy, PerformanceStatus, CancerModifier, Radiological_Test_Result, Biomarker_Measurement, Metastasis, Radiological_Test, Chemotherapy, Test, Dosage, Test_Result, Immunotherapy, Date, Gender, Prognostic_Biomarkers, Duration, Predictive_Biomarkers Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_biomarker&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Here , we report the first case of an intraductal tubulopapillary neoplasm of the pancreas with clear cell morphology . Immunohistochemistry revealed positivity for Pan-CK , CK7 , CK8/18 , MUC1 , MUC6 , carbonic anhydrase IX , CD10 , EMA , β-catenin and e-cadherin .&quot;]], [&quot;text&quot;])) Results : | | ner_chunk | entity | confidence | |:|:-|:-|-:| | 0 | intraductal | CancerModifier | 0.9934 | | 1 | tubulopapillary | CancerModifier | 0.6403 | | 2 | neoplasm of the pancreas | CancerDx | 0.758825 | | 3 | clear cell | CancerModifier | 0.9633 | | 4 | Immunohistochemistry | Test | 0.9534 | | 5 | positivity | Biomarker_Measurement | 0.8795 | | 6 | Pan-CK | Biomarker | 0.9975 | | 7 | CK7 | Biomarker | 0.9975 | | 8 | CK8/18 | Biomarker | 0.9987 | | 9 | MUC1 | Biomarker | 0.9967 | | 10 | MUC6 | Biomarker | 0.9972 | | 11 | carbonic anhydrase IX | Biomarker | 0.937567 | | 12 | CD10 | Biomarker | 0.9974 | | 13 | EMA | Biomarker | 0.9899 | | 14 | β-catenin | Biomarker | 0.8059 | | 15 | e-cadherin | Biomarker | 0.9806 | ner_nihss : NER model that can identify entities according to NIHSS guidelines for clinical stroke assessment to evaluate neurological status in acute stroke patients. Here are the labels it can detect : 11_ExtinctionInattention, 6b_RightLeg, 1c_LOCCommands, 10_Dysarthria, NIHSS, 5_Motor, 8_Sensory, 4_FacialPalsy, 6_Motor, 2_BestGaze, Measurement, 6a_LeftLeg, 5b_RightArm, 5a_LeftArm, 1b_LOCQuestions, 3_Visual, 9_BestLanguage, 7_LimbAtaxia, 1a_LOC . Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_nihss&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Abdomen , soft , nontender . NIH stroke scale on presentation was 23 to 24 for , one for consciousness , two for month and year and two for eye / grip , one to two for gaze , two for face , eight for motor , one for limited ataxia , one to two for sensory , three for best language and two for attention . On the neurologic examination the patient was intermittently&quot;]], [&quot;text&quot;])) Results : | | chunk | entity | |:|:-|:-| | 0 | NIH stroke scale | NIHSS | | 1 | 23 to 24 | Measurement | | 2 | one | Measurement | | 3 | consciousness | 1a_LOC | | 4 | two | Measurement | | 5 | month and year and | 1b_LOCQuestions | | 6 | two | Measurement | | 7 | eye / grip | 1c_LOCCommands | | 8 | one to | Measurement | | 9 | two | Measurement | | 10 | gaze | 2_BestGaze | | 11 | two | Measurement | | 12 | face | 4_FacialPalsy | | 13 | eight | Measurement | | 14 | one | Measurement | | 15 | limited | 7_LimbAtaxia | | 16 | ataxia | 7_LimbAtaxia | | 17 | one to two | Measurement | | 18 | sensory | 8_Sensory | | 19 | three | Measurement | | 20 | best language | 9_BestLanguage | | 21 | two | Measurement | | 22 | attention | 11_ExtinctionInattention | New NER Model Finder Pretrained Pipeline We are releasing new ner_model_finder pretrained pipeline trained with bert embeddings that can be used to find the most appropriate NER model given the entity name. Example : from sparknlp.pretrained import PretrainedPipeline finder_pipeline = PretrainedPipeline(&quot;ner_model_finder&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = finder_pipeline.fullAnnotate(&quot;psychology&quot;) Results : entity top models all models resolutions psychology [‘ner_medmentions_coarse’, ‘jsl_rd_ner_wip_greedy_clinical’, ‘ner_jsl_enriched’, ‘ner_jsl’, ‘jsl_ner_wip_modifier_clinical’, ‘ner_jsl_greedy’] [‘ner_medmentions_coarse’, ‘jsl_rd_ner_wip_greedy_clinical’, ‘ner_jsl_enriched’, ‘ner_jsl’, ‘jsl_ner_wip_modifier_clinical’, ‘ner_jsl_greedy’]:::[‘jsl_rd_ner_wip_greedy_clinical’, ‘ner_jsl_enriched’, ‘ner_jsl_slim’, ‘ner_jsl’, ‘jsl_ner_wip_modifier_clinical,… psychological condition:::clinical department::: … New Relation Extraction Model We are releasing new redl_nihss_biobert relation extraction model that can relate scale items and their measurements according to NIHSS guidelines. Example : ... re_model = RelationExtractionDLModel() .pretrained(&#39;redl_nihss_biobert&#39;, &#39;en&#39;, &quot;clinical/models&quot;) .setPredictionThreshold(0.5) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) ... sample_text = &quot;There , her initial NIHSS score was 4 , as recorded by the ED physicians . This included 2 for weakness in her left leg and 2 for what they felt was subtle ataxia in her left arm and leg .&quot; result = re_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : | chunk1 | entity1 | entity1_begin | entity1_end | entity2 | chunk2 | entity2_begin | entity2_end | relation | |:--|:-|-:|--:|:|:|-:|--:|:--| | initial NIHSS score | NIHSS | 12 | 30 | Measurement | 4 | 36 | 36 | Has_Value | | left leg | 6a_LeftLeg | 111 | 118 | Measurement | 2 | 89 | 89 | Has_Value | | subtle ataxia in her left arm and leg | 7_LimbAtaxia | 149 | 185 | Measurement | 2 | 124 | 124 | Has_Value | | left leg | 6a_LeftLeg | 111 | 118 | Measurement | 4 | 36 | 36 | 0 | | initial NIHSS score | NIHSS | 12 | 30 | Measurement | 2 | 124 | 124 | 0 | | subtle ataxia in her left arm and leg | 7_LimbAtaxia | 149 | 185 | Measurement | 4 | 36 | 36 | 0 | | subtle ataxia in her left arm and leg | 7_LimbAtaxia | 149 | 185 | Measurement | 2 | 89 | 89 | 0 | New LOINC, MeSH, NDC and SNOMED Entity Resolver Models We have four new Sentence Entity Resolver Models. sbiobertresolve_mesh : This model maps clinical entities to Medical Subject Heading (MeSH) codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Example : ... mesh_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_mesh&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;mesh_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) .setCaseSensitive(False) ... sample_text = &quot;&quot;&quot;She was admitted to the hospital with chest pain and found to have bilateral pleural effusion, the right greater than the left. We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma. At this time, chest tube placement for drainage of the fluid occurred and thoracoscopy with fluid biopsies, which were performed, which revealed malignant mesothelioma.&quot;&quot;&quot; result = resolver_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +--++-+-+-+-+ | ner_chunk| entity| mesh_code| all_codes| resolutions| distances| +--++-+-+-+-+ | chest pain| PROBLEM| D002637|D002637:::D059350:::D019547:::D020069:::D015746:::D000072716:::D005157:::D059265:::D001416:::D048...|Chest Pain:::Chronic Pain:::Neck Pain:::Shoulder Pain:::Abdominal Pain:::Cancer Pain:::Facial Pai...|0.0000:::0.0577:::0.0587:::0.0601:::0.0658:::0.0704:::0.0712:::0.0741:::0.0766:::0.0778:::0.0794:...| |bilateral pleural effusion| PROBLEM| D010996|D010996:::D010490:::D011654:::D016724:::D010995:::D016066:::D011001:::D007819:::D035422:::D004653...|Pleural Effusion:::Pericardial Effusion:::Pulmonary Edema:::Empyema, Pleural:::Pleural Diseases::...|0.0309:::0.1010:::0.1115:::0.1213:::0.1218:::0.1398:::0.1425:::0.1401:::0.1451:::0.1464:::0.1464:...| | the pathology| TEST| D010336|D010336:::D010335:::D001004:::D020969:::C001675:::C536472:::D004194:::D003951:::D013631:::C535329...|Pathology:::Pathologic Processes:::Anus Diseases:::Disease Attributes:::malformins:::Upington dis...|0.0788:::0.0977:::0.1364:::0.1396:::0.1419:::0.1459:::0.1418:::0.1393:::0.1514:::0.1541:::0.1491:...| | the pericardectomy|TREATMENT| D010492|D010492:::D011670:::D018700:::D020884:::D011672:::D005927:::D064727:::D002431:::C000678968:::D011...|Pericardiectomy:::Pulpectomy:::Pleurodesis:::Colpotomy:::Pulpotomy:::Glossectomy:::Posterior Caps...|0.1098:::0.1448:::0.1801:::0.1852:::0.1871:::0.1923:::0.1901:::0.2023:::0.2075:::0.2010:::0.1996:...| | mesothelioma| PROBLEM|D000086002|D000086002:::C535700:::D009208:::D032902:::D018301:::D018199:::C562740:::C000686536:::D018276:::D...|Mesothelioma, Malignant:::Malignant mesenchymal tumor:::Myoepithelioma:::Ganoderma:::Neoplasms, M...|0.0813:::0.1515:::0.1599:::0.1810:::0.1864:::0.1881:::0.1907:::0.1938:::0.1924:::0.1876:::0.2040:...| | chest tube placement|TREATMENT| D015505|D015505:::D019616:::D013896:::D012124:::D013906:::D013510:::D020708:::D035423:::D013903:::D000066...|Chest Tubes:::Thoracic Surgical Procedures:::Thoracic Diseases:::Respiratory Care Units:::Thoraco...|0.0557:::0.1473:::0.1598:::0.1604:::0.1725:::0.1651:::0.1795:::0.1760:::0.1804:::0.1846:::0.1883:...| | drainage of the fluid|TREATMENT| D004322|D004322:::D018495:::C045413:::D021061:::D045268:::D018508:::D005441:::D015633:::D014906:::D001834...|Drainage:::Fluid Shifts:::Bonain&#39;s liquid:::Liquid Ventilation:::Flowmeters:::Water Purification:...|0.1141:::0.1403:::0.1582:::0.1549:::0.1586:::0.1626:::0.1599:::0.1655:::0.1667:::0.1656:::0.1741:...| | thoracoscopy|TREATMENT| D013906|D013906:::D020708:::D035423:::D013905:::D035441:::D013897:::D001468:::D000069258:::D013909:::D013...|Thoracoscopy:::Thoracoscopes:::Thoracic Cavity:::Thoracoplasty:::Thoracic Wall:::Thoracic Duct:::...|0.0000:::0.0359:::0.0744:::0.1007:::0.1070:::0.1143:::0.1186:::0.1257:::0.1228:::0.1356:::0.1354:...| | fluid biopsies| TEST|D000073890|D000073890:::D010533:::D020420:::D011677:::D017817:::D001706:::D005441:::D005751:::D013582:::D000...|Liquid Biopsy:::Peritoneal Lavage:::Cyst Fluid:::Punctures:::Nasal Lavage Fluid:::Biopsy:::Fluids...|0.1408:::0.1612:::0.1763:::0.1744:::0.1744:::0.1810:::0.1744:::0.1828:::0.1896:::0.1909:::0.1950:...| | malignant mesothelioma| PROBLEM|D000086002|D000086002:::C535700:::C562740:::D009236:::D007890:::D012515:::D009208:::C009823:::C000683999:::C...|Mesothelioma, Malignant:::Malignant mesenchymal tumor:::Hemangiopericytoma, Malignant:::Myxosarco...|0.0737:::0.1106:::0.1658:::0.1627:::0.1660:::0.1639:::0.1728:::0.1676:::0.1791:::0.1843:::0.1849:...| +-+--++-+-+-+-+ sbiobertresolve_ndc : This model maps clinical entities and concepts (like drugs/ingredients) to National Drug Codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Also, if a drug has more than one NDC code, it returns all available codes in the all_k_aux_label column separated by | symbol. Example : ... ndc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_ndc&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;ndc_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) .setCaseSensitive(False) ... sample_text = &quot;&quot;&quot;The patient was transferred secondary to inability and continue of her diabetes, the sacral decubitus, left foot pressure wound, and associated complications of diabetes. She is given aspirin 81 mg, folic acid 1 g daily, insulin glargine 100 UNT/ML injection and metformin 500 mg p.o. p.r.n.&quot;&quot;&quot; result = resolver_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +-++--++--+--+--+ | ner_chunk|entity| ndc_code| description| all_codes| all_resolutions| other ndc codes| +-++--++--+--+--+ | aspirin 81 mg| DRUG|73089008114| aspirin 81 mg/81mg, 81 mg in 1 carton , capsule|[73089008114, 71872708704, 71872715401, 68210101500, 69536028110, 63548086706, 71679001000, 68196090051, 00113400500, 69536018112, 73089008112, 63981056362, 63739043402, 63548086705, 00113046708, 7...|[aspirin 81 mg/81mg, 81 mg in 1 carton , capsule, aspirin 81 mg 81 mg/1, 4 blister pack in 1 bag , tablet, aspirin 81 mg/1, 1 blister pack in 1 bag , tablet, coated, aspirin 81 mg/1, 1 bag in 1 dru...| [-, -, -, -, -, -, -, -, -, -, -, 63940060962, -, -, -, -, -, -, -, -, 70000042002|00363021879|41250027408|36800046708|59779027408|49035027408|71476010131|81522046708|30142046708, -, -, -, -]| | folic acid 1 g| DRUG|43744015101| folic acid 1 g/g, 1 g in 1 package , powder|[43744015101, 63238340000, 66326050555, 51552041802, 51552041805, 63238340001, 81919000204, 51552041804, 66326050556, 51552106301, 51927003300, 71092997701, 51927296300, 51552146602, 61281900002, 6...|[folic acid 1 g/g, 1 g in 1 package , powder, folic acid 1 kg/kg, 1 kg in 1 bottle , powder, folic acid 1 kg/kg, 1 kg in 1 drum , powder, folic acid 1 g/g, 5 g in 1 container , powder, folic acid 1...| [-, -, -, -, -, -, -, -, -, -, -, 51552139201, -, -, -, 81919000203, -, 81919000201, -, -, -, -, -, -, -]| |insulin glargine 100 UNT/ML injection| DRUG|00088502101|insulin glargine 100 [iu]/ml, 1 vial, glass in 1 package , injection, solution|[00088502101, 00088222033, 49502019580, 00002771563, 00169320111, 00088250033, 70518139000, 00169266211, 50090127600, 50090407400, 00002771559, 00002772899, 70518225200, 70518138800, 00024592410, 0...|[insulin glargine 100 [iu]/ml, 1 vial, glass in 1 package , injection, solution, insulin glargine 100 [iu]/ml, 1 vial, glass in 1 carton , injection, solution, insulin glargine 100 [iu]/ml, 1 vial ...|[-, -, -, 00088221900, -, -, 50090139800|00088502005, -, 70518146200|00169368712, 00169368512|73070020011, 00088221905|49502019675|50090406800, -, 73070010011|00169750111|50090495500, 66733077301|0...| | metformin 500 mg| DRUG|70010006315| metformin hydrochloride 500 mg/500mg, 500 mg in 1 drum , tablet|[70010006315, 62207041613, 71052050750, 62207049147, 71052091050, 25000010197, 25000013498, 25000010198, 71052063005, 51662139201, 70010049118, 70882012456, 71052011005, 71052065905, 71052050850, 1...|[metformin hydrochloride 500 mg/500mg, 500 mg in 1 drum , tablet, metformin hcl 500 mg/kg, 50 kg in 1 drum , powder, 5-fluorouracil 500 g/500g, 500 g in 1 container , powder, metformin er 500 mg 50...| [-, -, -, 70010049105, -, -, -, -, -, -, -, -, -, -, -, 71800000801|42571036007, -, -, -, -, -, -, -, -, -]| +-++--++--+--+--+ sbiobertresolve_loinc_augmented : This model maps extracted clinical NER entities to LOINC codes using sbiobert_base_cased_mli Sentence Bert Embeddings. It is trained on the augmented version of the dataset which is used in previous LOINC resolver models. Example : ... loinc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_loinc_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;loinc_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) .setCaseSensitive(False) ... sample_text=&quot;&quot;&quot;The patient is a 22-year-old female with a history of obesity. She has a Body mass index (BMI) of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126. Her hgba1c is 8.2%.&quot;&quot;&quot; result = resolver_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +--+--+++-+--+--+ | chunk|begin|end|entity|Loinc_Code| all_codes| resolutions| +--+--+++-+--+--+ | Body mass index| 74| 88| Test| LP35925-4|LP35925-4:::BDYCRC:::LP172732-2:::39156-5:::LP7...|body mass index:::body circumference:::body mus...| |aspartate aminotransferase| 111|136| Test| LP15426-7|LP15426-7:::14409-7:::LP307348-5:::LP15333-5:::...|aspartate aminotransferase::: aspartate transam...| | alanine aminotransferase| 146|169| Test| LP15333-5|LP15333-5:::LP307326-1:::16324-6:::LP307348-5::...|alanine aminotransferase:::alanine aminotransfe...| | hgba1c| 180|185| Test| 17855-8|17855-8:::4547-6:::55139-0:::72518-4:::45190-6:...| hba1c::: hgb a1::: hb1::: hcds1::: hhc1::: htr...| +--+--+++-+--+--+ sbiobertresolve_clinical_snomed_procedures_measurements : This model maps medical entities to SNOMED codes using sent_biobert_clinical_base_cased Sentence Bert Embeddings. The corpus of this model includes Procedures and Measurement domains. Example : ... snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_clinical_snomed_procedures_measurements&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) ... light_model = LightPipeline(resolver_model) result = light_model.fullAnnotate([&#39;coronary calcium score&#39;, &#39;heart surgery&#39;, &#39;ct scan&#39;, &#39;bp value&#39;]) Results : | | chunk | code | code_description | all_k_codes | all_k_resolutions | |:|:--|-:|:|:--|:-| | 0 | coronary calcium score | 450360000 | Coronary artery calcium score | [&#39;450360000&#39;, &#39;450734004&#39;, &#39;1086491000000104&#39;, &#39;1086481000000101&#39;, &#39;762241007&#39;] | [&#39;Coronary artery calcium score&#39;, &#39;Coronary artery calcium score&#39;, &#39;Dundee Coronary Risk Disk score&#39;, &#39;Dundee Coronary Risk rank&#39;, &#39;Dundee Coronary Risk Disk&#39;] | | 1 | heart surgery | 2598006 | Open heart surgery | [&#39;2598006&#39;, &#39;64915003&#39;, &#39;119766003&#39;, &#39;34068001&#39;, &#39;233004008&#39;] | [&#39;Open heart surgery&#39;, &#39;Operation on heart&#39;, &#39;Heart reconstruction&#39;, &#39;Heart valve replacement&#39;, &#39;Coronary sinus operation&#39;] | | 2 | ct scan | 303653007 | CT of head | [&#39;303653007&#39;, &#39;431864000&#39;, &#39;363023007&#39;, &#39;418272005&#39;, &#39;241577003&#39;] | [&#39;CT of head&#39;, &#39;CT guided injection&#39;, &#39;CT of site&#39;, &#39;CT angiography&#39;, &#39;CT of spine&#39;] | | 3 | bp value | 75367002 | Blood pressure | [&#39;75367002&#39;, &#39;6797001&#39;, &#39;723232008&#39;, &#39;46973005&#39;, &#39;427732000&#39;] | [&#39;Blood pressure&#39;, &#39;Mean blood pressure&#39;, &#39;Average blood pressure&#39;, &#39;Blood pressure taking&#39;, &#39;Speed of blood pressure response&#39;] | Updated RxNorm Sentence Entity Resolver Model We have updated sbiobertresolve_rxnorm_augmented model training on an augmented version of the dataset used in previous versions of the model. New Shift Days Feature in StructuredDeid Deidentification Module Now we can shift n days in the structured deidentification when the column is a Date. Example : df = spark.createDataFrame([ [&quot;Juan García&quot;, &quot;13/02/1977&quot;, &quot;711 Nulla St.&quot;, &quot;140&quot;, &quot;673 431234&quot;], [&quot;Will Smith&quot;, &quot;23/02/1977&quot;, &quot;1 Green Avenue.&quot;, &quot;140&quot;, &quot;+23 (673) 431234&quot;], [&quot;Pedro Ximénez&quot;, &quot;11/04/1900&quot;, &quot;Calle del Libertador, 7&quot;, &quot;100&quot;, &quot;912 345623&quot;] ]).toDF(&quot;NAME&quot;, &quot;DOB&quot;, &quot;ADDRESS&quot;, &quot;SBP&quot;, &quot;TEL&quot;) obfuscator = StructuredDeidentification(spark=spark, columns={&quot;NAME&quot;: &quot;ID&quot;, &quot;DOB&quot;: &quot;DATE&quot;}, columnsSeed={&quot;NAME&quot;: 23, &quot;DOB&quot;: 23}, obfuscateRefSource=&quot;faker&quot;, days=5 ) result = obfuscator.obfuscateColumns(self.df) result.show(truncate=False) Results : +-++--++-+ |NAME |DOB |ADDRESS |SBP|TEL | +-++--++-+ |[T1825511]|[18/02/1977]|711 Nulla St. |140|673 431234 | |[G6835267]|[28/02/1977]|1 Green Avenue. |140|+23 (673) 431234| |[S2371443]|[16/04/1900]|Calle del Libertador, 7|100|912 345623 | +-++--++-+ New Multiple Chunks Merge Ability in ChunkMergeApproach Updated ChunkMergeApproach to admit N input cols (.setInputCols(&quot;ner_chunk&quot;,&quot;ner_chunk_1&quot;,&quot;ner_chunk_2&quot;)). The input columns must be chunk columns. Example : ... deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_large&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&#39;DATE&#39;, &#39;AGE&#39;, &#39;NAME&#39;, &#39;PROFESSION&#39;, &#39;ID&#39;]) medical_ner = MedicalNerModel.pretrained(&quot;ner_events_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner2&quot;) ner_converter_2 = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner2&quot;]) .setOutputCol(&quot;ner_chunk_2&quot;) ssn_parser = ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity_ssn&quot;) .setJsonPath(&quot;../../src/test/resources/ssn.json&quot;) .setCaseSensitive(False) .setContextMatch(False) chunk_merge = ChunkMergeApproach() .setInputCols(&quot;entity_ssn&quot;,&quot;ner_chunk&quot;,&quot;ner_chunk_2&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) .setChunkPrecedence(&quot;field&quot;) ... New setBlackList Feature in ChunkMergeApproach Now we can filter out the entities in the ChunkMergeApproach using a black list .setBlackList([&quot;NAME&quot;,&quot;ID&quot;]). The entities specified in the blackList will be excluded from the final entity list. Example : chunk_merge = ChunkMergeApproach() .setInputCols(&quot;entity_ssn&quot;,&quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) .setBlackList([&quot;NAME&quot;,&quot;ID&quot;]) New setBlackList Feature in NerConverterInternal Now we can filter out the entities in the NerConverterInternal using a black list .setBlackList([&quot;Drug&quot;,&quot;Treatment&quot;]). The entities specified in the blackList will be excluded from the final entity list. Example : ner = MedicalNerModel.pretrained(&quot;ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) converter = NerConverterInternal() .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;) .setOutputCol(&quot;entities&quot;) .setBlackList([&quot;Drug&quot;,&quot;Treatment&quot;]) New setLabelCasing Feature in MedicalNerModel Now we can decide if we want to return the tags in upper or lower case with setLabelCasing(). That method convert the I-tags and B-tags in lower or upper case during the inference. The values will be ‘lower’ for lower case and ‘upper’ for upper case. Example : ... ner_tagger = MedicalNerModel() .pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) .setLabelCasing(&quot;lower&quot;) ... results = LightPipeline(pipelineModel).annotate(&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus &quot;) results[&quot;ner_tags&quot;] Results : [&#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-problem&#39;, &#39;I-problem&#39;, &#39;I-problem&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-problem&#39;, &#39;I-problem&#39;, &#39;I-problem&#39;, &#39;I-problem&#39;, &#39;I-problem&#39;] New Update Models Functionality We developed a new utility function called UpdateModels that allows you to refresh your cache_pretrained folder without running any annotator or manually checking. It has two methods; UpdateModels.updateCacheModels() : This method lets you update all the models existing in the cache_pretrained folder. It downloads the latest version of all the models existing in the cache_pretrained. Example : # Models in /cache_pretrained ls ~/cache_pretrained &gt;&gt; ner_clinical_large_en_3.0.0_2.3_1617206114650/ # Update models in /cache_pretrained from sparknlp_jsl.updateModels import UpdateModels UpdateModels.updateCacheModels() Results : # Updated models in /cache_pretrained ls ~/cache_pretrained &gt;&gt; ner_clinical_large_en_3.0.0_2.3_1617206114650/ ner_clinical_large_en_3.0.0_3.0_1617206114650/ UpdateModels.updateModels(&quot;11/24/2021&quot;) : This method lets you download all the new models uploaded to the Models Hub starting from a cut-off date (i.e. the last sync update). Example : # Models in /cache_pretrained ls ~/cache_pretrained &gt;&gt; ner_clinical_large_en_3.0.0_2.3_1617206114650/ ner_clinical_large_en_3.0.0_3.0_1617206114650/ # Update models in /cache_pretrained according to date from sparknlp_jsl.updateModels import UpdateModels UpdateModels.updateModels(&quot;11/24/2021&quot;) Results : # Updated models in /cache_pretrained ls ~/cache_pretrained &gt;&gt;ner_clinical_large_en_3.0.0_2.3_1617206114650/ ner_clinical_large_en_3.0.0_3.0_1617206114650/ ner_model_finder_en_3.3.2_2.4_1637761259895/ sbertresolve_ner_model_finder_en_3.3.2_2.4_1637764208798/ New and Updated Notebooks We have a new Connect to Annotation Lab via API Notebook you can find how to; upload pre-annotations to ALAB import a project form ALAB and convert to CoNLL file upload tasks without pre-annotations We have updated Clinical Relation Extraction Notebook by adding a Relation Extraction Model-NER Model-Relation Pairs table that can be used to get the most optimal results when using these models. To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_4",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_4"
  },
  "1433": {
    "id": "1433",
    "title": "NLP Lab Release Notes 3.4.0",
    "content": "3.4.0 Release date: 01-08-2022 We are very excited to release Annotation Lab v3.4.0 with support for Visual NER Automated Preannotation and Model Training. Spark NLP and Spark NLP for Healthcare libraries are upgraded to version 4.0. As always known security and bug fixes are also included with it. Here are the highlights of this release: Highlights Visual NER Training support. Annotation Lab offers the ability to train Visual NER models, apply active learning for automatic model training, and preannotate image-based tasks with existing models in order to accelerate annotation work. Floating or airgap licenses with scope ocr: inference and ocr: training are required for preannotation and training respectively. The minimal required training configuration is 64 GB RAM, 16 Core CPU for Visual NER Training. Visual NER Preannotation. For running preannotation on one or several tasks, the Project Owner or the Manager must select the target tasks and can click on the Preannotate button from the upper right side of the Tasks Page. The minimal required preannotation configuration is 32 GB RAM, 2 Core CPU for Visual NER Model. Spark NLP and Spark NLP for Healthcare upgrades. Annotation Lab 3.4.0 uses Spark NLP 4.0.0, Spark NLP for Healthcare 4.0.2 and Spark OCR 3.13.0. Confusion Matrix for Classification Projects. A checkbox is now added on the training page to enable the generation of confusion matrix for classification projects. The confusion matrix is visible in the live training logs as well as in the downloaded training logs. Project Import Improvements. The name of the imported project is set according to the name of the imported zip file. Users can now make changes in the content of the exported zip and then zip it back for import into Annotation Lab. Task Pagination in Labeling page. Tasks are paginated based on the number of characters they contain. Confidence filter slider is now visible only for preannotations. Previously the confidence filter was applied to both predictions and completions. Since all manual annotations have a confidence score of 1, we decided to only show and apply the confidence filter when the prediction widget is selected. Swagger Docs Changes. API docs have been restructured for an easier use and new methods have been added to mirror the new functionalities offered via the UI. Confidence score for Rules preannotations. Confidence of rule-based preannotations is now visible on the Labeling screen, the same as that of model-based preannotation. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_4_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_4_0"
  },
  "1434": {
    "id": "1434",
    "title": "Spark NLP release notes 3.4.0",
    "content": "3.4.0 Release date: 30-06-2021 Overview Signature Detection in image-based documents. More details please read in Signature Detection in Spark OCR New Features ImageSignatureDetector is a DL model for detecting signature on the image. New notebooks Image Signature Detection example Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_4_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_4_0"
  },
  "1435": {
    "id": "1435",
    "title": "Spark NLP for Healthcare Release Notes 3.4.0",
    "content": "3.4.0 We are glad to announce that Spark NLP Healthcare 3.4.0 has been released! This is a massive release: new features, new models, academic papers, and more! Highlights New German Deidentification NER Models New German Deidentification Pretrained Pipeline New Clinical NER Models New AnnotationMerger Annotator New MedicalBertForTokenClassifier Annotator New BERT-Based Clinical NER Models New Clinical Relation Extraction Models New LOINC, SNOMED, UMLS and Clinical Abbreviation Entity Resolver Models New ICD10 to ICD9 Code Mapping Pretrained Pipeline New Clinical Sentence Embedding Models Printing Validation and Test Logs for MedicalNerApproach and AssertionDLApproach Filter Only the Regex Entities Feature in Deidentification Annotator Add .setMaskingPolicy Parameter in Deidentification Annotator Add .cache_folder Parameter in UpdateModels.updateCacheModels() S3 Access Credentials No Longer Shipped Along Licenses Enhanced Security for the Library and log4shell Update New Peer-Reviewed Conference Paper on Clinical Relation Extraction New Peer-Reviewed Conference Paper on Adverse Drug Events Extraction New and Updated Notebooks New German Deidentification NER Models We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in German. ner_deid_generic and ner_deid_subentity models are trained with in-house annotations. ner_deid_generic : Detects 7 PHI entities in German (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID). ner_deid_subentity : Detects 12 PHI sub-entities in German (PATIENT, HOSPITAL, DATE, ORGANIZATION, CITY, STREET, USERNAME, PROFESSION, PHONE, COUNTRY, DOCTOR, AGE). Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;,&quot;de&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... text = &quot;&quot;&quot;Michael Berger wird am Morgen des 12 Dezember 2018 ins St. Elisabeth-Krankenhaus in Bad Kissingen eingeliefert. Herr Berger ist 76 Jahre alt und hat zu viel Wasser in den Beinen.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results : +-+-+-+ |chunk |ner_deid_generic_chunk|ner_deid_subentity_chunk | +-+-+-+ |Michael Berger |NAME |PATIENT | |12 Dezember 2018 |DATE |DATE | |St. Elisabeth-Krankenhaus|LOCATION |HOSPITAL | |Bad Kissingen |LOCATION |CITY | |Berger |NAME |PATIENT | |76 |AGE |AGE | +-+-+-+ New German Deidentification Pretrained Pipeline We developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from German medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate PATIENT, HOSPITAL, DATE, ORGANIZATION, CITY, STREET, USERNAME, PROFESSION, PHONE, COUNTRY, DOCTOR, AGE, CONTACT, ID, PHONE, ZIP, ACCOUNT, SSN, DLN, PLATE entities. Example : ... from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;de&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;Zusammenfassung : Michael Berger wird am Morgen des 12 Dezember 2018 ins St.Elisabeth Krankenhaus in Bad Kissingen eingeliefert. Herr Michael Berger ist 76 Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: T0110053F Platte A-BC124 Kontonummer: DE89370400440532013000 SSN : 13110587M565 Lizenznummer: B072RRE2I55 Adresse : St.Johann-Straße 13 19300&quot;&quot;&quot; result = deid_pipe.annotate(text) print(&quot; n&quot;.join(result[&#39;masked&#39;])) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) Results : Zusammenfassung : &lt;PATIENT&gt; wird am Morgen des &lt;DATE&gt; ins &lt;HOSPITAL&gt; eingeliefert. Herr &lt;PATIENT&gt; ist &lt;AGE&gt; Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: &lt;ID&gt; Platte &lt;PLATE&gt; Kontonummer: &lt;ACCOUNT&gt; SSN : &lt;SSN&gt; Lizenznummer: &lt;DLN&gt; Adresse : &lt;STREET&gt; &lt;ZIP&gt; Zusammenfassung : Herrmann Kallert wird am Morgen des 11-26-1977 ins International Neuroscience eingeliefert. Herr Herrmann Kallert ist 79 Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: 136704D357 Platte QA348G Kontonummer: 192837465738 SSN : 1310011981M454 Lizenznummer: XX123456 Adresse : Klingelhöferring 31206 Zusammenfassung : **** wird am Morgen des **** ins **** eingeliefert. Herr **** ist **** Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: **** Platte **** Kontonummer: **** SSN : **** Lizenznummer: **** Adresse : **** **** Zusammenfassung : [************] wird am Morgen des [**************] ins [**********************] eingeliefert. Herr [************] ist ** Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: [*******] Platte [*****] Kontonummer: [********************] SSN : [**********] Lizenznummer: [*********] Adresse : [*****************] [***] New Clinical NER Models We have two new clinical NER models. ner_abbreviation_clinical : This model is trained to extract clinical abbreviations and acronyms in texts and labels these entities as ABBR. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_abbreviation_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA: Laboratory tests include a CBC which is normal. Blood Type: AB positive. Rubella: Immune. VDRL: Nonreactive. Hepatitis C surface antigen: Negative. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet.&quot;]], [&quot;text&quot;])) Results : +--++ |chunk|ner_label| +--++ |CBC |ABBR | |AB |ABBR | |VDRL |ABBR | |HIV |ABBR | +--++ ner_drugprot_clinical : This model detects chemical compounds/drugs and genes/proteins in medical text and research articles. Here are the labels it can detect : GENE, CHEMICAL, GENE_AND_CHEMICAL. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_drugprot_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Anabolic effects of clenbuterol on skeletal muscle are mediated by beta 2-adrenoceptor activation&quot;]], [&quot;text&quot;])) Results : | | chunk | ner_label | |:|:|:| | 0 | clenbuterol | CHEMICAL | | 1 | beta 2-adrenoceptor | GENE | New AnnotationMerger Annotator A new annotator: AnnotationMerger. Besides NERs, now we will be able to merge results of Relation Extraction models and Assertion models as well. Therefore, it can merge results of Relation Extraction models, NER models, and Assertion Status models. Example-1 : ... annotation_merger = AnnotationMerger() .setInputCols(&quot;ade_relations&quot;, &quot;pos_relations&quot;, &quot;events_relations&quot;) .setInputType(&quot;category&quot;) .setOutputCol(&quot;all_relations&quot;) ... results = ann_merger_model.transform(spark.createDataFrame([[&quot;The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.&quot;]], [&quot;text&quot;])) Results-1 : | | all_relations | all_relations_entity1 | all_relations_chunk1 | all_relations_entity2 | all_relations_chunk2 | |:|:-|:|:--|:|:-| | 0 | 1 | DRUG | oxaprozin | ADE | tense bullae | | 1 | 1 | DRUG | oxaprozin | ADE | cutaneous fragility on the face and the back of the hands | | 2 | DOSAGE-DRUG | DOSAGE | 1 unit | DRUG | naproxen | | 3 | DRUG-DURATION | DRUG | naproxen | DURATION | for 5 days | | 4 | DOSAGE-DRUG | DOSAGE | 1 unit | DRUG | oxaprozin | | 5 | DRUG-FREQUENCY | DRUG | oxaprozin | FREQUENCY | daily | | 6 | OVERLAP | TREATMENT | naproxen | DURATION | 5 days | | 7 | OVERLAP | TREATMENT | oxaprozin | FREQUENCY | daily | | 8 | BEFORE | TREATMENT | oxaprozin | PROBLEM | rheumatoid arthritis | | 9 | AFTER | TREATMENT | oxaprozin | OCCURRENCE | presented | | 10 | OVERLAP | FREQUENCY | daily | PROBLEM | rheumatoid arthritis | | 11 | OVERLAP | FREQUENCY | daily | PROBLEM | tense bullae | | 12 | OVERLAP | FREQUENCY | daily | PROBLEM | cutaneous fragility on the face | | 13 | BEFORE | PROBLEM | rheumatoid arthritis | OCCURRENCE | presented | | 14 | OVERLAP | PROBLEM | rheumatoid arthritis | PROBLEM | tense bullae | | 15 | OVERLAP | PROBLEM | rheumatoid arthritis | PROBLEM | cutaneous fragility on the face | | 16 | BEFORE | OCCURRENCE | presented | PROBLEM | tense bullae | | 17 | BEFORE | OCCURRENCE | presented | PROBLEM | cutaneous fragility on the face | | 18 | OVERLAP | PROBLEM | tense bullae | PROBLEM | cutaneous fragility on the face | Example-2 : ... ner_annotation_merger = AnnotationMerger() .setInputCols(&quot;ner_chunk&quot;, &quot;radiology_ner_chunk&quot;, &quot;jsl_ner_chunk&quot;) .setInputType(&quot;chunk&quot;) .setOutputCol(&quot;all_ners&quot;) assertion_annotation_merger = AnnotationMerger() .setInputCols(&quot;clinical_assertion&quot;, &quot;radiology_assertion&quot;, &quot;jsl_assertion&quot;) .setInputType(&quot;assertion&quot;) .setOutputCol(&quot;all_assertions&quot;) ... results = ann_merger_model.transform(spark.createDataFrame([[&quot;The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.&quot;]], [&quot;text&quot;])) Results-2 : | | ners | all_assertions | |:|:--|:--| | 0 | naproxen | present | | 1 | chronic low back pain | present | | 2 | oxaprozin | present | | 3 | rheumatoid arthritis | present | | 4 | tense bullae | present | | 5 | cutaneous fragility on the face | present | | 6 | low back | Confirmed | | 7 | pain | Confirmed | | 8 | rheumatoid arthritis | Confirmed | | 9 | tense bullae | Confirmed | | 10 | cutaneous | Confirmed | | 11 | fragility | Confirmed | | 12 | face | Confirmed | | 13 | back | Confirmed | | 14 | hands | Confirmed | | 15 | 1 unit | Present | | 16 | naproxen | Past | | 17 | for 5 days | Past | | 18 | chronic | Someoneelse | | 19 | low | Past | | 20 | back pain | Present | | 21 | 1 unit | Past | | 22 | oxaprozin | Past | | 23 | daily | Past | | 24 | rheumatoid arthritis | Present | | 25 | tense | Present | | 26 | bullae | Present | | 27 | cutaneous fragility | Present | | 28 | face | Someoneelse | | 29 | back of the hands | Present | New MedicalBertForTokenClassifier Annotator We developed a new annotator called MedicalBertForTokenClassifier that can load BERT-Based clinical token classifier models head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. New BERT-Based Clinical NER Models Here are the MedicalBertForTokenClassifier Models we have in the library at the moment: bert_token_classifier_ner_ade bert_token_classifier_ner_anatomy bert_token_classifier_ner_bionlp bert_token_classifier_ner_cellular bert_token_classifier_ner_chemprot bert_token_classifier_ner_chemicals bert_token_classifier_ner_jsl_slim bert_token_classifier_ner_jsl bert_token_classifier_ner_deid bert_token_classifier_ner_drugs bert_token_classifier_ner_clinical bert_token_classifier_ner_bacteria In addition, we are releasing a new BERT-Based clinical NER model named bert_token_classifier_drug_development_trials. It is a MedicalBertForTokenClassification NER model to identify concepts related to drug development including Trial Groups , End Points , Hazard Ratio, and other entities in free text. It can detect the following entities: Patient_Count, Duration, End_Point, Value, Trial_Group, Hazard_Ratio, Total_Patients Example : ... tokenClassifier= MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_drug_development_trials&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... results = ner_model.transform(spark.createDataFrame([[&quot;In June 2003, the median overall survival with and without topotecan were 4.0 and 3.6 months, respectively. The best complete response ( CR ) , partial response ( PR ) , stable disease and progressive disease were observed in 23, 63, 55 and 33 patients, respectively, with topotecan, and 11, 61, 66 and 32 patients, respectively, without topotecan.&quot;]], [&quot;text&quot;])) Results : | | chunk | entity | |:|:|:--| | 0 | median | Duration | | 1 | overall survival | End_Point | | 2 | with | Trial_Group | | 3 | without topotecan | Trial_Group | | 4 | 4.0 | Value | | 5 | 3.6 months | Value | | 6 | 23 | Patient_Count | | 7 | 63 | Patient_Count | | 8 | 55 | Patient_Count | | 9 | 33 patients | Patient_Count | | 10 | topotecan | Trial_Group | | 11 | 11 | Patient_Count | | 12 | 61 | Patient_Count | | 13 | 66 | Patient_Count | | 14 | 32 patients | Patient_Count | | 15 | without topotecan | Trial_Group | New Clinical Relation Extraction Models We have two new clinical Relation Extraction models for detecting interactions between drugs and proteins. These models work hand-in-hand with the new ner_drugprot_clinical NER model and detect following relations between entities: INHIBITOR, DIRECT-REGULATOR, SUBSTRATE, ACTIVATOR, INDIRECT-UPREGULATOR, INDIRECT-DOWNREGULATOR, ANTAGONIST, PRODUCT-OF, PART-OF, AGONIST. redl_drugprot_biobert : This model was trained using BERT and performs with higher accuracy. re_drugprot_clinical : This model was trained using RelationExtractionApproach(). Example : ... drugprot_ner_tagger = MedicalNerModel.pretrained(&quot;ner_drugprot_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ner_tags&quot;) ... drugprot_re_biobert = RelationExtractionDLModel() .pretrained(&#39;redl_drugprot_biobert&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setPredictionThreshold(0.9) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) drugprot_re_clinical = RelationExtractionModel() .pretrained(&quot;re_drugprot_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(4) .setPredictionThreshold(0.9) .setRelationPairs([&#39;CHEMICAL-GENE&#39;]) ... sample_text = &quot;Lipid specific activation of the murine P4-ATPase Atp8a1 (ATPase II). The asymmetric transbilayer distribution of phosphatidylserine (PS) in the mammalian plasma membrane and secretory vesicles is maintained, in part, by an ATP-dependent transporter. This aminophospholipid &quot;flippase&quot; selectively transports PS to the cytosolic leaflet of the bilayer and is sensitive to vanadate, Ca(2+), and modification by sulfhydryl reagents. Although the flippase has not been positively identified, a subfamily of P-type ATPases has been proposed to function as transporters of amphipaths, including PS and other phospholipids. A candidate PS flippase ATP8A1 (ATPase II), originally isolated from bovine secretory vesicles, is a member of this subfamily based on sequence homology to the founding member of the subfamily, the yeast protein Drs2, which has been linked to ribosomal assembly, the formation of Golgi-coated vesicles, and the maintenance of PS asymmetry.&quot; result = re_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : ++--+-+--+--+-+-+--+--+-+ | relation| entity1|entity1_begin|entity1_end| chunk1|entity2|entity2_begin|entity2_end| chunk2|confidence| ++--+-+--+--+-+-+--+--+-+ |SUBSTRATE|CHEMICAL| 308| 310| PS| GENE| 275| 283| flippase| 0.998399| |ACTIVATOR|CHEMICAL| 1563| 1578| sn-1,2-glycerol| GENE| 1479| 1509|plasma membrane P...| 0.999304| |ACTIVATOR|CHEMICAL| 1563| 1578| sn-1,2-glycerol| GENE| 1511| 1517| Atp8a1| 0.979057| ++--+-+--+--+-+-+--+--+-+ New LOINC, SNOMED, UMLS and Clinical Abbreviation Entity Resolver Models We have five new Sentence Entity Resolver models. sbiobertresolve_clinical_abbreviation_acronym : This model maps clinical abbreviations and acronyms to their meanings using sbiobert_base_cased_mli Sentence Bert Embeddings. It is a part of ongoing research we have been running in-house, and trained with a limited dataset. We’ll be updating &amp; enriching the model in the upcoming releases. Example : ... abbr_resolver = SentenceEntityResolverModel.pretraind(&quot;sbiobertresolve_clinical_abbreviation_acronym&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;merged_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;abbr_meaning&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text = &quot;HISTORY OF PRESENT ILLNESS: The patient three weeks ago was seen at another clinic for upper respiratory infection-type symptoms. She was diagnosed with a viral infection and had used OTC medications including Tylenol, Sudafed, and Nyquil.&quot; results = abb_model.transform(spark.createDataFrame([[sample_text]]).toDF(&#39;text&#39;)) Results : | sent_id | ner_chunk | entity | abbr_meaning | all_k_results | all_k_resolutions | |-:|:|:|:--|:--|:| | 0 | OTC | ABBR | over the counter | [&#39;over the counter&#39;, &#39;ornithine transcarbamoylase&#39;, &#39;enteric-coated&#39;, &#39;thyroxine&#39;] | [&#39;OTC&#39;, &#39;OTC&#39;, &#39;EC&#39;, &#39;T4&#39;] | sbiobertresolve_umls_drug_substance : This model maps clinical entities to UMLS CUI codes. It is trained on 2021AB UMLS dataset. The complete dataset has 127 different categories, and this model is trained on the Clinical Drug, Pharmacologic Substance, Antibiotic, Hazardous or Poisonous Substance categories using sbiobert_base_cased_mli embeddings. Example : ... umls_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_umls_drug_substance&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... results = model.fullAnnotate([&#39;Dilaudid&#39;, &#39;Hydromorphone&#39;, &#39;Exalgo&#39;, &#39;Palladone&#39;, &#39;Hydrogen peroxide 30 mg&#39;, &#39;Neosporin Cream&#39;, &#39;Magnesium hydroxide 100mg/1ml&#39;, &#39;Metformin 1000 mg&#39;]) Results : | | chunk | code | code_description | all_k_code_desc | all_k_codes | |:|:|:|:|:-|:-| | 0 | Dilaudid | C0728755 | dilaudid | [&#39;C0728755&#39;, &#39;C0719907&#39;, &#39;C1448344&#39;, &#39;C0305924&#39;, &#39;C1569295&#39;] | [&#39;dilaudid&#39;, &#39;Dilaudid HP&#39;, &#39;Disthelm&#39;, &#39;Dilaudid Injection&#39;, &#39;Distaph&#39;] | | 1 | Hydromorphone | C0012306 | HYDROMORPHONE | [&#39;C0012306&#39;, &#39;C0700533&#39;, &#39;C1646274&#39;, &#39;C1170495&#39;, &#39;C0498841&#39;] | [&#39;HYDROMORPHONE&#39;, &#39;Hydromorphone HCl&#39;, &#39;Phl-HYDROmorphone&#39;, &#39;PMS HYDROmorphone&#39;, &#39;Hydromorphone injection&#39;] | | 2 | Exalgo | C2746500 | Exalgo | [&#39;C2746500&#39;, &#39;C0604734&#39;, &#39;C1707065&#39;, &#39;C0070591&#39;, &#39;C3660437&#39;] | [&#39;Exalgo&#39;, &#39;exaltolide&#39;, &#39;Exelgyn&#39;, &#39;Extacol&#39;, &#39;exserohilone&#39;] | | 3 | Palladone | C0730726 | palladone | [&#39;C0730726&#39;, &#39;C0594402&#39;, &#39;C1655349&#39;, &#39;C0069952&#39;, &#39;C2742475&#39;] | [&#39;palladone&#39;, &#39;Palladone-SR&#39;, &#39;Palladone IR&#39;, &#39;palladiazo&#39;, &#39;palladia&#39;] | | 4 | Hydrogen peroxide 30 mg | C1126248 | hydrogen peroxide 30 MG/ML | [&#39;C1126248&#39;, &#39;C0304655&#39;, &#39;C1605252&#39;, &#39;C0304656&#39;, &#39;C1154260&#39;] | [&#39;hydrogen peroxide 30 MG/ML&#39;, &#39;Hydrogen peroxide solution 30%&#39;, &#39;hydrogen peroxide 30 MG/ML [Proxacol]&#39;, &#39;Hydrogen peroxide 30 mg/mL cutaneous solution&#39;, &#39;benzoyl peroxide 30 MG/ML&#39;] | | 5 | Neosporin Cream | C0132149 | Neosporin Cream | [&#39;C0132149&#39;, &#39;C0306959&#39;, &#39;C4722788&#39;, &#39;C0704071&#39;, &#39;C0698988&#39;] | [&#39;Neosporin Cream&#39;, &#39;Neosporin Ointment&#39;, &#39;Neomycin Sulfate Cream&#39;, &#39;Neosporin Topical Ointment&#39;, &#39;Naseptin cream&#39;] | | 6 | Magnesium hydroxide 100mg/1ml | C1134402 | magnesium hydroxide 100 MG | [&#39;C1134402&#39;, &#39;C1126785&#39;, &#39;C4317023&#39;, &#39;C4051486&#39;, &#39;C4047137&#39;] | [&#39;magnesium hydroxide 100 MG&#39;, &#39;magnesium hydroxide 100 MG/ML&#39;, &#39;Magnesium sulphate 100mg/mL injection&#39;, &#39;magnesium sulfate 100 MG&#39;, &#39;magnesium sulfate 100 MG/ML&#39;] | | 7 | Metformin 1000 mg | C0987664 | metformin 1000 MG | [&#39;C0987664&#39;, &#39;C2719784&#39;, &#39;C0978482&#39;, &#39;C2719786&#39;, &#39;C4282269&#39;] | [&#39;metformin 1000 MG&#39;, &#39;metFORMIN hydrochloride 1000 MG&#39;, &#39;METFORMIN HCL 1000MG TAB&#39;, &#39;metFORMIN hydrochloride 1000 MG [Fortamet]&#39;, &#39;METFORMIN HCL 1000MG SA TAB&#39;] | sbiobertresolve_loinc_cased : This model maps extracted clinical NER entities to LOINC codes using sbiobert_base_cased_mli Sentence Bert Embeddings. It is trained with augmented cased concept names since sbiobert model is cased. Example : ... loinc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_loinc_cased&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text= &quot;&quot;&quot;The patient is a 22-year-old female with a history of obesity. She has a BMI of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126. Her hemoglobin is 8.2%.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[sample_text]], [&quot;text&quot;])) Results : +-++--+-+--+ | ner_chunk|entity| resolution| all_codes| resolutions| +-++--+-+--+ | BMI| Test| LP35925-4|[LP35925-4, 59574-4, BDYCRC, 73964-9, 59574-4,... |[Body mass index (BMI), Body mass index, Body circumference, Body muscle mass, Body mass index (BMI) [Percentile], ... | | aspartate aminotransferase| Test| 14409-7|[14409-7, 1916-6, 16325-3, 16324-6, 43822-6, 308... |[Aspartate aminotransferase, Aspartate aminotransferase/Alanine aminotransferase, Alanine aminotransferase/Aspartate aminotransferase, Alanine aminotransferase, Aspartate aminotransferase [Prese... | | alanine aminotransferase| Test| 16324-6|[16324-6, 16325-3, 14409-7, 1916-6, 59245-1, 30... |[Alanine aminotransferase, Alanine aminotransferase/Aspartate aminotransferase, Aspartate aminotransferase, Aspartate aminotransferase/Alanine aminotransferase, Alanine glyoxylate aminotransfer,... | | hemoglobin| Test| 14775-1|[14775-1, 16931-8, 12710-0, 29220-1, 15082-1, 72... |[Hemoglobin, Hematocrit/Hemoglobin, Hemoglobin pattern, Haptoglobin, Methemoglobin, Oxyhemoglobin, Hemoglobin test status, Verdohemoglobin, Hemoglobin A, Hemoglobin distribution width, Myoglobin,... | +-++--+-+--+ sbluebertresolve_loinc_uncased : This model maps extracted clinical NER entities to LOINC codes using sbluebert_base_uncased_mli Sentence Bert Embeddings. It trained on the augmented version of the uncased (lowercased) dataset which is used in previous LOINC resolver models. Example : ... loinc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbluebertresolve_loinc_uncased&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text= &quot;&quot;&quot;The patient is a 22-year-old female with a history of obesity. She has a BMI of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126. Her hgba1c is 8.2%.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[sample_text]], [&quot;text&quot;])) Results : +-++--+-+--+ | ner_chunk|entity| resolution| all_codes| resolutions| +-++--+-+--+ | BMI| Test| 39156-5|[39156-5, LP35925-4, BDYCRC, 73964-9, 59574-4,...] |[Body mass index, Body mass index (BMI), Body circumference, Body muscle mass, Body mass index (BMI) [Percentile], ...] | | aspartate aminotransferase| Test| 14409-7|[&#39;14409-7&#39;, &#39;16325-3&#39;, &#39;1916-6&#39;, &#39;16324-6&#39;,...] |[&#39;Aspartate aminotransferase&#39;, &#39;Alanine aminotransferase/Aspartate aminotransferase&#39;, &#39;Aspartate aminotransferase/Alanine aminotransferase&#39;, &#39;Alanine aminotransferase&#39;, ...] | | alanine aminotransferase| Test| 16324-6|[&#39;16324-6&#39;, &#39;1916-6&#39;, &#39;16325-3&#39;, &#39;59245-1&#39;,...] |[&#39;Alanine aminotransferase&#39;, &#39;Aspartate aminotransferase/Alanine aminotransferase&#39;, &#39;Alanine aminotransferase/Aspartate aminotransferase&#39;, &#39;Alanine glyoxylate aminotransferase&#39;,...] | | hgba1c| Test| 41995-2|[&#39;41995-2&#39;, &#39;LP35944-5&#39;, &#39;LP19717-5&#39;, &#39;43150-2&#39;,...]|[&#39;Hemoglobin A1c&#39;, &#39;HbA1c measurement device&#39;, &#39;HBA1 gene&#39;, &#39;HbA1c measurement device panel&#39;, ...] | +-++--+++ sbiobertresolve_snomed_drug : This model maps detected drug entities to SNOMED codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Example : ... snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_snomed_drug&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text = &quot;She is given Fragmin 5000 units subcutaneously daily, OxyContin 30 mg p.o. q.12 h., folic acid 1 mg daily, levothyroxine 0.1 mg p.o. daily, Avandia 4 mg daily, aspirin 81 mg daily, Neurontin 400 mg p.o. t.i.d., magnesium citrate 1 bottle p.o. p.r.n., sliding scale coverage insulin.&quot; results = model.transform(spark.createDataFrame([[sample_text]]).toDF(&#39;text&#39;)) Results : +--++--+--+++ | ner_chunk|entity| snomed_code| resolved_text| all_k_results| all_k_resolutions| +--++--+--+++ | Fragmin| DRUG| 9487801000001106| Fragmin|9487801000001106:::130752006:::28999000:::953500100000110...|Fragmin:::Fragilysin:::Fusarin:::Femulen:::Fumonisin:::Fr...| | OxyContin| DRUG| 9296001000001100| OxyCONTIN|9296001000001100:::373470001:::230091000001108:::55452001...|OxyCONTIN:::Oxychlorosene:::Oxyargin:::oxyCODONE:::Oxymor...| | folic acid| DRUG| 63718003| Folic acid|63718003:::6247001:::226316008:::432165000:::438451000124...|Folic acid:::Folic acid-containing product:::Folic acid s...| | levothyroxine| DRUG|10071011000001106| Levothyroxine|10071011000001106:::710809001:::768532006:::126202002:::7...|Levothyroxine:::Levothyroxine (substance):::Levothyroxine...| | Avandia| DRUG| 9217601000001109| avandia|9217601000001109:::9217501000001105:::12226401000001108::...|avandia:::avandamet:::Anatera:::Intanza:::Avamys:::Aragam...| | aspirin| DRUG| 387458008| Aspirin|387458008:::7947003:::5145711000001107:::426365001:::4125...|Aspirin:::Aspirin-containing product:::Aspirin powder:::A...| | Neurontin| DRUG| 9461401000001102| neurontin|9461401000001102:::130694004:::86822004:::952840100000110...|neurontin:::Neurolysin:::Neurine (substance):::Nebilet:::...| |magnesium citrate| DRUG| 12495006|Magnesium citrate|12495006:::387401007:::21691008:::15531411000001106:::408...|Magnesium citrate:::Magnesium carbonate:::Magnesium trisi...| | insulin| DRUG| 67866001| Insulin|67866001:::325072002:::414515005:::39487003:::411530000::...|Insulin:::Insulin aspart:::Insulin detemir:::Insulin-cont...| +--++--+--+++ New ICD10 to ICD9 Code Mapping Pretrained Pipeline We are releasing new icd10_icd9_mapping pretrained pipeline. This pretrained pipeline maps ICD10 codes to ICD9 codes without using any text data. You’ll just feed a comma or white space-delimited ICD10 codes and it will return the corresponding ICD9 codes as a list. Example : from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;icd10_icd9_mapping&quot;, &quot;en&quot;, &quot;clinical/models&quot;) pipeline.annotate(&#39;E669 R630 J988&#39;) Results : {&#39;document&#39;: [&#39;E669 R630 J988&#39;], &#39;icd10&#39;: [&#39;E669&#39;, &#39;R630&#39;, &#39;J988&#39;], &#39;icd9&#39;: [&#39;27800&#39;, &#39;7830&#39;, &#39;5198&#39;]} Code Descriptions: | | ICD10 | Details | |:|:|:--| | 0 | E669 | Obesity | | 1 | R630 | Anorexia | | 2 | J988 | Other specified respiratory disorders | | | ICD9 | Details | |:|:|:--| | 0 | 27800 | Obesity | | 1 | 7830 | Anorexia | | 2 | 5198 | Other diseases of respiratory system | New Clinical Sentence Embedding Models We have two new clinical Sentence Embedding models. sbiobert_jsl_rxnorm_cased : This model maps sentences &amp; documents to a 768 dimensional dense vector space by using average pooling on top of BioBert model. It’s also fine-tuned on RxNorm dataset to help generalization over medication-related datasets. Example : ... sentence_embeddings = BertSentenceEmbeddings.pretrained(&quot;sbiobert_jsl_rxnorm_cased&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;sbioert_embeddings&quot;) ... sbert_jsl_medium_rxnorm_uncased : This model maps sentences &amp; documents to a 512-dimensional dense vector space by using average pooling on top of BERT model. It’s also fine-tuned on the RxNorm dataset to help generalization over medication-related datasets. Example : ... sentence_embeddings = BertSentenceEmbeddings.pretrained(&quot;sbert_jsl_medium_rxnorm_uncased&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) ... Printing Validation and Test Logs in MedicalNerApproach and AssertionDLApproach Now we can check validation loss and test loss for each epoch in the logs created during trainings of MedicalNerApproach and AssertionDLApproach. Epoch 15/15 started, lr: 9.345794E-4, dataset size: 1330 Epoch 15/15 - 56.65s - loss: 37.58828 - avg training loss: 1.7899181 - batches: 21 Quality on validation dataset (20.0%), validation examples = 266 time to finish evaluation: 8.11s Total validation loss: 15.1930 Avg validation loss: 2.5322 label tp fp fn prec rec f1 I-Disease 707 72 121 0.9075738 0.8538647 0.8799004 B-Disease 657 81 60 0.8902439 0.916318 0.90309274 tp: 1364 fp: 153 fn: 181 labels: 2 Macro-average prec: 0.89890885, rec: 0.88509136, f1: 0.8919466 Micro-average prec: 0.89914304, rec: 0.8828479, f1: 0.89092094 Quality on test dataset: time to finish evaluation: 9.11s Total test loss: 17.7705 Avg test loss: 1.6155 label tp fp fn prec rec f1 I-Disease 663 113 126 0.85438144 0.8403042 0.8472843 B-Disease 631 122 77 0.8379814 0.8912429 0.86379194 tp: 1294 fp: 235 fn: 203 labels: 2 Macro-average prec: 0.8461814, rec: 0.86577356, f1: 0.85586536 Micro-average prec: 0.8463048, rec: 0.86439544, f1: 0.8552544 Filter Only the Regex Entities Feature in Deidentification Annotator The setBlackList() method will be able to filter just the detected Regex Entities. Before this change we filtered the chunks and the regex entities. Add .setMaskingPolicy Parameter in Deidentification Annotator Now we can have three modes to mask the entities in the Deidentification annotator. You can select the modes using the .setMaskingPolicy(&quot;entity_labels&quot;). The methods are the followings: “entity_labels”: Mask with the entity type of that chunk. (default) “same_length_chars”: Mask the deid entities with same length of asterix (*) with brackets ([,]) on both end. “fixed_length_chars”: Mask the deid entities with a fixed length of asterix (*). The length is setting up using the setFixedMaskLength(4) method. Given the following sentence John Snow is a good guy. the result will be: “entity_labels”: &lt;NAME&gt; is a good guy. “same_length_chars”: [*******] is a good guy. “fixed_length_chars”: **** is a good guy. Example Masked with entity labels DATE &lt;DATE&gt;, &lt;DOCTOR&gt;, The driver&#39;s license &lt;DLN&gt;. Masked with chars DATE [**********], [***********], The driver&#39;s license [*********]. Masked with fixed length chars DATE ****, ****, The driver&#39;s license ****. Obfuscated DATE 07-04-1981, Dr Vivian Irving, The driver&#39;s license K272344712994. Add .cache_folder Parameter in UpdateModels.updateCacheModels() This parameter lets user to define custom local paths for the folder on which pretrained models are saved (rather than using default cached_pretrained folder). This cache_folder must be a path (“hdfs:..”,”file:…”). UpdateModels.updateCacheModels(&quot;file:/home/jsl/cache_pretrained_2&quot;) UpdateModels.updateModels(&quot;12/01/2021&quot;,&quot;file:/home/jsl/cache_pretrained_2&quot;) The cache folder used by default is the folder loaded in the spark configuration ` spark.jsl.settings.pretrained.cache_folder.The default value for that property is ~/cache_pretrained` S3 Access Credentials No Longer Shipped Along Licenses S3 access credentials are no longer being shipped with licenses. Going forward, we’ll use temporal S3 access credentials which will be periodically refreshed. All this will happen automatically and will be transparent to the user. Still, for those users who would need to perform manual tasks involving access to S3, there’s a mechanism to get access to the set of credentials being used by the library at any given time. from sparknlp_jsl import get_credentials get_credentials(spark) Enhanced Security for the Library and log4shell Update On top of periodical security checks on the library code, 3rd party dependencies were analyzed, and some dependencies reported as containing vulnerabilities were replaced by more secure options. Also, the library was analyzed in the context of the recently discovered threat(CVE-2021-45105) on the log4j library. Spark NLP for Healthcare does not depend on the log4j library by itself, but the library gets loaded through some of its dependencies. It’s worth noting that the version of log4j dependency that will be in the classpath when running Spark NLP for Healthcare is 1.x, which would make the system vulnerable to CVE-2021-4104, instead of CVE-2021-45105. CVE-2021-4104 is related to the JMSAppender. Spark NLP for Healthcare does not provide any log4j configuration, so it’s up to the user to follow the recommendation of avoiding the use of the JMSAppender. New Peer-Reviewed Conference Paper on Clinical Relation Extraction We publish a new peer-reviewed conference paper titled Deeper Clinical Document Understanding Using Relation Extraction explaining the applications of Relation Extraction in a text mining framework comprising of Named Entity Recognition (NER) and Relation Extraction (RE) models. The paper is accepted to SDU (Scientific Document Understanding) workshop at AAAI-2022 conference and claims new SOTA scores on 5 out of 7 Biomedical &amp; Clinical Relation Extraction (RE) tasks. Dataset FCNN BioBERT Curr-SOTA i2b2-Temporal 68.7 73.6 72.41 i2b2-Clinical 60.4 69.1 67.97 DDI 69.2 72.1 84.1 CPI 65.8 74.3 88.9 PGR 81.2 87.9 79.4 ADE Corpus 89.2 90.0 83.7 Posology 87.8 96.7 96.1 Macro-averaged F1 scores of both RE models on public datasets. FCNN refers to the Speed-Optimized FCNN architecture, while BioBERT refers to the AccuracyOptimized BioBERT architecture. The SOTA metrics are obtained from (Guan et al. 2020), (Ningthoujam et al. 2019), (Asada, Miwa, and Sasaki 2020), (Phan et al. 2021), (Sousa and Couto 2020), (Crone 2020), and (Yang et al. 2021) respectively. New Peer-Reviewed Conference Paper on Adverse Drug Events Extraction We publish a new peer-reviewed conference paper titled Mining Adverse Drug Reactions from Unstructured Mediums at Scale proposing an end-to-end Adverse Drug Event mining solution using Classification, NER, and Relation Extraction Models. The paper is accepted to W3PHIAI (INTERNATIONAL WORKSHOP ON HEALTH INTELLIGENCE) workshop at AAAI-2022 conference, and claims new SOTA scores on 1 benchmark dataset for Classification, 3 benchmark datasets for NER, and 1 benchmark dataset for Relation Extraction. Task Dataset Spark NLP Curr-SOTA Classification ADE 85.96 87.0 Classification CADEC 86.69 81.5 Entity Recognition ADE 91.75 91.3 Entity Recognition CADEC 78.36 71.9 Entity Recognition SMM4H 76.73 67.81 Relation Extraction ADE 90.0 83.7 All F1 scores are Macro-averaged New and Updated Notebooks We have two new Notebooks: Chunk Sentence Splitter Notebook that involves usage of ChunkSentenceSplitter annotator. Clinical Relation Extraction Spark NLP Paper Reproduce Notebook that can be used for reproducing the results in Deeper Clinical Document Understanding Using Relation Extraction paper. We have updated our existing notebooks by adding new features and functionalities. Here are updated notebooks: Clinical Named Entity Recognition Model Clinical Entity Resolver Models Clinical DeIdentification Clinical NER Chunk Merger Pretrained Clinical Pipelines Healthcare Code Mapping Improved Entity Resolvers in Spark NLP with sBert To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_0"
  },
  "1436": {
    "id": "1436",
    "title": "NLP Lab Release Notes 3.4.1",
    "content": "3.4.1 Release date: 05-08-2022 Annotation Lab v3.4.1 has beed released and it includes Models Hub and Visual NER bug fixes. Here are the highlights of this release: Highlights Confidence score of labels predicted by Visual NER model is now displayed in the labeling page. Missing image issues that appeared when deleting a task in Visual NER project has been fixed. Jumpy screen on annotating Visual NER tasks is resolved. Addition of new models supported in Spark NLP 4.0.0 Upgrade TensorFlow to 2.7.1 and PySpark to 3.2.0 Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_4_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_4_1"
  },
  "1437": {
    "id": "1437",
    "title": "Spark NLP for Healthcare Release Notes 3.4.1",
    "content": "3.4.1 We are glad to announce that Spark NLP Healthcare 3.4.1 has been released! Highlights Brand new Spanish deidentification NER models Brand new Spanish deidentification pretrained pipeline New clinical NER model to detect supplements New RxNorm sentence entity resolver model New EntityChunkEmbeddings annotator New MedicalBertForSequenceClassification annotator New MedicalDistilBertForSequenceClassification annotator New MedicalDistilBertForSequenceClassification and MedicalBertForSequenceClassification models Redesign of the ContextualParserApproach annotator getClasses method in RelationExtractionModel and RelationExtractionDLModel annotators Label customization feature for RelationExtractionModel and RelationExtractionDL models useBestModel parameter in MedicalNerApproach annotator Early stopping feature in MedicalNerApproach annotator Multi-Language support for faker and regex lists of Deidentification annotator Spark 3.2.0 compatibility for the entire library Saving visualization feature in spark-nlp-display library Deploying a custom Spark NLP image (for opensource, healthcare, and Spark OCR) to an enterprise version of Kubernetes: OpenShift New speed benchmarks table on databricks New &amp; Updated Notebooks List of recently updated or added models Brand New Spanish Deidentification NER Models We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in Spanish. ner_deid_generic and ner_deid_subentity models are trained with in-house annotations. Both also are available for using Roberta Spanish Clinical Embeddings and sciwiki 300d. ner_deid_generic : Detects 7 PHI entities in Spanish (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID). ner_deid_subentity : Detects 13 PHI sub-entities in Spanish (PATIENT, HOSPITAL, DATE, ORGANIZATION, E-MAIL, USERNAME, LOCATION, ZIP, MEDICALRECORD, PROFESSION, PHONE, DOCTOR, AGE). Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_sciwiki_300d&quot;,&quot;es&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... text = &quot;&quot;&quot;Antonio Pérez Juan, nacido en Cadiz, España. Aún no estaba vacunado, se infectó con Covid-19 el dia 14/03/2020 y tuvo que ir al Hospital. Fue tratado con anticuerpos monoclonales en la Clinica San Carlos..&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results : | chunk | ner_deid_generic_chunk | ner_deid_subentity_chunk | |--||--| | Antonio Pérez Juan | NAME | PATIENT | | Cádiz | LOCATION | LOCATION | | España | LOCATION | LOCATION | | 14/03/2022 | DATE | DATE | | Clínica San Carlos | LOCATION | HOSPITAL | Brand New Spanish Deidentification Pretrained Pipeline We developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from Spanish medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask, fake or obfuscate the following entities: AGE, DATE, PROFESSION, E-MAIL, USERNAME, LOCATION, DOCTOR, HOSPITAL, PATIENT, URL, IP, MEDICALRECORD, IDNUM, ORGANIZATION, PHONE, ZIP, ACCOUNT, SSN, PLATE, SEX and IPADDR. from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;es&quot;, &quot;clinical/models&quot;) sample_text = &quot;&quot;&quot;Datos del paciente. Nombre: Jose . Apellidos: Aranda Martinez. NHC: 2748903. NASS: 26 37482910.&quot;&quot;&quot; result = deid_pipe.annotate(text) print(&quot; n&quot;.join(result[&#39;masked&#39;])) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) Results: Masked with entity labels Datos del paciente. Nombre: &lt;PATIENT&gt; . Apellidos: &lt;PATIENT&gt;. NHC: &lt;SSN&gt;. NASS: &lt;SSN&gt; &lt;SSN&gt; Masked with chars Datos del paciente. Nombre: [**] . Apellidos: [*************]. NHC: [*****]. NASS: [**] [******] Masked with fixed length chars Datos del paciente. Nombre: **** . Apellidos: ****. NHC: ****. NASS: **** **** Obfuscated Datos del paciente. Nombre: Sr. Lerma . Apellidos: Aristides Gonzalez Gelabert. NHC: BBBBBBBBQR648597. NASS: 041010000011 RZRM020101906017 04. New Clinical NER Model to Detect Supplements We are releasing ner_supplement_clinical model that can extract benefits of using drugs for certain conditions. It can label detected entities as CONDITION and BENEFIT. Also this model is trained on the dataset that is released by Spacy in their HealthSea product. Here is the benchmark comparison of both versions: Entity Spark NLP Spacy-HealthSea BENEFIT 0.8729641 0.8330684 CONDITION 0.8339274 0.8333333 Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_supplement_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Excellent!. The state of health improves, nervousness disappears, and night sleep improves. It also promotes hair and nail growth.&quot;]], [&quot;text&quot;])) Results : +++ | chunk | ner_label | +++ | nervousness | CONDITION | | night sleep improves | BENEFIT | | hair | BENEFIT | | nail | BENEFIT | +++ New RxNorm Sentence Entity Resolver Model sbiobertresolve_rxnorm_augmented_re : This model maps clinical entities and concepts (like drugs/ingredients) to RxNorm codes without specifying the relations between the entities (relations are calculated on the fly inside the annotator) using sbiobert_base_cased_mli Sentence Bert Embeddings (EntityChunkEmbeddings). Example : ... rxnorm_resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_rxnorm_augmented_re&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;entity_chunk_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... New EntityChunkEmbeddings Annotator We have a new EntityChunkEmbeddings annotator to compute a weighted average vector representing entity-related vectors. The model’s input usually consists of chunks of recognized named entities produced by MedicalNerModel. We can specify relations between the entities by the setTargetEntities() parameter, and the internal Relation Extraction model finds related entities and creates a chunk. Embedding for the chunk is calculated according to the weights specified in the setEntityWeights() parameter. For instance, the chunk warfarin sodium 5 MG Oral Tablet has DRUG, STRENGTH, ROUTE, and FORM entity types. Since DRUG label is the most prominent label for resolver models, now we can assign weight to prioritize DRUG label (i.e {&quot;DRUG&quot;: 0.8, &quot;STRENGTH&quot;: 0.2, &quot;ROUTE&quot;: 0.2, &quot;FORM&quot;: 0.2} as shown below). In other words, embeddings of these labels are multipled by the assigned weights such as DRUG by 0.8. For more details and examples, please check Sentence Entity Resolvers with EntityChunkEmbeddings Notebook in the Spark NLP workshop repo. Example : ... drug_chunk_embeddings = EntityChunkEmbeddings() .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;drug_chunk_embeddings&quot;) .setMaxSyntacticDistance(3) .setTargetEntities({&quot;DRUG&quot;: [&quot;STRENGTH&quot;, &quot;ROUTE&quot;, &quot;FORM&quot;]}) .setEntityWeights({&quot;DRUG&quot;: 0.8, &quot;STRENGTH&quot;: 0.2, &quot;ROUTE&quot;: 0.2, &quot;FORM&quot;: 0.2}) rxnorm_resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_rxnorm_augmented_re&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;drug_chunk_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) rxnorm_weighted_pipeline_re = Pipeline( stages = [ documenter, sentence_detector, tokenizer, embeddings, posology_ner_model, ner_converter, pos_tager, dependency_parser, drug_chunk_embeddings, rxnorm_resolver]) sampleText = [&quot;The patient was given metformin 500 mg, 2.5 mg of coumadin and then ibuprofen.&quot;, &quot;The patient was given metformin 400 mg, coumadin 5 mg, coumadin, amlodipine 10 MG&quot;] data_df = spark.createDataFrame(sample_df) results = rxnorm_weighted_pipeline_re.fit(data_df).transform(data_df) The internal relation extraction creates the chunks here, and the embedding is computed according to the weights. Results : +--+-+--+--+ |index| chunk|rxnorm_code_weighted_08_re| Concept_Name| +--+-+--+--+ | 0|metformin 500 mg| 860974|metformin hydrochloride 500 MG:::metformin 500 ...| | 0| 2.5 mg coumadin| 855313|warfarin sodium 2.5 MG [Coumadin]:::warfarin so...| | 0| ibuprofen| 1747293|ibuprofen Injection:::ibuprofen Pill:::ibuprofe...| | 1|metformin 400 mg| 332809|metformin 400 MG:::metformin 250 MG Oral Tablet...| | 1| coumadin 5 mg| 855333|warfarin sodium 5 MG [Coumadin]:::warfarin sodi...| | 1| coumadin| 202421|Coumadin:::warfarin sodium 2 MG/ML Injectable S...| | 1|amlodipine 10 MG| 308135|amlodipine 10 MG Oral Tablet:::amlodipine 10 MG...| +--+-+--+--+ New MedicalBertForSequenceClassification Annotator We developed a new annotator called MedicalBertForSequenceClassification. It can load BERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. New MedicalDistilBertForSequenceClassification Annotator We developed a new annotator called MedicalDistilBertForSequenceClassification. It can load DistilBERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. New MedicalDistilBertForSequenceClassification and MedicalBertForSequenceClassification Models We are releasing a new MedicalDistilBertForSequenceClassification model and three new MedicalBertForSequenceClassification models. bert_sequence_classifier_ade_biobert: a classifier for detecting if a sentence is talking about a possible ADE (TRUE, FALSE) bert_sequence_classifier_gender_biobert: a classifier for detecting the gender of the main subject of the sentence (MALE, FEMALE, UNKNOWN) bert_sequence_classifier_pico_biobert: a classifier for detecting the class of a sentence according to PICO framework (CONCLUSIONS, DESIGN_SETTING,INTERVENTION, PARTICIPANTS, FINDINGS, MEASUREMENTS, AIMS) Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_pico&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) ... sample_text = &quot;To compare the results of recording enamel opacities using the TF and modified DDE indices.&quot; result = sequence_clf_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +-+--+ |text |label| +-+--+ |To compare the results of recording enamel opacities using the TF and modified DDE indices.|AIMS | +-+--+ distilbert_sequence_classifier_ade : This model is a DistilBertForSequenceClassification model for classifying clinical texts whether they contain ADE (TRUE, FALSE). Example : ... sequenceClassifier = MedicalDistilBertForSequenceClassification .pretrained(&#39;distilbert_sequence_classifier_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&#39;token&#39;, &#39;document&#39;]) .setOutputCol(&#39;class&#39;) ... sample_text = &quot;I felt a bit drowsy and had blurred vision after taking Aspirin.&quot; result = sequence_clf_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +-+--+ |text |label| +-+--+ |I felt a bit drowsy and had blurred vision after taking Aspirin.| True| +-+--+ Redesign of the ContextualParserApproach Annotator We’ve dropped the annotator’s contextMatch parameter and removed the need for a context field when feeding a JSON configuration file to the annotator. Context information can now be fully defined using the prefix, suffix and contextLength fields in the JSON configuration file. We’ve also fixed issues with the contextException field in the JSON configuration file - it was mismatching values in documents with several sentences and ignoring exceptions situated to the right of a word/token. The ruleScope field in the JSON configuration file can now be set to document instead of sentence. This allows you to match multi-word entities like “New York” or “Salt Lake City”. You can do this by setting &quot;ruleScope&quot; : &quot;document&quot; in the JSON configuration file and feeding a dictionary (csv or tsv) to the annotator with its setDictionary parameter. These changes also mean that we’ve dropped the updateTokenizer parameter since the new capabilities of ruleScope improve the user experience for matching multi-word entities. You can now feed in a dictionary in your chosen format - either vertical or horizontal. You can set that with the following parameter: setDictionary(&quot;dictionary.csv&quot;, options={&quot;orientation&quot;:&quot;vertical&quot;}) Lastly, there was an improvement made to the confidence value calculation process to better measure successful hits. For more explanation and examples, please check this Contextual Parser medium article and Contextual Parser Notebook. getClasses Method in RelationExtractionModel and RelationExtractionDLModel Annotators Now you can use getClasses() method for checking the relation labels of RE models (RelationExtractionModel and RelationExtractionDLModel) like MedicalNerModel(). Example : clinical_re_Model = RelationExtractionModel() .pretrained(&quot;re_temporal_events_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) clinical_re_Model.getClasses() Output : [&#39;OVERLAP&#39;, &#39;BEFORE&#39;, &#39;AFTER&#39;] Label Customization Feature for RelationExtractionModel and RelationExtractionDL Models We are releasing label customization feature for Relation Extraction and Relation Extraction DL models by using .setCustomLabels() parameter. Example : ... reModel = RelationExtractionModel.pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(10) .setRelationPairs([&quot;drug-ade, ade-drug&quot;]) .setCustomLabels({&quot;1&quot;: &quot;is_related&quot;, &quot;0&quot;: &quot;not_related&quot;}) redl_model = RelationExtractionDLModel.pretrained(&#39;redl_ade_biobert&#39;, &#39;en&#39;, &quot;clinical/models&quot;) .setPredictionThreshold(0.5) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) .setCustomLabels({&quot;1&quot;: &quot;is_related&quot;, &quot;0&quot;: &quot;not_related&quot;}) ... sample_text = &quot;I experienced fatigue and muscle cramps after taking Lipitor but no more adverse after passing Zocor.&quot; result = model.transform(spark.createDataFrame([[sample_text]]).toDF(&#39;text&#39;)) Results : +--+-+-+-+-+-+ | relation|entity1| chunk1|entity2| chunk2|confidence| +--+-+-+-+-+-+ | is_related| ADE| fatigue| DRUG|Lipitor| 0.9999825| |not_related| ADE| fatigue| DRUG| Zocor| 0.9960077| | is_related| ADE|muscle cramps| DRUG|Lipitor| 1.0| |not_related| ADE|muscle cramps| DRUG| Zocor| 0.94971| +--+-+-+-+-+-+ useBestModel Parameter in MedicalNerApproach Annotator Introducing useBestModel param in MedicalNerApproach annotator. This param preserves and restores the model that has achieved the best performance at the end of the training. The priority is metrics from testDataset (micro F1), metrics from validationSplit (micro F1), and if none is set it will keep track of loss during the training. Example : med_ner = MedicalNerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) ... ... .setUseBestModel(True) Early Stopping Feature in MedicalNerApproach Annotator Introducing earlyStopping feature for MedicalNerApproach(). You can stop training at the point when the perforfmance on test/validation dataset starts to degrage. Two params are added to MedicalNerApproach() in order to use this feature: earlyStoppingCriterion : (float) This is used set the minimal improvement of the test metric to terminate training. The metric monitored is the same as the metrics used in useBestModel (macro F1 when using test/validation set, loss otherwise). Default is 0 which means no early stopping is applied. earlyStoppingPatience: (int), the number of epoch without improvement which will be tolerated. Default is 0, which means that early stopping will occur at the first time when performance in the current epoch is no better than in the previous epoch. Example : med_ner = MedicalNerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) ... ... .setTestDataset(test_data_parquet_path) .setEarlyStoppingCriterion(0.01) .setEarlyStoppingPatience(3) Multi-Language Support for Faker and Regex Lists of Deidentification Annotator We have a new .setLanguage() parameter in order to use internal Faker and Regex list for multi-language texts. When you are working with German and Spanish texts for a Deidentification, you can set this parameter to de for German and es for Spanish. Default value of this parameter is en. Example : deid_obfuscated = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;obfuscated&quot;) .setMode(&quot;obfuscate&quot;) .setLanguage(&#39;de&#39;) .setObfuscateRefSource(&quot;faker&quot;) Spark 3.2.0 Compatibility for the Entire Library Now we can use the Spark 3.2.0 version for Spark NLP for Healthcare by setting spark32=True in sparknlp_jsl.start() function. ! pip install --ignore-installed -q pyspark==3.2.0 import sparknlp_jsl spark = sparknlp_jsl.start(SECRET, spark32=True) Saving Visualization Feature in spark-nlp-display Library We have a new save_path parameter in spark-nlp-display library for saving any visualization results in Spark NLP. Example : from sparknlp_display import NerVisualizer visualiser = NerVisualizer() visualiser.display(light_result[0], label_col=&#39;ner_chunk&#39;, document_col=&#39;document&#39;, save_path=&quot;display_result.html&quot;) Deploying a Custom Spark NLP Image (for opensource, healthcare, and Spark OCR) to an Enterprise Version of Kubernetes: OpenShift Spark NLP for opensource, healthcare, and SPARK OCR is now available for Openshift - enterprise version of Kubernetes. For deployment, please refer to: Github Link: https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/platforms/openshift Youtube: https://www.youtube.com/watch?v=FBes-6ylFrM&amp;ab_channel=JohnSnowLabs New Speed Benchmarks Table on Databricks We prepared a speed benchmark table by running a clinical BERT For Token Classification model pipeline on various number of repartitioning and writing the results to parquet or delta formats. You can find the details here : Clinical Bert For Token Classification Benchmark Experiment. New &amp; Updated Notebooks We have updated our existing workshop notebooks with v3.4.0 by adding new features and functionalities. You can find the workshop notebooks updated with previous versions in the branches named with the relevant version. We have updated the ContextualParser Notebook with the new updates in this version. We have a new Sentence Entity Resolvers with EntityChunkEmbeddings Notebook for the new EntityChunkEmbeddings annotator. To see more, please check : Spark NLP Healthcare Workshop Repo List of Recently Updated or Added Models bert_sequence_classifier_ade_en bert_sequence_classifier_gender_biobert_en bert_sequence_classifier_pico_biobert_en distilbert_sequence_classifier_ade_en bert_token_classifier_ner_supplement_en deid_pipeline_es ner_deid_generic_es ner_deid_generic_roberta_es ner_deid_subentity_es ner_deid_subentity_roberta_es ner_nature_nero_clinical_en ner_supplement_clinical_en sbiobertresolve_clinical_abbreviation_acronym_en sbiobertresolve_rxnorm_augmented_re For all Spark NLP for healthcare models, please check : Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_1"
  },
  "1438": {
    "id": "1438",
    "title": "Spark NLP for Healthcare Release Notes 3.4.2",
    "content": "3.4.2 We are glad to announce that Spark NLP Healthcare 3.4.2 has been released! Highlights New RCT Classifier, NER models and pipeline (Deidentification) Setting the scope window (target area) dynamically in Assertion Status detection models Reading JSON files (exported from ALAB) from HDFS with AnnotationJsonReader Allow users to write Tensorflow graphs to HDFS Serving Spark NLP on APIs Updated documentation on installing Spark NLP for Healthcare in AWS EMR (Jupyter, Livy, Yarn, Hadoop) New series of notebooks to reproduce the academic papers published by our colleagues PySpark tutorial notebooks to let non-Spark users get started with Apache Spark ecosystem in Python New &amp; updated notebooks List of recently updated or added models New RCT Classifier, NER Models and Pipeline (Deidentification) We are releasing a new bert_sequence_classifier_rct_biobert model, four new Spanish deidentification NER models (ner_deid_generic_augmented, ner_deid_subentity_augmented, ner_deid_generic_roberta_augmented, ner_deid_subentity_roberta_augmented) and a pipeline (clinical_deidentification_augmented). bert_sequence_classifier_rct_biobert: This model can classify the sections within abstract of scientific articles regarding randomized clinical trials (RCT) (BACKGROUND, CONCLUSIONS, METHODS, OBJECTIVE, RESULTS). Example : ... sequenceClassifier_model = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_rct_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&#39;token&#39;]) .setOutputCol(&quot;class&quot;) ... sample_text = &quot;Previous attempts to prevent all the unwanted postoperative responses to major surgery with an epidural hydrophilic opioid , morphine , have not succeeded . The authors &#39; hypothesis was that the lipophilic opioid fentanyl , infused epidurally close to the spinal-cord opioid receptors corresponding to the dermatome of the surgical incision , gives equal pain relief but attenuates postoperative hormonal and metabolic responses more effectively than does systemic fentanyl .&quot; result = sequence_clf_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) &gt;&gt; class: &#39;BACKGROUND&#39; ner_deid_generic_augmented, ner_deid_subentity_augmented, ner_deid_generic_roberta_augmented, ner_deid_subentity_roberta_augmented models and clinical_deidentification_augmented pipeline : You can use either sciwi-embeddings (300 dimensions) or the Roberta Clinical Embeddings (infix _roberta_) with these NER models. These models and pipeline are different to their non-augmented versions in the following: They are trained with more data, now including an in-house annotated deidentification dataset; New SEX tag is available for all of them. This tag is now included in the NER and has been improved with more rules in the ContextualParsers of the pipeline, resulting in having a bigger recall to detect the sex of the patient. New STREET, CITY and COUNTRY entities are added to subentity versions. For more details and examples, please check Clinical Deidentification in Spanish notebook. Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_sciwiki_300d&quot;,&quot;es&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic_augmented&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... Results : chunk entity_subentity entity_generic -- - Antonio Miguel Martínez PATIENT NAME un varón SEX SEX 35 AGE AGE auxiliar de enfermería PROFESSION PROFESSION Cadiz CITY LOCATION España COUNTRY LOCATION Clinica San Carlos HOSPITAL LOCATION Setting the Scope Window (Target Area) Dynamically in Assertion Status Detection Models This parameter allows you to train the Assertion Status Models to focus on specific context windows when resolving the status of a NER chunk. The window is in format [X,Y] being X the number of tokens to consider on the left of the chunk, and Y the max number of tokens to consider on the right. Let’s take a look at what different windows mean: By default, the window is [-1,-1] which means that the Assertion Status will look at all of the tokens in the sentence/document (up to a maximum of tokens set in setMaxSentLen()). [0,0] means “don’t pay attention to any token except the ner_chunk”, what basically is not considering any context for the Assertion resolution. [9,15] is what empirically seems to be the best baseline, meaning that we look up to 9 tokens on the left and 15 on the right of the ner chunk to understand the context and resolve the status. Check this scope window tuning assertion status detection notebook that illustrates the effect of the different windows and how to properly fine-tune your AssertionDLModels to get the best of them. Example : assertion_status = AssertionDLApproach() .setGraphFolder(&quot;assertion_dl/&quot;) .setInputCols(&quot;sentence&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) ... ... .setScopeWindow([9, 15]) # NEW! Scope Window! Reading JSON Files (Exported from ALAB) From HDFS with AnnotationJsonReader Now we can read the dataframe from a HDFS that we read the files from in our cluster. Example : filename = &quot;hdfs:///user/livy/import.json&quot; reader = AnnotationToolJsonReader(assertion_labels = [&#39;AsPresent&#39;, &#39;AsAbsent&#39;, &#39;AsConditional&#39;, &#39;AsHypothetical&#39;, &#39;Family&#39;, &#39;AsPossible&#39;, &#39;AsElse&#39;]) df = reader.readDataset(spark, filename) Allow Users Write Tensorflow Graphs to HDFS Now we can save custom Tensorflow graphs to the HDFS that mainly being used in a cluster environment. tf_graph.build(&quot;ner_dl&quot;, build_params={&quot;embeddings_dim&quot;: 200, &quot;nchars&quot;: 128, &quot;ntags&quot;: 12, &quot;is_medical&quot;: 1}, model_location=&quot;hdfs:///user/livy&quot;, model_filename=&quot;auto&quot;) Serving Spark NLP on APIs Two new notebooks and a series of blog posts / Medium articles have been created to guide Spark NLP users to serve Spark NLP on a RestAPI. The notebooks can be found here. The articles can be found in the Technical Documentation of Spark NLP, available here and also in Medium: Serving Spark NLP via API (1/3): Microsoft’s Synapse ML Serving Spark NLP via API (2/3): FastAPI and LightPipelines Serving Spark NLP via API (3/3): Databricks Jobs and MLFlow Serve APIs The difference between both approaches are the following: SynapseML is a Microsoft Azure Open Source library used to carry out ML at scale. In this case, we use the Spark Serving feature, that leverages Spark Streaming and adds a web server with a Load Balancer, allowing concurrent processing of Spark NLP calls. Best approach if you look for scalability with Load Balancing. FastAPI + LightPipelines: A solution to run Spark NLP using a FastAPI webserver. It uses LightPipelines, what means having a very good performance but not leveraging Spark Clusters. Also, no Load Balancer is available in the suggestion, but you can create your own. Best approach if you look for performance. Databricks and MLFlow: Using MLFlow Serve or Databricks Jobs APIs to serve for inference Spark NLP pipelines from within Databricks. Best approach if you look for scalability within Databricks. Updated Documentation on Installing Spark NLP For Healthcare in AWS EMR (Jupyter, Livy, Yarn, Hadoop) Ready-to-go Spark NLP for Healthcare environment in AWS EMR. Full instructions are here. New Series of Notebooks to Reproduce the Academic Papers Published by Our Colleagues You can find all these notebooks here PySpark Tutorial Notebooks to Let Non-Spark Users to Get Started with Apache Spark Ecosystem in Python John Snow Labs has created a series of 8 notebooks to go over PySpark from zero to hero. Notebooks cover PySpark essentials, DataFrame creation, querying, importing data from different formats, functions / udfs, Spark MLLib examples (regression, classification, clustering) and Spark NLP best practises (usage of parquet, repartition, coalesce, custom annotators, etc). You can find all these notebooks here. New &amp; Updated Notebooks Series of academic notebooks : A new series of academic paper notebooks, available here Clinical_Deidentification_in_Spanish.ipynb: A notebook showcasing Clinical Deidentification in Spanish, available here. Clinical_Deidentification_Comparison.ipynb: A new series of comparisons between different Deidentification libraries. So far, it contains Spark NLP for Healthcare and ScrubaDub with Spacy Transformers. Available here. Scope_window_tuning_assertion_status_detection.ipynb: How to finetune Assertion Status using the Scope Window. Available here Clinical_Longformer_vs_BertSentence_&amp;_USE.ipynb: A Comparison of how Clinical Longformer embeddings, averaged by the Sentence Embeddings annotator, performs compared to BioBert and UniversalSentenceEncoding. Link here. Serving_SparkNLP_with_Synapse.ipynb: Serving SparkNLP for production purposes using Synapse ML. Available here Serving_SparkNLP_with_FastAPI_and_LP.ipynb: Serving SparkNLP for production purposes using FastAPI, RestAPI and LightPipelines. Available here Series of PySpark tutorial notebooks: Available here List of Recently Updated or Added Models sbiobertresolve_hcpcs bert_sequence_classifier_rct_biobert ner_deid_generic_augmented_es ner_deid_subentity_augmented_es ner_deid_generic_roberta_augmented_es ner_deid_subentity_roberta_augmented_es clinical_deidentification_augmented_es For all Spark NLP for healthcare models, please check : Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_2"
  },
  "1439": {
    "id": "1439",
    "title": "NLP Lab Release Notes 3.5.0",
    "content": "3.5.0 Release date: 25-08-2022 Annotation Lab 3.5.0 add support for out-of-the-box usage of Multilingual Models as well as support for some of the European Language Models: Romanian, Portuguese, Danish and Italian. It also provides support for split dataset using Test/Train tags in classification project and allows NER pretrained models evaluation with floating license. The release also includes fixes for known security vulnerabilities and for some bug reported by our user community. Here are the highlights of this release: Highlights Support for Multilingual Models. Previously, only multilingual embeddings were available in Models Hub page. A new language filter has been added to the Models hub page to make searching for all available multilingual models and embeddings more efficient. User can select the target language and then explore the set of relevant multilingual models and embeddings. Expended Support for European Language Models. Annotation Lab now offers support for four new European languages Romanian, Portuguese, Italian, and Danish, on top of English, Spanish, and German, already supported in previous versions. Many pretrained models in those languages are now available to download from the NLP Models Hub and easily use to preannotate documents on the Annotation Lab. Use Test/Train Tags for Classification Training Experiments. The Test/Train split of annotated tasks can be used when training classification models. When this option is checked on the Training Settings, all tasks that have the Test tag are used as test datasets. All tasks tagged as Train together with all other non Test tasks will be used as a training dataset. NER Model Evaluation available for Floating License. Project Owner and/or Manager can evaluate pretrained NER models against a set of annotated tasks in the presence of floating licenses. Earlier, this feature was only available in the presence of airgap licenses. Chunks preannotation in VisualNER. Annotation Lab 3.4.0 which first published the visual NER preannotation and visual NER model training could only create token level preannotations. With version 3.5.0, individual tokens are combined into one chunk entity and shown as merged to the user. Benchmarking Information for Models Trained with Annotation Lab. With version 3.5.0 benchmarking information is available for models trained within Annotation Lab. User can go to the Available Models Tab of the Models Hub page and view the benchmarking data by clicking the small graph icon next to the model. Configuration for Annotation Lab Deployment. The resources allocated to Annotation Lab deployment can be configured via the resource values in the annotationlab-updater.sh. The instruction to change the parameters are available in the instruction.md file. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_5_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_5_0"
  },
  "1440": {
    "id": "1440",
    "title": "Spark NLP release notes 3.5.0",
    "content": "3.5.0 Release date: 15-07-2021 Overview Improve table detection and table recognition. More details please read in Extract Tabular Data from PDF in Spark OCR New Features Added new method to ImageTableCellDetector which support borderless tables and combined tables. Added Wolf and Singh adaptive binarization methods to the ImageAdaptiveThresholding. Enhancements Added possibility to use different type of images as input for ImageTableDetector. Added display_pdf and display_images_horizontal util functions. New notebooks Tables Recognition from PDF Pdf de-identification on Databricks Dicom de-identification on Databricks Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_5_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_5_0"
  },
  "1441": {
    "id": "1441",
    "title": "Spark NLP for Healthcare Release Notes 3.5.0",
    "content": "3.5.0 We are glad to announce that Spark NLP Healthcare 3.5.0 has been released! Highlights Zero-shot Relation Extraction to extract relations between clinical entities with no training dataset Deidentification: New French Deidentification NER models and pipeline New Italian Deidentification NER models and pipeline Check our reference table for French and Italian deidentification metrics Added French support to the “fake” generation of data (aka data obfuscation) in the Deidentification annotator Deidentification benchmark: Spark NLP vs Cloud Providers (AWS, Azure, GCP) Graph generation: ChunkMapperApproach to augment NER chunks extracted by Spark NLP with a custom graph-like dictionary of relationships New Relation Extraction features: Configuration of case sensitivity in the name of the relations in Relation Extraction Models Models and Demos: We have reached 600 clinical models and pipelines, what sums up to 5000+ overall models in Models Hub! Check our new live demos including multilanguage deidentification to anonymize clinical notes in 5 different languages Generate Dataframes to train Assertion Status models using JSON Files exported from Annotation Lab (ALAB) Guide about how to scale from PoC to Production using Spark NLP for Healthcare in our new Medium Article, available here Core improvements: Contextual Parser (our Rule-based NER annotator) is now much more performant! Bug fixing and compatibility additions affecting and improving some behaviours of AssertionDL, BertSentenceChunkEmbeddings, AssertionFilterer and EntityRulerApproach New notebooks: zero-shot relation extraction and Deidentification benchmark vs Cloud Providers Zero-shot Relation Extraction to extract relations between clinical entities with no training dataset This release includes a zero-shot relation extraction model that leverages BertForSequenceClassificaiton to return, based on a predefined set of relation candidates (including no-relation / O), which one has the higher probability to be linking two entities. The dataset will be a csv which contains the following columns: sentence, chunk1, firstCharEnt1, lastCharEnt1, label1, chunk2, firstCharEnt2, lastCharEnt2, label2, rel. For example, let’s take a look at this dataset (columns chunk1, rel, chunk2 and sentence): +-+-+-+--+ | chunk1 | rel | chunk2 | sentence | |-+-+-+--| | light-headedness | PIP | diaphoresis | She states this light-headedness is often associated with shortness of breath and diaphoresis occasionally with nausea . | | respiratory rate | O | saturation | VITAL SIGNS - Temp 98.8 , pulse 60 , BP 150/94 , respiratory rate 18 , and saturation 96% on room air . | | lotions | TrNAP | incisions | No lotions , creams or powders to incisions . | | abdominal ultrasound | TeRP | gallbladder sludge | Abdominal ultrasound on 2/23/00 - This study revealed gallbladder sludge but no cholelithiasis . | | ir placement of a drainage catheter | TrAP | his abdominopelvic fluid collection | At that time he was made NPO with IVF , placed on Ampicillin / Levofloxacin / Flagyl and underwent IR placement of a drainage catheter for his abdominopelvic fluid collection | +-+-+-+--+ The relation types (TeRP, TrAP, PIP, TrNAP, etc…) are described here Let’s take a look at the first sentence! She states this light-headedness is often associated with shortness of breath and diaphoresis occasionally with nausea As we see in the table, the sentences includes a PIP relationship (Medical problem indicates medical problem), meaning that in that sentence, chunk1 (light-headedness) indicates chunk2 (diaphoresis). We set a list of candidates tags ([PIP, TrAP, TrNAP, TrWP, O]) and candidate sentences ([light-headedness caused diaphoresis, light-headedness was administered for diaphoresis, light-headedness was not given for diaphoresis, light-headedness worsened diaphoresis]), meaning that: PIP is expressed by light-headedness caused diaphoresis TrAP is expressed by light-headedness was administered for diaphoresis TrNAP is expressed by light-headedness was not given for diaphoresis TrWP is expressed by light-headedness worsened diaphoresis or something generic, like O is expressed by light-headedness and diaphoresis… We will get that the biggest probability of is PIP, since it’s phrase light-headedness caused diaphoresis is the most similar relationship expressing the meaning in the original sentence (light-headnedness is often associated with ... and diaphoresis) The example code is the following: ... re_ner_chunk_filter = sparknlp_jsl.annotator.RENerChunksFilter() .setRelationPairs([&quot;problem-test&quot;,&quot;problem-treatment&quot;]) .setMaxSyntacticDistance(4) .setDocLevelRelations(False) .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) # The relations are defined by a map- keys are relation label, values are lists of predicated statements. The variables in curly brackets are NER entities, there could be more than one, e.g. &quot; improves &quot; re_model = sparknlp_jsl.annotator.ZeroShotRelationExtractionModel .pretrained(&quot;re_zeroshot_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setRelationalCategories({ &quot;CURE&quot;: [&quot; cures .&quot;], &quot;IMPROVE&quot;: [&quot; improves .&quot;, &quot; cures .&quot;], &quot;REVEAL&quot;: [&quot; reveals .&quot;]}) .setMultiLabel(False) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) pipeline = sparknlp.base.Pipeline() .setStages([documenter, tokenizer, sentencer, words_embedder, pos_tagger, ner_tagger, ner_converter, dependency_parser, re_ner_chunk_filter, re_model]) data = spark.createDataFrame( [[&quot;Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer.&quot;]] ).toDF(&quot;text&quot;) model = pipeline.fit(data) results = model.transform(data) results .selectExpr(&quot;explode(relations) as relation&quot;) .show(truncate=False) Results: +-+ |relation | +-+ |{category, 534, 613, REVEAL, {entity1_begin -&gt; 48, relation -&gt; REVEAL, hypothesis -&gt; An MRI test reveals cancer., confidence -&gt; 0.9760039, nli_prediction -&gt; entail, entity1 -&gt; TEST, syntactic_distance -&gt; 4, chunk2 -&gt; cancer, entity2_end -&gt; 85, entity1_end -&gt; 58, entity2_begin -&gt; 80, entity2 -&gt; PROBLEM, chunk1 -&gt; An MRI test, sentence -&gt; 1}, []} | |{category, 267, 357, IMPROVE, {entity1_begin -&gt; 0, relation -&gt; IMPROVE, hypothesis -&gt; Paracetamol improves sickness., confidence -&gt; 0.98819494, nli_prediction -&gt; entail, entity1 -&gt; TREATMENT, syntactic_distance -&gt; 3, chunk2 -&gt; sickness, entity2_end -&gt; 45, entity1_end -&gt; 10, entity2_begin -&gt; 38, entity2 -&gt; PROBLEM, chunk1 -&gt; Paracetamol, sentence -&gt; 0}, []}| |{category, 0, 90, IMPROVE, {entity1_begin -&gt; 0, relation -&gt; IMPROVE, hypothesis -&gt; Paracetamol improves headache., confidence -&gt; 0.9929625, nli_prediction -&gt; entail, entity1 -&gt; TREATMENT, syntactic_distance -&gt; 2, chunk2 -&gt; headache, entity2_end -&gt; 33, entity1_end -&gt; 10, entity2_begin -&gt; 26, entity2 -&gt; PROBLEM, chunk1 -&gt; Paracetamol, sentence -&gt; 0}, []} | +-+ Take a look at the example notebook here. Stay tuned for the few-shot Annotator to be release soon! New French Deidentification NER models and pipeline We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in French. ner_deid_generic and ner_deid_subentity models are trained with in-house annotations. ner_deid_generic : Detects 7 PHI entities in French (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID). ner_deid_subentity : Detects 15 PHI sub-entities in French (PATIENT, HOSPITAL, DATE, ORGANIZATION, E-MAIL, USERNAME, ZIP, MEDICALRECORD, PROFESSION, PHONE, DOCTOR, AGE, STREET, CITY, COUNTRY). Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;, &quot;fr&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;fr&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;fr&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... text = &quot;&quot;&quot;J&#39;ai vu en consultation Michel Martinez (49 ans) adressé au Centre Hospitalier De Plaisir pour un diabète mal contrôlé avec des symptômes datant de Mars 2015.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results : | chunk | ner_deid_generic_chunk | ner_deid_subentity_chunk | |-||--| | Michel Martinez | NAME | PATIENT | | 49 ans | AGE | AGE | | Centre Hospitalier De Plaisir | LOCATION | HOSPITAL | | Mars 2015 | DATE | DATE | We also developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from French medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate the following entities: DATE, AGE, SEX, PROFESSION, ORGANIZATION, PHONE, E-MAIL, ZIP, STREET, CITY, COUNTRY, PATIENT, DOCTOR, HOSPITAL, MEDICALRECORD, SSN, IDNUM, ACCOUNT, PLATE, USERNAME, URL, and IPADDR. from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;fr&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;PRENOM : Jean NOM : Dubois NUMÉRO DE SÉCURITÉ SOCIALE : 1780160471058 ADRESSE : 18 Avenue Matabiau VILLE : Grenoble CODE POSTAL : 38000&quot;&quot;&quot; result = deid_pipeline.annotate(text) Results: Masked with entity labels PRENOM : &lt;PATIENT&gt; NOM : &lt;PATIENT&gt; NUMÉRO DE SÉCURITÉ SOCIALE : &lt;SSN&gt; ADRESSE : &lt;STREET&gt; VILLE : &lt;CITY&gt; CODE POSTAL : &lt;ZIP&gt; Masked with chars PRENOM : [**] NOM : [****] NUMÉRO DE SÉCURITÉ SOCIALE : [***********] ADRESSE : [****************] VILLE : [******] CODE POSTAL : [***] Masked with fixed length chars PRENOM : **** NOM : **** NUMÉRO DE SÉCURITÉ SOCIALE : **** ADRESSE : **** VILLE : **** CODE POSTAL : **** Obfuscated PRENOM : Mme Olivier NOM : Mme Traore NUMÉRO DE SÉCURITÉ SOCIALE : 164033818514436 ADRESSE : 731, boulevard de Legrand VILLE : Sainte Antoine CODE POSTAL : 37443 New Italian Deidentification NER models and pipeline We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in Italian. ner_deid_generic and ner_deid_subentity models are trained with in-house annotations. ner_deid_generic : Detects 8 PHI entities in Italian (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID, SEX). ner_deid_subentity : Detects 19 PHI sub-entities in Italian (DATE, AGE, SEX, PROFESSION, ORGANIZATION, PHONE, EMAIL, ZIP, STREET, CITY, COUNTRY, PATIENT, DOCTOR, HOSPITAL, MEDICALRECORD, SSN, IDNUM, USERNAME, URL). Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;, &quot;it&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;it&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;it&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... text = &quot;&quot;&quot;Ho visto Gastone Montanariello (49 anni) riferito all&#39; Ospedale San Camillo per diabete mal controllato con sintomi risalenti a marzo 2015.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results : | chunk | ner_deid_generic_chunk | ner_deid_subentity_chunk | |-||--| | Gastone Montanariello| NAME | PATIENT | | 49 | AGE | AGE | | Ospedale San Camillo | LOCATION | HOSPITAL | | marzo 2015 | DATE | DATE | We also developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from Italian medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate the following entities: DATE, AGE, SEX, PROFESSION, ORGANIZATION, PHONE, E-MAIL, ZIP, STREET, CITY, COUNTRY, PATIENT, DOCTOR, HOSPITAL, MEDICALRECORD, SSN, IDNUM, ACCOUNT, PLATE, USERNAME, URL, and IPADDR. from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;it&quot;, &quot;clinical/models&quot;) sample_text = &quot;&quot;&quot;NOME: Stefano Montanariello CODICE FISCALE: YXYGXN51C61Y662I INDIRIZZO: Viale Burcardo 7 CODICE POSTALE: 80139&quot;&quot;&quot; result = deid_pipeline.annotate(sample_text) Results: Masked with entity labels NOME: &lt;PATIENT&gt; CODICE FISCALE: &lt;SSN&gt; INDIRIZZO: &lt;STREET&gt; CODICE POSTALE: &lt;ZIP&gt; Masked with chars NOME: [*******************] CODICE FISCALE: [**************] INDIRIZZO: [**************] CODICE POSTALE: [***] Masked with fixed length chars NOME: **** CODICE FISCALE: **** INDIRIZZO: **** CODICE POSTALE: **** Obfuscated NOME: Stefania Gregori CODICE FISCALE: UIWSUS86M04J604B INDIRIZZO: Viale Orlando 808 CODICE POSTALE: 53581 Check our reference table for French and Italian deidentification metrics Please find this reference table with metrics comparing F1 score for the available entities in French and Italian clinical pipelines: |Entity Label |Italian|French| |-|-|| |PATIENT |0.9069 |0.9382| |DOCTOR |0.9171 |0.9912| |HOSPITAL |0.8968 |0.9375| |DATE |0.9835 |0.9849| |AGE |0.9832 |0.8575| |PROFESSION |0.8864 |0.8147| |ORGANIZATION |0.7385 |0.7697| |STREET |0.9754 |0.8986| |CITY |0.9678 |0.8643| |COUNTRY |0.9262 |0.8983| |PHONE |0.9815 |0.9785| |USERNAME |0.9091 |0.9239| |ZIP |0.9867 |1.0 | |E-MAIL |1 |1.0 | |MEDICALRECORD|0.8085 |0.939 | |SSN |0.9286 |N/A | |URL |1 |N/A | |SEX |0.9697 |N/A | |IDNUM |0.9576 |N/A | Added French support in Deidentification Annotator for data obfuscation Our Deidentificator annotator is now able to obfuscate entities (coming from a deid NER model) with fake data in French language. Example: Example code: ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;, &quot;fr&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;]).setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;fr&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;,&quot;token&quot;, &quot;word_embeddings&quot;]).setOutputCol(&quot;ner&quot;) ner_converter = NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setRefSep(&quot;#&quot;) .setDateTag(&quot;DATE&quot;) .setLanguage(&quot;fr&quot;) .setObfuscateRefSource(&#39;faker&#39;) pipeline = Pipeline() .setStages([ documentAssembler, sentenceDetector, tokenizer, embeddings, clinical_ner, ner_converter, de_identification ]) sentences = [ [&quot;&quot;&quot;J&#39;ai vu en consultation Michel Martinez (49 ans) adressé au Centre Hospitalier De Plaisir pour un diabète mal contrôlé avec des symptômes datant&quot;&quot;&quot;] ] my_input_df = spark.createDataFrame(sentences).toDF(&quot;text&quot;) output = pipeline.fit(my_input_df).transform(my_input_df) ... Entities detected: ++-+ |token |entity | ++-+ |J&#39;ai |O | |vu |O | |en |O | |consultation|O | |Michel |B-PATIENT | |Martinez |I-PATIENT | |( |O | |49 |B-AGE | |ans |O | |) |O | |adressé |O | |au |O | |Centre |B-HOSPITAL| |Hospitalier |I-HOSPITAL| |De |I-HOSPITAL| |Plaisir |I-HOSPITAL| |pour |O | |un |O | |diabète |O | |mal |O | ++-+ Obfuscated sentence: +--+ |result | +--+ |[J&#39;ai vu en consultation Sacrispeyre Ligniez (86 ans) adressé au Centre Hospitalier Pierre Futin pour un diabète mal contrôlé avec des symptômes datant]| +--+ Deidentification benchmark: Spark NLP vs Cloud Providers (AWS, Azure, GCP) We have published a new notebook with a benchmark and the reproduceable code, comparing Spark NLP for Healthcare Deidentification capabilities of one of our English pipelines (clinical_deidentification_glove_augmented) versus: AWS Comprehend Medical Azure Cognitive Services GCP Data Loss Prevention The notebook is available here, and the results are the following: SPARK NLP AWS AZURE GCP AGE 1 0.96 0.93 0.9 DATE 1 0.99 0.9 0.96 DOCTOR 0.98 0.96 0.7 0.6 HOSPITAL 0.92 0.89 0.72 0.72 LOCATION 0.9 0.81 0.87 0.73 PATIENT 0.96 0.95 0.78 0.48 PHONE 1 1 0.8 0.97 ID 0.93 0.93 - - ChunkMapperApproach: mapping extracted entities to an ontology (Json dictionary) with relations We have released a new annotator, called ChunkMapperApproach(), that receives a ner_chunk and a Json with a mapping of NER entities and relations, and returns the ner_chunk augmented with the relations from the Json ontology. Example of a small ontology with relations: Giving the map with entities and relationships stored in mapper.json, we will use an NER to detect entities in a text and, in case any of them is found, the ChunkMapper will augment the output with the relationships from this dictionary: {&quot;mappings&quot;: [{ &quot;key&quot;: &quot;metformin&quot;, &quot;relations&quot;: [{ &quot;key&quot;: &quot;action&quot;, &quot;values&quot; : [&quot;hypoglycemic&quot;, &quot;Drugs Used In Diabets&quot;] },{ &quot;key&quot;: &quot;treatment&quot;, &quot;values&quot; : [&quot;diabetes&quot;, &quot;t2dm&quot;] }] }] text = [&quot;&quot;&quot;The patient was prescribed 1 unit of Advil for 5 days after meals. The patient was also given 1 unit of Metformin daily. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day.&quot;&quot;&quot;] ... nerconverter = NerConverterInternal() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunk&quot;) chunkerMapper = ChunkMapperApproach() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;relations&quot;) .setDictionary(&quot;mapper.json&quot;) .setRel(&quot;action&quot;) pipeline = Pipeline().setStages([document_assembler,sentence_detector,tokenizer, ner, nerconverter, chunkerMapper]) res = pipeline.fit(test_data).transform(test_data) res.select(F.explode(&#39;ner_chunk.result&#39;).alias(&quot;chunks&quot;)).show(truncate=False) Entities: +-+ |chunks | +-+ |Metformin | |insulin glargine| |insulin lispro | |metformin | |mg | |times | +-+ Checking the relations: ... pd_df = res.select(F.explode(&#39;relations&#39;).alias(&#39;res&#39;)).select(&#39;res.result&#39;, &#39;res.metadata&#39;).toPandas() ... Results: Entity: metformin Main relation: hypoglycemic Other relations (included in metadata): Drugs Used In Diabets Configuration of case sensitivity in the name of the relations in Relation Extraction Models We have added a new parameter, called ‘relationPairsCaseSensitive’, which affects the way setRelationPairs works. If relationPairsCaseSensitive is True, then the pairs of entities in the dataset should match the pairs in setRelationPairs in their specific case (case sensitive). By default it’s set to False, meaning that the match of those relation names is case insensitive. Before 3.5.0, .setRelationPairs([&quot;dosage-drug&quot;]) would not return relations if it was trained with a relation called DOSAGE-DRUG (different casing). Now, setting .setRelationPairs([&quot;dosage-drug&quot;])and relationPairsCaseSensitive(False) or just leaving it by default, it will return any dosage-drug or DOSAGE-DRUG relationship. Example of usage in Python: ... reModel = RelationExtractionModel() .pretrained(&quot;posology_re&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;dosage-drug&quot;]) .setRelationPairsCaseSensitive(False) .setOutputCol(&quot;relations_case_insensitive&quot;) ... This will return relations named dosage-drug, DOSAGE-DRUG, etc. We have reached the milestone of 600 clinical models (and 5000+ models overall) ! 🥳 This release added to Spark NLP Models Hub 100+ pretrained clinical pipelines, available to use as one-liners, including some of the most used NER models, namely: ner_deid_generic_pipeline_de: German deidentification pipeline with aggregated (generic) labels ner_deid_subentity_pipeline_de: German deidentification pipeline with specific (subentity) labels ner_clinical_biobert_pipeline_en: A pretrained pipeline based on ner_clinical_biobert to carry out NER on BioBERT embeddings ner_abbreviation_clinical_pipeline_en: A pretrained pipeline based on ner_abbreviation_clinical that detects medical acronyms and abbreviations ner_ade_biobert_pipeline_en: A pretrained pipeline based on ner_ade_biobert to carry out Adverse Drug Events NER recognition using BioBERT embeddings ner_ade_clinical_pipeline_en: Similar to the previous one, but using clinical_embeddings ner_radiology_pipeline_en: A pretrained pipeline to detect Radiology entities (coming from ner_radiology_wip model) ner_events_clinical_pipeline_en: A pretrained pipeline to extract Clinical Events related entities (leveraging ner_events_clinical) ner_anatomy_biobert_pipeline_en: A pretrained pipeline to extract Anamoty entities (from ner_anamoty_biobert) …100 more Here is how you can use any of the pipelines with one line of code: from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;explain_clinical_doc_medication&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;The patient is a 30-year-old female with a long history of insulin dependent diabetes, type 2. She received a course of Bactrim for 14 days for UTI. She was prescribed 5000 units of Fragmin subcutaneously daily, and along with Lantus 40 units subcutaneously at bedtime.&quot;&quot;&quot;)[0] Results: +-+-++ | | chunks | entities | |:|:|:--| | 0 | insulin | DRUG | | 1 | Bactrim | DRUG | | 2 | for 14 days | DURATION | | 3 | 5000 units | DOSAGE | | 4 | Fragmin | DRUG | | 5 | subcutaneously | ROUTE | | 6 | daily | FREQUENCY | | 7 | Lantus | DRUG | | 8 | 40 units | DOSAGE | | 9 | subcutaneously | ROUTE | | 10 | at bedtime | FREQUENCY | +-+-++ +-+-++-+ | | chunks | entities | assertion | |:|:|:--|:| | 0 | insulin | DRUG | Present | | 1 | Bactrim | DRUG | Past | | 2 | Fragmin | DRUG | Planned | | 3 | Lantus | DRUG | Planned | +-+-++-+ +-+--++--+-+ | relation | entity1 | chunk1 | entity2 | chunk2 | |:|:-|:--|:-|:| | DRUG-DURATION | DRUG | Bactrim | DURATION | for 14 days | | DOSAGE-DRUG | DOSAGE | 5000 units | DRUG | Fragmin | | DRUG-ROUTE | DRUG | Fragmin | ROUTE | subcutaneously | | DRUG-FREQUENCY | DRUG | Fragmin | FREQUENCY | daily | | DRUG-DOSAGE | DRUG | Lantus | DOSAGE | 40 units | | DRUG-ROUTE | DRUG | Lantus | ROUTE | subcutaneously | | DRUG-FREQUENCY | DRUG | Lantus | FREQUENCY | at bedtime | +-+--++--+-+ We have updated our 11.Pretrained_Clinical_Pipelines.ipynb notebook to properly show this addition. Don’t forget to check it out! All of our scalable, production-ready Spark NLP Clinical Models and Pipelines can be found in our Models Hub Finally, we have added two new entityMapper models: drug_ontology and section_mapper For all Spark NLP for healthcare models, please check our Models Hub webpage Have you checked our demo page? New several demos were created, available at https://nlp.johnsnowlabs.com/demos In this release we feature the Multilingual deidentification, showcasing how to deidentify clinical texts in English, Spanish, German, French and Italian. This demo is available here For the rest of the demos, please visit Models Hub Demos Page Generate Dataframes to train Assertion Status Models using JSON files exported from Annotation Lab (ALAB) Now we can generate a dataframe that can be used to train an AssertionDLModel by using the output of AnnotationToolJsonReader.generatePlainAssertionTrainSet(). The dataframe contains all the columns that you need for training. Example : filename = &quot;../json_import.json&quot; reader = AnnotationToolJsonReader(assertion_labels = [&#39;AsPresent&#39;, &#39;AsAbsent&#39;, &#39;AsConditional&#39;, &#39;AsHypothetical&#39;, &#39;AsFamily&#39;, &#39;AsPossible&#39;, &#39;AsElse&#39;]) df = reader.readDataset(spark, filename) reader.generatePlainAssertionTrainSet(df).show(truncate=False) Results : +-+--+--++--++ |task_id|sentence |begin|end|ner |assertion| +-+--+--++--++ |1 |Patient has a headache for the last 2 weeks |2 |3 |a headache |AsPresent| +-+--+--++--++ Understand how to scale from a PoC to Production using Spark NLP for Healthcare in our new Medium Article, available here We receive many questions about how Spark work distribution is carried out, what specially becomes important before making the leap from a PoC to a big scalable, production-ready cluster. This article helps you understand: How many different ways to create a cluster are available, as well as their advantages and disadvantages; How to scale all of them; How to take advantage of autoscalability and autotermination policy in Cloud Providers; Which are the steps to take depending on your infrastructure, to make the leap to production; If you need further assistance, please reach our Support team at support@johnsnowlabs.com Contextual Parser (our Rule-based NER annotator) is now much more performant! Contextual Parser has been improved in terms of performance. These are the metrics comparing 3.4.2 and 3.5.0 4 cores and 30 GB RAM ===================== 10 MB 20 MB 30MB 50MB 3.4.2 349 786 982 1633 3.5.0 142 243 352 556 8 cores and 60 GB RAM ===================== 10 MB 20 MB 30MB 50MB 3.4.2 197 373 554 876 3.5.0 79 136 197 294 We have reached the milestone of 600 clinical demos! During this release, we included: More than 100+ recently created clinical models and pipelines, including NER, NER+RE, NER+Assertion+RE, etc. Added two new entityMapper models: drug_action_treatment_mapper and normalized_section_header_mapper For all Spark NLP for healthcare models, please check : Models Hub Page Bug fixing and compatibility additions This is the list of fixed issues and bugs, as well as one compatibility addition between EntityRuler and AssertionFiltered: Error in AssertionDLApproach and AssertionLogRegApproach: an error was being triggered wthen the dataset contained long (64bits) instead of 32 bits integers for the start / end columns. Now this bug is fixed. Error in BertSentenceChunkEmbeddings: loading a model after downloading it with pretrained() was triggering an error. Now you can load any model after downloading it with pretrained(). Adding setIncludeConfidence to AssertionDL Python version, where it was missing. Now, it’s included in both Python and Scala, as described here Making EntityRuler and AssertionFiltered compatible: AssertionFilterer annotator that is being used to filter the entities based on entity labels now can be used by EntityRulerApproach, a rule based entity extractor: Path(&quot;test_file.jsonl&quot;).write_text(json.dumps({&quot;id&quot;:&quot;cough&quot;,&quot;label&quot;:&quot;COUGH&quot;,&quot;patterns&quot;:[&quot;cough&quot;,&quot;coughing&quot;]})) ... entityRuler = EntityRulerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setPatternsResource(&quot;test_file.jsonl&quot;, ReadAs.TEXT, {&quot;format&quot;: &quot;jsonl&quot;}) clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_dl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) assertion_filterer = AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;assertion_filtered&quot;) .setWhiteList([&quot;present&quot;]) ... empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) ruler_model = rulerPipeline.fit(empty_data) text = &quot;I have a cough but no fatigue or chills.&quot; ruler_light_model = LightPipeline(ruler_model).fullAnnotate(text)[0][&#39;assertion_filtered&#39;] Result: Annotation(chunk, 9, 13, cough, {&#39;entity&#39;: &#39;COUGH&#39;, &#39;id&#39;: &#39;cough&#39;, &#39;sentence&#39;: &#39;0&#39;})] New notebooks: zero-shot relation extraction and Deidentification benchmark (Spark NLP and Cloud Providers) Check these recently notebooks created by our Healthcare team and available in our Spark NLP Workshop git repo, where you can find many more. Zero-shot Relation Extraction, available here. Deidentification benchmark (SparkNLP and Cloud Providers), available here Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_0"
  },
  "1442": {
    "id": "1442",
    "title": "Spark NLP for Healthcare Release Notes 3.5.1",
    "content": "3.5.1 We are glad to announce that 3.5.1 version of Spark NLP for Healthcare has been released! Highlights Deidentification: New Portuguese Deidentification NER models and pretrained pipeline. This is the 6th supported language for deidentification (English, German, Spanish, Italian, French and Portuguese). New pretrained models and pipelines: New RxNorm Sentence Entity Resolver model to map and extract pharmaceutical actions (e.g. analgesic, hypoglycemic) as well as treatments (e.g. backache, diabetes) along with the RxNorm code resolved (sbiobertresolve_rxnorm_action_treatment) New RCT classification models and pretrained pipelines to classify the sections within the abstracts of scientific articles regarding randomized clinical trials (RCT). (rct_binary_classifier_use, rct_binary_classifier_biobert, bert_sequence_classifier_binary_rct_biobert, rct_binary_classifier_use_pipeline, rct_binary_classifier_biobert_pipeline, bert_sequence_classifier_binary_rct_biobert_pipeline) New features: Add getClasses() attribute for MedicalBertForTokenClassifier and MedicalBertForSequenceClassification to find out the entity classes of the models Download the AnnotatorModels from the healthcare library using the Healthcare version instead of the open source version (the pretrained models were used to be dependent on open source Spark NLP version before) New functionality to download and extract clinical models from S3 via direct zip url. Core improvements: Fixing the confidence scores in MedicalNerModel when setIncludeAllConfidenceScores is true Graph_builder relation_extraction model file name extension problem with auto parameter. List of recently updated or added models Portuguese Deidentification Models This is the 6th supported language for deidentification (English, German, Spanish, Italian, French and Portuguese). This version includes two Portuguese deidentification models to mask or obfuscate Protected Health Information in the Portuguese language. The models are the following: ner_deid_generic: extracts Name, Profession, Age, Date, Contact (Telephone numbers, Email addresses), Location (Address, City, Postal code, Hospital Name, Organization), ID (Social Security numbers, Medical record numbers) and Sex entities. See Model Hub Page for details. ner_deid_subentity: Patient (name), Hospital (name), Date, Organization, City, ID, Street, Sex, Email, ZIP, Profession, Phone, Country, Doctor (name) and Age See Model Hub Page for details. You will use the w2v_cc_300d Portuguese Embeddings with these models. The pipeline should look as follows: ... word_embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;, &quot;pt&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_subentity = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;pt&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner_deid_subentity&quot;) ner_converter_subentity = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner_deid_subentity&quot;]) .setOutputCol(&quot;ner_chunk_subentity&quot;) ner_generic = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;pt&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner_deid_generic&quot;) ner_converter_generic = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner_deid_generic&quot;]) .setOutputCol(&quot;ner_chunk_generic&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentencerDL, tokenizer, word_embeddings, ner_subentity, ner_converter_subentity, ner_generic, ner_converter_generic, ]) text = &quot;&quot;&quot;Detalhes do paciente. Nome do paciente: Pedro Gonçalves NHC: 2569870. Endereço: Rua Das Flores 23. Código Postal: 21754-987. Dados de cuidados. Data de nascimento: 10/10/1963. Idade: 53 anos Data de admissão: 17/06/2016. Doutora: Maria Santos&quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) results = nlpPipeline.fit(data).transform(data) Results: +--+-+ |chunk |ner_generic_label|ner_subentity_label| +--+-+ |Pedro Gonçalves | NAME | PATIENT | |2569870 | ID | ID | |Rua Das Flores 23| LOCATION | STREET | |21754-987 | LOCATION | ZIP | |10/10/1963 | DATE | DATE | |53 | AGE | AGE | |17/06/2016 | DATE | DATE | |Maria Santos | NAME | DOCTOR | +--+-+ We also include a Clinical Deidentification Pipeline for Portuguese that uses ner_deid_subentity NER model and also several ContextualParsers for rule based contextual Named Entity Recognition tasks. It’s available to be used as follows: from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;pt&quot;, &quot;clinical/models&quot;) The pretrained pipeline comes with Deidentification and Obfuscation capabilities as shows the following example: text = &quot;&quot;&quot;RELAÇÃO HOSPITALAR NOME: Pedro Gonçalves NHC: MVANSK92F09W408A ENDEREÇO: Rua Burcardo 7 CÓDIGO POSTAL: 80139 DATA DE NASCIMENTO: 03/03/1946 IDADE: 70 anos SEXO: Homens E-MAIL: pgon21@tim.pt DATA DE ADMISSÃO: 12/12/2016 DOUTORA: Eva Andrade RELATO CLÍNICO: 70 anos, aposentado, sem alergia a medicamentos conhecida, com a seguinte história: ex-acidente de trabalho com fratura de vértebras e costelas; operado de doença de Dupuytren na mão direita e ponte ílio-femoral esquerda; diabetes tipo II, hipercolesterolemia e hiperuricemia; alcoolismo ativo, fuma 20 cigarros/dia. Ele foi encaminhado a nós por apresentar hematúria macroscópica pós-evacuação em uma ocasião e microhematúria persistente posteriormente, com evacuação normal. O exame físico mostrou bom estado geral, com abdome e genitais normais; o toque retal foi compatível com adenoma de próstata grau I/IV. A urinálise mostrou 4 hemácias/campo e 0-5 leucócitos/campo; o resto do sedimento era normal. O hemograma é normal; a bioquímica mostrou uma glicemia de 169 mg/dl e triglicerídeos 456 mg/dl; função hepática e renal são normais. PSA de 1,16 ng/ml. DIRIGIDA A: Dr. Eva Andrade - Centro Hospitalar do Medio Ave - Avenida Dos Aliados, 56 E-MAIL: evandrade@poste.pt &quot;&quot;&quot; result = deid_pipeline.annotate(text) Results: | | Sentence | Masked | Masked with Chars | Masked with Fixed Chars | Obfuscated | |:|:-|:|:-|:--|:-| | 0 | RELAÇÃO HOSPITALAR | RELAÇÃO HOSPITALAR | RELAÇÃO HOSPITALAR | RELAÇÃO HOSPITALAR | RELAÇÃO HOSPITALAR | | | NOME: Pedro Gonçalves | NOME: &lt;DOCTOR&gt; | NOME: [*************] | NOME: **** | NOME: Isabel Magalhães | | 1 | NHC: MVANSK92F09W408A | NHC: &lt;ID&gt; | NHC: [**************] | NHC: **** | NHC: 124 445 311 | | 2 | ENDEREÇO: Rua Burcardo 7 | ENDEREÇO: &lt;STREET&gt; | ENDEREÇO: [************] | ENDEREÇO: **** | ENDEREÇO: Rua de Santa María, 100 | | 3 | CÓDIGO POSTAL: 80139 | CÓDIGO POSTAL: &lt;ZIP&gt; | CÓDIGO POSTAL: [***] | CÓDIGO POSTAL: **** | CÓDIGO POSTAL: 1000-306 | | | DATA DE NASCIMENTO: 03/03/1946 | DATA DE NASCIMENTO: &lt;DATE&gt; | DATA DE NASCIMENTO: [********] | DATA DE NASCIMENTO: **** | DATA DE NASCIMENTO: 04/04/1946 | | 4 | IDADE: 70 anos | IDADE: &lt;AGE&gt; anos | IDADE: ** anos | IDADE: **** anos | IDADE: 46 anos | | 5 | SEXO: Homens | SEXO: &lt;SEX&gt; | SEXO: [****] | SEXO: **** | SEXO: Mulher | | 6 | E-MAIL: pgon21@tim.pt | E-MAIL: &lt;EMAIL&gt; | E-MAIL: [***********] | E-MAIL: **** | E-MAIL: eric.shannon@geegle.com | | | DATA DE ADMISSÃO: 12/12/2016 | DATA DE ADMISSÃO: &lt;DATE&gt; | DATA DE ADMISSÃO: [********] | DATA DE ADMISSÃO: **** | DATA DE ADMISSÃO: 23/12/2016 | | 7 | DOUTORA: Eva Andrade | DOUTORA: &lt;DOCTOR&gt; | DOUTORA: [*********] | DOUTORA: **** | DOUTORA: Isabel Magalhães | See Model Hub Page for details. Check Spark NLP Portuguese capabilities in 4.7.Clinical_Deidentification_in_Portuguese.ipynb notebook we have prepared for you. New RxNorm Sentence Entity Resolver Model (sbiobertresolve_rxnorm_action_treatment) We are releasing sbiobertresolve_rxnorm_action_treatment model that maps clinical entities and concepts (like drugs/ingredients) to RxNorm codes using sbiobert_base_cased_mli Sentence Bert Embeddings. This resolver model maps and extracts pharmaceutical actions (e.g analgesic, hypoglycemic) as well as treatments (e.g backache, diabetes) along with the RxNorm code resolved. Actions and treatments of the drugs are returned in all_k_aux_labels column. See Model Card for details. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_action_treatment&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, rxnorm_resolver]) lp_model = LightPipeline(pipelineModel) text = [&quot;Zita 200 mg&quot;, &quot;coumadin 5 mg&quot;, &#39;avandia 4 mg&#39;] result= lp_model.annotate(text) Results* : | | ner_chunk | rxnorm_code | action | treatment | |:|:--|--:|:-|| | 0 | Zita 200 mg | 104080 | [&#39;Analgesic&#39;, &#39;Antacid&#39;, &#39;Antipyretic&#39;] | [&#39;Backache&#39;, &#39;Pain&#39;, &#39;Sore Throat&#39;]| | 1 | coumadin 5 mg | 855333 | [&#39;Anticoagulant&#39;] | [&#39;Cerebrovascular Accident&#39;] | | 2 | avandia 4 mg | 261242 | [&#39;Drugs Used In Diabets&#39;,&#39;Hypoglycemic&#39;]| [&#39;Diabetes Mellitus&#39;, ...] | | New RCT Classification Models and Pretrained Pipelines We are releasing new Randomized Clinical Trial (RCT) classification models and pretrained pipelines that can classify the sections within the abstracts of scientific articles regarding randomized clinical trials (RCT). Classification Models: rct_binary_classifier_use (Models Hub page) rct_binary_classifier_biobert (Models Hub page) bert_sequence_classifier_binary_rct_biobert (Models Hub page) Pretrained Pipelines: rct_binary_classifier_use_pipeline (Models Hub page) rct_binary_classifier_biobert_pipeline (Models Hub page) bert_sequence_classifier_binary_rct_biobert_pipeline (Models Hub page) Classification Model Example : ... use = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) classifier_dl = ClassifierDLModel.pretrained(&#39;rct_binary_classifier_use&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;class&quot;) use_clf_pipeline = Pipeline( stages = [ document_assembler, use, classifier_dl ]) sample_text = &quot;&quot;&quot;Abstract:Based on the American Society of Anesthesiologists&#39; Practice Guidelines for Sedation and Analgesia by Non-Anesthesiologists (ASA-SED), a sedation training course aimed at improving medical safety was developed by the Japanese Association for Medical Simulation in 2011. This study evaluated the effect of debriefing on participants&#39; perceptions of the essential points of the ASA-SED. A total of 38 novice doctors participated in the sedation training course during the research period. Of these doctors, 18 participated in the debriefing group, and 20 participated in non-debriefing group. Scoring of participants&#39; guideline perceptions was conducted using an evaluation sheet (nine items, 16 points) created based on the ASA-SED. The debriefing group showed a greater perception of the ASA-SED, as reflected in the significantly higher scores on the evaluation sheet (median, 16 points) than the control group (median, 13 points; p &lt; 0.05). No significant differences were identified before or during sedation, but the difference after sedation was significant (p &lt; 0.05). Debriefing after sedation training courses may contribute to better perception of the ASA-SED, and may lead to enhanced attitudes toward medical safety during sedation and analgesia. &quot;&quot;&quot; result = use_clf_pipeline.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : &gt;&gt; class: True Pretrained Pipeline Example : from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;rct_binary_classifier_use_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;Abstract:Based on the American Society of Anesthesiologists&#39; Practice Guidelines for Sedation and Analgesia by Non-Anesthesiologists (ASA-SED), a sedation training course aimed at improving medical safety was developed by the Japanese Association for Medical Simulation in 2011. This study evaluated the effect of debriefing on participants&#39; perceptions of the essential points of the ASA-SED. A total of 38 novice doctors participated in the sedation training course during the research period. Of these doctors, 18 participated in the debriefing group, and 20 participated in non-debriefing group. Scoring of participants&#39; guideline perceptions was conducted using an evaluation sheet (nine items, 16 points) created based on the ASA-SED. The debriefing group showed a greater perception of the ASA-SED, as reflected in the significantly higher scores on the evaluation sheet (median, 16 points) than the control group (median, 13 points; p &lt; 0.05). No significant differences were identified before or during sedation, but the difference after sedation was significant (p &lt; 0.05). Debriefing after sedation training courses may contribute to better perception of the ASA-SED, and may lead to enhanced attitudes toward medical safety during sedation and analgesia. &quot;&quot;&quot; result = pipeline.annotate(text) Results : &gt;&gt; class: True New Features Add getClasses() attribute to MedicalBertForTokenClassifier and MedicalBertForSequenceClassification Now you can use getClasses() method for checking the entity labels of MedicalBertForTokenClassifier and MedicalBertForSequenceClassification like MedicalNerModel. tokenClassifier = MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_ner_ade&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) .setMaxSentenceLength(512) tokenClassifier.getClasses() [&#39;B-DRUG&#39;, &#39;I-ADE&#39;, &#39;I-DRUG&#39;, &#39;O&#39;, &#39;B-ADE&#39;] Download the AnnotatorModels from the healthcare library using the Healthcare version instead of the open source version Now we download the private models using the Healthcare version instead of the open source version (the pretrained models were used to be dependent on open source Spark NLP version before). New functionality to download and extract clinical models from S3 via direct link. Now, you can download clinical models from S3 via direct link directly by downloadModelDirectly method. See the Models Hub Page to find out the download url of each model. from sparknlp.pretrained import ResourceDownloader #The first argument is the path to the zip file and the second one is the folder. ResourceDownloader.downloadModelDirectly(&quot;clinical/models/assertion_dl_en_2.0.2_2.4_1556655581078.zip&quot;, &quot;clinical/models&quot;) Core improvements: Fix MedicalNerModel confidence scores when setIncludeAllConfidenceScores is True A mismatch problem between the tag with the highest confidence score and the predicted tag in MedicalNerModel is resolved. Graph_builder relation_extraction model file name extension problem with auto param A naming problem which occurs while generating a graph for Relation Extraction via graph builder was resolved. Now, the TF graph is generated with the correct extension (.pb). List of Recently Updated or Added Models ner_deid_generic_pt ner_deid_subentity_pt clinical_deidentification_pt sbiobertresolve_rxnorm_action_treatment rct_binary_classifier_use rct_binary_classifier_biobert bert_sequence_classifier_binary_rct_biobert rct_binary_classifier_use_pipeline rct_binary_classifier_biobert_pipeline bert_sequence_classifier_binary_rct_biobert_pipeline sbiobertresolve_ndc Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_1"
  },
  "1443": {
    "id": "1443",
    "title": "Spark NLP for Healthcare Release Notes 3.5.2",
    "content": "3.5.2 Highlights TFGraphBuilder annotator to create graphs for training NER, Assertion, Relation Extraction, and Generic Classifier models Default TF graphs added for AssertionDLApproach to let users train models without custom graphs New functionalities in ContextualParserApproach Printing the list of clinical pretrained models and pipelines with one-liner New clinical models Clinical NER model (ner_biomedical_bc2gm) Clinical ChunkMapper models (abbreviation_mapper, rxnorm_ndc_mapper, drug_brandname_ndc_mapper, rxnorm_action_treatment_mapper) Bug fixes New and updated notebooks List of recently updated or added models TFGraphBuilder annotator to create graphs for Training NER, Assertion, Relation Extraction, and Generic Classifier Models We have a new annotator used to create graphs in the model training pipeline. TFGraphBuilder inspects the data and creates the proper graph if a suitable version of TensorFlow (&lt;= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach. You can use this builder with MedicalNerApproach, RelationExtractionApproach, AssertionDLApproach, and GenericClassifierApproach Example: graph_folder_path = &quot;./medical_graphs&quot; med_ner_graph_builder = TFGraphBuilder() .setModelName(&quot;ner_dl&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setGraphFile(&quot;auto&quot;) .setHiddenUnitsNumber(20) .setGraphFolder(graph_folder_path) med_ner = MedicalNerApproach() ... .setGraphFolder(graph_folder) medner_pipeline = Pipeline()([ ..., med_ner_graph_builder, med_ner ]) For more examples, please check TFGraph Builder Notebook. Default TF graphs added for AssertionDLApproach to let users train models without custom graphs We added default TF graphs for the AssertionDLApproach to let users train assertion models without specifying any custom TF graph. Default Graph Features: Feature Sizes: 100, 200, 768 Number of Classes: 2, 4, 8 New Functionalities in ContextualParserApproach Added .setOptionalContextRules parameter that allows to output regex matches regardless of context match (prefix, suffix configuration). Allows sending a JSON string of the configuration file to setJsonPath parameter. Confidence Value Scenarios: When there is regex match only, the confidence value will be 0.5. When there are regex and prefix matches together, the confidence value will be &gt; 0.5 depending on the distance between target token and the prefix. When there are regex and suffix matches together, the confidence value will be &gt; 0.5 depending on the distance between target token and the suffix. When there are regex, prefix, and suffix matches all together, the confidence value will be &gt; than the other scenarios. Example: jsonString = { &quot;entity&quot;: &quot;CarId&quot;, &quot;ruleScope&quot;: &quot;sentence&quot;, &quot;completeMatchRegex&quot;: &quot;false&quot;, &quot;regex&quot;: &quot; d+&quot;, &quot;prefix&quot;: [&quot;red&quot;], &quot;contextLength&quot;: 100 } with open(&quot;jsonString.json&quot;, &quot;w&quot;) as f: json.dump(jsonString, f) contextual_parser = ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;jsonString.json&quot;) .setCaseSensitive(True) .setOptionalContextRules(True) Printing the List of Clinical Pretrained Models and Pipelines with One-Liner Now we can check what the clinical model names are of a specific annotator and the names of clinical pretrained pipelines in a language. Listing Clinical Model Names: Example: from sparknlp_jsl.pretrained import InternalResourceDownloader InternalResourceDownloader.showPrivateModels(&quot;AssertionDLModel&quot;) Results: +--+++ | Model | lang | version | +--+++ | assertion_ml | en | 2.0.2 | | assertion_dl | en | 2.0.2 | | assertion_dl_healthcare | en | 2.7.2 | | assertion_dl_biobert | en | 2.7.2 | | assertion_dl | en | 2.7.2 | | assertion_dl_radiology | en | 2.7.4 | | assertion_jsl_large | en | 3.1.2 | | assertion_jsl | en | 3.1.2 | | assertion_dl_scope_L10R10 | en | 3.4.2 | | assertion_dl_biobert_scope_L10R10 | en | 3.4.2 | +--+++ Listing Clinical Pretrained Pipelines: from sparknlp_jsl.pretrained import InternalResourceDownloader InternalResourceDownloader.showPrivatePipelines(&quot;en&quot;) +--+++ | Pipeline | lang | version | +--+++ | clinical_analysis | en | 2.4.0 | | clinical_ner_assertion | en | 2.4.0 | | clinical_deidentification | en | 2.4.0 | | clinical_analysis | en | 2.4.0 | | explain_clinical_doc_ade | en | 2.7.3 | | icd10cm_snomed_mapping | en | 2.7.5 | | recognize_entities_posology | en | 3.0.0 | | explain_clinical_doc_carp | en | 3.0.0 | | recognize_entities_posology | en | 3.0.0 | | explain_clinical_doc_ade | en | 3.0.0 | | explain_clinical_doc_era | en | 3.0.0 | | icd10cm_snomed_mapping | en | 3.0.2 | | snomed_icd10cm_mapping | en | 3.0.2 | | icd10cm_umls_mapping | en | 3.0.2 | | snomed_umls_mapping | en | 3.0.2 | | ... | ... | ... | +--+++ New ner_biomedical_bc2gm NER Model This model has been trained to extract genes/proteins from a medical text. See Model Card for more details. Example : ... ner = MedicalNerModel.pretrained(&quot;ner_biomedical_bc2gm&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... text = spark.createDataFrame([[&quot;Immunohistochemical staining was positive for S-100 in all 9 cases stained, positive for HMB-45 in 9 (90%) of 10, and negative for cytokeratin in all 9 cases in which myxoid melanoma remained in the block after previous sections.&quot;]]).toDF(&quot;text&quot;) result = model.transform(text) Results : +--++ |chunk |ner_label | +--++ |S-100 |GENE_PROTEIN| |HMB-45 |GENE_PROTEIN| |cytokeratin|GENE_PROTEIN| +--++ New Clinical ChunkMapper Models We have 4 new ChunkMapper models and a new Chunk Mapping Notebook for showing their examples. drug_brandname_ndc_mapper: This model maps drug brand names to corresponding National Drug Codes (NDC). Product NDCs for each strength are returned in result and metadata. See Model Card for more details. Example : document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;chunk&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;drug_brandname_ndc_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;chunk&quot;]) .setOutputCol(&quot;ndc&quot;) .setRel(&quot;Strength_NDC&quot;) model = PipelineModel(stages=[document_assembler, chunkerMapper]) light_model = LightPipeline(model) res = light_model.fullAnnotate([&quot;zytiga&quot;, &quot;ZYVOX&quot;, &quot;ZYTIGA&quot;]) Results : +-+--+--+ | Brandname | Strenth_NDC | Other_NDSs | +-+--+--+ | zytiga | 500 mg/1 | 57894-195 | [&#39;250 mg/1 | 57894-150&#39;] | | ZYVOX | 600 mg/300mL | 0009-4992 | [&#39;600 mg/300mL | 66298-7807&#39;, &#39;600 mg/300mL | 0009-7807&#39;] | | ZYTIGA | 500 mg/1 | 57894-195 | [&#39;250 mg/1 | 57894-150&#39;] | +-+--+--+ abbreviation_mapper: This model maps abbreviations and acronyms of medical regulatory activities with their definitions. See Model Card for details. Example: input = [&quot;&quot;&quot;Gravid with estimated fetal weight of 6-6/12 pounds. LABORATORY DATA: Laboratory tests include a CBC which is normal. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet.&quot;&quot;&quot;] &gt;&gt; output: ++-+ |Abbreviation|Definition | ++-+ |CBC |complete blood count | |HIV |human immunodeficiency virus| ++-+ rxnorm_action_treatment_mapper: RxNorm and RxNorm Extension codes with their corresponding action and treatment. Action refers to the function of the drug in various body systems; treatment refers to which disease the drug is used to treat. See Model Card for more details. Example: input = [&#39;Sinequan 150 MG&#39;, &#39;Zonalon 50 mg&#39;] &gt;&gt; output: ++++ |chunk |rxnorm_code |Action | ++++ |Sinequan 150 MG|1000067 |Antidepressant | |Zonalon 50 mg |103971 |Analgesic | ++++ rxnorm_ndc_mapper: This pretrained model maps RxNorm and RxNorm Extension codes with corresponding National Drug Codes (NDC). See Model Card for more details. Example: input = [&#39;doxepin hydrochloride 50 MG/ML&#39;, &#39;macadamia nut 100 MG/ML&#39;] &gt;&gt; output: ++++ |chunk |rxnorm_code |Product NDC | ++++ |doxepin hydrochloride 50 MG/ML|1000091 |00378-8117 | |macadamia nut 100 MG/ML |212433 |00064-2120 | ++++ Bug Fixes We fixed some issues in DrugNormalizer, DateNormalizer and ContextualParserApproach annotators. DateNormalizer : We fixed some relative date issues and also DateNormalizer takes account the Leap years now. DrugNormalizer : Fixed some formats. ContextualParserApproach : Computing the right distance for prefix. Extracting the right content for suffix. Handling special characters in prefix and suffix. New and Updated Notebooks We prepared Spark NLP for Healthcare 3hr Notebook to cover mostly used components of Spark NLP in ODSC East 2022-3 hours hands-on workshop on ‘Modular Approach to Solve Problems at Scale in Healthcare NLP’. You can also find its Databricks version here. New Chunk Mapping Notebook for showing the examples of Chunk Mapper models. Updated healthcare tutorial notebooks for Databricks with sparknlp_jsl v3.5.1 We have a new Databricks healthcare tutorials folder in which you can find all Spark NLP for Healthcare Databricks tutorial notebooks. Updated Graph Builder Notebook by adding the examples of new TFGraphBuilder annotator. List of Recently Updated or Added Models sbiobertresolve_rxnorm_action_treatment ner_biomedical_bc2gm abbreviation_mapper rxnorm_ndc_mapper drug_brandname_ndc_mapper sbiobertresolve_cpt_procedures_measurements_augmented sbiobertresolve_icd10cm_slim_billable_hcc sbiobertresolve_icd10cm_slim_normalized For all Spark NLP for healthcare models, please check : Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_2"
  },
  "1444": {
    "id": "1444",
    "title": "Spark NLP for Healthcare Release Notes 3.5.3",
    "content": "3.5.3 Highlights New rxnorm_mapper model New ChunkMapperFilterer annotator to filter ChunkMapperModel results New features Add the setReplaceLabels parameter that allows replacing the non-conventional labels without using an external source file in the NerConverterInternal(). Case sensitivity can be set in ChunkMapperApproach and ChunkMapperModel through setLowerCase() parameter. Return multiple relations at a time in ChunkMapperModel models via setRels() parameter. Filter the multi-token chunks separated with whitespace in ChunkMapperApproach by setAllowMultiTokenChunk() parameter. New license validation policy in License Validator. Bug fixes Updated notebooks List of recently updated or added models New rxnorm_mapper Model We are releasing rxnorm_mapper model that maps clinical entities and concepts to corresponding rxnorm codes. See Model Hub Page for details. Example : ... chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRel(&quot;rxnorm_code&quot;) ... sample_text = &quot;The patient was given Zyrtec 10 MG, Adapin 10 MG Oral Capsule, Septi-Soothe 0.5 Topical Spray&quot; Results : +++ |chunk |rxnorm_mappings| +++ |Zyrtec 10 MG |1011483 | |Adapin 10 MG Oral Capsule |1000050 | |Septi-Soothe 0.5 Topical Spray|1000046 | +++ New ChunkMapperFilterer Annotator to Filter ChunkMapperModel Results ChunkMapperFilterer annotator allows filtering of the chunks that were passed through the ChunkMapperModel. If setReturnCriteria() is set as &quot;success&quot;, only the chunks which are mapped by ChunkMapperModel are returned. Otherwise, if setReturnCriteria() is set as &quot;fail&quot;, only the chunks which are not mapped by ChunkMapperModel are returned. Example : ... cfModel = ChunkMapperFilterer() .setInputCols([&quot;ner_chunk&quot;,&quot;mappings&quot;]) .setOutputCol(&quot;chunks_filtered&quot;) .setReturnCriteria(&quot;success&quot;) #or &quot;fail&quot; ... sample_text = &quot;The patient was given Warfarina Lusa and amlodipine 10 mg. Also, he was given Aspagin, coumadin 5 mg and metformin&quot; .setReturnCriteria(&quot;success&quot;) Results : +--++--+--+ |begin|end| entity| mappings| +--++--+--+ | 22| 35| DRUG|Warfarina Lusa| +--++--+--+ .setReturnCriteria(&quot;fail&quot;) Results : +--++--++ |begin|end| entity| not mapped| +--++--++ | 41| 50| DRUG| amlodipine| | 80| 86| DRUG| Aspagin| | 89| 96| DRUG| coumadin| | 115|123| DRUG| metformin| +--++--++ New Features: Add setReplaceLabels Parameter That Allows Replacing the Non-Conventional Labels Without Using an External Source File in the NerConverterInternal(). Now you can replace the labels in NER models with custom labels by using .setReplaceLabels parameter with NerConverterInternal annotator. In this way, you will not need to use any other external source file to replace the labels with custom ones. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter_original = NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;original_label&quot;) ner_converter_replaced = NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;replaced_label&quot;) .setReplaceLabels({&quot;Drug_Ingredient&quot; : &quot;Drug&quot;,&#39;Drug_BrandName&#39;:&#39;Drug&#39;}) ... sample_text = &quot;The patient was given Warfarina Lusa and amlodipine 10 mg. Also, he was given Aspagin, coumadin 5 mg, and metformin&quot; Results : +--+--+++--+ |chunk |begin|end|original_label |replaced_label| +--+--+++--+ |Warfarina Lusa|22 |35 |Drug_BrandName |Drug | |amlodipine |41 |50 |Drug_Ingredient|Drug | |10 mg |52 |56 |Strength |Strength | |he |65 |66 |Gender |Gender | |Aspagin |78 |84 |Drug_BrandName |Drug | |coumadin |87 |94 |Drug_Ingredient|Drug | |5 mg |96 |99 |Strength |Strength | |metformin |106 |114|Drug_Ingredient|Drug | +--+--+++--+ Case Sensitivity in ChunkMapperApproach and ChunkMapperModel Through setLowerCase() Parameter The case status of ChunkMapperApproach and ChunkMapperModel can be set by using setLowerCase() parameter. Example : ... chunkerMapperapproach = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;mappings.json&quot;) .setRel(&quot;action&quot;) .setLowerCase(True) #or False ... sentences = [[&quot;&quot;&quot;The patient was given Warfarina lusa and amlodipine 10 mg, coumadin 5 mg. The patient was given Coumadin&quot;&quot;&quot;]] setLowerCase(True) Results : ++--+ |chunk |mapped | ++--+ |Warfarina lusa |540228 | |amlodipine |329526 | |coumadin |202421 | |Coumadin |202421 | ++--+ setLowerCase(False) Results : ++--+ |chunk |mapped | ++--+ |Warfarina lusa |NONE | |amlodipine |329526 | |coumadin |NONE | |Coumadin |202421 | ++--+ Return Multiple Relations At a Time In ChunkMapper Models Via setRels() Parameter Multiple relations for the same chunk can be set with the setRels() parameter in both ChunkMapperApproach and ChunkMapperModel. Example : ... chunkerMapperapproach = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;mappings.json&quot;) .setRels([&quot;action&quot;,&quot;treatment&quot;]) .setLowerCase(True) ... sample_text = &quot;The patient was given Warfarina Lusa.&quot; Results : +--++--+-++ |begin|end| entity| mappings| relation| +--++--+-++ | 22| 35|Warfarina Lusa|Anticoagulant| action| | 22| 35|Warfarina Lusa|Heart Disease|treatment| +--++--+-++ Filter the Multi-Token Chunks Separated With Whitespace in ChunkMapperApproach and ChunkMapperModel by setAllowMultiTokenChunk() Parameter The chunks that include multi-tokens separated by a whitespace, can be filtered by using setAllowMultiTokenChunk() parameter. Example : ... chunkerMapper = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;mappings.json&quot;) .setLowerCase(True) .setRels([&quot;action&quot;, &quot;treatment&quot;]) .setAllowMultiTokenChunk(False) ... sample_text = &quot;The patient was given Warfarina Lusa&quot; setAllowMultiTokenChunk(False) Results : +--++--+--+--+ |begin|end| chunk|mappings|relation| +--++--+--+--+ | 22| 35|Warfarina Lusa| NONE| null| +--++--+--+--+ setAllowMultiTokenChunk(True) Results : +--++--+-++ |begin|end| chunk| mappings| relation| +--++--+-++ | 22| 35|Warfarina Lusa|Anticoagulant| action| | 22| 35|Warfarina Lusa|Heart Disease|treatment| +--++--+-++ New License Validation Policies in License Validator A new version of the License Validator has been included in Spark NLP for Healthcare. This License Validator checks the compatibility between the type of your license and the environment you are using, allowing the license to be used only for the environment it was requested (single-node, cluster, databricks, etc) and the number of concurrent sessions (floating or not-floating). You can check which type of license you have in my.johnsnowlabs.com -&gt; My Subscriptions. If your license stopped working, please contact support@johnsnowlabs.com so that it can be checked the difference between the environment your license was requested for and the one it’s currently being used. Bug Fixes We fixed some issues in AnnotationToolJsonReader tool, DrugNormalizer and ContextualParserApproach annotators. DrugNormalizer : Fixed some issues that affect the performance. ContextualParserApproach : Fixed the issue in the computation of indices for documents with more than one sentence while defining the rule-scope field as a document. AnnotationToolJsonReader : Fixed an issue where relation labels were not being extracted from the Annotation Lab json file export. Updated Notebooks Clinical Named Entity Recognition Notebook .setReplaceLabels parameter example was added. Chunk Mapping Notebook New case sensitivity, selecting multiple relations, filtering multi-token chunks and ChunkMapperFilterer features were added. List of Recently Updated Models sbiobertresolve_icdo_augmented rxnorm_mapper For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_3"
  },
  "1445": {
    "id": "1445",
    "title": "Spark NLP release notes 3.6.0",
    "content": "3.6.0 Release date: 05-08-2021 Overview Handwritten detection and visualization improvement. New Features Added ImageHandwrittenDetector for detecting ‘signature’, ‘date’, ‘name’, ‘title’, ‘address’ and others handwritten text. Added rendering labels and scores in ImageDrawRegions. Added possibility to scale image to fixed size in ImageScaler with keeping original ratio. Enhancements Support new version of pip for installing python package Added support string labels for detectors Added an auto inferencing of the input shape for detector models New license validator Bugfixes Fixed display BGR images in display functions New and updated notebooks Image Signature Detection example Image Handwritten Detection example Image Scaler example Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_6_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_6_0"
  },
  "1446": {
    "id": "1446",
    "title": "Spark NLP release notes 3.7.0",
    "content": "3.7.0 Release date: 30-08-2021 Overview Improve table recognition and render OCR results to the PDF with original image New Features Added ImageToTextPdf transformer for storing recognized text to the searchable PDF with original image Added PdfAssembler for assembling multipage PDF document from single page PDF documents Enhancements Added support dbfs for store models. This allow to use models on Databricks. Improved ImageTableCellDetector algorithms Added params for tuning ImageTableCellDetector algorithms Added possibility to render detected lines to the original image in ImageTableCellDetector Added support to store recognized results to CSV in ImageCellsToTextTable Added display_table and display_tables functions Added display_pdf_file function for displaying pdf in embedded pdf viewer Updated license validator New and updated notebooks Process multiple page scanned PDF (New) Image Table Detection example Image Cell Recognition example Image Table Recognition Tables Recognition from PDF Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_7_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_7_0"
  },
  "1447": {
    "id": "1447",
    "title": "Spark NLP release notes 3.8.0",
    "content": "3.8.0 Release date: 14-09-2021 Overview Support Microsoft PPT and PPTX documents. New Features Added PptToPdf transformer for converting PPT and PPTX slides to the PDF document. Added PptToTextTable transformer for extracting tables from PPT and PPTX slides. New and updated notebooks Convert PPT to PDF (New) Extract tables from PPT (New) Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_8_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_8_0"
  },
  "1448": {
    "id": "1448",
    "title": "Spark NLP release notes 3.9.0",
    "content": "3.9.0 Release date: 20-10-2021 Overview Improve visualization and support Spark NLP. New Features Added HocrTokenizer Added HocrDocumentAssembler Added ImageDrawAnnotations Added support Arabic language in ImageToText and ImageToHocr Enhancements Added postprocessing to the ImageTableDetector Added Spark NLP by default to spark session in start function Changed default value for ignoreResolution param in ImageToText Updated license-validator. Added support floating license and set AWS keys from license. Added ‘whiteList’ param to the VisualDocumentNER New and updated notebooks Spark OCR HOCR Visual Document NER Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_9_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_9_0"
  },
  "1449": {
    "id": "1449",
    "title": "Spark NLP release notes 3.9.1",
    "content": "3.9.1 Release date: 02-11-2021 Overview Added preserving of original file formatting Enhancements Added keepLayout param to the ImageToText New and updated notebooks Preserve Original Formatting Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_9_1",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_9_1"
  },
  "1450": {
    "id": "1450",
    "title": "Spark NLP release notes 4.0.0",
    "content": "4.0.0 Release date: 16-07-2022 Overview We are very glad to announce that Spark OCR 4.0.0 has been released! This release comes with new models, new functionality, bug fixes, and compatibility with 4.0.0 versions of Spark NLP and Spark NLP for Healthcare. New Features New DicomMetadataDeidentifier class to help deidentifying metadata of dicom files. Example Notebook. New helper function display_dicom() to help displaying DICOM files in notebooks. New DicomDrawRegions that can clean burned pixels for removing PHI. Improved support for DICOM files containing 12bit images. Bug Fixes Fixes on the Visual NER Finetuning process including VisualDocumentNERv2 and AlabReader. Improved exception handling for VisualDocumentClassifier models. New Models New LayoutLMv3 based Visual Document NER: layoutlmv3_finetuned_funsd. Improved handwritten detection ocr_base_handwritten_v2. VisualDocumentClassifierV2: layoutlmv2_rvl_cdip_40k. This model adds more data compared to layoutlmv2_rvl_cdip_1500, and achieves an accuracy of 88%. Compatibility Updates Deprecated Spark 2.3 and Spark 2.4 support. Tested compatibility with Spark-NLP and Spark NLP for Healthcare 4.0.0. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_0_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_0_0"
  },
  "1451": {
    "id": "1451",
    "title": "Spark NLP for Healthcare Release Notes 4.0.0",
    "content": "4.0.0 Highlights 8 new chunk mapper models and 9 new pretrained chunk mapper pipelines to convert one medical terminology to another (Snomed to ICD10, RxNorm to UMLS etc.) 2 new medical NER models (ner_clinical_trials_abstracts and ner_pathogen) and pretrained NER pipelines 20 new biomedical NER models based on the LivingNER corpus in 8 languages (English, Spanish, French, Italian, Portuguese, Romanian, Catalan and Galician) 2 new medical NER models for Romanian language (ner_clinical, ner_clinical_bert) Deidentification support for Romanian language (ner_deid_subentity, ner_deid_subentity_bert and a pretrained deidentification pipeline) The first public health model: Emotional stress classifier (bert_sequence_classifier_stress) ResolverMerger annotator to merge the results of ChunkMapperModel and SentenceEntityResolverModel annotators New Shortest Context Match and Token Index Features in ContextualParserApproach Prettified relational categories in ZeroShotRelationExtractionModel annotator Create graphs for open source NerDLApproach with the TFGraphBuilder Spark NLP for Healthcare library installation with Poetry (dependency management and packaging tool) Bug fixes Updated notebooks List of recently updated or added models (50+ new medical models and pipelines) 8 New Chunk Mapper Models and 9 New Pretrained Chunk Mapper Pipelines to Convert One Medical Terminology to Another (Snomed to ICD10, RxNorm to UMLS etc.) We are releasing 8 new ChunkMapperModel models and 9 new pretrained pipelines for mapping clinical codes with their corresponding. Mapper Models: Mapper Name Source Target snomed_icd10cm_mapper SNOMED CT ICD-10-CM icd10cm_snomed_mapper ICD-10-CM SNOMED CT snomed_icdo_mapper SNOMED CT ICD-O icdo_snomed_mapper ICD-O SNOMED CT rxnorm_umls_mapper RxNorm UMLS icd10cm_umls_mapper ICD-10-CM UMLS mesh_umls_mapper MeSH UMLS snomed_umls_mapper SNOMED CT UMLS Example: ... snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_snomed_conditions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;snomed_icd10cm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;snomed_code&quot;]) .setOutputCol(&quot;icd10cm_mappings&quot;) .setRels([&quot;icd10cm_code&quot;]) pipeline = PipelineModel( stages = [ documentAssembler, sbert_embedder, snomed_resolver, chunkerMapper ]) light_pipeline= LightPipeline(pipeline) result = light_pipeline.fullAnnotate(&quot;Radiating chest pain&quot;) Results : | | ner_chunk | snomed_code | icd10cm_mappings | |:|:|--:|:-| | 0 | Radiating chest pain | 10000006 | R07.9 | Pretrained Pipelines: Pipeline Name Source Target icd10cm_snomed_mapping ICD-10-CM SNOMED CT snomed_icd10cm_mapping SNOMED CT ICD-10-CM icdo_snomed_mapping ICD-O SNOMED CT snomed_icdo_mapping SNOMED CT ICD-O rxnorm_ndc_mapping RxNorm NDC icd10cm_umls_mapping ICD-10-CM UMLS mesh_umls_mapping MeSH UMLS rxnorm_umls_mapping RxNorm UMLS snomed_umls_mapping SOMED CT UMLS Example: from sparknlp.pretrained import PretrainedPipeline pipeline= PretrainedPipeline(&quot;rxnorm_umls_mapping&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result= pipeline.annotate(&quot;1161611 315677&quot;) Results : {&#39;document&#39;: [&#39;1161611 315677&#39;], &#39;rxnorm_code&#39;: [&#39;1161611&#39;, &#39;315677&#39;], &#39;umls_code&#39;: [&#39;C3215948&#39;, &#39;C0984912&#39;]} 2 New Medical NER Models (ner_clinical_trials_abstracts and ner_pathogene) and Pretrained NER Pipelines ner_clinical_trials_abstracts: This model can extract concepts related to clinical trial design, diseases, drugs, population, statistics and publication. It can detect Age, AllocationRatio, Author, BioAndMedicalUnit, CTAnalysisApproach, CTDesign, Confidence, Country, DisorderOrSyndrome, DoseValue, Drug, DrugTime, Duration, Journal, NumberPatients, PMID, PValue, PercentagePatients, PublicationYear, TimePoint, Value entities. See Model Hub Page for details. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical_trials_abstracts&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ... sample_text = &quot;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&quot; bert_token_classifier_ner_clinical_trials_abstracts: This model is the BERT-based version of ner_clinical_trials_abstracts model and it can detect Age, AllocationRatio, Author, BioAndMedicalUnit, CTAnalysisApproach, CTDesign, Confidence, Country, DisorderOrSyndrome, DoseValue, Drug, DrugTime, Duration, Journal, NumberPatients, PMID, PValue, PercentagePatients, PublicationYear, TimePoint, Value entities. See Model Hub Page for details. Example : ... tokenClassifier = MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_ner_clinical_trials_abstracts&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... sample_text = &quot;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&quot; ner_clinical_trials_abstracts_pipeline: This pretrained pipeline is build upon the ner_clinical_trials_abstracts model and it can extract Age, AllocationRatio, Author, BioAndMedicalUnit, CTAnalysisApproach, CTDesign, Confidence, Country, DisorderOrSyndrome, DoseValue, Drug, DrugTime, Duration, Journal, NumberPatients, PMID, PValue, PercentagePatients, PublicationYear, TimePoint, Value entities. See Model Hub Page for details. Example : pipeline = PretrainedPipeline(&quot;ner_clinical_trials_abstracts_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&quot;) Results : +-++ | chunk| ner_label| +-++ | randomised| CTDesign| | multicentre| CTDesign| |insulin glargine| Drug| | NPH insulin| Drug| | type 2 diabetes|DisorderOrSyndrome| +-++ ner_pathogen: This model is trained for detecting medical conditions (influenza, headache, malaria, etc), medicine (aspirin, penicillin, methotrexate) and pathogenes (Corona Virus, Zika Virus, E. Coli, etc) in clinical texts. It can extract Pathogen, MedicalCondition, Medicine entities. See Model Hub Page for details. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_pathogen&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;Racecadotril is an antisecretory medication and it has better tolerability than loperamide. Diarrhea is the condition of having loose, liquid or watery bowel movements each day. Signs of dehydration often begin with loss of the normal stretchiness of the skin. While it has been speculated that rabies virus, Lyssavirus and Ephemerovirus could be transmitted through aerosols, studies have concluded that this is only feasible in limited conditions.&quot; ner_pathogen_pipeline: This pretrained pipeline is build upon the ner_pathogen model and it can extract Pathogen, MedicalCondition, Medicine entities. See Model Hub Page for details. Example : pipeline = PretrainedPipeline(&quot;ner_pathogen_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;Racecadotril is an antisecretory medication and it has better tolerability than loperamide. Diarrhea is the condition of having loose, liquid or watery bowel movements each day. Signs of dehydration often begin with loss of the normal stretchiness of the skin. While it has been speculated that rabies virus, Lyssavirus and Ephemerovirus could be transmitted through aerosols, studies have concluded that this is only feasible in limited conditions.&quot;) Results : ++-+ |chunk |ner_label | ++-+ |Racecadotril |Medicine | |loperamide |Medicine | |Diarrhea |MedicalCondition| |dehydration |MedicalCondition| |rabies virus |Pathogen | |Lyssavirus |Pathogen | |Ephemerovirus |Pathogen | ++-+ ner_biomedical_bc2gm_pipeline : This pretrained pipeline can extract genes/proteins from medical texts by labelling them as GENE_PROTEIN. See Model Hub Page for details. Example : pipeline = PretrainedPipeline(&quot;ner_biomedical_bc2gm_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;Immunohistochemical staining was positive for S-100 in all 9 cases stained, positive for HMB-45 in 9 (90%) of 10, and negative for cytokeratin in all 9 cases in which myxoid melanoma remained in the block after previous sections.&quot;&quot;&quot;) Results : +--++ |chunk |ner_label | +--++ |S-100 |GENE_PROTEIN| |HMB-45 |GENE_PROTEIN| |cytokeratin|GENE_PROTEIN| +--++ 20 New Biomedical NER Models Based on the [LivingNER corpus] in 8 Languages We are releasing 20 new NER and MedicalBertForTokenClassifier models for *English, French, Italian, Portuguese, Romanian, Catalan and Galician languages that are trained on the LivingNER multilingual corpus and for Spanish that is trained on LivingNER corpus is composed of clinical case reports extracted from miscellaneous medical specialties including COVID, oncology, infectious diseases, tropical medicine, urology, pediatrics, and others. These models can detect living species as HUMAN and SPECIES entities in clinical texts. Here is the list of model names and their embeddings used while training: Language Annotator Embeddings Model Name es MedicalBertForTokenClassification   bert_token_classifier_ner_living_species es MedicalNerModel bert_base_cased_es ner_living_species_bert es MedicalNerModel roberta_base_biomedical_es ner_living_species_roberta es MedicalNerModel embeddings_scielo_300d_es ner_living_species_300 es MedicalNerModel w2v_cc_300d_es ner_living_species en MedicalBertForTokenClassification   bert_token_classifier_ner_living_species en MedicalNerModel embeddings_clinical_en ner_living_species en MedicalNerModel biobert_pubmed_base_cased_en ner_living_species_biobert fr MedicalNerModel w2v_cc_300d_fr ner_living_species fr MedicalNerModel bert_embeddings_bert_base_fr_cased ner_living_species_bert pt MedicalBertForTokenClassification   bert_token_classifier_ner_living_species pt MedicalNerModel w2v_cc_300d_pt ner_living_species pt MedicalNerModel roberta_embeddings_BR_BERTo_pt ner_living_species_roberta pt MedicalNerModel biobert_embeddings_biomedical_pt ner_living_species_bert it MedicalBertForTokenClassification   bert_token_classifier_ner_living_species it MedicalNerModel bert_base_italian_xxl_cased_it ner_living_species_bert it MedicalNerModel w2v_cc_300d_it ner_living_species ro MedicalNerModel bert_base_cased_ro ner_living_species_bert cat MedicalNerModel w2v_cc_300d_cat ner_living_species gal MedicalNerModel w2v_cc_300d_gal ner_living_species Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_living_species&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;&quot;&quot;Patient aged 61 years; no known drug allergies, smoker of 63 packs/year, significant active alcoholism, recently diagnosed hypertension. He came to the emergency department approximately 4 days ago with a frontal headache coinciding with a diagnosis of hypertension, for which he was started on antihypertensive treatment. The family reported that they found him &quot;slower&quot; accompanied by behavioural alterations; with no other accompanying symptoms.Physical examination: Glasgow Glasgow 15; neurological examination without focality except for bradypsychia and disorientation in time, person and space. Afebrile. BP: 159/92; heart rate 70 and O2 Sat: 93%; abdominal examination revealed hepatomegaly of two finger widths with no other noteworthy findings. CBC: Legionella antigen and pneumococcus in urine negative.&quot;&quot;&quot;]], [&quot;text&quot;])) Results : ++-+ |ner_chunk |label | ++-+ |Patient |HUMAN | |family |HUMAN | |person |HUMAN | |Legionella |SPECIES| |pneumococcus|SPECIES| ++-+ 2 New Medical NER Models for Romanian Language We trained ner_clinical and ner_clinical_bert models that can detect Measurements, Form, Symptom, Route, Procedure, Disease_Syndrome_Disorder, Score, Drug_Ingredient, Pulse, Frequency, Date, Body_Part, Drug_Brand_Name, Time, Direction, Dosage, Medical_Device, Imaging_Technique, Test, Imaging_Findings, Imaging_Test, Test_Result, Weight, Clinical_Dept and Units entities in Romanian clinical texts. ner_clinical: This model is trained with w2v_cc_300d embeddings model. Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;,&quot;ro&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;Aorta ascendenta inlocuita cu proteza de Dacron de la nivelul anulusului pana pe segmentul ascendent distal pe o lungime aproximativa de 75 mm.&quot; ner_clinical_bert: This model is trained with bert_base_cased embeddings model. Example : ... embeddings = BertEmbeddings.pretrained(&quot;bert_base_cased&quot;, &quot;ro&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical_bert&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;Aorta ascendenta inlocuita cu proteza de Dacron de la nivelul anulusului pana pe segmentul ascendent distal pe o lungime aproximativa de 75 mm.&quot; Results : +-+--+ | chunks| entities| +-+--+ | Aorta ascendenta| Body_Part| | proteza de Dacron|Medical_Device| | anulusului| Body_Part| |segmentul ascendent| Body_Part| | distal| Direction| | 75| Measurements| | mm| Units| +-+--+ Deidentification Support for Romanian Language (ner_deid_subentity, ner_deid_subentity_bert and a Pretrained Deidentification Pipeline) We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in Romanian. ner_deid_subentity and ner_deid_subentity_bert models are trained with in-house annotations and can detect 17 different entities (AGE, CITY, COUNTRY, DATE, DOCTOR, EMAIL, FAX, HOSPITAL, IDNUM, LOCATION-OTHER, MEDICALRECORD, ORGANIZATION, PATIENT, PHONE, PROFESSION, STREET, ZIP). ner_deid_subentity: This model is trained with w2v_cc_300d embeddings model. See Model Hub Page for details. Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;,&quot;ro&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;&quot;&quot; Spitalul Pentru Ochi de Deal, Drumul Oprea Nr. 972 Vaslui, 737405 România Tel: +40(235)413773 Data setului de analize: 25 May 2022 15:36:00 Nume si Prenume : BUREAN MARIA, Varsta: 77 Medic : Agota Evelyn Tımar C.N.P : 2450502264401&quot;&quot;&quot; ner_deid_subentity_bert: This model is trained with bert_base_cased embeddings model. See Model Hub Page for details. Example : ... embeddings = BertEmbeddings.pretrained(&quot;bert_base_cased&quot;, &quot;ro&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_bert&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... text = &quot;&quot;&quot; Spitalul Pentru Ochi de Deal, Drumul Oprea Nr. 972 Vaslui, 737405 România Tel: +40(235)413773 Data setului de analize: 25 May 2022 15:36:00 Nume si Prenume : BUREAN MARIA, Varsta: 77 Medic : Agota Evelyn Tımar C.N.P : 2450502264401&quot;&quot;&quot; Results : +-++ |chunk |ner_label| +-++ |Spitalul Pentru Ochi de Deal|HOSPITAL | |Drumul Oprea Nr |STREET | |Vaslui |CITY | |737405 |ZIP | |+40(235)413773 |PHONE | |25 May 2022 |DATE | |BUREAN MARIA |PATIENT | |77 |AGE | |Agota Evelyn Tımar |DOCTOR | |2450502264401 |IDNUM | +-++ clinical_deidentification: This pretrained pipeline that can be used to deidentify PHI information from Romanian medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate ACCOUNT, PLATE, LICENSE, AGE, CITY, COUNTRY, DATE, DOCTOR, EMAIL, FAX, HOSPITAL, IDNUM, LOCATION-OTHER, MEDICALRECORD, ORGANIZATION, PATIENT, PHONE, PROFESSION, STREET, ZIP entities. See Model Hub Page for details. Example : from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) text = &quot;Varsta : 77, Nume si Prenume : BUREAN MARIA, Data setului de analize: 25 May 2022, Licență : B004256985M, Înmatriculare : CD205113, Cont : FXHZ7170951927104999&quot; result = deid_pipeline.annotate(text) print(&quot; nMasked with entity labels&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked&#39;])) print(&quot; nMasked with chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; nMasked with fixed length chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; nObfuscated&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) Results : Masked with entity labels Varsta : &lt;AGE&gt;, Nume si Prenume : &lt;PATIENT&gt;, Data setului de analize: &lt;DATE&gt;, Licență : &lt;LICENSE&gt;, Înmatriculare : &lt;PLATE&gt;, Cont : &lt;ACCOUNT&gt; Masked with chars Varsta : **, Nume si Prenume : [**********], Data setului de analize: [*********], Licență : [*********], Înmatriculare : [******], Cont : [******************] Masked with fixed length chars Varsta : ****, Nume si Prenume : ****, Data setului de analize: ****, Licență : ****, Înmatriculare : ****, Cont : **** Obfuscated Varsta : 91, Nume si Prenume : Dragomir Emilia, Data setului de analize: 01-04-2001, Licență : T003485962M, Înmatriculare : AR-65-UPQ, Cont : KHHO5029180812813651 The First Public Health Model: Emotional Stress Classifier We are releasing a new bert_sequence_classifier_stress model that can classify whether the content of a text expresses emotional stress. It is a PHS-BERT-based model and trained with the Dreaddit dataset. Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_stress&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) sample_text = &quot;No place in my city has shelter space for us, and I won&#39;t put my baby on the literal street. What cities have good shelter programs for homeless mothers and children?&quot; Results : +-+--+ |text | class| +-+--+ |No place in my city has shelter space for us, and I won&#39;t put my baby on the literal street. What cities have good shelter programs for homeless mothers and children?|[stress]| +-+--+ ResolverMerger Annotator to Merge the Results of ChunkMapperModel and SentenceEntityResolverModel Annotators ResolverMerger annotator allows to merge the results of ChunkMapperModel and SentenceEntityResolverModel annotators. You can detect your results that fail by ChunkMapperModel with ChunkMapperFilterer and then merge your resolver and mapper results with ResolverMerger. Example : ... chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;chunk&quot;]) .setOutputCol(&quot;RxNorm_Mapper&quot;) .setRel(&quot;rxnorm_code&quot;) cfModel = ChunkMapperFilterer() .setInputCols([&quot;chunk&quot;, &quot;RxNorm_Mapper&quot;]) .setOutputCol(&quot;chunks_fail&quot;) .setReturnCriteria(&quot;fail&quot;) ... resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;resolver_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) resolverMerger = ResolverMerger() .setInputCols([&quot;resolver_code&quot;,&quot;RxNorm_Mapper&quot;]) .setOutputCol(&quot;RxNorm&quot;) ... Results : +--+--++-+-+ |chunk |RxNorm_Mapper |chunks_fail |resolver_code|RxNorm | +--+--++-+-+ |[Adapin 10 MG, coumadin 5 mg] |[1000049, NONE] |[coumadin 5 mg]|[855333] |[1000049, 855333] | |[Avandia 4 mg, Tegretol, zytiga]|[NONE, 203029, 1100076]|[Avandia 4 mg] |[261242] |[261242, 203029, 1100076]| +--+--++-+-+ New Shortest Context Match and Token Index Features in ContextualParserApproach We have new functionalities in ContextualParserApproach to make it more performant. setShortestContextMatch() parameter will allow stop looking for matches in the text when a token defined as a suffix is found. Also it will keep tracking of the last mathced prefix and subsequent mathches with suffix. Now the index of the matched token can be found in metadata. Example : ... contextual_parser = ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;cities.json&quot;) .setCaseSensitive(True) .setDictionary(&#39;cities.tsv&#39;, options={&quot;orientation&quot;:&quot;vertical&quot;}) .setShortestContextMatch(True) ... sample_text = &quot;Peter Parker is a nice guy and lives in Chicago.&quot; Results : +-++-+ |chunk |ner_label|tokenIndex| +-++-+ |Chicago|City |9 | +-++-+ Prettified relational categories in ZeroShotRelationExtractionModel annotator Now you can setRelationalCategories() between the entity labels by using a single {} instead of two. Example : re_model = ZeroShotRelationExtractionModel.pretrained(&quot;re_zeroshot_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationalCategories({&quot;ADE&quot;: [&quot;{DRUG} causes {PROBLEM}.&quot;]}) Create Graphs for Open Source NerDLApproach with the TFGraphBuilder Now you can create graphs for model training with NerDLApproach by using the new setIsMedical() parameter of TFGraphBuilder annotator. If setIsMedical(True), the model can be trained with MedicalNerApproach, but if it is setIsMedical(False) it can be used with NerDLApproach for training non-medical models. graph_folder_path = &quot;./graphs&quot; ner_graph_builder = TFGraphBuilder() .setModelName(&quot;ner_dl&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setGraphFile(&quot;auto&quot;) .setHiddenUnitsNumber(20) .setGraphFolder(graph_folder_path) .setIsMedical(False) ner = NerDLApproach() ... .setGraphFolder(graph_folder_path) ner_pipeline = Pipeline()([ ..., ner_graph_builder, ner ]) Spark NLP for Healthcare Library Installation with Poetry Documentation (dependency management and packaging tool). We have a new documentation page for showing Spark NLP for Healthcare installation with Poetry. You can find it here. Bug fixes ContextualParserApproach: Fixed the bug using a dictionary and document rule scope in JSON config file. RENerChunksFilter: Preparing a pretrained pipeline with RENerChunksFilter annotator issue is fixed. Updated Notebooks ZeroShot Clinical Relation Extraction Notebook: Added new features, visualization and new examples. Clinical_Entity_Resolvers Notebook: Added an example of ResolverMerger. Chunk Mapping Notebook: Added new models into the model list and an example of mapper pretrained pipelines. Healthcare Code Mapping Notebook: Added all mapper pretrained pipeline examples. List of Recently Updated and Added Models ner_pathogene ner_pathogen_pipeline ner_clinical_trials_abstracts bert_token_classifier_ner_clinical_trials_abstracts ner_clinical_trials_abstracts_pipeline ner_biomedical_bc2gm_pipeline bert_sequence_classifier_stress icd10cm_snomed_mapper snomed_icd10cm_mapper snomed_icdo_mapper icdo_snomed_mapper rxnorm_umls_mapper icd10cm_umls_mapper mesh_umls_mapper snomed_umls_mapper icd10cm_snomed_mapping snomed_icd10cm_mapping icdo_snomed_mapping snomed_icdo_mapping rxnorm_ndc_mapping icd10cm_umls_mapping mesh_umls_mapping rxnorm_umls_mapping snomed_umls_mapping drug_action_tretment_mapper normalized_section_header_mapper drug_brandname_ndc_mapper abbreviation_mapper rxnorm_ndc_mapper rxnorm_action_treatment_mapper rxnorm_mapper ner_deid_subentity -&gt; ro ner_deid_subentity_bert -&gt; ro clinical_deidentification -&gt; ro ner_clinical -&gt; ro ner_clinical_bert -&gt; ro bert_token_classifier_ner_living_species -&gt; es ner_living_species_bert -&gt; es ner_living_species_roberta -&gt; es ner_living_species_300 -&gt; es ner_living_species -&gt; es bert_token_classifier_ner_living_species -&gt; en ner_living_species -&gt; en ner_living_species_biobert -&gt; en ner_living_species -&gt; fr ner_living_species_bert -&gt; fr bert_token_classifier_ner_living_species -&gt; pt ner_living_species -&gt; pt ner_living_species_roberta -&gt; pt ner_living_species_bert -&gt; pt bert_token_classifier_ner_living_species -&gt; it ner_living_species_bert -&gt; it ner_living_species -&gt; pt ner_living_species_bert -&gt; ro ner_living_species -&gt; ro ner_living_species -&gt; gal For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_0_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_0_0"
  },
  "1452": {
    "id": "1452",
    "title": "Spark NLP release notes 4.0.2",
    "content": "4.0.2 Release date: 12-09-2022 Overview We are glad to announce that Spark OCR 4.0.2 has been released! This release comes with new features, fixes and more!. New Features VisualDocumentClassifierV2 is now trainable! Continuing with the effort to make all the most useful models easily trainable, we added training capabilities to this annotator. Added support for Simplified Chinese. Added new ‘PdfToForm’ annotator, capable of extracting forms from digital PDFs. This is different from previously introduced VisualDocumentNER annotator in that this new annotator works only on digital documents, as opposite to the scanned forms handled by VisualDocumentNER. PdfToForm is complementary to VisualDocumentNER. Improvements Support for multi-frame dicom has been added. Added the missing load()​ method in ImageToTextV2. New Notebooks We added two new notebooks for VisualDocumentClassifierV2, a preprocessing notebook, useful when you’re dealing with large datasets, and a fine-tuning notebook. We added a new sample notebook showing how to extract forms from digital PDF documents. We added a new sample notebook explaining how to use Simplified Chinese OCR. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_0_2",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_0_2"
  },
  "1453": {
    "id": "1453",
    "title": "Spark NLP for Healthcare Release Notes 4.0.2",
    "content": "4.0.2 Highlights 16 new text classification models for English and Spanish social media text related to public health topics (stress, domestic violence, vaccine status, drug reviews etc.) Pretrained medication NER pipeline to augment posology NER models with Drugbank dataset Pretrained medication resolver pipeline to extract RxNorm, UMLS, NDC, SNOMED CT codes and action/treatments. New disease NER model for Spanish language 5 new chunk mapper models to convert clinical entities to relevant medical terminology (UMLS) 5 new pretrained resolver pipelines to convert clinical entities to relevant medical terminology (UMLS) New Relation Extraction model to detect Drug and ADE relations New module for converting Annotation Lab (ALAB) exports into formats suitable for training new models Updated De-identification pretrained pipelines New setBlackList() parameter in ChunkFilterer() annotator New Doc2ChunkInternal() annotator Listing clinical pretrained models and pipelines with one-liner Bug fixes New and updated notebooks List of recently updated or added models (40+ new models and pipelines) 16 New Classification Models for English and Spanish Social Media Texts Related to Public Health Topics (Stress, Domestic Violence, Vaccine Status, Drug Reviews etc.) We are releasing 11 new MedicalBertForSequenceClassification models to classify text from social media data for English and Spanish languages. model name description predicted entities bert_sequence_classifier_ade_augmented this model classify tweets reporting ADEs (Adverse Drug Events). ADE noADE bert_sequence_classifier_health_mandates_stance_tweet this model classifies stance in tweets about health mandates. FAVOR AGAINST NONE bert_sequence_classifier_health_mandates_premise_tweet this model classifies premise in tweets about health mandates. has_premse has_no_premse bert_sequence_classifier_treatement_changes_sentiment_tweet this model classifies treatment changes reviews in tweets as negative and positive. positive negative bert_sequence_classifier_drug_reviews_webmd this model classifies drug reviews from WebMD as negative and positive. positive negative bert_sequence_classifier_self_reported_age_tweet this model classifies if there is a self-reported age in social media data. self_report_age no_report bert_sequence_classifier_self_reported_symptoms_tweet this model classifies self-reported COVID-19 symptoms in Spanish language tweets. Lit-News_mentions Self_reports non_personal_reports bert_sequence_classifier_self_reported_vaccine_status_tweet this model classifies self-reported COVID-19 vaccination status in tweets. Vaccine_chatter Self_reports bert_sequence_classifier_self_reported_partner_violence_tweet this model classifies self-reported Intimate partner violence (IPV) in tweets. intimate_partner_violence non_intimate_partner_violence bert_sequence_classifier_exact_age_reddit this model classifies if there is a self-reported age in social media forum posts (Reddit). self_report_age no_report bert_sequence_classifier_self_reported_stress_tweet this model classifies stress in social media (Twitter) posts in the self-disclosure category. stressed not-stressed Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_exact_age_reddit&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;class&quot;) ... sample_text = [&quot;Is it bad for a 19 year old it&#39;s been getting worser.&quot;, &quot;I was about 10. So not quite as young as you but young.&quot;] Results : +-+--+ |text |class | +-+--+ |Is it bad for a 19 year old its been getting worser. |[self_report_age]| |I was about 10. So not quite as young as you but young.|[no_report] | +-+--+ We are releasing 5 new public health classification models. model name description predicted entities bert_sequence_classifier_health_mentions This model can classify public health mentions in social media text figurative_mention other_mention health_mention classifierdl_health_mentions This model can classify public health mentions in social media text figurative_mention other_mention health_mention bert_sequence_classifier_vaccine_sentiment This model can extract information from COVID-19 Vaccine-related tweets neutral positive negative classifierdl_vaccine_sentiment This model can extract information from COVID-19 Vaccine-related tweets neutral positive negative bert_sequence_classifier_stressor This model can classify source of emotional stress in text. Family_Issues Financial_Problem Health_Fatigue_or_Physical Pain Other School Work Social_Relationships Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_health_mentions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) ... sample_text =[&quot;Another uncle of mine had a heart attack and passed away. Will be cremated Saturday I think I ve gone numb again RIP Uncle Mike&quot;, &quot;I don&#39;t wanna fall in love. If I ever did that, I think I&#39;d have a heart attack&quot;, &quot;Aluminum is a light metal that causes dementia and Alzheimer&#39;s disease. You should never put aluminum into your body (including deodorants).&quot;] Results : +--+--+ |text |result | +--+--+ |Another uncle of mine had a heart attack and passed away. Will be cremated Saturday I think I ve gone numb again RIP Uncle Mike |[health_mention] | |I don&#39;t wanna fall in love. If I ever did that, I think I&#39;d have a heart attack |[figurative_mention]| |Aluminum is a light metal that causes dementia and Alzheimer&#39;s disease. You should never put aluminum into your body (including deodorants).|[other_mention] | +--+--+ Pretrained Medication NER Pipeline to Augmented Posology NER Models with Drugbank Dataset We are releasing a medication NER pretrained pipeline to extract medications in clinical text. It’s an augmented version of posology NER model with Drugbank datasets and can retun all the medications with a single line of code without building a pipeline with models. ner_medication_pipeline: This pretrained pipeline can detect medication entities and label them as DRUG in clinical text. See Models Hub Page for more details. Example : from sparknlp.pretrained import PretrainedPipeline medication_pipeline = PretrainedPipeline(&quot;ner_medication_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;The patient was prescribed metformin 1000 MG, and glipizide 2.5 MG. The other patient was given Fragmin 5000 units, Xenaderm to wounds topically b.i.d. and OxyContin 30 mg.&quot;&quot;&quot; Results : |--|--| | chunk | ner_label | |--|--| | metformin 1000 MG | DRUG | | glipizide 2.5 MG | DRUG | | Fragmin 5000 units | DRUG | | Xenaderm | DRUG | | OxyContin 30 mg | DRUG | |--|--| Pretrained Medication Resolver Pipeline to Extract RxNorm, UMLS, NDC , SNOMED CT Codes and Action/Treatments We are releasing a medication resolver pipeline to extract medications and and resolve RxNorm, UMLS, NDC, SNOMED CT codes and action/treatments in clinical text. You can get those codes if available with a single line of code without building a pipeline with models. medication_resolver_pipeline: This pretrained pipeline can detect medication entities and resolve codes if available. Example : from sparknlp.pretrained import PretrainedPipeline medication_pipeline = PretrainedPipeline(&quot;medication_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;The patient was prescribed Mycobutn 150 MG, Salagen 5 MG oral tablet, The other patient is given Lescol 40 MG and Lidoderm 0.05 MG/MG, triazolam 0.125 MG Oral Tablet, metformin hydrochloride 1000 MG Oral Tablet&quot;&quot;&quot; Results : ||-||--|-|-|||-| | ner_chunk | RxNorm_Chunk | Action | Treatment | UMLS | SNOMED_CT | NDC_Product | NDC_Package | entity | ||-||--|-|-|||-| | Mycobutn 150 MG | 103899 | Antimiycobacterials | Infection | C0353536 | - | 00013-5301 | 00013-5301-17 | DRUG | | Salagen 5 MG oral tablet | 1000915 | Antiglaucomatous | Cancer | C0361693 | - | 59212-0705 | 59212-0705-10 | DRUG | | Lescol 40 MG | 103919 | Hypocholesterolemic | Heterozygous Familial Hypercholesterolemia | C0353573 | - | 00078-0234 | 00078-0234-05 | DRUG | | Lidoderm 0.05 MG/MG | 1011705 | Anesthetic | Pain | C0875706 | - | 00247-2129 | 00247-2129-30 | DRUG | | triazolam 0.125 MG Oral Tablet | 198317 | - | - | C0690642 | 373981005 | 00054-4858 | 00054-4858-25 | DRUG | | metformin hydrochloride 1000 MG Oral Tablet | 861004 | - | - | C0978482 | 376701008 | 00093-7214 | 00185-0221-01 | DRUG | ||-||--|-|-|||-| New Disease NER Model for Spanish Language We are releasing a new MedicalBertForTokenClassifier model to extract disease entities from social media text in Spanish. bert_token_classifier_disease_mentions_tweet: This model can extract disease entities in Spanish tweets and label them as ENFERMEDAD (disease). See Models Hub Page for more details. Example : ... tokenClassifier = MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_disease_mentions_tweet&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;label&quot;) .setCaseSensitive(True) ... example_text = &quot;&quot;&quot;El diagnóstico fueron varios. Principal: Neumonía en el pulmón derecho. Sinusitis de caballo, Faringitis aguda e infección de orina, también elevada. Gripe No. Estuvo hablando conmigo, sin exagerar, mas de media hora, dándome ánimo y fuerza y que sabe, porque ha visto&quot;&quot;&quot; Results : ++-+ |chunk |ner_label | ++-+ |Neumonía en el pulmón|ENFERMEDAD| |Sinusitis |ENFERMEDAD| |Faringitis aguda |ENFERMEDAD| |infección de orina |ENFERMEDAD| |Gripe |ENFERMEDAD| ++-+ 5 new Chunk Mapper Models to Convert Clinical Entities to Relevant Medical Terminology (UMLS) We are releasing 5 new ChunkMapperModel models to map clinical entities with their corresponding UMLS CUI codes. Mapper Name Source Target umls_clinical_drugs_mapper Drugs UMLS CUI umls_clinical_findings_mapper Clinical Findings UMLS CUI umls_disease_syndrome_mapper Disease and Syndromes UMLS CUI umls_major_concepts_mapper Clinical Major Concepts UMLS CUI umls_drug_substance_mapper Drug Substances UMLS CUI Example : ... ner_model = MedicalNerModel.pretrained(&quot;ner_posology_greedy&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;clinical_ner&quot;) ner_model_converter = NerConverterInternal() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;clinical_ner&quot;) .setOutputCol(&quot;ner_chunk&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;umls_drug_substance_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;umls_code&quot;]) .setLowerCase(True) ... example_text = &quot;&quot;&quot;The patient was given metformin, lenvatinib and lavender 700 ml/ml&quot;&quot;&quot; Results : ++++ | ner_chunk|ner_label|umls_code| ++++ | metformin| DRUG| C0025598| | lenvatinib| DRUG| C2986924| |lavender 700 ml/ml| DRUG| C0772360| ++++ 5 new Pretrained Resolver Pipelines to Convert Clinical Entities to Relevant Medical Terminology (UMLS) We now have 5 new resolver PretrainedPipeline to convert clinical entities to their UMLS CUI codes. You just need to feed your text and it will return the corresponding UMLS codes. Pipeline Name Entity Target umls_drug_resolver_pipeline Drugs UMLS CUI umls_clinical_findings_resolver_pipeline Clinical Findings UMLS CUI umls_disease_syndrome_resolver_pipeline Disease and Syndromes UMLS CUI umls_major_concepts_resolver_pipeline Clinical Major Concepts UMLS CUI umls_drug_substance_resolver_pipeline Drug Substances UMLS CUI Example : from sparknlp.pretrained import PretrainedPipeline pipeline= PretrainedPipeline(&quot;umls_clinical_findings_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) sample_text = &quot;HTG-induced pancreatitis associated with an acute hepatitis, and obesity&quot; Results : +-+++ |chunk |ner_label|umls_code| +-+++ |HTG-induced pancreatitis |PROBLEM |C1963198 | |an acute hepatitis |PROBLEM |C4750596 | |obesity |PROBLEM |C1963185 | +-+++ New Relation Extraction Model to Detect Drug and ADE relations We are releasing new re_ade_conversational model that can extract relations between DRUG and ADE entities from conversational texts and tag the relations as is_related and not_related. See Models Hub Page for more details. Example : ... re_model = RelationExtractionModel().pretrained(&quot;re_ade_conversational&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationPairs([&quot;ade-drug&quot;, &quot;drug-ade&quot;]) ... sample_text = &quot;E19.32 day 20 rivaroxaban diary. still residual aches and pains; only had 4 paracetamol today.&quot; Results : |--|-|-||-| | chunk1 | entitiy1 | chunk2 | entity2 | relation | |--|-|-||-| | residual aches and pains | ADE | rivaroxaban | DRUG | is_related | | residual aches and pains | ADE | paracetamol | DRUG | not_related | |--|-|-||-| New Module for Converting Annotation Lab (ALAB) Exports Into Suitable Formats for Training New Models We have a new sparknlp_jsl.alab module with functions for converting ALAB JSON exports into suitable formats for training NER, Assertion and Relation Extraction models. Example : from sparknlp_jsl.alab import get_conll_data, get_assertion_data, get_relation_extraction_data get_conll_data(spark=spark, input_json_path=&quot;alab_demo.json&quot;, output_name=&quot;conll_demo&quot;) assertion_df = get_assertion_data(spark=spark, input_json_path = &#39;alab_demo.json&#39;, assertion_labels = [&#39;ABSENT&#39;], relevant_ner_labels = [&#39;PROBLEM&#39;, &#39;TREATMENT&#39;]) relation_df = get_relation_extraction_data(spark=spark, input_json_path=&#39;alab_demo.json&#39;) These functions contain over 10 arguments each which give you all the flexibility you need to convert your annotations to trainable formats. These include parameters controlling tokenization, ground truth selections, negative annotations, negative annotation weights, task exclusions, and many more. To find out how to make best use of these functions, head over to this repository. Updated De-identification Pretrained Pipelines We have updated de-identification pretrained pipelines to provide better performance than ever before. This includes an update to the clinical_deidentification pretrained pipeline and a new light-weight version clinical_deidentification_slim. Example : from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;en&quot;, &quot;clinical/models&quot;) slim_deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) sample_text = &quot;Name : Hendrickson, Ora, Record date: 2093-01-13, # 719435&quot; Results : Name : &lt;PATIENT&gt;, Record date: &lt;DATE&gt;, &lt;MEDICALRECORD&gt; Name : [**************], Record date: [********], [****] Name : ****, Record date: ****, **** Name : Alexia Mcgill, Record date: 2093-02-19, Y138038 New setBlackList() Parameter in ChunkFilterer() Annotator We are releasing a new setBlackList() parameter in the ChunkFilterer() annotator. ChunkFilterer() lets through every chunk except those that match the list of phrases or regex rules in the setBlackList() parameter. Example : ... chunk_filterer = ChunkFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;) .setOutputCol(&quot;chunk_filtered&quot;) .setCriteria(&quot;isin&quot;) .setBlackList([&#39;severe fever&#39;, &#39;severe cough&#39;]) ... example_text= &quot;&quot;&quot;Patient with severe fever, severe cough, sore throat, stomach pain, and a headache.&quot;&quot;&quot; Results : +-++ |ner_chunk |chunk_filtered | +-++ |[severe fever, severe cough, sore throat, stomach pain, a headache]|[sore throat, stomach pain, a headache]| +-++ New Doc2ChunkInternal() Annotator We are releasing a Doc2ChunkInternal() annotator. This is a licensed version of the open source Doc2Chunk() annotator. You can now customize the tokenization step within Doc2Chunk(). This will be quite handy when it comes to training custom assertion models. Example : ... doc2ChunkInternal = Doc2ChunkInternal() .setInputCols(&quot;document&quot;,&quot;token&quot;) .setStartCol(&quot;start&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;doc2chunkInternal&quot;) ... df= spark.createDataFrame([ [&quot;The mass measures 4 x 3.5cm in size more.&quot;,8,&quot;size&quot;], [&quot;The mass measures 4 x 3.5cm in size more.&quot;,9,&quot;size&quot;]]).toDF(&quot;sentence&quot;,&quot;start&quot;, &quot;target&quot;) Results : +--+--++--+--+ | sentence|start|target| doc2chunkInternal| doc2chunk| +--+--++--+--+ |The mass measures 4 x 3.5cm in size more.| 8| size|[{chunk, 31, 34, size, {sentence -&gt; 0, chunk -&gt; 0}, []}]|[{chunk, 31, 34, size, {sentence -&gt; 0, chunk -&gt; 0}, []}] | |The mass measures 4 x 3.5cm in size more.| 9| size| []|[{chunk, 31, 34, size, {sentence -&gt; 0, chunk -&gt; 0}, []}] | +--+--++--+--+ Listing Pretrained Clinical Models and Pipelines with One-Liner We have new returnPrivatePipelines() and returnPrivateModels() features under InternalResourceDownloader package to return licensed models and pretrained pipelines as a list. Example : from sparknlp_jsl.pretrained import InternalResourceDownloader # pipelines = InternalResourceDownloader.returnPrivatePipelines() assertion_models = InternalResourceDownloader.returnPrivateModels(&quot;AssertionDLModel&quot;) Results : [[&#39;assertion_ml&#39;, &#39;en&#39;, &#39;2.0.2&#39;], [&#39;assertion_dl&#39;, &#39;en&#39;, &#39;2.0.2&#39;], [&#39;assertion_dl_healthcare&#39;, &#39;en&#39;, &#39;2.7.2&#39;], [&#39;assertion_dl_biobert&#39;, &#39;en&#39;, &#39;2.7.2&#39;], [&#39;assertion_dl&#39;, &#39;en&#39;, &#39;2.7.2&#39;], [&#39;assertion_dl_radiology&#39;, &#39;en&#39;, &#39;2.7.4&#39;], [&#39;assertion_jsl_large&#39;, &#39;en&#39;, &#39;3.1.2&#39;], [&#39;assertion_jsl&#39;, &#39;en&#39;, &#39;3.1.2&#39;], [&#39;assertion_dl_scope_L10R10&#39;, &#39;en&#39;, &#39;3.4.2&#39;], [&#39;assertion_dl_biobert_scope_L10R10&#39;, &#39;en&#39;, &#39;3.4.2&#39;], [&#39;assertion_oncology_treatment_binary_wip&#39;, &#39;en&#39;, &#39;3.5.0&#39;]] Bug Fixes ZeroShotRelationExtractionModel: Fixed the issue that blocks the use of this annotator. AnnotationToolJsonReader: Fixed the issue with custom pipeline usage in this annotator. RelationExtractionApproach: Fixed issues related to training logs and inference. New and Updated Notebooks Clinical Named Entity Recognition Notebook: Added new getPrivateModel() feature Clinical Entity Resolvers Notebook: Added an example of reseolver pretrained pipelines Pretrained Clinical Pipelines Notebook: Pipeline list updated and examples of resolver pretrained pipelines were added Chunk Mapping Notebook: New mapper models added into model list All certification notebooks updated with v4.0.0. List of Recently Updated and Added Models and Pretrained Pipelines bert_token_classifier_ner_anatem bert_token_classifier_ner_bc2gm_gene bert_token_classifier_ner_bc4chemd_chemicals bert_token_classifier_ner_bc5cdr_chemicals bert_token_classifier_ner_bc5cdr_disease bert_token_classifier_ner_jnlpba_cellular bert_token_classifier_ner_linnaeus_species bert_token_classifier_ner_ncbi_disease bert_token_classifier_ner_species bert_sequence_classifier_ade_augmented bert_sequence_classifier_health_mandates_stance_tweet bert_sequence_classifier_health_mandates_premise_tweet bert_sequence_classifier_treatement_changes_sentiment_tweet bert_sequence_classifier_drug_reviews_webmd bert_sequence_classifier_self_reported_age_tweet bert_sequence_classifier_self_reported_symptoms_tweet =&gt; es bert_sequence_classifier_self_reported_vaccine_status_tweet bert_sequence_classifier_self_reported_partner_violence_tweet bert_sequence_classifier_exact_age_reddit bert_sequence_classifier_self_reported_stress_tweet bert_token_classifier_disease_mentions_tweet =&gt; es bert_token_classifier_ner_ade_tweet_binary bert_token_classifier_ner_pathogen clinical_deidentification clinical_deidentification_slim umls_clinical_drugs_mapper umls_clinical_findings_mapper umls_disease_syndrome_mapper umls_major_concepts_mapper umls_drug_substance_mapper umls_drug_resolver_pipeline umls_clinical_findings_resolver_pipeline umls_disease_syndrome_resolver_pipeline umls_major_concepts_resolver_pipeline umls_drug_substance_resolver_pipeline classifierdl_health_mentions bert_sequence_classifier_health_mentions ner_medication_pipeline bert_sequence_classifier_vaccine_sentiment classifierdl_vaccine_sentiment bert_sequence_classifier_stressor re_ade_conversational medication_resolver_pipeline Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_0_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_0_2"
  },
  "1454": {
    "id": "1454",
    "title": "NLP Lab Release Notes 4.10.0",
    "content": "Trial License Integration, Comment and Tag Functionality, and Enhanced Task Export Filters NLP Lab 4.10 The release of NLP Lab version 4.10 comes with an array of exciting new features aimed at enhancing user experience and improving the efficiency of the platform. Among the notable additions are the integration of a get trial license feature, enabling users to explore the full potential of NLP Lab, and the seamless automatic import of the trial license into the platform. Additionally, users can now conveniently add comments in the Labeling Page, providing a more collaborative and organized environment for annotation tasks. Another valuable feature introduced in this release is the ability to add tags directly in the Labeling Screen, allowing for better categorization and management of labeled data. Lastly, the update includes an expanded range of filters when exporting tasks, empowering users to customize and streamline their task exports. Here are the highlights of this release: Get trial license from License page In version 4.10, we have implemented an updated License page layout, providing a simpler process for acquiring a trial license. Users can now request a trial license directly from the License page, eliminating the need to navigate to external pages. This new workflow introduces a dedicated “Get License” tab, while the Import License and Existing Licenses tabs remain unchanged. To obtain a trial license, users are required to fill out the form on the “Get License” tab, providing their organizational email. Once the form is submitted, a validation link is sent to the provided email address and the trial license is automatically imported to the NLP Lab when the link is clicked, making it readily available for use. Comments in the Labeling Page NLP Lab 4.10 introduces an enhanced comment feature for labeling pages, enabling users to easily add, update, and delete comments within labeling pages. This feature significantly improves work efficiency and productivity and enhances communication between team members, leading to faster delivery and more effective collaboration. To access this feature, users can find the New Burger menu located at the top right of the labeling page. Within the burger menu, users will find an option for Comments, which displays the total number of comments. By clicking this option, a new pop-up window will appear, providing access to various commenting features. Tags from the Labeling Screen NLP Lab 4.10 introduces an enhanced tags feature for labeling pages. This feature provide users with a convenient way to create, add, and remove tags from tasks directly on the labeling page. It significantly contributes to better organization and enahnced productivity streamlining task management by offering users increased flexibility in categorizing and tracking their labeled data. Similar to the comment feature described above, the tag feature can be accessed through the burger menu located at the top right corner. The burger menu displays the total number of tags associated with its functions. By clicking the burger menu option, a new popup window appears, allowing users to add existing tags or create new ones. Filters for exporting tasks This version of NLP Lab comes with a new feature: selective annotation exports. Users can now choose which annotations to export by using two new filters on the export page. These new filters can be combined with other filter options like tags, Only ground truth, and Exclude tasks without Completions. Filter Exported Annotations by Task: this filter allows users to select annotations based on the task (NER, Classification, Assertion, Relation Extraction) Select Annotations to Include In the Export: this filter can be used to select available labels, classes, assertion labels, or relations. Improvements Add video template to the project content type The current release, re-introduces the Video content type to the project configuration page. This provides users with a flexible way to annotate projects that are based on video content. Image path for visual NER task export JSON should always be in list The inconsistency with regards to the format of the image property value in the exported task JSON was eliminated in the current version. When there was a single image task, the image property had a value of string type, but for multiple images, it was of list type. To ensure consistency, the image property will now always have a value of list type. Remove items in chart with empty value for “Tasks by Status” chart In the previous versions, “Tasks by status” chart displayed redundant values(0.00%) when there are no tasks for the specific status category. In the current release, these redundant values have been removed from “Tasks by status” chart in the analytics page. Tasks and Project filters based on multiple tags Filtering tasks based on tags , inside the task view’s tag filter has been updated to allow users to select multiple tags from the Tags dropdown. This allows filtering of the tasks based on multiple criteria. In our previous versions, the users were limited to selecting only one tag at a time, making the filtering mechanism restrictive when attempting to narrow down tasks based on multiple tags simultaneously. The new functionality increases productivity by allowing users to apply multiple filter criteria for retreiving the desired list of tasks, matching at least one of the selected tags. Additionally, the same improved filter behaivour can be found in project page too. This provides users with increased flexibility and efficiency in filtering tasks based on multiple tags, thereby improving task and project management and facilitating a more streamlined workflow. Bug Fixes ALAB-2212 Audio/Video cannot be played after the completion is submitted In previous versions, users were not able to play/pause Audio/Video after the completion is submited. The bug has been resolved in the latest release, allowing users to play/pause Audio/Video after the completion is submitted. ALAB-2312 When the group color is white the project name, description and instructions cannot be seen on the project card In the latest release, the problem with the visibility of the project name, description, and instructions on the projects page has been resolved. Previously, when assigning the group color white to the project group, the text was not visible because it blended with the white background. ALAB-3133 Validation is missing in the UI from the configuration when invalid orientation is added This release includes the addition of validation for incorrect orientation in project configuration, accompanied by appropriate error messaging. Hence, project configurations will only permit the inclusion of “Vertical Layout,” “Horizontal Layout,” and “Horizontal-Sticky Layout. Databricks license should not be imported into NLP Lab It is no longer possible to import Spark NLP licenses generated for Databricks into the NLP Lab. Users will be presented with an error message in the UI if they attempt to upload such licenses. By modifying the URL, the user can access pages of projects that have not been shared with them. In previous versions, users were able to access configuration pages of projects that had not been shared with them by modifying the URL. However, this issue has been resolved in the current version. Pretrained assertions are listed in dropdown when creating relation prompts When creating relation prompts, a list of labels is displayed. However, the list previously included assertion labels, which are not supported for creating relation prompts. As a result, the assertion label will no longer be shown when users create relation prompts. ALAB-3365 Single-word annotation is split into multiple blocks when the user is annotating a task In earlier version, annotating a single word would result in it being split into multiple blocks instead of being annotated as a single word. This issue occurred when highlighting only a few characters of the word without selecting any label initially and later attempting to annotate the entire word. This bug has been fixed in the latest release. ALAB-3368 Pre-annotation button becomes irresponsive in a project with 1000s of pre-annotated task Previously, after running pre-annotation on thousands of tasks, the pre-annotation status was missing from the task cards on the Tasks page. Additionally, the pre-annotation button was unresponsive. These issues have been resolved in the latest release. The responsiveness of the pre-annotation button has also users can navigate seamlessly between different pages on the Tasks page. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_10_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_10_0"
  },
  "1455": {
    "id": "1455",
    "title": "NLP Lab Release Notes 4.10.1",
    "content": "4.10.1 Release date: 12-06-2023 The v4.10.1 version release includes the following bug fixes: Improvement Remove recognized text seen on the top of the Visual NER task Bug Fixes Airflow-scheduler pod randomly crashes When one of the two visual NER tasks with the same name is deleted, the image of the other task goes missing When the user clicks on “buy license” the user is redirected to “license.johnsnowlabs.com” instead of “my.johnsnowlabs.com” Prediction not generated for Visual NER project Old visual NER tasks without comments are shown as task Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_10_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_10_1"
  },
  "1456": {
    "id": "1456",
    "title": "NLP Lab Release Notes 4.1.0",
    "content": "4.1.0 Release date: 30-09-2022 Here are the highlights of this release: Highlights Updated login page. This release of Annotation Lab has an updated Login View. Unlike a plain old form, we have an aesthetically pleasing Login Page with a section highlighting the key features of Annotation Lab. Now the Sign-In page highlights the new features we add to the Annotation Lab with animated GIFs. Project Dashboard. The Projects dashboard has a new structure with visually pleasing project cards. For each project, details like description, tasks count, groups, team members, etc. are now available on the main dashboard so users can quickly identify the projects they need to work on, without navigating to the Project Details page. Projects can also be sorted by name or date of creation. Categorize Projects with Groups. Projects can be organized in custom groups, and each project card will inherit the group color so that the users can visually distinguish the projects easily in a large cluster of projects. Also, the new color picker for the group is much more user-friendly and customizable, unlike the random color generator in the previous versions of Annotation Lab. Project Filters. The filters associated with the Projects dashboard are clear, simple, and precise to make the users more productive and efficient while working with a large number of projects. Project Creation Wizard. A project creation wizard is now available and will guide users through each step of the project creation and configuration. Two navigation buttons Back and Next were added to the Team page. The Back button navigates to the Project’s Details page and the Next button to navigates to the Configuration page. Optimized Task page. The newly redesigned task page incorporates all the Task Related operations that a user needs to perform, such as Import, Export, Labeling, Pre-Annotation, etc., in a single page without having to navigate between different pages. Support for multiple comments. Previously a comment could be pinned to a task from the Task List Page where anyone could leave a note for peer contributors. With this release, multiple comments can be added to any task. The users can have a to and fro communication in the comment section resulting in the improved efficiency of the annotation process. New Import page. The new Import Page contains detailed information on the supported file formats with sample files attached to them. Users can refer to the samples and create their files/tasks to import with minimum help. New Export page. The new Export page simplifies the experience while exporting annotations in different formats. The Annotation page. The annotation page has been reorganized and optimized as annotators spend most of their time on this page. The Side Column now separates Annotation, Versions, and Progress into separate tabs. The Regions/Labels UI is migrated into a collapsible structure that inherits the Label color defined in the project configuration to make it easy for users to identify annotations in case of a large number of Regions or Labels. The role switcher is now more visible on the upper right side, and the choice is persisted when navigating to other pages of the same project. New Train page. The Train page is now part of the Project Menu, for improved accessibility. It has been revised to improve the experience and guide users on each step. Users can now follow a step-wise wizard view or a synthesis view for initiating the training of a model. During the training, a progress bar is shown to give users basic information on the status of the training process. New Models HUB page. This version comes with brightened and improved Models HUB page. The cards for models, embeddings, and rules are visually pleasing and highlight their source. The displayed information is much more compact and easy to read. The cards are visually separable just by looking at the colors and the card types. New License page. The License Page now has a tabbed view. The first tab allows importing of the JSL license in the preferred method. The second tab displays the already existing license on a full page with corresponding details and actions. The page provides detailed instructions on how to import licenses and how to get a trial license. New Users page. The Users page is redesigned to make the operations regarding users’ information more time efficient and less confusing. The Personal Info, Role, and Credential sections are merged into a single page so that users do not have to click around to add/update. New Analytics Request page. The Swagger and Secrets Page have been merged into one single API Integration page. The users can find everything needed on that page without having to click around for the needed information regarding the APIs. New Clusters page. The Servers page has been redesigned and renamed into the Clusters page. The page now shows more details like License type/scope and Server usage of all the spawned instances at a given time. A license information banner is now available on the Clusters and License pages. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_1_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_1_0"
  },
  "1457": {
    "id": "1457",
    "title": "Spark NLP release notes 4.1.0",
    "content": "4.1.0 Release date: 22-09-2022 Overview We are glad to announce that Spark OCR 4.1.0 has been released! This release comes with new features, enhancements, fixes and more!. New Features DicomSplitter: new annotator that helps to distribute and split Dicom files into multiple frames. It supports multiple strategies, similar to our PdfToImage annotator. It enables parallel processing of different frames and keeps memory utilization bounded. For big datasets, or memory constrained environments, it enables Streaming Mode to process frames 1-by-1, resulting in very low memory requirements. DicomToImageV2: new annotator that supports loading images from Dicom files/frames, without loading Dicom files into memory. Targeted to datasets containing big Dicom files. This is an example on how to use the two above mentioned annotators to process images, coming from your big Dicom files in a memory constrained setting, splitter = DicomSplitter() splitter.setInputCol(&quot;path&quot;) splitter.setOutputCol(&quot;frames&quot;) splitter.setSplitNumBatch(2) splitter.setPartitionNum(2) dicom = DicomToImageV2() dicom.setInputCols([&quot;path&quot;, &quot;frames&quot;]) dicom.setOutputCol(&quot;image&quot;) pipeline = PipelineModel(stages=[ splitter, dicom ]) New image pre-processing annotators: ImageHomogenizeLight, ImageRemoveBackground, ImageEnhanceContrast, ImageRemoveGlare. For examples on how to use them, and their amazing results check this notebook: SparkOcrImagePreprocessing.ipynb. Improvements VisualDocumentClassifierV2 training has been improved for more efficient memory utilization. Library dependencies have been updated to remove security vulnerabilities. Bug Fixes The infamous “ImportError: No module named resource” bug that was affecting Windows users has been fixed. Some issues while loading images using AlabReader have been fixed. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_1_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_1_0"
  },
  "1458": {
    "id": "1458",
    "title": "Spark NLP for Healthcare Release Notes 4.1.0",
    "content": "4.1.0 Highlights Zero-Shot NER model to extract entities with no training dataset 7 new clinical NER models in Spanish 8 new clinical classification models in English and German related to public health topics (depression, covid sentiment, health mentions) New pretrained chunk mapper model (drug_ade_mapper) to map drugs with their corresponding adverse drug events A new pretrained resolver pipeline (medication_resolver_pipeline) to extract medications and resolve their adverse reactions (ADE), RxNorm, UMLS, NDC, SNOMED CT codes and action/treatments in clinical text with a single line of code. Updated NER profiling pretrained pipelines with new NER models to allow running 64 clinical NER models at once Core improvements and bug fixes New and updated notebooks 20+ new clinical models and pipelines added &amp; updated in total Zero-Shot NER model to Extract Entities With No Training Dataset We are releasing the first of its kind Zero-Shot NER model that can detect any named entities without using any annotated dataset to train a model. It allows extracting entities by crafting appropriate prompts to query any RoBERTa Question Answering model. See Models Hub Page for more details. Example : ... zero_shot_ner = ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clincial/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;PROBLEM&quot;: [&quot;What is the disease?&quot;, &quot;What is his symptom?&quot;, &quot;What is her disease?&quot;, &quot;What is his disease?&quot;, &quot;What is the problem?&quot; ,&quot;What does a patient suffer&quot;, &#39;What was the reason that the patient is admitted to the clinic?&#39;], &quot;DRUG&quot;: [&quot;Which drug?&quot;, &quot;Which is the drug?&quot;, &quot;What is the drug?&quot;, &quot;Which drug does he use?&quot;, &quot;Which drug does she use?&quot;, &quot;Which drug do I use?&quot;, &quot;Which drug is prescribed for a symptom?&quot;], &quot;ADMISSION_DATE&quot;: [&quot;When did patient admitted to a clinic?&quot;], &quot;PATIENT_AGE&quot;: [&quot;How old is the patient?&quot;,&#39;What is the age of the patient?&#39;] }) ... sample_text = [&quot;The doctor pescribed Majezik for my severe headache.&quot;, &quot;The patient was admitted to the hospital for his colon cancer.&quot;, &quot;27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis.&quot;] Results : ++--+-+ | chunk| ner_label|confidence| ++--+-+ | Majezik| DRUG|0.64671576| | severe headache| PROBLEM| 0.5526346| | colon cancer| PROBLEM| 0.8898498| | 27 years old| PATIENT_AGE| 0.6943085| | Sep 1st|ADMISSION_DATE|0.95646095| |a right-sided pleural effusion for thoracentesis| PROBLEM|0.50026613| ++--+-+ 7 New Clinical NER Models in Spanish We are releasing 4 new MedicalNerModel and 3 new MedicalBertForTokenClassifier NER models in Spanish. model name description predicted entities ner_negation_uncertainty This model detects relevant entities from Spanish medical texts NEG UNC USCO NSCO disease_mentions_tweet This model detects disease mentions in Spanish tweets ENFERMEDAD ner_clinical_trials_abstracts This model detects relevant entities from Spanish clinical trial abstracts CHEM DISO PROC ner_pharmacology This model detects pharmacological entities from Spanish medical texts PROTEINAS NORMALIZABLES bert_token_classifier_ner_clinical_trials_abstracts This model detects relevant entities from Spanish clinical trial abstracts CHEM DISO PROC bert_token_classifier_negation_uncertainty This model detects relevant entities from Spanish medical texts NEG NSCO UNC USCO bert_token_classifier_pharmacology This model detects pharmacological entities from Spanish medical texts PROTEINAS NORMALIZABLES Example : ... ner = MedicalNerModel.pretrained(&#39;ner_clinical_trials_abstracts&#39;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) example_text= &quot;&quot;&quot;&quot;Efecto de la suplementación con ácido fólico sobre los niveles de homocisteína total en pacientes en hemodiálisis. La hiperhomocisteinemia es un marcador de riesgo independiente de morbimortalidad cardiovascular. Hemos prospectivamente reducir los niveles de homocisteína total (tHcy) mediante suplemento con ácido fólico y vitamina B6 (pp), valorando su posible correlación con dosis de diálisis, función residual y parámetros nutricionales.&quot;&quot;&quot;&quot; Results : +--++ |chunk |ner_label| +--++ |suplementación |PROC | |ácido fólico |CHEM | |niveles de homocisteína |PROC | |hemodiálisis |PROC | |hiperhomocisteinemia |DISO | |niveles de homocisteína total|PROC | |tHcy |PROC | |ácido fólico |CHEM | |vitamina B6 |CHEM | |pp |CHEM | |diálisis |PROC | |función residual |PROC | +--++ 8 New Clinical Classification Models in English and German Related to Public Health Topics (Depression, Covid Sentiment, Health Mentions) We are releasing 8 new MedicalBertForSequenceClassification models to classify text from social media data in English and German related to public health topics (depression, covid sentiment, health mentions) model name description predicted entities bert_sequence_classifier_depression_binary This model classifies whether a social media text expresses depression or not. no-depression depression bert_sequence_classifier_health_mentions_gbert_large This GBERT-large based model classifies public health mentions in German social media text. non-health health-related bert_sequence_classifier_health_mentions_medbert This German-MedBERT based model classifies public health mentions in German social media text. non-health health-related bert_sequence_classifier_health_mentions_gbert This GBERT-large based model classifies public health mentions in German social media text. non-health health-related bert_sequence_classifier_health_mentions_bert This bert-base-german based model classifies public health mentions in German social media text. non-health health-related bert_sequence_classifier_depression_twitter This PHS-BERT based model classifies whether tweets contain depressive text or not. depression no-depression bert_sequence_classifier_depression This PHS-BERT based model classifies depression level of social media text into three levels. no-depression minimum high-depression bert_sequence_classifier_covid_sentiment This BioBERT based sentiment analysis model classifies whether a tweet contains positive, negative, or neutral sentiments about COVID-19 pandemic. neutral positive negative Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_depression_twitter&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) example_text = [&quot;Do what makes you happy, be with who makes you smile, laugh as much as you breathe, and love as long as you live!&quot;, &quot;Everything is a lie, everyone is fake, I&#39;m so tired of living&quot;] Results : +++ |text |result | +--++ |Do what makes you happy, be with who makes you smile, laugh as much as you breathe, and love as long as you live!|[no-depression]| |Everything is a lie, everyone is fake, I am so tired of living. |[depression] | +--++ New Pretrained Chunk Mapper Model (drug_ade_mapper) to Map Drugs With Their Corresponding Adverse Drug Events We are releasing new drug_ade_mapper pretrained chunk mapper model to map drugs with their corresponding adverse drug events. See Models Hub Page for more details. Example : ... chunkMapper = ChunkMapperModel.pretrained(&quot;drug_ade_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;ADE&quot;]) ... sample_text = &quot;The patient was prescribed 1000 mg fish oil and multivitamins. She was discharged on zopiclone and ambrisentan.&quot; Results : +-++-+ |ner_chunk |ade_mappings|all_relations | +-++-+ |1000 mg fish oil|Dizziness |Myocardial infarction:::Nausea | |multivitamins |Erythema |Acne:::Dry skin:::Skin burning sensation:::Inappropriate schedule of product administration| |zopiclone |Vomiting |Malaise:::Drug interaction:::Asthenia:::Hyponatraemia | |ambrisentan |Dyspnoea |Therapy interrupted:::Death:::Dizziness:::Drug ineffective | +-++-+ A New Pretrained Resolver Pipeline (medication_resolver_pipeline) to Extract Medications and Resolve Their Adverse Reactions (ADE), RxNorm, UMLS, NDC, SNOMED CT Codes and Action/Treatments in Clinical Text. We are releasing the medication_resolver_pipeline pretrained pipeline to extract medications and resolve their adverse reactions (ADE), RxNorm, UMLS, NDC, SNOMED CT codes and action/treatments in clinical text with a single line of code. Also, you can use medication_resolver_transform_pipeline to use transform method of Spark. See Models Hub Page for more details. Example : from sparknlp.pretrained import PretrainedPipeline sample_text = &quot;&quot;&quot;The patient was prescribed Amlodopine Vallarta 10-320mg, Eviplera. The other patient is given Lescol 40 MG and Everolimus 1.5 mg tablet.&quot;&quot;&quot; med_pipeline = PretrainedPipeline(&quot;medication_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) med_pipeline.annotate(sample_text) med_transform_pipeline = PretrainedPipeline(&quot;medication_resolver_transform_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) med_transform_pipeline.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : | chunk | ner_label | ADE | RxNorm | Action | Treatment | UMLS | SNOMED_CT | NDC_Product | NDC_Package | |:--|:|:-|:|:|:-|:|:|:--|:--| | Amlodopine Vallarta 10-320mg | DRUG | Gynaecomastia | 722131 | NONE | NONE | C1949334 | 425838008 | 00093-7693 | 00093-7693-56 | | Eviplera | DRUG | Anxiety | 217010 | Inhibitory Bone Resorption | Osteoporosis | C0720318 | NONE | NONE | NONE | | Lescol 40 MG | DRUG | NONE | 103919 | Hypocholesterolemic | Heterozygous Familial Hypercholesterolemia | C0353573 | NONE | 00078-0234 | 00078-0234-05 | | Everolimus 1.5 mg tablet | DRUG | Acute myocardial infarction | 2056895 | NONE | NONE | C4723581 | NONE | 00054-0604 | 00054-0604-21 | Updated NER Profiling Pretrained Pipelines With New NER Models to Allow Running 64 Clinical NER Models at Once We have upadated ner_profiling_clinical and ner_profiling_biobert pretrained pipelines with the new NER models. When you run these pipelines over your text, now you will end up with the predictions coming out of 64 clinical NER models in ner_profiling_clinical and 22 clinical NER models in ner_profiling_biobert results. You can check ner_profiling_clinical and ner_profiling_biobert Models Hub pages for more details and the NER model lists that these pipelines include. Core Improvements and Bug Fixes Updated HCC module (from sparknlp_jsl.functions import profile) with the new changes in HCC score calculation functions. AnnotationToolJsonReader, NerDLMetrics and StructuredDeidentification: These annotators can be used on Spark 3.0 now. NerDLMetrics: Added case_sensitive parameter and case sensitivity issue in tokens is solved. Added drop_o parameter to computeMetricsFromDF method and dropO parameter in NerDLMetrics class is deprecated. MedicalNerModel: Inconsistent NER model results between different versions issue is solved. AssertionDLModel: Unindexed chunks will be ignored by the AssertionDLModel instead of raising an exception. ContextualParserApproach: These two issues are solved when using ruleScope: &quot;document&quot; configuration: Wrong index computations of chunks after matching sub-tokens. Including sub-token matches even though completeMatchRegex: &quot;true&quot;. New and Updated Notebooks We have a new Zero-Shot Clinical NER Notebook to show how to use zero-shot NER model. We have updated Medicare Risk Adjustment Score Calculation Notebook with the new changes in HCC score calculation functions. We have updated these notebooks with the new updates in NER profiling pretrained pipelines: Clinical Named Entity Recognition Model Notebook Pretrained Clinical Pipelines Notebook Pretrained NER Profiling Pipelines Notebook We have updated Clinical Assertion Model Notebook according to the bug fix in the training section. We moved all Azure/AWS/Databricks notebooks to products folder in spark-nlp-worksop repo. 20+ New Clinical Models and Pipelines Added &amp; Updated in Total zero_shot_ner_roberta medication_resolver_pipeline medication_resolver_transform_pipeline ner_profiling_clinical ner_profiling_biobert drug_ade_mapper ner_negation_uncertainty disease_mentions_tweet ner_clinical_trials_abstracts ner_pharmacology bert_token_classifier_ner_clinical_trials_abstracts bert_token_classifier_negation_uncertainty bert_token_classifier_pharmacology bert_sequence_classifier_depression_binary bert_sequence_classifier_health_mentions_gbert_large bert_sequence_classifier_health_mentions_medbert bert_sequence_classifier_health_mentions_gbert bert_sequence_classifier_health_mentions_bert bert_sequence_classifier_depression_twitter bert_sequence_classifier_depression bert_sequence_classifier_covid_sentiment Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_1_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_1_0"
  },
  "1459": {
    "id": "1459",
    "title": "NLP Lab Release Notes 4.2.0",
    "content": "4.2.0 Release date: 02-11-2022 Annotation Lab 4.2.0 supports projects combining models trained with multiple embeddings for preannotation as well as predefined Demo projects that can be imported with the click of a button for easy experimentations and features testing. The Project Configuration page now has a new “View” step to configure the layout of the Labeling page. The release also includes stabilization and fixes bugs reported by our user community. Here are the highlights of this release: Highlights Projects can reuse and combine models trained with different embeddings for pre-annotation. Now, it is easily possible to use models with different embeddings and deploy them as part of the same pre-annotation server. In the customize configuration page all the added models and their embeddings are listed. The list makes it easier for the user to delete the labels of a specific model. Demo Projects can be imported for experiments. To allow users access and experiment with already configured and populated projects we have added the option to import predefined Demo projects. This is for helping users understand the various features offered by the Annotation Lab. The user can import demo projects from the Import Project window, by clicking on the Import Demo Project option. Visual Update of the Annotation Screen Layout from the View Tab. A new tab - “View” - has been added to the project setup wizard after the “Content Type” selection tab. This gives users the ability to set different layouts based on their needs and preferences. Support for Granular License Scopes. This versions brings support for more granular license scopes such as Healthcare: Inference, Healthcare: Training, OCR: Inference or OCR: Training. This is in line with the latest developments of the John Snow Labs licenses. Easy Reuse and Editing of Pre-annotations. For an improved usability, when pre-annotations are available for a task, those will be shown by default when accessing the labeling screen. Users can filter them based on the confidence score and the either accept the visible annotations as a new submitted completion or start editing those as part of a new completion. Easy Export of Large Visual NER Projects. From version 4.2.0 users will be able to export large NER/ Visual NER projects with a size bigger than 500 MB. Smaller Project Tiles on the Projects Dashboard. The size of a project tile was compacted in this version in order to increase the number of project cards that could be displayed on the screen at one time. Confusion Matrix in Training Logs for NER projects. With the addition of confusion matrix it will be easier to understand the performance of the model and judge whether the model is underfitting or overfitting. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_2_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_2_0"
  },
  "1460": {
    "id": "1460",
    "title": "Spark NLP release notes 4.2.0",
    "content": "4.2.0 Release date: 31-10-2022 We are glad to announce that Spark OCR 4.2.0 has been released. This is mostly a compatibility release to ensure compatibility of Spark OCR against Spark NLP 4.2.1, and Spark NLP Healthcare 4.2.1. Improvements Improved memory consumption and performance in the training of Visual NER models. New Features PdfToForm new param: useFullyQualifiedName, added capability to return fully qualified key names. New or Updated Notebooks SparkOcrProcessMultiplepageScannedPDF.ipynb has been added to show how to serve a multi-page document processing pipeline. SparkOcrDigitalFormRecognition.ipynb has been updated to show utilization of useFullyQualifiedName parameter. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_2_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_2_0"
  },
  "1461": {
    "id": "1461",
    "title": "Spark NLP for Healthcare Release Notes 4.2.0",
    "content": "4.2.0 Highlights Introducing 46 new Oncology specific pretrained models (12 NER, 12 BERT-based token classification, 14 relation extraction, 8 assertion status models) Brand new NerQuestionGenerator annotator for automated prompt generation for a QA-based Zero-Shot NER model Updated ALAB (Annotation Lab) module becoming a fullfledged suite to manage activities on ALAB via its API remotely New pretrained assertion status detection model (assertion_jsl_augmented) to classify the negativity &amp; assertion scope of medical concepts New chunk mapper models and pretrained pipeline to map entities (phrases) to their corresponding ICD-9, ICD-10-CM and RxNorm codes New ICD-9-CM sentence entity resolver model and pretrained pipeline New shifting days feature in DeIdentification by using the new DocumentHashCoder annotator Updated NER model finder pretrained pipeline to help users find the most appropriate NER model for their use case in one-liner Medicare risk adjustment score calculation module updated to support different version and year combinations Core improvements and bug fixes New and updated notebooks 50+ new clinical models and pipelines added &amp; updated in total Introducing 46 New Oncology Specific Pretrained Models (12 NER, 12 BERT-Based Token Classification, 14 Relation Extraction, 8 Assertion Status Models) These models will be the first versions (wip - work in progress) of Oncology models. See Oncology Model Notebook for examples. New Oncological NER and BERT-Based Token Classification Models We have 12 new oncological NER and their BERT-based token classification models. NER model name (MedicalNerModel) BERT-Based model name (MedicalBertForTokenClassifier) description predicted entities ner_oncology_therapy_wip bert_token_classifier_ner_oncology_therapy_wip This model extracts entities related to cancer therapies, including posology entities and response to treatment, using granular labels. Response_To_Treatment, Line_Of_Therapy, Cancer_Surgery, Radiotherapy, Immunotherapy, Targeted_Therapy, Hormonal_Therapy, Chemotherapy, Unspecific_Therapy, Route, Duration, Cycle_Count, Dosage, Frequency, Cycle_Number, Cycle_Day, Radiation_Dose ner_oncology_diagnosis_wip bert_token_classifier_ner_oncology_diagnosis_wip This model extracts entities related to cancer diagnosis, including the presence of metastasis. Grade, Staging, Tumor_Size, Adenopathy, Pathology_Result, Histological_Type, Metastasis, Cancer_Score, Cancer_Dx, Invasion, Tumor_Finding, Performance_Status ner_oncology_wip bert_token_classifier_ner_oncology_wip This model extracts more than 40 oncology-related entities. Histological_Type, Direction, Staging, Cancer_Score, Imaging_Test, Cycle_Number, Tumor_Finding, Site_Lymph_Node, Invasion, Response_To_Treatment, Smoking_Status, Tumor_Size, Cycle_Count, Adenopathy, Age, Biomarker_Result, Unspecific_Therapy, Site_Breast, Chemotherapy, Targeted_Therapy, Radiotherapy, Performance_Status, Pathology_Test, Site_Other_Body_Part, Cancer_Surgery, Line_Of_Therapy, Pathology_Result, Hormonal_Therapy, Site_Bone, Biomarker, Immunotherapy, Cycle_Day, Frequency, Route, Duration, Death_Entity, Metastasis, Site_Liver, Cancer_Dx, Grade, Date, Site_Lung, Site_Brain, Relative_Date, Race_Ethnicity, Gender, Oncogene, Dosage, Radiation_Dose ner_oncology_tnm_wip bert_token_classifier_ner_oncology_tnm_wip This model extracts mentions related to TNM staging. Lymph_Node, Staging, Lymph_Node_Modifier, Tumor_Description, Tumor, Metastasis, Cancer_Dx ner_oncology_anatomy_general_wip bert_token_classifier_ner_oncology_anatomy_general_wip This model extracts anatomical entities. Anatomical_Site, Direction ner_oncology_demographics_wip bert_token_classifier_ner_oncology_demographics_wip This model extracts demographic information, including smoking status. Age, Gender, Smoking_Status, Race_Ethnicity ner_oncology_test_wip bert_token_classifier_ner_oncology_test_wip This model extracts mentions of oncology-related tests. Oncogene, Biomarker, Biomarker_Result, Imaging_Test, Pathology_Test ner_oncology_unspecific_posology_wip bert_token_classifier_ner_oncology_unspecific_posology_wip This model extracts any mention of cancer therapies and posology information using general labels Cancer_Therapy, Posology_Information ner_oncology_anatomy_granular_wip bert_token_classifier_ner_oncology_anatomy_granular_wip This model extracts anatomical entities using granular labels. Direction, Site_Lymph_Node, Site_Breast, Site_Other_Body_Part, Site_Bone, Site_Liver, Site_Lung, Site_Brain ner_oncology_response_to_treatment_wip bert_token_classifier_ner_oncology_response_to_treatment_wip This model extracts entities related to the patient’s response to cancer treatment. Response_To_Treatment, Size_Trend, Line_Of_Therapy ner_oncology_biomarker_wip bert_token_classifier_ner_oncology_biomarker_wip This model extracts biomarkers and their results. Biomarker, Biomarker_Result ner_oncology_posology_wip bert_token_classifier_ner_oncology_posology_wip This model extracts oncology specific posology information and cancer therapies. Cycle_Number, Cycle_Count, Radiotherapy, Cancer_Surgery, Cycle_Day, Frequency, Route, Cancer_Therapy, Duration, Dosage, Radiation_Dose F1 Scores: label f1 label f1 label f1 label f1 label f1 Adenopathy 0.73 Cycle_Day 0.83 Histological_Type 0.71 Posology_Information 0.88 Site_Lymph_Node 0.91 Age 0.97 Cycle_Number 0.79 Hormonal_Therapy 0.90 Race_Ethnicity 0.86 Smoking_Status 0.82 Anatomical_Site 0.83 Date 0.97 Imaging_Test 0.90 Radiation_Dose 0.87 Staging 0.85 Biomarker 0.89 Death_Entity 0.82 Invasion 0.80 Radiotherapy 0.90 Targeted_Therapy 0.87 Biomarker_Result 0.82 Direction 0.82 Line_Of_Therapy 0.91 Relative_Date 0.79 Tumor 0.91 Cancer_Dx 0.92 Dosage 0.91 Lymph_Node 0.86 Route 0.84 Tumor_Description 0.81 Cancer_Surgery 0.85 Duration 0.77 Lymph_Node_Modifier 0.75 Site_Bone 0.80 Tumor_Finding 0.92 Cancer_Therapy 0.90 Frequency 0.88 Metastasis 0.95 Site_Brain 0.78 Tumor_Size 0.88 Chemotherapy 0.90 Gender 0.99 Oncogene 0.77 Site_Breast 0.88     Cycle_Count 0.81 Grade 0.81 Pathology_Test 0.79 Site_Lung 0.79     NER Model Example: ... medical_ner = MedicalNerModel.pretrained(&quot;ner_oncology_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;The had previously undergone a left mastectomy and an axillary lymph node dissection for a left breast cancer twenty years ago. The tumor was positive for ER. Postoperatively, radiotherapy was administered to her breast.&quot; BERT-Based Token Classification Model Example: ... tokenClassifier = MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_ner_oncology_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... sample_text = &quot;The had previously undergone a left mastectomy and an axillary lymph node dissection for a left breast cancer twenty years ago. The tumor was positive for ER. Postoperatively, radiotherapy was administered to her breast.&quot; Results: +++ |chunk |ner_label | +++ |left |Direction | |mastectomy |Cancer_Surgery | |axillary lymph node dissection|Cancer_Surgery | |left |Direction | |breast cancer |Cancer_Dx | |twenty years ago |Relative_Date | |tumor |Tumor_Finding | |positive |Biomarker_Result | |ER |Biomarker | |radiotherapy |Radiotherapy | |her |Gender | |breast |Site_Breast | +++ New Oncological Assertion Status Models We have 8 new oncological assertion status detection models. model name description predicted entities assertion_oncology_wip This model identifies the assertion status of different oncology-related entities. Medical_History, Family_History, Possible, Hypothetical_Or_Absent assertion_oncology_problem_wip This assertion model identifies the status of Cancer_Dx extractions and other problem entities. Present, Possible, Hypothetical, Absent, Family assertion_oncology_treatment_wip This model identifies the assertion status of treatments mentioned in text. Present, Planned, Past, Hypothetical, Absent assertion_oncology_response_to_treatment_wip This assertion model identifies if the response to treatment mentioned in text actually happened, or if it mentioned as something absent or hypothetical. Present_Or_Past, Hypothetical_Or_Absent assertion_oncology_test_binary_wip This assertion model identifies if a test mentioned in text actually was used, or if it mentioned as something absent or hypothetical. Present_Or_Past, Hypothetical_Or_Absent assertion_oncology_smoking_status_wip This assertion model is used to classify the smoking status of the patient. Absent, Past, Present assertion_oncology_family_history_wip This assertion model identifies if an entity refers to a family member. Family_History, Other assertion_oncology_demographic_binary_wip This assertion model identifies if the demographic entities refer to the patient or to someone else. Patient, Someone_Else Example: ... assertion = AssertionDLModel.pretrained(&quot;assertion_oncology_problem_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &#39;ner_chunk&#39;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) ... sample_text = &quot;Considering the findings, the patient may have a breast cancer. There are no signs of metastasis. Family history positive for breast cancer in her maternal grandmother.&quot; Results: +-+-++ | chunk| ner_label|assertion| +-+-++ |breast cancer| Cancer_Dx| Possible| | metastasis|Metastasis| Absent| |breast cancer| Cancer_Dx| Family| +-+-++ New Oncological Relation Extraction Models We are releasing 7 new RelationExtractionModel and 7 new RelationExtractionDLModel models to extract relations between various oncological concepts. model name description predicted entities re_oncology_size_wip This model links Tumor_Size extractions to their corresponding Tumor_Finding extractions. is_size_of, O re_oncology_biomarker_result_wip This model links Biomarker and Oncogene extractions to their corresponding Biomarker_Result extractions. is_finding_of, O re_oncology_granular_wip This model can be identified four relation types is_size_of, is_finding_of, is_date_of, is_location_of, O re_oncology_location_wip This model links extractions from anatomical entities (such as Site_Breast or Site_Lung) to other clinical entities (such as Tumor_Finding or Cancer_Surgery). is_location_of, O re_oncology_temporal_wip This model links Date and Relative_Date extractions to clinical entities such as Test or Cancer_Dx. is_date_of, O re_oncology_test_result_wip This model links test extractions to their corresponding results. is_finding_of, O re_oncology_wip This model link between dates and other clinical entities, between tumor mentions and their size, between anatomical entities and other clinical entities, and between tests and their results. is_related_to, O redl_oncology_size_biobert_wip This model links Tumor_Size extractions to their corresponding Tumor_Finding extractions. is_size_of, O redl_oncology_biomarker_result_biobert_wip This model links Biomarker and Oncogene extractions to their corresponding Biomarker_Result extractions. is_finding_of, O redl_oncology_location_biobert_wip This model links extractions from anatomical entities (such as Site_Breast or Site_Lung) to other clinical entities (such as Tumor_Finding or Cancer_Surgery). is_location_of, O redl_oncology_temporal_biobert_wip This model links Date and Relative_Date extractions to clinical entities such as Test or Cancer_Dx. is_date_of, O redl_oncology_test_result_biobert_wip This model links test extractions to their corresponding results. is_finding_of, O redl_oncology_biobert_wip This model identifies relations between dates and other clinical entities, between tumor mentions and their size, between anatomical entities and other clinical entities, and between tests and their results. is_related_to redl_oncology_granular_biobert_wip This model can be identified four relation types is_date_of, is_finding_of, is_location_of, is_size_of, O F1 Scores and Samples: label F1 Score sample_text results is_finding_of 0.95 “Immunohistochemistry was negative for thyroid transcription factor-1 and napsin A.” negative - thyroid transcription factor-1, negative - napsin is_date_of 0.81 “A mastectomy was performed two months ago.” mastectomy-two months ago is_location_of 0.92 “In April 2011, she first noticed a lump in her right breast.” lump - breast is_size_of 0.86 “The patient presented a 2 cm mass in her left breast.” 2 cm - mass is_related_to 0.87 A mastectomy was performed two months ago.” mastectomy - two months ago Example: ... re_model = RelationExtractionModel.pretrained(&quot;re_oncology_size_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunk&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationPairs([&quot;Tumor_Finding-Tumor_Size&quot;, &quot;Tumor_Size-Tumor_Finding&quot;]) .setMaxSyntacticDistance(10) ... sample_text = &quot;The patient presented a 2 cm mass in her left breast, and the tumor in her other breast was 3 cm long.&quot; Results: +-+-++-++-+ | relation| entity1|chunk1| entity2|chunk2|confidence| +-+-++-++-+ |is_size_of| Tumor_Size| 2 cm|Tumor_Finding| mass| 0.8532705| |is_size_of|Tumor_Finding| tumor| Tumor_Size| 3 cm| 0.8156226| +-+-++-++-+ Brand New NerQuestionGenerator Annotator For Automated Prompt Generation For A QA-based Zero-Shot NER Model. This annotators helps you build questions on the fly using 2 entities from different labels (preferably a subject and a verb). For example, let’s suppose you have an NER model, able to detect PATIENTand ADMISSION in the following text: John Smith was admitted Sep 3rd to Mayo Clinic PATIENT: John Smith ADMISSION: was admitted You can add the following annotator to construct questions using PATIENT and ADMISSION: # setEntities1 says which entity from NER goes first in the question # setEntities2 says which entity from NER goes second in the question # setQuestionMark to True adds a &#39;?&#39; at the end of the sentence (after entity 2) # To sum up, the pattern is [QUESTIONPRONOUN] [ENTITY1] [ENTITY2] [QUESTIONMARK] qagenerator = NerQuestionGenerator() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;question&quot;) .setQuestionMark(True) .setQuestionPronoun(&quot;When&quot;) .setStrategyType(&quot;Paired&quot;) .setEntities1([&quot;PATIENT&quot;]) .setEntities2([&quot;ADMISSION&quot;]) In the column question you will find: When John Smith was admitted?. Likewise you could have Where or any other question pronoun you may need. You can use those questions in a QuestionAnsweringModel or ZeroShotNER (any model which requires a question as an input. Let’s see the case of QA. qa = BertForQuestionAnswering.pretrained(&quot;bert_qa_spanbert_finetuned_squadv1&quot;,&quot;en&quot;) .setInputCols([&quot;question&quot;, &quot;document&quot;]) .setOutputCol(&quot;answer&quot;) .setCaseSensitive(True) The result will be: +--+--+ |question |answer | +--+--+ |[{document, 0, 25, When John Smith was admitted ? ...}] |[{chunk, 0, 8, Sep 3rd ...}] | +--+--+ Strategies: Paired: First chunk of Entity 1 will be grouped with first chunk of Entity 2, second with second, third with third, etc (one-vs-one) Combined: A more flexible strategy to be used in case the number of chukns in Entity 1 is not aligned with the number of chunks in Entityt 2. The first chunk from Entity 1 will be grouped with all chunks in Entity 2, the second chunk in Entity 1 with again be grouped with all the chunks in Entity 2, etc (one-vs-all). Updated ALAB (Annotation Lab) Module Becoming a Fullfledged Suite to Manage Activities on ALAB Via Its API Remotely We are release a new module for interacting with Annotation Lab with minimal code. Users can now create/edit/delete projects and their tasks. Also, they can upload preannotations, and export annotations and generate training data for various models. Complete documentation and tutorial is available at Spark NLP Workshop. Following is a comprehensive list of supported tasks: Getting details of all projects in the Annotation Lab instance. Creating New Projects. Deleting Projects. Setting &amp; editing configuration of projects. Accessing/getting configuration of any existing project. Upload tasks to a project. Deleting tasks of a project. Generating Preannotations for a project using custom Spark NLP pipelines. Uploading Preannotations to a project. Generating dataset for training Classification models. Generating dataset for training NER models. Generating dataset for training Assertion models. Generating dataset for training Relation Extraction models. Using Annotation Lab Module: from sparknlp_jsl.alab import AnnotationLab alab = AnnotationLab() alab.set_credentials(username=username, password=password, client_secret=client_secret, annotationlab_url=annotationlab_url) # create a new project alab.create_project(&#39;alab_demo&#39;) # assign ner labels to the project alab.set_project_config(&#39;alab_demo&#39;, ner_labels=[&#39;Age&#39;, &#39;Gender&#39;]) # upload tasks alab.upload_tasks(&#39;alab_demo&#39;, task_list=[txt1, txt2...]) # export tasks alab.get_annotations(&#39;alab_demo&#39;) New Pretrained Assertion Status Detection Model (assertion_jsl_augmented) to Classify The Negativity &amp; Assertion Scope of Medical Concepts We are releasing new assertion_jsl_augmented model to classify the assertion status of the clinical entities with Present, Absent, Possible, Planned, Past, Family, Hypothetical and SomeoneElse labels. See Models Hub Page for more details. Example: ... clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_jsl_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) ... sample_text = &quot;&quot;&quot;Patient had a headache for the last 2 weeks, and appears anxious when she walks fast. No alopecia noted. She denies pain. Her father is paralyzed and it is a stressor for her. She was bullied by her boss and got antidepressant. We prescribed sleeping pills for her current insomnia&quot;&quot;&quot; Results: +--+--++-+--++ |ner_chunk |begin|end|ner_label |sentence_id|assertion| +--+--++-+--++ |headache |14 |21 |Symptom |0 |Past | |anxious |57 |63 |Symptom |0 |Possible | |alopecia |89 |96 |Disease_Syndrome_Disorder|1 |Absent | |pain |116 |119|Symptom |2 |Absent | |paralyzed |136 |144|Symptom |3 |Family | |antidepressant|212 |225|Drug_Ingredient |4 |Past | |sleeping pills|242 |255|Drug_Ingredient |5 |Planned | |insomnia |273 |280|Symptom |5 |Present | +--+--++-+--++ New Chunk Mapper models and Pretrained Pipeline to map entities (phrases) to their corresponding ICD-9, ICD-10-CM and RxNorm codes We are releasing 4 new chunk mapper models that can map entities to their corresponding ICD-9, ICD-10-CM and RxNorm codes. model name description rxnorm_normalized_mapper Mapping drug entities (phrases) with the corresponding RxNorm codes and normalized resolutions. icd9_mapper Mapping entities with their corresponding ICD-9-CM codes. icd10_icd9_mapper Mapping ICD-10-CM codes with their corresponding ICD-9-CM codes. icd9_icd10_mapper Mapping ICD-9-CM codes with their corresponding ICD-10-CM codes. icd10_icd9_mapping (Pipeline) This pretrained pipeline maps ICD-10-CM codes to ICD-9-CM codes without using any text data. Model Example: ... chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_normalized_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;rxnorm_code&quot;, &quot;normalized_name&quot;]) ... sample_text = &quot;The patient was given Zyrtec 10 MG, Adapin 10 MG Oral Capsule, Septi-Soothe 0.5 Topical Spray&quot; Results: ++--+--+ |ner_chunk |rxnorm_code|normalized_name | ++--+--+ |Zyrtec 10 MG |1011483 |cetirizine hydrochloride 10 MG [Zyrtec] | |Adapin 10 MG Oral Capsule |1000050 |doxepin hydrochloride 10 MG Oral Capsule [Adapin] | |Septi-Soothe 0.5 Topical Spray|1000046 |chlorhexidine diacetate 0.5 MG/ML Topical Spray [Septi-Soothe]| ++--+--+ Pipeline Example: from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline( &quot;icd10_icd9_mapping&quot;,&quot;en&quot;,&quot;clinical/models&quot;) pipeline.annotate(&quot;Z833 A0100 A000&quot;) Results: | icd10_code | icd9_code | |:--|:-| | Z833 - A0100 - A000 | V180 - 0020 - 0010 | New ICD-9-CM Sentence Entity Resolver Model and Pretrained Pipeline sbiobertresolve_icd9 : This model maps extracted medical entities to their corresponding ICD-9-CM codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Example: ... icd10_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd9&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text = &quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2.&quot; Results: +-+-+++-+ | ner_chunk| entity|icd9_code| resolution| all_codes| +-+-+++-+ | gestational diabetes mellitus|PROBLEM| V12.21|[Personal history of gestational diabetes, Ne...|[V12.21, 775.1, 249, 250, 249.7, 249.71, 249.9, 249.61,...| |subsequent type two diabetes mellitus|PROBLEM| 249|[Secondary diabetes mellitus, Diabetes mellit...|[249, 250, 249.9, 249.7, 775.1, 249.6, 249.8, V12.21, 2...| | an acute hepatitis|PROBLEM| 571.1|[Acute alcoholic hepatitis, Viral hepatitis, ...|[571.1, 070, 571.42, 902.22, 279.51, 571.4, 091.62, 572...| | obesity|PROBLEM| 278.0|[Overweight and obesity, Morbid obesity, Over...|[278.0, 278.01, 278.02, V77.8, 278, 278.00, 272.2, 783....| | a body mass index|PROBLEM| V85|[Body mass index [BMI], Human bite, Localized...|[V85, E928.3, 278.1, 993, E008.4, V61.5, 747.63, V85.5,...| +-+-+++-+ icd9_resolver_pipeline : This pretrained pipeline maps entities with their corresponding ICD-9-CM codes. You’ll just feed your text and it will return the corresponding ICD-9-CM codes. Example: from sparknlp.pretrained import PretrainedPipeline resolver_pipeline = PretrainedPipeline(&quot;icd9_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) sample_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years and anisakiasis. Also, it was reported that fetal and neonatal hemorrhage&quot;&quot;&quot; result = resolver_pipeline.fullAnnotate(sample_text) Results: +--+++ |chunk |ner_chunk|icd9_code| +--+++ |gestational diabetes mellitus|PROBLEM |V12.21 | |anisakiasis |PROBLEM |127.1 | |fetal and neonatal hemorrhage|PROBLEM |772 | +--+++ New Shifting Days Feature in Deidentification by Using the New DocumentHashCoder Annotator Now we can shift dates in the documents rather than obfuscating randomly. We have a new DocumentHashCoder() annotator to determine shifting days. This annotator gets the hash of the specified column and creates a new document column containing day shift information. And then, the DeIdentification annotator deidentifies this new doc. We can use the seed parameter to hash consistently. Example: documentHasher = DocumentHashCoder() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;document2&quot;) .setPatientIdColumn(&quot;patientID&quot;) .setRangeDays(100) .setNewDateShift(&quot;shift_days&quot;) .setSeed(100) de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;document2&quot;]) .setOutputCol(&quot;deid_text&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setLanguage(&quot;en&quot;) .setObfuscateRefSource(&#39;faker&#39;) .setUseShifDays(True) Results: output.select(&#39;patientID&#39;,&#39;text&#39;, &#39;deid_text.result&#39;).show(truncate = False) ++-++ |patientID|text |result | ++-++ |A001 |Chris Brown was discharged on 10/02/2022|[Glorious Mc was discharged on 27/03/2022] | |A001 |Mark White was discharged on 10/04/2022 |[Kimberlee Bair was discharged on 25/05/2022]| |A003 |John was discharged on 15/03/2022 |[Monia Richmond was discharged on 17/05/2022]| |A003 |John Moore was discharged on 15/12/2022 |[Veleta Pollard was discharged on 16/02/2023]| ++-++ Instead of shifting days according to ID column, we can specify shifting values with another column. Example: documentHasher = DocumentHashCoder() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;document2&quot;) .setDateShiftColumn(&quot;dateshift&quot;) de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;document2&quot;]) .setOutputCol(&quot;deid_text&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setLanguage(&quot;en&quot;) .setObfuscateRefSource(&#39;faker&#39;) .setUseShifDays(True) Results: +-+++ |text |dateshift|result | +-+++ |Chris Brown was discharged on 10/02/2022|10 |[Levorn Powers was discharged on 20/02/2022] | |Mark White was discharged on 10/04/2022 |10 |[Hall Jointer was discharged on 20/04/2022] | |John was discharged on 15/03/2022 |30 |[Jared Gains was discharged on 14/04/2022] | |John Moore was discharged on 15/12/2022 |30 |[Frederic Seitz was discharged on 14/01/2023]| +-+++ You can check Clinical Deidentification Notebook for more examples. Updated NER Model Finder Pretrained Pipeline to Help Users Find The Most Appropriate NER Model For Their Use Case In One-Liner We have updated ner_model_finder pretrained pipeline and sbertresolve_ner_model_finder resolver model with 70 clinical NER models and their labels. See Models Hub Page for more details and the Pretrained Clinical Pipelines Notebook for the examples. Support Different Version and Year Combinations on Medicare Risk Adjustment Score Calculation Module Now, you can calculate CMS-HCC risk score with different version and year combinations by importing one of the following function calculate the score. - profileV2217 - profileV2318 - profileV2417 - profileV2218 - profileV2319 - profileV2418 - profileV2219 - profileV2419 - profileV2220 - profileV2420 - profileV2221 - profileV2421 - profileV2222 - profileV2422 from sparknlp_jsl.functions import profileV24Y20 See the notebook for more details. Core Improvements and Bug Fixes ContextualParserApproach: New parameter completeContextMatch. This parameter let the user define whether to do an exact match of prefix and suffix. Deidentification: Enhanced default regex rules in French deidentification for DATE entity extraction. ZeroShotRelationExtractionModel: Fixed the issue that setting some parameters together and no need to setRelationalCategories after downloading the model. New and Updated Notebooks New MedicalBertForSequenceClassification Notebook to show how to use MedicalBertForSequenceClassification models. New ALAB Module Notebook to show all features of ALAB Module. New Oncology Models Notebook to show the examples of the new Oncology models. Updated Medicare Risk Adjustment Score Calculation Notebook with the new changes in HCC score calculation functions. Updated Clinical DeIdentification Notebook by adding how not to deidentify a part of an entity section and showing examples of shifting days feature with the new DocumentHashCoder. Updated Pretrained Clinical Pipelines Notebook with the updated ner_model_finder results. 50+ New Clinical Models and Pipelines Added &amp; Updated in Total assertion_jsl_augmented rxnorm_normalized_mapper ner_model_finder sbertresolve_ner_model_finder sbiobertresolve_icd9 icd9_resolver_pipeline rxnorm_normalized_mapper icd9_mapper icd10_icd9_mapper icd9_icd10_mapper icd10_icd9_mapping bert_qa_spanbert_finetuned_squadv1 ner_oncology_therapy_wip ner_oncology_diagnosis_wip ner_oncology_wip ner_oncology_tnm_wip ner_oncology_anatomy_general_wip ner_oncology_demographics_wip ner_oncology_test_wip ner_oncology_unspecific_posology_wip ner_oncology_anatomy_granular_wip ner_oncology_response_to_treatment_wip ner_oncology_biomarker_wip ner_oncology_posology_wip bert_token_classifier_ner_oncology_therapy_wip bert_token_classifier_ner_oncology_diagnosis_wip bert_token_classifier_ner_oncology_wip bert_token_classifier_ner_oncology_tnm_wip bert_token_classifier_ner_oncology_anatomy_general_wip bert_token_classifier_ner_oncology_demographics_wip bert_token_classifier_ner_oncology_test_wip bert_token_classifier_ner_oncology_unspecific_posology_wip bert_token_classifier_ner_oncology_anatomy_granular_wip bert_token_classifier_ner_oncology_response_to_treatment_wip bert_token_classifier_ner_oncology_biomarker_wip bert_token_classifier_ner_oncology_posology_wip assertion_oncology_wip assertion_oncology_problem_wip assertion_oncology_treatment_wip assertion_oncology_response_to_treatment_wip assertion_oncology_test_binary_wip assertion_oncology_smoking_status_wip assertion_oncology_family_history_wip assertion_oncology_demographic_binary_wip re_oncology_size_wip re_oncology_biomarker_result_wip re_oncology_granular_wip re_oncology_location_wip re_oncology_temporal_wip re_oncology_test_result_wip re_oncology_wip redl_oncology_size_biobert_wip redl_oncology_biomarker_result_biobert_wip redl_oncology_location_biobert_wip redl_oncology_temporal_biobert_wip redl_oncology_test_result_biobert_wip redl_oncology_biobert_wip redl_oncology_granular_biobert_wip Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_0"
  },
  "1462": {
    "id": "1462",
    "title": "Visual NLP(Spark OCR) release notes 4.2.1",
    "content": "4.2.1 Release date: 11-28-2022 We’re glad to announce that Spark-OCR 4.2.1 has been released! This release is almost completely about LightPipelines. LightPipeline added to Spark-OCR Originally introduced by Spark-NLP, this has been one of the most celebrated features by our users. In a nutshell, LightPipelines allow you switching your pipeline from distributed processing to local mode, in a single line of code. Also, results are much easier to post-process as they come in plain Python data structures. Now, LightPipelines are available in Spark-OCR as well! This is an initial implementation only covering three of our most popular annotators: ImageToText, PdfToImage, and BinaryToImage. Although not all the annotators from Spark-OCR are included in this initial release, a number of interesting features are being delivered: Latency has been dramatically reduced for small input dataset sizes. Interoperability with Spark-NLP and Spark-NLP healthcare: you can mix any NLP annotator with supported OCR annotators on the same LightPipeline. Following is a chart comparing performance of different techniques on batches of different page counts: 8, 16, 24, 32, 40, 48, and 80 pages. For the 8 pages case, on the left side of the chart, LightPipelines average 1.25s per page vs. 4s per page that were scored by a similar Pytesseract implementation. That makes LightPipelines a great candidate to achieve low latency on small sized batches, while still leveraging parallelism. Korean Support You can start using Korean language by just passing the ‘KOR’ option to ImageToText, ... # Run OCR ocr = ImageToText() # Set Korean language ocr.setLanguage(Language.KOR) # Download model from JSL S3 ocr.setDownloadModelData(True) Bug Fixes AlabReader has been updated to handle the new structure present in Annotation Lab’s exported annotations. New Notebooks Check how to use LightPipelines in this notebook: SparkOcrLightPipelines.ipynb Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_2_1",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_2_1"
  },
  "1463": {
    "id": "1463",
    "title": "Spark NLP for Healthcare Release Notes 4.2.1",
    "content": "4.2.1 Highlights Creating new chunks with NerConverterInternal by merging chunks by skipping stopwords in between. Adding relation direction to RelationExtraction models to make the relations direction-aware. Using proper regional date formats in the DeIdentification module. Being able to play with different date formats in DateNormalizer output. New Replacer annotator to replace chunks with their normalized versions (`DateNormalizer’) in documents. New ModelTracer helper class to generate and add model UID and timestamps of the stages in a pipeline Added entity source and labels to the AssertionFilterer metadata New chunk mapper and sentence entity resolver models and a pipeline for CVX Updated clinical NER models with new labels New Certification Training notebooks for the johnsnowlabs library New and updated notebooks 6 new clinical models and pipelines added &amp; updated in total Creating New Chunks with NerConverterInternal by Merging Chunks by Skipping Stopwords in Between. NerConverterInternal’s new setIgnoreStopWords parameter allows merging between chunks with the same label, ignoring stopwords and punctuations. txt = &quot;&quot;&quot; The qualified manufacturers for this starting material are: Alpha Chemicals Pvt LTD 17, R K Industry House, Walbhat Rd, Goregaon – 400063 Mumbai, Maharashtra, India Beta Chemical Co., Ltd Huan Cheng Xi Lu 3111hao Hai Guan Da Ting Shanghai, China &quot;&quot;&quot; Example for default: NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_deid&quot;]) .setOutputCol(&quot;chunk_deid&quot;) .setGreedyMode(True) .setWhiteList([&#39;LOCATION&#39;]) Results: | chunks | entities | begin | end | |:-|:|:|-:| | R K Industry House | LOCATION | 90 | 107 | | Walbhat | LOCATION | 110 | 116 | | Mumbai | LOCATION | 141 | 146 | | Maharashtra | LOCATION | 149 | 159 | | India | LOCATION | 162 | 166 | | Huan Cheng Xi Lu 3111hao | LOCATION | 191 | 214 | | Shanghai | LOCATION | 234 | 241 | | China | LOCATION | 244 | 248 | Example for setting setIgnoreStopWords parameter: NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_deid&quot;]) .setOutputCol(&quot;chunk_deid&quot;) .setGreedyMode(True) .setWhiteList([&#39;LOCATION&#39;]) .setIgnoreStopWords([&#39; n&#39;, &#39;,&#39;, &quot;and&quot;, &#39;or&#39;, &#39;.&#39;]) Results: | chunks | entities | begin | end | |:|:|:|-:| | R K Industry House Walbhat | LOCATION | 90 | 116 | | Mumbai Maharashtra India | LOCATION | 141 | 166 | | Huan Cheng Xi Lu 3111hao | LOCATION | 191 | 214 | | Shanghai China | LOCATION | 234 | 248 | Adding Relation Direction to RelationExtraction Models to Make the Relations Direction-aware. We have a new setRelationDirectionCol parameter that is used during training with a new separate column that specified relationship directions. The column should contain one of the following values: rightwards: The first entity in the text is also the first argument of the relation (as well as the second entity in the text is the second argument). In other words, the relation arguments are ordered left to right in the text. leftwards: The first entity in the text is the second argument of the relation (and the second entity in the text is the first argument). both: Order doesn’t matter (relation is symmetric). In our test cases, it was observed that the accuracy increased significantly when we just add setRelationDirectionCol parameter by keeping the other parameter as they are. Example: +--+++--+-+-+ | chunk1| label1| label2| chunk2| rel| rel_dir| +--+++--+-+-+ |expected long ter...|treatment|treatment| a picc line| O| both| | light-headedness| problem| problem| diaphoresis| PIP|rightwards| | po pain medications|treatment| problem| his pain|TrAP| leftwards| |bilateral pleural...| problem| problem|increased work of...| PIP|rightwards| | her urine output| test| problem| decreased|TeRP|rightwards| |his psychiatric i...| problem| problem|his neurologic in...| PIP|rightwards| | white blood cells| test| test| red blood cells| O| both| | chloride| test| test| bun| O| both| | further work-up| test| problem|his neurologic co...|TeCP|rightwards| | four liters|treatment| test| blood pressure| O| both| +--+++--+-+-+ re_approach_with_dir = RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setLabelColumn(&quot;rel&quot;) ... .setRelationDirectionCol(&quot;rel_dir&quot;) Using Proper Regional date Formats in DeIdentification Module You can specify the format for date entities that will be shifted to the new date or converted to a year. de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei_id&quot;) .setRegion(&#39;us&#39;) # &#39;eu&#39; for Europe Being Able to Play With Different Date Formats in DateNormalizer Output Now we can customize the normalized date formats in the output of DateNormalizer by using the new setOutputDateformat parameter. There are two options to do that; us for MM/DD/YYYY, eu for DD/MM/YYYY formats. Example: date_normalizer_us = DateNormalizer() .setInputCols(&#39;date_chunk&#39;) .setOutputCol(&#39;normalized_date_us&#39;) .setOutputDateformat(&#39;us&#39;) date_normalizer_eu = DateNormalizer() .setInputCols(&#39;date_chunk&#39;) .setOutputCol(&#39;normalized_date_eu&#39;) .setOutputDateformat(&#39;eu&#39;) sample_text = [&#39;She was last seen in the clinic on Jan 30, 2018, by Dr. Y.&#39;, &#39;Chris Brown was discharged on 12Mar2021&#39;, &#39;We reviewed the pathology obtained on 13.04.1999.&#39;] Results: +-++++ |text |date_chunk |normalized_date_eu|normalized_date_us| +-++++ |She was last seen in the clinic on Jan 30, 2018, by Dr. Y.|Jan 30, 2018|30/01/2018 |01/30/2018 | |Chris Brown was discharged on 12Mar2021 |12Mar2021 |12/03/2021 |03/20/2021 | |We reviewed the pathology obtained on 13.04.1999. |13.04.1999 |13/04/1999 |04/13/1999 | +-++++ New Replacer Annotator To Replace Chunks With Their Normalized Versions (DateNormalizer) In Documents We have a new Replacer annotator that returns the original document by replacing it with the normalized version of the original chunks. Example: date_normalizer = DateNormalizer() .setInputCols(&#39;date_chunk&#39;) .setOutputCol(&#39;normalized_date&#39;) replacer = Replacer() .setInputCols([&quot;normalized_date&quot;,&quot;document&quot;]) .setOutputCol(&quot;replaced_document&quot;) sample_text = [&#39;She was last seen in the clinic on Jan 30, 2018, by Dr. Y.&#39;, &#39;Chris Brown was discharged on 12Mar2021&#39;, &#39;We reviewed the pathology obtained on 13.04.1999.&#39;] Results: +-++--+ |text |normalized_date|replaced_document | +-++--+ |She was last seen in the clinic on Jan 30, 2018, by Dr. Y.|2018/01/30 |She was last seen in the clinic on 2018/01/30, by Dr. Y.| |Chris Brown was discharged on 12Mar2021 |2021/03/12 |Chris Brown was discharged on 2021/03/12 | |We reviewed the pathology obtained on 13.04.1999. |1999/04/13 |We reviewed the pathology obtained on 1999/04/13. | +-++--+ New ModelTracer Helper Class to Generate and Add Model UID and Timestamps of the Stages in a Pipeline ModelTracer allows to track the UIDs and timestamps of each stage of a pipeline. Example: from sparknlp_jsl.modelTracer import ModelTracer ... pipeline = Pipeline( stages=[ documentAssembler, tokenizer, tokenClassifier, ]) df = pipeline.fit(data).transform(data) result = ModelTracer().addUidCols(pipeline = pipeline, df = df) result.show(truncate=False) Results: +-+--+--++-+--+-+ |text|document|token|ner|documentassembler_model_uid |tokenizer_model_uid |bert_for_token_classification_model_uid | +-+--+--++-+--+-+ |... |... |... |...|{uid -&gt; DocumentAssembler_a666efd1d789, timestamp -&gt; 2022-10-21_11:34}|{uid -&gt; Tokenizer_01fbad79f069, timestamp -&gt; 2022-10-21_11:34}|{uid -&gt; BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89, timestamp -&gt; 2022-10-21_11:34}| +-+--+--++-+--+-+ Added Entity Source and Labels to the AssertionFilterer Metadata Now the AssertionFilterer annotator returns the entity source and assertion labels in the metadata. Example: assertionFilterer = AssertionFilterer() .setInputCols([&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList([&quot;Absent&quot;]) text = &quot;Patient has a headache for the last 2 weeks, no alopecia noted.&quot; Results: # before v4.2.1 +--+ |filtered | +--+ |[{chunk, 48, 55, alopecia, {entity -&gt; PROBLEM, sentence -&gt; 0, chunk -&gt; 1, confidence -&gt; 0.9988}, []}]| +--+ # v4.2.1 ++ |filtered | ++ |[{chunk, 48, 55, alopecia, {chunk -&gt; 1, confidence -&gt; 0.9987, ner_source -&gt; ner_chunk, assertion -&gt; Absent, entity -&gt; PROBLEM, sentence -&gt; 0}, []}]| ++ New Chunk Mapper and Sentence Entity Resolver Models And A Pipeline for CVX We are releasing 2 new chunk mapper models to map entities to their corresponding CVX codes, vaccine names and CPT codes. There are 3 types of vaccine names mapped; short_name, full_name and trade_name model name description cvx_name_mapper Mapping vaccine products to their corresponding CVX codes, vaccine names and CPT codes. cvx_code_mapper Mapping CVX codes to their corresponding vaccine names and CPT codes. Example: chunkerMapper = ChunkMapperModel .pretrained(&quot;cvx_name_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;cvx_code&quot;, &quot;short_name&quot;, &quot;full_name&quot;, &quot;trade_name&quot;, &quot;cpt_code&quot;]) data = spark.createDataFrame([[&#39;DTaP&#39;], [&#39;MYCOBAX&#39;], [&#39;cholera, live attenuated&#39;]]).toDF(&#39;text&#39;) Results: +--+--+--+-++--+ |chunk |cvx_code|short_name |full_name |trade_name |cpt_code| +--+--+--+-++--+ |[DTaP] |[20] |[DTaP] |[diphtheria, tetanus toxoids and acellular pertussis vaccine]|[ACEL-IMUNE]|[90700] | |[MYCOBAX] |[19] |[BCG] |[Bacillus Calmette-Guerin vaccine] |[MYCOBAX] |[90585] | |[cholera, live attenuated]|[174] |[cholera, live attenuated]|[cholera, live attenuated] |[VAXCHORA] |[90625] | +--+--+--+-++--+ sbiobertresolve_cvx: This sentence entity resolver model maps vaccine entities to CVX codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Additionally, this model returns status of the vaccine (Active/Inactive/Pending/Non-US) in all_k_aux_labels column. Example: cvx_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_cvx&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;cvx_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) result = light_model.fullAnnotate([&quot;Sinovac&quot;, &quot;Moderna&quot;, &quot;BIOTHRAX&quot;]) Results: +-+--+-+--+ |ner_chunk |cvx_code|resolved_text |Status | +-+--+-+--+ |Sinovac |511 |COVID-19 IV Non-US Vaccine (CoronaVac, Sinovac) |Non-US | |Moderna |227 |COVID-19, mRNA, LNP-S, PF, pediatric 50 mcg/0.5 mL dose|Inactive| |BIOTHRAX |24 |anthrax |Active | +-+--+-+--+ cvx_resolver_pipeline: This pretrained pipeline maps entities with their corresponding CVX codes. Example: from sparknlp.pretrained import PretrainedPipeline resolver_pipeline = PretrainedPipeline(&quot;cvx_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text= &quot;The patient has a history of influenza vaccine, tetanus and DTaP&quot; result = resolver_pipeline.fullAnnotate(text) Results: +--++--+ |chunk |ner_chunk|cvx_code| +--++--+ |influenza vaccine|Vaccine |160 | |tetanus |Vaccine |35 | |DTaP |Vaccine |20 | +--++--+ Updated Clinical NER Models With New Labels ner_jsl and ner_covid_trials models were updated with the new label called “Vaccine_Name”. Example: ... jsl_ner = MedicalNerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;jsl_ner&quot;) ... sample_text= &quot;&quot;&quot;The patient is a 21-day-old Caucasian male here for 2 days, there is no side effect observed after the influenza vaccine&quot;&quot;&quot; Results: |chunks | begin | end | entities | ||--:|:|:| |21-day-old | 18 | 27 | Age | |Caucasian | 29 | 37 | Race_Ethnicity | |male | 39 | 42 | Gender | |for 2 days | 49 | 58 | Duration | |influenza vaccine | 100 | 116 | Vaccine_Name | New Certification Training Notebooks for the johnsnowlabs Library Now we have 46 new Healtcare Certification Training notebooks for the users who want to use the new johnsnowlabs library. New and Updated Notebooks New Coreference Resolution notebook to find other references of clinical entities in a document. Updated Clinical Name Entity Recognition Model notebook with the new feature setIgnoreStopWords parameter and ModelTracer module. Updated Clinical Assertion Model notebook with the new changes in AssertionFilterer improvement. Updated Clinical Deidentification notebook with the new setRegion parameter in DeIdentification. Updated Clinical Relation Extraction notebook with the new setRelationDirectionCol parameter in RelationExtractionApproach. Updated Date Normalizer notebook with the new setOutputDateformat parameter in DateNormalizer and Replacer annotator. Updated 25 Certification Training Public notebooks and 47 Certification Training Healthcare notebooks with the latest updates in the libraries. Updated 6 Databricks Public notebooks and 14 Databricks Healthcare notebooks with the latest updates in the libraries and 4 new Databricks notebooks created. 6 New Clinical Models and Pipelines Added &amp; Updated in Total cvx_code_mapper cvx_name_mapper sbiobertresolve_cvx cvx_resolver_pipeline ner_jsl ner_covid_trials Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_1"
  },
  "1464": {
    "id": "1464",
    "title": "Spark NLP for Healthcare Release Notes 4.2.2",
    "content": "4.2.2 Highlights Fine-tuning Relation Extraction models with your data Added Romanian support in deidentification annotator for data obfuscation New SDOH (Social Determinants of Health) ner model Improved oncology models and 4 pretrained pipelines New chunk mapper models to map entities (phrases) to their corresponding ICD-10-CM codes as well as clinical abbreviations to their definitions New ICD-10-PCS sentence entity resolver model and ICD-10-CM resolver pipeline New utility &amp; helper modules documentation page New and updated notebooks 22 new clinical models and pipelines added &amp; updated in total Fine-Tuning Relation Extraction Models With Your Data Instead of starting from scratch when training a new Relation Extraction model, you can train a new model by adding your new data to the pretrained model. There are two new params in RelationExtractionApproach which allows you to initialize your model with the data from the pretrained model: setPretrainedModelPath: This parameter allows you to point the training process to an existing model. setОverrideExistingLabels: This parameter overrides the existing labels in the original model that are assigned the same output nodes in the new model. Default is True, when it is set to False the RelationExtractionApproach uses the existing labels and if it finds new ones it tries to assign them to unused output nodes. Example: reApproach_finetune = RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setLabelColumn(&quot;rel&quot;) ... .setFromEntity(&quot;begin1i&quot;, &quot;end1i&quot;, &quot;label1&quot;) .setToEntity(&quot;begin2i&quot;, &quot;end2i&quot;, &quot;label2&quot;) .setPretrainedModelPath(&quot;existing_RE_MODEL_path&quot;) .setOverrideExistingLabels(False) You can check Resume RelationExtractionApproach Training Notebook for more examples. Added Romanian Support in Deidentification Annotator For Data Obfuscation Deidentification annotator is now able to obfuscate entities (coming from a deid NER model) with fake data in Romanian language. Example: deid_obfuscated_faker = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;obfuscated&quot;) .setMode(&quot;obfuscate&quot;) .setLanguage(&#39;ro&#39;) .setObfuscateDate(True) .setObfuscateRefSource(&#39;faker&#39;) text = &quot;&quot;&quot;Nume si Prenume : BUREAN MARIA, Varsta: 77 ,Spitalul Pentru Ochi de Deal, Drumul Oprea Nr. 972 Vaslui&quot;&quot;&quot; Result: Sentence Masked with entity Masked with Chars Masked with Fixed Chars Obfuscated Nume si Prenume : BUREAN MARIA, Varsta: 77 ,Spitalul Pentru Ochi de Deal, Drumul Oprea Nr. 972 Vaslui Nume si Prenume : &lt; PATIENT&gt;, Varsta: &lt; AGE&gt; ,&lt; HOSPITAL&gt;, &lt; STREET&gt; &lt; CITY&gt; Nume si Prenume : ****, Varsta: ** ,********, ****** ** Nume si Prenume : **, Varsta: ** , **, ** ** Nume si Prenume : Claudia Crumble, Varsta: 18 ,LOS ANGELES AMBULATORY CARE CENTER, 706 north parrish avenue Piscataway New SDOH (Social Determinants of Health) NER Model Social Determinants of Health(SDOH) are the socioeconomic factors under which people live, learn, work, worship, and play that determine their health outcomes.The World Health Organization also provides a definition of social determinants of health. Social determinants of health as the conditions in which people are born, grow, live, work and age. These circumstances are shaped by the distribution of money, power, and resources at global, national, and local levels. Social determinants of health (SDOH) have a major impact on people’s health, well-being, and quality of life. SDOH include lots of factors, also contribute to wide health disparities and inequities. In this project We have tried to define well these factors. The goal of this project is to train models for natural language processing focused on extracting terminology related to social determinants of health from various kinds of biomedical documents. This first model is Named Entity Recognition (NER) task. The project is still ongoing and will mature over time and the number of sdoh factors (entities) will also be enriched. It will include other tasks as well. Example: ner_model = MedicalNerModel.pretrained(&quot;sdoh_slim_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;&quot;&quot; Mother states that he does smoke, there is a family hx of alcohol on both maternal and paternal sides of the family, maternal grandfather who died of alcohol related complications and paternal grandmother with severe alcoholism. Pts own drinking began at age 16, living in LA, had a DUI at age 17 after totaling a new car that his mother bought for him, he was married. &quot;&quot;&quot; Result: +-+-+ | token| ner_label| +-+-+ | Mother| B-Family_Member| | he| B-Gender| | smoke| B-Smoking| | alcohol| B-Alcohol| | maternal| B-Family_Member| | paternal| B-Family_Member| | maternal| B-Family_Member| | grandfather| B-Family_Member| | alcohol| B-Alcohol| | paternal| B-Family_Member| | grandmother| B-Family_Member| | severe| B-Alcohol| | alcoholism| I-Alcohol| | drinking| B-Alcohol| | age| B-Age| | 16| I-Age| | LA|B-Geographic_Entity| | age| B-Age| | 17| I-Age| | his| B-Gender| | mother| B-Family_Member| | him| B-Gender| | he| B-Gender| | married| B-Marital_Status| +-+-+ Improved Oncology NER Models And 4 New Pretrained Pipelines We are releasing the improved version of Oncological NER models (_wip) and 4 new pretrained oncological pipelines which are able to detect assertion status and relations between the extracted oncological entities. NER model name (MedicalNerModel) description predicted entities ner_oncology_anatomy_general Extracting anatomical entities. Anatomical_Site, Direction ner_oncology_anatomy_granular Extracting anatomical entities using granular labels. Direction, Site_Lymph_Node, Site_Breast, Site_Other_Body_Part, Site_Bone, Site_Liver, Site_Lung, Site_Brain ner_oncology_biomarker Extracting biomarkers and their results. Biomarker, Biomarker_Result ner_oncology_demographics Extracting demographic information, including smoking status. Age, Gender, Smoking_Status, Race_Ethnicity ner_oncology_diagnosis Extracting entities related to cancer diagnosis, including the presence of metastasis. Grade, Staging, Tumor_Size, Adenopathy, Pathology_Result, Histological_Type, Metastasis, Cancer_Score, Cancer_Dx, Invasion, Tumor_Finding, Performance_Status ner_oncology Extracting more than 40 oncology-related entities. Histological_Type, Direction, Staging, Cancer_Score, Imaging_Test, Cycle_Number, Tumor_Finding, Site_Lymph_Node, Invasion, Response_To_Treatment, Smoking_Status, Tumor_Size, Cycle_Count, Adenopathy, Age, Biomarker_Result, Unspecific_Therapy, Site_Breast, Chemotherapy, Targeted_Therapy, Radiotherapy, Performance_Status, Pathology_Test, Site_Other_Body_Part, Cancer_Surgery, Line_Of_Therapy, Pathology_Result, Hormonal_Therapy, Site_Bone, Biomarker, Immunotherapy, Cycle_Day, Frequency, Route, Duration, Death_Entity, Metastasis, Site_Liver, Cancer_Dx, Grade, Date, Site_Lung, Site_Brain, Relative_Date, Race_Ethnicity, Gender, Oncogene, Dosage, Radiation_Dose ner_oncology_posology This model extracts oncology specific posology information and cancer therapies. Cycle_Number, Cycle_Count, Radiotherapy, Cancer_Surgery, Cycle_Day, Frequency, Route, Cancer_Therapy, Duration, Dosage, Radiation_Dose ner_oncology_unspecific_posology Extracting any mention of cancer therapies and posology information using general labels Cancer_Therapy, Posology_Information ner_oncology_response_to_treatment_wip Extracting entities related to the patient’s response to cancer treatment. Response_To_Treatment, Size_Trend, Line_Of_Therapy ner_oncology_therapy Extracting entities related to cancer therapies, including posology entities and response to treatment, using granular labels. Response_To_Treatment, Line_Of_Therapy, Cancer_Surgery, Radiotherapy, Immunotherapy, Targeted_Therapy, Hormonal_Therapy, Chemotherapy, Unspecific_Therapy, Route, Duration, Cycle_Count, Dosage, Frequency, Cycle_Number, Cycle_Day, Radiation_Dose ner_oncology_test Extracting mentions of oncology-related tests. Oncogene, Biomarker, Biomarker_Result, Imaging_Test, Pathology_Test ner_oncology_tnm Extracting mentions related to TNM staging. Lymph_Node, Staging, Lymph_Node_Modifier, Tumor_Description, Tumor, Metastasis, Cancer_Dx Oncological Pipeline (PretrainedPipeline) Description oncology_general_pipeline Includes Named-Entity Recognition, Assertion Status and Relation Extraction models to extract information from oncology texts. This pipeline extracts diagnoses, treatments, tests, anatomical references and demographic entities. oncology_biomarker_pipeline Includes Named-Entity Recognition, Assertion Status and Relation Extraction models to extract information from oncology texts. This pipeline focuses on entities related to biomarkers oncology_diagnosis_pipeline Includes Named-Entity Recognition, Assertion Status, Relation Extraction and Entity Resolution models to extract information from oncology texts. This pipeline focuses on entities related to oncological diagnosis. oncology_therapy_pipeline Includes Named-Entity Recognition and Assertion Status models to extract information from oncology texts. This pipeline focuses on entities related to therapies. Example: from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;oncology_general_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;The patient underwent a left mastectomy for a left breast cancer two months ago. The tumor is positive for ER and PR.&quot; Result: **** ner_oncology_wip results **** | chunk | ner_label | |:|:--| | left | Direction | | mastectomy | Cancer_Surgery | | left | Direction | | breast cancer | Cancer_Dx | | two months ago | Relative_Date | | tumor | Tumor_Finding | | positive | Biomarker_Result | | ER | Biomarker | | PR | Biomarker | **** assertion_oncology_wip results **** | chunk | ner_label | assertion | |:--|:|:| | mastectomy | Cancer_Surgery | Past | | breast cancer | Cancer_Dx | Present | | tumor | Tumor_Finding | Present | | ER | Biomarker | Present | | PR | Biomarker | Present | **** re_oncology_wip results **** | chunk1 | entity1 | chunk2 | entity2 | relation | |:--|:--|:|:--|:--| | mastectomy | Cancer_Surgery | two months ago | Relative_Date | is_related_to | | breast cancer | Cancer_Dx | two months ago | Relative_Date | is_related_to | | tumor | Tumor_Finding | ER | Biomarker | O | | tumor | Tumor_Finding | PR | Biomarker | O | | positive | Biomarker_Result | ER | Biomarker | is_related_to | | positive | Biomarker_Result | PR | Biomarker | is_related_to | New Chunk Mapper Models to Map Entities (phrases) to Their Corresponding ICD-10-CM Codes As Well As Clinical Abbreviations to Their Definitions We have 2 new chunk mapper models: abbreviation_mapper_augmented is an augmented version of the existing abbreviation_mapper model. It maps abbreviations and acronyms of medical regulatory activities to their definitions. icd10cm_mapper maps entities to corresponding ICD-10-CM codes. Example: chunkerMapper = ChunkMapperModel .pretrained(&quot;icd10cm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;icd10cm_code&quot;]) text = &quot;&quot;&quot;A 35-year-old male with a history of primary leiomyosarcoma of neck, gestational diabetes mellitus diagnosed eight years prior to presentation and presented with a one-week history of polydipsia, poor appetite, and vomiting.&quot;&quot;&quot; Result: ++-++ |ner_chunk |entity |icd10cm_code| ++-++ |primary leiomyosarcoma of neck|PROBLEM|C49.0 | |gestational diabetes mellitus |PROBLEM|O24.919 | |polydipsia |PROBLEM|R63.1 | |poor appetite |PROBLEM|R63.0 | |vomiting |PROBLEM|R11.10 | ++-++ New ICD-10-PCS Sentence Entity Resolver Model and ICD-10-CM Resolver Pipeline We are releasing new ICD-10-PCS resolver model and ICD-10-CM resolver pipeline: sbiobertresolve_icd10pcs_augmented model maps extracted medical entities to ICD-10-PCS codes using sbiobert_base_cased_mli sentence bert embeddings. It trained on the augmented version of the dataset which is used in previous ICD-10-PCS resolver model. Example: icd10pcs_resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_icd10pcs_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) text = &quot;Given the severity of her abdominal examination and her persistence of her symptoms, it is detected that need for laparoscopic appendectomy and possible open appendectomy as well as pyeloplasty. We recommend performing a mediastinoscopy&quot; Result: +-++-++--+ | ner_chunk| entity|icd10pcs_code| resolutions| all_codes| +-++-++--+ | abdominal examination| Test| 2W63XZZ|[traction of abdominal wall [trac...|[2W63XZZ, BW40ZZZ...| |laparoscopic appendectomy|Procedure| 0DTJ8ZZ|[resection of appendix, endo [res...|[0DTJ8ZZ, 0DT84ZZ...| | open appendectomy|Procedure| 0DBJ0ZZ|[excision of appendix, open appro...|[0DBJ0ZZ, 0DTJ0ZZ...| | pyeloplasty|Procedure| 0TS84ZZ|[reposition bilateral ureters, pe...|[0TS84ZZ, 0TS74ZZ...| | mediastinoscopy|Procedure| BB1CZZZ|[fluoroscopy of mediastinum [fluo...|[BB1CZZZ, 0WJC4ZZ...| +-++-++--+ icd10cm_resolver_pipeline pretrained pipeline maps entities with their corresponding ICD-10-CM codes. You’ll just feed your text and it will return the corresponding ICD-10-CM codes. Example: from sparknlp.pretrained import PretrainedPipeline resolver_pipeline = PretrainedPipeline(&quot;icd10cm_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years and anisakiasis. Also, it was reported that fetal and neonatal hemorrhage&quot; Result: +--+++ |chunk |ner_chunk|icd10cm_code| +--+++ |gestational diabetes mellitus|PROBLEM |O24.919 | |anisakiasis |PROBLEM |B81.0 | |fetal and neonatal hemorrhage|PROBLEM |P545 | +--+++ New Utility &amp; Helper Modules Documentation Page We have a new utility &amp; helper modules documentation page that you can find the documentations of Spark NLP for Healthcare modules with examples. New and Updated Notebooks New Resume RelationExtractionApproach Training notebook train a model already trained on a different dataset. Updated Clinical Deidentification notebook with day shifting feature in DeIdentification. Updated Clinical Multi Language Deidentification notebook with new Romanian obfuscation and faker improvement. Updated Adverse Drug Event ADE NER and Classifier notebook with the new models and improvement. 22 New Clinical Models and Pipelines Added &amp; Updated in Total abbreviation_mapper_augmented icd10cm_mapper sbiobertresolve_icd10pcs_augmented icd10cm_resolver_pipeline oncology_biomarker_pipeline oncology_diagnosis_pipeline oncology_therapy_pipeline oncology_general_pipeline ner_oncology_anatomy_general ner_oncology_anatomy_granular ner_oncology_biomarker ner_oncology_demographics ner_oncology_diagnosis ner_oncology ner_oncology_posology ner_oncology_response_to_treatment ner_oncology_test ner_oncology_therapy ner_oncology_tnm ner_oncology_unspecific_posology sdoh_slim_wip t5_base_pubmedqa For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_2"
  },
  "1465": {
    "id": "1465",
    "title": "Spark NLP for Healthcare Release Notes 4.2.3",
    "content": "4.2.3 Highlights 3 new chunk mapper models to mapping Drugs and Diseases from the KEGG Database as well as mapping abbreviations to their categories New utility &amp; helper Relation Extraction modules to handle preprocess New utility &amp; helper OCR modules to handle annotate New utility &amp; helper NER log parser Adding flexibility chunk merger prioritization Core improvements and bug fixes New and updated notebooks 3 new clinical models and pipelines added &amp; updated in total 3 New Hhunk Mapper Models to Mapping Drugs and Diseases from the KEGG Database as well as Mapping Abbreviations to Their Categories kegg_disease_mapper: This pretrained model maps diseases with their corresponding category, description, icd10_code, icd11_code, mesh_code, and hierarchical brite_code. This model was trained with the data from the KEGG database. Example: chunkerMapper = ChunkMapperModel.pretrained(&quot;kegg_disease_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;description&quot;, &quot;category&quot;, &quot;icd10_code&quot;, &quot;icd11_code&quot;, &quot;mesh_code&quot;, &quot;brite_code&quot;]) text= &quot;A 55-year-old female with a history of myopia, kniest dysplasia and prostate cancer. She was on glipizide , and dapagliflozin for congenital nephrogenic diabetes insipidus.&quot; Result: +--+--+--+-+-++--+ | ner_chunk| description| category|icd10_code|icd11_code|mesh_code| brite_code| +--+--+--+-+-++--+ | myopia|Myopia is the most common ocular disorder world...| Nervous system disease| H52.1| 9D00.0| D009216| 08402,08403| | kniest dysplasia|Kniest dysplasia is an autosomal dominant chond...|Congenital malformation| Q77.7| LD24.3| C537207| 08402,08403| | prostate cancer|Prostate cancer constitutes a major health prob...| Cancer| C61| 2C82| NONE|08402,08403,08442,08441| |congenital nephrogenic diabetes insipidus|Nephrogenic diabetes insipidus (NDI) is charact...| Urinary system disease| N25.1| GB90.4A| D018500| 08402,08403| +--+--+--+-+-++--+ kegg_drug_mapper: This pretrained model maps drugs with their corresponding efficacy, molecular_weight as well as CAS, PubChem, ChEBI, LigandBox, NIKKAJI, PDB-CCD codes. This model was trained with the data from the KEGG database. Example: chunkerMapper = ChunkMapperModel.pretrained(&quot;kegg_drug_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;efficacy&quot;, &quot;molecular_weight&quot;, &quot;CAS&quot;, &quot;PubChem&quot;, &quot;ChEBI&quot;, &quot;LigandBox&quot;, &quot;NIKKAJI&quot;, &quot;PDB-CCD&quot;]) text= &quot;She is given OxyContin, folic acid, levothyroxine, Norvasc, aspirin, Neurontin&quot; Result: +-+--+-+-+--+-+++-+ | ner_chunk| efficacy|molecular_weight| CAS| PubChem| ChEBI|LigandBox| NIKKAJI|PDB-CCD| +-+--+-+-+--+-+++-+ | OxyContin| Analgesic (narcotic), Opioid receptor agonist| 351.8246| 124-90-3| 7847912.0| 7859.0| D00847|J281.239H| NONE| | folic acid|Anti-anemic, Hematopoietic, Supplement (folic a...| 441.3975| 59-30-3| 7847138.0|27470.0| D00070| J1.392G| FOL| |levothyroxine| Replenisher (thyroid hormone)| 776.87| 51-48-9|9.6024815E7|18332.0| D08125| J4.118A| T44| | Norvasc|Antihypertensive, Vasodilator, Calcium channel ...| 408.8759|88150-42-9|5.1091781E7| 2668.0| D07450| J33.383B| NONE| | aspirin|Analgesic, Anti-inflammatory, Antipyretic, Anti...| 180.1574| 50-78-2| 7847177.0|15365.0| D00109| J2.300K| AIN| | Neurontin| Anticonvulsant, Antiepileptic| 171.2368|60142-96-3| 7847398.0|42797.0| D00332| J39.388F| GBN| +-+--+-+-+--+-+++-+ abbreviation_category_mapper: This pretrained model maps abbreviations and acronyms of medical regulatory activities with their definitions and categories. Predicted categories: general, problem, test, treatment, medical_condition, clinical_dept, drug, nursing, internal_organ_or_component, hospital_unit, drug_frequency, employment, procedure. Example: chunkerMapper = ChunkMapperModel.pretrained(&quot;abbreviation_category_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;abbr_ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;definition&quot;, &quot;category&quot;]) text = [&quot;&quot;&quot;Gravid with estimated fetal weight of 6-6/12 pounds. LABORATORY DATA: Laboratory tests include a CBC which is normal. VDRL: Nonreactive HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet.&quot;&quot;&quot;] Result: | chunk | category | definition | |:--|:|:| | CBC | general | complete blood count | | VDRL | clinical_dept | Venereal Disease Research Laboratories | | HIV | medical_condition | Human immunodeficiency virus | New Utility &amp; Helper Relation Extraction Modules to Handle Preprocess This process is standard and training column should be same in all RE trainings. We can simplify this process with helper class. With proposed changes it can be done as follows: Example: from sparknlp_jsl.training import REDatasetHelper # map entity columns to dataset columns column_map = { &quot;begin1&quot;: &quot;firstCharEnt1&quot;, &quot;end1&quot;: &quot;lastCharEnt1&quot;, &quot;begin2&quot;: &quot;firstCharEnt2&quot;, &quot;end2&quot;: &quot;lastCharEnt2&quot;, &quot;chunk1&quot;: &quot;chunk1&quot;, &quot;chunk2&quot;: &quot;chunk2&quot;, &quot;label1&quot;: &quot;label1&quot;, &quot;label2&quot;: &quot;label2&quot; } # apply preprocess function to dataframe data = REDatasetHelper(data).create_annotation_column( column_map, ner_column_name=&quot;train_ner_chunks&quot; # optional, default train_ner_chunks ) New Utility &amp; Helper OCR Modules to Handle Annotations This modeule can generates an annotated PDF file using input PDF files. style: PDF file proccess style that has 3 options; black_band: Black bands over the chunks detected by NER pipeline. bounding_box: Colorful bounding boxes around the chunks detected by NER pipeline. Each color represents a different NER label. highlight: Colorful highlights over the chunks detected by NER pipeline. Each color represents a different NER label. You can check Spark OCR Utility Module notebook for more examples. Example: from sparknlp_jsl.utils.ocr_nlp_processor import ocr_entity_processor path=&#39;/*.pdf&#39; box = &quot;bounding_box&quot; ocr_entity_processor(spark=spark,file_path=path,ner_pipeline = nlp_model,chunk_col = &quot;merged_chunk&quot;, black_list = [&quot;AGE&quot;, &quot;DATA&quot;, &quot;PATIENT&quot;], style = box, save_dir = &quot;colored_box&quot;,label= True, label_color = &quot;red&quot;,color_chart_path = &quot;label_colors.png&quot;, display_result=True) box = &quot;highlight&quot; ocr_entity_processor(spark=spark,file_path=path, ner_pipeline = nlp_model, chunk_col = &quot;merged_chunk&quot;, black_list = [&quot;AGE&quot;, &quot;DATE&quot;, &quot;PATIENT&quot;], style = box, save_dir = &quot;colored_box&quot;, label= True, label_color = &quot;red&quot;, color_chart_path = &quot;label_colors.png&quot;, display_result=True) box = &quot;black_band&quot; ocr_entity_processor(spark=spark,file_path=path, ner_pipeline = nlp_modelchunk_col = &quot;merged_chunk&quot;, style = box, save_dir = &quot;black_band&quot;,label= True, label_color = &quot;red&quot;, display_result = True) Results: Bounding box with labels and black list Highlight with labels and black_list black_band with labels New Utility &amp; Helper NER Log Parser ner_utils: This new module is used after NER training to calculate mertic chunkbase and plot training logs. Example: nerTagger = NerDLApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) ... .setOutputLogsPath(&#39;ner_logs&#39;) ner_pipeline = Pipeline(stages=[glove_embeddings, graph_builder, nerTagger]) ner_model = ner_pipeline.fit(training_data) evaluate: if verbose, returns overall performance, as well as performance per chunk type; otherwise, simply returns overall precision, recall, f1 scores Example: from sparknlp_jsl.utils.ner_utils import evaluate metrics = evaluate(preds_df[&#39;ground_truth&#39;].values, preds_df[&#39;prediction&#39;].values) Result: processed 14133 tokens with 1758 phrases; found: 1779 phrases; correct: 1475. accuracy: 83.45%; (non-O) accuracy: 96.67%; precision: 82.91%; recall: 83.90%; FB1: 83.40 LOC: precision: 91.41%; recall: 85.69%; FB1: 88.46 524 MISC: precision: 78.15%; recall: 62.11%; FB1: 69.21 151 ORG: precision: 61.86%; recall: 74.93%; FB1: 67.77 430 PER: precision: 90.80%; recall: 93.58%; FB1: 92.17 674 loss_plot: Plots the figure of loss vs epochs Example: from sparknlp_jsl.utils.ner_utils import loss_plot loss_plot(&#39;./ner_logs/&#39;+log_files[0]) Results: get_charts : Plots the figures of metrics ( precision, recall, f1) vs epochs Example: from sparknlp_jsl.utils.ner_utils import get_charts get_charts(&#39;./ner_logs/&#39;+log_files[0]) Results: Adding Flexibility Chunk Merger Prioritization orderingFeatures: Array of strings specifying the ordering features to use for overlapping entities. Possible values are ChunkBegin, ChunkLength, ChunkPrecedence, ChunkConfidence selectionStrategy: Whether to select annotations sequentially based on annotation order Sequential or using any other available strategy, currently only DiverseLonger are available. defaultConfidence: When ChunkConfidence ordering feature is included and a given annotation does not have any confidence the value of this param will be used. chunkPrecedence: When ChunkPrecedence ordering feature is used this param contains the comma separated fields in metadata that drive prioritization of overlapping annotations. When used by itself (empty chunkPrecedenceValuePrioritization) annotations will be prioritized based on number of metadata fields present. When used together with chunkPrecedenceValuePrioritization param it will prioritize based on the order of its values. chunkPrecedenceValuePrioritization: When ChunkPrecedence ordering feature is used this param contains an Array of comma separated values representing the desired order of prioritization for the VALUES in the metadata fields included from chunkPrecedence. Example: text = &quot;&quot;&quot;A 63 years old man presents to the hospital with a history of recurrent infections that include cellulitis, pneumonias, and upper respiratory tract infections...&quot;&quot;&quot; +-+ |ner_deid_chunk | +-+ |[{chunk, 2, 3, 63, {entity -&gt; AGE, sentence -&gt; 0, chunk -&gt; 0, confidence -&gt; 0.9997}}]| +-+ +-+ |jsl_ner_chunk | +-+ |[{chunk, 2, 13, 63 years old, {entity -&gt; Age, sentence -&gt; 0, chunk -&gt; 0, confidence -&gt; 0.85873336}}]| +-+ Merging overlapped chunks by considering their lenght If we set setOrderingFeatures([&quot;ChunkLength&quot;]) and setSelectionStrategy(&quot;DiverseLonger&quot;) parameters, the longest chunk will be prioritized in case of overlapping. Example: chunk_merger = ChunkMergeApproach() .setInputCols(&#39;ner_deid_chunk&#39;, &quot;jsl_ner_chunk&quot;) .setOutputCol(&#39;merged_ner_chunk&#39;) .setOrderingFeatures([&quot;ChunkLength&quot;]) .setSelectionStrategy(&quot;DiverseLonger&quot;) Results: |begin|end| chunk| entity| +--++-++ | 2| 13| 63 years old| Age| | 15| 17| man| Gender| | 35| 42| hospital| Clinical_Dept| Merging overlapped chunks by considering custom values that we set setChunkPrecedence() parameter contains an Array of comma separated values representing the desired order of prioritization for the VALUES in the metadata fields included from setOrderingFeatures([&quot;chunkPrecedence&quot;]). Example: chunk_merger = ChunkMergeApproach() .setInputCols(&#39;ner_deid_chunk&#39;, &quot;jsl_ner_chunk&quot;) .setOutputCol(&#39;merged_ner_chunk&#39;) .setMergeOverlapping(True) .setOrderingFeatures([&quot;ChunkPrecedence&quot;]) .setChunkPrecedence(&#39;ner_deid_chunk,AGE&#39;) # .setChunkPrecedenceValuePrioritization([&quot;ner_deid_chunk,AGE&quot;, &quot;jsl_ner_chunk,Age&quot;]) Results: |begin|end| chunk| entity| +--++-++ | 2| 3| 63| AGE| | 15| 17| man| Gender| | 35| 42| hospital| Clinical_Dept| You can check NER Chunk Merger notebook for more examples. Core improvements and bug fixes AssertionDL IncludeConfidence() parameters default value set by True Fixed NaN outputs in RelationExtraction Fixed loadSavedModel method that we use for importing transformers into Spark NLP Fixed replacer with setUseReplacement(True) parameter Added overall confidence score to MedicalNerModel when setIncludeAllConfidenceScore is True Fixed in InternalResourceDownloader showAvailableAnnotators New and Updated Notebooks New Spark OCR Utility Module notebook to help handle OCR process. Updated Clinical Entity Resolvers notebook with Assertion Filterer example. Updated NER Chunk Merger notebook with flexibility chunk merger prioritization example. Updated Clinical Relation Extraction notebook with new REDatasetHelper module. Updated ALab Module SparkNLP JSL notebook with new updates. 3 New Clinical Models and Pipelines Added &amp; Updated in Total kegg_disease_mapper kegg_drug_mapper abbreviation_category_mapper For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_3"
  },
  "1466": {
    "id": "1466",
    "title": "Visual NLP(Spark OCR) release notes 4.2.4",
    "content": "4.2.4 We are glad to announce that Spark OCR 4.2.4⚡has been released!! This release includes new optimized ImageToTextV2 models, more support on annotators in LightPipelines, a new PdfToHocr annotator, enhancements, and more! New Features New annotators supported in LightPipelines: PdfToText and most Image transformations. Check sample notebook for details. Handling of PDFs with broken headers: some PDFs may contain incorrect header information causing the pipelines to fail to process them, now PDF processing annotators support handling these documents. New Annotators New ImageToTextV2 Transformers based OCR annotator, Intended to become a full replacement of original ImageToTextV2. Speed ups of up to 2x compared to original model. It doesn’t require GPU, it works with CPU only environments. Preliminary experiments show similar character error rate compared to original model. Optimized versions take less space(about a half) and are faster to store and download. Full JVM implementation. Limitations: currently the new ImageToTextV2 doesn’t support Hocr output. To start using it, follow this example, ... from sparkocr.optimized import ImageToTextV2 ocr = ImageToTextV2.pretrained(&quot;ocr_base_printed_v2_opt&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) New PdfToHocr: this new annotator allows to produce HOCR output from digital PDFs. This is not only useful for integrating into existing annotators that already consume HOCR, but for new pipelines that will be released in the future. Stay tuned for new releases. New Models ocr_base_printed_v2 ocr_base_handwritten_v2 ocr_base_printed_v2_opt (quantized version) ocr_base_handwritten_v2_opt (quantized version) New Notebooks New supported transformers in LightPipelines in action, SparkOcrLightPipelinesPdf.ipynb PdfToHocr, SparkOCRPdfToHocr.ipynb This release is compatible with Spark NLP 4.2.4, and Spark NLP for Healthcare 4.2.3. Versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_2_4",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_2_4"
  },
  "1467": {
    "id": "1467",
    "title": "Spark NLP for Healthcare Release Notes 4.2.4",
    "content": "4.2.4 Highlights New chunk mapper model for matching drugs by categories as well as other brands and names 4 new NER and classification models for Social Determinant of Health Allow fuzzy matching in the ChunkMapper annotator New NameChunkObfuscatorApproach annotator to obfuscate doctor and patient names using a custom external list (consistent name obfuscation) New AssertionChunkConverter annotator to prepare assertion model training dataset from chunk indices New training_log_parser module to parse NER and Assertion Status Detection model training log files Obfuscation of age entities by age groups in Deidentification Controlling the behaviour of unnormalized dates while shifting the days in Deidentification (setUnnormalizedDateMode parameter) Setting default day, months or years for partial dates via DateNormalizer Setting label case sensitivity in AssertionFilterer getClasses method for Zero Shot NER and Zero Shot Relation Extraction models Setting max syntactic distance parameter in RelationExtractionApproach Generic Relation Extraction Model (generic_re) to extract relations between any named entities using syntactic distances Core improvements and bug fixes New and updated notebooks New and updated demos MEDICAL QUESTION ANSWERING SMOKING STATUS MENTAL HEALTH DEPRESSION 5 new clinical models and pipelines added &amp; updated in total New Chunk Mapper Model For Matching Drugs by Categories As Well As Other Brands and Names We have a new drug_category_mapper chunk mapper model that maps drugs to their categories, other brands and names. It has two categories called main category and subcategory. Example: chunkerMapper = ChunkMapperModel.pretrained(&quot;drug_category_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;main_category&quot;, &quot;sub_category&quot;, &quot;other_name&quot;]) sample_text= &quot;She is given OxyContin, folic acid, levothyroxine, Norvasc, aspirin, Neurontin.&quot; Result: +-++--+--+ | ner_chunk| main_category| sub_category|other_names| +-++--+--+ | OxyContin| Pain Management| Opioid Analgesics| Oxaydo| | folic acid| Nutritionals| Vitamins, Water-Soluble| Folvite| |levothyroxine|Metabolic &amp; Endocrine| Thyroid Products| Levo T| | Norvasc| Cardiovascular| Antianginal Agents| Katerzia| | aspirin| Cardiovascular|Antiplatelet Agents, Cardiovascular| ASA| | Neurontin| Neurologics| GABA Analogs| Gralise| +-++--+--+ 4 New NER and Classification Models for Social Determinant of Health We are releasing 4 new NER and Classification models for Social Determinant of Health. ner_sdoh_mentions: Detecting Social Determinants of Health mentions in clinical notes. Predicted entities: sdoh_community, sdoh_economics, sdoh_education, sdoh_environment, behavior_tobacco, behavior_alcohol, behavior_drug. Example: ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_mentions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;&quot;&quot;Mr. John Smith is a pleasant, cooperative gentleman with a long standing history (20 years) of diverticulitis. He is married and has 3 children. He works in a bank. He denies any alcohol or intravenous drug use. He has been smoking for many years.&quot;&quot;&quot; Result: +-+-+ |chunk |ner_label | +-+-+ |married |sdoh_community | |children |sdoh_community | |works |sdoh_economics | |alcohol |behavior_alcohol| |intravenous drug|behavior_drug | |smoking |behavior_tobacco| +-+-+ MedicalBertForSequenceClassification models that can be used in Social Determinant of Health related classification tasks: model name description predicted entities bert_sequence_classifier_sdoh_community_absent_status Classifies the clinical texts related to the loss of social support such as a family member or friend in the clinical documents. A discharge summary was classified True for Community-Absent if the discharge summary had passages related to the loss of social support and False if such passages were not found in the discharge summary. True False bert_sequence_classifier_sdoh_community_present_status Classifies the clinical texts related to social support such as a family member or friend in the clinical documents. A discharge summary was classified True for Community-Present if the discharge summary had passages related to active social support and False if such passages were not found in the discharge summary. True False bert_sequence_classifier_sdoh_environment_status Classifies the clinical texts related to environment situation such as any indication of housing, homeless or no related passage. A discharge summary was classified as True for the SDOH Environment if there was any indication of housing, False if the patient was homeless and None if there was no related passage. True False None Example: sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_sdoh_community_present_status&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) sample_text = [&quot;Right inguinal hernia repair in childhood Cervical discectomy 3 years ago Umbilical hernia repair 2137. Retired schoolteacher, now substitutes. Lives with wife in location 1439. Has a 27 yo son and a 25 yo daughter. Name (NI) past or present smoking hx, no EtOH.&quot;, &quot;Atrial Septal Defect with Right Atrial Thrombus Pulmonary Hypertension Obesity, Obstructive Sleep Apnea. Denies tobacco and ETOH. Works as cafeteria worker.&quot;] Result: +-+-+ | text| result| +-+-+ |Right inguinal hernia repair in childhood Cervical discectomy 3 years ago Umbilical hernia repair...| [True]| |Atrial Septal Defect with Right Atrial Thrombus Pulmonary Hypertension Obesity, Obstructive Sleep...|[False]| +-+-+ Allow Fuzzy Matching in the ChunkMapper Annotator There are multiple options to achieve fuzzy matching using the ChunkMapper annotation: Partial Token NGram Fingerprinting: Useful to combine two frequent usecases; when there are noisy non informative tokens at the beginning / end of the chunk and the order of the chunk is not absolutely relevant. i.e. stomach acute pain –&gt; acute pain stomach ; metformin 100 mg –&gt; metformin. Char NGram Fingerprinting: Useful in usecases that involve typos or different spacing patterns for chunks. i.e. head ache / ache head –&gt; headache ; metformini / metformoni / metformni –&gt; metformin Fuzzy Distance (Slow): Useful when the mapping can be defined in terms of edit distance thresholds using functions like char based like Levenshtein, Hamming, LongestCommonSubsequence or token based like Cosine, Jaccard. The mapping logic will be run in the previous order also ordering by longest key inside each option as an intuitive way to minimize false positives. Basic Mapper Example: cm = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setLowerCase(True) .setRels([&quot;action&quot;, &quot;treatment&quot;]) text = &quot;&quot;&quot;The patient was given Lusa Warfarina 5mg and amlodipine 10 MG. The patient was given Aspaginaspa, coumadin 5 mg, coumadin, and he has metamorfin&quot;&quot;&quot; # Since mappers only match one-to-one | ner_chunk | fixed_chunk | action | treatment | |:-|:|:-|:-| | Aspaginaspa | nan | nan | nan | | Lusa Warfarina 5mg | nan | nan | nan | | amlodipine 10 | nan | nan | nan | | coumadin | coumadin | Coagulation Inhibitor | hypertension | | coumadin 5 mg | nan | nan | nan | | metamorfin | nan | nan | nan | Since mappers only match one-to-one, we see that only 1 chunk has action and teatment in the table above. Token Fingerprinting Example: cm = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setLowerCase(True) .setRels([&quot;action&quot;, &quot;treatment&quot;]) .setAllowMultiTokenChunk(True) .setEnableTokenFingerprintMatching(True) .setMinTokenNgramFingerprint(1) .setMaxTokenNgramFingerprint(3) .setMaxTokenNgramDroppingCharsRatio(0.5) Result: | ner_chunk | fixed_chunk | action | treatment | |:--|:-|:--|:-| | Aspaginaspa | nan | nan | nan | | Lusa Warfarina 5mg | Warfarina lusa | Analgesic | diabetes | | amlodipine 10 | amlodipine | Calcium Ions Inhibitor | hypertension | | coumadin | coumadin | Coagulation Inhibitor | hypertension | | coumadin 5 mg | coumadin | Coagulation Inhibitor | hypertension | | metamorfin | nan | nan | nan | Token and Char Fingerprinting Example: cm = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setLowerCase(True) .setRels([&quot;action&quot;, &quot;treatment&quot;]) .setAllowMultiTokenChunk(True) .setEnableTokenFingerprintMatching(True) .setMinTokenNgramFingerprint(1) .setMaxTokenNgramFingerprint(3) .setMaxTokenNgramDroppingCharsRatio(0.5) .setEnableCharFingerprintMatching(True) .setMinCharNgramFingerprint(1) .setMaxCharNgramFingerprint(3) Result: | ner_chunk | fixed_chunk | action | treatment | |:--|:|:|:-| | Aspaginaspa | aspagin | Cycooxygenase Inhibitor | arthritis | | Lusa Warfarina 5mg | Warfarina lusa | Analgesic | diabetes | | amlodipine 10 | amlodipine | Calcium Ions Inhibitor | hypertension | | coumadin | coumadin | Coagulation Inhibitor | hypertension | | coumadin 5 mg | coumadin | Coagulation Inhibitor | hypertension | | metamorfin | nan | nan | nan | Token and Char Fingerprinting With Fuzzy Distance Calculation Example: cm = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;mappings.json&quot;) .setLowerCase(True) .setRels([&quot;action&quot;]) .setAllowMultiTokenChunk(True) .setEnableTokenFingerprintMatching(True) .setMinTokenNgramFingerprint(1) .setMaxTokenNgramFingerprint(3) .setMaxTokenNgramDroppingCharsRatio(0.5) .setEnableCharFingerprintMatching(True) .setMinCharNgramFingerprint(1) .setMaxCharNgramFingerprint(3) .setEnableFuzzyMatching(True) .setFuzzyMatchingDistanceThresholds(0.31) Result: | ner_chunk | fixed_chunk | action | treatment | |:-|:|:|:-| | Aspaginaspa | aspagin | Cycooxygenase Inhibitor | arthritis | | Lusa Warfarina 5mg | Warfarina lusa | Analgesic | diabetes | | amlodipine 10 | amlodipine | Calcium Ions Inhibitor | hypertension | | coumadin | coumadin | Coagulation Inhibitor | hypertension | | coumadin 5 mg | coumadin | Coagulation Inhibitor | hypertension | | metamorfin | metformin | hypoglycemic | diabetes | You can check Chunk_Mapping notebook for more examples. New NameChunkObfuscatorApproach Annotator to Obfuscate Doctor and Patient Names Using a Custom External List (consistent name obfuscation) We have a new NameChunkObfuscatorApproach annotator that can be used in deidentification tasks for replacing doctor and patient names with fake names using a reference document. Example: names = &quot;&quot;&quot;Mitchell#NAME Jackson#NAME Leonard#NAME Bowman#NAME Fitzpatrick#NAME Melody#NAME&quot;&quot;&quot; with open(&#39;names_test.txt&#39;, &#39;w&#39;) as file: file.write(names) nameChunkObfuscator = NameChunkObfuscatorApproach() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;replacement&quot;) .setRefFileFormat(&quot;csv&quot;) .setObfuscateRefFile(&quot;names_test.txt&quot;) .setRefSep(&quot;#&quot;) text = &#39;&#39;&#39;John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment. &#39;&#39;&#39; Result: Original text : John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment. Obfuscated text : Fitzpatrick is a &lt;AGE&gt; y.o. patient admitted. Mr. Bowman was seen by attending physician Dr. Melody and was scheduled for emergency assessment. You can check Clinical DeIdentification notebook for more examples. New AssertionChunkConverter Annotator to Prepare Assertion Model Training Dataset From Chunk Indices In some cases, there may be issues while creating the chunk column by using token indices and losing some data while training and testing the assertion status model if there are issues in these token indices. So we developed a new AssertionChunkConverter annotator that takes begin and end indices of the chunks as input and creates an extended chunk column with metadata that can be used for assertion status detection model training. Example: ... converter = AssertionChunkConverter() .setInputCols(&quot;tokens&quot;) .setChunkTextCol(&quot;target&quot;) .setChunkBeginCol(&quot;char_begin&quot;) .setChunkEndCol(&quot;char_end&quot;) .setOutputTokenBeginCol(&quot;token_begin&quot;) .setOutputTokenEndCol(&quot;token_end&quot;) .setOutputCol(&quot;chunk&quot;) sample_data = spark.createDataFrame([[&quot;An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized.&quot;, &quot;Minnie&quot;, 57, 63], [&quot;After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation &quot;, &quot;PCP&quot;, 31, 34]]) .toDF(&quot;text&quot;, &quot;target&quot;, &quot;char_begin&quot;, &quot;char_end&quot;) Result: ++-+--+--++--+++-+ |target|char_begin|char_end|token_begin|token_end|tokens[token_begin].result|tokens[token_end].result|target|chunk | ++-+--+--++--+++-+ |Minnie|57 |62 |10 |10 |Minnie |Minnie |Minnie|[{chunk, 57, 63, Minnie, {sentence -&gt; 0}, []}]| |PCP |31 |34 |5 |5 |PCP |PCP |PCP |[{chunk, 31, 33, PCP, {sentence -&gt; 0}, []}] | ++-+--+--++--+++-+ New training_log_parser Module to Parse Training Log Files of NER And Assertion Status Detection Models We are releasing a new training_log_parser module that helps to parse NER and Assertion Status Detection model training log files using a single module. Here are the methods and their descriptions:   Description ner_log_parser assertion_log_parser How to import You can import this module for NER and Assertion as shown here from sparknlp_jsl.training_log_parser import ner_log_parser from sparknlp_jsl.training_log_parser import assertion_log_parser get_charts Plots the figures of metrics ( precision, recall, f1) vs epochs ner_log_parser.get_charts(log_file, threshold) assertion_log_parser.get_charts(log_file, labels, threshold) loss_plot Plots the figures of validation and test loss values vs epochs. ner_log_parser.loss_plot(path) assertion_log_parser.loss_plot(path) get_best_f1_scores Returns the best Micro and Macro F1 Scores on test set ner_log_parser.get_best_f1_scores(path) assertion_log_parser.get_best_f1_scores(path) parse_logfile Returns the parsed log file in pandas dataframe format with the order of label-score dataframe, epoch-metrics dataframe and graph file used in tranining. ner_log_parser.parse_logfile(path) assertion_log_parser.parse_logfile(path, labels) evaluate if verbose, returns overall performance, as well as performance per chunk type; otherwise, simply returns overall precision, recall, f1 scores. Ground truth and predictions should be provided in pandas dataframe. ner_log_parser.evaluate(preds_df[&#39;ground_truth&#39;].values, preds_df[&#39;prediction&#39;].values) - Import from sparknlp_jsl.training_log_parser import ner_log_parser, assertion_log_parser ner_parser = ner_log_parser() assertion_parser = assertion_log_parser() Example for NER loss_plot method: ner_parser.loss_plot(&#39;NER_training_log_file.log&#39;) Result: Example for NER evaluate method: metrics = ner_parser.evaluate(preds_df[&#39;ground_truth&#39;].values, preds_df[&#39;prediction&#39;].values) Result: Example for Assertion get_best_f1_scores method: assertion_parser.get_best_f1_scores(&#39;Assertion_training_log_file.log&#39;, [&#39;Absent&#39;, &#39;Present&#39;]) Result: Obfuscation of Age Entities by Age Groups in Deidentification We have a new setAgeRanges() parameter in Deidentification annotator that provides the ability to set a custom range for obfuscation of AGE entities by another age within that age group (range). Default age groups list is [1, 4, 12, 20, 40, 60] and users can set any range. Infant = 0-1 year. Toddler = 2-4 yrs. Child = 5-12 yrs. Teen = 13-19 yrs. Adult = 20-39 yrs. Middle Age Adult = 40-59 yrs. Senior Adult = 60+ Example: deidentification = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;age_chunk&quot;]) .setOutputCol(&quot;obfuscation&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setObfuscateRefSource(&quot;faker&quot;) .setAgeRanges([1, 4, 12, 20, 40, 60, 80]) Result: +--++--+ |text |age_chunk|obfuscation | +--++--+ |1 year old baby |1 |2 year old baby | |4 year old kids |4 |6 year old kids | |A 15 year old female with |15 |A 12 year old female with | |Record date: 2093-01-13, Age: 25|25 |Record date: 2093-03-01, Age: 30| |Patient is 45 years-old |45 |Patient is 44 years-old | |He is 65 years-old male |65 |He is 75 years-old male | +--++--+ Controlling the behaviour of unnormalized dates while shifting the days in Deidentification (setUnnormalizedDateMode parameter) Two alternatives can be used when deidentification in unnormalized date formats, these are mask and obfuscation. setUnnormalizedDateMode(&#39;mask&#39;) parameter is used to mask the DATE entities that can not be normalized. setUnnormalizedDateMode(&#39;obfuscate&#39;) parameter is used to obfuscate the DATE entities that can not be normalized. Example: de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;document2&quot;]) .setOutputCol(&quot;deid_text&quot;) .setMode(&quot;obfuscate&quot;) ... .setUnnormalizedDateMode(&quot;mask&quot;) # or obfuscation Result: +--++++ |text |dateshift| mask | obfuscation| +--++++ |04/19/2018 |-5 | 04/14/2018 | 04/14/2018 | |04-19-2018 |-2 | 04-17-2018 | 04-17-2018 | |19 Apr 2018|10 | &lt;DATE&gt; | 10-10-1975 | |04-19-18 |20 | &lt;DATE&gt; | 03-23-2001 | +--++++ Setting Default Day, Months or Years for Partial Dates via DateNormalizer We have 3 new parameters to make DateNormalizer more flexible with date replacing. If any of the day, month and year information is missing in the date format, the following default values will be added. setDefaultReplacementDay: default value is 15 setDefaultReplacementMonth: default value is July or 6 setDefaultReplacementYear: default value is 2020 Example: date_normalizer_us = DateNormalizer() .setInputCols(&#39;date_chunk&#39;) .setOutputCol(&#39;normalized_date_us&#39;) .setOutputDateformat(&#39;us&#39;) .setDefaultReplacementDay(&quot;15&quot;) .setDefaultReplacementMonth(&quot;6&quot;) .setDefaultReplacementYear(&quot;2020&quot;) Result: ++++ |text |date_chunk |normalized_date_us| ++++ |08/02/2018 |08/02/2018 |08/02/2018 | |3 April 2020|3 April 2020|04/03/2020 | |03/2021 |03/2021 |03/15/2021 | |05 Jan |05 Jan |01/05/2020 | |01/05 |01/05 |01/05/2020 | |2022 |2022 |06/15/2022 | ++++ You can check Date Normalizer notebook for more examples Setting Label Case Sensitivity in AssertionFilterer We have case sensitive filtering flexibility for labels by setting new setCaseSensitive(True) in AssertionFilterer annotator. Example: assertion_filterer = AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;assertion_filtered&quot;) .setCaseSensitive(False) .setWhiteList([&quot;ABsent&quot;]) sample_text = &quot;The patient was admitted 2 weeks ago with a headache. No alopecia was noted.&quot; Result: | chunks | entities | assertion | confidence | | -- | - | | - | | Alopecia | Disease_Syndrome_Disorder | Absent | 1 | getClasses Method to Zero Shot NER and Zero Shot Relation Extraction Models The predicted entities of ZeroShotNerModel and ZeroShotRelationExtractionModels can be extracted with getClasses methods just like NER annotators. Example: zero_shot_ner = ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setEntityDefinitions({ &quot;PROBLEM&quot;: [&quot;What is the disease?&quot;, &quot;What is the problem?&quot; ,&quot;What does a patient suffer&quot;], &quot;DRUG&quot;: [&quot;Which drug?&quot;, &quot;Which is the drug?&quot;, &quot;What is the drug?&quot;], &quot;ADMISSION_DATE&quot;: [&quot;When did patient admitted to a clinic?&quot;], &quot;PATIENT_AGE&quot;: [&quot;How old is the patient?&quot;,&#39;What is the gae of the patient?&#39;] }) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) zero_shot_ner.getClasses() Result: [&#39;DRUG&#39;, &#39;PATIENT_AGE&#39;, &#39;ADMISSION_DATE&#39;, &#39;PROBLEM&#39;] Setting Max Syntactic Distance Flexibility In RelationExtractionApproach Now we are able to set maximal syntactic distance as threshold in RelationExtractionApproach while training relation extraction models. reApproach = RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setLabelColumn(&quot;rel&quot;) ... .setMaxSyntacticDistance(10) Generic Relation Extraction Model (generic_re) to extract relations between any named entities using syntactic distances We already have more than 80 relation extraction (RE) models that can extract relations between certain named entities. Nevertheless, there are some rare entities or cases that you may not find the right RE or the one you find may not work as expected due to nature of your dataset. In order to ease this burden, we are releasing a generic RE model (generic_re) that can be used between any named entities using the syntactic distances, POS tags and dependency tree between the entities. You can tune this model by using the setMaxSyntacticDistance param. Example: reModel = RelationExtractionModel() .pretrained(&quot;generic_re&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationPairs([&quot;Biomarker-Biomarker_Result&quot;, &quot;Biomarker_Result-Biomarker&quot;, &quot;Oncogene-Biomarker_Result&quot;, &quot;Biomarker_Result-Oncogene&quot;, &quot;Pathology_Test-Pathology_Result&quot;, &quot;Pathology_Result-Pathology_Test&quot;]) .setMaxSyntacticDistance(4) text = &quot;&quot;&quot;Pathology showed tumor cells, which were positive for estrogen and progesterone receptors.&quot;&quot;&quot; Result: |sentence |entity1_begin |entity1_end | chunk1 | entity1 |entity2_begin |entity2_end | chunk2 | entity2 | relation |confidence| |--:|-:|--:|:-|:--|-:|--:|:--|:--|:--|-| | 0 | 1 | 9 | Pathology | Pathology_Test | 18 | 28 | tumor cells | Pathology_Result | Pathology_Test-Pathology_Result | 1| | 0 | 42 | 49 | positive | Biomarker_Result | 55 | 62 | estrogen | Biomarker | Biomarker_Result-Biomarker | 1| | 0 | 42 | 49 | positive | Biomarker_Result | 68 | 89 | progesterone receptors | Biomarker | Biomarker_Result-Biomarker | 1| Core improvements and bug fixes Fixed obfuscated addresses capitalized word style Added more patterns for Date Obfuscation Improve speed of get_conll_data() method in alab module Fixed serialization Issue with MLFlow ContextualParser Renamed TFGraphBuilder.setIsMedical to TFGraphBuilder.setIsLicensed New and Updated Notebooks Updated ZeroShot Clinical NER Notebook with getClasses method for zero shot NER models. Updated Clinical Assertion Notebook with AssertionChunkConverter, AssertionFilterer and TFGraphBuilder.setIsLicensed examples. Updated Clinical Entity Resolvers Notebook with AssertionFilterer example. Updated Clinical DeIdentification Notebook with setUnnormalizedDateMode and NameChunkObfuscatorApproach example. Updated ZeroShot Clinical Relation Extraction Notebook with getClasses and setMaxSyntacticDistance method for Relation Extraction models. Updated Date Normalizer notebook with DateNormalizer for dynamic date replace values. Updated Chunk Mapping notebook with fuzzy matching flexibility examples. New and Updated Demos MEDICAL QUESTION ANSWERING SMOKING STATUS MENTAL HEALTH DEPRESSION 5 New Clinical Models and Pipelines Added &amp; Updated in Total drug_category_mapper ner_sdoh_mentions bert_sequence_classifier_sdoh_community_absent_status bert_sequence_classifier_sdoh_community_present_status bert_sequence_classifier_sdoh_environment_status For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_4",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_4"
  },
  "1468": {
    "id": "1468",
    "title": "Spark NLP for Healthcare Release Notes 4.2.8",
    "content": "4.2.8 Highlights 4 new clinical named entity recognition models (3 oncology, 1 others) 5 new Social Determenant of Health text classification models New DocumentMLClassifierApproach annotator for training text classification models using SVM and Logistic Regression using TfIdf New Resolution2Chunk annotator to map entity resolver outputs (terminology codes) to other clinical terminologies New DocMapperModel annotator allows to use any mapper model in DOCUMENT type Option to return Deidentification output as a single document Inter-Annotator Agreement (IAA) metrics module that works with NLP Lab seamlessly Assertion dataset preparation module now supports chunk start and end indices, rather than token indices Added ner_source in the ChunkConverter metadata Core improvements and bug fixes Added chunk confidence score in the RelationExtractionModel metadata Added confidence score in the DocumentLogRegClassifierApproach metadata Fixed non-deterministic Relation Extraction DL Models (30+ models updated in the model hub) Fixed incompatible PretrainedPipelines with PySpark v3.2.x and v3.3.x Fixed ZIP label issue on faker mode with setZipCodeTag parameter in Deidentification Fixed obfuscated numbers have the same number of chars as the original ones Fixed name obfuscation hashes in Deidentification for romanian language Fixed LightPipeline validation parameter for internal annotators LightPipeline support for GenericClassifier (FeatureAssembler) New and updated notebooks New Clinical Text Classification with Spark_NLP Notebook New Clinical Text Classification with DocumentMLClassifier Notebook Updated ALAB Notebook New and updated demos SOCIAL DETERMINANT demo 9 new clinical models and pipelines added &amp; updated in total 4 New Clinical Named Entity Recognition Models (3 Oncology, 1 Others) We are releasing 3 new oncological NER models that were trained by using embeddings_healthcare_100d embeddings model. model name description predicted entities ner_oncology_anatomy_general_healthcare Extracts anatomical entities using an unspecific label Anatomical_Site Direction ner_oncology_biomarker_healthcare Extracts mentions of biomarkers and biomarker results in oncological texts. Biomarker_Result Biomarker ner_oncology_unspecific_posology_healthcare Extracts mentions of treatments and posology information using unspecific labels (low granularity). Posology_Information Cancer_Therapy Example: ... word_embeddings = WordEmbeddingsModel() .pretrained(&quot;embeddings_healthcare_100d&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner = MedicalNerModel .pretrained(&quot;ner_oncology_anatomy_general_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;The patient presented a mass in her left breast, and a possible metastasis in her lungs and in her liver.&quot; Result: ++-+ |chunk |ner_label | ++-+ |left |Direction | |breast |Anatomical_Site | |lungs |Anatomical_Site | |liver |Anatomical_Site | ++-+ We are releasing new oncological NER models that used for model training is provided by European Clinical Case Corpus (E3C), a project aimed at offering a freely available multilingual corpus of semantically annotated clinical narratives. Example: ... ner = MedicalNerModel.pretrained(&#39;ner_eu_clinical_case&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;&quot;&quot;A 3-year-old boy with autistic disorder on hospital of pediatric ward A at university hospital. He has no family history of illness or autistic spectrum disorder.&quot;&quot;&quot; Result: +++ |chunk |ner_label | +++ |A 3-year-old boy |patient | |autistic disorder |clinical_condition| |He |patient | |illness |clinical_event | |autistic spectrum disorder |clinical_condition| +++ 5 New Social Determinant of Health Text Classification Models We are releasing 5 new models that can be used in Social Determinant of Health related classification tasks. model name description predicted entities genericclassifier_sdoh_alcohol_usage_sbiobert_cased_mli This model is intended for detecting alcohol use in clinical notes and trained by using GenericClassifierApproach annotator. Present Past Never None genericclassifier_sdoh_alcohol_usage_binary_sbiobert_cased_mli This model is intended for detecting alcohol use in clinical notes and trained by using GenericClassifierApproach annotator. Present Never None genericclassifier_sdoh_tobacco_usage_sbiobert_cased_mli This model is intended for detecting tobacco use in clinical notes and trained by using GenericClassifierApproach annotator Present Past Never None genericclassifier_sdoh_economics_binary_sbiobert_cased_mli This model classifies related to social economics status in the clinical documents and trained by using GenericClassifierApproach annotator. True False genericclassifier_sdoh_substance_usage_binary_sbiobert_cased_mli This model is intended for detecting substance use in clinical notes and trained by using GenericClassifierApproach annotator. Present None Example: ... features_asm = FeaturesAssembler() .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;features&quot;) generic_classifier_tobacco = GenericClassifierModel.pretrained(&quot;genericclassifier_sdoh_tobacco_usage_sbiobert_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;class_tobacco&quot;) generic_classifier_alcohol = GenericClassifierModel.pretrained(&quot;genericclassifier_sdoh_alcohol_usage_sbiobert_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;class_alcohol&quot;) text = [&quot;Retired schoolteacher, now substitutes. Lives with wife in location 1439. Has a 27 yo son and a 25 yo daughter. He uses alcohol and cigarettes&quot;, &quot;The patient quit smoking approximately two years ago with an approximately a 40 pack year history, mostly cigar use.&quot;, &quot;The patient denies any history of smoking or alcohol abuse. She lives with her one daughter.&quot;, &quot;She was previously employed as a hairdresser, though says she hasnt worked in 4 years. Not reported by patient, but there is apparently a history of alochol abuse.&quot; ] Result: +-+++ | text| tobacco| alcohol| +-+++ |Retired schoolteacher, now substitutes. Lives with wife in location 1439. Has a 27 yo son and a 2...|[Present]|[Present]| |The patient quit smoking approximately two years ago with an approximately a 40 pack year history...| [Past]| [None]| | The patient denies any history of smoking or alcohol abuse. She lives with her one daughter.| [Never]| [Never]| |She was previously employed as a hairdresser, though says she hasnt worked in 4 years. Not report...| [None]| [Past]| +-+++ New DocumentMLClassifierApproach Annotator For Training Text Classification Models Using SVM And Logistic Regression Using TfIdf We have a new DocumentMLClassifierApproach that can be used for training text classification models with Logistic Regression and SVM algorithms. Training data requires “text” and their “label” columns only and the trained model will be a DocumentMLClassifierModel(). Input types: TOKEN Output type: CATEGORY Parameters Description labels array to output the label in the original form. labelCol column with the value result we are trying to predict. maxIter maximum number of iterations. tol convergence tolerance after each iteration. fitIntercept whether to fit an intercept term, default is true. maxTokenNgram the max number of tokens for Ngrams minTokenNgram the min number of tokens for Ngrams vectorizationModelPath specify the vectorization model if it has been already trained. classificationModelPath specify the classification model if it has been already trained. classificationModelClass specify the SparkML classification class; possible values are logreg, svm Example: ... classifier_svm= DocumentMLClassifierApproach() .setInputCols(&quot;token&quot;) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) .setMaxTokenNgram(1) .setClassificationModelClass(&quot;svm&quot;) #or &quot;logreg&quot; model_svm = Pipeline(stages=[document, token, classifier_svm]).fit(trainingData) text = [ [&quot;This 1-year-old child had a gastrostomy placed due to feeding difficulties.&quot;], [&quot;He is a pleasant young man who has a diagnosis of bulbar cerebral palsy and hypotonia.&quot;], [&quot;The patient is a 45-year-old female whose symptoms are pain in the left shoulder and some neck pain.&quot;], [&quot;The patient is a 61-year-old female with history of recurrent uroseptic stones.&quot;] ] Result: +-+-+ |text |prediction | +-+-+ |He is a pleasant young man who has a diagnosis of bulbar cerebral palsy and hypotonia. |Neurology | |This 1-year-old child had a gastrostomy placed due to feeding difficulties. |Gastroenterology| |The patient is a 61-year-old female with history of recurrent uroseptic stones. |Urology | |The patient is a 45-year-old female whose symptoms are pain in the left shoulder and some neck pain.|Orthopedic | +-+-+ Option To Return Deidentification Output As a Single Document We can return Deidentification() output as a single document by setting new setOutputAsDocument as True. If it is False, the outputs will be list of sentences as it is used to be. Example: deid_obfuscated = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk_subentity&quot;]) .setOutputCol(&quot;obfuscated&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setObfuscateRefFile(&#39;obfuscate.txt&#39;) .setObfuscateRefSource(&quot;file&quot;) .setUnnormalizedDateMode(&quot;obfuscate&quot;) .setOutputAsDocument(True) # or False for sentence level result text =&#39;&#39;&#39; Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson , Ora MR # 7194334 Date : 01/13/93 . Patient : Oliveira, 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street &#39;&#39;&#39; Result of .setOutputAsDocument(True): &#39;obfuscated&#39;: [&#39;Record date : 2093-01-14 , Beer-Karge , M.D . , Name : Hasan Jacobi Jäckel MR # &lt;MEDICALRECORD&gt; Date : 01-31-1991 . Patient : Herr Anselm Trüb, 51 years-old , Record date : 2080-01-08 . Klinik St. Hedwig . &lt;MEDICALRECORD&gt; Keats Street&#39;] Result of .setOutputAsDocument(False): &#39;obfuscated&#39;: [&#39;Record date : 2093-02-19 , Kaul , M.D . , Name : Frauke Oestrovsky MR # &lt;MEDICALRECORD&gt; Date : 05-08-1971 .&#39;, &#39;Patient : Lars Bloch, 33 years-old , Record date : 2079-11-11 .&#39;, &#39;University Hospital of Düsseldorf . &lt;MEDICALRECORD&gt; Keats Street&#39;] New Resolution2Chunk Annotator To Map Entity Resolver Outputs (terminology codes) To Other Clinical Terminologies We have a new Resolution2Chunk annotator that maps the entity resolver outputs to other clinical terminologies. Example: icd_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_augmented_billable_hcc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;icd10cm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) resolver2chunk = Resolution2Chunk() .setInputCols([&quot;icd10cm_code&quot;]) .setOutputCol(&quot;resolver2chunk&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;icd10cm_snomed_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;resolver2chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;snomed_code&quot;]) sample_text = &quot;&quot;&quot;Diabetes Mellitus&quot;&quot;&quot; Result: +--+--++--+ |text |ner_chunk |icd10cm_code|snomed_code| +--+--++--+ |Diabetes Mellitus|Diabetes Mellitus|E109 |170756003 | +--+--++--+ New DocMapperModel Annotator Allows To Use With Any Mapper Model In DOCUMENT Type Any ChunkMapperModel can be used with this new annotator called DocMapperModel and as its name suggests, it is used to map short strings via DocumentAssembler without using any other annotator between to convert strings to Chunk type that ChunkMapperModel expects. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) model = DocMapperModel.pretrained(&quot;drug_brandname_ndc_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;mappings&quot;) sample_text = &quot;ZYVOX&quot; Result: | Brand_Name | Strenth_NDC | |:-|:-| | ZYVOX | 600 mg/300mL | 0009-4992 | Inter-Annotator Agreement (IAA) metrics module that works with NLP Lab seamlessly We added a new get_IAA_metrics() method to ALAB module. This method allows you to compare and evaluate the annotations in the seed corpus that all annotators annotated the same documents at the begining of an annotation project. It returns all the results in CSV files. Here are the parameters; spark : SparkSession. conll_dir (str): path to the folder that conll files in. annotator_names (list): list of annotator names. set_ref_annotator (str): reference annotator name. If present, all comparisons made with respect to it, if it is None all annotators will be compared by each other. Default is None. return_NerDLMetrics (boolean): If True, we get the full_chunk and - partial_chunk_per_token IAA metrics by using NerDLMetrics. If False, we get the chunk based metrics using evaluate method of training_log_parser module and the token based metrics using classification reports, then write the results in “eval_metric_files” folder. Default is False. save_dir (str): path to save the token based results dataframes, default is “results_token_based”. For more details and examples, please check ALAB Notebook. Example: alab.get_IAA_metrics(spark, conll_dir = path_to_conll_folder, annotator_names = [&quot;annotator_1&quot;,&quot;annotator_2&quot;,&quot;annotator_3&quot;,&quot;annotator_4&quot;], set_ref_annotator = &quot;annotator_1&quot;, return_NerDLMetrics = False, save_dir = &quot;./token_based_results&quot;) Assertion dataset preparation module now supports chunk start and end indices, rather than token indices. Here are the new features in get_assertion_data(); Now it returns the char_begin and char_end indices of the chunks. These columns can be used in AssertionDLApproach() annotator instead of token_begin and token_end columns for training an Assertion Status Detection model. Added included_task_ids parameter that allows you to prepare the assertion model training dataframe with only the included tasks. Default is None. Added seed parameter that allows you to get the same training dataframe at each time when you set unannotated_label_strategy. Default is None. For more details and examples, please check ALAB Notebook. Added ner_source in the ChunkConverter Metadata We added ner_source in the metadata of ChunkConverter output. In this way, the sources of the chunks can be seen if there are multiple components that have the same NER label in the same pipeline. Example: ... age_contextual_parser = ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;age_cp&quot;) .setJsonPath(&quot;age.json&quot;) .setCaseSensitive(False) .setPrefixAndSuffixMatch(False) chunks_age = ChunkConverter() .setInputCols(&quot;age_cp&quot;) .setOutputCol(&quot;age_chunk&quot;) ... sample_text = &quot;&quot;&quot;The patient is a 28 years old female with a history of gestational diabetes mellitus was diagnosed in April 2002 in County Baptist Hospital .&quot;&quot;&quot; Result: [Annotation(chunk, 17, 18, 28, {&#39;tokenIndex&#39;: &#39;4&#39;, &#39;entity&#39;: &#39;Age&#39;, &#39;field&#39;: &#39;Age&#39;, &#39;ner_source&#39;: &#39;age_chunk&#39;, &#39;chunk&#39;: &#39;0&#39;, &#39;normalized&#39;: &#39;&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;confidenceValue&#39;: &#39;0.74&#39;})] Core Improvements and Bug Fixes Added chunk confidence score in the RelationExtractionModel metadata Added confidence score in the DocumentLogRegClassifierApproach metadata Fixed non-deterministic Relation Extraction DL Models (30+ models updated in the model hub) Fixed incompatible PretrainedPipelines with PySpark v3.2.x and v3.3.x Fixed ZIP label issue on faker mode with setZipCodeTag parameter in Deidentification Fixed obfuscated numbers have the same number of chars as the original ones Fixed name obfuscation hashes in Deidentification for romanian language Fixed LightPipeline validation parameter for internal annotators LightPipeline support for GenericClassifier (FeatureAssembler) New and Updated Notebooks New Clinical Text Classification with Spark_NLP Notebook show how can use medical text with ClassifierDL, MultiClassifierDL, GenericClassifier, and DocumentLogRegClassifier New Clinical Text Classification with DocumentMLClassifier Notebook show how can use medical text with DocumentMLClassifier Updated ALAB Notebook with the changes in get_assertion_data() and the new get_IAA_metrics() method. New and Updated Demos SOCIAL DETERMINANT demo 9 New Clinical Models and Pipelines Added &amp; Updated in Total ner_oncology_anatomy_general_healthcare ner_oncology_biomarker_healthcare ner_oncology_unspecific_posology_healthcare ner_eu_clinical_case genericclassifier_sdoh_economics_binary_sbiobert_cased_mli genericclassifier_sdoh_substance_usage_binary_sbiobert_cased_mli genericclassifier_sdoh_tobacco_usage_sbiobert_cased_mli genericclassifier_sdoh_alcohol_usage_sbiobert_cased_mli genericclassifier_sdoh_alcohol_usage_binary_sbiobert_cased_mli For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_8",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_8"
  },
  "1469": {
    "id": "1469",
    "title": "NLP Lab Release Notes 4.3.0",
    "content": "4.3.0 Release date: 25-11-2022 Annotation Lab 4.3.0 adds support for Finance and Legal NLP Libraries, Finance and Legal License Scopes, and access to pre-trained Visual NER models on the Models Hub. It also allows easy task import directly from S3 and keeps the complete history of training logs. The release also includes stabilization and fixes for several issues reported by our user community. Here are the highlights of this release: Highlights Support for Finance NLP and Legal NLP. Annotation Labs now includes a full-fledged integration with two new NLP libraries: Finance NLP and Legal NLP. Pretrained models for the Finance and Legal verticals are now available on the Models Hub page, covering tasks such as Entity Recognition, Assertion Status, and Text Classification. Searching models on Models Hub. A new filter named Edition was added to the Models Hub. It includes all supported NLP editions: Healthcare, Opensource, Legal, Finance, and Visual. It will ease search for models specific to an Edition, which can then easily be downloaded and used within Annotation Lab projects. Support for Finance and Legal Licenses. Annotation Lab now supports import of licenses with legal and/or finance scopes. It can be uploaded from the Licenses page. Similar to Healthcare and Visual licenses, they unlock access to optimized annotators, models, embeddings, and rules. Pre-annotations using Finance and Legal models. Finance and Legal models downloaded from the Models Hub can be used for pre-annotation in NER, assertion status, and classification projects. Train Finance and Legal models. Two new options: Legal and Finance libraries were added for selection when training a new NER model in Annotation Lab. The new options are only available when at least one valid license with the corresponding scope is added to the License page. Import tasks from S3. Annotation Lab now supports importing tasks/documents stored on Amazon S3. In the Import Page, a new section was added which allows users to define S3 connection details. All documents in the specified path will then be imported as tasks in the current project. Project level history of the Trained Models. It is now possible to keep track of all previous training activities executed for a project. When pressing the History button from the Train page, users are presented with a list of all trainings triggered for the current project. Easier page navigation. Users can now right-click on the available links and select “Open in new tab” to open the link in a new tab without losing the current work context. Optimized user editing UI. All the checkboxes on the Users Edit page now have the same style. The “UserAdmins” group was renamed to “Admins” and the description of groups is more detailed and easier to understand. Also, a new error message is shown when an invalid email address is used. Improved page navigation for Visual NER projects. For Visual NER projects, users can jump to a specific page in any multi-page task instead of passing through all pages to reach a target section of a PDF document. Visual configuration options for Visual NER project. Users are now able to add custom labels and choices in the project configuration from the Visual tab for Visual NER projects as well as for the text projects. Visual NER Models available on the Models Hub page. Visual NER models can now be filtered, downloaded from the NLP Models Hub, and used for pre-annotating image-based documents. Lower CPU and Memory resources allocated to the license server. In this version, the resources allocated to the license server were decreased to CPU: 1000m (1 core) and Memory: 1GB. Simplify Training and Pre-annotation configurations. Now the user only need to adjust “Memory limit” and “CPU limit” in the Infrastructure page. “Spark Drive Memory” is calculated as 85% of Memory Limit where are “Spark Kryo Buff Max” and “Spark Driver Max Result Size” are constants with values “2000 MB” and “4096 MB” respectively. Auto-close user settings. The user settings menu is closed automatically when a user clicks on any other settings options. Preserve task filters. From version 4.3.0, all defined filters in the task page remain preserved when the user navigates back and forth between the labeling page and the task page. Optimized Alert Messages. All the alert notification shows clear errors, warnings, information, and success messages. Zoom in/out features in Visual NER projects with Sticky Left Column view. In various views of Visual NER, zoom-controlling features are now available by default. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_3_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_3_0"
  },
  "1470": {
    "id": "1470",
    "title": "Visual NLP(Spark OCR) release notes 4.3.0",
    "content": "4.3.0 Release date: 2023-01-13 We are glad to announce that Spark OCR 4.3.0 has been released!! This big release comes with improvements in Dicom Processing, Visual Question Answering, new Table Extraction annotators, and much more!. New Features PositionFinder now works in LightPipelines. New annotator HocrToTextTable to work together with PdfToHocr that allows table extraction from digital PDFs. This allows to extract tables using a mixed pipeline in which tables are detected using visual features, but the text is pulled directly from the digital layer of the PDF yielding near to perfect results, and removing OCR overhead. New Dicom Processing improvements, Added support of Dicom documents to BinaryFile Datasource: this allows to write Dicom documents from Spark Dataframes to all data storages supported by Spark, in batch and streaming mode. Added possibility to specify name of the files in BinaryFile Datasource: now we can store images, PDFs, Dicom files directly using Spark capabilities with names of our choice, overcoming the limitation imposed by Spark of naming files according to partitions. Added DicomToMetadata Transformer: it allows to extract metadata from the Dicom documents. This allows to analyze Dicom metadata using Spark capabilities. For example, collect statistic about color schema, number of frames, compression of the images. This is useful for estimating needed resources and time before starting to process a big dataset. Added DicomToImageV3 based on Pydicom with better support of different color schemas. Added support YBR_FULL_422, YBR_FULL images. Also fixed handling pixel data with different pixel size for RGB and Monochrome images. Added support for compression after update pixel data in DicomDrawRegions. This reduces size of output Dicom files by applying JPEGBaseline8Bit compression to the pixel data. Added support for different color schemas in DicomDrawRegions. Added support YBR_FULL_422, YBR_FULL images. Added support for coordinates with rotated bounding box in DicomDrawRegions for compatibility with ImageTextDetectorV2. Fixed ImageTextDetectorV2 for images without text. New Donut based VisualQuestionAnswering annotator. Supports two modes of operation: it can receive an array of questions in the same row as the input image; in this way, each input image can be queried by an arbitrary set of user-defined questions, and also questions can be defined globally outside the Dataframe. This will cause that all images will be queried by the same set of questions. Running time is about a half the time per question when compared to the open-source version. Optimized model is smaller(about a half) of the original open-source version, making it easier to download and distribute in a cluster. Two models available: docvqa_donut_base and docvqa_donut_base_opt(quantized). LightPipelines support. Bug Fixes Empty tables now handled properly in ImageCellsToTextTable. Pretrained models for VisualDocumentNerV21 are now accessible. New/updated Notebooks SparkOcrVisualQuestionAnswering.ipynb, this notebook shows examples on how to use Donut based visual question answering in Spark-OCR. SparkOCRPdfToTable.ipynb, this notebook shows how PdfToHocr and HocrToTextTable can be put together to do table extraction without OCR, by just relying on the digital layer of text in the PDF. Still, existent well tested table detection models, continue to be used for finding the tables. SparkOcrImageTableRecognitionWHOCR.ipynb, this notebook shows table detection, and the HocrToTextTable in action. Compared to previous implementations, now the OCR method is external, and it can be replaced by different implementations(even handwritten!). This release is compatible with Spark NLP for Healthcare 4.2.4, and Spark NLP 4.2.4. Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_3_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_3_0"
  },
  "1471": {
    "id": "1471",
    "title": "Spark NLP for Healthcare Release Notes 4.3.0",
    "content": "4.3.0 Highlights 12 new clinical models and pipelines added &amp; updated (8 new clinical named entity recognition models including 4 social determinants of health models) New Chunk Mapper model for mapping RxNorm codes to drug brand names New text classification annotators (architectures) for training text classification models using SVM and Logistic Regression with sentence embeddings One-liner clinical deidentification module Certification_Training notebooks (written in johnsnowlabs library) moved to parent workshop folder Different validation split per epoch in MedicalNerApproach Core improvements and bug fixes New read_conll method for reading conll files as Conll.readDataset does but it returns pandas dataframe with document(task) ids. Updated documentation Allow using FeatureAssembler in pretrained pipelines. Fixed RelationExtractionModel running in LightPipeline Fixed get_conll_data method issue New and updated notebooks New Clinical Deidentification Utility Module Notebook. Updated Clinical_Named_Entity_Recognition_Model with Conll.readDataset examples. Updated Clinical Text Classification with Spark NLP with new GenericLogRegClassifierApproach and GenericSVMClassifierApproach examples. New and updated demos SOCIAL DETERMINANT NER demo SOCIAL DETERMINANT CLASSIFICATION demo SOCIAL DETERMINANT GENERIC CLASSIFICATION demo 13 new clinical models and pipelines added &amp; updated in total 12 New Clinical Models And Pipelines Added &amp; Updated (8 New Clinical Named Entity Recognition Models Including 4 Social Determinants of Health Models) We are releasing 4 new SDOH NER models that were trained by using embeddings_clinical embeddings model. model name description predicted entities ner_sdoh_wip Extracts terminology related to Social Determinants of Health from various kinds of biomedical documents. Other_SDoH_Keywords Education Population_Group Quality_Of_Life Housing Substance_Frequency Smoking Eating_Disorder Obesity Healthcare_Institution Financial_Status Age Chidhood_Event Exercise Communicable_Disease Hypertension Other_Disease Violence_Or_Abuse Spiritual_Beliefs Employment Social_Exclusion Access_To_Care Marital_Status Diet Social_Support Disability Mental_Health Alcohol Insurance_Status Substance_Quantity Hyperlipidemia Family_Member Legal_Issues Race_Ethnicity Gender Geographic_Entity Sexual_Orientation Transportation Sexual_Activity Language Substance_Use ner_sdoh_social_environment_wip Extracts social environment terminologies related to Social Determinants of Health from various kinds of biomedical documents. Social_Support Chidhood_Event Social_Exclusion Violence_Abuse_Legal ner_sdoh_demographics_wip Extracts demographic information related to Social Determinants of Health from various kinds of biomedical documents. Family_Member Age Gender Geographic_Entity Race_Ethnicity Language Spiritual_Beliefs ner_sdoh_income_social_status_wip Extracts income and social status information related to Social Determinants of Health from various kinds of biomedical documents. Education Marital_Status Financial_Status Population_Group Employment Example: ... clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_texts =&quot;Smith is a 55 years old, divorced Mexcian American woman with financial problems. She speaks spanish. She lives in an apartment. She has been struggling with diabetes for the past 10 years and has recently been experiencing frequent hospitalizations due to uncontrolled blood sugar levels. Smith works as a cleaning assistant and does not have access to health insurance or paid sick leave. She has a son student at college. Pt with likely long-standing depression. She is aware she needs rehab. Pt reprots having her catholic faith as a means of support as well. She has long history of etoh abuse, beginning in her teens. She reports she has been a daily drinker for 30 years, most recently drinking beer daily. She smokes a pack of cigarettes a day. She had DUI back in April and was due to be in court this week.&quot; Result: ++--++-+ |chunk |begin|end|ner_label | ++--++-+ |55 years old |11 |22 |Age | |divorced |25 |32 |Marital_Status | |Mexcian American |34 |49 |Race_Ethnicity | |financial problems|62 |79 |Financial_Status | |spanish |93 |99 |Language | |apartment |118 |126|Housing | |diabetes |158 |165|Other_Disease | |cleaning assistant|307 |324|Employment | |health insurance |354 |369|Insurance_Status | |son |401 |403|Family_Member | |student |405 |411|Education | |college |416 |422|Education | |depression |454 |463|Mental_Health | |rehab |489 |493|Access_To_Care | |catholic faith |518 |531|Spiritual_Beliefs | |support |547 |553|Social_Support | |etoh abuse |589 |598|Alcohol | |teens |618 |622|Age | |drinker |658 |664|Alcohol | |drinking beer |694 |706|Alcohol | |daily |708 |712|Substance_Frequency| |smokes |719 |724|Smoking | |a pack |726 |731|Substance_Quantity | |cigarettes |736 |745|Smoking | |a day |747 |751|Substance_Frequency| |DUI |762 |764|Legal_Issues | ++--++-+ We are releasing 8 new NER models which are trained by European Clinical Case Corpus (E3C), a project aimed at offering a freely available multilingual corpus of semantically annotated clinical narratives. ner_eu_clinical_case: This model extracts 6 different clinical entities based on medical taxonomies. ner_eu_clinical_condition: This model extracts one entity – clinical / medical conditions. model name lang predicted entities ner_eu_clinical_case es clinical_condition clinical_event bodypart units_measurements patient date_time ner_eu_clinical_case fr clinical_condition clinical_event bodypart units_measurements patient date_time ner_eu_clinical_case eu clinical_condition clinical_event bodypart units_measurements patient date_time ner_eu_clinical_condition en clinical_condition ner_eu_clinical_condition es clinical_condition ner_eu_clinical_condition eu clinical_condition ner_eu_clinical_condition fr clinical_condition ner_eu_clinical_condition it clinical_condition Example: word_embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;,&quot;es&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner = MedicalNerModel.pretrained(&quot;ner_eu_clinical_case&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;&quot;&quot;Paciente de 59 años que refiere dificultad para caminar desde hace un mes aproximadamente. Presenta debilidad y dolor en los miembros inferiores, que mejora tras detenerse, acompañándose en ocasiones de lumbalgia no irradiada. En la exploración neurológica presenta habla hipofónica, facial centrado. Debido a la mala perfusión secundaria a la sepsis aparecieron lesiones necróticas en extremidades superiores y principalmente inferiores distales. Motilidad ocular interna y externa normal.&quot;&quot;&quot; Result: +++ |chunk |ner_label | +++ |Paciente de 59 años |patient | |refiere |clinical_event | |dificultad para caminar |clinical_event | |hace un mes aproximadamente|date_time | |debilidad |clinical_event | |dolor |clinical_event | |los miembros inferiores |bodypart | |mejora |clinical_event | |detenerse |clinical_event | |lumbalgia |clinical_event | |irradiada |clinical_event | |exploración |clinical_event | |habla |clinical_event | |hipofónica |clinical_event | |perfusión |clinical_event | |sepsis |clinical_event | |lesiones |clinical_event | |extremidades superiores |bodypart | |inferiores distales |bodypart | |Motilidad |clinical_event | |normal |units_measurements| +++ New Chunk Mapper Model for Mapping RxNorm Codes to Drug Brand Names We are releasing rxnorm_drug_brandname_mapper pretrained model that maps RxNorm and RxNorm Extension codes with their corresponding drug brand names. It returns 2 types of brand names called rxnorm_brandname and rxnorm_extension_brandname for the corresponding RxNorm or RxNorm Extension code. Example: ... chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;rxnorm_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;rxnorm_brandname&quot;, &quot;rxnorm_extension_brandname&quot;]) sample_text= [&#39;metformin&#39;, &#39;advil&#39;] Result: +--+-+--+--+ | drug_name|rxnorm_result| mapping_result| relation | +--+-+--+--+ | metformin| 6809|Actoplus Met (metformin):::Avandamet (metformin...| rxnorm_brandname| | metformin| 6809|A FORMIN (metformin):::ABERIN MAX (metformin)::...|rxnorm_extension_brandname| | advil| 153010| Advil (Advil)| rxnorm_brandname| | advil| 153010| NONE|rxnorm_extension_brandname| +--+-+--+--+ New Text Classification Annotators (Architectures) For Training Text Classification Models Using SVM and Logistic Regression With Sentence Embeddings We have a new text classification architecture called GenericLogRegClassifierApproach that implements a multinomial Logistic Regression with sentence embeddings. This is a single layer neural network with the logistic function at the output. The input to the model is FeatureVector (from any sentence embeddings) and the output is Category annotations with labels and corresponding confidence scores. Training data requires “text” and their “label” columns only and the trained model will be a GenericLogRegClassifierModel(). We have another text classification architecture called GenericSVMClassifierApproach that implements SVM (Support Vector Machine) classification. The input to the model is FeatureVector (from any sentence embeddings) and the output is Category annotations with labels and corresponding confidence scores. Taining data requires “text” and their “label” columns only and the trained model will be a GenericSVMClassifierModel(). Input types: FEATURE_VECTOR Output type: CATEGORY Example: features_asm = sparknlp_jsl.base.FeaturesAssembler() .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;feature_vector&quot;) gcf_graph_builder = sparknlp_jsl.annotators.TFGraphBuilder() .setModelName(&quot;logreg_classifier&quot;) .setInputCols([&quot;feature_vector&quot;]) .setLabelColumn(&quot;label&quot;) .setGraphFolder(&quot;/tmp/&quot;) .setGraphFile(&quot;log_reg_graph.pb&quot;) log_reg_approach = sparknlp_jsl.annotators.GenericLogRegClassifierApproach() .setLabelColumn(&quot;label&quot;) .setInputCols([&quot;feature_vector&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(f&quot;/tmp/log_reg_graph.pb&quot;) .setEpochsNumber(10) .setBatchSize(1) .setLearningRate(0.001) One-Liner Clinical Deidentification Module Spark NLP for Healthcare provides functionality to apply Deidentification using one-liner module called Deid. The Deid module is a tool for deidentifying Protected Health Information (PHI) from data in a file path. It can be used with or without ant Spark NLP NER pipelines. It can apply deidentification and obfuscation on different columns at the same time. It returns the deidentification &amp; obfuscation results as a spark dataframe as well as a csv or json file saved locally. The module also includes functionality for applying Structured Deidentification task to data from a file path. The function, deidentify(), can be used with a custom pipeline or without defining any custom pipeline. structured_deidentifier() function can be used for the Structured Deidentification task. Please see this notebook for the detailed usage and explanation of all parameters. Check here for the documentation of the module. Deidentification with a custom pipeline Example: from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark ) res= deid_implementor.deidentify( # required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: A custom pipeline model to be used for deidentification. If not specified, the default is None. custom_pipeline=nlpModel, #optional: Fields to be deidentified and their deidentification modes, by default {&quot;text&quot;: &quot;mask&quot;} fields={&quot;text_column_1&quot;: &quot;text_column_1_deidentified&quot;, &quot;text_column_2&quot;: &quot;text_column_2_deidentified&quot;}, #optional: The masking policy. Default is &quot;entity_labels&quot;. masking_policy=&quot;fixed_length_chars&quot;, #optional: The fixed mask length. Default is 4. fixed_mask_length=4) Result: ++-+-+-+-+ | ID| text_column_1| text_column_1_deidentified| text_column_2| text_column_2_deidentified| ++-+-+-+-+ | 0|Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson ...|Record date : ** , ** , M.D . , Name : ** MR .|Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-...|Date : 10-16-1991 PCP : Alveda Castles , 26 years-old , Record date...| ++-+-+-+-+ Deidentification with no custom pipeline Example: from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark ) res= deid_implementor.deidentify( # required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: Fields to be deidentified and their deidentification modes, by default {&quot;text&quot;: &quot;mask&quot;} fields={&quot;text&quot;: &quot;mask&quot;}, #optional: The masking policy. Default is &quot;entity_labels&quot;. masking_policy=&quot;entity_labels&quot;) Result: ++-+-+ | ID| text_original| text_deid| ++-+-+ | 0| &quot;| &quot;| | 1|Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson ...|Record date : &lt;DATE&gt; , &lt;DOCTOR&gt; , M.D . , Name : &lt;PATIENT&gt; , MR # &lt;...| | 2| &quot;| &quot;| ++-+-+ Structured Deidentification Example: from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark ) res= deid_implementor.structured_deidentifier( #required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: A dictionary that contains the column names and the tags that should be used for deidentification. Default is {&quot;NAME&quot;:&quot;PATIENT&quot;,&quot;AGE&quot;:&quot;AGE&quot;} columns_dict= {&quot;NAME&quot;: &quot;ID&quot;, &quot;DOB&quot;: &quot;DATE&quot;}, #optional: The seed value for the random number generator. Default is {&quot;NAME&quot;: 23, &quot;AGE&quot;: 23} columns_seed= {&quot;NAME&quot;: 23, &quot;DOB&quot;: 23}, #optional: The source of the reference file. Default is faker. ref_source=&quot;faker&quot;, #optional: The number of days to be shifted. Default is None shift_days=5) Result: +-++--++-+ | NAME| DOB| ADDRESS|SBP| TEL| +-++--++-+ |[N2649912]|[18/02/1977]| 711 Nulla St.|140| 673 431234| | [W466004]|[28/02/1977]| 1 Green Avenue.|140|+23 (673) 431234| | [M403810]|[16/04/1900]|Calle del Liberta...|100| 912 345623| +-++--++-+ Different Validation Split Per Epoch In MedicalNerApproach The validation splits in MedicalNerApproach used to be static and same for every epoch. Now we can control with behaviour with a new parameter called setRandomValidationSplitPerEpoch(bool) and allow users to set random validation splits per epoch. Certification_Training Notebooks (Written In Johnsnowlabs Library) Moved to Parent Workshop Folder re-organize and re-locate open-source-nlp folder re-organize and re-locate healthcare-nlp folder Core Improvements and Bug Fixes New read_conll method for reading conll files as Conll.readDataset does but it returns dataframe with document(task) ids. Updated documentation Allow using FeatureAssembler in pretrained pipelines. Fixed RelationExtractionModel running in LightPipeline Fixed get_conll_data method issue New and Updated Notebooks New Clinical Deidentification Utility Module Notebook. Updated Clinical_Named_Entity_Recognition_Model with Conll.readDataset examples. Updated Clinical Text Classification with Spark NLP with new GenericLogRegClassifierApproach and GenericSVMClassifierApproach examples. New and Updated Demos SOCIAL DETERMINANT NER demo SOCIAL DETERMINANT CLASSIFICATION demo SOCIAL DETERMINANT GENERIC CLASSIFICATION demo 12 New Clinical Models and Pipelines Added &amp; Updated in Total ner_eu_clinical_case-&gt; es ner_eu_clinical_case-&gt; fr ner_eu_clinical_case-&gt; eu ner_eu_clinical_condition-&gt; en ner_eu_clinical_condition-&gt; es ner_eu_clinical_condition-&gt; fr ner_eu_clinical_condition-&gt; eu ner_eu_clinical_condition-&gt; it ner_sdoh_demographics_wip ner_sdoh_income_social_status_wip ner_sdoh_social_environment_wip ner_sdoh_wip rxnorm_drug_brandname_mapper For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_0"
  },
  "1472": {
    "id": "1472",
    "title": "Visual NLP(Spark OCR) release notes 4.3.1",
    "content": "4.3.1 Release date: 17-02-2023 We’re glad to announce that Visual NLP 😎 4.3.1 has been released. Highlights ImageTextCleaner &amp; ImageTableDetector have improved memory consumption. New Annotators supported in LightPipelines. Table extraction from Digital PDFs pipeline now entirely supported as a LightPipeline. ImageTextCleaner &amp; ImageTableDetector improved memory consumption ImageTextCleaner &amp; ImageTableDetector improved memory consumption: we reduced about 30% the memory consumption for this annotator making it more memory friendly and enabling running on memory constrained environments like Colab. New Annotators supported in LightPipelines Now the following annotators are supported in LightPipelines, PdfToHocr, HocrTokenizer, ImageTableDetector, ImageScaler, HocrToTextTable, Table extraction from Digital PDFs pipeline now entirely supported as a LightPipeline. Our Table Extraction from digital PDFs pipeline now supports running as a LightPipeline, check the updated notebook: SparkOCRPdfToTable.ipynb This release is compatible with Spark NLP for Healthcare 4.3.0, and Spark NLP 4.3.0. Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_3_1",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_3_1"
  },
  "1473": {
    "id": "1473",
    "title": "Spark NLP for Healthcare Release Notes 4.3.1",
    "content": "4.3.1 Highlights The first Voice of Patients (VOP) named entity recognition model New Social Determinants of Health (SDOH) named entity recognition models New entity resolution model for mapping Rxnorm codes according to the National Institute of Health (NIH) Database New Chunk Mapper models for mapping NDC codes to drug brand names as well as clinical entities (like drugs/ingredients) to Rxnorm codes Format consistency for formatted entity obfuscation in Deidentification module New parameters for controlling the validation set while training a NER model with MedicalNerApproach Whitelisting the entities while merging multiple entities in ChunkMergeApproach Core improvements and bug fixes New and updated notebooks New and updated demos 8 new clinical models and pipelines added &amp; updated in total The First Voice of Patients (VOP) Named Entity Recognition Model We are releasing a new VOP NER model that was trained on the conversations gathered from patients forums. model name description predicted entities ner_vop_slim_wip This model extracts healthcare-related terms from the documents transferred from the patient’s own sentences. AdmissionDischarge Age BodyPart ClinicalDept DateTime Disease Dosage_Strength Drug Duration Employment Form Frequency Gender Laterality Procedure PsychologicalCondition RelationshipStatus Route Symptom Test Vaccine VitalTest Example: ... clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_vop_slim_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_texts = [&quot;Hello,I&#39;m 20 year old girl. I&#39;m diagnosed with hyperthyroid 1 month ago. I was feeling weak, poor digestion, depression, left chest pain, increased heart rate from 4 months. Also i have b12 deficiency so I&#39;m taking weekly supplement of 1000 mcg b12 daily.&quot;] Result: chunk begin end ner_label 20 year old 10 20 Age girl 22 25 Gender hyperthyroid 47 58 Disease 1 month ago 60 70 DateTime weak 87 90 Symptom depression 137 146 PsychologicalCondition left 149 152 Laterality chest 154 158 BodyPart pain 160 163 Symptom heart rate 176 185 VitalTest 4 months 215 222 Duration b12 deficiency 613 626 Disease weekly 667 672 Frequency supplement 674 683 Drug 1000 mcg 702 709 Dosage_Strength b12 711 713 Drug daily 715 719 Frequency New Social Determinants of Health (SDOH) Named Entity Recognition Models We are releasing 4 new SDOH NER models with various entity combinations. model name description predicted entities ner_sdoh_substance_usage_wip This model extracts substance usage information related to Social Determinants of Health from various kinds of biomedical documents. Smoking Substance_Duration Substance_Use Substance_Quantity Substance_Frequency Alcohol ner_sdoh_access_to_healthcare_wip This model extracts access to healthcare information related to Social Determinants of Health from various kinds of biomedical documents. Insurance_Status Healthcare_Institution Access_To_Care ner_sdoh_community_condition_wip This model extracts community condition information related to Social Determinants of Health from various kinds of biomedical documents. Transportation Community_Living_Conditions Housing Food_Insecurity ner_sdoh_health_behaviours_problems_wip This model extracts health and behaviours problems related to Social Determinants of Health from various kinds of biomedical documents. Diet Mental_Health Obesity Eating_Disorder Sexual_Activity Disability Quality_Of_Life Other_Disease Exercise Communicable_Disease Hyperlipidemia Hypertension ner_sdoh_substance_usage_wip Example: ... clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_substance_usage_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_texts = [&quot;He does drink occasional alcohol approximately 5 to 6 alcoholic drinks per month.&quot;, &quot;He continues to smoke one pack of cigarettes daily, as he has for the past 28 years.&quot;] Result: chunk begin end ner_label drink 8 12 Alcohol occasional 14 23 Substance_Frequency alcohol 25 31 Alcohol 5 to 6 47 52 Substance_Quantity alcoholic drinks 54 69 Alcohol per month 71 79 Substance_Frequency smoke 16 20 Smoking one pack 22 29 Substance_Quantity cigarettes 34 43 Smoking daily 45 49 Substance_Frequency past 28 years 70 82 Substance_Duration ner_sdoh_access_to_healthcare_wip Example: ... sample_texts = [&quot;She has a pension and private health insurance, she reports feeling lonely and isolated.&quot;, &quot;He also reported food insecurityduring his childhood and lack of access to adequate healthcare.&quot;, &quot;She used to work as a unit clerk at XYZ Medical Center.&quot;] Result: chunk begin end ner_label private health insurance 22 45 Insurance_Status access to adequate healthcare 65 93 Access_To_Care XYZ Medical Center 36 53 Healthcare_Institution ner_sdoh_community_condition_wip Example: ... sample_texts = [&quot;He is currently experiencing financial stress due to job insecurity, and he lives in a small apartment in a densely populated area with limited access to green spaces and outdoor recreational activities.&quot;, &quot;Patient reports difficulty affording healthy food, and relies oncheaper, processed options.&quot;, &quot;She reports her husband and sons provide transportation top medical apptsand do her grocery shopping.&quot;] Result: chunk begin end ner_label small apartment 87 101 Housing green spaces 154 165 Community_Living_Conditions outdoor recreational activities 171 201 Community_Living_Conditions healthy food 37 48 Food_Insecurity transportation 41 54 Transportation ner_sdoh_health_behaviours_problems_wip Example: ... sample_texts = [&quot;She has not been getting regular exercise and not followed diet for approximately two years due to chronic sciatic pain.&quot;, &quot;Medical History: The patient is a 32-year-old female who presents with a history of anxiety, depression, bulimia nervosa, elevated cholesterol, and substance abuse.&quot;, &quot;Pt was intubated atthe scene &amp; currently sedated due to high BP. Also, he is currently on social security disability.&quot;] Result: chunk begin end ner_label regular exercise 25 40 Exercise diet 59 62 Diet chronic sciatic pain 99 118 Other_Disease anxiety 84 90 Mental_Health depression 93 102 Mental_Health bulimia nervosa 105 119 Eating_Disorder elevated cholesterol 122 141 Hyperlipidemia high BP 56 62 Hypertension disability 106 115 Disability New Entity Resolver Model for Mapping Rxnorm Codes According To the National Institute of Health (NIH) Database We are releasing sbiobertresolve_rxnorm_nih pretrained model to map clinical entities and concepts (like drugs/ingredients) to RxNorm codes according to the National Institute of Health (NIH) database using sbiobert_base_cased_mli Sentence Bert Embeddings. Example: ... rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_nih&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) text= &quot;She is given folic acid 1 mg daily , levothyroxine 0.1 mg and aspirin 81 mg daily .&quot; Result: | ner_chunk | entity |rxnorm_code | all_codes | resolutions | |:|:-|--:|:-|:| | folic acid 1 mg | DRUG | 12281181 | [&#39;12281181&#39;, &#39;12283696&#39;, &#39;12270292&#39;, ...| [&#39;folic acid 1 MG [folic acid 1 MG]&#39;, &#39;folic acid 1.1 MG [folic acid 1.1 MG]&#39;,...| | levothyroxine 0.1 mg | DRUG | 12275630 | [&#39;12275630&#39;, &#39;12275646&#39;, &#39;12301585&#39;, ...| [&#39;levothyroxine sodium 0.1 MG [levothyroxine sodium 0.1 MG]&#39;, &#39;levothyroxine ...| | aspirin 81 mg | DRUG | 12278696 | [&#39;12278696&#39;, &#39;12299811&#39;, &#39;12298729&#39;, ...| [&#39;aspirin 81 MG [aspirin 81 MG]&#39;, &#39;aspirin 81 MG [YSP Aspirin] [aspirin 81 MG ...| New Chunk Mapper Models For Mapping NDC Codes to Drug Brand Names As Well As Clinical Entities (like drugs/ingredients) to Rxnorm Codes We have two new chunk mapper models. ndc_drug_brandname_mapper model maps NDC codes with their corresponding drug brand names as well as RxNorm Codes according to National Institute of Health (NIH). Example: ... mapper = ChunkMapperModel.pretrained(&quot;ndc_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;drug_brand_name&quot;]) text= [&quot;0009-4992&quot;, &quot;57894-150&quot;] Result:   ndc_code drug_brand_name 0 0009-4992 ZYVOX 1 57894-150 ZYTIGA rxnorm_nih_mapper model maps entities with their corresponding RxNorm codes according to the National Institute of Health (NIH) database. It returns Rxnorm codes along with their NIH Rxnorm Term Types within a parenthesis. Example: ... chunkerMapper = ChunkMapperModel .pretrained(&quot;rxnorm_nih_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;rxnorm_code&quot;]) Result: ner_chunk mappings relation Adapin 10 MG Oral Capsule 1911002 (SY) rxnorm_code acetohexamide 12250421 (IN) rxnorm_code Parlodel 829 (BN) rxnorm_code Format Consistency For Formatted Entity Obfuscation In Deidentification Module We have added a new setSameLengthFormattedEntities parameter that obfuscates the formatted entities like PHONE, FAX, ID, IDNUM, BIOID, MEDICALRECORD, ZIP, VIN, SSN, DLN, PLATE and LICENSE with the fake ones in the same format. Default is an empty list ([]). Example: obfuscated = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;deid_ner_chunk&quot;]) .setOutputCol(&quot;obfuscated&quot;) .setMode(&quot;obfuscate&quot;) .setLanguage(&#39;en&#39;) .setObfuscateDate(True) .setObfuscateRefSource(&#39;faker&#39;) .setSameLengthFormattedEntities([&quot;PHONE&quot;,&quot;MEDICALRECORD&quot;, &quot;IDNUM&quot;]) sample_text = &quot;&quot;&quot;Record date: 2003-01-13 Name : Hendrickson, Ora, Age: 25 MR: #7194334 ID: 1231511863 Phone: (302) 786-5227&quot;&quot;&quot; Result: sentence masking obfuscation Record date: 2003-01-13 Record date: &lt;DATE&gt; Record date: 2003-03-07 Name : Hendrickson, Ora, Age: 25 Name : &lt;PATIENT&gt;, Age: &lt;AGE&gt; Name : Manya Horsfall, Age: 20 MR: #7194334 MR: &lt;MEDICALRECORD&gt; MR: #4868080 ID: 1231511863 ID: &lt;IDNUM&gt; ID: 2174658035 Phone: (302) 786-5227 Phone:&lt;PHONE&gt; Phone: (467) 302-9509 New Parameters For Controlling The Validation Set While Training a NER Model With MedicalNerApproach We added a new parameter to MedicalNerApproach for controlling the validation set while training. setRandomValidationSplitPerEpoch: If it is True, the validation set is randomly splitted for each epoch; and if it is False, the split is done only once before training (the same validation split used after each epoch). Default is False. Example: nerTagger = MedicalNerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setValidationSplit(0.2) .setRandomValidationSplitPerEpoch(True) .setRandomSeed(42) ... Whitelisting The Entities While Merging Multiple Entities In ChunkMergeApproach We have added setWhiteList parameter to ChunkMergeApproach annotator that you can whitelist detected entities while merging. Example: chunk_merge = ChunkMergeApproach() .setInputCols(&quot;deid_chunk_1&quot;, &quot;deid_chunk_2&quot;) .setOutputCol(&quot;merged_chunk&quot;) .setMergeOverlapping(True) #.setWhiteList([&quot;AGE&quot;,&quot;DATE&quot;]) sample_text = &quot;Mr. ABC is a 25 years old with a nonproductive cough that started last week. He has a history of pericarditis in May 2006 and developed cough with right-sided chest pain, and admitted to Beverley Count Hospital.&quot; Result for without WhiteList: index ner_chunk entity 0 John Smith PATIENT 1 25 AGE 2 May 2006 DATE 3 Beverley Count Hospital HOSPITAL Result for with WhiteList([&quot;AGE&quot;,&quot;DATE&quot;]): index ner_chunk entity 0 25 AGE 1 May 2006 DATE Core Improvements and Bug Fixes Fixed the bug in get_assertion_data method issue in ALAB module Updated documentation pages with corrections and additions. New and Updated Notebooks Updated Spark NLP for Healthcare Workshop in 3 hr with latest examples. New and Updated Demos SOCIAL_DETERMINANT_ALCOHOL demo SOCIAL_DETERMINANT_TOBACCO demo 8 New Clinical Models and Pipelines Added &amp; Updated in Total ner_sdoh_substance_usage_wip ner_sdoh_access_to_healthcare_wip ner_sdoh_community_condition_wip ner_sdoh_health_behaviours_problems_wip ner_vop_slim_wip sbiobertresolve_rxnorm_nih ndc_drug_brandname_mapper rxnorm_nih_mapper For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_1"
  },
  "1474": {
    "id": "1474",
    "title": "Spark NLP for Healthcare Release Notes 4.3.2",
    "content": "4.3.2 Highlights Welcoming BioGPT (Generative pre-trained transformer for biomedical text generation and mining) to Spark NLP, with a faster inference and better memory management. New MedicalQuestionAnswering annotator based on BioGPT to answer questions from PubMed abstracts Crossing 1000+ healthcare specific pretrained models &amp; pipelines in the Model hub Running obfuscation and deidentification at the same time, based on selected entities in one pass Core improvements and bug fixes New features added to NameChunkObfuscation module More flexibility for setAgeRanges in DeIdentification Added new sub-module to the ALAB module for reviewing annotations and spotting label errors easily Added ner_jsl model label definitions to the model cards More flexibility in ocr_nlp_processor with new parameters for the OCR pipeline Updated 120+ clinical pipelines to make them compatible with all PySpark versions New and updated notebooks New and updated demos Medical Question Answering demo Social Determinants of Health Behaviour Problems demo Social Determinants of Health Access Status demo Voice of The Patients demo New blogposts 30+ new clinical models and pipelines added &amp; updated in total Welcoming BioGPT (Generative Pre-Trained Transformer For Biomedical Text Generation and Mining) to Spark NLP BioGPT is a domain-specific generative pre-trained Transformer language model for biomedical text generation and mining. BioGPT follows the Transformer language model backbone, and is pre-trained on 15M PubMed abstracts from scratch. Experiments demonstrate that BioGPT achieves better performance compared with baseline methods and other well-performing methods across all the tasks. Read more at the official paper. We ported BioGPT (BioGPT-QA-PubMedQA-BioGPT) into Spark NLP for Healthcare with better inference speed and memory optimization. New MedicalQuestionAnswering Annotator Based On BioGPT To Answer Questions From PubMed Abstracts New medical_qa_biogpt model is based on the original BioGPT-QA-PubMedQA-BioGPT model (trained with Pubmed abstracts) can generate two types of answers, short and long. The first type of question is &quot;short&quot; and is designed to elicit a simple, concise answer that is typically one of three options: yes, no, or maybe. The second type of question is &quot;long&quot; and intended to prompt a more detailed response. Unlike the short questions, which are generally answerable with a single word, long questions require a more thoughtful and comprehensive response. Overall, the distinction between short and long questions is based on the complexity of the answers they are meant to elicit. Short questions are used when a quick and simple answer is sufficient, while long questions are used when a more detailed and nuanced response is required. med_qa = MedicalQuestionAnswering.pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; pipeline = Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; Result for long answer: Question [&quot;What is the effect of directing attention on memory?&quot;] Answer [&quot;the results of the present study suggest that the visual indexing theory does not fully explain the effects of spatial attention on memory performance.&quot;] Result for short answer: Question [&quot;Does directing attention improve memory for items?&quot;] Answer [&quot;no&quot;] You can check the Medical Question Answering Notebook for more examples and see the Medical Question Answering demo. Crossing 1000+ Healthcare Specific Pretrained Models &amp; Pipelines In Models Hub We just crossed 1000+ healthcare specific pretrained models &amp; pipelines in the Models Hub Page! Running Obfuscation and Deidentification At The Same Time, Based On Selected Entities In One Pass The DeIdentification() annotator has been enhanced with the inclusion of multi-mode functionality. Users are required to define a dictionary that contains the policies which will be applied to the labels and save it as a JSON file. Then multi-mode functionality can be utilized in the de-identification process by providing the path of the JSON file to the setSelectiveObfuscationModes() parameter. If the entities are not provided in the JSON file, they will be deidentified according to the setMode() as default. Example JSON file : sample_deid = { &quot;obfuscate&quot;: [&quot;PHONE&quot;], &quot;mask_entity_labels&quot;: [&quot;ID&quot;], &quot;skip&quot;: [&quot;DATE&quot;], &quot;mask_same_length_chars&quot;: [&quot;NAME&quot;], &quot;mask_fixed_length_chars&quot;: [&quot;ZIP&quot;, &quot;LOCATION&quot;] } Description of possible modes to enable multi-mode deidentification: obfuscate: Replace the values with random values. mask_same_length_chars: Replace the name with the minus two same lengths asterisk, plus one bracket on both ends. mask_entity_labels: Replace the values with the entity labels. mask_fixed_length_chars: Replace the name with the asterisk with fixed length. You can also invoke setFixedMaskLength(). skip: Skip the entities (intact). Example: ... deid = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setSelectiveObfuscationModesPath(&quot;sample_deid.json&quot;) .setSameLengthFormattedEntities([&quot;PHONE&quot;]) text = &quot;Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson Ora , M.R # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555 .&quot; Result: [Record date : 2093-01-13 , [********] , M.D . , Name : [*************] , M.R # &lt;ID&gt;, Date : 01/13/93 . PCP : [******] , &lt;AGE&gt; years-old , Record date : 2079-11-09 . ******* , ******* , Phone 98-496-9970 ] DATE entities were skipped: 2093-01-13 =&gt; 2093-01-13, 01/13/93=&gt; 01/13/93 PHONE entity was obfuscated with fake phone number: 55-555-5555 =&gt; 98-496-9970 ID entity was masked with ID tag: 7194334 =&gt; &lt;ID&gt; NAME entities were masked with same original lenght: David Hale = &gt; [********], Hendrickson Ora =&gt; [*************] LOCATION entities were masked with fixed lenght: Cocke County Baptist Hospital =&gt; ******* , 0295 Keats Street =&gt; ******* Core Improvements and Bug Fixes New features added to NameChunkObfuscation module More flexibility for setAgeRanges in DeIdentification Adding new sub-module to the ALAB module to review annotation and spot label errors easily Added ner_jsl model label definitions to the model card More flexibility in ocr_nlp_processor with new parameters for the OCR pipeline, please see Spark OCR Utility Module Updated 120+ clinical pipelines to make them compatible with all PySpark versions New and Updated Notebooks New Medical Question Answering Notebook for showing how medical question answering can be used with new MedicalQuestionAnswering annotator. Updated Clinical DeIdentification Notebook with latest updates. New and Updated Demos Medical Question Answering demo Social Determinants of Health Behaviour Problems demo Social Determinants of Health Access Status demo Voice of The Patients demo New Blogposts Extract Social Determinants of Health Entities From Clinical Text with Spark NLP Extract Clinical Entities From Patient Forums with Healthcare NLP Mapping Rxnorm and NDC Codes to the National Institute of Health (NIH) Drug Brand Names with Spark NLP Format Consistency For Entity Obfuscation In De-Identification with Spark NLP 30+ New Clinical Models and Pipelines Added &amp; Updated in Total biogpt_pubmed_qa 30+ new clinical ner pipelines For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_2"
  },
  "1475": {
    "id": "1475",
    "title": "Spark OCR release notes",
    "content": "4.3.3 Release date: 14-03-2023 We’re glad to announce that Visual NLP 😎 4.3.3 has been released. Highlights New parameter keepOriginalEncoding in PdfToHocr. New Yolo-based table and form detector. Memory consumption in VisualQuestionAnswering and ImageTableDetector models has been improved. Fixes in AlabReader Fixes in HocrToTextTable. New parameter keepOriginalEncoding in PdfToHocr Now you can choose to make PdfToHocr return an ASCII normalized version of the characters present in the PDF(keepOriginalEncoding=False) or to return the original Unicode character(keepOriginalEncoding=True). Source PDF, Keeping the encoding, Not keeping it, New Yolo-based Table and Form detector This new model allows to distinguish between forms and tables, so you can apply different downstream processing afterwards. Check a full example of utilization in this notebook. Memory consumption in VisualQuestionAnswering and ImageTableDetector models has been improved Memory utilization has been improved to make it more GC friendly. The practical result is that big jobs are more stable, and less likely to get restarted because of exhausting resources. Fixes in AlabReader AlabReader has been improved to fix some bugs, and to improve the performance. Fixes in HocrToTextTable HocrToTextTable has been improved in order to better handle some corner cases in which the last rows of tables were being missed. This release of Visual NLP is compatible with version 4.3.1 of Spark-NLP and version 4.3.1 of Spark NLP for Healthcare. Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_3_3",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_3_3"
  },
  "1476": {
    "id": "1476",
    "title": "NLP Lab Release Notes 4.4.0",
    "content": "4.4.0 Release date: 05-12-2022 Annotation Lab 4.4.0 brings performance matrix and benchmarking information for NER and classification models - both imported from NLP Models Hub and/or trained locally. Furthermore, with this release, tasks can be explicitly assigned to Project Owners for annotators and/or reviewers. The release also includes several improvements and fixes for issues reported by our users. Here are the highlights of this release: Highlights Benchmarking information for Classification models. Benchmarking information is now available for Classification models. It includes the confusion matrix in the training logs and is also available on the models on the Models page, which is accessible by clicking on the benchmarking icon. Task Assignment for Project Owners. Project Owners can now be explicitly assigned as annotators and/or reviewers for tasks. It is useful when working in a small team and when the Project Owners are also involved in the annotation process. A new option “Only Assigned” checkbox is now available on the labeling page that allows Project Owners to filter the tasks explicitly assigned to them when clicking the Next button. New Role available on the Team Page. On the Team Setup page, the project creator is now clearly identified by the “Owner” role. Rules Available in the Finance and Legal Editions. Rules can now be deployed and used for pre-annotation using the Legal and Finance licenses. UX Improvement for Completion. The action icons are now available on the completions, and users can directly execute the appropriate action without having to select the completion first. IAA chart improvements. NER labels and Assertion Status labels are now handled separately in the IAA charts on the Analytics page. The filter for selecting the label type is added on the respective charts. Import tasks with title field. Users can now import the tasks with title information pre-defined in the JSON/CSV. The title field was also added to the sample task file that can be downloaded from the Import page. Rename Models Hub page. The name Models HUB on the left navigation panel has been changed to Hub. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_4_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_4_0"
  },
  "1477": {
    "id": "1477",
    "title": "Spark OCR release notes",
    "content": "4.4.0 Release date: 15-04-2023 We’re glad to announce that Visual NLP 😎 4.4.0 has been released. Highlights Pretrained Pipelines for Visual NLP Deprecations &amp; Changes Improvements New notebooks Pretrained Pipelines for Visual NLP We are adding support for pretrained pipelines that will allow to package an entire set of models and transformations into single unit. For starters, this is the list of pretrained pipelines we are releasing today, mixed_scanned_digital_pdf: OCR pipeline to support a mix of digital and scanned documents as inputs. mixed_scanned_digital_pdf_image_cleaner: OCR pipeline to support a mix of digital and scanned documents as inputs. The ImageTextCleaner transformer will be applied to those PDFs containing scanned images. mixed_scanned_digital_pdf_skew_correction: OCR pipeline to support a mix of digital and scanned documents as inputs. The ImageSkewCorrector transformer will be applied to those PDFs containing scanned images. image_handwritten_transformer_extraction: OCR on handwritten texts contained in images. image_printed_transformer_extraction: OCR printed texts contained on images. pdf_printed_transformer_extraction: OCR printed texts contained in PDFs. pdf_handwritten_transformer_extraction: OCR handwritten texts contained in PDFs. Deprecations &amp; Changes Some ImageToTextV2 models have been deprecated in favor of new optimized versions that work entirely on the JVM, and also now work in LightPipelines. ocr_base_handwritten -&gt; ocr_base_handwritten_v2 ocr_base_printed -&gt; ocr_base_printed_v2 Also, the optimized versions are available through, ocr_base_printed_v2_opt ocr_base_handwritten_v2_opt Note: If you don’t upgrade, you can continue to use the same model names. VisualDocumentNer: one class to rule(and load) all Visual NER models! You should replace VisualDocumentNerV2 instances with this class name, and just provide the right pretrained model name, e.g., VisualDocumentNer.pretrained(“visual_document_NER_SROIE0526”) or VisualDocumentNer.pretrained(“lilt_roberta_funsd_v1”) Also, LayoutLMv2 models have been deprecated in favor of Lilt based versions, e.g., layoutlmv2_funsd -&gt; lilt_roberta_funsd_v1 Accordingly, these changes have been reflected in sample notebook, which has been renamed, SparkOCRVisualDocumentNERv2.ipynb -&gt; SparkOCRVisualDocumentNer-FormParsing.ipynb Finally, VisualDocumentNer fine tuning notebooks are currently deprecated until new ones are included on next release. Improvements We improved digital PDF data ingestion for documents containing ligature glyphs which are used in some fonts. Ligature glyphs are symbols that may represent two or more characters. For instance, ‘f’ and ‘i’ may be represented as one char ‘fi’. We improved our transformer to process them correctly. New Notebooks SparkOcrPretrainedPipelines.ipynb: use this notebook to learn how to use the new pretrained pipelines feature added to Visual NLP 4.4.0. This release is compatible with Spark NLP 4.4.0 and Spark NLP for Healthcare 4.4.0. Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_4_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_4_0"
  },
  "1478": {
    "id": "1478",
    "title": "Spark NLP for Healthcare Release Notes 4.4.0",
    "content": "4.4.0 Highlights Introducing biogpt_chat_jsl, the first ever closed-book medical question answering LLM based on BioGPT, that is finetuned on medical conversations, and scale over Spark clusters. New MedicalSummarizer annotator and 5 new medical summarizer models for accurate and specialized results in medical text analysis, performning 30-35% (Blue) better than non-clinical summarizer models, with half of the parameters. New MedicalTextGenerator annotator and 4 new medical text generator models for effortless creation of tailored medical documents New Voice of Patients (VOP) NER model for detection of clinical terms in patient’s own sentences New Social Determinants of Health (SDOH) classification models 2 brand new Clinical Embeddings Models, delivering unparalleled accuracy and insights for your medical data analysis New annotator for windowed sentence splitting for enhanced context analysis Gender-based name obfuscation in Deidentification for more accurate anonymization Deidentification now supports unnormalized date shifting and format consistency Setting entity pairs for each relation labels feature in RelationExtractionModel to reduce false positives Core improvements and bug fixes Format consistency for formatted entity obfuscation is set as default now New and updated notebooks New and updated demos 30 new clinical models and pipelines added &amp; updated in total Introducing biogpt_chat_jsl, The First Ever Closed-Book Medical Question Answering LLM Based On BioGPT We developed a new LLM called biogpt_chat_jsl, the first ever closed-book medical question answering LLM based on BioGPT, that is finetuned on medical conversations happening in a clinical settings and can answer clinical questions related to symptoms, drugs, tests, and diseases. Due to the generative nature of the conversations returned by the model, we wrap this model around our brand new MedicalTextGenerator annotator that can scale over Spark clusters and fully compatible with the rest of the NLP models within the same pipeline as a downstream task (i.e. the generated text can be fed to NER or any other model in Spark NLP within the same pipeline). Example: gpt_jsl_qa = MedicalTextGenerator.pretrained(&quot;biogpt_chat_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document_prompt&quot;) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(256) .setDoSample(True) .setTopK(3) .setRandomSeed(42) sample_text = &quot;How to treat asthma ?&quot; Result: [&#39;Asthma is itself an allergic disease due to cold or dust or pollen or grass etc. irrespective of the triggering factor. You can go for pulmonary function tests if not done. Treatment is mainly symptomatic which might require inhalation steroids, beta agonists, anticholinergics as MDI or rota haler as a regular treatment. To decrease the inflammation of bronchi and bronchioles, you might be given oral antihistamines with mast cell stabilizers (montelukast) and steroids (prednisolone) with nebulization and frequently steam inhalation. To decrease the bronchoconstriction caused by allergens, you might be given oral antihistamines with mast cell stabilizers (montelukast) and steroids (prednisolone) with nebulization and frequently steam inhalation. The best way to cure any allergy is a complete avoidance of allergen or triggering factor. Consult your pulmonologist for further advise.&#39;] New MedicalSummarizer Annotator And 5 New Medical Summarizer Models For Accurate And Specialized Results In Medical Text Analysis We have a new MedicalSummarizer annotator that uses a generative deep learning model to create summaries of medical texts given clinical contexts. This annotator helps to quickly summarize complex medical information. Also we are releasing 5 new medical summarizer models. name description summarizer_clinical_jsl This model is a modified version of Flan-T5 (LLM) based summarization model that is finetuned with clinical notes, encounters, critical care notes, discharge notes, reports, curated by John Snow Labs. This model is further optimized by augmenting the training methodology, and dataset. It can generate summaries from clinical notes up to 512 tokens given the input text (max 1024 tokens). summarizer_clinical_jsl_augmented This model is a modified version of Flan-T5 (LLM) based summarization model that is at first finetuned with natural instructions and then finetuned with clinical notes, encounters, critical care notes, discharge notes, reports, curated by John Snow Labs. This model is further optimized by augmenting the training methodology, and dataset. It can generate summaries from clinical notes up to 512 tokens given the input text (max 1024 tokens). summarizer_clinical_questions This model is a modified version of Flan-T5 (LLM) based summarization model that is finetuned with medical questions exchanged in clinical mediums (clinic, email, call center etc.) by John Snow Labs. It can generate summaries up to 512 tokens given an input text (max 1024 tokens). summarizer_biomedical_pubmed This model is a modified version of Flan-T5 (LLM) based summarization model that is finetuned with biomedical datasets (Pubmed abstracts) by John Snow Labs. It can generate summaries up to 512 tokens given an input text (max 1024 tokens). summarizer_generic_jsl This model is a modified version of Flan-T5 (LLM) based summarization model that is finetuned with additional data curated by John Snow Labs. This model is further optimized by augmenting the training methodology, and dataset. It can generate summaries from clinical notes up to 512 tokens given the input text (max 1024 tokens) Our clinical summarizer models with only 250M parameters perform 30-35% better than non-clinical SOTA text summarizers with 500M parameters, in terms of Bleu and Rouge benchmarks. That is, we achieve 30% better with half of the parameters that other LLMs have. See the details below. 🔎 Benchmark on MtSamples Summarization Dataset model_name model_size Rouge Bleu bertscore_precision bertscore_recall: bertscore_f1 philschmid/flan-t5-base-samsum 250M 0.1919 0.1124 0.8409 0.8964 0.8678 linydub/bart-large-samsum 500M 0.1586 0.0732 0.8747 0.8184 0.8456 philschmid/bart-large-cnn-samsum 500M 0.2170 0.1299 0.8846 0.8436 0.8636 transformersbook/pegasus-samsum 500M 0.1924 0.0965 0.8920 0.8149 0.8517 summarizer_clinical_jsl 250M 0.4836 0.4188 0.9041 0.9374 0.9204 summarizer_clinical_jsl_augmented 250M 0.5119 0.4545 0.9282 0.9526 0.9402 🔎 Benchmark on MIMIC Summarization Dataset model_name model_size Rouge Bleu bertscore_precision bertscore_recall: bertscore_f1 philschmid/flan-t5-base-samsum 250M 0.1910 0.1037 0.8708 0.9056 0.8879 linydub/bart-large-samsum 500M 0.1252 0.0382 0.8933 0.8440 0.8679 philschmid/bart-large-cnn-samsum 500M 0.1795 0.0889 0.9172 0.8978 0.9074 transformersbook/pegasus-samsum 570M 0.1425 0.0582 0.9171 0.8682 0.8920 summarizer_clinical_jsl 250M 0.395 0.2962 0.895 0.9316 0.913 summarizer_clinical_jsl_augmented 250M 0.3964 0.307 0.9109 0.9452 0.9227 Example: summarizer = MedicalSummarizer.pretrained(&quot;summarizer_clinical_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&#39;document&#39;]) .setOutputCol(&#39;summary&#39;) .setMaxTextLength(512) .setMaxNewTokens(512) sample_text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. &quot;&quot;&quot; Result: [&quot;A 78-year-old female with hypertension, syncope, and spinal stenosis returns for recheck. She denies chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. She is on multiple medications and has Elocon cream and Synalar cream for rash.&quot;] Example: summarizer = MedicalSummarizer.pretrained(&quot;summarizer_clinical_questions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;summary&quot;) .setMaxTextLength(512) .setMaxNewTokens(512) sample_text = &quot;&quot;&quot;Hello,I&#39;m 20 year old girl. I&#39;m diagnosed with hyperthyroid 1 month ago. I was feeling weak, light headed,poor digestion, panic attacks, depression, left chest pain, increased heart rate, rapidly weight loss, from 4 months. Because of this, I stayed in the hospital and just discharged from hospital. I had many other blood tests, brain mri, ultrasound scan, endoscopy because of some dumb doctors bcs they were not able to diagnose actual problem. Finally I got an appointment with a homeopathy doctor finally he find that i was suffering from hyperthyroid and my TSH was 0.15 T3 and T4 is normal . Also i have b12 deficiency and vitamin D deficiency so I&#39;m taking weekly supplement of vitamin D and 1000 mcg b12 daily. I&#39;m taking homeopathy medicine for 40 days and took 2nd test after 30 days. My TSH is 0.5 now. I feel a little bit relief from weakness and depression but I&#39;m facing with 2 new problem from last week that is breathtaking problem and very rapid heartrate. I just want to know if i should start allopathy medicine or homeopathy is okay? Bcs i heard that thyroid take time to start recover. So please let me know if both of medicines take same time. Because some of my friends advising me to start allopathy and never take a chance as i can develop some serious problems.Sorry for my poor english😐Thank you.&quot;&quot;&quot; Result: [&#39;What are the treatments for hyperthyroidism?&#39;] You can check the Medical Summarization Notebook for more examples and see the Medical Summarization demo. New MedicalTextGenerator Annotator And 4 New Medical Text Generator Models For Effortless Creation Of Tailored Medical Documents We are releasing 4 new medical text generator models with a new MedicalTextGenerator annotator that uses the basic BioGPT model to perform various tasks related to medical text abstraction. With this annotator, a user can provide a prompt and context and instruct the system to perform a specific task, such as explaining why a patient may have a particular disease or paraphrasing the context more directly. In addition, this annotator can create a clinical note for a cancer patient using the given keywords or write medical texts based on introductory sentences. The BioGPT model is trained on large volumes of medical data allowing it to identify and extract the most relevant information from the text provided. name description text_generator_biomedical_biogpt_base This model is a BioGPT (LLM) based text generation model that is finetuned with biomedical datasets (Pubmed abstracts) by John Snow Labs. Given a few tokens as an intro, it can generate human-like, conceptually meaningful texts up to 1024 tokens given an input text (max 1024 tokens). text_generator_generic_flan_base This model is a modified version of Flan-T5 (LLM) based text generation model, which is basically the same as official Flan-T5-base model released by Google. Given a few tokens as an intro, it can generate human-like, conceptually meaningful texts up to 512 tokens given an input text (max 1024 tokens). text_generator_generic_jsl_base This model is a modified version of Flan-T5 (LLM) based text generation model that is finetuned with natural instruction datasets by John Snow Labs. Given a few tokens as an intro, it can generate human-like, conceptually meaningful texts up to 512 tokens given an input text (max 1024 tokens). text_generator_generic_flan_t5_large This model is based on google’s Flan-T5 Large, and can generate conditional text. Sequence length is 512 tokens. Example: med_text_generator = MedicalTextGenerator.pretrained(&quot;text_generator_generic_jsl_base&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document_prompt&quot;) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(256) .setDoSample(True) .setTopK(3) .setRandomSeed(42) sample_text = &quot;the patient is admitted to the clinic with a severe back pain and &quot; Result: [&#39;the patient is admitted to the clinic with a severe back pain and a severe left - sided leg pain. The patient was diagnosed with a lumbar disc herniation and underwent a discectomy. The patient was discharged on the third postoperative day. The patient was followed up for a period of 6 months and was found to be asymptomatic. A rare case of a giant cell tumor of the sacrum. Giant cell tumors ( GCTs ) are benign, locally aggressive tumors that are most commonly found in the long bones of the extremities. They are rarely found in the spine. We report a case of a GCT of the sacrum in a young female patient. The patient presented with a history of progressive lower back pain and a palpable mass in the left buttock. The patient underwent a left hemilaminectomy and biopsy. The histopathological examination revealed a GCT. The patient was treated with a combination of surgery and radiation therapy. The patient was followed up for 2 years and no recurrence was observed. A rare case of a giant cell tumor of the sacrum. Giant cell tumors ( GCTs ) are benign, locally aggressive tumors that are most commonly found in the long bones of the extremities.&#39;] You can check the Medical Text Generation Notebook for more examples and see the Medical Text Generation demo. New Voice of Patients (VOP) NER Model For Detection of Clinical Terms In Patient’s Own Sentences Announcing a new ner_vop_wip model that can detect SubstanceQuantity, Measurements, Treatment, Modifier, RaceEthnicity, Allergen, TestResult, InjuryOrPoisoning, Frequency, MedicalDevice, Procedure, Duration, DateTime, HealthStatus, Route, Vaccine, Disease, Symptom, RelationshipStatus, Dosage, Substance, VitalTest, AdmissionDischarge, Test, Laterality, ClinicalDept, PsychologicalCondition, Age, BodyPart, Drug, Employment, Form entities in patient’s own sentences. For more details, please check the model card. Example: ... ner = MedicalNerModel.pretrained(&quot;ner_vop_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;Hello,I&#39;m 20 year old girl. I&#39;m diagnosed with hyperthyroid 1 month ago. I was feeling weak, light headed, depression, left chest pain, increased heart rate, rapidly weight loss, from 4 months.&quot; Results: chunk ner_label 20 year old Age girl Gender hyperthyroid Disease 1 month ago DateTime weak Symptom light headed Symptom depression PsychologicalCondition left Laterality chest BodyPart pain Symptom increased TestResult heart rate VitalTest rapidly Modifier weight loss Symptom 4 months Duration New Social Determinants of Health (SDOH) Classification Models Announcing new classification models that can be used for SDOH tasks. name description labels genericclassifier_sdoh_housing_insecurity_sbiobert_cased_mli This Generic Classifier model is intended for detecting whether the patient has housing insecurity. If the clinical note includes patient housing problems, the model identifies it. If there is no housing issue or it is not mentioned in the text, it is regarded as “no housing insecurity”. The model is trained by using GenericClassifierApproach annotator. Housing_Insecurity: The patient has housing problems.No_Housing_Insecurity: The patient has no housing problems or it is not mentioned in the clinical notes. genericclassifier_sdoh_mental_health_clinical This Generic Classifier model is intended for detecting if the patient has mental health problems in clinical notes. This model is trained by using GenericClassifierApproach annotator. Mental_Disorder: The patient has mental health problems. No_Or_Not_Mentioned: The patient doesn’t have mental health problems or it is not mentioned in the clinical notes. genericclassifier_sdoh_under_treatment_sbiobert_cased_mli This Generic Classifier model is intended for detecting if the patient is under treatment or not. If under treatment is not mentioned in the text, it is regarded as “not under treatment”. The model is trained by using GenericClassifierApproach annotator. Under_Treatment: The patient is under treatment. Not_Under_Treatment_Or_Not_Mentioned: The patient is not under treatment or it is not mentioned in the clinical notes. Example: generic_classifier = GenericClassifierModel.pretrained(&quot;genericclassifier_sdoh_mental_health_clinical&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;class&quot;) sample_text = [&quot;James is a 28-year-old man who has been struggling with schizophrenia for the past five years. He was diagnosed with the condition after experiencing a psychotic episode in his early 20s.&quot;, &quot;Patient John is a 60-year-old man who presents to a primary care clinic for a routine check-up. He reports feeling generally healthy, with no significant medical concerns.&quot;] Results: text result James is a 28-year-old man who has been struggling with schizophrenia for the past five years. He… [Mental_Disorder] Patient John is a 60-year-old man who presents to a primary care clinic for a routine check-up. H… [No_Or_Not_Mentioned] 2 Brand New Clinical Embeddings Models, Delivering Unparalleled Accuracy And Insights For Your Medical Data Analysis We are releasing two new clinical embeddings models, which were trained using the word2vec algorithm on clinical and biomedical datasets. The models are expected to be more effective in generalizing recent content, and the dataset curation cut-off date was March 2023. The models come in two sizes: the large model is around 2 GB, while the medium model is around 1 GB, and both have 200 dimensions. Benchmark tests indicate that the new embeddings models can replace the previous clinical embeddings while training other models (e.g. NER, assertion, RE etc.). name description embeddings_clinical_medium This model is trained on a list of clinical and biomedical datasets curated in-house. The size of the model is around 1 GB and has 200 dimensions. embeddings_clinical_large This model is trained on a list of clinical and biomedical datasets curated in-house. The size of the model is around 2 GB and has 200 dimensions. Example: embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical_medium&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) We are releasing 12 new NER models, trained with the new embeddings. Windowed Sentence Splitting For Enhanced Context Analysis We have a new WindowedSentenceModel annotator that helps you to merge the previous and following sentences of a given piece of text, so that you add the context surrounding them. This is super useful for especially context-rich analyses that require a deeper understanding of the language being used. Inferring the class from sentence X may be a much harder task sometime, due to the lack of context, than to infer the class of sentence X-1 + sentence X + sentence X+1. In this example, the window is 1, that’s why we augment sentence with 1 neighbour from behind and another from ahead. Window size can be configured so that each piece of text/sentence get a number of previous and posterior sentences as context, equal to the windows size. Example: windowedSentence1 = WindowedSentenceModel() .setWindowSize(1) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;window_1&quot;) sample_text = &quot;&quot;&quot;The patient was admitted on Monday. She has a right-sided pleural effusion for thoracentesis. Her Coumadin was placed on hold.A repeat echocardiogram was checked. She was started on prophylaxis for DVT. Her CT scan from March 2006 prior to her pericardectomy. It already shows bilateral plural effusions.&quot;&quot;&quot; Results : result     The patient was admitted on Monday. She has a right-sided pleural effusion for thoracentesis.   The patient was admitted on Monday. She has a right-sided pleural effusion for thoracentesis. Her Coumadin was placed on hold.   She has a right-sided pleural effusion for thoracentesis. Her Coumadin was placed on hold. A repeat echocardiogram was checked.   Her Coumadin was placed on hold. A repeat echocardiogram was checked. She was started on prophylaxis for DVT.   A repeat echocardiogram was checked. She was started on prophylaxis for DVT. Her CT scan from March 2006 prior to her pericardectomy.   She was started on prophylaxis for DVT. Her CT scan from March 2006 prior to her pericardectomy. It already shows bilateral plural effusions.   Her CT scan from March 2006 prior to her pericardectomy. It already shows bilateral plural effusions. Gender-Based Name Obfuscation in Deidentification For More Accurate Anonymization We have enhanced the Deidentification capabilities by introducing gender-based name obfuscation, which enables more accurate anonymization of personal information. This feature checks the gender categories of names and replaces them with fake names from the same gender category. For example, if a name belongs to a male person, it will be replaced with a fake name of a male person. Similarly, female names will be replaced with fake female names, while unisex names will be replaced with fake unisex names. This ensures that the anonymized data remains consistent and maintains its accuracy, without compromising on privacy. Example: obfuscation = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) Results: sentence obfuscated William Walker is a 62 y.o. patient admitted Jamire Allen is a 64 y.o. patient admitted Jack Davies was seen by attending his Doctor. Decarlos Ran was seen by attending his Doctor. Cecilia Reyes was scheduled for assessment. Ressie Moellers was scheduled for assessment. Jessica Smith was discharged on 10/02/2022 Leocadia Quin was discharged on 04/04/2022 Evelyn White was seen by physician Tritia Santiago was seen by physician Riley John was started on prophylaxis Nayel Dodrill was started on prophylaxis Deidentification Now Maintains Unnormalized Date Shifting And Format Consistency The DATE entity obfuscation now maintains the same format as the original date, ensuring that the anonymized data remains consistent and easy to work with. This improvement in format consistency is designed to enhance the clarity and usability of Deidentification annotator, making it easier to extract meaningful insights from text data while still protecting individual privacy. Example: obfuscation = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setDays(10) Results: dates obfuscated 08/02/2018 18/02/2018 8/2/2018 18/2/2018 08/02/18 18/02/18 8/2/18 18/2/18 11/2018 12/2018 01/05 11/05 12 Mar 2021 22 Mar 2021 Mar 2021 Apr 2021 Jan 30, 2018 Feb 9, 2018 Jan 3, 2018 Jan 13, 2018 Jan 05 Jan 15 Jan 5 Jan 15 2022 2023 Setting Entity Pairs For Each Relation Labels Feature In RelationExtractionModel to reduce false positives RelationExtractionModel now includes the ability to set entity pairs for each relation label, giving you more control over your results and even greater accuracy. In the following example, we utilize entity pair restrictions to limit the results of Relation Extraction labels solely to relations that exist between specified entities, thus improving the accuracy and relevance of the extracted data. If we don’t set setRelationTypePerPair parameter here, RE model may return different RE labels for these specified entities. Example: re_model = RelationExtractionModel.pretrained(&quot;re_test_result_date&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationPairsCaseSensitive(False) .setRelationTypePerPair({ &quot;is_result_of&quot;: [&quot;Test_Result-Test&quot;], &quot;is_date_of&quot;: [&quot;Date-Test&quot;], &quot;is_finding_of&quot;: [&quot;Test-EKG_Findings&quot;, &quot;Test-ImagingFindings&quot;] }) .setPredictionThreshold(0) Core Improvements and Bug Fixes We set format consistency for formatted entity obfuscation of PHONE, FAX, ID, IDNUM, BIOID, MEDICALRECORD, ZIP, VIN, SSN, DLN, LICENSE and PLATE entities as default to make it easy-to-use. New and Updated Notebooks New Medical Summarization Notebook for summarization of clinical context can be used with new MedicalSummarizer annotator. New Medical Text Generation Notebook for test generation of clinical context can be used with new MedicalTextGenerator annotator. New and Updated Demos Medical Summarization demo Medical Text Generation demo 30 New Clinical Models and Pipelines Added &amp; Updated in Total ner_vop_wip biogpt_chat_jsl summarizer_generic_jsl summarizer_clinical_jsl summarizer_biomedical_pubmed summarizer_clinical_questions summarizer_clinical_jsl_augmented text_generator_biomedical_biogpt_base text_generator_generic_flan_base text_generator_generic_flan_t5_large text_generator_generic_jsl_base genericclassifier_sdoh_housing_insecurity_sbiobert_cased_mli genericclassifier_sdoh_mental_health_clinical genericclassifier_sdoh_under_treatment_sbiobert_cased_mli embeddings_clinical_medium embeddings_clinical_large ner_jsl_limited_80p_for_benchmarks ner_oncology_limited_80p_for_benchmarks ner_jsl_emb_clinical_large ner_jsl_emb_clinical_medium ner_oncology_emb_clinical_medium ner_oncology_emb_clinical_large ner_vop_emb_clinical_medium_wip ner_vop_emb_clinical_large_wip ner_sdoh_emb_clinical_large_wip ner_sdoh_emb_clinical_medium_wip ner_posology_emb_clinical_large ner_posology_emb_clinical_medium ner_deid_large_emb_clinical_large ner_deid_large_emb_clinical_medium For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_0"
  },
  "1479": {
    "id": "1479",
    "title": "NLP Lab Release Notes 4.4.1",
    "content": "4.4.1 Release date: 07-12-2022 Annotation Lab 4.4.1 hotfix has beed released and it includes few features, enhancements, and bug fixes. Here are the highlights of this release: Highlights Users can now delete the relations using the backspace key (on windows) or delete key (on mac) or using the delete action icon on Relations widget. Unsupported Legal and Finance models are now hidden on the Models Hub Issue when deploying pre-annotation server for some assertion models have been fixed. The “Only Assigned” checkbox state is preserved when user moves to the next task. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_4_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_4_1"
  },
  "1480": {
    "id": "1480",
    "title": "Spark OCR release notes",
    "content": "4.4.1 Release date: 15-05-2023 We are glad to announce that Visual NLP 😎 4.4.1 has been released! This release comes with a number of improvements, bug fixes, new implementations, and more! Highlights New Features Entirely new implementation for PositionFinder. New Base64ToImage Transformer. Italian Language Support. Control Task Parallelism in ImageToTextV2. Fixes &amp; Enhancements Most Java Vulnerabilities are gone. Improvements in Dicom file processing. Fixes in Python installation process. New notebooks SparkOcrLightPipelinesBase64.ipynb. New Features Entirely new implementation for PositionFinder: PositionFinder has been re-implemented to deal with the limitations of the original version. Many bugs in the previous version simply won’t be present in the new implementation. Also, the new version will work with coordinates originated in digital PDFs as well as coordinates originated on images. The following methods have been deprecated, and added, .setMatchingWindow():(deprecated) .setWindowPageTolerance():(deprecated) .setOcrScaleFactor: (new) Bounding boxes created for OCRed documents(i.e. ImageToText) will be vertically scaled up/down by this factor. E.g., provide 1.2, to scale up the coordinates by 20%. .setPdfScaleFactor: (new) Bounding boxes created for Pdf documents(i.e. PdfToText) will be vertically scaled up/down by this factor. E.g., provide 1.2, to scale up the coordinates by 20%. The two new methods will allow to apply a vertical scaling for bounding boxes according to the source document type, so if, for example, the text coordinates were extracted from a digital PDF, and then converted to an image, PositionFinder will be able to read the original dimensions of the PDF, and scale coordinates accordingly. Known Limitations: in this new version entities spawning multiple lines won’t be supported. We plan to add this support on release 4.4.2. New Base64ToImage Transformer. The new Base64ToImage Transformer is analogous to the BinaryToImage Transformer, but it will use a base64 encoded image as input. Check the sample notebook in this release notes for a practical end-to-end example on how to use it. Italian Language Support: support for Italian language has been added, you can start using it similarly to other languages by passing the ‘ita’ value for the language parameter, # Run OCR ocr = ImageToText() ocr.setInputCol(&quot;image&quot;) ocr.setOutputCol(&quot;text&quot;) ocr._set(language=&quot;ita&quot;) ocr.setDownloadModelData(True) Control Task Parallelism in ImageToTextV2. There’s a new parameter ‘taskParallelism’ in ImageToTextV2 to control the thread parallelism for each task. This way, you have the following options according to your needs to configure your workload, Low latency: you set taskParallelism to a number that can minimize the time for each document to be processed. This competes with the GPU setup. This is the strong scalability situation in which you need a quick response for each document so it can be consumed faster. You turn your document level parallelism to a low value so you work on few documents at a time and apply a high number of resources on each document. One way to achieve this is with reduced partition count in your dataframe. High throughput: you use a higher partition count in the dataframe, and a value of taskParallelism such that you keep the throughput high, without worrying about latency. This is the typical weak scaling situation in which you just scale out the workload through a Spark batch job. Example, ocr = ImageToTextV2.pretrained(&quot;ocr_base_printed_v2_opt&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setRegionsColumn(&quot;text_regions&quot;) .setInputCols([&quot;image&quot;]) .setOutputCol(&quot;text&quot;) .setTaskParallelism(12) Fixes Most vulnerabilities at the Java level were removed: 50 out of 52 reported vulnerabilities were removed from the JAR file of Visual NLP. Only 2 medium vulnerabilities remain. Improvements in Dicom file processing, Added support multiple frame overlay in DicomToImageV3, DicomDrawRegions. Fixed support 16 bit greyscale images. Added support 16 bit images (across Visual NLP in general). Fixes in ImageDrawRegions: ImageDrawRegions now allows scaling of input coordinates acording to the source document against which the coordinates were created. So, for example if the image was created using PdfToImage, using high resolution, and we want to draw the coordinates that were derived from the ‘position’ column in PdfToImage, we can scale the bounding boxes to account for this change in resolution, setSourceImageHeightCol: sets the name of the column where the original image height is present. setSourceImageWidthCol: sets the name of the column where the original image width is present. setScaleBoundingBoxes: enables/disables the scaling of the bounding boxes. Defaults to ‘false’(disabled). Known Limitations: due to mismatch in column types from different annotators returning dimensions, ImageDrawRegions scaling won’t work with some of them. This behavior will be fixed on next release. Fixes in Python installation process: installation process has been improved especially in environments with newer Python versions like Colab. New Notebooks SparkOcrLightPipelinesBase64.ipynb: learn how to use the new Base64ToImage Transformer in LightPipelines to feed in memory string buffers to Visual NLP pipelines. This release is compatible with Spark NLP for Healthcare 4.4.1, and Spark NLP 4.4.1. Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_4_1",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_4_1"
  },
  "1481": {
    "id": "1481",
    "title": "Spark NLP for Healthcare Release Notes 4.4.1",
    "content": "4.4.1 Highlights We are pleased to announce the latest enhancements and features for Spark NLP for Healthcare. This release showcases significant improvements and updates, including: Introducing a new biogpt-chat-jsl model (LLM), fine-tuned for clinical conversations in healthcare settings. A specialized medical summarizer model (LLM) designed specifically for radiology report analysis. Eight new Voice of Patient (VOP) Named Entity Recognition (NER) models for detecting clinical terms expressed in patients’ own words. Advanced Chunk Mapper models for precise mapping of NDC and HCPCS codes. Innovative Social Determinants of Health (SDOH) text classification models. Enhanced NER profiling with updated pre-trained pipelines, enabling the simultaneous execution of 100 clinical NER models. The implementation of a negative label feature for increased accuracy in the Zero Shot Relation Extraction Model. Allowing users to select specific entity tags in NameChunkObfuscator, Multi-mode deidentification &amp; obfuscation support in a single pass with the streamlined Deid module. Core improvements and bug fixes: Aligning ChunkMapperModel output metadata with SentenceEntityResolverModel metadata for seamless compatibility. Resolving issues with the MedicalNerApproach setTagsMapping parameter. Removing “non-sense” UNK tokens from text generators (e.g. BioGPt) for enhanced output quality. New and updated notebooks New and updated demos 17 new clinical models and pipelines added &amp; updated in total We are committed to delivering exceptional tools and resources for healthcare professionals and researchers, and we look forward to your valuable feedback on these latest updates. Introducing A New biogpt-chat-jsl Model (LLM), Fine-Tuned For Clinical Conversations In Healthcare Settings. We are excited to present the biogpt_chat_jsl_conversational text generator model, an advanced adaptation of the BioGPT-JSL model, meticulously fine-tuned with authentic medical conversations from clinical environments. This model is adept at answering clinical queries related to symptoms, medications, diagnostic tests, and various diseases. In comparison to its predecessor, the biogpt_chat_jsl model, the new biogpt_chat_jsl_conversational model generates more succinct and focused responses, significantly enhancing the efficiency and user experience of our software. This cutting-edge model is poised to revolutionize the way healthcare professionals and researchers engage with clinical information. Example: gpt_qa = MedicalTextGenerator.pretrained(&quot;biogpt_chat_jsl_conversational&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(100) sample_text = &quot;How to treat asthma?&quot; Result: answer: You have to take montelukast + albuterol tablet once or twice in day according to severity of symptoms. Montelukast is used as a maintenance therapy to relieve symptoms of asthma. Albuterol is used as a rescue therapy when symptoms are severe. You can also use inhaled corticosteroids ( ICS ) like budesonide or fluticasone for long term treatment. A Specialized Medical Summarizer Model (LLM) Designed Specifically For Radiology Report Analysis. We are proud to unveil the summarizer_radiology model, a highly specialized tool engineered to efficiently distill radiology reports by pinpointing and retaining the most crucial information. This model enables users to rapidly access a succinct synopsis of a report’s key findings without compromising on essential details. The summarizer_radiology model represents a significant advancement in the field of medical text analysis, offering unparalleled support to healthcare professionals in swiftly grasping the salient points of complex radiology reports and ultimately enhancing patient care outcomes. Example: summarizer = MedicalSummarizer.pretrained(&quot;summarizer_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;summary&quot;) .setMaxTextLength(512) .setMaxNewTokens(512) sample_text = &quot;&quot;&quot;INDICATIONS: Peripheral vascular disease with claudication. RIGHT: 1. Normal arterial imaging of right lower extremity. 2. Peak systolic velocity is normal. 3. Arterial waveform is triphasic. 4. Ankle brachial index is 0.96. LEFT: 1. Normal arterial imaging of left lower extremity. 2. Peak systolic velocity is normal. 3. Arterial waveform is triphasic throughout except in posterior tibial artery where it is biphasic. 4. Ankle brachial index is 1.06. IMPRESSION: Normal arterial imaging of both lower lobes. &quot;&quot;&quot; Result: The patient has peripheral vascular disease with claudication. The right lower extremity shows normal arterial imaging, but the peak systolic velocity is normal. The arterial waveform is triphasic throughout, except for the posterior tibial artery, which is biphasic. The ankle brachial index is 0.96. The impression is normal arterial imaging of both lower lobes. Eight New Voice of Patient (VOP) Named Entity Recognition (NER) Models For Detecting Clinical Terms Expressed In Patients’ Own Words. We are thrilled to introduce eight innovative Voice of Patient (VOP) Named Entity Recognition (NER) models, meticulously crafted to extract clinical terms from patients’ unique linguistic expressions. These models empower healthcare professionals to analyze patient data with enhanced accuracy and efficiency, paving the way for more precise diagnoses and tailored treatment plans. By leveraging the capabilities of these VOP NER models, healthcare providers can better understand patients’ perspectives, bridging the communication gap and fostering more effective patient-centered care. model name description predicted entities ner_vop_anatomy_wip Detecting anatomical terms expressed in patients’ own words. Laterality, BodyPart ner_vop_clinical_dept_wip Detecting medical devices and clinical department mentions terms expressed in patients’ own words. MedicalDevice, AdmissionDischarge, ClinicalDept ner_vop_demographic_wip Detecting demographic terms expressed in patients’ own words. SubstanceQuantity, RaceEthnicity, RelationshipStatus, Substance, Age, Employment, Gender ner_vop_problem_reduced_wip Detecting clinical condition terms expressed in patients’ own words. Modifier, HealthStatus, Problem ner_vop_problem_wip Detecting clinical condition terms expressed in patients’ own words using a granular taxonomy. InjuryOrPoisoning, Modifier, HealthStatus, Symptom, Disease, PsychologicalCondition ner_vop_temporal_wip Detecting temporal references terms expressed in patients’ own words. Frequency, Duration, DateTime ner_vop_test_wip Detecting test mention terms expressed in patients’ own words. Measurements, TestResult, Test, VitalTest ner_vop_treatment_wip Detecting treatment terms expressed in patients’ own words. Treatment, Frequency, Procedure, Route, Duration, Dosage, Drug, Form Example: ner = MedicalNerModel.pretrained(&quot;ner_vop_problem_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;&quot;&quot;I&quot;ve been experiencing joint pain and fatigue lately, so I went to the rheumatology department. After some tests, they diagnosed me with rheumatoid arthritis and started me on a treatment plan to manage the symptoms.&quot;&quot;&quot; Results: chunk ner_label pain Symptom fatigue Symptom rheumatoid arthritis Disease Advanced Chunk Mapper Models For Precise Mapping Of NDC And HCPCS Codes: We are delighted to present our cutting-edge chunk mapper models, meticulously crafted for the accurate mapping of National Drug Code (NDC) and Healthcare Common Procedure Coding System (HCPCS) codes. These innovative models enable users to swiftly and effortlessly identify the relevant codes, optimizing the coding and billing process while bolstering accuracy. The introduction of these advanced chunk mapper models demonstrates our commitment to delivering state-of-the-art solutions that streamline healthcare administration tasks, ultimately contributing to improved efficiency and patient care outcomes. hcpcs_ndc_mapper model maps Healthcare Common Procedure Coding System (HCPCS) codes to their corresponding National Drug Codes (NDC) and their drug brand names. Example: ... chunkerMapper = DocMapperModel.pretrained(&quot;hcpcs_ndc_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;hcpcs_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;ndc_code&quot;, &quot;brand_name&quot;]) text= [&quot;Q5106&quot;, &quot;J9211&quot;, &quot;J7508&quot;] Result: hcpcs_chunk mappings relation Q5106 59353-0003-10 ndc_code Q5106 RETACRIT (PF) 3000 U/1 ML brand_name J9211 59762-2596-01 ndc_code J9211 IDARUBICIN HYDROCHLORIDE (PF) 1 MG/ML brand_name J7508 00469-0687-73 ndc_code J7508 ASTAGRAF XL 5 MG brand_name ndc_hcpcs_mapper model maps NDC with their corresponding HCPCS codes and their descriptions. Example: ... chunkerMapper = DocMapperModel.pretrained(&quot;ndc_hcpcs_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ndc_chunk&quot;]) .setOutputCol(&quot;hcpcs&quot;) .setRels([&quot;hcpcs_code&quot;, &quot;hcpcs_description&quot;]) text= [&quot;16714-0892-01&quot;, &quot;00990-6138-03&quot;, &quot;43598-0650-11&quot;] Result: ndc_chunk mappings relation 16714-0892-01 J0878 hcpcs_code 16714-0892-01 INJECTION, DAPTOMYCIN, 1 MG hcpcs_description 00990-6138-03 A4217 hcpcs_code 00990-6138-03 STERILE WATER/SALINE, 500 ML hcpcs_description 43598-0650-11 J9340 hcpcs_code 43598-0650-11 INJECTION, THIOTEPA, 15 MG hcpcs_description Innovative Social Determinants Of Health (SDOH) Text Classification Models. We are excited to announce the release of three new Social Determinants of Health (SDOH) text classification models, specifically tailored to analyze and classify information related to insurance status, insurance coverage, and SDOH insurance type. These cutting-edge models enable healthcare professionals and researchers to better understand the nuanced interplay of insurance factors that influence health outcomes and access to care. By leveraging these innovative SDOH classification models, stakeholders can gain valuable insights into the insurance landscape and its impact on health disparities, ultimately informing more targeted interventions and policies to improve patient care and well-being. model name description predicted entities genericclassifier_sdoh_insurance_status_sbiobert_cased_mli Detecting whether the patient has insurance or not Insured, Uninsured, Unknown genericclassifier_sdoh_insurance_coverage_sbiobert_cased_mli Detecting insurance coverage Good, Poor, Unknown genericclassifier_sdoh_insurance_type_sbiobert_cased_mli Detecting insurance type Employer, Medicaid, Medicare, Military, Private, Other Example: features_asm = FeaturesAssembler() .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;features&quot;) generic_classifier = GenericClassifierModel.pretrained(&quot;genericclassifier_sdoh_insurance_type_sbiobert_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) text_list = [ &quot;&quot;&quot;The patient has VA insurance.&quot;&quot;&quot;, &quot;&quot;&quot;She is under Medicare insurance&quot;&quot;&quot;, &quot;&quot;&quot;The patient has good coverage of Private insurance&quot;&quot;&quot;, &quot;&quot;&quot;Medical File for John Smith, Male, Age 42 Chief Complaint: Patient complains of nausea, vomiting, and shortness of breath...&quot;&quot;&quot;, &quot;&quot;&quot;Certainly, here is an example case study for a patient with private insurance: Case Study for Emily Chen, Female, Age 38 ...&quot;&quot;&quot;, &quot;&quot;&quot;Medical File for John Doe, Male, Age 72 Chief Complaint: Patient reports shortness of breath and fatigue. History of Pres...&quot;&quot;&quot;] Result: text result The patient has VA insurance. Military She is under Medicare insurance Medicare Medical File for John Smith, Male, Age 42 Chief Complaint: Patient complains of nausea, vomiti… Medicaid Certainly, here is an example case study for a patient with private insurance: Case Study for … Private Medical File for John Doe, Male, Age 72 Chief Complaint: Patient reports shortness of breath… Medicare Updated NER Profiling Pretrained Pipelines With New NER Models to Allow Running 100 Clinical NER Models At Once We are proud to announce the latest updates to our ner_profiling_clinical and ner_profiling_biobert pre-trained pipelines, which now feature the integration of new Named Entity Recognition (NER) models. When executing these pipelines on your text, you can now benefit from the predictions generated by an impressive 100 clinical NER models in ner_profiling_clinical and 22 clinical NER models in ner_profiling_biobert. These enhancements to our pre-trained pipelines showcase our commitment to providing healthcare professionals and researchers with state-of-the-art tools, enabling more efficient and accurate analysis of clinical text to support data-driven decision-making and improved patient care outcomes. You can check ner_profiling_clinical and ner_profiling_biobert Models Hub pages for more details and the NER model lists that these pipelines include. The Implementation Of A Negative Label Feature For Increased Accuracy In The Zero Shot Relation Extraction Model We are pleased to introduce the addition of a new setNegativeRelationships parameter to the ZeroShotRelationExtractionModel annotator, empowering users to exercise more effective control over the model’s predictions for enhanced accuracy. This innovative parameter generates negative examples of relations and subsequently removes them, resulting in improved precision for positive labels. This advanced feature demonstrates our ongoing commitment to delivering state-of-the-art solutions for healthcare professionals and researchers, facilitating more accurate analysis of complex relationships within clinical text and ultimately contributing to better patient care and outcomes. Example: re_model = sparknlp_jsl.annotator.ZeroShotRelationExtractionModel .pretrained() .setRelationalCategories({ &quot;CURE&quot;: [&quot;{TREATMENT} cures {PROBLEM}.&quot;], &quot;IMPROVE&quot;: [&quot;{TREATMENT} improves {PROBLEM}.&quot;, &quot;{TREATMENT} cures {PROBLEM}.&quot;], &quot;REVEAL&quot;: [&quot;{TEST} reveals {PROBLEM}.&quot;]}) .setMultiLabel(False) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) .setNegativeRelationships([&quot;IMPROVE&quot;]) sample_text = &quot;Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer.&quot; Without Setting setNegativeRelationships: relation chunk1 entity1 chunk2 entity2 hypothesis confidence REVEAL An MRI test TEST cancer PROBLEM An MRI test reveals cancer. 0.9760039 IMPROVE Paracetamol TREATMENT sickness PROBLEM Paracetamol improves sickness. 0.98819494 IMPROVE Paracetamol TREATMENT headache PROBLEM Paracetamol improves headache. 0.9929625 After Setting setNegativeRelationships: relation chunk1 entity1 chunk2 entity2 hypothesis confidence REVEAL An MRI test TEST cancer PROBLEM An MRI test reveals cancer. 0.9760039 Allowing users To Select Specific Entity Tags In NameChunkObfuscator We are excited to introduce the new setNameEntities parameter for the NameChunkObfuscator annotator, enabling users to specify the labels they wish to obfuscate using an array list. The default value is set to [“NAME”], offering greater flexibility and customization when working with sensitive information. This enhancement to the NameChunkObfuscator reflects our dedication to providing user-centric tools that cater to the diverse needs of healthcare professionals and researchers, ensuring the protection of sensitive data while maintaining the utility of the information for analysis and decision-making. Example: nameChunkObfuscator = NameChunkObfuscatorApproach() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;replacement&quot;) .setNameEntities([&quot;PATIENT&quot;,&quot;DOCTOR&quot;,&quot;NAME&quot;]) sample_text = &#39;&#39;&#39;John Davies Hendrickson is a 62 y.o. patient admitted. Dr. Lorand was scheduled for emergency assessment. John Davies Hendrickson is a teacher and Dr. Lorand is a Doctor. Olivera is 25 years-old. Dr. Roland offered his patient Olivera a healthy diet. John Davies Hendrickson Lorand has biggest name&#39;&#39;&#39; As can be seen in the table below, DOCTOR and PATIENT chunks are consistently replaced with the same obfuscation chunks. ner_chunk label replacement John Davies Hendrickson PATIENT Aesculapius Amalasuntha Lorand DOCTOR Fulvia John Davies Hendrickson PATIENT Aesculapius Amalasuntha Lorand DOCTOR Fulvia Olivera PATIENT Killian Roland DOCTOR Rudolf Olivera DOCTOR Killian John Davies Hendrickson Lorand PATIENT Deipnosophistae Hermaphroditus   Sentence Obfuscated 0 John Davies Hendrickson is a 62 y.o. patient admitted. Aesculapius Amalasuntha is a 62 y.o. patient admitted. 1 Dr. Lorand was scheduled for emergency assessment. Dr. Fulvia was scheduled for emergency assessment. 2 John Davies Hendrickson is a teacher and Dr. Lorand is a Doctor. Aesculapius Amalasuntha is a teacher and Dr. Fulvia is a Doctor. 3 Olivera is 25 years-old. Killian is 25 years-old. 4 Dr. Roland offered his patient Olivera a healthy diet. Dr. Rudolf offered his patient Killian a healthy diet. 5 John Davies Hendrickson Lorand has biggest name Deipnosophistae Hermaphroditus has biggest name Multi-mode Deidentification And Obfuscation Support In A Single Pass With The Streamlined Deid Module We are proud to announce the enhancement of our Deid module with the introduction of a one-pass, multi-mode deidentification feature. This powerful new capability significantly improves the module’s functionality, enabling users to deidentify their data with increased efficiency, accuracy, and flexibility. To utilize this feature for a single column, simply set the multi_mode_file_path parameter with the JSON file path describing the desired multi-mode configuration. This streamlined approach demonstrates our commitment to providing state-of-the-art tools that cater to the evolving needs of healthcare professionals and researchers, ensuring the protection of sensitive information while maintaining data utility for analysis and decision-making. Example: #json to choose deid mode sample_json= { &quot;obfuscate&quot;: [&quot;NAME&quot;, &quot;PHONE&quot;] , &quot;mask_entity_labels&quot;: [&quot;AGE&quot;], &quot;skip&quot;: [&quot;SSN&quot;], &quot;mask_same_length_chars&quot;:[&quot;DATE&quot;], &quot;mask_fixed_length_chars&quot;:[&quot;ZIP&quot;, &quot;LOCATION&quot;] } import json with open(&#39;sample_multi-mode.json&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f: json.dump(sample_json, f, ensure_ascii=False, indent=4) #Deidentification with multi mode for one column deid_implementor= Deid(spark, input_file_path=&quot;deid_data.csv&quot;, output_file_path=&quot;deidentified.csv&quot;, custom_pipeline=model, multi_mode_file_path=&quot;sample_multi-mode.json&quot;) For multiple columns, we can set one specific JSON file path multi mode for each column. Example: #json to choose deid mode for the 2nd column sample_json_column2= { &quot;obfuscate&quot;: [&quot;SSN&quot;, &quot;AGE&quot;] , &quot;mask_entity_labels&quot;: [&quot;DATE&quot;], &quot;skip&quot;: [&quot;ID&quot;], &quot;mask_same_length_chars&quot;:[&quot;NAME&quot;], &quot;mask_fixed_length_chars&quot;:[&quot;ZIP&quot;, &quot;LOCATION&quot;] } import json with open(&#39;sample_multi-mode_column2.json&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f: json.dump(sample_json_column2, f, ensure_ascii=False, indent=4) #Deidentification with multi mode for multiple columns deid_implementor= Deid(spark, input_file_path=&quot;deid_multiple_data.csv&quot;, output_file_path=&quot;deidentified.csv&quot;, custom_pipeline=model, fields={&quot;text&quot;: &quot;sample_multi-mode.json&quot;, &quot;text_1&quot;:&quot;sample_multi-mode_column2.json&quot;}, masking_policy=&quot;fixed_length_chars&quot;, fixed_mask_length=2, separator=&quot;,&quot;) For more detail please check Clinical Deidentification Utility Module Core Improvements and Bug Fixes Aligning ChunkMapperModel output metadata with SentenceEntityResolverModel metadata for seamless compatibility. Resolving issues with the MedicalNerApproach setTagsMapping parameter. Removing “non-sense” UNK tokens from text generators (e.g. BioGPt) for enhanced output quality New and Updated Notebooks New Comparison Medical Text Summarization Notebook for summarization of clinical context can be used with new MedicalSummarizer annotator. New Biogpt Chat JSL Notebook for test generation of clinical context can be used with new MedicalTextGenerator annotator. New Text Classification with Contextual Window Splitting for text classification with contextual window splitting can be used with the new WindowedSentenceModel annotator. New Review Functions of ALab Module Notebook for ALAB module review functions. Updated Clinical Deidentification Utility Module with the latest improvement. New and Updated Demos Medical Large Language Modeling demo Medical Summarization Radiology demo BIOGPT CHAT JSL demo MODELS demo With MODELS demos, you can select all healthcare models as Task and Annotator based and you can see information about the models. 17 New Clinical Models and Pipelines Added &amp; Updated in Total biogpt_chat_jsl_conversational summarizer_radiology ner_profiling_biobert ner_profiling_clinical ner_vop_anatomy_wip ner_vop_clinical_dept_wip ner_vop_demographic_wip ner_vop_problem_reduced_wip ner_vop_problem_wip ner_vop_temporal_wip ner_vop_test_wip ner_vop_treatment_wip ndc_hcpcs_mapper hcpcs_ndc_mapper genericclassifier_sdoh_insurance_status_sbiobert_cased_mli genericclassifier_sdoh_insurance_coverage_sbiobert_cased_mli genericclassifier_sdoh_insurance_type_sbiobert_cased_mli For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_1"
  },
  "1482": {
    "id": "1482",
    "title": "Spark OCR release notes",
    "content": "4.4.2 Release date: 30-05-2023 We are glad to announce that Visual NLP 😎 4.4.2 has been released. This is a small release with mostly bug fixes and minor improvements. Fixes ImageTextDetectorV2 initialization bug happening in some cluster environments is now fixed. PdfToText and PdfToHocr now return document dimensions using the same data type(integer). Remaining 2 vulnerabilities from release 4.4.1 in JAR package are now gone. Fixed the problem causing the following exception in HocrToTextTable: java.lang.UnsupportedOperationException. New Features Bounding boxes spawning multiple lines are now supported in PositionFinder! original: masked: Here for “Lockheed Martin” PositionFinder will return two bounding boxes. Remember that you can still link the two bounding boxes to the original entity by using the ‘chunk index’. Support for Spark 3.4. Guidelines for building Visual NLP into a Java app. Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_4_2",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_4_2"
  },
  "1483": {
    "id": "1483",
    "title": "Spark NLP for Healthcare Release Notes 4.4.2",
    "content": "4.4.2 Highlights We are thrilled to unveil the latest set of upgrades and advancements for Spark NLP for Healthcare. This edition brings to the fore a host of remarkable enhancements and updates, which are as follows: The medical QA models now incorporates Flan-T5 models, significantly expanding its capacity. We introduce a newly finetuned biogpt-chat-jsl model, fine-tuned with clinical conditions to produce more precise descriptions when prompted. The brand-new medical summarizer model is designed to provide summarizations of clinical guidelines under predefined categories such as causes, symptoms, and more. Text summarization method utilizing a map-reduce approach for section-wise summarization. New chunk mapper model to map ICD10CM codes with corresponding causes and claim analysis codes according to CDC guidelines. The PHI obfuscation (De-identification module) now offers the ability to customize the casings of fake entities for each entity type. Users now have the option to enable or disable the ‘gender awareness’ feature in the De-identification module. A set of four new classifier models has been introduced, further broadening the scope of our toolkit. We now offer new clinical NER models specifically designed for extracting clinical terms in the German language. Core functionalities have been fine-tuned with numerous improvements and bug fixes. We are introducing new and updated notebooks, and demonstrations, providing a more user-friendly experience. We have added and updated a substantial number of new clinical models and pipelines, further solidifying our offering in the healthcare domain. We are confident that these enhancements will elevate your Spark NLP for Healthcare experience, enabling more accurate and streamlined processing of healthcare-related natural language data. The Medical QA Models Now Incorporates Flan-T5 Models, Significantly Expanding Its Capacity The newly incorporated flan_t5_base_jsl_qa model is meticulously designed to function seamlessly with the MedicalQuestionAnswering annotator. This innovative model is engineered to offer an efficacious solution for providing accurate answers and insightful information across a broad spectrum of domains. It is important to note that this is a general model and has not yet been fine-tuned for clinical texts. However, we are planning to carry out this specialized fine-tuning in our upcoming releases, further enhancing its applicability and precision in the clinical context. Example: med_qa = MedicalQuestionAnswering.pretrained(&quot;flan_t5_base_jsl_qa&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setCustomPrompt(&quot;Question: {QUESTION}. Context: {DOCUMENT}&quot;) .setMaxNewTokens(70) .setTopK(1) paper_abstract = &quot;We have previously reported the feasibility of diagnostic and therapeutic peritoneoscopy including liver biopsy, gastrojejunostomy, and tubal ligation by an oral transgastric approach. We present results of per-oral transgastric splenectomy in a porcine model. The goal of this study was to determine the technical feasibility of per-oral transgastric splenectomy using a flexible endoscope. We performed acute experiments on 50-kg pigs. All animals were fed liquids for 3 days prior to procedure. The procedures were performed under general anesthesia with endotracheal intubation. The flexible endoscope was passed per orally into the stomach and puncture of the gastric wall was performed with a needle knife. The puncture was extended to create a 1.5-cm incision using a pull-type sphincterotome, and a double-channel endoscope was advanced into the peritoneal cavity. The peritoneal cavity was insufflated with air through the endoscope. The spleen was visualized. The splenic vessels were ligated with endoscopic loops and clips, and then mesentery was dissected using electrocautery. Endoscopic splenectomy was performed on six pigs. There were no complications during gastric incision and entrance into the peritoneal cavity. Visualization of the spleen and other intraperitoneal organs was very good. Ligation of the splenic vessels and mobilization of the spleen were achieved using commercially available devices and endoscopic accessories.&quot; question = &quot;How is transgastric endoscopic performed?&quot; Result: [&#39;Transgastric endoscopic surgery is a type of surgery that involves removing the obstructions from the heart and lungs. It involves removing the trachea, a small artery, and a small sphincter. The trachea is then removed and the sphincter is removed.&#39;] Introducing a Newly Finetuned biogpt-chat-jsl Model, based on Clinical Conditions. We are excited to present our newly fine-tuned biogpt-chat-jsl model. This model, known as biogpt_chat_jsl_conditions, is based on the robust BioGPT architecture and has been meticulously fine-tuned with questions pertaining to a wide array of medical conditions. Our team has concentrated on emphasizing the Q&amp;A aspect, making it less conversational but highly focused on delivering accurate and insightful answers. This enhanced focus on question answering ensures that users can extract critical and relevant information quickly and accurately. This strategic fine-tuning with clinical guidelines strengthens the model’s ability to provide superior results in the realm of medical NLP. Example: gpt_qa = MedicalTextGenerator.pretrained(&quot;biogpt_chat_jsl_conditions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(199) text = &quot;What are the potential causes and risk factors for developing cardiovascular disease?&quot; Result: [Cardiovascular disease ( CVD ) is a general term for conditions affecting the heart or blood vessels. It can be caused by a variety of factors, including smoking, high blood pressure, diabetes, high cholesterol, and obesity. Certain medical conditions, such as chronic kidney disease, can also increase the risk of developing CVD.] The Brand-New Medical Summarizer Model Designed To Provide Summarizations Of Clinical Guidelines Under Predefined Categories Such As Causes, Symptoms, And More. We are pleased to introduce the summarizer_clinical_guidelines_large model as part of our latest enhancements. This innovative Medical Summarizer Model is adept at providing succinct summarizations of clinical guidelines. At present, the model is equipped to handle guidelines for Asthma and Breast Cancer, though we plan to expand this repertoire in future iterations. One of the notable features of this model is its ability to neatly categorize summarizations into four distinct sections: Overview, Causes, Symptoms, and Treatments. This systematic segregation facilitates ease of understanding and aids in extracting specific information more efficiently. An additional technical specification to note is the model’s context length, which stands at 768 tokens. This parameter ensures an optimal balance between detail and brevity, allowing for comprehensive yet concise summarizations. Example: summarizer = MedicalSummarizer.pretrained(&quot;summarizer_clinical_guidelines_large&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;summary&quot;) .setMaxTextLength(768) .setMaxNewTokens(512) text = &quot;&quot;&quot;Clinical Guidelines for Breast Cancer: Breast cancer is the most common type of cancer among women. It occurs when the cells in the breast start growing abnormally, forming a lump or mass. This can result in the spread of cancerous cells to other parts of the body. Breast cancer may occur in both men and women but is more prevalent in women. The exact cause of breast cancer is unknown. However, several risk factors can increase your likelihood of developing breast cancer, such as: - A personal or family history of breast cancer - A genetic mutation, such as BRCA1 or BRCA2 - Exposure to radiation - Age (most commonly occurring in women over 50) - Early onset of menstruation or late menopause - Obesity - Hormonal factors, such as taking hormone replacement therapy Breast cancer may not present symptoms during its early stages. Symptoms typically manifest as the disease progresses. Some notable symptoms include: - A lump or thickening in the breast or underarm area - Changes in the size or shape of the breast - Nipple discharge - Nipple changes in appearance, such as inversion or flattening - Redness or swelling in the breast Treatment for breast cancer depends on several factors, including the stage of the cancer, the location of the tumor, and the individual&#39;s overall health. Common treatment options include: - Surgery (such as lumpectomy or mastectomy) - Radiation therapy - Chemotherapy - Hormone therapy - Targeted therapy Early detection is crucial for the successful treatment of breast cancer. Women are advised to routinely perform self-examinations and undergo regular mammogram testing starting at age 40. If you notice any changes in your breast tissue, consult with your healthcare provider immediately.&quot;&quot;&quot; Result: Overview of the disease: Breast cancer is the most common type of cancer among women, occurring when the cells in the breast start growing abnormally, forming a lump or mass. It can result in the spread of cancerous cells to other parts of the body. Causes: The exact cause of breast cancer is unknown, but several risk factors can increase the likelihood of developing it, such as a personal or family history, a genetic mutation, exposure to radiation, age, early onset of menstruation or late menopause, obesity, and hormonal factors. Symptoms: Symptoms of breast cancer typically manifest as the disease progresses, including a lump or thickening in the breast or underarm area, changes in the size or shape of the breast, nipple discharge, nipple changes in appearance, and redness or swelling in the breast. Treatment recommendations: Treatment for breast cancer depends on several factors, including the stage of the cancer, the location of the tumor, and the individual&#39;s overall health. Common treatment options include surgery, radiation therapy, chemotherapy, hormone therapy, and targeted therapy. Early detection is crucial for successful treatment of breast cancer. Women are advised to routinely perform self-examinations and undergo regular mammogram testing starting at age 40. Text Summarization Method Utilizing A Map-Reduce Approach For Section-Wise Summarization. We are pleased to announce the augmentation of our MedicalSummarizer annotator with the integration of advanced parameters. This enhancement broadens the scope of your medical summarization activities, granting you increased flexibility and helping to navigate the constraints of token limitations. These newly introduced parameters notably amplify the functionality of the annotator, equipping users with the ability to generate detailed and accurate summaries of medical documents. The MedicalSummarizer now utilizes a map-reduce approach, a method that progressively condenses separate text sections until the summary achieves the desired length. We are introducing the following parameters: setRefineSummary: Activate this for a more refined summarization, albeit at a slightly increased computational cost. setRefineSummaryTargetLength: Set your desired summary length in tokens (separated by whitespace). This feature is only operative when setRefineSummary is activated. setRefineChunkSize: Define the size of refined chunks according to your preference. This size should match the LLM context window size in tokens. This feature is only operative when setRefineSummary is enabled. setRefineMaxAttempts: Set the maximum number of attempts for re-summarizing chunks that exceed the setRefineSummaryTargetLength before discontinuation. This feature is only operative when setRefineSummary is enabled. These advancements in the MedicalSummarizer annotator underline our unwavering commitment to delivering cutting-edge tools that enable healthcare professionals and researchers to conduct more efficient and precise medical text analysis. Example: MedicalSummarizer.pretrained() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;summary&quot;) .setMaxTextLength(512) .setMaxNewTokens(512) .setDoSample(True) .setRefineSummary(True) .setRefineSummaryTargetLength(100) .setRefineMaxAttempts(3) .setRefineChunkSize(512) text = &quot;&quot;&quot;The patient is a pleasant 17-year-old gentleman who was playing basketball today in gym. Two hours prior to presentation, he started to fall and someone stepped on his ankle and kind of twisted his right ankle and he cannot bear weight on it now. It hurts to move or bear weight. No other injuries noted. He does not think he has had injuries to his ankle in the past. SOCIAL HISTORY: He does not drink or smoke. MEDICAL DECISION MAKING: He had an x-ray of his ankle that showed a small ossicle versus avulsion fracture of the talonavicular joint on the lateral view. He has had no pain over the metatarsals themselves. This may be a fracture based upon his exam. He does want to have me to put him in a splint. He was given Motrin here. He will be discharged home to follow up with Dr. X from Orthopedics. DISPOSITION: Crutches and splint were administered here. I gave him a prescription for Motrin and some Darvocet if he needs to length his sleep and if he has continued pain to follow up with Dr. X. Return if any worsening problems.&quot;&quot;&quot; Result: [&#39;An ankle exam revealed an osteocorotony in an injured man, who had pain on both Metatatsals. The physician prescribed sprained knee walker, thigh splinting for pain and crutches, but a calconavenous joint had a fracture. A physician will consult an orthopedic specialist for relief, follow up by the doctor, follow-down based on pain.&#39;] New Chunk Mapper Model To Map ICD10CM Codes With Corresponding Causes and Claim Analysis Codes According To CDC Guidelines. This model is designed to map ICD-10-CM codes and deliver corresponding causes and generate claim analysis codes for each respective ICD-10-CM code, adhering to the guidelines provided by the Centers for Disease Control and Prevention (CDC). This model efficiently interfaces with the complex structure of ICD-10-CM coding, facilitating the extraction of meaningful and contextually relevant information. In instances where an equivalent claim analysis code is not available, the model will return a None result. Example: chunkerMapper = ChunkMapperModel.pretrained(&quot;icd10cm_cause_claim_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;icd_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;icd10cm_cause&quot;, &quot;icd10cm_claim_analysis_code&quot;]) text = [&quot;D69.51&quot;, &quot;G43.83&quot;, &quot;A18.03&quot;] Result: icd10cm_code cause icd10cm_claim_analysis_code D69.51 Unintentional injuries D69.51 D69.51 Adverse effects of medical treatment D69.51 G43.83 Headache disorders G43.83 G43.83 Tension-type headache G43.83 G43.83 Migraine G43.83 A18.03 Whooping cough A18.03 The PHI Obfuscation (De-Identification Module) Now Offers The Ability To Customize The Casings Of Fake Entities For Each Entity Type. This update introduces the entityCasingModes parameter in the Deidentification classes, a feature that enables you to define a Json path containing a dictionary of modes for casing selections. This powerful capability lets you dictate how the casing of entities or data elements should be altered during the deidentification process, providing you with greater control and flexibility over your data. The entityCasingModes parameter offers the following casing modes: lowercase: Transforms all characters to lowercase following the rules of the default locale. uppercase: Changes all characters to uppercase based on the default locale’s rules. capitalize: Adjusts the first character to uppercase and alters the remaining characters to lowercase. titlecase: Modifies the first character in every token (word) to uppercase and changes the remaining characters to lowercase. With the ability to set the entityCasingModes parameter with the appropriate casing mode for each entity type, you now have enhanced control over the deidentification process and how it manages the casing of those elements. This update underlines our commitment to providing advanced and user-centric tools that cater to your specific needs in healthcare data processing. Example: casing_dict= { &quot;lowercase&quot;: [&quot;IDNUM&quot;,&quot;MEDICALRECORD&quot;] , &quot;uppercase&quot;: [&quot;city&quot;,&quot;street&quot;], &quot;capitalize&quot;: [ &quot;AGE&quot;], &quot;titlecase&quot;:[&quot;DOCTOR&quot;, &quot;PATIENT&quot;, &quot;HOSPITAL&quot;], } import json with open(&#39;entity_casing.json&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f: json.dump(casing_dict, f, ensure_ascii=False, indent=4) obfuscation = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_subentity_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setEntityCasingModes(&quot;./entity_casing.json&quot;) text =&#39;&#39;&#39; Record date: 08-24-2007. SSN : S5067003218XYZ. Adress: Keats Street, San Francisco . Victoria Davis is a 61-year-old , born in Los Angeles, white female. Her surgery took place at Emory University Hospital on August 21, 2007. The right total knee replacement performed by Dr. Anderson Johnson and Dr. Amelia Martinez. Davis was transfused with 2 units of autologous blood postoperatively. &#39;&#39;&#39; Result:   sentence mask deidentified 0 Record date: 08-24-2007. Record date: &lt;DATE&gt;. Record date: 09-01-2007. 1 SSN : S5067003218XYZ. SSN : &lt;MEDICALRECORD&gt;. SSN : r7150154340vuf. 2 Adress: Keats Street, San Francisco . Adress: &lt;CITY&gt;, &lt;STATE&gt; . Adress: HAROLD, COLORADO . 3 Victoria Davis is a 61-year-old , born in Los Angeles, white female. &lt;PATIENT&gt; is a &lt;AGE&gt; , born in &lt;CITY&gt;, white female. Marivic Friend is a 62-year-old , born in AUSTIN, white female. 4 Her surgery took place at Emory University Hospital on August 21, 2007. Her surgery took place at &lt;HOSPITAL&gt; on &lt;DATE&gt;. Her surgery took place at Healthsouth Rehabilitation Hospital The Woodlands on August 29, 2007. 5 The right total knee replacement performed by Dr. Anderson Johnson and Dr. Amelia Martinez. The right total knee replacement performed by Dr. &lt;DOCTOR&gt; and Dr. &lt;DOCTOR&gt;. The right total knee replacement performed by Dr. Marland Sensor and Dr. Freada Gin. 6 Davis was transfused with 2 units of autologous blood postoperatively. &lt;PATIENT&gt; was transfused with 2 units of autologous blood postoperatively. Zadok Phlegm was transfused with 2 units of autologous blood postoperatively. Users Now Have The Option To Enable Or Disable The ‘Gender Awareness’ Feature In The De-Identification Module. Users now have the ability to enable or disable the ‘Gender Awareness’ feature, providing greater control over the deidentification process. This feature is operated via the setGenderAwareness parameter in the Deidentification class. By setting this parameter to True, the deidentification algorithm will consider the gender information associated with names. This additional layer of awareness allows for a more precise and accurate process of anonymization. The option to activate or deactivate ‘Gender Awareness’ provides you with increased flexibility to adapt the deidentification process to your specific needs, further enhancing the accuracy and utility of the De-Identification module. Example: obfuscation = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setGenderAwareness(True) data = [ &#39;William Walker is a 62 y.o. patient admitted&#39;, &#39;Jack Davies was seen by attending his Doctor.&#39;, &#39;Cecilia Reyes was scheduled for assessment.&#39;, &#39;Jessica Smith was discharged on 10/02/2022&#39;, &#39;Evelyn White was seen by physician&#39;, &#39;Riley John MD. was started on prophylaxis&#39;, ] Result:   sentence deid_entity_label obfuscated 0 William Walker is a 62 y.o. patient admitted &lt;PATIENT&gt; is a &lt;AGE&gt; y.o. patient admitted Emillio Epps is a 77 y.o. patient admitted 1 Jack Davies was seen by attending his Doctor. &lt;PATIENT&gt; was seen by attending his Doctor. Mitsuru Hitchcock was seen by attending his Doctor. 2 Cecilia Reyes was scheduled for assessment. &lt;PATIENT&gt; was scheduled for assessment. Celeste Pies was scheduled for assessment. 3 Jessica Smith was discharged on 10/02/2022 &lt;PATIENT&gt; was discharged on &lt;DATE&gt; Chancey Banner was discharged on 12/03/2022 4 Evelyn White was seen by physician &lt;PATIENT&gt; was seen by physician Mistee Pipe was seen by physician 5 Riley John MD. was started on prophylaxis &lt;DOCTOR&gt; MD. was started on prophylaxis Yandel Alvine MD. was started on prophylaxis A Set Of Four New Classifier Models Has Been Introduced, Further Broadening The Scope Of Our Toolkit. We are excited to announce 4 new classification models. model name annotator predicted entities classifierml_ade DocumentMLClassifierApproach True, False classifier_logreg_ade DocumentLogRegClassifierModel True, False generic_svm_classifier_ade GenericSVMClassifierModel True, False generic_logreg_classifier_ade GenericLogRegClassifierModel True, False Example: logreg = DocumentLogRegClassifierModel.pretrained(&quot;classifier_logreg_ade&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;prediction&quot;) [&quot;&quot;&quot;I feel great after taking tylenol.&quot;&quot;&quot;], [&quot;&quot;&quot;Detection of activated eosinophils in nasal polyps of an aspirin-induced asthma patient.&quot;&quot;&quot;] Result: text result I feel great after taking tylenol [False] Detection of activated eosinophils in nasal polyps of an aspirin-induced asthma patient. [True] We Now Offer New Clinical NER Models Specifically Designed For Extracting Clinical Terms In The German Language. We are excited to announce the German ner_clinical models, that can detect Problem, Test and Treatment entities. Example: clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text= &quot;&quot;&quot;Verschlechterung von Schmerzen oder Schwäche in den Beinen , Verlust der Darm - oder Blasenfunktion oder andere besorgniserregende Symptome. Der Patient erhielt empirisch Ampicillin , Gentamycin und Flagyl sowie Narcan zur Umkehrung von Fentanyl . ALT war 181 , AST war 156 , LDH war 336 , alkalische Phosphatase war 214 und Bilirubin war insgesamt 12,7 .&quot;&quot;&quot; Result: chunk ner_label Schmerzen PROBLEM Schwäche in den Beinen PROBLEM Verlust der Darm PROBLEM Blasenfunktion PROBLEM Symptome PROBLEM empirisch Ampicillin TREATMENT Gentamycin TREATMENT Flagyl TREATMENT Narcan TREATMENT Fentanyl TREATMENT ALT TEST AST TEST LDH TEST alkalische Phosphatase TEST Bilirubin TEST Core Functionalities Have Been Fine-Tuned With Numerous Improvements and Bug Fixes Updated default models and documentation for pretrained() functions in most annotators. Use custom signatures when saving a MedicalBertForSequenceClassification model We Are Introducing New and Updated Notebooks And Demonstrations, Providing a More User-Friendly Experience. New Porting_QA_Models_From_Text_Generator_Backbone notebook for porting QA models from Text_Generator Models. Updated Biogpt_Chat_JSL notebook with latest model. Updated Medical_Text_Summarization notebook with lastest improvement. Updated Medical_Question_Answering norebook with latest model. New SOCIAL DETERMINANT CLASSIFICATION GENERIC demo New SPANISH CLINICAL TEXT SUMMARIZATION demo We Have Added And Updated A Substantial Number Of New Clinical Models And Pipelines, Further Solidifying Our Offering In The Healthcare Domain. flan_t5_base_jsl_qa biogpt_chat_jsl_conditions summarizer_clinical_guidelines_large ner_clinical -&gt; de classifier_logreg_ade classifierml_ade generic_svm_classifier_ade generic_logreg_classifier_ade ner_anatomy_emb_clinical_large ner_anatomy_emb_clinical_medium ner_abbreviation_emb_clinical_large ner_abbreviation_emb_clinical_medium icd10cm_cause_claim_mapper spellcheck_drug_norvig For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_2"
  },
  "1484": {
    "id": "1484",
    "title": "Spark OCR release notes",
    "content": "4.4.3 Release date: 33-06-2023 We are glad to announce that Visual NLP 😎 4.4.3 has been released. Highlights In line with our unwavering dedication to delivering top-notch products, Visual NLP is backed by our steadfast commitment to quality and stability. We have meticulously addressed various issues and introduced enhancements to ensure a seamless user experience. By diligently resolving bugs, improving error handling, and expanding functionality, we prioritize the reliability and robustness of Visual NLP. ImageToText Auxiliary Data Download Fix: Resolved an issue related to downloading auxiliary data in ImageToText, ensuring seamless data retrieval. Expanded DICOM Compression Algorithm Support: Introduced support for additional compression algorithms in the images returned by DicomDrawRegions, including, JPEGBaseline8Bit: 8-bit basic lossy JPEG encoding. JPEGLSLossless: lossless JPEG encoding. RLELossless: lossless run-length-encoding. You can change it by calling the API like this, DicomDrawRegions.setCompression() The default value is RLELossless. Serialization Error Fix in PositionFinder: Rectified a serialization error that previously existed in PositionFinder, resolving the issue encountered since version 4.3.2. Enhanced Exception Handling and Error Reporting in DICOM Transformers: Implemented improvements in exception handling and error reporting within DICOM transformers, resulting in enhanced stability and preventing unexpected crashes. Error information is now conveniently available in the ‘exception’ column. ImageToTextV2 Introduces ‘Positions’ Column: Expanded the capabilities of ImageToTextV2 to include a newly introduced ‘positions’ column, aligning it with similar functionality of ImageToText. The ‘positions’ column contains coordinates that are used to locate text in images and PDFs, and is consumed by annotators like PositionFinder. Resolved Path Error in DicomDrawRegions: Rectified a path error within DicomDrawRegions, ensuring its proper functionality. Among the functionalities affected was this notebook: SparkOcrDicomDeIdentification.ipynb Improved Matching Strategy in PositionFinder: PositionFinder now employs an advanced matching strategy to accurately identify the coordinates of entities, even in cases where spaces and newlines are present within the entity. We added a more complex example to showcase capabilities: SparkOcrPDFDeIdentification.ipynb ImageToPdf Preserves Input Columns: ImageToPdf has been enhanced to retain all input columns, preventing any loss of valuable data during the conversion process. This release is compatible with Spark NLP 4.4.4 and Spark NLP for Healthcare 4.4.3. Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_4_3",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_4_3"
  },
  "1485": {
    "id": "1485",
    "title": "Spark NLP for Healthcare Release Notes 4.4.3",
    "content": "4.4.3 Highlights We are delighted to announce a suite of remarkable enhancements and updates in our latest release of Spark NLP for Healthcare. This release comes with 30+ new clinical pretrained models and pipelines, and is a testament to our commitment to continuously innovate and improve, furnishing you with a more sophisticated and powerful toolkit for healthcare natural language processing. Newly introduced Arabic De-Identification NER models and pretrained pipelines New medical summarizer model fine-tuned with a custom dataset to minimize clinical jargon in laymen terms New Medical Summarizer Pretrained Pipelines that can be used in one line Updated ICD-10-CM resolver and chunk mapper models aligning with the latest updates in the ICD-10-CM terminology to ensure unparalleled accuracy in clinical coding. A new Voice of Patient (VOP) medical classifier model focusing on the side effect classification of treatments and procedures in patients’ own words. Enhanced Social Determinants of Health (SDOH) classifier models for detecting patients’ situation according to certain conditions (under treatment or not, suffering from housing insecurity) Introducing the innovative NerTemplateRender annotator to generate customized prompts for zero shot models. Sentence-wise token indexes now available in MedicalNerModel annotator We have also made fine-tuned improvements to core functionalities and corrected various bugs, enhancing the overall robustness and reliability of Spark NLP for Healthcare. Enhanced Gender Awareness feature: Our improved Gender Awareness feature now comes with an extended faker list, ensuring more comprehensive and accurate gender identification. Expanded English Faker Name List: We’ve broadened the range of our English Faker Name list, allowing for more diverse and inclusive data generation. Updated notebooks and demonstrations: We’re improving user experience with our updated notebooks and demonstrations, making Spark NLP for Healthcare easier to navigate and understand. The addition and update of numerous new clinical models and pipelines continue to reinforce our offering in the healthcare domain. We believe that these enhancements will elevate your experience with Spark NLP for Healthcare, enabling a more efficient, accurate, and streamlined analysis of healthcare-related natural language data. Newly Introduced Arabic De-Identification NER Models And Pretrained Pipelines We’re thrilled to present our newly-integrated Arabic deidentification Named Entity Recognition (NER) models, featuring two diverse approaches. The first model provides granular entity recognition with 17 entities, while the other offers a more generic approach, identifying 8 entities. These models are accompanied by corresponding pretrained pipelines that can be deployed in a streamlined one-liner format. Designed explicitly for deidentification tasks in Arabic language, these models and pipelines leverage our proprietary dataset curation and specialized augmentation methods. This expansion broadens the linguistic scope of our toolset, underscoring our commitment to providing comprehensive solutions for global healthcare NLP needs. NER model pipeline description predicted entities ner_deid_subentity ner_deid_subentity_pipeline This model/pipeline can detect protected health information (PHI) entities with 17 different labels. PATIENT, HOSPITAL, DATE, ORGANIZATION, CITY, STREET, USERNAME, SEX, IDNUM, EMAIL, ZIP, MEDICALRECORD, PROFESSION, PHONE, COUNTRY, DOCTOR, AGE ner_deid_generic ner_deid_generic_pipeline This model/pipeline can detect PHI entities with 8 different labels. CONTACT, NAME, DATE, ID, SEX, LOCATION, PROFESSION, AGE NER Model Example: clinical_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;ar&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) Pretrained Pipeline Examle: from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;ner_deid_generic_pipeline&quot;, &quot;ar&quot;, &quot;clinical/models&quot;) sample_text = &#39;&#39;&#39; عالج الدكتور محمد المريض أحمد البالغ من العمر 55 سنة في 15/05/2000 في مستشفى مدينة الرباط. رقم هاتفه هو 0610948235 وبريده الإلكتروني mohamedmell@gmail.com.&#39;&#39;&#39; Result: chunk ner_label محمد DOCTOR 55 سنة AGE 15/05/2000 DATE الرباط CITY 0610948235 PHONE mohamedmell@gmail.com EMAIL You can check the Multi Language Deidentification Notebook for more examples and see the NER DEMOGRAPHICS ARABIC demo. New Medical Summarizer Model Fine-Tuned With A Custom Dataset To Minimize Clinical Jargon In Laymen Terms We are delighted to announce the release of our summarizer_clinical_laymen model, a refined variant of our Flan-T5 (LLM) based summarization model. This model has been carefully fine-tuned with a custom dataset curated by John Snow Labs, expressly designed to minimize the use of clinical terminology in the generated summaries. The summarizer_clinical_laymen model is capable of producing summaries of up to 512 tokens from an input text of a maximum of 1024 tokens. This innovation embodies our commitment to providing user-friendly and accessible NLP solutions, making it easier for non-clinical personnel and patients to comprehend medical summaries without losing critical information. Example: summarizer = MedicalSummarizer.pretrained(&quot;summarizer_clinical_laymen&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(512) text = &quot;&quot;&quot;Jennifer was seen in my office for evaluation for elective surgical weight loss on October 6, 2008. ABC is a 34-year-old female with a BMI of 43. She is 5&#39;6&quot; tall and weighs 267 pounds. She is motivated to attempt surgical weight loss because she has been overweight for over 20 years and wants to have more energy and improve her self-image. She is not only affected physically, but also socially by her weight. When she loses weight she always regains it and she always gains back more weight than she has lost. At one time, she lost 100 pounds and gained the weight back within a year. She has tried numerous commercial weight loss programs including Weight Watcher&#39;s for four months in 1992 with 15-pound weight loss, RS for two months in 1990 with six-pound weight loss, Slim Fast for six weeks in 2004 with eight-pound weight loss, an exercise program for two months in 2007 with a five-pound weight loss, Atkin&#39;s Diet for three months in 2008 with a ten-pound weight loss, and Dexatrim for one month in 2005 with a five-pound weight loss. She has also tried numerous fat reduction or fad diets. She was on Redux for nine months with a 100-pound weight loss. n nPAST MEDICAL HISTORY: She has a history of hypertension and shortness of breath. n nPAST SURGICAL HISTORY: Pertinent for cholecystectomy. n nPSYCHOLOGICAL HISTORY: Negative. n nSOCIAL HISTORY: She is single. She drinks alcohol once a week. She does not smoke. n nFAMILY HISTORY: Pertinent for obesity and hypertension. n nMEDICATIONS: Include Topamax 100 mg twice daily, Zoloft 100 mg twice daily, Abilify 5 mg daily, Motrin 800 mg daily, and a multivitamin. n nALLERGIES: She has no known drug allergies. n nREVIEW OF SYSTEMS: Negative. n nPHYSICAL EXAM: This is a pleasant female in no acute distress. Alert and oriented x 3. HEENT: Normocephalic, atraumatic. Extraocular muscles intact, nonicteric sclerae. Chest is clear to auscultation bilaterally. Cardiovascular is normal sinus rhythm. Abdomen is obese, soft, nontender and nondistended. Extremities show no edema, clubbing or cyanosis. n nASSESSMENT/PLAN: This is a 34-year-old female with a BMI of 43 who is interested in surgical weight via the gastric bypass as opposed to Lap-Band. ABC will be asking for a letter of medical necessity from Dr. XYZ. She will also see my nutritionist and social worker and have an upper endoscopy. Once this is completed, we will submit her to her insurance company for approval.&quot;&quot;&quot; Result: This is a clinical note about a 34-year-old woman who is interested in having weight loss surgery. She has been overweight for over 20 years and wants to have more energy and improve her self-image. She has tried many diets and weight loss programs, but has not been successful in keeping the weight off. She has a history of hypertension and shortness of breath, but is not allergic to any medications. She will have an upper endoscopy and will be contacted by a nutritionist and social worker. The plan is to have her weight loss surgery through the gastric bypass rather than Lap-Band. New Medical Summarizer Pretrained Pipelines That Can Be Used In One Line We are excited to announce the launch of seven new medical summarizer pretrained pipelines. These novel pipelines have been specifically developed to enable streamlined execution in a succinct one-liner format, eliminating the need to construct verbose pipelines. model name description summarizer_biomedical_pubmed_pipeline Finetuned with biomedical datasets (Pubmed abstracts) by John Snow Labs summarizer_clinical_jsl_augmented_pipeline Finetuned with natural instructions and then finetuned with clinical notes, encounters, critical care notes, discharge notes, reports, curated by John Snow Labs summarizer_clinical_jsl_pipeline Summarize clinical notes, encounters, critical care notes, discharge notes, reports, etc. summarizer_clinical_questions_pipeline Finetuned with medical questions exchanged in clinical mediums (clinic, email, call center etc.) by John Snow Labs. It generates question summarizer_generic_jsl_pipeline Finetuned with additional data curated by John Snow Labs. This model is further optimized by augmenting the training methodology, and dataset. summarizer_radiology_pipeline Capable to summarizing radiology reports while preserving the important information such as imaging tests and findings. summarizer_clinical_guidelines_large_pipeline Finetuned to summarize clinical guidelines (only for Asthma and Breast Cancer as of now) into four different sections: Overview, Causes, Symptoms, Treatments. Example: from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;summarizer_clinical_guidelines_large_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;Clinical Guidelines for Breast Cancer: Breast cancer is the most common type of cancer among women. It occurs when the cells in the breast start growing abnormally, forming a lump or mass. This can result in the spread of cancerous cells to other parts of the body. Breast cancer may occur in both men and women but is more prevalent in women. The exact cause of breast cancer is unknown. However, several risk factors can increase your likelihood of developing breast cancer, such as: - A personal or family history of breast cancer - A genetic mutation, such as BRCA1 or BRCA2 - Exposure to radiation - Age (most commonly occurring in women over 50) - Early onset of menstruation or late menopause - Obesity - Hormonal factors, such as taking hormone replacement therapy Breast cancer may not present symptoms during its early stages. Symptoms typically manifest as the disease progresses. Some notable symptoms include: - A lump or thickening in the breast or underarm area - Changes in the size or shape of the breast - Nipple discharge - Nipple changes in appearance, such as inversion or flattening - Redness or swelling in the breast Treatment for breast cancer depends on several factors, including the stage of the cancer, the location of the tumor, and the individual&#39;s overall health. Common treatment options include: - Surgery (such as lumpectomy or mastectomy) - Radiation therapy - Chemotherapy - Hormone therapy - Targeted therapy Early detection is crucial for the successful treatment of breast cancer. Women are advised to routinely perform self-examinations and undergo regular mammogram testing starting at age 40. If you notice any changes in your breast tissue, consult with your healthcare provider immediately. &quot;&quot;&quot; Result: Overview of the disease: Breast cancer is the most common type of cancer among women, occurring when the cells in the breast start growing abnormally, forming a lump or mass. It can result in the spread of cancerous cells to other parts of the body. Causes: The exact cause of breast cancer is unknown, but several risk factors can increase the likelihood of developing it, such as a personal or family history, a genetic mutation, exposure to radiation, age, early onset of menstruation or late menopause, obesity, and hormonal factors. Symptoms: Symptoms of breast cancer typically manifest as the disease progresses, including a lump or thickening in the breast or underarm area, changes in the size or shape of the breast, nipple discharge, nipple changes in appearance, and redness or swelling in the breast. Treatment recommendations: Treatment for breast cancer depends on several factors, including the stage of the cancer, the location of the tumor, and the individual&#39;s overall health. Common treatment options include surgery, radiation therapy, chemotherapy, hormone therapy, and targeted therapy. Early detection is crucial for successful treatment of breast cancer. Women are advised to routinely perform self-examinations and undergo regular mammogram testing starting at age 40. Updated ICD-10-CM Resolver And Chunk Mapper Models Aligning With The Latest Updates In The ICD-10-CM Terminology To Ensure Unparalleled Accuracy In Clinical Coding. New and updated ICD-10-CM sentence entity resolver and chunk mapper models provide enhanced accuracy and comprehensive concept recognition for effective coding and medical condition classification. These models were trained based on the latest version of ICD-10-CM release (April 1, 2023). Here are the updated ICD-10-CM sentence entity resolver and chunk mapper models. model name type description icd10cm_mapper chunk mapper Maps medical entities with their corresponding ICD-10-CM codes. icd10cm_billable_hcc_mapper chunk mapper Maps ICD-10-CM codes with their corresponding billable and HCC scores. If there is no HCC score for the corresponding ICD-10-CM code, result will be returned as 0. sbiobertresolve_hcc_augmented resolver Maps medical entities to Hierarchical Condition Categories (HCC) codes using sbiobert_base_cased_mli Sentence Bert Embeddings. sbiobertresolve_icd10cm_augmented resolver Maps medical entities to ICD-10-CM codes using sbiobert_base_cased_mli Sentence Bert Embeddings. sbiobertresolve_icd10cm_augmented_billable_hcc resolver Maps medical entities to ICD-10-CM codes using sbiobert_base_cased_mli Sentence Bert Embeddings and it supports 7-digit codes with HCC status. sbiobertresolve_icd10cm_generalised_augmented resolver Maps medical entities to ICD-10-CM codes using sbiobert_base_cased_mli Sentence Bert Embeddings. It predicts ICD-10-CM codes up to 3 characters (according to ICD-10-CM code structure the first three characters represent general type of the injury or disease). sbiobertresolve_icd10cm_slim_billable_hcc resolver Maps medical entities to ICD-10-CM codes using sbiobert_base_cased_mli Sentence Bert Embeddings and it supports 7-digit codes with HCC status. In this model, synonyms having low cosine similarity to unnormalized terms are dropped. sbertresolve_icd10cm_slim_billable_hcc resolver Maps medical entities to ICD-10-CM codes using sbert_jsl_medium_uncased Sentence Bert Embeddings and it supports 7-digit codes with HCC status. In this model, synonyms having low cosine similarity to unnormalized terms are dropped. sbertresolve_icd10cm_augmented_billable_hcc resolver maps clinical entities and concepts to ICD-10-CM codes using sbert_jsl_medium_uncased sentence bert embeddings and it supports 7-digit codes with HCC status. It also returns the official resolution text within the brackets inside the metadata. sbertresolve_icd10cm_augmented resolver Maps medical entities and concepts to ICD-10-CM codes using sbert_jsl_medium_uncased sentence bert embeddings. It also returns the official resolution text within the brackets inside the metadata. Mapper Example: chunkMapper= ChunkMapperModel().pretrained(&quot;icd10cm_billable_hcc_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;billable&quot;, &quot;hcc_score&quot;]) .setLowerCase(True) .setMultivaluesRelations(True) sample_icd_codes= [&quot;D66&quot;, &quot;S22.00&quot;, &quot;Z3A.10&quot;] Result: icd10cm_code billable hcc_score D66 1 46 S22.00 0 0 Z3A.10 1 0 Resolver Example: icd_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_augmented_billable_hcc&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) sample_text = &quot;The patient has a gestational diabetes mellitus history and subsequent type two diabetes mellitus, associated with obesity, presented with a one-week history of poor appetite, and vomiting.&quot; Result: ner_chunk icd10cm_code resolution billable_status hcc_status hcc_score gestational diabetes mellitus O24.4 gestational diabetes mellitus [gestational diabetes mellitus] 0 0 0 subsequent type two diabetes mellitus O24.11 pre-existing type 2 diabetes mellitus [pre-existing type 2 diabetes mellitus] 0 0 0 obesity E66.9 obesity [obesity, unspecified] 1 0 0 poor appetite R63.0 poor appetite [anorexia] 1 0 0 vomiting R11.1 vomiting [vomiting] 0 0 0 A New Voice Of Patient (VOP) Medical Classifier Model Focusing On The Side Effect Classification Of Treatments And Procedures In Patients’ Own Words We have a new VOP classification model that classifies the patients’ expressions in order to determine if they make any references to the side effects associated with medical treatments or procedures. bert_sequence_classifier_vop_side_effect: This model is a BioBERT based classifier that classifies texts written by patients as True if side effects from treatments or procedures are mentioned. Example: sequenceClassifier = MedicalBertForSequenceClassification .pretrained(&quot;bert_sequence_classifier_vop_side_effect&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&#39;token&#39;]) .setOutputCol(&quot;prediction&quot;) Result: text result I felt kind of dizzy after taking that medication for a month. True I had a dental procedure last week and everything went well. False Enhanced Social Determinants Of Health (SDOH) Classifier Models For Detecting Patients’ Situation According To Certain Conditions (Under Treatment Or Not, Suffering From Housing Insecurity) We have updated SDOH classification models to offer improved accuracy. genericclassifier_sdoh_under_treatment_sbiobert_cased_mli: This Generic Classifier model is intended for detecting if the patient is under treatment or not. If under treatment is not mentioned in the text, it is regarded as “Not_Under_Treatment_Or_Not_Mentioned”. The model is trained by using GenericClassifierApproach annotator. Under_Treatment: The patient is under treatment. Not_Under_Treatment_Or_Not_Mentioned: The patient is not under treatment or it is not mentioned in the clinical notes Example: generic_classifier = GenericClassifierModel .pretrained(&quot;genericclassifier_sdoh_under_treatment_sbiobert_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) text_list = [&quot;Patient is a 50-year-old male who was diagnosed with hepatitis C. He has received a treatment plan that includes medication and regular monitoring of his liver function.&quot;, &quot;Patient has been living with chronic migraines for several years. She has not pursued any specific treatment for her migraines and has been managing her condition through lifestyle modifications such as stress reduction techniques and avoiding triggers.&quot;] Result: text result Patient is a 50-year-old male who was diagnosed with hepatitis C. He has received a treatment pla… Under_Treatment Patient has been living with chronic migraines for several years. She has not pursued any specifi… Not_Under_Treatment_Or_Not_Mentioned genericclassifier_sdoh_housing_insecurity_sbiobert_cased_mli: This Generic Classifier model is intended for detecting whether the patient has housing insecurity. If the clinical note includes patient housing problems, the model identifies it. If there is no housing issue or it is not mentioned in the text, it is regarded as “no housing insecurity”. The model is trained by using GenericClassifierApproach annotator. Housing_Insecurity: The patient has housing problems. No_Housing_Insecurity_Or_Not_Mentioned: The patient has no housing problems or it is not mentioned in the clinical notes. Example: generic_classifier = GenericClassifierModel .pretrained(&quot;genericclassifier_sdoh_housing_insecurity_sbiobert_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) text_list = [ &quot;Patient is a 50-year-old male who no has stable housing. He recently underwent a hip replacement surgery and has made a full recovery. &quot;, &quot;Patient is a 25-year-old female who has her private housing. She presented with symptoms of a urinary tract infection and was diagnosed with the condition. Her living situation has allowed her to receive prompt medical care and treatment, and she has made a full recovery. &quot;] Result: text result Patient is a 50-year-old male who no has stable housing. He recently underwent a hip replacement … Housing_Insecurity Patient is a 25-year-old female who has her private housing. She presented with symptoms of a uri… No_Housing_Insecurity_Or_Not_Mentioned Introducing The Innovative Nertemplaterender Annotator To Generate Customized Prompts For Zero Shot Models The New Annotator NerTemplateRender function is designed to render templates by permuting chunks of text when there is an excess of text available to fill the template. This annotator provides flexibility in rendering templates by permuting, combining, and resampling chunks of text based on the specified options, ensuring efficient utilization of available text resources. It provides several options for customizing the rendering process, here are the parameters: setTemplates: Sets The list of scope fields to consider when making entity tuples to render the templates. “ + “The scope fields are the metadata keys containing the scope index or name for each chunk. “ + “i.e. sentence, paragraph, section … setPermuteEntities: Sets True if you want to permute chunks when the text has more than enough to fill the template, generating even more outputs. Overrides combineEntities setCombineEntities: “Sets True if you want to combine chunks when the text has more than enough to fill the template, generating more outputs setResampleEntities: Sets True if you want to resample entities from texts that do not have enough chunks to fill a template Example: NerTemplateRender = NerTemplateRenderModel() .setInputCols(&quot;chunk_deid&quot;) .setOutputCol(&quot;templates&quot;) .setTemplates([&quot;When ?&quot;, &quot;What medication did prescribe for ?&quot;, &quot;Which hospital was admitted to for ?&quot;, &quot;Why were admitted to on by ?&quot; ]) .setPermuteEntities(True) .setResampleEntities(True) data = spark.createDataFrame([ [&quot;John Smith was admitted Sep 3rd to Mayo Clinic&quot;], [&quot;Dr. David pescribed metformin 500mg for my severe headache.&quot;], [&quot;Olivia was admitted to the Memorial Hospital for her colon cancer.&quot;], [&quot;27 years old Anne was admitted to clinic on Sep 1st by Dr. Jennifer for a right-sided pleural effusion for thoracentesis.&quot;]].toDF(&quot;text&quot;) Result: result template When John Smith admitted ? 1 What medication did David prescribe for my severe headache? 2 Which hospital was Olivia admitted to for her colon cancer? 3 When Olivia admitted ? 1 Which hospital was Anne admitted to for a right-sided pleural effusion? 3 What medication did Jennifer prescribe for a right-sided pleural effusion? 2 Why were Anne admitted to clinic on Sep 1st by Jennifer? 4 When Anne admitted ? 1 Sentence-Wise Token Indexes Are Now Avaliable In MedicalNerModel Annotator The MedicalNerModel now includes a new parameter called setSentenceTokenIndex which allows you to obtain the token index at the sentence level. This parameter provides a convenient way to retrieve the specific token index associated with each sentence in the medical text. By using this parameter, you can easily identify and locate tokens within a sentence, enabling more granular analysis and processing of medical text data. Example: clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) .setSentenceTokenIndex(True) sample_text = &quot;&quot;&quot;He had a nonproductive cough that started last week. He had chest pain with a fever since yesterday.&quot;&quot;&quot; Result: token ner_label confidence sentence_token_index sentence He O 0.9999 0 0 had O 0.9996 1 0 a B-PROBLEM 0.9406 2 0 nonproductive I-PROBLEM 0.9605 3 0 cough I-PROBLEM 0.9872 4 0 that O 0.9559 5 0 started O 0.9945 6 0 last O 0.9863 7 0 week O 0.4276 8 0 . O 0.9999 9 0 He O 0.9998 0 1 had O 0.9988 1 1 chest B-PROBLEM 0.9978 2 1 pain I-PROBLEM 0.9974 3 1 with O 0.9998 4 1 a B-PROBLEM 0.9527 5 1 fever I-PROBLEM 0.9907 6 1 since O 0.9999 7 1 yesterday O 0.9176 8 1 . O 0.9999 9 1 We Have Also Made Fine-Tuned Improvements To Core Functionalities And Corrected Various Bugs, Enhancing The Overall Robustness And Reliability Of Spark Nlp For Healthcare Enhanced Gender Awareness feature: Our improved Gender Awareness feature now comes with an extended faker list, ensuring more comprehensive and accurate gender identification. Expanded English Faker Name List: We’ve broadened the range of our English Faker Name list, allowing for more diverse and inclusive data generation. Updated Notebooks And Demonstrations: We’Re Improving User Experience With Our Updated Notebooks And Demonstrations, Making Spark Nlp For Healthcare Easier To Navigate And Understand Updated Multi Language Deidentification Notebook notebook for lastest models New MEDICAL SUMMARIZATION GUIDELINES demo New DEID CONSISTENCY demo New NER DEMOGRAPHICS ARABIC demo We Have Added And Updated A Substantial Number Of New Clinical Models And Pipelines, Further Solidifying Our Offering In The Healthcare Domain. summarizer_clinical_laymen bert_sequence_classifier_vop_side_effect ner_deid_subentity -&gt; ar ner_deid_generic -&gt; ar ner_deid_subentity_pipeline -&gt; ar ner_deid_generic_pipeline -&gt; ar summarizer_radiology_pipeline summarizer_generic_jsl_pipeline summarizer_clinical_jsl_pipeline summarizer_biomedical_pubmed_pipeline summarizer_clinical_questions_pipeline summarizer_clinical_jsl_augmented_pipeline summarizer_clinical_guidelines_large_pipeline icd10cm_billable_hcc_mapper icd10cm_mapper sbiobertresolve_hcc_augmented sbiobertresolve_icd10cm_augmented sbiobertresolve_icd10cm_augmented_billable_hcc sbiobertresolve_icd10cm_generalised_augmented sbiobertresolve_icd10cm_slim_billable_hcc sbertresolve_icd10cm_augmented sbertresolve_icd10cm_augmented_billable_hcc sbertresolve_icd10cm_slim_billable_hcc genericclassifier_sdoh_under_treatment_sbiobert_cased_mli genericclassifier_sdoh_housing_insecurity_sbiobert_cased_mli ner_ade_emb_clinical_large ner_ade_emb_clinical_medium ner_cellular_emb_clinical_large ner_cellular_emb_clinical_medium ner_bacterial_species_emb_clinical_large ner_bacterial_species_emb_clinical_medium For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_3"
  },
  "1486": {
    "id": "1486",
    "title": "Spark OCR release notes",
    "content": "4.4.4 Release date: 02-08-2023 We are glad to announce that Visual NLP 4.4.4 😎 has been released! This release includes a wide array of new features and bug fixes. Our dedication to maintaining stability and upholding quality remains unwavering, and this update reflects our commitment to enhancing your experience. Lilt based Visual Ner Fine-Tuning: we are adding fine tuning capabilities to our Lilt-based Visual NER models. Use NLP Lab or any other source to create your data, and quickly get new models. For an end-to-end example check this notebook. ImageTextDetector has been refactored to provide a fully JVM implementation with the same capabilities of ImageToTextV2 transformer. It includes an optimized ONNX version of the CRAFT model with a refiner network. To use this new implementation, you can call it almost exactly as ImageToTextV2, textDetector = ImageTextDetector .pretrained(&quot;image_text_detector_opt&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;region&quot;) .setWidth(500) The accuracy is almost the same as that of ImageTextDetectorV2. We will continue to improve the performance, memory consumption, and accuracy of this model, and eventually deprecate ImageTextDetectorV2. Check this sample notebook for an end-to-end example. PdfToText support for handling ligatures: ligatures are special characters that represent more than one glyph like ‘ffi’ or ‘fl’, which are used to prettify the rendering in some PDFs. The new PdfToText.setNormalizeLigatures(Boolean) will determine whether ligatures are expanded into two or more characters when returned in the ‘positions’ column. Default value is true(ligatures will be expanded). Among other things, this helps the process of matching entities to coordinates in PositionFinder. PositionFinder has an improved matching strategy to map entities to coordinates that prevents entities from remaining unmapped in many situations. Also, error reporting has been improved, making it clear in the logs when for some reason an entity couldn’t be located in the document, and coordinates were not returned. Bug Fixes &amp; Improvements Serialization problems in ImageDrawRegions and ImageDrawAnnotations were fixed. Some dependencies have been upgraded to newer versions to maintain . Improved exception handling in DicomDrawRegions(duplicated exceptions) &amp; ImageTextDetectorV2(crash). This release is compatible with Spark-NLP 4.4.4 and Spark-NLP for Healthcare 4.4.3 Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_4_4",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_4_4"
  },
  "1487": {
    "id": "1487",
    "title": "Spark NLP for Healthcare Release Notes 4.4.4",
    "content": "4.4.4 Highlights We are delighted to announce a suite of remarkable enhancements and updates in our latest release of Spark NLP for Healthcare. This release comes with 40+ new clinical pretrained models and pipelines, and is a testament to our commitment to continuously innovate and improve, furnishing you with a more sophisticated and powerful toolkit for healthcare natural language processing. Enhanced PySpark v3.4.X support for advanced Natural Language Processing New module focused on extracting the most relevant information with Extractive Summarization Customized prompts in TextGenerator Annotator Arabic language obfuscation support in Deidentification One liner Arabic language Clinical Deidentification Pipeline 36 New Voice of Patient (VOP) NER models and pipelines for entity extraction from patient’s own words (usually in non-medical jargon) New BioBERT-based VOP Classification Models for classifying certain tones (if HCP consult, medically sound, mention of ADE, self-reported etc.) in patient’s own words Enhanced entity detection accuracy with the official version of Social Determinants of Health (SDOH) model New NER model for precise detection of demographic characteristics in clinical notes Updated Medicare Risk Adjustment score calculation module incorporating CMS’s latest proposed updates including the Version 28 support New Resources Downloader Notebook that includes comprehensive guideline for model downloading Pretrained pipelines now compatible with all PySpark versions Various core improvements; bug fixes, enhanced overall robustness and reliability of Spark NLP for Healthcare Updated notebooks and demonstrations for making Spark NLP for Healthcare easier to navigate and understand The addition and update of numerous new clinical models and pipelines continue to reinforce our offering in the healthcare domain We believe that these enhancements will elevate your experience with Spark NLP for Healthcare, enabling more efficient, accurate, and streamlined analysis of healthcare-related natural language data. Enhanced PySpark v3.4.X Support for Advanced Natural Language Processing SparkNLP, now offers enhanced support for PySpark v3.4, enabling data scientists and NLP practitioners to leverage the latest features and capabilities of Apache Spark while working with text data. New Module Focused On Extracting The Most Relevant Information With Extractive Summarization Extractive summarization focuses on extracting the most relevant information rather than generating new content. The process typically includes preprocessing the text, identifying important sentences using various criteria, ranking them based on their importance, and selecting the top-ranked sentences for the final summary. Extractive summarization is favored for its objectivity, preserving the factual accuracy of the original text. Parameters: similarityThreshold: Sets the minimal cosine similarity between sentences to consider them similar. summarySize: Sets the number of sentences to summarize the text Example: sentence_embeddings = BertSentenceEmbeddings() .pretrained(&quot;sent_small_bert_L2_128&quot;) .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) summarizer = ExtractiveSummarization() .setInputCols([&quot;sentences&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;summaries&quot;) .setSummarySize(2) .setSimilarityThreshold(0) text = &quot;&quot;&quot;Residual disease after initial surgery for ovarian cancer is the strongest prognostic factor for survival. However, the extent of surgical resection required to achieve optimal cytoreduction is controversial. Our goal was to estimate the effect of aggressive surgical resection on ovarian cancer patient survival. A retrospective cohort study of consecutive patients with International Federation of Gynecology and Obstetrics stage IIIC ovarian cancer undergoing primary surgery was conducted between January 1, 1994, and December 31, 1998. The main outcome measures were residual disease after cytoreduction, frequency of radical surgical resection, and 5-year disease-specific survival. The study comprised 194 patients, including 144 with carcinomatosis. The mean patient age and follow-up time were 64.4 and 3.5 years, respectively. After surgery, 131 (67.5%) of the 194 patients had less than 1 cm of residual disease (definition of optimal cytoreduction). Considering all patients, residual disease was the only independent predictor of survival; the need to perform radical procedures to achieve optimal cytoreduction was not associated with a decrease in survival. For the subgroup of patients with carcinomatosis, residual disease and the performance of radical surgical procedures were the only independent predictors. Disease-specific survival was markedly improved for patients with carcinomatosis operated on by surgeons who most frequently used radical procedures compared with those least likely to use radical procedures (44% versus 17%, P &lt; .001). Overall, residual disease was the only independent predictor of survival. Minimizing residual disease through aggressive surgical resection was beneficial, especially in patients with carcinomatosis.&quot;&quot;&quot; Result: &#39;The main outcome measures were residual disease after cytoreduction, frequency of radical surgical resection, and 5-year disease-specific survival. nThe study comprised 194 patients, including 144 with carcinomatosis.&#39;, &#39;Considering all patients, residual disease was the only independent predictor of survival; the need to perform radical procedures to achieve optimal cytoreduction was not associated with a decrease in survival. For the subgroup of patients with carcinomatosis, residual disease and the performance of radical surgical procedures were the only independent predictors.&#39; See Extractive Summarization Notebook for examples. Customized Prompts in TextGenerator Annotator The MedicalTextGenerator() function incorporates a powerful feature called SetCustomPrompt, designed to enhance text generation capabilities. By utilizing this feature, users can input a custom prompt, typically in the format of “question: {DOCUMENT} answer:”. This structure allows for the generation of informative and contextually relevant medical text responses. This feature enhances the flexibility and usability of the MedicalTextGenerator() function, empowering users to generate accurate and contextually appropriate medical text with ease. Example: gpt_qa = MedicalTextGenerator().pretrained(&quot;biogpt_chat_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(299) .setStopAtEos(True) .setDoSample(False) .setTopK(3) .setRandomSeed(42) .setCustomPrompt(&quot;question: {DOCUMENT} answer:&quot;) text = &quot;What medications are commonly used to treat emphysema?&quot; Result: question: What medications are commonly used to treat emphysema ? answer: Hello, There are two types of medications to treat emphysema: 1. Alpha agonists ( like albuterol or albuterol / levosalbutamol ) are used to treat symptoms of shortness of breath ( SOB ) and tightness in the chest ( tightness in chest ). These meds cause a mild to moderate increase in heart rate ( tachycardia ). 2. Beta blockers ( like propranolol or metoprolol ) are used to treat or to prevent symptoms of heart failure ( ejection fraction is 20 % or less ). These medications cause or worsen shortness of breath, tightness in chest, heart rate. You can take a combination of these medications. The combination that you will work best is a two - pill combination of albuterol and propranolol ( half tablet twice a day ). This will reduce or eliminate the need for albuterol and albuterol / levosalbutamol in your case. The other medications are used in consultation with your physician. See Medical Text Generation Notebook for examples. One Liner Arabic Language Clinical Deidentification Pipeline We’re thrilled to announce that Spark NLP for Healthcare now supports obfuscation in Arabic De-identification (Deid) models. This feature enhances data privacy by substituting sensitive Protected Health Information (PHI) with corresponding synthetic data, while preserving data integrity through observance of certain consistency rules. Example: deid_masked_entity = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;masked_with_entity&quot;) .setMode(&quot;mask&quot;) .setLanguage(&#39;ar&#39;) .setMaskingPolicy(&quot;entity_labels&quot;) deid_masked_char = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;masked_with_chars&quot;) .setMode(&quot;mask&quot;) .setLanguage(&#39;ar&#39;) .setMaskingPolicy(&quot;same_length_chars&quot;) deid_masked_fixed_char = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;masked_fixed_length_chars&quot;) .setMode(&quot;mask&quot;) .setLanguage(&#39;ar&#39;) .setMaskingPolicy(&quot;fixed_length_chars&quot;) .setFixedMaskLength(4) obfuscation = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;obfuscated&quot;) .setMode(&quot;obfuscate&quot;) .setLanguage(&#39;ar&#39;) .setObfuscateDate(True) .setObfuscateRefSource(&quot;faker&quot;) .setRegexOverride(True) text = &#39;&#39;&#39; الملاحظات السريرية - مريض السكري التاريخ: 11 مايو 1999 اسم المريض: فاطمة علي العنوان: شارع الحرية ، حي السلام ، القاهرة دولة: مصر اسم المستشفى: مستشفى الشفاء اسم الطبيب: د.محمد صلاح &#39;&#39;&#39; Result:   original sentence Masked Masked with Chars Masked with Fixed Chars Obfuscated 0 الملاحظات السريرية - مريض السكري الملاحظات السريرية - مريض السكري الملاحظات السريرية - مريض السكري الملاحظات السريرية - مريض السكري الملاحظات السريرية - مريض السكري 1 التاريخ: 11 مايو 1999 التاريخ: [تاريخ] التاريخ: [٭٭٭٭٭٭٭٭٭٭] التاريخ: ٭٭٭٭ التاريخ: 11 يوليو 1999 2 اسم المريض: فاطمة علي اسم المريض: [الاسم] اسم المريض: [٭٭٭٭٭٭٭] اسم المريض: ٭٭٭٭ اسم المريض: رياض محروق 3 العنوان: شارع الحرية ، حي السلام ، القاهرة العنوان: شارع الحرية ، حي [الموقع] ، [الموقع] العنوان: شارع الحرية ، حي [٭٭٭٭] ، [٭٭٭٭٭] العنوان: شارع الحرية ، حي ٭٭٭٭ ، ٭٭٭٭ العنوان: شارع الحرية ، حي شارع الجنوب أفريقي ، شارع التقدم 4 دولة: مصر دولة: [الموقع] دولة: [٭] دولة: ٭٭٭٭ دولة: الشارع الأسفلتي 5 اسم المستشفى: مستشفى الشفاء اسم المستشفى: مستشفى الشفاء اسم المستشفى: مستشفى الشفاء اسم المستشفى: مستشفى الشفاء اسم المستشفى: مستشفى الشفاء 6 اسم الطبيب: د.محمد صلاح اسم الطبيب: [الاسم] اسم الطبيب: [٭٭٭٭٭٭٭٭٭] اسم الطبيب: ٭٭٭٭ اسم الطبيب: ليث مصري See Clinincal Multi Language Deidentification Notebook for examples. New Arabic Clinical Deidentification Pipeline This pipeline can be used to deidentify Arabic PHI information from medical texts in one one liner to ease the process of building the entire pipeline one by one. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate CONTACT, NAME, DATE, ID, LOCATION, AGE, PATIENT, HOSPITAL, ORGANIZATION, CITY, STREET, USERNAME, SEX, IDNUM, EMAIL, ZIP, MEDICALRECORD, PROFESSION, PHONE, COUNTRY, DOCTOR, SSN, ACCOUNT, LICENSE, DLN and VIN. Example: from sparknlp.pretrained import PretrainedPipeline deid_pipeline_ar = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;ar&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot; ملاحظات سريرية - مريض الربو: التاريخ: 30 مايو 2023 اسم المريضة: ليلى حسن تم تسجيل المريض في النظام باستخدام رقم الضمان الاجتماعي 123456789012. العنوان: شارع المعرفة، مبنى رقم 789، حي الأمانة، جدة الرمز البريدي: 54321 البلد: المملكة العربية السعودية اسم المستشفى: مستشفى النور اسم الطبيب: د. أميرة أحمد &quot;&quot;&quot; Result:   Sentence masked_with_entity Masked with Chars Masked with Fixed Chars Obfuscated 0 ملاحظات سريرية - مريض الربو: nالتاريخ: 30 مايو 2023 ملاحظات سريرية - مريض الربو: nالتاريخ: [تاريخ] [تاريخ] ملاحظات سريرية - مريض الربو: nالتاريخ: [٭٭٭٭٭] [٭٭] ملاحظات سريرية - مريض الربو: nالتاريخ: ٭٭٭٭ ٭٭٭٭ ملاحظات سريرية - مريض الربو: nالتاريخ: 30 يونيو 2024 1 اسم المريضة: ليلى حسن اسم المريضة: [المريض] اسم المريضة: [٭٭٭٭٭٭] اسم المريضة: ٭٭٭٭ اسم المريضة: أدهم جبالي 2 تم تسجيل المريض في النظام باستخدام رقم الضمان الاجتماعي 123456789012. تم تسجيل المريض في النظام باستخدام رقم الضمان الاجتماعي [هاتف]. تم تسجيل المريض في النظام باستخدام رقم الضمان الاجتماعي [٭٭٭٭٭٭٭٭٭٭]. تم تسجيل المريض في النظام باستخدام رقم الضمان الاجتماعي ٭٭٭٭. تم تسجيل المريض في النظام باستخدام رقم الضمان الاجتماعي 963525347201. 3 العنوان: شارع المعرفة، مبنى رقم 789، حي الأمانة، جدة العنوان: شارع المعرفة، مبنى رقم [الرمز البريدي] [المدينة] [المدينة] العنوان: شارع المعرفة، مبنى رقم [٭٭] [٭٭٭٭٭٭٭٭٭] [٭] العنوان: شارع المعرفة، مبنى رقم ٭٭٭٭ ٭٭٭٭ ٭٭٭٭ العنوان: شارع المعرفة، مبنى رقم 160، كلميم سانت كاترين 4 الرمز البريدي: 54321 الرمز البريدي: [الرمز البريدي] الرمز البريدي: [٭٭٭] الرمز البريدي: ٭٭٭٭ الرمز البريدي: 79915 5 البلد: المملكة العربية السعودية البلد: [المدينة] [البلد] البلد: [٭٭٭٭٭٭٭٭٭٭٭٭٭] [٭٭٭٭٭٭] البلد: ٭٭٭٭ ٭٭٭٭ البلد: زغوان الغربية أوزبكستان 6 اسم المستشفى: مستشفى النور اسم المستشفى: [الموقع] اسم المستشفى: [٭٭٭٭٭٭٭٭٭٭] اسم المستشفى: ٭٭٭٭ اسم المستشفى: شارع المدارس 7 اسم الطبيب: د. أميرة أحمد اسم الطبيب: د. [دكتور] اسم الطبيب: د. [٭٭٭٭٭٭٭٭] اسم الطبيب: د. ٭٭٭٭ اسم الطبيب: د. هندية قبلاوي See Clinincal Multi Language Deidentification Notebook for examples. 36 New Voice Of Patient (VOP) NER Models And Pipelines For Entity Extraction From Patient’s Own Words We are excited to introduce our new NER models which extract clinical entities from the documents that are shared by patients in their own words. model_name description predicted_entity ner_vop_anatomy_emb ner_vop_anatomy_emb_clinical_medium ner_vop_anatomy_emb_clinical_large ner_vop_anatomy_pipeline Extracts anatomical terms from the documents transferred from the patient’s own sentences. BodyPart, Laterality ner_vop_clinical_dept ner_vop_clinical_dept_emb_clinical_medium ner_vop_clinical_dept_emb_clinical_large ner_vop_clinical_dept_pipeline Extracts medical devices and clinical department mentions terms from the documents transferred from the patient’s own sentences. AdmissionDischarge, ClinicalDept, MedicalDevice ner_vop_demographic ner_vop_demographic_emb_clinical_medium ner_vop_demographic_emb_clinical_large ner_vop_demographic_pipeline Extracts demographic terms from the documents transferred from the patient’s own sentences. Gender, Employment, RaceEthnicity, Age, Substance, RelationshipStatus, SubstanceQuantity ner_vop_problem ner_vop_problem_emb_clinical_medium ner_vop_problem_emb_clinical_large ner_vop_problem_pipeline Extracts clinical problems from the documents transferred from the patient’s own sentences using a granular taxonomy. PsychologicalCondition, Disease, Symptom, HealthStatus, Modifier, InjuryOrPoisoning ner_vop_test ner_vop_test_emb_clinical_medium ner_vop_test_emb_clinical_large ner_vop_test_pipeline Extracts test mentions from the documents transferred from the patient’s own sentences. VitalTest, Test, Measurements, TestResult ner_vop_temporal ner_vop_temporal_emb_clinical_medium ner_vop_temporal_emb_clinical_large_final ner_vop_temporal_pipeline Extracts temporal references from the documents transferred from the patient’s own sentences. DateTime, Frequency, Duration ner_vop_treatment ner_vop_treatment_emb_clinical_medium ner_vop_treatment_emb_clinical_large ner_vop_treatment_pipeline Extracts treatments mentioned in documents transferred from the patient’s own sentences. Drug, Form, Dosage, Frequency, Route, Duration, Procedure, Treatment ner_vop ner_vop_emb_clinical_medium ner_vop_emb_clinical_large ner_vop_pipeline Extracts healthcare-related terms from the documents transferred from the patient’s own sentences. Gender, Employment, Age, BodyPart, Substance, Form, PsychologicalCondition, Vaccine, Drug, DateTime, ClinicalDept, Laterality, Test, AdmissionDischarge, Disease, VitalTest, Dosage, Duration, RelationshipStatus, Route, Allergen, Frequency, Symptom, Procedure, HealthStatus, InjuryOrPoisoning, Modifier, Treatment, SubstanceQuantity, MedicalDevice, TestResult ner_vop_problem_reduced ner_vop_problem_reduced_emb_clinical_medium ner_vop_problem_reduced_emb_clinical_large ner_vop_problem_reduced_pipeline Extracts clinical problems from the documents transferred from the patient’s own sentences. The taxonomy is reduced (one label for all clinical problems). Problem, HealthStatus, Modifier Example: ner = MedicalNerModel.pretrained(&quot;ner_vop&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;&quot;&quot;Hello,I&#39;m 20 year old girl. I&#39;m diagnosed with hyperthyroid 1 month ago. I was feeling weak, light headed,poor digestion, panic attacks, depression, left chest pain, increased heart rate, rapidly weight loss, from 4 months. Because of this, I stayed in the hospital and just discharged from hospital.&quot;&quot;&quot; Result: chunk ner_label 20 year old Age girl Gender hyperthyroid Disease 1 month ago DateTime weak Symptom light Symptom panic attacks PsychologicalCondition depression PsychologicalCondition left Laterality chest BodyPart pain Symptom increased TestResult heart rate VitalTest rapidly Modifier weight loss Symptom 4 months Duration hospital ClinicalDept discharged AdmissionDischarge For all Voice of Patient models, please check: Models Hub Page New BioBERT-Based VOP Classification Models for Biomedical Text Analysis We are excited to introduce a new Bert-based Voice of Patient classifier models which are a collection of BioBERT-based classifiers designed for various text classification tasks in the biomedical domain. These models leverage the power of BERT, a transformer-based language model, to analyze and classify different types of textual data. They are trained to understand the nuances of medical language and concepts to make accurate predictions. modelname description pred_entity bert_sequence_classifier_vop_drug_side_effect bert_sequence_classifier_vop_drug_side_effect_pipeline Classify informal texts (such as tweets or forum posts) according to the presence of drug side effects. Drug_AE, Other bert_sequence_classifier_vop_hcp_consult bert_sequence_classifier_vop_hcp_consult_pipeline Identify texts that mention a HCP consult. Consulted_By_HCP, Other bert_sequence_classifier_vop_self_report bert_sequence_classifier_vop_self_report_pipeline Classify texts depending on if they are self-reported or if they refer to another person. 1st_Person, 3rd_Person bert_sequence_classifier_vop_sound_medical bert_sequence_classifier_vop_sound_medical_pipeline Identify whether the suggestion that is mentioned in the text is medically sound. True, False Example: sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_vop_sound_medical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&#39;token&#39;]) .setOutputCol(&quot;prediction&quot;) sample_texts = [&quot;I had a lung surgery for emphyema and after surgery my xray showing some recovery.&quot;, &quot;I was advised to put honey on a burned skin.&quot;] Result: text result My friend was treated for her skin cancer two years ago. 3rd_Person I started with dysphagia in 2021, then, a few weeks later, felt weakness in my legs, followed by a severe diarrhea. 1st_Person Enhanced Entity Detection Accuracy With The Official Version Of Social Determinants Of Health (SDOH) Model We are excited to introduce a new model that specializes in identifying social determinants of health (SDOH) mentions. This model accurately recognizes instances where SDOH characteristics, including Access_To_Care, Community_Safety, Education, Food_Insecurity, Insurance_Status, and more entities are referenced. Its advanced capabilities provide valuable insights for SDOH-related analyses and applications. Example: ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_texts = &quot;&quot;&quot;Smith is living in New York, a divorced Mexcian American woman. She has recently been experiencing frequent hospitalizations due to uncontrolled blood sugar levels. Smith works as a cleaning assistant and cannot access health insurance or paid sick leave. Pt with likely long-standing depression.She has a long history of etoh abuse, beginning in her teens. She has been a daily drinker for 30 years. She had DUI in April and was due to court this week.&quot;&quot;&quot; Result:   chunks begin end entities 0 New York 20 27 Geographic_Entity 1 divorced 32 39 Marital_Status 2 Mexcian American 41 56 Race_Ethnicity 3 woman 58 62 Gender 4 She 65 67 Gender 5 hospitalizations 109 124 Other_SDoH_Keywords 6 cleaning assistant 183 200 Employment 7 health insurance 220 235 Insurance_Status 8 depression 286 295 Mental_Health 9 She 297 299 Gender 10 etoh abuse 323 332 Alcohol 11 her 348 350 Gender 12 teens 352 356 Age 13 She 359 361 Gender 14 daily 374 378 Substance_Frequency 15 drinker 380 386 Alcohol 16 30 years 392 399 Substance_Duration 17 She 402 404 Gender 18 DUI 410 412 Legal_Issues See Models Hub Page for more details. New NER Model For Precise Detection Of Demographic Characteristics In Clinical Notes This new model identifies healthcare mentions that refer to a situation where a patient’s demographic characteristics, such as race, ethnicity, gender, age, socioeconomic status, or geographic location. Example: ner = MedicalNerModel.pretrained(&quot;ner_demographic_extended_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;&quot;&quot;Patient Information: Gender: Non-binary Age: 68 years old Race: Black Employment status: Retired Marital Status: Divorced Sexual Orientation: Asexual Religion: Judaism Body Mass Index: 29.1 Unhealthy Habits: Substance use Socioeconomic Status: Low Income Area of Residence: Rural setting Disability Status: Blindness Chief Complaint: The patient presented to the emergency department with complaint of severe chest pain that started suddenly while asleep. &quot;&quot;&quot; Result: chunk ner_label confidence Non-binary Gender 0.9987 68 years old Age 0.6892667 Black Race_ethnicity 0.9226 Retired Employment_status 0.9426 Divorced Marital_Status 0.9996 Asexual Sexual_orientation 1.0 Judaism Religion 0.986 Substance use Unhealthy_habits 0.48755002 See Models Hub Page for more details. Updated Medicare Risk Adjustment Score Calculation Module Incorporating CMS’s Latest Proposed Updates Including The Version 28 Support We are excited to introduce significant updates to the Medical Risk Adjustment module of Spark-NLP for Healthcare! CMS (Centers for Medicare &amp; Medicaid Services) releases updated versions of risk adjustment models periodically to account for changes in healthcare data, policy requirements, and advancements in statistical modeling techniques. With this release, Spark-NLP for Healthcare incorporates the proposed updates by CMS for the risk adjustment module, featuring a major update represented as Version 28. Each version of the risk adjustment module is associated with a specific year, indicating the time period for which the model is designed. For example, ESRDV21Y19 (ESRD version 21 year 19) refers to the 21st version of the risk adjustment model for End-Stage Renal Disease (ESRD) and is designed for the year 2019. Updates on Risk Adjustment Module: New modules added to Spark-NLP for Healthcare: Version Year Module Name 28 Combined profileV28 28 2024 profileV28Y24 24 Combined profileV24 ESRDV21 2019 profileESRDV21Y19 A new feature has been introduced in this release that enhances the risk score calculation process. With this update, the risk score calculation now incorporates the coding pattern (intensity) adjustment and normalization factor for all versions and years. The default parameters for the profile() method have been modified in this release. Previous Default: Version 24, Year 19 Updated Default: Version 28, Year Combined We have included the risk_score_adj and risk_score_age_adj information in the outputs of the profile methods. Example: Risk Adjustment Module should be used with the following information in order: 1- A list of ICD10 codes for the measurement year. 2- The age of the patient. 3- The gender of the patient; {“M”, “F”} 4- The eligibility segment of the patient. Allowed values are as follows: - &quot;CFA&quot;: Community Full Benefit Dual Aged - &quot;CFD&quot;: Community Full Benefit Dual Disabled - &quot;CNA&quot;: Community NonDual Aged - &quot;CND&quot;: Community NonDual Disabled - &quot;CPA&quot;: Community Partial Benefit Dual Aged - &quot;CPD&quot;: Community Partial Benefit Dual Disabled - &quot;INS&quot;: Long Term Institutional - &quot;NE&quot;: New Enrollee - &quot;SNPNE&quot;: SNP NE 5- Original reason for entitlement code (orec). - &quot;0&quot;: Old age and survivor&#39;s insurance - &quot;1&quot;: Disability insurance benefits - &quot;2&quot;: End-stage renal disease - &quot;3&quot;: Both DIB and ESRD 6- If the patient is in Medicaid or not. #sample pyspark dataframe called df: df.show(5) &gt;&gt;&gt; ICD10CM_CODES GENDER OREC AGE MEDICAID ELIGIBILITY M86622, M0549, I… M 0 32 true CFD E133311, E200, T… M 0 32 true CFD C179, I70348, C8… M 0 32 true CFD S72463A, C37, E1… M 0 32 true CFD S1224XB, S72115B… M 0 32 true CFD Applying profileV28Y24 module over the sample data: df = df.withColumn(&quot;hcc_profile&quot;, profileV28Y24(df.ICD10CM_CODES, df.AGE, df.GENDER, df.ELIGIBILITY, df.OREC, df.MEDICAID)) Result: ICD10CM_CODES GENDER OREC AGE MEDICAID ELIGIBILITY hcc_profile risk_score hcc_lst risk_score_adj risk_score_age_adj hcc_map parameters details M86622, M0549, I… M 0 32 true CFD 10.022, “HCC401… 10.022 “HCC401”,”HCC21”… 9.2913 0.1771 “L97214”:”HCC38… “elig”:”CFD”,”ag… “CFD_HCC267”:0.5… E133311, E200, T… M 0 32 true CFD 9.374, “HCC280”… 9.374 “HCC280”,”CHR_LU… 8.6906 0.1771 “G308”:”HCC127”… “elig”:”CFD”,”ag… “CFD_HCC202”:0.2… C179, I70348, C8… M 0 32 true CFD 12.988, “HCC17”… 12.988 “HCC17”,”HCC401”… 12.0411 0.1771 “C4A20”:”HCC21”… “elig”:”CFD”,”ag… “CFD_HCC280”:0.2… S72463A, C37, E1… M 0 32 true CFD 17.034, “HF_CHR… 17.034 “HF_CHR_LUNG”,”H… 15.7921 0.1771 “C8296”:”HCC21”… “elig”:”CFD”,”ag… “CFD_HCC267”:0.5… S1224XB, S72115B… M 0 32 true CFD 7.99, “HCC401”,… 7.99 “HCC401”,”HCC51”… 7.4075 0.1771 “D57818”:”HCC10… “elig”:”CFD”,”ag… “CFD_HCC267”:0.5… For the detailed usage of the module, please visit Calculate Medicare Risk Adjustment Score notebook. New Resources Downloader Notebook That Includes Comprehensive Guideline For Model Downloading Model Download Helpers Notebook includes a comprehensive guide to the various parameters and functionalities of the ResourceDownloader annotator, which facilitates the downloading and management of resources such as pretrained models and pipelines. This annotator is designed to efficiently download and manage various resources, including pretrained models and pipelines without using your sensitive AWS keys in any script/ environment with no addional library (e.g. boto3, aws cli) needed. Examples: with S3 URI s3_uri = &quot;s3://auxdata.johnsnowlabs.com/public/models/nerdl_conll_elmo_en_4.0.0_3.0_1654103884644.zip&quot; ResourceDownloader.downloadModelDirectly(s3_uri, &quot;public/models&quot;, unzip=True) with model name python model_name = “public/models/nerdl_restaurant_100d_en_3.3.4_3.0_1640949258750.zip” ResourceDownloader.downloadModelDirectly(model_name, “public/models”, unzip=True) - updateCacheModels python from sparknlp_jsl.updateModels import UpdateModels UpdateModels.updateCacheModels() ls ~/cache_pretrained # embeddings_clinical_en_2.0.2_2.4_1558454742956/ # ner_clinical_large_en_2.5.0_2.4_1590021302624/ Pretrained Pipelines Now Compatible With All PySpark Versions We are thrilled to announce the release of our new PretrainedPipeline, specifically designed to be compatible with all versions of PySpark. This groundbreaking update ensures seamless integration and effortless deployment of Spark NLP’s powerful pretrained models across different PySpark environments. Various Core Improvements: Bug Fixes, Enhanced Overall Robustness, And Reliability Of Spark NLP For Healthcare The save() method on MedicalSummarization has been fixed, ensuring proper functionality. The bug in the Chunk2Token Python class has been resolved, eliminating any issues related to it. The Fine-tune issue in SentenceEntityResolver has been fixed, enhancing its performance and accuracy. The sparknlp_jsl.start()function now works correctly with the apple_silicon and aarch64 parameters. The default scopeWindow parameter on AssertionDLApproach has been updated to (9,15), enhancing its effectiveness in processing textual assertions. Compilation issues related to SparkNLP v443 have been resolved, resulting in smoother operation. We have improved the documentation, providing clearer instructions and explanations for easier usage. Updated Notebooks And Demonstrations For Making Spark NLP For Healthcare Easier To Navigate And Understand New Extractive Summarization Notebook New Model Download Helpers Notebook Updated Biogpt_Chat_JSL Notebook for latest models Updated Clinical MultiLanguage Deidentification Notebook for latest models New All in One Voice Of Patient New Voice Of Patient CLASSIFICATION_SIDE_EFFECT Demo Updated SOCIAL DETERMINANT CLASSIFICATION GENERIC Demo Updated CLINICAL DEIDENTIFICATION MULTI-LANGUAGE Demo We Have Added And Updated A Substantial Number Of New Clinical Models And Pipelines, Further Solidifying Our Offering In The Healthcare Domain. clinical_deidentification -&gt; ar summarizer_clinical_laymen_pipeline ner_demographic_extended_healthcare ner_sdoh ner_vop_anatomy ner_vop_anatomy_emb_clinical_medium ner_vop_anatomy_emb_clinical_large ner_vop_anatomy_pipeline ner_vop_clinical_dept ner_vop_clinical_dept_emb_clinical_medium ner_vop_clinical_dept_emb_clinical_large ner_vop_clinical_dept_pipeline ner_vop_demographic ner_vop_demographic_emb_clinical_medium ner_vop_demographic_emb_clinical_large ner_vop_demographic_pipeline ner_vop_problem ner_vop_problem_emb_clinical_medium ner_vop_problem_emb_clinical_large ner_vop_problem_pipeline ner_vop_test ner_vop_test_emb_clinical_medium ner_vop_test_emb_clinical_large ner_vop_test_pipeline ner_vop_temporal ner_vop_temporal_emb_clinical_medium ner_vop_temporal_emb_clinical_large_final ner_vop_temporal_pipeline ner_vop_treatment ner_vop_treatment_emb_clinical_medium ner_vop_treatment_emb_clinical_large ner_vop_treatment_pipeline ner_vop ner_vop_emb_clinical_medium ner_vop_emb_clinical_large ner_vop_pipeline ner_vop_problem_reduced ner_vop_problem_reduced_emb_clinical_medium ner_vop_problem_reduced_emb_clinical_large ner_vop_problem_reduced_pipeline bert_sequence_classifier_vop_drug_side_effect bert_sequence_classifier_vop_drug_side_effect_pipeline bert_sequence_classifier_vop_hcp_consult bert_sequence_classifier_vop_hcp_consult_pipeline bert_sequence_classifier_vop_self_report bert_sequence_classifier_vop_self_report_pipeline bert_sequence_classifier_vop_sound_medical bert_sequence_classifier_vop_sound_medical_pipeline For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_4",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_4_4"
  },
  "1488": {
    "id": "1488",
    "title": "NLP Lab Release Notes 4.5.0",
    "content": "4.5.0 Release date: 01-01-2023 Over the last year, Annotation Lab has grown to be much more than a document annotation tool. It became a full-fledged AI system, capable of testing pre-trained models and rules, applying them to new datasets, training, and tuning models, and exporting them to be deployed in production. All those features together with the new Playground concept presented in the current release notes contributed to the transformation of the Annotation Lab into the NLP Lab. A new Playground feature is released as part of the NLP Lab’s Hub that allows users to quickly test any model and/or rule on a snippet of text without the need to create a project and import tasks. NLP Lab also supports the training of Legal and Finance models and Model evaluation for classification projects. As always the release includes some stabilization and bug fixes for issues reported by our user community. Below are the details of what has been included in this release. NLP Lab’s Playground NLP Lab introduces the Playground feature where users can directly deploy and test models and/or rules. In previous versions, the pre-annotation servers could only be deployed from within a given project. With the addition of the Playground, models can easily be deployed and tested on a sample text without going through the project setup wizard. Any model or rule can now be selected and deployed for testing by clicking on the “Open in Playground” button. Rules are deployable in the Playground from the rules page. When a particular rule is deployed in the playground, the user can also change the parameters of the rules on the right side of the page. After saving the changes users need to click on the “Deploy” button to refresh the results of the pre-annotation on the provided text. Deployment of models and rules is supported by floating and air-gapped licenses. Healthcare, Legal, and Finance models require a license with their respective scopes to be deployed in Playground. Unlike pre-annotation servers, only one playground can be deployed at any given time. Export trained models to the S3 bucket With this release, users can easily export trained models to a given s3 bucket. This feature is available on the Available Models page under the Hub tab. Users need to enter the S3 bucket path, S3 access key, and S3 secret key to upload the model to the S3 bucket. Support Training of Finance and Legal Models With this release, users can perform training of Legal and Finance models depending on the available license(s). When training a new model in the NLP Lab, users have the option to select what library to use. Two options were available up until now: Open source and Healthcare. This release adds two new options: Legal and Finance. This helps differentiate the library used for training the models. The new options are only available when at least one valid license with the corresponding scope is added to the License page. Improvements Keyword-based Search at task level Finding tokens on the Visual NER project was restricted to only one page, and searching for keywords from the labeling page on a text-based project was not available. NLP Lab supports task-level keyword-based searches. The keyword-based search feature will work for text and Visual NER projects alike. The search will work on all paginated pages. It is also possible to navigate between search results, even if that result is located on another page. Important Previously this feature was implemented with the help of tag in the Visual NER project configurations. With the implementation of search at task level, the previous search tag should be removed from existing visual NER projects. Config to be removed from all existing Visual NER project: &lt;Search name=&quot;search&quot; toName=&quot;image&quot; placeholder=&quot;Search&quot;/&gt; Chunk-based Search in Visual NER tasks In previous versions, users could only run token-based searches at page level. The search feature did not support searching a collection of tokens as a single chunk. With this release, users can find a chunk of tokens in the Visual NER task. Model Evaluation for Classification Projects Up until now, the Annotation Lab only supported test and model evaluation for the NER-based projects. From this version on, NLP Lab supports test and model evaluation for Classification project as well. Evaluation results can now be downloaded if needed. Hide and Unhide Regions in NER project In this version, we support the hide/show annotated token regions feature in the text-based project in the same way as it was available in the Visual NER project. Ground Truth can only be set/unset by the owner of the completion With this version, we have improved the feature to set/unset ground truth for a completion submitted by an annotator. Now, for the Manager/Project Owner/Reviewer, the button to set/unset ground truth is disabled. The ground truth can only be updated by the annotator who submitted the completion or is unset when a submitted completion is rejected by a reviewer. Finite Zoom Out Level in Visual NER tasks Previously, users could zoom in and zoom out again on images while working with the Visual NER project, but the user could not get what the last stage of zoom-out was. Now, when the user zooms out of the image if it is the last phase then the zoom-out button will automatically be disabled so the user knows where to stop zooming out next. Taxonomy Location Customizable from the Project Configuration There are many different views available for each project template. This diversity can be confusing for users. For eliminating this complexity, the View tab was removed from the project configuration page and replaced by an “orientation” option that can be directly applied to the project configuration. Orientation will decide, where the taxonomy (labels, choices, text, images, etc.) will be located on the labeling screen i.e. placed at the top, bottom or next to the annotation screen. Pre-annotation CPU requirement message in Visual NER projects By default, the pre-annotation server uses 2 CPUs. For Visual NER pre-annotation, it is likely that 2 CPUs are not enough. Now a friendly message is shown during the deployment of Visual NER pre-annotation if the CPU count is less than or equal to 2. Bug Fixes Expanding the text on the Labelling page visually does not expand the labeling area Previously, expanding the text area on the labeling page did not make any changes in the text expansion. This issue has been fixed. Now, expanding the text will change the text area to full-screen mode. Revoking granted analytics request do not update the revoked section Earlier, when an analytics request was revoked, the corresponding entry was not shown in the revoked section. We have fixed this issue. With NLP Lab 4.5.0, the revoked entries are available in the revoked section. Also, when an analytics request is revoked, in the revoked section, two new actions, Accept and Delete, are available. Show Confidence score in Regions option is not working properly for non-Visual NER tasks For none Visual NER tasks, enabling/disabling “Show Confidence score in Regions” from Layout did not change the UI. The changes only appear when the page was reloaded or when the Versions tab was clicked. This issue has been fixed in this version. Username validation is missing when creating a new user With this version, the issue related to the missing validation of the username when creating a new user has been fixed. Issues with role selection on Teams page When a user was added to the project team as a new team member, the recently added user name was still visible in the search bar. This issue has been fixed. Clicking on the eye icon to hide a labeled region removes the region from the Annotations widget Previously, when a user clicked on the eye icon to hide a label, the labeled region was removed from the Annotations widget. Furthermore, the color of the label was also changed in the panel. This issue has been fixed. Deployed legal and finance models servers are not associated with their respective licenses In the previous version, when a Legal and Finance model server was deployed, the respective licenses were not associated with their deployed server. The availability of the Legal and Finance license was checked when the models were deployed. Version 4.5.0 fixes this bug. Model Evaluation cannot be triggered using an air-gapped healthcare license with scope training/inference The issue of triggering Model Evaluation using an air-gapped healthcare license with the training/inference scope has been fixed. When user enabled “Allow user for custom selection of regions”, token values are missing in JSON export Earlier, when the user annotates tokens while enabling “Allow user for custom selection of regions” and exports the completion. The token values were missing from the JSON export. In this version, the issue is fixed, and all the token fields and values are available in the JSON Pre-annotation server with pending status is not removed when the user deletes the server from the cluster page Deleting the pre-annotation server with status pending from the cluster page did not delete the pod from Kubernetes and created multiple pre-annotation pods. This issue has been fixed. Project export with space in the name is allowed to be imported In the earlier version, the users could import previously exported projects with space in the project’s name. Though the project was listed on the projects page, the project could not be deleted. Also, the user was unable to perform any operations on the project. The “Only Assigned” checkbox overlaps the review dialog box The overlap between the “Only Assigned” checkbox and the review dialog box was fixed. Open-source Models cannot be downloaded in the NLP Lab without a license Previously open-source models could not be downloaded from the NLP models hub when there was no license uploaded. This issue has been fixed. Now all open-source licenses are downloadable without any issue. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_5_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_5_0"
  },
  "1489": {
    "id": "1489",
    "title": "NLP Lab Release Notes 4.5.1",
    "content": "4.5.1 Release date: 05-01-2023 This release includes some stabilization and bug fixes for issues reported by our user community. Below are the details of what has been included in this release. Improvement Name of available models should be visible completely in the Predefined Labels tab Bug Fixes Finance models cannot be downloaded to NLP Lab with a floating license from Models Hub Trained visual NER model is not listed in the predefined labels section on the configuration page Error due to circular dependency of logger Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_5_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_5_1"
  },
  "1490": {
    "id": "1490",
    "title": "NLP Lab Release Notes 4.6.2",
    "content": "4.6.2 Release date: 21-01-2023 NLP Lab 4.6.2 comes with support for zero-shot learning via prompts. Prompt engineering is a very recent but rapidly growing discipline that aims to guide language models such as GPT-3 to generate specific and desired outputs, such as answering a question or writing a coherent story. This version of the NLP Lab, adds support for the creation and use of prompts for entities and relations identification within text documents. The goal of prompt engineering in this context is designing and crafting some questions, which are fed into a question-answering model together with some input text. The purpose is to guide the language model to generate specific and desired outputs, such as identifying entities or relations within the input text. This release offers features such as creation and editing of prompts, a dedicated section for prompts management and sharing inside the resources Hub, an optimized configuration page allowing mixing models, prompts, and rules into the same project, and support for quick prompts deployments and testing to the Playground. Prompts on the Hub The resources Hub has a new page dedicated to prompts. It allows users to easily discover and explore the existing prompts or create new prompts for identifying entities or relations. Currently, NLP Lab supports prompts for Healthcare, Finance, and Legal domains applied using pre-trained question-answering language models published on the NLP Models Hub and available to download in one click. The main advantage behind the use of prompts in entity or relation recognition is the ease of definition. Non-technical domain experts can easily create prompts, test and edit them on the playground on custom text snippets and, when ready, deploy them for pre-annotation as part of larger NLP projects. Together with rules, prompts are very handy in situations where no pre-trained models exist, for the target entities and domains. With rules and prompts the annotators never start their projects from scratch but can capitalize on the power of zero-shot models and rules to help them pre-annotate the simple entities and relations and speed up the annotation process. As such the NLP Lab ensures fewer manual annotations are required from any given task. Creating NER Prompts NER prompts, can be used to identify entities in natural language text documents. Those can be created based on healthcare, finance, and legal zero-shot models selectable from the “Domain” dropdown. For one prompt, the user adds one or more questions for which the answer represents the target entity to annotate. Creating Relation Prompts Prompts can also be used to identify relations between entities for healthcare, finance, and legal domains. The domain-specific zero-shot model to use for detecting relation can be selected from the “Domain” dropdown. The relation prompts are defined by a pair of entities related by a predicate. The entities can be selected from the available dropdowns listing all entities available in the current NLP Lab (included in available NER models or rules) for the specified domain. A simplified configuration wizard allows the reuse of models, rules, and prompts The project configuration page was simplified by grouping into one page all available resources that can be reused for pre-annotation: models, rules, and prompts. Users can easily mix and match the relevant resources and add them to their configuration. Note: One project configuration can only reuse the prompts defined by one single zero-shot model. Prompts created based on multiple zero-shot models (e.g. finance or legal or healthcare) cannot be mixed into the same project because of high resource consumption. Furthermore, all prompts require a license with a scope that matches the domain of the prompt. Experiment with prompts in Playground NLP Lab’s Playground supports the deployment and testing of prompts. Users can quickly test the results of applying a prompt on custom text, can easily edit the prompt, save it, and deploy it right away to see the change in the pre-annotation results. Zero-Shot Models available in the NLP Models Hub NLP Models Hub now lists the newly released zero-shot models that are used to define prompts. These models need to be downloaded to NLP Lab instance before prompts can be created. A valid license must be available for the models to be downloaded to NLP Lab. Bug Fixes Error while deploying classification model to the playground Previously, deploying the classification model to the playground had some issues which have been fixed in this version. **Information on the model’s details not visible completely on the playground ** In this version, we have fixed an issue related to the visibility of the information for Edition, Uploaded by, and Source inside the Models Detail accordion. Now, the UI can handle long model names on the playground page. Undo and Reset buttons are not working With release 4.6.2, issues regarding undo/redo buttons in the labeling page for annotated tokens have been fixed. Now, the Undo and Redo button works as expected. Finance and Legal models cannot be downloaded to NLP Lab with a floating license from Models Hub Earlier, users were not able to download the Finance and Legal model from the NLP Models HUB page using floating licenses. This issue has been fixed. Now, legal and finance models are downloadable in the NLP lab using a floating license. Pre-annotation server cannot be deployed for Visual NER This version also fixes the issue of failing to deploy the pre-annotation server for Visual NER models. Draft saved is seen for submitted completion Previously, in the NER task when the user clicked on regions of a previously submitted completion and viewed the versions submitted by the users, a draft was saved. A draft should not be created and saved for submitted completions. This issue was fixed in 4.6.2. Training fails for NER when embedding_clinical is used and the license type is open-source Earlier it was not possible to train a NER model with the open-source library using embeddings_clinical. This issue has been fixed. Hence users can now train open-sourced models with embeddings_clinical. UI goes blank for the Visual NER project when an annotation is saved and the next button is clicked In the previous version, annotators were not served the next task after clicking the Next button. A blank page with a console error was seen. Now the next task is served in the Visual NER project without any error. Pre-annotation server cannot be deployed for RE model There was an issue with the deployment of trained NER models with a relation extraction model. This issue has been fixed in this version. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_2"
  },
  "1491": {
    "id": "1491",
    "title": "NLP Lab Release Notes 4.6.3",
    "content": "4.6.3 Release date: 31-01-2023 NLP Lab v4.6.3 is available which includes improvements for Playground and Prompt Engineering features introduced in v4.5 and v4.6. Here are some of them: Prompt (relation) using 2 different NER models is possible Ability to add long texts with new lines in the playground Issue when finance models are directly deployed to playground from the Hub page is fixed Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_3",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_3"
  },
  "1492": {
    "id": "1492",
    "title": "NLP Lab Release Notes 4.6.5",
    "content": "4.6.5 Release date: 08-02-2023 NLP Lab v4.6.5, which includes significant optimizations and bugfixes for Project Analytics and the Prompt Engineering feature. The following are some of the key updates included in this release: The issue with the all_extracted_chunks chart not updating in the analytics page has now been resolved. The performance of project analytics operations has been improved, allowing for faster calculation of results. Limits have been added to the prompt description and prompt questions, ensuring that the text does not crash the UI. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_5",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_5"
  },
  "1493": {
    "id": "1493",
    "title": "NLP Lab Release Notes 4.7.1",
    "content": "4.7.1 Release date: 22-02-2023 The latest version of NLP Lab, version 4.7.1, brings several enhancements that are worth highlighting. One of the most notable improvements is in relation prompts. NLP Lab now offers support for combining NER models, prompts and rules when defining relation prompts. The playground feature in NLP Lab has also received some noteworthy upgrades in version 4.7.1. The “playground” environment was initially added to facilitate experiments with different NLP models, tweak prompts and rules, and explore the potential of language models in a safe, sandboxed environment. The improvements made to the playground in this version are expected to enhance the overall user experience, and to make the environment faster and more responsive. In addition to these improvements, the latest version of NLP Lab has extended support for importing large task archives. This means that users can now work with bigger datasets more efficiently, which will undoubtedly save them time and effort. Below are the specifics of the additions included in this release: Improvements in Prompts Build Relation Prompts using NER Models, Prompts and Rules In previous version, relation prompts could be defined based on NER models and rules. In this release, NLP Lab allows for NER prompts to be reused when defining relation prompts. To include a NER prompt within a relation prompt, users need to navigate to the Questions section of the Relation Prompt creation page and search for the prompt to reuse. Once the NER prompt has been selected, users can start defining the question patterns. For example, users could create prompts that identify the relationship between people and the organizations they work for, or prompts that identify the relationship between a place and its geographic coordinates. The ability to incorporate NER prompts into relation prompts is a significant advancement in prompts engineering, and it opens up new possibilities for more sophisticated and accurate natural language processing. Improvements in Playground Direct Navigation to Active Playground Sessions Navigating between multiple projects to and from the playground experiments can be necessary, especially when you want to revisit a previously edited prompt or rule. This is why NLP Lab Playground now allow users to navigate to any active Playground session without having to redeploy the server. This feature enables users to check how their resources (models, rules and prompts) behave at project level, compare the preannotation results with ground truth, and quickly get back to experiments for modifying prompts or rules without losing progress or spending time on new deployments. This feature makes experimenting with NLP prompts and rules in a playground more efficient, streamlined, and productive. Automatic Deployment of Updated Rules/Prompts Another benefit of experimenting with NLP prompts and rules in the playground is the immediate feedback that you receive. When you make changes to the parameters of your rules or to the questions in your prompts, the updates are deployed instantly. Manually deploying the server is not necessary any more for changes made to Rules/Prompts to be reflected in the preannotation results. Once the changes are saved, by simply clicking on the Test button, updated results are presented. This allows you to experiment with a range of variables and see how each one affects the correctness and completeness of the results. The real-time feedback and immediate deployment of changes in the playground make it a powerful tool for pushing the boundaries of what is possible with language processing. Playground Server Destroyed after 5 Minutes of Inactivity When active, the NLP playground consumes resources from your server. For this reason, NLP Lab defines an idle time limit of 5 minutes after which the playground is automatically destroyed. This is done to ensure that the server resources are not being wasted on idle sessions. When the server is destroyed, a message is displayed, so users are aware that the session has ended. Users can view information regarding the reason for the Playground’s termination, and have the option to restart by pressing the Restart button. Playground Servers use Light Pipelines The replacement of regular preannotation pipelines with Light Pipelines has a significant impact on the performance of the NLP playground. Light pipelines allow for faster initial deployment, quicker pipeline update and fast processing of text data, resulting in overall quicker results in the UI. Direct Access to Model Details Page on the Playground Another useful feature of NLP Lab Playground is the ability to quickly and easily access information on the models being used. This information can be invaluable for users who are trying to gain a deeper understanding of the model’s inner workings and capabilities. In particular, by click on the model’s name it is now possible to navigate to the NLP Models hub page. This page provides users with additional details about the model, including its training data, architecture, and performance metrics. By exploring this information, users can gain a better understanding of the model’s strengths and weaknesses, and use this knowledge to make more informed decisions on how good the model is for the data they need to annotate. Improvements in Task Import Support for Large Document Import One of the challenges when working on big annotation projects is dealing with large size tasks, especially when uploading them to the platform. This is particularly problematic for files/archives larger than 20 MB, which can often lead to timeouts and failed uploads. To address this issue, NLP Lab has implemented chunk file uploading on the task import page. Chunk file uploading is a method that breaks large files into smaller, more manageable chunks. This process makes the uploading of large files smoother and more reliable, as it reduces the risk of timeouts and failed uploads. This is especially important for NLP practitioners who work with large datasets, as it allows them to upload and process their data more quickly and effectively. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_7_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_7_1"
  },
  "1494": {
    "id": "1494",
    "title": "NLP Lab Release Notes 4.7.4",
    "content": "4.7.4 Release date: 27-02-2023 NLP Lab v4.7.4, which includes significant optimizations and bugfixes. The following are some of the key updates included in this release: Ability to track NLP Lab installation and upgrades Resolved CVE issues related to Debian packages Corrected the number of completions needed to trigger Active learning when no test-tagged tasks are present.” Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_7_4",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_7_4"
  },
  "1495": {
    "id": "1495",
    "title": "NLP Lab Release Notes 4.8.1",
    "content": "4.8.1 Release date: 22-03-2023 More Powerful Prompts, New Annotation Gesture, and Enhanced Support for Floating Licences in NLP Lab 4.8 NLP Lab 4.8 brings more power to the prompts allowing a more efficient text preannotation, it adapts to the user’s preferences in terms of annotation gestures, adds supports for bundles of floating licenses shared across the annotation team for parallel preannotation, training, and experiments in the playground. It also includes a long list of optimizations covering project configuration steps, large projects export, or automatic download of missing resources. Here are the highlights of this release: More Powerful Prompts NLP Lab 4.8 introduces several new features that enhance prompt-based preannotation. One significant improvement is the incorporation of negative questions into prompt definitions, which allows users to establish characteristics that do not apply to the target entity or relation. This version also enables the creation of relation prompts using labels from custom models even if trained with different embeddings, providing more flexibility for prompt-based preannotation. Additionally, the software now automatically downloads prompt dependencies and supports prompt import/export. The prompt definition page also features a dynamic question count and filters for easy navigation. Combining Positive and Negative Questions for More Precise Prompts Definition NLP Lab 4.8 enhances the precision of entity annotation using prompts by incorporating negative questions. On the prompt definition screen, users can now specify two categories of questions - Questions that establish the characteristics of the target entity and Questions that establish the characteristics that do not apply to the entity. Both the affirmative and negative definitions will be executed as separate prompts, integrated into the same pipeline, enabling users to eliminate incorrect entities generated by the prompts. This feature will substantially boost the efficiency of prompt-based entity generation and streamline the process for our users. Relation Prompts Combine Entities from Models Trained with Different Embeddings NLP Lab allows the definition of relation prompts by combining entities defined in pre-trained models, rules, and prompts. However, previous versions of the software did not allow users to create relation prompts using custom-trained models. In this update, users can implement and use relation prompts linking 2 entities defined in custom-trained models (e.g. trained via the NLP Lab). Moreover, there is no restriction for the reference models which can also be trained using different embeddings. We are confident that this new feature will enhance the power of the prompts and offer more flexibility for prompt-based preannotation. Automatically Download Necessary Prompt Dependencies NLP Lab Prompts are created based on Zero Shot models. The later are part of the Healthcare, Finance and Legal libraries and are accessible only in the presence of a valid license key. The prompt definition options are populated according to license availability: e.g. if a Healthcare NLP license is available, the Healthcare option will be active in the Domain dropdown. As such, when creating a prompt, the user has to choose the domain of the prompt, and based on that, NLP Lab will infer the Zero Shot model needed by the prompt. When users select one of the active domains if the corresponding Zero Shot model is not available locally, NLP Lab will automatically download it from the NLP Models Hub. Import/Export Prompts Prompts are preannotation resources that users often want to move from one instance of the NLP Lab to another or to archive for future reference. NLP Lab now supports prompt import and export from the UI. The user can import a ZIP/JSON file containing one or several prompt definitions. The imported prompts will become available on the Prompts page under the Hub menu item. Users can also export prompts in JSON format via the burger menu available for each prompt. Dynamic Count of Questions on the Prompt Definition Page Each prompt can include a maximum of 30 positive questions and 30 negative questions. For facilitating user actions when defining/updating prompts, NLP Lab now includes a count of the number of questions added so far. For instance, if two questions have been added while creating a prompt, then the UI should show Questions(2/30) Filters in the prompt page The Prompts page can become crowded very quickly as prompts are quite popular and easy to define and use for preannotation, especially by non technical users. For helping users quickly identify the prompts they need, a search option is available as well as 2 filters. Using the 2 dropdown menus at the top right side of the page, prompts can be filtered based on their Type or Domain. Undo Changes For Prompt and Rules in the playground We are thrilled to introduce the Undo feature added to the NLP Lab Playground. This function enables users to quickly undo any changes made during their current experimental session. By selecting the &quot;Undo Changes&quot; button, all modifications made to the prompt/rules will be reverted to their original state. We are confident that this feature will significantly improve the user experience by providing greater control over the editing process. New Annotation Gesture Some of our users suggested updating the annotation gesture we initially offered, as it was counter-intuitive, especially for users accustomed to modern text editing tools. Specifically, the process of first selecting the Label and then selecting the chunk to annotate may not feel natural anymore, as tools such as MS Word, where you first select a text and then have options to format or access contextual menus that open next to your selection, have changed the way we all feel about text manipulation. We hear you! To make NLP Lab more intuitive and user-friendly, NLP Lab now supports a new way of annotating text. This new feature allows users to select the text first and then choose the label to apply. We believe that this will make the annotation process more intuitive and efficient for many users. This feature is available for both text projects and Visual NER projects. You are now able to switch between the two options: selecting text and assigning an entity, or selecting an entity and assigning text. Both will work. This way, users can choose the annotation method that works best for their project and their personal preferences. Optimized Project Configurations Automatic Model Download During Project Import When a user imports a project in NLP Lab 4.8, the system automatically downloads any absent models utilized by the imported project. To enable users to check whether the models have been downloaded or not, a new section named &quot;Download Models&quot; has been included in the Import status. If the required models have been downloaded or are already present, a green tick will be displayed. On the other hand, if the download process is unsuccessful, a red cross will be shown. When the automatic download of a model/embeddings fails, an error message is displayed on the model card in the Hub-&gt;Models page. Users can hover over the question mark icon to see the details. Update the behavior of the save button on the Project configuration page While setting up the configuration, the user can now choose to save the settings on all configuration sections without being redirected to another page or having to deploy a preannotation server. After saving the configuration, the user can deploy the pre-annotation server by pressing the Pre-Annotate button from the tasks page or navigating to the Configuration -&gt; Customize Labels page and save the configuration there. Once the server is deployed, the user will either be directed to the Tasks page or to the Import page. Missing Embeddings Warning in the Configuration Page If embeddings are missing for a model that is part of a project configuration, a black warning message was displayed on the configuration page to alert the user. This warning message was not visible before, but now the displayed text ensures that the user can see the error. Efficient Export for Large Projects Visual NER projects, pre-annotations, and training have substantially increased NLP Lab project sizes. Unfortunately, this growth has made importing and exporting tasks or projects time-consuming, especially when dealing with large files. The new version of the system has addressed this issue by enhancing both project and task exports, making it possible to quickly export large files and manage a vast number of tasks. This optimization also applies to text-based projects, where the export time has been reduced by a factor of ten. The current version of the system includes a pop-up message that appears before exporting both tasks and projects. This message notifies the user that the system is preparing the data for download and advises them to remain on the page and avoid enabling pop-ups to prevent any interruptions. Once the data preparation is complete, the download will start automatically, and the user will not need to take any additional steps. Enhanced Support for Floating Licenses Support for Bundles of Licenses We are delighted to inform you that NLP Lab now offers support for bundles of floating licenses. Those are licenses that enable multiple pre-annotation/training servers to run concurrently based on the values of the &quot;max_parallel_jobs&quot; parameter. In the previous version, our floating license system only allowed for one pre-annotation/training server to operate at a time. With this new update, users can enjoy the benefits of a single floating license that can support multiple pre-annotation/training servers simultaneously. Display a banner showing the number of days remaining for the available trial license NLP Lab improves the user experience by providing more accessible information about license validity. Currently, users can only check their license status on the Licenses page, which may not be convenient as it requires manual action. To address this issue, we have added a new feature that displays a warning on the user interface before the license expires. This notification reminds you to review your subscription status or renew your license before it expires. For trial licenses with less than 30 days remaining, a banner will be displayed on the UI indicating the remaining trial days and a link to create a new subscription. This way, you can easily keep track of your trial period and take the necessary steps before it ends. Improvements Increased Flexibility in Username Definition With the latest release of NLP Lab, users can create usernames with increased flexibility and ease. Specifically, support has been added for the use of the underscore symbol &quot;&quot; in usernames. This enhancement will enable users to create unique and more expressive usernames that better represent their identity or brand. Furthermore, this feature will allow users to avoid any potential conflicts or duplications with other usernames. Improved User Experience with Clearer Relation Prompts NLP Lab has recently introduced an improvement to the way relation prompts are displayed in the Pre-annotation pop-up. Previously, the relation prompts were shown under the generic &quot;Pre-annotation prompts&quot; category, which may have caused confusion for users. With this update, relation prompts are now shown under a separate sub-heading of &quot;RE prompts&quot; or &quot;Relation prompts,&quot; providing clearer and more organized categorization. This improvement will enable users to manage the creation and deployment of relation prompts more intuitively and efficiently. Enhanced Accessibility and Functionality of Model Hub Page To improve the accessibility and functionality of the Model Hub page, NLP Lab has implemented several changes in its latest version. One such improvement is the ability to distinguish between downloadable models and license-restricted models. Models that require a license will now be disabled when the appropriate license is not available, making it easier for users to navigate and select models to reuse. Another enhancement is the introduction of a new menu on the model/rules card, which allows users to effortlessly download models from Modelshub or open them in the playground. This menu provides a more streamlined and convenient way for users to access and utilize the available models and resources. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_1"
  },
  "1496": {
    "id": "1496",
    "title": "NLP Lab Release Notes 4.8.2",
    "content": "4.8.2 Release date: 03-04-2023 NLP Lab v4.8.2 includes bugfixes for AKS setup. This version includes fixes for the following issues: PDF is not imported to NLP Lab due to delay in file sync between deployed pods in different nodes of AKS system Backup cronjob is not created in AKS deployment Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_2"
  },
  "1497": {
    "id": "1497",
    "title": "NLP Lab Release Notes 4.8.3",
    "content": "4.8.3 Release date: 05-04-2023 NLP Lab v4.8.3 includes a bugfix related to restoration of database backup. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_3",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_3"
  },
  "1498": {
    "id": "1498",
    "title": "NLP Lab Release Notes 4.8.4",
    "content": "4.8.4 Release date: 13-04-2023 NLP Lab v4.8.4 release includes stabilization and bugfixes. Here are some of the key updates included in this release: Improvements in Keycloak resources API calls with proper error handling Get_server error is seen in annotationlab pod when user navigate to clusters page When the user selects a new label, the chunk that was previously unselected becomes labeled The user is not able to select multi-line text in the Visual NER task using the post-annotation gesture For a multi-paged task, user is not able to annotate texts with a label when text is selected first Training fails when the training type is Assertion Deployment crashes for Prompt without false_prompts parameter Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_4",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_4"
  },
  "1499": {
    "id": "1499",
    "title": "NLP Lab Release Notes 4.9.2",
    "content": "4.9.2 Release date: 04-05-2023 Enhanced Analytics, Improved Labeling Experience, and stabilization in NLP Lab 4.9 NLP Lab version 4.9 is now available with new features to enhance the analytics capabilities of the platform. The latest release provides managers with more insights into their projects and team productivity, enabling more efficient progress monitoring and better DL model outcomes. The addition of Time Indicators and Edit Counts on each annotation version is a notable feature that allows annotators to track statistics of the edits made in the completions, providing them with valuable insights into their work and the evolution of the Annotation Guidelines. To ensure that labeling page space is used optimally, the layout has been improved to use every corner of the page. This means that the labeling page now provides a more streamlined and efficient experience for users. In addition, the new version includes bug fixes and stabilization, which are customary in every software release. These features are designed to enhance the user experience and improve the accuracy and efficiency of NLP Lab. Here are the highlights of this release: Enhanced Annotation Process Monitoring through Edit Time Indicators This version allows users to view the time taken to finalize a completion and the number of edits made to any version of annotations, providing more transparency in the annotation process. The feature introduces two new terms, “Lead Time” and “Edit Time.” “Lead Time” refers to the time taken to annotate a completion, whether from scratch or cloned from a prediction. “Edit Time” represents the time invested in annotating a cloned completion. In addition to this, users can also see the number of modifications made to cloned completions. This feature can help managers track the time invested in various phases of completion and help in optimizing the annotation process. Tracking of Annotation Versions and Edits The latest update includes a new feature aimed at providing users with a more comprehensive understanding of completion progress and edit history. By utilizing the Versions tab, users can now track the source of a copied completion as well as the number of edits made between consecutive completions. This allows users to easily monitor the evolution of a completion and better understand the amount of work required for each completion. When a completion is created based on a filtered prediction or cloned from an existing completion, the number of edits made to the previous version will be displayed. Additionally, for completions based on predictions, the confidence score range selected will be available in the format of (min: 0 max: 1) for copied completions. This feature is designed to provide greater transparency in completion progress and streamline the tracking of edit history. New Analytics Update: Enhanced Charts Provide Managers with Deeper Insights into Project Performance NLP Lab 4.9.0 includes several improvements aimed at enhancing the user experience and efficacity of analytics charts. Improvements have been made to the Inter-annotator Agreement (IAA) charts. In cases where there is an insufficient amount of data to populate the IAA charts due to non-overlapping tasks completed by users, the UI now displays a message that informs the user that there is not enough data available to calculate the IAA chart. This enhancement aims to improve the transparency of IAA charts by alerting users to any insufficient data, providing guidance on how to resolve the issue, and promoting the assignment of overlapping tasks to ensure the availability of sufficient data. Updates were made to the Total number of completions per annotator chart. The chart has been renamed as “Total Completions vs Ground Truth Completions Per Annotator” to provide a more accurate description of the data it represents. The chart now includes two columns for each annotator, displaying the total number of completions and the number of ground truth completions side by side. This enhancement is designed to provide users with a more detailed and accurate understanding of the number of draft completions, helping them to track successive changes/corrections on the same tasks and address discrepancies in their work productivity. This version includes a new “Completion By Status” pie chart. This chart provides users with a visual representation of the statuses of completions in their projects. The chart displays two categories of completions: ground truth completions (indicated by a star) and draft completions. The pie chart also includes a new text description at the bottom of the chart informing users on the average number of draft completions per task. This feature aims to provide users with a better understanding of the number of edits and corrections required to complete a task and how the number of corrections affects the project’s overall completion rate. Additionally, the Team Productivity section has been reorganized to provide a more user-friendly experience. The Total completions, Completion by status, and Time Period have been added as three separate columns in a single row. This new layout aims to make it easier for users to access the information they need and provides a more streamlined experience. In previous versions, some users reported inconsistencies in the Average Time Annotator Spend on One Task chart. Specifically, some bars in the chart represented the same value for the amount of time annotators spent on a single task but differed in height. This issue has been resolved in version 4.9. The chart now accurately displays the same value for the amount of time annotators spend on a single task with consistent bar height. Overall, this update represents our ongoing commitment to improving the functionality and user experience of the NLP Lab platform, ensuring that users can trust the accuracy and consistency of the data they rely on for their projects. Another new feature added to the “Annotators Comparison (by chunks)” chart is a column titled “Context” that provides users with additional information about each chunk of data being annotated. The Context column displays 50 characters before and after each chunk in the task content, allowing users to view the context in which the chunk appears. This additional information helps users check the consistency of annotations across team members by making it easier to understand the correctness of annotations and to identify the errors in the data. Overall, this update represents an important improvement in supporting the IAA processes, specifically in making informed decisions about how to annotate each chunk of data. Two bar charts have also been updated “Total vs distinct values by label across completions” and “Numeric values across labels”. Previously, these charts displayed percentages and now they display the label counts instead. By providing users with the Label count, users can more easily understand the distribution of labels across completions and numeric values across labels. This change can help users make more informed decisions about how to annotate data, resulting in improved accuracy and consistency in their annotations. A new bar chart was also added to the Tasks tab of the Analytics page, called “Average Task Length”. It displays the average length of tasks completed by each annotator, measured in the number of characters. The chart is calculated based on the total number of tasks assigned to a user that contain at least one completion created by the respective user, regardless of the status of the task. This chart provides valuable insights into the performance of annotators, allowing them to compare each other’s productivity patterns and trends related to task length. By understanding how long each task is on average, users can make more informed decisions about how to allocate resources and manage their projects effectively. Improvements Serve the Next Task in Line for Reviewers After a reviewer completes a task review, the system will automatically serve the next task to the reviewer, saving time and streamlining the process. This feature can be enabled through the configuration page by checking the “Serve next reviewing task after review” option. With this feature, reviewers can continue working without the need to manually request the next task. This can help ensure that the review process is always moving forward and that reviewers have a continuous stream of work. License ID Available on License Page A recent update to the system has introduced enhancements to the license import process. Specifically, users can now view a License ID for each license on the “Existing Licenses” page, which is also included in the “popup” used for importing licenses. It is worth noting that the option to log in via MyJSL has been removed from the “Existing Licenses” tab and is only accessible on the Import License page. However, it is important to bear in mind that manually imported licenses will not display a License ID. These changes are intended to facilitate the recognition of licenses and improve the user-friendliness of the license page. Improved Task Status Indicators for Pre-Annotation Results In the current system, a red circle is displayed when pre-annotation fails to produce results for a task. However, this can be misleading as it implies an error has occurred. To rectify this, we replaced the red circle with a gray circle for tasks that yield zero pre-annotation results. This modification aims to provide users with a more precise representation of the pre-annotation process, clarifying that no errors have taken place. Improved Task Status Indicators for Pre-Annotation ResultsOptimezed Layout for Expanded Annotation Page The recent update enables a better use of empty spaces in the annotation area when it is expanded. To increase the annotating area, the sidebars are now hidden, and the top title area is also hidden to provide the maximum area for annotators to work on. Improved Layout for Side Bar Tabs In the previous versions, when the “move side panel to the bottom” option was enabled, the sidebar was relocated to the bottom of the screen but with the same layout. The layout in this mode has been modified to utilize the entire horizontal space. This was accomplished by dividing the sidebar tabs into distinct widgets, eliminating the need for users to switch between tabs. Display of License Expiration Warnings If a license has less than 30 days of validity remaining but other licenses have more than 30 days, no warning banner will be shown. On the other hand, if all licenses are about to expire, with a validity of less than 30 days, a warning banner will be displayed indicating the expiration date. The purpose of this feature is to provide clear and timely information to users regarding the status of their licenses. Bug Fixes Enable “Show all Regions” in labeling setting by default By default, the “Show labels inside the regions” setting in the labeling page was disabled as a general setting. However, you now have the option to enable it by default if you enable the “Show all regions in tree” option in the project configuration. The same applies to the layout settings, where the “Show all regions in Tree” option can also enable the “Show labels inside the regions” setting by default. Rule matches any matching sequence of characters in a token in a task Previously, when users selected the “Complete Match Regex” option and generated predictions via rule-preannotations, partially matching tokens were being labeled. With this release, when the “Complete Match Regex” option is selected, only tokens that exactly match the provided regex will be labeled. This update improves the accuracy and reliability of the preannotation process. Error while Running Visual NER training An issue affecting the training process of Visual NER projects has been resolved in this release. Previously, Visual NER training fails when attempting to use the same image/PDF for multiple tasks in projects and running training. With the implementation of the fix, training can now be successfully executed on these types of projects. Issue in db connection when multiple models are downloaded while crud operation is being performed by server users The number of default database connections has been increased from 5 to 10 and can be configured using an environment variable to meet specific needs. This update addresses issues that may arise during heavy communication between the application and the database, such as when multiple models are downloaded simultaneously. Pretrained VisualNER labels are listed in the dropdown when creating relation prompts The pre-trained and trained Visual NER labels can be found in the form that creates relation prompts. Since their labels are not related to NER labels they have been removed from the form list. When the admin user view as an annotator on the labeling page, tasks that are not assigned to the admin are seen This release addresses an issue on the labeling page for project owners who view the labeling page as an annotator. Previously, when the “Only Assigned” checkbox was selected, tasks that were not assigned to the admin were still visible. The issue has been resolved, and only tasks that are assigned to the admin will be displayed when the “Only Assigned” checkbox is checked. Save changes pop-up should not be visible when no changes are made to the annotations in a multi-page pdf Previously, even if a page had no unsaved annotations when the user moved to the next page, a pop-up message asking “Do you want to save changes?” would appear. However, now the user can navigate to the next page without any pop-up messages when no changes have been made. User is not able to pre-annotate chunks enclosed in big brackets with the help of rules In the previous version, the user was unable to pre-annotate chunks enclosed in large brackets using rules. However, this issue has been resolved in the current version. When the pre-annotation pod is deleted from the backend, the cluster page freezes with an empty list Previously, an issue occurred when the pre-annotation pod was deleted from the backend or the pre-annotation server crashed, causing the cluster page to become unresponsive and display an empty list. This issue also arose when users attempted to deploy the pre-annotation server from the tasks page. However, this problem has now been resolved. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_9_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_9_2"
  },
  "1500": {
    "id": "1500",
    "title": "Spark OCR release notes",
    "content": "5.0.0 Release date: 21-08-2023 We are glad to announce that Visual NLP 😎 5.0.0 has been released! This release comes with new models, bug fixes and more! New Models New dit_base_finetuned_rvlcdip_opt: Dit based Visual Document Classification model. This is an optimized version of previous dit_base_finetuned_rvlcdip model. It has a reduced model size of 80MB(vs. 304 of original model), which reduces the memory footprint, also memory management within the model itself has been improved. It offers a speedup of 1.54x compared to the original implementation. The impact in accuracy is minimal, it achieves an accuracy of 91.55% over RVL-CDIP dataset compared to 91.83% of the original model. Setting up the model is straightforward, doc_class = VisualDocumentClassifierV3() .pretrained(&quot;dit_base_finetuned_rvlcdip_opt&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols([&quot;image&quot;]) .setOutputCol(&quot;label&quot;) Use this notebook as a reference. New image_text_detector_mem_opt: memory optimized Craft Text Detection Model. This is new a model that improves the performance and memory consumption of the previous ImageTextDetector models. This is the same CRAFT architecture, where memory management has been improved, and refiner network has been merged into a single graph with the main network. This removes expensive data movement and reduces memory consumption. Setting up the model is straightforward, text_detector = ImageTextDetector.pretrained(&quot;image_text_detector_opt&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) text_detector.setInputCol(&quot;image&quot;) text_detector.setOutputCol(&quot;text_regions&quot;) Use this notebook as a reference. New lilt_rvl_cdip_296K: Lilt based Visual Document Classification model: Language-independent Layout Transformer (LiLT) model for document classification. The model was trained on RVL-CDIP dataset that consists of 400.000 grayscale images in 16 classes. Setting up the model is done like this, doc_class = VisualDocumentClassifierLilt() .pretrained(&quot;lilt_rvl_cdip_296K&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;label&quot;) Use this notebook as a reference. New Annotators New DicomToPdf and DicomUpdatePdf annotators: the new annotators now make it possible to extract and update encapsulated PDF files within DICOM documents. This opens up opportunities to building de-identification pipelines for the purpose of anonymizing PDF documents that have been encapsulated(embedded) into Dicom files. Bug Fixes ImageDrawAnnotations serialization issues were solved. FormRelationExtraction is now compatible with the new Lilt Visual Ner models. Pipeline serialization issues in Databricks affecting annotators like ImageHandwrittenDetector have been solved. Pillow related errors in Colab setup have been fixed. New Notebooks VisualDocumentClassifierTraining, notebooks for Visual Documents Classifier fine tuning have been updated to use the new Lilt based models. SparkOcrDeidentificationDicomWithEncapsulatedPDF.ipynb, learn how to use the new DicomToPdf and DicomUpdatePdf. SparkOcrDicomDeIdentificationV2Streaming.ipynb, learn how to setup a Spark Structured Streaming pipeline for Dicom Deidentification. Previous versions 5.0.0 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.3 4.3.0 4.2.4 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_5_0_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_5_0_0"
  },
  "1501": {
    "id": "1501",
    "title": "Spark NLP for Healthcare Release Notes 5.0.0",
    "content": "5.0.0 Highlights We are delighted to announce a suite of remarkable enhancements and updates in our latest release of Spark NLP for Healthcare. This release comes with the first Few Shot Text Classifier module and ONNX-optimized sBioBert sentence embeddings as well as 21 new clinical pretrained models and pipelines. It is a testament to our commitment to continuously innovate and improve, furnishing you with a more sophisticated and powerful toolkit for healthcare natural language processing. Introducing the very first Few Shot Classifier model to our toolkit to train classifier models with limited labeled data. New ONNX Sentence BioBERT Embeddings model, designed to enhance performance and accuracy 2 New Medical Question Answering models based on SOTA LLMs, designed to provide accurate answers to your inquiries against clinical notes 7 new NER models for Social Determinants of Health(SDOH), broadening our ability to identify and analyze crucial factors that impact health outcomes. New profiling pipelines for Social Determinants Of Health (SDOH), Voice Of The Patient (VOP), and Oncology to run multiple models at once in a single line New clinical multi-class classifier models for classification of articles based on cancer hallmarks and Covid-19 topics New Patient Urgency Text Classifier model, designed to analyze the level of emergency in medical situations requiring immediate assistance Brand-new Dutch clinical NER models, empowering accurate recognition and extraction of clinical entities in Dutch language New German sentence entity resolver model exclusively tailored for ICD-10-GM codes New feature to InternalResourceDownloader for point cache folder UpdateModels is now more flexible and can be used to update existing models in the cache folder New feature for ChunkFilterer to enable filtering chunks according to confidence thresholds New feature for StructuredDeidentification to make it flexible for different languages Enhanced ALAB module with Relation Extraction model training data preparation ability using document-level annotations Various core improvements; bug fixes, enhanced overall robustness and reliability of Spark NLP for Healthcare Improved Deidentification performance with refactoring Updated clinical_deidentification pipeline by enhancing the AGE entity extraction capability Minor corrections have been made to the calculation formulas in the Medicare Risk Adjustment Module Updated notebooks and demonstrations for making Spark NLP for Healthcare easier to navigate and understand The addition and update of numerous new clinical models and pipelines continue to reinforce our offering in the healthcare domain We believe that these enhancements will elevate your experience with Spark NLP for Healthcare, enabling more efficient, accurate, and streamlined analysis of healthcare-related natural language data. Introducing The Very First Few Shot Classifier Model To Our Toolkit To Train Classifier Models With Limited Labeled Data The FewShotClassifierApproach and FewShotClassifierModel annotators are new additions to the set of annotators available in the Spark NLP for Healthcare library. These annotators specifically target few-shot classification tasks, which involve training a model to make accurate predictions with limited labeled data. These new annotators provide a valuable capability for handling scenarios where labeled data is scarce or expensive to obtain. By effectively utilizing limited labeled examples, the few-shot classification approach enables the creation of models that can generalize and classify new instances accurately, even with minimal training data. In our experiment, we compared the Few-Shot Classifier trained on partial data, equivalent to 40% of our entire dataset, against the ClassifierDL trained on both full (80% of the dataset) and partial data. To maintain fairness, the test set was constant at 20% of the entire dataset for all cases, and the same sentence embeddings were employed across the board. The Few-Shot Classifier achieved a macro F1 score of 0.867, outperforming outperform that of the ClassifierDL using the full dataset, which scored a macro F1 score of 0.847. The ClassifierDL using partial data also showed comparable results to its full data counterpart, demonstrating its robustness with less training data, but it was still surpassed by the Few-Shot Classifier. This superior performance from the Few-Shot Classifier with less data signifies that it is highly efficient and effective, making it an excellent choice for scenarios where data scarcity is a concern. We’re excited to see how this innovative feature will enhance the future of text classification tasks in our library. Stay tuned for more updates as we continue to optimize and improve our offerings.   macro-f1-score weighted-f1-score accuracy ClassifierDL_full_Data 0.85 0.84 0.84 ClassifierDL_partial_Data 0.84 0.84 0.84 FewShot_partial_Data 0.87 0.87 0.87 The FewShotClassifier is designed to process sentence embeddings as input. It generates category annotations, providing labels along with confidence scores that range from 0 to 1. Input annotation types supported by this model include SENTENCE_EMBEDDINGS, while the output annotation type is CATEGORY. Example: few_shot_approach = FewShotClassifierApproach() .setLabelColumn(&quot;label&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(f&quot;/tmp/log_reg_graph.pb&quot;) .setEpochsNumber(10) .setBatchSize(1) .setLearningRate(0.001) pipeline = Pipeline( stages=[ document_asm, sentence_embeddings, graph_builder, few_shot_approach ]) data = [ [&quot;ADE_positive&quot;, &#39;Both PAN and methotrexate have been independently demonstrated to cause sensorineural hearing loss.&#39;], [&quot;ADE_positive&quot;, &#39;Adrenal suppression in a fetus due to administration of methylprednisolone has hitherto been rarely published.&#39;], [&quot;ADE_negative&quot;, &#39;Pathogenic mechanisms for the development of pseudomembranous colitis and the epidemiology of this condition in patients with AIDS are discussed.&#39;], [&quot;ADE_negative&quot;, &#39;I report a patient who developed the syndrome during treatment for schizophrenia with the antipsychotic agent molindone hydrochloride.&#39;] ] model = pipeline.fit(train_data) tests = [ &#39;Bleomycin pneumonitis potentiated by oxygen administration.&#39;, &#39;Enzymes derived from two different bacterial sources (Escherichia coli and Erwinia carotovora) are in common use.&#39;, ] Result: text prediction category Bleomycin pneumonitis potentiated by oxygen administration. ADE_positive Enzymes derived from two different bacterial sources (Escherichia coli and Erwinia carotovora) are in common use. ADE_negative please check: Text Classification with FewShotClassifier Notebook for more information New ONNX Sentence BioBERT Embeddings Model, Designed To Enhance Performance And Accuracy Spark NLP 5.0.0 introduced support for ONNX Runtime that can handle machine learning models in the ONNX format and has been proven to significantly boost inference performance across a multitude of models. This integration leads to substantial improvements when serving our LLM models, including BERT. We now introduce the first medical sentence embeddings, that is called sbiobert_base_cased_mli_onnx and optimized with ONNX, generating two times faster inference. Example: sbiobert_embeddings = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli_onnx&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) Result: Gives a 768 dimensional vector representation of the sentence. Please see the model card 2 New Medical Question Answering Models Based On SOTA LLMs, Designed To Provide Accurate Answers To Your Inquiries Against Clinical Notes Now we have clinical_notes_qa_base and clinical_notes_qa_large models that are capable of open-book question answering on Medical Notes. These new medical question answering models empower users to extract valuable information and insights from medical notes effectively. Whether you are a healthcare professional, researcher, or enthusiast, the clinical_notes_qa_base and clinical_notes_qa_large models offer advanced tools for retrieving targeted information from medical documents and enhancing your understanding of the medical domain. Example: med_qa = sparknlp_jsl.annotators.MedicalQuestionAnswering() .pretrained(&quot;clinical_notes_qa_base&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setCustomPrompt(&quot;Context: {context} n Question: {question} n Answer: &quot;) .setOutputCol(&quot;answer&quot;) note_text = &quot;&quot;&quot;Patient with a past medical history of hypertension for 15 years. n(Medical Transcription Sample Report) nHISTORY OF PRESENT ILLNESS: nThe patient is a 74-year-old white woman who has a past medical history of hypertension for 15 years, history of CVA with no residual hemiparesis and uterine cancer with pulmonary metastases, who presented for evaluation of recent worsening of the hypertension. According to the patient, she had stable blood pressure for the past 12-15 years on 10 mg of lisinopril.&quot;&quot;&quot; question = &quot;What is the primary issue reported by patient?&quot; Result: &quot;The primary issue reported by the patient is hypertension.&quot; please check: MEDICAL LLM Demo 7 New NER Models For Social Determinants Of Health (SDOH), Broadening Our Ability To Identify And Analyze Crucial Factors That Impact Health Outcomes Introducing our new set of SDOH NER models that are specifically designed to identify and extract entities related to various social determinants of health. Here is a brief overview of each model and the entities it predicts: model name description predicted entities ner_sdoh_access_to_healthcare extract entities related to access to healthcare Access_To_Care, Healthcare_Institution, Insurance_Status ner_sdoh_community_condition identify and extract entities associated with different community conditions Community_Safety, Environmental_Condition, Food_Insecurity, Housing, Transportation ner_sdoh_demographics extract entities associated with different demographic factors Age, Family_Member, Gender, Geographic_Entity, Language, Race_Ethnicity, Spiritual_Beliefs ner_sdoh_health_behaviours_problems extract entities associated with health behaviors and problems Communicable_Disease, Diet, Disability, Eating_Disorder, Exercise, Hyperlipidemia, Hypertension, Mental_Health, Obesity, Other_Disease, Quality_Of_Life, Sexual_Activity ner_sdoh_income_social_status extract entities associated with income and social status Education, Employment, Financial_Status, Income, Marital_Status, Population_Group ner_sdoh_social_environment extract entities associated with different aspects of the social environment Chidhood_Event, Legal_Issues, Social_Exclusion, Social_Support, Violence_Or_Abuse ner_sdoh_substance_usage extract entities associated with substance usage Alcohol, Smoking, Substance_Duration, Substance_Frequency, Substance_Quantity, Substance_Use Example: ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_health_behaviours_problems&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;&quot;&quot;The patient is a 54-year-old female with a complex medical history, including anxiety, depression, bulimia nervosa, elevated cholesterol, substance abuse, hypertension, and hyperlipidemia. Her partner has been diagnosed with hepatitis C. She reports a lack of regular exercise and a departure from a healthy diet for approximately two years due to chronic sciatic pain. Her sedentary lifestyle and poor diet have contributed to obesity, leading to a negative impact on her self-esteem. The patient is motivated to make lifestyle improvements, including weight loss, addressing her mental well-being, and enhancing her sexual satisfaction.&quot;&quot;&quot; Result: chunk begin end ner_label anxiety 78 84 Mental_Health depression 87 96 Mental_Health bulimia nervosa 99 113 Eating_Disorder elevated cholesterol 116 135 Hyperlipidemia hypertension 155 166 Hypertension hyperlipidemia 173 186 Hyperlipidemia hepatitis C 225 235 Communicable_Disease regular exercise 261 276 Exercise healthy diet 301 312 Diet chronic sciatic pain 349 368 Other_Disease sedentary lifestyle 375 393 Exercise poor diet 399 407 Diet obesity 429 435 Obesity self-esteem 474 484 Quality_Of_Life lifestyle improvements 521 542 Quality_Of_Life mental well-being 583 599 Mental_Health sexual satisfaction 620 638 Sexual_Activity please check Social Determinant of Health Notebook for more information New Profiling Pipelines For Social Determinants Of Health (SDOH), Voice Of The Patient (VOP), and Oncology To Run Multiple Models At Once In A Single Line We are excited to introduce our new profiling pipelines that focus on Social Determinants of Health (SDOH), Voice of Patient (VOP), and Oncology domains. We can use pretrained NER profiling pipelines for exploring all the available pretrained NER models at once. These profiling pipelines offer powerful tools for extracting meaningful information from medical text data in the respective domains. They assist in uncovering patterns, trends, and insights that are crucial for research, analysis, and decision-making in healthcare and related fields. Here’s a brief overview of each pipeline and the included NER models: Pipeline Name included NER Models ner_profiling_oncology ner_oncology_unspecific_posology, ner_oncology_tnm, ner_oncology_therapy, ner_oncology_test, ner_oncology_response_to_treatment, ner_oncology_posology, ner_oncology, ner_oncology_limited_80p_for_benchmarks, ner_oncology_diagnosis, ner_oncology_demographics, ner_oncology_biomarker, ner_oncology_anatomy_granular, ner_oncology_anatomy_general ner_profiling_sdoh ner_sdoh, ner_sdoh_social_environment_wip, ner_sdoh_mentions, ner_sdoh_demographics, ner_sdoh_community_condition, ner_sdoh_substance_usage, ner_sdoh_access_to_healthcare, ner_sdoh_health_behaviours_problems, ner_sdoh_income_social_status ner_profiling_vop ner_vop_clinical_dept, ner_vop_temporal, ner_vop_test, ner_vop, ner_vop_problem, ner_vop_problem_reduced, ner_vop_treatment, ner_vop_demographic, ner_vop_anatomy Example: from sparknlp.pretrained import PretrainedPipeline ner_profiling_pipeline = PretrainedPipeline(&quot;ner_profiling_oncology&quot;, &#39;en&#39;, &#39;clinical/models&#39;) For results and different examples, please see Voice of Patient Notebook Social Determinant of Health Notebook Oncology Notebook New Clinical Multi-Class Classifier Models for Classification Of Articles Based On Cancer Hallmarks And Covid-19 Topics We are pleased to introduce our two new multi-classifier models. Here’s a brief overview of each model and the entities they predict: model name description predicted entities multiclassifierdl_hoc This model makes a semantic classification of the article according to the hallmarks of cancer based on its abstract Activating_Invasion_And_Metastasis, Avoiding_Immune_Destruction, Cellular_Energetics, Enabling_Replicative_Immortality, Evading_Growth_Suppressors, Genomic_Instability_And_Mutation, Inducing_Angiogenesis, Resisting_Cell_Death, Sustaining_Proliferative_Signaling, Tumor_Promoting_Inflammation multiclassifierdl_litcovid This model determines the relevant COVID-19 topics of the article based on its abstract. Mechanism, Transmission, Diagnosis, Treatment, Prevention, Case_Report, Epidemic_Forecasting These multi-classifier models enhance the classification and analysis of articles by providing predictions related to specific domains. They facilitate efficient information retrieval and assist researchers and practitioners in quickly identifying articles relevant to cancer hallmarks or specific COVID-19 topics based on abstract content Example: multi_classifier_dl = MultiClassifierDLModel.pretrained(&quot;multiclassifierdl_litcovid&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;category&quot;) text = &quot;&quot;&quot;Low level of plasminogen increases risk for mortality in COVID-19 patients. The pathophysiology of coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), and especially of its complications is still not fully understood. In fact, a very high number of patients with COVID-19 die because of thromboembolic causes. A role of plasminogen, as precursor of fibrinolysis, has been hypothesized. In this study, we aimed to investigate the association between plasminogen levels and COVID-19-related outcomes in a population of 55 infected Caucasian patients (mean age: 69.8 +/- 14.3, 41.8% female). Low levels of plasminogen were significantly associated with inflammatory markers (CRP, PCT, and IL-6), markers of coagulation (D-dimer, INR, and APTT), and markers of organ dysfunctions (high fasting blood glucose and decrease in the glomerular filtration rate). A multidimensional analysis model, including the correlation of the expression of coagulation with inflammatory parameters, indicated that plasminogen tended to cluster together with IL-6, hence suggesting a common pathway of activation during disease&#39;s complication. Moreover, low levels of plasminogen strongly correlated with mortality in COVID-19 patients even after multiple adjustments for presence of confounding. These data suggest that plasminogen may play a pivotal role in controlling the complex mechanisms beyond the COVID-19 complications, and may be useful both as biomarker for prognosis and for therapeutic target against this extremely aggressive infection.&quot;&quot;&quot; Result: text result Low level of plasminogen increases risk for mortality in COVID-19 patients. The pathophysiology of coronavirus diseas… [Mechanism, Treatment, Diagnosis] New Patient Urgency Text Classifier Model, Designed To Analyze The Level Of Emergency In Medical Situations Requiring Immediate Assistance The Patient Urgency Text Classifier model is designed to analyze the level of emergency in medical situations that demand immediate assistance from medical organizations. bert_sequence_classifier_patient_urgency: This model has undergone training using a dataset of emergency calls, which have been labeled with three distinct classes (High, Medium, Low). Example: sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_patient_urgency&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;prediction&quot;) sample_text_list = [ &quot;I think my father is having a stroke. His face is drooping, he can’t move his right side and he’s slurring his speech. He is breathing, but it’s really ragged. And, he is not responding when I talk to him…he seems out of it.&quot;, &quot;My old neighbor has fallen and cannot get up. She is conscious, but she is in a lot of pain and cannot move.&quot;, &quot;My wife has been in pain all morning. She had an operation a few days ago. This morning, she woke up in pain and is having a hard time moving around. The pain is around the surgery area. It is not severe, but it’s making her uncomfortable. She does not have fever, nausea or vomiting. There’s some slight feeling of being bloated.&quot; ] Result: text result I think my father is having a stroke. His face is drooping, he can’t move his right side and he’s… High My old neighbor has fallen and cannot get up. She is conscious, but she is in a lot of pain and c… Medium My wife has been in pain all morning. She had an operation a few days ago. This morning, she woke… Low Brand-new Dutch Clinical NER Models, Empowering Accurate Recognition And Extraction Of Clinical Entities In Dutch Language ner_clinical and bert_token_classifier_ner_clinical: These two Dutch clinical NER models provide valuable tools for processing and analyzing Dutch clinical texts. They assist in automating the extraction of important clinical information, facilitating research, medical documentation, and other applications within the Dutch healthcare domain. Example: ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;nl&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;&quot;&quot;Dhr. Van Dijk, 58 jaar oud, kwam naar de kliniek met klachten van aanhoudende hoest, koorts en kortademigheid. We hebben besloten om een röntgenfoto van de borst, bloedonderzoek en een CT-scan te laten uitvoeren. De resultaten wezen op een ernstige longontsteking, een verhoogd aantal witte bloedcellen en mogelijk COPD. Hem is een antibiotica kuur en een sterke hoestsiroop voorgeschreven. Daarnaast adviseren we hem een voedzaam dieet te volgen.&quot;&quot;&quot; Result: chunk begin end ner_label confidence aanhoudende hoest 66 82 PROBLEM 0.82 koorts 85 90 PROBLEM 0.99 kortademigheid 95 108 PROBLEM 0.99 röntgenfoto van de borst 137 160 TEST 0.61 bloedonderzoek 163 176 TEST 0.92 een CT-scan 181 191 TEST 0.73 ernstige longontsteking 240 262 PROBLEM 0.78 een verhoogd aantal witte bloedcellen 265 301 PROBLEM 0.45 COPD 315 318 PROBLEM 0.98 antibiotica kuur 332 347 TREATMENT 0.63 een sterke hoestsiroop 352 373 TREATMENT 0.47 een voedzaam dieet 418 435 TREATMENT 0.69 New German Sentence Entity Resolver Model Exclusively Tailored For ICD-10-GM Codes robertaresolve_icd10gm: This model maps extracted medical entities to ICD10-GM codes for the German language using xlmroberta_embeddings_paraphrase_mpnet_base_v2 embeddings. With this German Sentence Entity Resolver, you can efficiently analyze German medical texts and obtain the relevant ICD-10-GM codes associated with the extracted medical entities. This enables precise categorization and classification of medical data, enhancing medical research, coding, and analysis in the German healthcare domain. Example: icd10gm_resolver = SentenceEntityResolverModel.pretrained(&quot;robertaresolve_icd10gm&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;icd10gm_code&quot;) text = [&quot;Dyspnoe&quot;, &quot;Lymphknoten&quot;] Result: chunks code resolutions all_codes all_distances Dyspnoe R06.0 Dyspnoe:::Dysphagie:::Dysurie… R06.0:::R13:::R30.0… 0.00:::1.09:::1.17… Lymphknoten D36.0 Lymphknoten:::Lymphknotenvergrößerung… D36.0:::R59:::Q82.0… 0.00:::0.04:::0.12… New Feature To InternalResourceDownloader To Point Cache Folder By setting the cache_folder_path, you can control where the downloaded resources are stored, enabling easy access and reuse of the downloaded models in subsequent operations or workflows. Example: from sparknlp_jsl.pretrained import InternalResourceDownloader #The first argument is the path to the zip file and the second one is the folder. InternalResourceDownloader.downloadModelDirectly(&quot;clinical/models/ner_clinical_large_en_2.5.0_2.4_1590021302624.zip&quot;, &quot;clinical/models&quot;, unzip=False, cache_folder_path=&quot;/content&quot;) UpdateModels Is Now More Flexible And Can Be Used To Update Existing Models In The Cache Folder UpdateModels is a helper class that provides functionality to update existing pretrained models located in the cache folder. It offers two main methods: updateCacheModels and updateModels. UpdateModels.updateCacheModels(cache_folder=&#39;&#39;): This method refreshes all the pretrained models located in the cache pretrained folder. UpdateModels.updateModels(): This method downloads all the new pretrained models that have been released since the specified date interval. model_names: A list of names of the models to be downloaded. language: The language of the models, with a default value of “en”. start_date: The starting date used to filter the models, in the format “yyyy-MM-dd”. end_date: The ending date used to filter the models, in the format “yyyy-MM-dd”. cache_folder: The path indicating where the models will be downloaded and stored. Example: from sparknlp_jsl.updateModels import UpdateModels UpdateModels.updateModels(start_date = &quot;2021-01-01&quot;, end_date = &quot;2023-07-07&quot;, model_names=[&quot;ner_clinical&quot;,&quot;ner_jsl&quot;], language=&quot;en&quot;, remote_loc=&quot;clinical/models&quot;, cache_folder=&quot;/content/jsl_models&quot; ) ls /content/jsl_models/ Result: ner_clinical_en_3.0.0_3.0_1617208419368/ ner_jsl_en_4.2.0_3.0_1666181370373/ New Feature For ChunkFilterer To Enable Filtering Chunks According To Confidence Thresholds We have added a new setEntitiesConfidence parameter to ChunkFilterer annotator that enables filtering the chunks according to the confidence thresholds. The only thing you need to do is provide a dictionary that has the NER labels as keys and the confidence thresholds as values. Example: posology_ner = MedicalNerModel.pretrained(&quot;ner_posology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;posology_ner_chunk&quot;) chunk_filterer = ChunkFilterer() .setInputCols(&quot;sentence&quot;,&quot;posology_ner_chunk&quot;) .setOutputCol(&quot;chunk_filtered&quot;) .setFilterEntity(&quot;entity&quot;) .setEntitiesConfidence({&quot;DRUG&quot;:0.9, &quot;FREQUENCY&quot;:0.9, &quot;DOSAGE&quot;:0.9, &quot;DURATION&quot;:0.9, &quot;STRENGTH&quot;:0.9}) sample_text = &#39;The patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night.&#39; Detected chunks: sentence_id chunks entities confidence 0 1 DOSAGE 0.99 0 capsule FORM 0.99 0 Advil DRUG 0.99 0 for 5 days DURATION 0.71 1 40 units DOSAGE 0.85 1 insulin glargine DRUG 0.83 1 at night FREQUENCY 0.81 Filtered by confidence scores: sentence_id chunks entitie confidence 0 1 DOSAGE 0.99 0 capsule FORM 0.99 0 Advil DRUG 0.99 New Feature For StructuredDeidentification To Make It Flexible For Different Languages The new language feature added to StructuredDeidentification enhances its flexibility by supporting different languages for deidentification tasks. Example: from sparknlp_jsl.structured_deidentification import StructuredDeidentification obfuscator = StructuredDeidentification(spark, {&quot;NAME&quot;:&quot;PATIENT&quot;, &quot;AGE&quot;:&quot;AGE&quot;, &quot;ADDRESS&quot;:&quot;LOCATION&quot;, &quot;DOB&quot;:&quot;DATE&quot;}, obfuscateRefSource = &quot;faker&quot;, language=&quot;de&quot;) obfuscator_df = obfuscator.obfuscateColumns(df) Original Dataframe: NAME DOB AGE ADDRESS Cecilia Chapman 04/02/1935 83 711-2880 Nulla St. Mankato Mississippi Iris Watson 03/10/2009 9 283 8562 Fusce Rd. Frederick Nebraska Bryar Pitts 11/01/1921 98 5543 Aliquet St. Fort Dodge GA Theodore Lowe 13/02/2002 16 Ap #867-859 Sit Rd. Azusa New York Calista Wise 20/08/1942 76 7292 Dictum Av. San Antonio MI Obfuscated Result: NAME DOB AGE ADDRESS Giesela Janzen 19/03/1935 86 Annie-Lübs-Platz 8/0 Folker Sonntag 30/10/2009 5 Georg-Albers-Platz 8/7 Matthäus Koch 13/02/1921 99 Annelore-Schmidt-Straße 6/2 Elly Metz 23/03/2002 17 Klemens-Thanel-Straße 4 Friederike Heinrich 30/09/1942 75 Rita-Süßebier-Weg 550 Enhanced ALAB Module With Relation Extraction Model Training Data Preparation Ability Using Document-Level Annotations In order to facilitate the preparation of document-level annotated data for training Relation Extraction models, we have introduced a new parameter called doc_wise_annot to the get_relation_extraction_data method in the ALAB module. By setting the doc_wise_annot parameter to True, the method will return the dataframe with sentence-cross annotations, if they exist. The default value is False. Example: alab.get_relation_extraction_data( spark=spark, input_json_path=&#39;alab_demo.json&#39;, ground_truth=True, ... doc_wise_annot=True ) Various Core Improvements: Bug Fixes, Enhanced Overall Robustness, And Reliability Of Spark NLP For Healthcare Improved Deidentification performance with refactoring Updated clinical_deidentification pipeline by enhancing the AGE entity extraction capability Minor corrections have been made to the calculation formulas in the Medicare Risk Adjustment Module Updated Notebooks And Demonstrations For making Spark NLP For Healthcare Easier To Navigate And Understand New Text Classification with Few Shot Classifier Notebook New Voice of Patient Notebook New Social Determinant of Health Notebook Updated Oncology Notebook for latest models New All-In-One Social Determinant of Health Demo Updated Medical LLM Demo Updated German ICD10GM Resolver Demo We Have Added And Updated A Substantial Number Of New Clinical Models And Pipelines, Further Solidifying Our Offering In The Healthcare Domain. clinical_notes_qa_base clinical_notes_qa_large ner_profiling_vop ner_profiling_sdoh ner_profiling_oncology ner_sdoh_access_to_healthcare ner_sdoh_community_condition ner_sdoh_demographics ner_sdoh_health_behaviours_problems ner_sdoh_income_social_status ner_sdoh_social_environment ner_sdoh_substance_usage multiclassifierdl_hoc multiclassifierdl_litcovid bert_sequence_classifier_patient_urgency ner_clinical -&gt; nl bert_token_classifier_ner_clinical -&gt; nl robertaresolve_icd10gm -&gt; de icd10gm_resolver_pipeline -&gt; de clinical_deidentification sbiobert_base_cased_mli_onnx For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_5_0_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_5_0_0"
  },
  "1502": {
    "id": "1502",
    "title": "Spark NLP for Healthcare Release Notes 5.0.1",
    "content": "5.0.1 Highlights We are delighted to announce a suite of remarkable enhancements and updates in our latest release of Spark NLP for Healthcare. This release comes with the first NER models that are augmented by LangTest library for robustness and bias as well as a support for RxHCC risk score calculation in latest versions. Integrated the Risk Adjustment for Prescription Drug Hierarchical Condition Categories (RxHCC) model into our risk adjustment score calculation engine Advanced entity detection for Section Headers and Diagnoses entities in clinical notes Augmented NER models by leveraging the capabilities of the LangTest library Enhanced Sentence Entity Resolver Models for associating clinical entities with LOINC Strengthen the performance of assertion status detection by reinforcing it with entity type constraints Entity blacklisting in AssertionFilterer to manage assertion status effectively Enhanced ChunkMergeApproach and ChunkFilterer with case sensitivity settings New feature for ChunkMergeApproach to enable filtering chunks according to confidence thresholds Included sentence ID information in Relation Extraction Model metadata Various core improvements; bug fixes, enhanced overall robustness and reliability of Spark NLP for Healthcare Improved deidentification regex pattern for Romanian language Fixed exploded sentences issue in RelationExtractionDLModel Updated notebooks and demonstrations for making Spark NLP for Healthcare easier to navigate and understand The addition and update of numerous new clinical models and pipelines continue to reinforce our offering in the healthcare domain We believe that these enhancements will elevate your experience with Spark NLP for Healthcare, enabling more efficient, accurate, and streamlined analysis of healthcare-related natural language data. Integrated The Risk Adjustment For Prescription Drug Hierarchical Condition Categories (RxHCC) Model Into Our Risk Adjustment Score Calculation Engine We have integrated the RxHCC into our existing risk adjustment score calculation module. This means more accurate and comprehensive risk adjustment scores, especially for patients whose healthcare costs are significantly influenced by prescription drug usage. This enhancement brings a holistic view of a patient’s healthcare needs, further improving the precision of risk assessment. We are pleased to introduce support for RxHCC risk score calculation in two new versions: v05 (applicable for 2020, 2021, 2022, and 2023) and v08 (applicable for 2022 and 2023). To utilize these versions with specific years, simply use the following formats: profileRxHCCV05YXX for v05 and profileRxHCCV08YXX for v08. Example: Input Data Frame: filename Age icd10_code Extracted_Entities_vs_ICD_Codes Gender eligibility orec esrd patient_01.txt 66 C49.9, J18.9, C49.9, D61.81, I26, M06.9 {leiomyosarcoma, C49.9}, {pneumonia, J18.9}, … F CE_NoLowAged 1 false patient_02.txt 59 C50.92, P61.4, C80.1 {breast cancer, C50.92}, {dysplasia, P61.4}, … F CE_NoLowNoAged 0 true # v08 year 2023 from sparknlp_jsl.functions import profileRxHCCV08Y23 df = df.withColumn(&quot;rxhcc_profile&quot;, profileRxHCCV08Y23(df.icd10_code, df.Age, df.Gender, df.eligibility, df.orec, df.esrd)) df = df.withColumn(&quot;rxhcc_profile&quot;, F.from_json(F.col(&quot;rxhcc_profile&quot;), schema)) df = df.withColumn(&quot;risk_score&quot;, df.rxhcc_profile.getItem(&quot;risk_score&quot;)) .withColumn(&quot;parameters&quot;, df.rxhcc_profile.getItem(&quot;parameters&quot;)) .withColumn(&quot;details&quot;, df.rxhcc_profile.getItem(&quot;details&quot;)) Results (V08-Y23): filename Age icd10_code Extracted_Entities_vs_ICD_Codes Gender eligibility orec esrd rxhcc_profile risk_score parameters details patient_01.txt 66 C49.9, J18.9, C49.9, D61.81, I26, M06.9 {leiomyosarcoma, C49.9}, {pneumonia, J18.9}, … F CE_NoLowAged 1 false {0.575, null, {“elig”:”CE_NoLowAged”,”age”:66, … 0.575 {“elig”:”CE_NoLowAged”,”age”: … {“Rx_CE_NoLowAged_F65_69”… patient_02.txt 59 C50.92, P61.4, C80.1 {breast cancer, C50.92}, {dysplasia, P61.4}, … F CE_NoLowNoAged 0 true {0.367, null, {“elig”:”CE_NoLowNoAged”,”age”:59… 0.367 {“elig”:”CE_NoLowNoAged”,”age”… { Rx_CE_NoLowNoAged_F55_5… Advanced Entity Detection For Section Headers And Diagnoses Entities In Clinical Notes We have a new state-of-the-art NER model that is specifically designed to extract vital data from clinical documents, focusing on two key aspects: Section Headers and Diagnoses. By accurately identifying and labeling various medical conditions like heart disease, diabetes, and Alzheimer’s disease, this model provides unparalleled insights into diagnosis and treatment trends. Example: clinical_ner = MedicalNerModel.pretrained(&quot;ner_section_header_diagnosis&quot;, &quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) .setLabelCasing(&quot;upper&quot;) text = &quot;&quot;&quot; Medical History: Patient has a history of Chronic respiratory disease. Clinical History: Patient presented with shortness of breath and chest pain. Chief Complaint: Patient complained of chest pain and difficulty breathing. History of Present Illness: Patient has been experiencing chest pain and shortness of breath for the past week. Symptoms were relieved by medication at first but became worse over time. Past Medical History: Patient has a history of Asthma and was previously diagnosed with Bronchitis. Medications: Patient is currently taking Albuterol, Singulair, and Advair for respiratory issues. Allergies: Patient has a documented allergy to Penicillin. &quot;&quot;&quot; Result: chunks entities confidence Medical History MEDICAL_HISTORY_HEADER 0.81 Chronic respiratory disease RESPIRATORY_DISEASE 0.74 Clinical History CLINICAL_HISTORY_HEADER 0.77 Chief Complaint CHIEF_COMPLAINT_HEADER 0.85 History of Present Illness HISTORY_PRES_ILNESS_HEADER 0.99 Past Medical History MEDICAL_HISTORY_HEADER 0.71 Asthma RESPIRATORY_DISEASE 0.99 Bronchitis RESPIRATORY_DISEASE 0.84 Medications MEDICATIONS_HEADER 0.99 Allergies ALLERGIES_HEADER 0.99 Please check: ner_section_header_diagnosis model card for more information. Augmented NER Models Leveraging LangTest Library Capabilities Newly introduced augmented NER models, namely ner_posology_langtest, ner_jsl_langtest, ner_ade_clinical_langtest, and ner_sdoh_langtest, are powered by the innovative LangTest library. This cutting-edge NLP toolkit is at the forefront of language processing advancements, incorporating state-of-the-art techniques and algorithms to enhance the capabilities of our models significantly. Example: clinical_ner = MedicalNerModel.pretrained(&quot;ner_sdoh_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;&quot;&quot;Smith is 55 years old, living in New York, a divorced Mexcian American woman with financial problems. She speaks Spanish and Portuguese. She lives in an apartment. She has been struggling with diabetes for the past 10 years and has recently been experiencing frequent hospitalizations due to uncontrolled blood sugar levels. Smith works as a cleaning assistant and cannot access health insurance or paid sick leave.&quot;&quot;&quot; Result: chunk begin end ner_label 55 years old 9 20 Age New York 33 40 Geographic_Entity divorced 45 52 Marital_Status Mexcian American 54 69 Race_Ethnicity woman 71 75 Gender financial problems 82 99 Financial_Status She 102 104 Gender Spanish 113 119 Language Portuguese 125 134 Language She 137 139 Gender apartment 153 161 Housing She 164 166 Gender diabetes 193 200 Other_Disease hospitalizations 268 283 Other_SDoH_Keywords cleaning assistant 342 359 Employment access health ins… 372 394 Insurance_Status Enhanced Sentence Entity Resolver Models For Associating Clinical Entities With LOINC Introducing the new sbiobertresolve_loinc_numeric model and improving the sbiobertresolve_loinc_augmented model, both offering enhanced accuracy for mapping medical laboratory observations and clinical measurements to their corresponding Logical Observation Identifiers Names and Codes (LOINC). The sbiobertresolve_loinc_numeric model is specialized in numeric LOINC codes, as it was trained without the inclusion of LOINC “Document Ontology” codes starting with the letter “L”. On the other hand, the sbiobertresolve_loinc_augmented model offers broader functionality, capable of returning both numeric and document ontology codes for enhanced versatility. Example: resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_loinc_numeric&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;loinc_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) sample_text = &quot;The patient is a 22-year-old female with a history of obesity. She has a Body mass index (BMI) of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126.&quot; Results: chunk entity loinc_code all_codes resolutions BMI Test 39156-5 39156-5, 89270-3, 100847-3… [BMI [Body mass index], BMI Est [Body mass index], BldA [Gas &amp; ammonia panel], … aspartate aminotransferase Test 14409-7 14409-7, 1916-6, 16324-6, … [Aspartate aminotransferase [Aspartate aminotransferase], Aspartate aminotransf… alanine aminotransferase Test 16324-6 16324-6, 16325-3, 1916-6, … [Alanine aminotransferase [Alanine aminotransferase], Alanine aminotransferase/… Strengthen The Performance Of Assertion Status Detection By Reinforcing With Entity Type Constraints Introducing the latest enhancements to our AssertionDLModel - the setEntityAssertion and setEntityAssertionCaseSensitive parameters. Now, you can effortlessly constrain assertions based on specific entity types using a convenient dictionary format: {&quot;entity&quot;: [assertion_label1, assertion_label2, .. assertion_labelN]}. When an entity is not found in the dictionary, no constraints are applied, ensuring flexibility in your data processing. With the setEntityAssertionCaseSensitive parameter, you can control the case sensitivity for both entities and assertion labels. Unleash the full potential of your NLP model with these cutting-edge additions to the AssertionDLModel. Example: clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_jsl_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setEntityAssertionCaseSensitive(False) .setEntityAssertion({ &quot;PROBLEM&quot;: [&quot;hypothetical&quot;, &quot;absent&quot;], &quot;treAtment&quot;: [&quot;present&quot;], &quot;TEST&quot;: [&quot;POssible&quot;], }) text = &#39;&#39;&#39; A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, and associated with an acute hepatitis, presented with a one-week history of polyuria, poor appetite, and vomiting. She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation. Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent laboratory findings on admission were: serum glucose 111 mg/dl, creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, and venous pH 7.27. &#39;&#39;&#39; Result: idx chunks entities assertion confidence 0 metformin TREATMENT Present 0.54 1 glipizide TREATMENT Present 0.99 2 dapagliflozin TREATMENT Present 1.0 3 HTG PROBLEM Hypothetical 1.0 4 Physical examination TEST Possible 0.94 5 tenderness PROBLEM Absent 1.0 6 guarding PROBLEM Absent 1.0 7 rigidity PROBLEM Hypothetical 0.99 Entity Blacklisting In AssertionFilterer For Effective Assertion Status Management With the setBlackList option in the AssertionFilterer annotator, you can now blacklist specific entities based on their assertion labels. Example: clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_jsl_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) assertion_filterer = AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;assertion_filtered&quot;) .setBlackList([&quot;Hypothetical&quot;]) text = &quot;&quot;&quot;Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. No alopecia and pain noted&quot;&quot;&quot; Without Filtering Results:   chunks entities assertion confidence 0 a headache PROBLEM Present 1 1 a head CT TEST Hypothetical 1 2 anxious PROBLEM SomeoneElse 0.77 3 alopecia PROBLEM Hypothetical 0.97 4 pain PROBLEM Hypothetical 0.99 Filtered Results:   chunks entities assertion confidence 0 a headache PROBLEM Present 0.97 1 anxious PROBLEM SomeoneElse 0.99 Enhanced ChunkMergeApproach And ChunkFilterer With Case Sensitivity Settings The setCaseSensitive parameter now applies to the whitelist and blacklist functionalities. As part of the enhancement, this parameter has been included in the filtering feature, which serves as a superclass for, ChunkFilterer and ChunkMergeApproach. With this update, the caseSensitive setting can be conveniently utilized across these classes, offering improved control and consistency in the filtering process. Example: posology_ner = MedicalNerModel.pretrained(&quot;ner_posology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) chunk_filterer = ChunkFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;) .setOutputCol(&quot;chunk_filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList([&#39;ADVIL&#39;,&#39;Metformin&#39;, &#39;Insulin Lispro&#39;]) .setCaseSensitive(False) text =&quot;&quot;&quot;The patient was prescribed 1 capsule of Advil for 5 days . She was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , metformin 1000 mg two times a day.&quot;&quot;&quot; Result: # detected ner chunks [&#39;1&#39;, &#39;capsule&#39;, &#39;Advil&#39;, &#39;for 5 days&#39;, &#39;40 units&#39;, &#39;insulin glargine&#39;, &#39;at night&#39;, &#39;12 units&#39;, &#39;insulin lispro&#39;, &#39;with meals&#39;, &#39;metformin&#39;, &#39;1000 mg&#39;, &#39;two times a day&#39;] # filtered ner chunks [&#39;Advil&#39;, &#39;insulin lispro&#39;, &#39;metformin&#39;] New Feature For ChunkMergeApproach To Enable Filtering Chunks According To Confidence Thresholds We have added a new setEntitiesConfidence parameter to ChunkMergeApproach annotator that enables filtering the chunks according to the confidence thresholds. The only thing you need to do is provide a csv file that has the NER labels as keys and the confidence thresholds as values. Example: conf_dict = &quot;&quot;&quot;DRUG,0.99 FREQUENCY,0.99 DOSAGE,0.99 DURATION,0.99 STRENGTH,0.99 &quot;&quot;&quot; with open(&#39;conf_dict.csv&#39;, &#39;w&#39;) as f: f.write(conf_dict) chunk_merger = ChunkMergeApproach() .setInputCols(&quot;posology_ner_chunk&quot;) .setOutputCol(&#39;merged_ner_chunk&#39;) .setEntitiesConfidenceResource(&quot;conf_dict.csv&quot;) sample_text = &#39;The patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night.&#39; Detected chunks: chunks begin end entities confidence 1 27 27 DOSAGE 0.99 capsule 29 35 FORM 0.99 Advil 40 44 DRUG 0.99 for 5 days 46 55 DURATION 0.71 40 units 125 132 DOSAGE 0.85 insulin glargine 137 152 DRUG 0.83 at night 154 161 FREQUENCY 0.81 Filtered by confidence scores: chunks begin end entities confidence 1 27 27 DOSAGE 0.99 capsule 29 35 FORM 0.99 Advil 40 44 DRUG 0.99 Included Sentence Id Information In RelationExtractionModel Metadata Our Relation Extraction Models have been upgraded with the inclusion of sentence information in the metadata. This enhancement offers a deeper understanding of the extracted relationships and facilitates more precise analysis and interpretation of the results. Example: re_dl_model = RelationExtractionDLModel.pretrained(&#39;redl_bodypart_direction_biobert&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations_dl&quot;) .setPredictionThreshold(0.5) text = &#39;&#39;&#39;MRI demonstrated infarction in the upper brain stem , and right basil ganglia. No neurologic deficits other than some numbness in his left hand. there is a problem at right chest.&#39;&#39;&#39; Result: idx sentence chunk1 entity1 chunk2 entity2 relation confidence 0 0 upper Direction brain stem Internal_organ_or_component 1 1.0 1 0 upper Direction basil ganglia Internal_organ_or_component 0 0.99 2 0 right Direction basil ganglia Internal_organ_or_component 1 1.0 3 1 left Direction hand External_body_part_or_region 1 1.0 4 2 right Direction chest External_body_part_or_region 1 1.0 Various Core Improvements: Bug Fixes, Enhanced Overall Robustness, And Reliability Of Spark NLP For Healthcare Improved deidentification regex pattern for Romanian language Fixed exploded sentences issue in Relation Extraction DL (when .setExplodeSentences(True) is used in SentenceDetector, RelationExtractionDLModel’s relation output has only the sentence#0 relations, other sentences’ relations are not displayed.) Updated Notebooks And Demonstrations For making Spark NLP For Healthcare Easier To Navigate And Understand Updated Clinical_Named_Entity_Recognition_Model notebook according to latest improvement in ChunkFilterer Updated Clinical_Assertion_Model notebook according to latest improvement in AssertionFilterer Updated Clinical_NER_Chunk_Merger notebook according to latest improvement in ChunkMergerApproach Updated Clinical_Relation_Extraction notebook according to latest improvement in RelationExtractionModel’s metadata Updated Calculate_Medicare_Risk_Adjustment_Score notebook according to latest improvement in HCC implementation We Have Added And Updated A Substantial Number Of New Clinical Models And Pipelines, Further Solidifying Our Offering In The Healthcare Domain. ner_section_header_diagnosis ner_posology_langtest ner_jsl_langtest ner_sdoh_langtest ner_ade_clinical_langtest sbiobertresolve_loinc_numeric sbiobertresolve_loinc_augmented For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_5_0_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_5_0_1"
  },
  "1503": {
    "id": "1503",
    "title": "Spark NLP for Healthcare Release Notes 5.0.2",
    "content": "5.0.2 Highlights We are delighted to announce a suite of remarkable enhancements and updates in our latest release of Spark NLP for Healthcare. This release comes with the first Text2SQL module and ONNX-optimized medical text summarization models as well as 20 new clinical pretrained models and pipelines. It is a testament to our commitment to continuously innovate and improve, furnishing you with a more sophisticated and powerful toolkit for healthcare natural language processing. Text2SQL module to translate text prompts into accurate SQL queries Support for ONNX integration of Seq2Seq models such as MedicalTextGenerator, MedicalSummarizer, and MedicalQuestionAnswering 2 new medical QA models and 1 new summarization model optimized with ONNX. Brand new clinical NER model for extracting clinical entities in the Portuguese language 3 novel assertion status (negativity scope) detection models tailored for entities extracted from Voice of Patient (VoP) notes Detecting assertion statuses of entities related to Social Determinants of Health (SDOH) identified within clinical notes Classifying transportation insecurity within the context of Social Determinants of Health (SDOH) Text Classifier models to infer Age Groups from health records, even in the absence of explicit age indications or mentions. Mapping ICD-10-CM codes to Medicare Severity-Diagnosis Related Group (MS-DRG) Five new sentence entity resolver (terminology mapping) pretrained pipelines, designed to streamline solutions with a single line of code Various core improvements; bug fixes, enhanced overall robustness and reliability of Spark NLP for Healthcare Improvement of the deidentification faker list (city, street, hospital, profession) for various language Updated notebooks and demonstrations for making Spark NLP for Healthcare easier to navigate and understand The addition and update of numerous new clinical models and pipelines continue to reinforce our offering in the healthcare domain We believe that these enhancements will elevate your experience with Spark NLP for Healthcare, enabling more efficient, accurate, and streamlined analysis of healthcare-related natural language data. Text2SQL module to translate text prompts into accurate SQL queries We are excited to introduce our latest innovation, the Text2SQL annotator. This powerful tool revolutionizes the way you interact with databases by effortlessly translating natural language text prompts into accurate and effective SQL queries. With the integration of a state-of-the-art LLM, this annotator opens new possibilities for enhanced data retrieval and manipulation, streamlining your workflow and boosting efficiency. Also we have a new text2sql_mimicsql model that is specifically finetuned on MIMIC-III dataset schema for enhancing the precision of SQL queries derived from medical natural language queries on MIMIC dataset. Please check the model card for more details. Example: text2sql = Text2SQL.pretrained(&quot;text2sql_mimicsql&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sql&quot;) sample_text = &quot;Calulate the total number of patients who had icd9 code 5771&quot; Results: SQL Query SELECT COUNT ( DISTINCT DEMOGRAPHIC.”SUBJECT_ID” ) FROM DEMOGRAPHIC INNER JOIN PROCEDURES on DEMOGRAPHIC.HADM_ID = PROCEDURES.HADM_ID WHERE PROCEDURES.”ICD9_CODE” = “5771” Please check: Text to SQL Generation Notebook for more information Support for ONNX integration of Medical Seq2Seq models ONNX integration empowers our Seq2Seq models to perform their tasks more efficiently and effectively. By leveraging the optimized capabilities of these LLMs through ONNX, the processing speed and overall performance of these models are substantially improved. 2 New Medical QA Models and 1 New Summarization Model Optimized with ONNX. We’re excited to introduce the ONNX-powered versions of summarizer_clinical_laymen, clinical_notes_qa_base and clinical_notes_qa_large models, representing a significant advancement in efficiency and versatility. Model Description summarizer_clinical_laymen_onnx The ONNX version of summarizer_clinical_laymen model that is finetuned with custom dataset by John Snow Labs to avoid using clinical jargon on the summaries. clinical_notes_qa_base_onnx The ONNX version of clinical_notes_qa_base model that is capable of open-book question answering on Medical Notes. clinical_notes_qa_large_onnx The ONNX version of clinical_notes_qa_large model that is capable of open-book question answering on Medical Notes. Example: med_qa = MedicalQuestionAnswering() .pretrained(&quot;clinical_notes_qa_base_onnx&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setCustomPrompt(&quot;Context: {context} n Question: {question} n Answer: &quot;) .setOutputCol(&quot;answer&quot;) note_text = &quot;Patient with a past medical history of hypertension for 15 years. n(Medical Transcription Sample Report) nHISTORY OF PRESENT ILLNESS: nThe patient is a 74-year-old white woman who has a past medical history of hypertension for 15 years, history of CVA with no residual hemiparesis and uterine cancer with pulmonary metastases, who presented for evaluation of recent worsening of the hypertension. According to the patient, she had stable blood pressure for the past 12-15 years on 10 mg of lisinopril.&quot; question = &quot;What is the primary issue reported by patient?&quot; Results: answer The primary issue reported by the patient is hypertension. Brand New Clinical NER Model For Extracting Clinical Entities In The Portuguese Language Portuguese clinical NER models provide valuable tools for processing and analyzing Portuguese clinical texts. They assist in automating the extraction of important clinical information, facilitating research, medical documentation, and other applications within the Portuguese healthcare domain. For more details, please check the model card. Example: ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;pt&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;&quot;&quot;A paciente apresenta sensibilidade dentária ao consumir alimentos quentes e frios. Realizou-se um exame clínico e radiográfico para avaliar possíveis cáries ou problemas na raiz do dente.&quot;&quot;&quot; Results: chunk begin end ner_label sensibilidade dentária 21 42 PROBLEM alimentos 56 64 TREATMENT exame clínico 98 110 TEST cáries 150 155 PROBLEM problemas na raiz do dente 160 185 PROBLEM 3 Novel Assertion Status (Negativity Scope) Detection Models Tailored for Entities Extracted from Voice of Patient (VoP) Notes We are excited to announce 3 new assertion status detection models that can classify assertions for the detected entities in VoP notes with the Hypothetical_Or_Absent, Present_Or_Past, and SomeoneElse labels. Model Description assertion_vop_clinical This model is trained with embeddings_clinical embeddings and predicts the assertion status of the detected chunks. assertion_vop_clinical_medium This model is trained with embeddings_clinical_medium embeddings and predicts the assertion status of the detected chunks. assertion_vop_clinical_large This model is trained with embeddings_clinical_large embeddings and predicts the assertion status of the detected chunks. Example: assertion = AssertionDLModel.pretrained(&quot;assertion_vop_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) sample_text = &quot;I was feeling anxiety honestly. Can it bring on tremors? It was right after my friend was diagnosed with diabetes.&quot; Results: chunk begin end ner_label sent_id assertion confidence anxiety 14 20 PsychologicalCondition 0 Present_Or_Past 0.98 tremors 48 54 Symptom 1 Hypothetical_Or_Absent 0.99 diabetes 105 112 Disease 2 SomeoneElse 0.99 Detecting Assertion Statuses (Negativity Scope) of Entities Related to Social Determinants of Health (SDOH) Identified within Clinical Notes We are introducing a new assertion_sdoh_wip assertion status detection model that can classify assertions for the detected SDOH entities in text into six distinct labels: Absent, Present, Someone_Else, Past, Hypothetical, and Possible. For more details, please check the model card. Example: assertion = AssertionDLModel.pretrained(&quot;assertion_sdoh_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) sample_text = &quot;Smith works as a cleaning assistant and does not have access to health insurance or paid sick leave. But she has generally housing problems. She lives in a apartment now. She has long history of EtOH abuse, beginning in her teens. She is aware she needs to attend Rehab Programs.&quot; Results: chunk begin end ner_label assertion cleaning assistant 17 34 Employment Present health insurance 64 79 Insurance_Status Absent apartment 156 164 Housing Present EtOH abuse 196 205 Alcohol Past Rehab Programs 265 278 Access_To_Care Hypothetical Classifying Transportation Insecurity within the Context of Social Determinants of Health (SDOH) Introducing two new transportation insecurity classifier models for SDOH that offer precise label assignments and confidence scores. With a strong ability to thoroughly analyze text, these models categorize content into No_Transportation_Insecurity_Or_Unknown and Transportation_Insecurity, providing valuable insights into transportation-related insecurity. Model Description genericclassifier_sdoh_transportation_insecurity_e5_large This model is trained with E5 large embeddings within a generic classifier framework. genericclassifier_sdoh_transportation_insecurity_sbiobert_cased_mli This model is trained with BioBERT embeddings within a generic classifier framework Example: generic_classifier = GenericClassifierModel.pretrained(&quot;genericclassifier_sdoh_transportation_insecurity_sbiobert_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) sample_text_list = [&quot;Patient B is a 40-year-old female who was diagnosed with breast cancer. She has received a treatment plan that includes surgery, chemotherapy, and radiation therapy. She is alone and can not drive a car or can not use public bus. &quot;, &quot;Lisa, a 28-year-old woman, was diagnosed with generalized anxiety disorder (GAD), a mental disorder characterized by excessive worry and persistent anxiety.&quot;] Results: Text Transportation Insecurity Class Patient B is a 40-year-old female who was diagnosed with breast cancer. She has received a treatm… Transportation_Insecurity Lisa, a 28-year-old woman, was diagnosed with generalized anxiety disorder (GAD), a mental disord… No_Transportation_Insecurity_Or_Unknown Text Classifier Models to Infer Age Groups from Health Records, Even in the Absence of Explicit Age Indications or Mentions. Now we have three new Age Group Text Classifier models that are designed to analyze the age group of individuals mentioned in health documents, whether or not the age is explicitly mentioned in the training data. These models are trained using in-house annotated health-related text, and categorized into three classes: Adult: Refers to individuals who are fully grown or developed, usually 18 years or older. Child: A young human who is not yet an adult. Typically refers to someone below the legal age of adulthood, which is often below 18 years old. Unknown: Represents situations where determining the age group from the given text is not possible. Model Description bert_sequence_classifier_age_group This model is a BioBERT-based Age Group Text Classifier and it is trained for analyzing the age group of a person mentioned in health documents. genericclassifier_age_group_sbiobert_cased_mli This Generic Classifier model is trained for analyzing the age group of a person mentioned in health documents. few_shot_classifier_age_group_sbiobert_cased_mli This Few Shot Classifier model is trained for analyzing the age group of a person mentioned in health documents. Example: few_shot_classifier = FewShotClassifierModel.pretrained(&quot;few_shot_classifier_age_group_sbiobert_cased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;prediction&quot;) sample_text_list = [[&quot;A patient presented with complaints of chest pain and shortness of breath. The medical history revealed the patient had a smoking habit for over 30 years, and was diagnosed with hypertension two years ago. After a detailed physical examination, the doctor found a noticeable wheeze on lung auscultation and prescribed a spirometry test, which showed irreversible airway obstruction. The patient was diagnosed with Chronic obstructive pulmonary disease (COPD) caused by smoking.&quot;], [&quot;Hi, wondering if anyone has had a similar situation. My 1 year old daughter has the following; loose stools/ pale stools, elevated liver enzymes, low iron. 5 months and still no answers from drs. &quot;], [&quot;Hi have chronic gastritis from 4 month(confirmed by endoscopy).I do not have acid reflux.Only dull ache above abdomen and left side of chest.I am on reberprozole and librax.My question is whether chronic gastritis is curable or is it a lifetime condition?I am loosing hope because this dull ache is not going away.Please please reply&quot;]] Results: Text Age Group A patient presented with complaints of chest pain and shortness of breath. The medical history revealed the patient had a smoking habit for over 30… Adult Hi, wondering if anyone has had a similar situation. My 1 year old daughter has the following; loose stools/ pale stools, elevated liver enzymes, l… Child Hi have chronic gastritis from 4 month(confirmed by endoscopy).I do not have acid reflux. Only dull ache above abdomen and left side of chest.I am o… Unknown Mapping ICD-10-CM Codes to Medicare Severity-Diagnosis Related Group (MS-DRG) We have a new icd10cm_ms_drg_mapper chunk mapper model that maps the ICD-10-CM codes with their corresponding Medicare Severity-Diagnosis Related Group (MS-DRG). Example: chunkMapper = DocMapperModel.pretrained(&quot;icd10cm_ms_drg_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;icd_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;ms-drg&quot;]) sample_codes = [&quot;L08.1&quot;, &quot;U07.1&quot;, &quot;C10.0&quot;, &quot;J351&quot;] Results: ICD10CM Code MS-DRG L08.1 Erythrasma U07.1 COVID-19 C10.0 Malignant neoplasm of vallecula J351 Hypertrophy of tonsils For more details, please check the model card. Five New Sentence Entity Resolver (Terminology Mapping) Pretrained Pipelines, Designed to Streamline Solutions with a Single Line of Code We have five new sentence entity resolver pipelines that are meticulously designed to enhance your solutions by efficiently identifying entities and their resolutions within the clinical note. You can easily integrate this advanced capability using just a single line of code. Pipeline Description abbreviation_pipeline Detects abbreviations and acronyms of medical regulatory activities as well as map them with their definitions and categories. icd10cm_multi_mapper_pipeline Maps ICD-10-CM codes to their corresponding billable mappings, hcc codes, cause mappings, claim mappings, SNOMED codes, UMLS codes and ICD-9 codes without using any text data. You’ll just feed white space-delimited ICD-10-CM codes and get the result. rxnorm_multi_mapper_pipeline Maps RxNorm codes to their corresponding drug brand names, rxnorm extension brand names, action mappings, treatment mappings, UMLS codes, NDC product codes and NDC package codes. You’ll just feed white space-delimited RxNorm codes and get the result. rxnorm_resolver_pipeline Maps medication entities with their corresponding RxNorm codes. You’ll just feed your text and it will return the corresponding RxNorm codes. snomed_multi_mapper_pipeline Maps SNOMED codes to their corresponding ICD-10, ICD-O, and UMLS codes. You’ll just feed white space-delimited SNOMED codes and get the result. from sparknlp.pretrained import PretrainedPipeline abbr_pipeline = PretrainedPipeline(&quot;abbreviation_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = abbr_pipeline.fullAnnotate(&quot;&quot;&quot;Gravid with estimated fetal weight of 6-6/12 pounds. LABORATORY DATA: Laboratory tests include a CBC which is normal. VDRL: Nonreactive&quot;&quot;&quot;) Results: chunk entity category_mappings definition_mappings CBC ABBR general complete blood count VDRL ABBR clinical_dept Venereal Disease Research Laboratories HIV ABBR medical_condition Human immunodeficiency virus Various Core Improvements: Bug Fixes, Enhanced Overall Robustness, And Reliability Of Spark NLP For Healthcare Improvement of the deidentification faker list (city, street, hospital, profession) for various language Updated Notebooks And Demonstrations For making Spark NLP For Healthcare Easier To Navigate And Understand New Extracting Public Health Related_Insights From Social Media Texts Using Healthcare NLP Notebook for automated health information extraction and co-occurrence analysis with JohnSnowLabs models Text to SQL Generation Notebook for automatically converting natural language questions into corresponding SQL queries Updated NORMALIZED SECTION HEADER MAPPER Demo with ner_section_header_diagnosis model Updated ENTITY RESOLVER LOINC Demo with sbiobertresolve_loinc_numeric and sbiobertresolve_loinc_augmented models We Have Added And Updated A Substantial Number Of New Clinical Models And Pipelines, Further Solidifying Our Offering In The Healthcare Domain. summarizer_clinical_laymen_onnx clinical_notes_qa_large_onnx clinical_notes_qa_base_onnx ner_clinical -&gt; pt text2sql_mimicsql assertion_sdoh_wip genericclassifier_sdoh_transportation_insecurity_e5_large genericclassifier_sdoh_transportation_insecurity_sbiobert_cased_mli bert_sequence_classifier_age_group genericclassifier_age_group_sbiobert_cased_mli icd10cm_ms_drg_mapper abbreviation_pipeline rxnorm_resolver_pipeline icd10cm_multi_mapper_pipeline rxnorm_multi_mapper_pipeline snomed_multi_mapper_pipeline assertion_vop_clinical assertion_vop_clinical_medium assertion_vop_clinical_large few_shot_classifier_age_group_sbiobert_cased_mli For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_5_0_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_5_0_2"
  },
  "1504": {
    "id": "1504",
    "title": "NLP Lab Release Notes 5.1.0",
    "content": "5.1.0 Release date: 30-06-2023 NLP Lab 5 - Harness the Power of Section-Based Annotation for Advanced NLP Tasks We’re excited to announce that NLP Lab 5 is now available! This major update offers out-of-the-box support for section-based annotation, a feature that makes annotating larger documents with deep learning (DL) models or large language models (LLMs) an absolute breeze. Section-based annotation is a cornerstone feature, that proposes a new strategy to handle manual and automatic text annotation. First of all, it allows the splitting of tasks into distinct sections, at various granular levels such as sentences, paragraphs, or even pages, depending on the requirement of the use case at hand. This approach gives annotators a clear view and fine-grained control over the document structure. Second, it allows users to specify what are the relevant sections for their project’s specific goals. This can be done by a combination of specific keywords that can be found inside the relevant texts, regular expressions (regex) matching particular patterns within the text, or by the use of classifiers specially trained to recognize specific types of sections.  This two-step process ensures that only relevant sections, those most likely to provide valuable insights, are selected for further annotation. The following are three essential benefits related to this process: - streamlined and targeted annotations that ignore irrelevant sections within a task,  - context limitation for text processing via LLMs, and DL models for increased performance and speed at lower costs, - customizable taxonomies for each section for focused (pre)annotations. Relevant sections can be automatically identified by the NLP Lab during the task import step but they can also be manually adjusted/created/removed when required, by the annotators themselves as part of their completions.  Limiting the (pre)annotation context is essential in view of the larger integration with LLM we are preparing (stay tuned for NLP Lab 5.2). By focusing on one relevant section at a time, instead of an entire document that can be hundreds of pages long, NLP Lab ensures that the LLM ingests only the relevant context, suppressing distraction by eliminating noise or irrelevant data. This will improve the response time and the precision of predictions while being considerate of the processing costs.  NER tasks are all about precision! Starting with NLP Lab 5 you will be able to associate relevant labels to specific sections of text. This results in more precise entity recognition and reduced chances of false positives. This granularity of annotation is crucial for those working on projects where each detail matters. For classification tasks, the section-based annotation feature enables classification to be performed at the sentence, paragraph, or page level. This offers unparalleled flexibility to split the task according to the required level of granularity. Whether you are classifying sentences or whole paragraphs, NLP Lab now accommodates your needs in a much more tailored way. We understand that annotators want to focus their efforts on the most pertinent areas of the documents they process. With section-based annotation, they can focus solely on the relevant sections, leading to better productivity and less time spent scrolling through irrelevant content. During model training, only the annotations from the relevant sections will be used. This feature drastically reduces the training time required, saving valuable computational resources and accelerating the project timelines. When it comes to preannotations, the models, prompts, and rules now evaluate solely the relevant sections. This thoughtful approach results in more precise pre-annotations and faster computation of results, thereby boosting your project efficiency. Overall, section-based annotation in NLP Lab streamlines the annotation process, enabling annotators to concentrate on the necessary sections while optimizing training time and enhancing the accuracy of pre-annotations. We’re confident that this new release will significantly improve your NLP project execution. We can’t wait to see what amazing things you’ll do with it! NLP Tasks compatible with Section-Based Annotation NLP Lab offers Section-Based Annotation features for the following tasks: Named Entity Recognition (NER): NER tasks involving text can now be partitioned into sections using bespoke rules, facilitating an efficient examination and annotation of only the pertinent sections.  Text Classification: With the introduction of Section-Based Annotation, tasks can now be divided into relevant sections, and each section can be independently classified, eliminating the limitations of classifying the entire task as a whole. Combined NER and Classification: NLP Lab’s versatility enables it to support project configurations combining NER and assertion labeling, with classification or relation extraction. Users can now identify relevant sections within the project and carry out classification as well as NER and relation labeling within each section. Specific taxonomies can be defined for each such section that offers more control over the annotation targets. Visual NER: Section-Based Annotation is now available for Visual NER projects, specifically designed for image-based tasks. This feature is particularly beneficial when dealing with lengthy PDFs that are divided into sections by page. Users have the ability to specify the specific pages that are relevant to their needs. With Section-Based Annotation, NLP Lab offers a more granular approach to annotation and analysis, allowing users to focus on specific sections and achieve more accurate and efficient results. Task Splitting  The project definition wizard introduces the task-splitting feature as an independent step, following the content type definition. In this second step of the project definition, users can opt for annotating the entire task at hand by choosing the “Entire Document” option or annotating only the relevant sections by choosing the “Relevant Sections” option. Three methods are available for splitting your tasks: Split by Page: In text projects, a page is delineated by a specific character count. Users will find a dropdown menu featuring the same two default options as seen in the annotation screen for identifying a page: 1800 and 3600 characters. For Visual NER projects, a page represents a single page in the PDF document or an image. The page boundaries are automatically established, eliminating the need for further user inputs. Split by Paragraph: Text tasks can be divided into paragraphs by using a dynamic regex such as “ n”. Custom regex expressions are also supported and can be defined to adapt the task splitting to the particularities of your documents.  Split by Sentence: This selection enables users to partition text documents into individual sentences, using single or multiple delimiters. The full-stop sign ‘.’ is the default delimiter used to identify sentence boundaries. Since a sentence may end with various delimiters. users have the flexibility to include multiple delimiters for sentence segmentation. IMPORTANT REMARKS: The Split by Paragraph and Split by Sentence options are not applicable for Visual NER projects. Section Based annotations cannot be enabled for pre-existing projects with annotated tasks or any project with tasks already in progress.  What Makes a Section Relevant? After enabling the “Relevant Sections” feature and selecting a method to split documents into smaller parts (either by page, paragraph, or sentence), users can proceed to define the rules for identifying the relevant sections they want to work on. Only the sections that match the added section rules will be considered relevant.  Each section has a name that can be linked to the taxonomy elements (NER, assertion, or classification labels) that apply to that specific section. As such, all taxonomy elements that do not apply to section A, for instance, will be hidden on the annotation screen when section A is active or selected, making it easier for human users to check preannotations or define new annotations.  Four types of rules can be combined to identify relevant sections: Index-Based Rules The section index refers to the crt. number of a section in the ordered list of sections created for a task. Index values are positive or negative integers, and can be specified in various formats. For example, you can define a sequence of integers such as 4, 5, 9 for the fourth, fifth and ninth sections, a range of values such as 1-10 to include all values from 1 to 10 or a negative value -1 to denote the last section in the task.  Keyword-Based Rules Keywords can be used to mark a section as relevant. Each keyword can be a single word or a phrase consisting of alphanumeric characters. Multiple keywords can be used by separating them with commas (“,”). All sections containing the specified (list of) keywords will be considered relevant.  Regex-Based Rules: Regex (regular expressions) can also be used to identify relevant sections. If a match is found within the document based on the provided regex, the corresponding page, paragraph, or sentence will be considered relevant. Classifier-Based Rules: Identification of relevant sections can also be done using pre-trained classifier models. Users can select one classifier from the available ones (downloaded or trained within NLP Lab) and pick the classes considered relevant for the current project. Those will be associated to a section name. Multiple relevant sections can be created with the same classifier. Please note that only one classifier can be used for section classification as part of one project. Saving this rule will deploy a classifier server, which can be viewed on the Cluster page. Licensed classifiers require a free valid license to run, and the deployment of a classifier is subject to the availability of server capacity. Merge Consecutive Sections for Simplified Workflows: Successive sections with the same name can be merged into one section. This feature is available by checking the corresponding option below the section definition widget. This simplifies the annotation process by grouping together neighboring sections with the same name for which the same taxonomy applies.  ) IMPORTANT REMARKS: For Visual NER projects, the rules for defining relevant sections are limited to index, keywords, and regex. Section Specific Taxonomies The section-based annotation options provide users with the flexibility to customize and configure the labels and choices that are displayed in specific sections. This setup can be conveniently accomplished via the project configuration page, which presents a visual mode for label customization. In the case of Named Entity Recognition (NER) labels, users can simply click on individual labels and choose the specific sections where they want the label to be visible. By doing so, users have the ability to define the sections within the task where each NER label should appear, ensuring that the annotation is precise and applicable to the intended sections. Similarly, for choices, users can navigate to the three-dot menu, typically located next to each choice name. By selecting this menu, users can access the configuration settings to designate the relevant sections where the particular choice should be displayed. This feature allows users to tailor the choices available for annotation in specific sections, making the annotation process more precise and efficient. By providing the ability to configure labels and choices at the section level, users can ensure that their annotation efforts are focused on the most relevant parts of the text. This ensures that the annotation process is efficient, saving valuable time and resources. Ultimately, this level of customization empowers users to create high-quality annotations tailored to their specific tasks and objectives. Pre-annotation Focused on Relevant Sections In Section-Based Annotation projects, users can mix DL models, rules, and prompts for pre-annotating relevant sections according to their specific taxonomies. By splitting tasks into relevant sections, pre-annotation leverages the trained/deployed model to generate predictions focusing exclusively on those smaller chunks of text. This significantly streamlines the pre-annotation workflow, enabling users to leverage the precision and efficiency of predictions derived from DL models, LLM prompts, and rules.  Also when leveraging prompts-based annotation it is important to consider the context limitations. The LLMs can only process a certain number of tokens (words or characters, depending on the model) at a time. For instance, for OpenAI’s GPT-3, the maximum limit is approximately 6500 words, while the context length of GPT-4 is limited to approximately 25,000 words. There is also a version that can handle up to 50 pages of text, but the more context you send to LLM the higher the costs. If the document you are trying to preannotate is larger than the LLM’s limit, you will need to break it down into smaller sections. This is where section-based annotation becomes particularly useful. It allows you to focus on the most relevant parts of the document without exceeding the token limit. It’s also important to note that LLMs do not have a memory of previous requests. Therefore, the context that is sent for each request should contain all the necessary information for generating accurate predictions. Model Training with Section-Level Annotations In projects that support Section-Based Annotation, each section is treated as an individual document during the training process. This means that the annotations contained within a given section, along with the section’s text, are provided to the training pipeline. By considering the specific content and context of the relevant sections, the training process becomes more targeted and accurate, resulting in improved model performance. This advanced training approach allows for a more focused training experience by excluding irrelevant sections and solely focusing on the sections that contain annotations. Training specifically on these relevant sections optimizes the training process, resulting in improved pre-annotation efficiency and accuracy. This targeted approach enhances the precision and overall accuracy of trained models. Manual Annotation of Relevant Sections Start from the Default Relevant Sections When importing a new task, the relevant sections are automatically created based on the rules defined on the section configuration page. This division allows the annotator to focus on annotating the relevant sections individually. By breaking down the task into manageable sections, the annotation process becomes more focused and efficient. When a task is opened in the annotation screen, a new completion is generated by default, based on the automatically detected sections. The first relevant section is active by default and shown as highlighted in the yellow background (see item 7 on the below image) on the UI. Additionally, the name of the active section is displayed in the top bar (5), providing clear context to the user. Manual Creation/Removal of Relevant Section There may be occasions when the predefined rules do not accurately capture the necessary relevant sections. For such scenarios, the user has the option to manually select the required text regions within the document and add a new section using the ‘Create’ button located at the top of the annotation area (see item 2 in the below image). A pop-up window allows users to choose the section to which the selected region belongs. (see item 3 in the image below). This ensures that no relevant information is overlooked or omitted during the annotation process. The custom-created sections are specific to the completions created by each user, and it can be possible that different users will submit starred completions with different relevant sections for the same task. This type of situation should be discussed in Inter Annotator Agreement meetings and consensus should be reached on what defines a relevant section.  By incorporating both automated section generation based on configuration rules and the ability to manually create sections, the annotation system offers a comprehensive approach that balances convenience and customization. Annotators can annotate efficiently on the automatically detected sections, while also having the flexibility to modify or create sections manually when necessary. It is also possible to remove an existing section. For this, users can simply click on the delete button associated with that section (see item 4 on the above images). Navigating Between Relevant sections Users can easily navigate to relevant sections using the ‘Previous’ and ‘Next’ buttons. Clicking these navigation buttons moves the user’s view to the appropriate area where the relevant section is located. If the relevant section is on the next page, the display will automatically transition to that page, ensuring seamless access to the desired section. Cloning Completions with Custom Sections In section-based tasks, cloning a completion entails automatically duplicating the section as well as the associated annotations. In other words, the process of copying completions ensures that the section structure, along with its corresponding annotations, is replicated in the new completion. This feature allows users to work on multiple iterations or variations of the task, each with its distinct relevant section, without losing any work - annotations, and labels - done in the original completion. By supporting the duplication of completions while preserving the section-based context, the annotation system grants users the flexibility to modify and refine their work as needed. It enables users to submit different versions of completions, each with its unique relevant section, facilitating a more nuanced and specific analysis of the underlying data. Creating New Completions If there are multiple completions submitted by different annotators and the user decides to create a new completion from scratch, the relevant sections will be generated based on the rules that were initially set when the task was imported. IMPORTANT REMARKS: Changes made to the section rules do not apply to existing imported tasks. The updated rules are only applied to newly imported tasks. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_5_1_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_5_1_0"
  },
  "1505": {
    "id": "1505",
    "title": "Spark NLP for Healthcare Release Notes 5.1.0",
    "content": "5.1.0 Highlights We are delighted to announce remarkable enhancements and updates in our latest release of Spark NLP for Healthcare. This release comes with the first clinical NER models in 5 new languages as well as 22 new clinical pretrained models and pipelines. 5 new clinical NER models for extracting clinical entities in the French, Italian, Polish, Spanish, and Turkish languages Introducing the pretrained ContextualParserModel to allow saving &amp; loading rule based NER models and releasing the first date-of-birth NER model 3 new text classification models for classifying complaints and positive emotions in clinical texts 6 new augmented NER models by leveraging the capabilities of the LangTest library to significantly boost their robustness Improved the RelationExtractionModel annotator by enabling the selection of single or multiple labels in outputs and providing customizable feature scaling techniques Improved consistency of names during the deidentification process, regardless of variations in casing or altered token sequences Enhancing Text2SQL with custom schemas and releasing the first pretrained zero-shot Text2SQL Model for single tables. Enhancements in Text2SQL: tableLimit and postProcessingSubstitutions parameters, and expanded variable support Revamped the method names within the ocr_nlp_processor module and incorporated functionality to create colorful overlay bands using RGB codes over identified entities Various core improvements; bug fixes, enhanced overall robustness and reliability of Spark NLP for Healthcare The option to remove scope window constraints in the AssertionDLModel is now accessible by setting it to [-1, -1], default is [9, 15] Updated notebooks Updated Contextual Parser Rule Based NER Notebook with new CP model example Updated Spark OCR Utility Module Notebook with the new updates in ocr_nlp_processor module Updated Text To SQL Generation Notebook with new single tables model New demos New Multi-Language Clinical NER Demo New ASSERTION_SDOH Demo New ASSERTION_VOP Demo New TEXT2SQL Demo New CLASSIFICATION LITCOVID Demo New PATIENT COMPLAINT CLASSIFICATION Demo Updated Age Group Classification Demo The addition and update of numerous new clinical models and pipelines continue to reinforce our offering in the healthcare domain These enhancements will elevate your experience with Spark NLP for Healthcare, enabling more efficient, accurate, and streamlined analysis of healthcare-related natural language data. 5 New Clinical NER Models for Extracting Clinical Entities in the French, Italian, Polish, Spanish, and Turkish languages 5 new Clinical NER models provide valuable tools for processing and analyzing multi-language clinical texts. They assist in automating the extraction of important clinical information, facilitating research, medical documentation, and other applications within the multi-language healthcare domain. Model Name Lang Predicted Entities Language ner_clinical PROBLEM TEST TREATMENT es ner_clinical PROBLEM TEST TREATMENT fr ner_clinical PROBLEM TEST TREATMENT it ner_clinical PROBLEM TEST TREATMENT pl ner_clinical PROBLEM TEST TREATMENT tr Example: ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;tr&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;&quot;&quot;Hasta sıcak ve soğuk yiyecekler yerken diş hassasiyetinden şikayetçiydi. Olası çürük veya diş kökü problemlerini değerlendirmek için klinik ve radyografik muayene yapıldı ve diş köküne yakın bir boşluk tespit edildi. Sorunu gidermek için restoratif tedavi uygulandı.&quot;&quot;&quot; Result: chunk begin end ner_label soğuk yiyecekler yerken diş hassasiyeti 18 56 PROBLEM radyografik muayene 144 162 TEST restoratif tedavi 234 250 TREATMENT Please check: Multi-Language Clinical NER Demo Introducing the Pretrained ContextualParserModel to Allow Saving &amp; Loading Rule Based NER Models and Releasing the First Date-of-Birth NER Model Now you can save your ContextualParserModel models without exposing &amp; sharing the rule sets and load back later on. We also release the first pretrained ContextualParserModel that can extract date-of-birth (DOB) entities in clinical texts. Example: dob_contextual_parser = ContextualParserModel.pretrained(&quot;date_of_birth_parser&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;chunk_dob&quot;) text = &quot;&quot;&quot; Record date : 2081-01-04 DB : 11.04.1962 DT : 12-03-1978 DOD : 10.25.23 SOCIAL HISTORY: She was born on Nov 04, 1962 in London and got married on 04/05/1979. When she got pregnant on 15 May 1079, the doctor wanted to verify her DOB was November 4, 1962. Her date of birth was confirmed to be 11-04-1962, the patient is 45 years old on 25 Sep 2007. PROCEDURES: Patient was evaluated on 1988-03-15 for allergies. She was seen by the endocrinology service and she was discharged on 9/23/1988. MEDICATIONS 1. Coumadin 1 mg daily. Last INR was on August 14, 2007, and her INR was 2.3.&quot;&quot;&quot; Result: sentence_id chunk begin end ner_label 1 11.04.1962 32 41 DOB 3 Nov 04, 1962 109 120 DOB 4 November 4, 1962 241 256 DOB 5 11-04-1962 297 306 DOB please check: Model Card and Contextual Parser Rule Based NER Notebook for more information 3 New Text Classification Models for Classifying Complaints and Positive Emotions in Clinical Texts Introducing three novel text classification models tailored for healthcare contexts, specifically designed to differentiate between expressions of Complaint – characterized by negative or critical language reflecting dissatisfaction with healthcare experiences – and No_Complaint – denoting positive or neutral sentiments without any critical elements. These models offer enhanced insights into patient feedback and emotions within the healthcare domain. Model Name Predicted Entities Annotator few_shot_classifier_patient_complaint_sbiobert_cased_mli Complaint No_Complaint FewShotClassifierModel bert_sequence_classifier_patient_complaint Complaint, No_Complaint MedicalBertForSequenceClassification genericclassifier_patient_complaint_sbiobert_cased_mli Complaint No_Complaint GenericClassifierModel Example: sequenceClassifier = MedicalBertForSequenceClassification .pretrained(&quot;bert_sequence_classifier_patient_complaint&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&#39;token&#39;]) .setOutputCol(&quot;prediction&quot;) sample_text = [ [&quot;&quot;&quot;The Medical Center is a large state of the art hospital facility with great doctors, nurses, technicians and receptionists. Service is top notch, knowledgeable and friendly. This hospital site has plenty of parking&quot;&quot;&quot;], [&quot;&quot;&quot;My gf dad wasn’t feeling well so we decided to take him to this place cus it’s his insurance and we waited for a while and mind that my girl dad couldn’t breath good while the staff seem not to care and when they got to us they said they we’re gonna a take some blood samples and they made us wait again and to see the staff workers talking to each other and laughing taking there time and not seeming to care about there patience, while we were in the lobby there was another guy who told us they also made him wait while he can hardly breath and they left him there to wait my girl dad is coughing and not doing better and when the lady came in my girl dad didn’t have his shirt because he was hot and the lady came in said put on his shirt on and then left still waiting to get help rn&quot;&quot;&quot;] ] Result: text result The Medical Center is a large state of the art hospital facility with great doctors, nurses, technicians and receptionists. Service is top notch, … No_Complaint My gf dad wasn’t feeling well so we decided to take him to this place cus it’s his insurance and we waited for a while and mind that my girl dad co… Complaint 6 New Augmented NER Models by Leveraging the Capabilities of the LangTest Library to Significantly Boost Their Robustness Newly introduced augmented NER models namely ner_events_clinical_langtest, ner_oncology_anatomy_general_langtest, ner_oncology_anatomy_granular_langtest, ner_oncology_demographics_langtest, ner_oncology_posology_langtest, and ner_oncology_response_to_treatment_langtest are powered by the innovative LangTest library. This cutting-edge NLP toolkit is at the forefront of language processing advancements, incorporating state-of-the-art techniques and algorithms to enhance the capabilities of our models significantly. These models are strengthened against various perturbations (lowercase, uppercase, titlecase, punctuation removal, etc.), and the previous and new robustness scores are presented below model names original robustness new robustness ner_oncology_anatomy_granular_langtest 0.79 0.89 ner_oncology_response_to_treatment_langtest 0.76 0.90 ner_oncology_demographics_langtest 0.81 0.95 ner_oncology_anatomy_general_langtest 0.79 0.81 ner_oncology_posology_langtest 0.74 0.85 ner_events_clinical_langtest 0.71 0.80 Example: clinical_ner = MedicalNerModel.pretrained(&quot;ner_events_clinical_langtest&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;The patient presented to the emergency room last evening&quot; Result: chunk ner_label presented EVIDENTIAL the emergency room CLINICAL_DEPT last evening DATE Improved the RelationExtractionModel Annotator by Enabling the Selection of Single or Multiple Labels in Outputs and Providing Customizable Feature Scaling Techniques The RelationExtractionModel annotator is now equipped with the setMultiClass() method, which provides the option to specify whether the model should return only the label with the highest confidence score or include all labels in its output. Furthermore, the model offers the setFeatureScaling() method, granting the ability to apply different feature scaling techniques such as zscore, minmax or empty (no scaling). setFeatureScaling Example: reModel = RelationExtractionModel.pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(10) .setRelationPairs([&quot;drug-ade, ade-drug&quot;]) .setFeatureScaling(&quot;zscore&quot;) # or minmax text = &quot;I experienced fatigue, aggression, and sadness after taking Lipitor but no more adverse after passing Zocor.&quot; Result: index chunk1 entity1 chunk2 entity2 relation zscore minmax 0 fatigue ADE Lipitor DRUG 0 0.9964 0.9983 1 Zocor DRUG fatigue ADE 0 0.9884 0.9341 2 aggression ADE Lipitor DRUG 1 0.6123 0.9999 3 Zocor DRUG aggression ADE 0 0.9972 0.9833 4 sadness ADE Lipitor DRUG 1 0.9999 0.9644 5 Zocor DRUG sadness ADE 1 0.9080 0.9644 setFeatureScaling Example: reModel = RelationExtractionModel.pretrained(&quot;re_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(10) .setRelationPairs([&quot;problem-test&quot;, &quot;problem-treatment&quot;]) .setMultiClass(True) # or Default value is False text = &quot;&quot;&quot; A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation, associated with obesity with a body mass index ( BMI ) of 33.5 kg/m2 . &quot;&quot;&quot; setMultiClass(False) Result: chunk1 entity1 chunk2 entity2 relation confidence gestational diabetes mellitus PROBLEM BMI TEST TeRP 1.0 setMultiClass(True) Result: | chunk1 | entity1 | chunk2 | entity2 | relation | confidence | |——————————-|———|——–|———|———-|————| | gestational diabetes mellitus | PROBLEM | BMI | TEST | TeRP | TeRP_confidence: 1.0 TrCP_confidence: 0.0, TeCP_confidence: 2.36E-35 TrAP_confidence: 8.85E-32 TrWP_confidence: 1.16E-34 TrNAP_confidence: 0.0 TrIP_confidence: 0.0 PIP_confidence: 1.87E-28 O_confidence: 9.56E-13 | Improved Consistency of Names During the Deidentification Process, Regardless of Variations in Casing or Altered Token Sequences The Deidentification annotator maintains consistent name handling in its obfuscation mode, even when the same name appears in different formats, such as varying casing or altered token orders. This ensures that names remain consistently protected regardless of their presentation within the text. Example: deidentification = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) sample_text = &quot;&quot;&quot;Patient Name: SULLAVAN, John K, MRN: 123456 SULLAVAN, JOHN K, Male, 05/09/1985 John K Sullavan is 25 years old patient has heavy back pain started from last week. &quot;&quot;&quot; Results: sentence masked deidentified Patient Name: SULLAVAN, John K, MRN: 123456 Patient Name: &lt;PATIENT&gt; MRN: &lt;MEDICALRECORD&gt; Patient Name: Viviann Spare MRN: 376947 SULLAVAN, JOHN K, Male, 05/09/1985 &lt;PATIENT&gt;, Male, &lt;DATE&gt; Viviann Spare, Male, &lt;DATE&gt; John K Sullavan is 25 years old patient has heavy back pain started from last week. &lt;PATIENT&gt; is &lt;AGE&gt; years old patient has heavy back pain started from last week. Viviann Spare is 20 years old patient has heavy back pain started from last week. Enhancing Text2SQL with Custom Schemas and Releasing the First Pretrained Zero-Shot Text2SQL Model for Single Tables. Utilizing text2sql_with_schema_single_table to generate SQL queries from natural language queries and custom database schemas featuring single tables. Powered by a large-scale finetuned language model developed by John Snow Labs on single-table schema data Example: query_schema = {&quot;patient&quot;: [&quot;ID&quot;,&quot;Name&quot;,&quot;Age&quot;,&quot;Gender&quot;,&quot;BloodType&quot;,&quot;Weight&quot;,&quot;Height&quot;,&quot;Address&quot;,&quot;Email&quot;,&quot;Phone&quot;] } text2sql_with_schema_single_table = Text2SQL.pretrained(&quot;text2sql_with_schema_single_table&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setMaxNewTokens(200) .setSchema(query_schema) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sql_query&quot;) sample_text = &quot;&quot;&quot; Calculate the average age of patients with blood type &#39;A-&#39; &quot;&quot;&quot; Results: SELECT AVG(Age) FROM patient WHERE BloodType = &quot;A-&quot; please check: Model Card and Text To SQL Generation Notebook for more information Enhancements in Text2SQL: tableLimit and postProcessingSubstitutions Parameters, and Expanded Variable Support You can use the following code to replace particular strings with other strings in the generated sequence: text2sql_with_schema_single_table.setPostProcessingSubstitutions({ &#39;greater than&#39;: &#39;&gt;&#39;, &#39;not equal to&#39;: &#39;&lt;&gt;&#39;, &#39;less than or equal to&#39;: &#39;&lt;=&#39;, &#39;superior&#39;: &#39;&gt;&#39;, &#39;inferior&#39;: &#39;&lt;&#39;, &#39;greater than or equal to&#39;: &#39;&gt;=&#39;, &#39;inferior or equal&#39;: &#39;&lt;=&#39;, &#39;superior or equal&#39;: &#39;&gt;=&#39;, &#39;equal to&#39;: &#39;=&#39;, &#39;less than&#39;: &#39;&lt;&#39; }) Variables which can be used in the prompt template: &quot;{tables_list}&quot;: comma separated list of tables &quot;{tables}&quot;: comma separated list of tables with column names &quot;{table1_name}&quot;, &quot;{table2_name}&quot;, ... names of particular tables. &quot;{table1_columns}&quot;, &quot;{table2_columns}&quot;, ... comma separated lists of columns in particular tables. see Text To SQL Generation Notebook for more information Revamped the Method Names Within the ocr_nlp_processor Module and Incorporated Functionality to Create Colorful Overlay Bands Using RGB Codes Over Identified Entities We’ve modified the method names in the ocr_nlp_processor module and introduced the capability to specify RGB codes for overlaying colorful bands on entities. This allows improved readability for color-blind individuals when viewing deidentified PDF files if you set it box_color = (115, 203, 235) (“115” Red, “203” Green, “235” Blue). ocr_nlp_processor Methods: Previous Now black_band colored_box colored_box bounding_box highlight highlight Example: from sparknlp_jsl.utils.ocr_nlp_processor import ocr_entity_processor ocr_entity_processor(spark=spark, file_path = path, ner_pipeline = nlp_model, chunk_col = &quot;merged_chunk&quot;, style = box, save_dir = &quot;deidentified_pdfs&quot;, box_color= (115, 235, 255), label= True, label_color = &quot;red&quot;, resolution=100, display_result = True) Various Core Improvements; Bug Fixes, Enhanced Overall Robustness and Reliability of Spark NLP for Healthcare The option to remove scope window constraints in the AssertionDLModel is now accessible by setting it to [-1, -1], default is [9, 15] Updated Notebooks And Demonstrations For making Spark NLP For Healthcare Easier To Navigate And Understand Updated Contextual Parser Rule Based NER Notebook with new CP model example Updated Spark OCR Utility Module Notebook with the new updates in ocr_nlp_processor module Updated Text To SQL Generation Notebook with new single tables model New Multi-Language Clinical NER Demo New Social Determinants of Health Assertion Demo New Voice of Patients Assertion Demo New TEXT2SQL Demo New CLASSIFICATION LITCOVID Demo New PATIENT COMPLAINT CLASSIFICATION Demo Updated Age Group Classification Demo We Have Added And Updated A Substantial Number Of New Clinical Models And Pipelines, Further Solidifying Our Offering In The Healthcare Domain. date_of_birth_parser ner_clinical -&gt; es ner_clinical -&gt; fr ner_clinical -&gt; it ner_clinical -&gt; pl ner_clinical -&gt; tr bert_sequence_classifier_patient_complaint genericclassifier_patient_complaint_sbiobert_cased_mli few_shot_classifier_patient_complaint_sbiobert_cased_mli ner_events_clinical_langtest ner_oncology_anatomy_general_langtest ner_oncology_anatomy_granular_langtest ner_oncology_demographics_langtest ner_oncology_posology_langtest ner_oncology_response_to_treatment_langtest ner_clinical_pipeline -&gt; es ner_clinical_pipeline -&gt; fr ner_clinical_pipeline -&gt; it ner_clinical_pipeline -&gt; nl ner_clinical_pipeline -&gt; pl ner_clinical_pipeline -&gt; pt ner_clinical_pipeline -&gt; tr For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 5.1.0 5.0.2 5.0.1 5.0.0 4.4.4 4.4.3 4.4.2 4.4.1 4.4.0 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_5_1_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_5_1_0"
  },
  "1506": {
    "id": "1506",
    "title": "NLP Lab Release Notes 5.1.1",
    "content": "5.1.1 Release date: 10-07-2023 We are pleased to announce the release of v5.1.1 which includes the following Section Based Annotation bug fixes: Relevant sections are now listed in the “export JSON” task for Section Based Annotation enabled projects. Section based annotation enabled visual NER projects now support import of annotated tasks. The imported tasks are split on the basis of the rules and relevant sections are captured. The side menu options will now show a hover state only when they are clickable. Error messages will now be shown when invalid section rules for “Section Index” are entered. Section Index now supports Index with single value (1, 2, 3, …) and series index (1-5) in the same rule. Manually created relevant sections of a deleted completion were still visible for section based tasks. This issue has been fixed. In the previous version, when a model was trained in a Visual NER project, the trained model did not have any prediction labels. This issue has been fixed. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_5_1_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_5_1_1"
  },
  "1507": {
    "id": "1507",
    "title": "NLP Lab Release Notes 5.2.2",
    "content": "5.2.2 Release date: 03-08-2023 NLP Lab 5.2: Introducing Synthetic Data Generation with ChatGPT, improved HIPAA compliance with s3 integration and disabled local exports, enhanced Section Based Annotation, and much more! We are thrilled to announce the release of NLP Lab 5.2, packed with exciting new features to elevate your annotation experience and streamline your NLP projects. With synthetic task generation powered by ChatGPT, effortlessly create diverse text documents, enriching your dataset for more robust training. Collaborate and access your annotated data with ease, as we integrate Amazon S3 for tasks and project export, ensuring smooth teamwork and safe data sharing. To ensure data security and privacy, we now offer the option to disable tasks and projects to export to local workstations, guaranteeing that your sensitive information remains protected within the confines of the platform. Furthermore, our Section-based annotation feature has received significant enhancements, including support for task splitting with external services, targeted pre-annotation for relevant sections, and pre-annotation for all sections defined for a given task. These improvements streamline your annotation workflow, saving you valuable time and effort. Experience the power of NLP Lab v5.2 today, and elevate your annotation and data management to new heights! Here are the highlights of this release: Synthetic task generation with ChatGPT With NLP Lab 5.2, you can harness the potential of synthetic documents generated by LLMs such as ChatGPT. This integration allows you to easily create diverse and customizable synthetic text for your annotation tasks, enabling you to balance any entity skewness in your data and to train and evaluate your models more efficiently. NLP Labs offers seamless integration with ChatGPT, enabling on-the-fly text generation. Additionally, NLP Labs provides the flexibility to manage multiple service providers key pairs for robust and flexible integration. These service providers can be assigned to specific projects, simplifying resource management. During the integration process, Each Service Provider Key can be validated via the UI (User Interface), ensuring seamless integration. Once the service provider integration is completed, it can be utilized in projects that can benefit from the robust capabilities of this new integration. Text generation becomes straightforward and effortless. Provide a prompt adapted to your data needs (you can test it via the ChatGPT app and copy/paste it to NLP Lab when ready) to initiate the generation process and obtain the required tasks. Users can further control the results by setting the “Temperature” and the “Number of text to generate.” The “Temperature” parameter governs the “creativity” or randomness of the LLM-generated text. Higher temperature values (e.g., 0.7) yield more diverse and creative outputs, whereas lower values (e.g., 0.2) produce more deterministic and focused outputs. The NLP Lab integration delivers the generated text in a dedicated UI that allows users to review, edit, and tag it in place. After an initial verification and editing, the generated texts can be imported into the project as Tasks, serving as annotation tasks for model training. Additionally, the generated texts can be downloaded locally in CSV format, facilitating their reuse in other projects. NLP Labs will soon support integration with additional service providers, further empowering our users with more powerful capabilities for even more efficient and robust model generation. Integration with Amazon S3 for tasks and projects export NLP Lab 5.2 offers seamless integration with Amazon Simple Storage Service. Users can now effortlessly export annotated tasks and projects directly to a given S3 bucket. This enhancement simplifies data management and ensures a smooth transition from annotation to model training and deployment. In previous versions, exported tasks were sent to the local workstation, but now it is possible to store annotated tasks and project backups securely in an S3 bucket. When triggering export, a new popup window will prompt the user to choose the target destination. By default, the “Local Export” tab is selected. This means that when the user clicks on the export button, target files will be downloaded to the local workstation. For those who prefer the convenience and reliability of cloud storage, it is now possible to select the “S3 Export” tab - enter Amazon S3 credentials, and export tasks and projects directly to the specified S3 bucket path. S3 credentials can be stored by the NLP Lab for future use. Improved HIPAA compliance with disabled exports to local storage Another new feature NLP Lab 5.2 offers is the option to restrict the export for more control over tasks and projects. Exporting tasks and projects to the local workstation can be disabled by admin users when dealing with sensitive data. This encourages users to adopt the more versatile and secure option of exporting data to Amazon S3. Disable Local Export: System administrators can now manage export settings from the system settings page. By enabling the “Disable Local Export” option, the export to a local workstation for all projects is turned off. Selective Export Exceptions: Administrators have the flexibility to specify projects that can still use local export if needed. To do this, click on the “Add Project” button from the Exceptions widget and search for the projects to add to the exceptions list. S3 Bucket Export: With the “Disable Local Export” option activated, users can only export tasks and projects to Amazon S3 bucket paths. This ensures the protection of sensitive data that will be stored securely in the cloud. By introducing these export enhancements, NLP Lab 5.2.0 empowers organizations to streamline their data management processes while maintaining flexibility and control over export options. Users can continue to export specific projects to their local workstations if required, while others can benefit from the reliability and accessibility of exporting to Amazon S3 buckets. Section-based annotation improvements ###Support for task splitting with external services We are excited to introduce a new feature in NLP Lab that allows users to import sections created outside of the platform. Users can now import tasks already split into sections using external tools like Open AI’s ChatGPT. For this, we added support for “Additional sections” – sections that do not have a definition to allow their automatic identification by NLP Lab. Those sections can only be manually created by annotators or imported via the JSON import format. On the import screen users must check the “Preserve Imported Sections” options, if the imported JSON file includes a section definition. Targeted pre-annotation for relevant sections While in previous versions the Annotation screen was set to filter out the list of available labels/choices based on their association with the active sections, this version takes things to the next level. It is now possible to also filter out pre-annotations based on section-specific configuration. Users can configure labels to be displayed exclusively in specific sections during the manual annotation and the automatic pre-annotation process. For instance, let’s consider a NER project with a taxonomy composed of two labels: Label1, which is now set to be shown only in Section1, and Label2, configured to be shown solely in Section2. When running pre-annotation, NLP Lab will automatically adhere to these associations. Consequently, during the pre-annotation process, in Section 1, users will only see annotations for Label1, and similarly, in Section 2, only instances of Label2 will be shown. Pre-annotations applied to all defined sections tasks NLP Lab 5.2, adds a new feature - “Preannotations for Union of Sections”. This enhancement ensures that pre-annotations cover all relevant sections – imported from outside sources, manually added by annotators, or automatically detected by the tool. With this feature, collaboration is enhanced, and all points of view are taken into account during pre-annotation, resulting in a more precise and efficient annotation process. Imagine there’s a task Task-1, and two annotators, Annotator-1 and Annotator-2, are working on it. Annotator-1 decides to customize the sections and manually deletes all the relevant sections generated through section rules. Instead, he adds a new relevant section manually. On the other hand, Annotator-2 prefers to keep the sections automatically detected and also manually creates a new relevant section, different from what Annotator-1 added. Now, when the project manager runs pre-annotation on Task-1, the pre-annotation process will consider the union of sections added by both annotators, along with the relevant sections generated from the section rules or imported from external sources. To further optimize the annotation experience, NLP Lab provides a checkbox “Filter pre-annotations according to my latest completion” within the Predictions card on the right-hand side of the labeling screen. Enabling this option ensures that the pre-annotation process only includes sections present in the latest completion of the current user. Improvements Re-split tasks on Update of Section Definitions Improvements have been made to the splitting operation in Section Based Annotations, where it was previously not possible to re-split an already imported task. Now, users can re-split older tasks with new / updated rules such that any new completions will reflect the new rules (if the user so chooses) Disable auto-draft on the Annotation page Version 5.2 brings a new addition to the labeling page settings—an option that allows users to disable auto-draft functionality. When this option is enabled, drafts will no longer be automatically saved in the client cache. Consequently, annotations will be lost if the page is changed or reloaded without clicking save or update. To preserve their progress, users must manually save or update the task before making any page changes or reloading. Note: By opting to disable auto-draft, all previously saved auto-drafts for every completion across projects will be permanently deleted. Error message when project description exceeds the character limit When adding/updating the description for a project, an error message is shown if the description exceeds 300 characters, instead of failing silently New Banner for Status of Section Splitting Classifier To better indicate the state of deployment of classifier servers, a banner has been added to the Import page for tasks. Users can now re-deploy the server or cancel its deployment if need be. The banner can be of the following colors: Blue: when the classifier is being deployed Orange: when the classifier was deployed and deleted Green: when the classifier is deployed successfully Red: When the classifier deployment is failed Reorder, Resize, and addition of tooltips for Section Based Annotation configurations The input fields for the Section-based Configurations have been reorganized and resized to enhance the user experience during the creation of rules. Additionally, tooltips have been implemented for lengthy Section names, allowing users to view them in their entirety without the need to manually scroll through each letter within the input box. These improvements aim to streamline the configuration process. Manual Section Creation During the manual section creation process, once the selection has been made, it will persist within the section creation modal until the section is successfully created or if the process is canceled. This ensures that the selected data or preferences are retained throughout the procedure, providing a seamless and uninterrupted user experience. Bug Fixes User with an “Admin” Role did not have permission to make changes to the license and infrastructure page Users with an admin role were unable to modify the license and infrastructure page. This issue has been resolved, and now users belonging to the “Admin” group have full permissions for backup, models hub, infrastructure, analytics, cluster, playground, and license. User should be able to end the path URL with “/” while using S3 folder import Users can now import tasks from the S3 bucket using paths that both end with “/” and those that do not end with “/”. Project search not working on the second page of the Projects list Page The project search feature on the second page of the Projects list page was not functioning correctly. This problem has been fixed, and now users can search for projects from all pages. Show downloading animation on the “Models Hub” page A downloading animation has been added to the “Models Hub” page, allowing users to track the progress and completion status when downloading any model. Relations are only generated for the first relevant sections in the SBA-enabled projects, where sections are “split by sentence” This issue has been resolved, and relations are now created for entities/labels in all active relevant sections during pre-annotation. Clicking on the “Next” or “Previous” button from a page, where no relevant sections are present, did not work This issue has been fixed, and now the “Next” and “Previous” Buttons will provide more flexibility while navigating between sections. “Prompts” using “NER healthcare prompts could not be added to the project configuration The issue preventing the addition of RE prompts using NER healthcare prompts to the project configuration has been fixed. Unable to access Customize Labels page when an error occurs in the project configuration Users encountered difficulty accessing the Customize Labels page when an error occurred in the project configuration while adding models/rules/prompts. Both the Re-use Resources tab and Customize Labels Tabs became inaccessible, but this issue has been resolved. Remove warning message regarding pre-annotation of tasks exceeding 45k tokens The warning message regarding the pre-annotation of tasks exceeding 45k tokens, specifically with floating licenses, has been removed. Users can now pre-annotate tasks containing 45k+ tokens regardless of the license used. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_5_2_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_5_2_2"
  },
  "1508": {
    "id": "1508",
    "title": "NLP Lab Release Notes 5.2.3",
    "content": "5.2.3 Release date: 10-08-2023 We are pleased to announce the release of v5.2.3 which includes the following bug fixes: Text Generation Error Removal: Resolved an issue where there was no option to remove text generations with errors from the Result section. CSV Download Retry: Fixed the problem with CSV download for generated tasks, which was failing on the first attempt after correcting an invalid secret key. Exported Failed Tasks: Addressed the problem where failed generated tasks were being exported as blank tasks in the CSV file. These blank tasks could also be imported, which has been rectified. Unauthorized Page Navigation: Users were encountering an “Unauthorized” page when attempting to navigate to the configuration page. This issue has been resolved, and users can now access the configuration page without any problem. Scheduled Synthetic Dag: The generation of synthetic Dags was erroneously scheduled even if the feature was disabled. This behavior has been fixed, and synthetic Dags will now respect the disabled setting. Ad-hoc Task Generation: Corrected the issue where ad-hoc synthetic tasks were not being generated for projects with long names. UI Crash on History Button Click: Resolved a production UI crash that occurred when users clicked on the History button on the train page when the trained failed due to max server count. Firefox Compatibility: Fixed the problem where importing generated tasks was not functioning correctly in the Firefox browser. Visual NER Project Export: Fixed a 500 Error that was preventing the export of tagged Visual NER tasks. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_5_2_3",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_5_2_3"
  },
  "1509": {
    "id": "1509",
    "title": "NLP Lab Release Notes 5.3.2",
    "content": "5.3.2 Release date: 30-08-2023 NLP Lab 5.3 - A Leap Forward in Pre-Annotation through ChatGPT-Powered Entity Recognition We’re excited to present NLP Lab 5.3, an exciting update that marks our foray into integrating Large Language Models (LLMs) into our platform. Leading the charge is the integration with ChatGPT family of models, the first in a series of LLM integrations we have planned for the future. This not only sets the stage for a new era of enhanced pre-annotation capabilities but also underscores our commitment to staying at the forefront of NLP innovation. By weaving ChatGPT’s prowess into our ecosystem, we’re offering users an expanded range of prompt possibilities and a refined entity extraction process. But that’s not all! Beyond the ChatGPT integration, we’ve made a series of enhancements across the board. From a revamped taxonomy customization experience for section-based projects to thoughtful improvements in OCR text formatting, every change in this release is designed to improve your annotation experience. Whether you’re a seasoned NLP Lab user or just getting started, we believe this update will offer you a blend of familiarity and fresh innovation, ensuring a smoother, more productive annotation journey. Dive into the details below to discover all that NLP Lab 5.3 has in store for you. Entity Extraction and Pre-Annotation via GPT Prompting The highlight of this release is the integration with an external service provider, Open AI, to expand and deepen the range of prompts available for pre-annotation (in addition to the Zero Shot entity and relation prompts already supported). This feature:. Broadens Prompt Possibilities: By integrating with Open AI LLM models, users can tap into a more diverse set of prompts, leveraging external expertise to craft pre-annotations, as an alternative pre-annotation solution or when pre-trained models are not available. Efficient Entity Extraction: As current LLMs, GPT family included, are not very good at entity recognition tasks, NLP Lab included a post-processing step on the result provided by LLM. This improves entity identification and helps precisely locate the entities in the given text. These entities, carefully curated and aligned with NLP Lab pre-annotation requirements pave the way for a more efficient and streamlined annotation experience. The following sections explain in detail how to define and use GPT prompts. Setting Up the Integration with Open AI service Integrating “ChatGPT” into the NLP Lab has been designed to be a straightforward process, ensuring users can harness the power of external expertise seamlessly. It consists of three easy steps: Integrations Page: Navigate to the Integrations Page located within the System Settings. This is the hub where all external service providers, including Open AI’s GPT Models, can be defined and managed. Define the Service Provider: To initiate the integration, users are required to provide specific details: Service Provider Name: This is the identifier for the external service, which in this case would be “ChatGPT” or any other name you prefer to use. Secret Key: Every external service comes with a unique Secret Key that ensures secure communication between the platforms. Enter the Secret Key associated with your Open AI subscription here. To ensure the integration process is error-free, users can validate the provided Secret Key directly within the form. This validation step ensures that the connection is secure and that the key is correct. Project Association: Once a successful connection with “ChatGPT” (or any external LLM service provider) is established, it doesn’t end there. The integrated service will now be available for association with selected projects. This means users can decide which projects will benefit from the “ChatGPT” integration and enable it accordingly. The Open AI integration allows users to tap into a vast reservoir of external expertise, enhancing the depth and breadth of their projects. We’ve ensured that the integration process is as intuitive as possible, allowing users to focus on what truly matters: crafting refined and effective pre-annotations. ChatGPT Prompt Definition and Testing Users can generate LLM prompts on the dedicated Prompt page from the Hub of Resources. For ChatGPT Prompts, NLP Lab offers a dedicated definition interface. Here’s what to expect when creating a new LLM prompt: Name the Prompt: Within this new tab, users will first be asked to provide a name for their prompt. This name will be used for pre-annotating identified entities. At this point, we recommend creating one prompt per target entity. Select the Service Provider: Next, users can choose the specific service provider they’ve previously set up via the Integrations Page. Test in Real-time: A standout feature is the ability to test ChatGPT prompts at creation time. As you craft your prompt, you can immediately see how it performs on some test data. This not only allows for immediate feedback but also ensures that the final prompt aligns perfectly with the user’s objectives. This streamlined approach ensures that integrating and testing external prompts is as intuitive and efficient as possible. Consistent Workflow with LLM Prompts Even with the introduction of new features in NLP Lab’s 5.3.0 release, users can take comfort in the consistent experience offered when working with prompts. The addition of external service provider prompts brings a fresh layer to the annotation process, yet the core workflow you’re familiar with stays the same. Familiarity Amidst Innovation: Despite the new integrations, the process of using available prompts remains as straightforward as ever. Whether you’re working with traditional prompts or the newly introduced ones, the experience is smooth and consistent. Seamless Transition: Our commitment to user-centric design means that even as we innovate, we prioritize the ease of use you’ve come to expect. Transitioning to or incorporating external prompts is made effortless, with the interface and steps for prompt creation, selection, and integration remaining intuitive and unchanged. With NLP Lab 5.3.0, you get the best of both worlds: exciting new features and the comfort of a familiar workflow. Note: Pre-annotation of tasks using LLM Prompts does not require the deployment of the pre-annotation server. The pop-up to deploy the pre-annotation server is only shown if the project configuration consists of both LLM prompts and spark NLP models. Improvements Enhanced Taxonomy to Section Mapping NLP Labs 5.3.0 brings significant upgrades to the taxonomy customization experience when dealing with Section-based projects. Revamped Viewing Experience for Taxonomy Elements: We’ve reimagined the way users view “Labels to Sections” associations: At-a-Glance Overview: Gone are the days of manually selecting each label to view its associations. Now, users can instantly see the complete mapping of Labels to Sections, providing a holistic view of the project’s current configuration. Efficient Updates: This consolidated view enables users to quickly grasp their current setup and make any necessary adjustments with ease, making the entire process more user-centric. Bulk Association of “Labels/Choices to Section: A standout enhancement is the ability to associate “Labels/Choices” to sections in bulk. Unlike the previous version, where users could only associate one label at a time, this update allows for simultaneous selection and association of multiple labels to various sections. This enhancement not only streamlines the project configuration and annotation process but also offers a more intuitive user experience, saving valuable time and effort. To facilitate these new features, we have made minor adjustments to the project configuration page in NLP Labs. Under the “Customize Labels” tab, you can now find a new button named “Associate Sections”. Clicking on this button allows users to quickly access the tabular form of the mapping, making it easier to manage Labels/Choices linkage with specific sections. For both “Labels” and “Choices”, we have provided the dedicated “Associate Sections” button on their respective configuration tabs. These new improvements are supported in all section-based annotation-enabled projects, including Visual NER projects. Section-Based Annotation: automatically disregard empty sections In earlier iterations of the section-based annotation project feature, users noticed that some empty sections were marked as relevant when automatically splitting content into paragraphs. Recognizing this issue, version 5.3.0 brings a thoughtful enhancement: sections without any textual content are now automatically disregarded. This ensures a more streamlined annotation process, omitting empty sections like the examples provided below. Updated Pre-annotation Status indicator on task page In the past, the pre-annotate status exclusively indicated whether a prediction was marked as “generated,” “not generated,” or if the pre-annotation process had encountered a failure. With the integration of pre-annotations derived from ChatGPT, the updated approach to preannotation status will encompass statuses for both SparkNLP predictions and ChatGPT predictions. Specifically, for projects involving both SparkNLP models and prompts generated through ChatGPT as an external provider, a revamped pre-annotation circle has been reimagined as a ring divided into two halves. The first half of the ring will showcase the pre-annotation status derived from SparkNLP, while the second half will depict the status of predictions stemming from ChatGPT. Enhanced Formatting for OCR Text For text projects using PDF/Image processing via Visual NLP, we’re excited to introduce an enhanced format feature. Once this feature is activated, the imported text is reformatted to offer better clarity and spacing within the annotation interface. Our goal with this enhancement is to foster a clearer, more spacious workspace, ensuring precision and ease during text annotation. Tags Definition Button was moved on the Tasks Page In version 5.3.0, the “Add More” option for task tags was moved. Based on user feedback, we’ve moved the “Add More” button to a more accessible location at the top of the Tags dropdown list. Along with its new position, the button now sports a “+” icon and a refreshed design, while retaining its original functionality. Importantly, the button’s functionality remains consistent with its previous purpose. Bug Fixes For HTML sources projects replace the dialogue in PREVIEWS with the JSL link The preview format for HTML Dialogues &amp; Conversations projects has been enhanced to feature a JSL link in place of the traditional ‘Dialogues’. Tags are not consistently assigned to Tasks Previously, tasks generated from external providers lacked assigned tags, posing challenges for users in distinguishing imported tasks’ sources. To address this, tags are now consistently assigned when clicking on the edges of tag options or the color indicators instead of only being assigned when clicking directly on the tag name. Model evaluation starts before the required resources are available when the maximum server count is reached In the previous version, model evaluations would commence even if the necessary resources were unavailable or if the maximum server count had been reached. To address this, a new approach has been implemented. When a model evaluation is in progress, a dedicated server is generated on the cluster page. This server is designed to be automatically removed once the evaluation concludes. Furthermore, should the maximum server count be reached and a user initiates an evaluation, an error message indicating “Maximum Model Server Limit Reached” will be displayed. Additionally, users have the option to delete an evaluation server from the cluster page. This action results in the evaluation being aborted on the Train page, accompanied by a notification banner indicating the aborted evaluation. For all Search Fields, White Space before/after the “search keyword” causes the search action to return no results Previously, in all Search Fields, having white space before or after the “search keyword” resulted in the search action yielding no results. Consequently, a change has been implemented to ensure that search results are displayed accurately regardless of any leading/trailing whitespace around the search keyword. This enhancement is universally applicable to all search fields within the application. The duplication error for Section Field does not resolve if the user changes/deletes the value of the other duplicate field Previously, if a Section-based Rule with a duplicate name was added, the error would still show as if the first originally named rule was edited to a different name. With Version 5.3.0, the duplication error will now be resolved if any of the rules that fall under the duplication case are edited to be unique. Incorrect active section name is shown in the top bar for pages without relevant section In the case of a multi-page task that does not have relevant sections, the previously active section will no longer appear at the page’s top. Additionally, if a page contains no pertinent sections, the Active tab on the task’s upper part will be displayed in a subdued manner. Tasks imported in Visual NER Project are not visible until the tasks page is refreshed The issue of the OCR task imported in Visual NER projects not appearing on the Tasks page and the Import button staying disabled until manually refreshed has been resolved in this version. Clicking on undo button in the playground resets every detail of the rule deployed Previously, using the Undo button in the playground didn’t restore rules to their original state after modifications. The Undo action cleared all aspects (suffix, rule type, content length) from deployed playground rules. This problem has now been addressed. Section Based Annotation: Merger of consecutive sections of the same name Previously, when the option “Merge Consecutive sections of the same type” was chosen, any two sections created by the rule that appeared consecutively were combined into a single section. This approach posed a challenge as it could result in an elongated chain of sections if all sections were consecutive. With the recent improvement, only the relevant sections with matching section names are merged. For instance, if there are sections named S1, S1, S3, S1, S2, S2 created consecutively, only the first occurrence of S1 and the final instance of S2 will be merged into a single section, while S3 will remain unaffected. Section Based Annotation: Model is redeployed if the same classifier is modified for the same project The sections classifier no longer undergoes redeployment each time classifier options are modified for the same model. Additionally, the section classifier remains unaffected when an additional classifier rule using the same classifier is introduced. Consequently, in scenarios involving task importation, newly added classifier rules are integrated into the new tasks. However, the section classifier is automatically deployed in situations where a new classifier server is added and the previous one is subsequently removed. “Filter pre-annotations according to my latest completion” shows predictions for deleted sections in SBA-enabled project There was an inconsistency when applying “Filter pre-annotations according to my latest completion” for SBA enabled task. The problem of the filter not functioning correctly, resulting in predictions for deleted sections, has been resolved in version 5.3.0. RE prompts using NER Prompts cannot be deployed in the playground Previously, errors were encountered in the playground when deploying the Relation prompt using the NER prompt in the playground. With this update, these issues have been resolved. Generate Synthetic Text: Unable to import generated text if the SBA project has Classification Rules There was a singular case for Section-based Projects, where adding classification section-based rules to create sections prevented the import of the generated synthetic text. In version 5.3.0, this has been fixed and now users can import the synthetic tasks after or even while the classification model for the section rules is being deployed. Validation missing when deleting section rule which is already associated with label/choice in the Configuration &gt; Customize Labels page Previously, when a user tried to delete the section rule that was associated with label/choice, there was no warning suggesting user that the section is linked to labels/choices in the configuration. The issue has now been resolved and users are given a warning dialog box about the link between the section and the labels/choices and he/she can either proceed and delete the section or cancel it and make necessary changes in configuration. Filter XML code does not filter labels for the NER project Before, the Filter XML function failed to filter the label/assertion list effectively. This issue has now been resolved. When a project’s taxonomy contains a substantial number of NER/Assertion labels, the display of the taxonomy consumes significant screen space, impeding annotators’ navigation through the labels. To address this, Annotation Lab has introduced a search feature for labels within NER projects, offering an autocomplete search option. For incorporating the search bar targeting NER Labels or Choices, utilize the Filter tag as exemplified in the subsequent XML configuration. This filtering mechanism is also applicable to Visual NER filters. Versions Version Version Version 5.3.2 5.2.3 5.2.2 5.1.1 5.1.0 4.10.1 4.10.0 4.9.2 4.8.4 4.8.3 4.8.2 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_5_3_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_5_3_2"
  },
  "1510": {
    "id": "1510",
    "title": "Resolve Entities to Terminology Codes - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/resolve_entities_codes",
    "relUrl": "/resolve_entities_codes"
  },
  "1511": {
    "id": "1511",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/pretrained/resource_downloader.html",
    "relUrl": "/api/python/modules/sparknlp/pretrained/resource_downloader.html"
  },
  "1512": {
    "id": "1512",
    "title": "Risk and Factors - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/risk_factors",
    "relUrl": "/risk_factors"
  },
  "1513": {
    "id": "1513",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/roberta_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/roberta_embeddings.html"
  },
  "1514": {
    "id": "1514",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_question_answering.html"
  },
  "1515": {
    "id": "1515",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification.html"
  },
  "1516": {
    "id": "1516",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_token_classification.html"
  },
  "1517": {
    "id": "1517",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/roberta_sentence_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/roberta_sentence_embeddings.html"
  },
  "1518": {
    "id": "1518",
    "title": "Rules",
    "content": "Rule based annotation is supported by Healthcare NLP, Finance NLP, and Legal NLP via the ContextualParser Annotator. Annotation Lab supports creating and using rules in a NER project using any one of these libraries with the presence of valid license. Users in the Admins group can see and edit the available rules on the Rules page under the Models Hub menu. Users can create new rules using the + Add Rules button. Users can also import and export the rules. There are two types of rules supported: Regex Based: Users can define a regex that will be used to label all possible hit chunks and label them as the target entity. For example, for labeling height entity the following regex can be used [0-7]&#39;((0?[0-9])|(1(0|1)))&#39;&#39;. All hits found in the task’s text content that match the regex are pre-annotated as height. Dictionary-Based: Users can define and upload a CSV dictionary of keywords that cover the list of chunks that should be annotated as a target entity. For example, for the label female, all occurrences of strings woman, lady, and girl within the text content of a given task will be pre-annotated as female. After adding a rule, the Project Owner or Manager can add the rule to the configuration of the project where they want to use it. This can be done from the Rules screen of the Project Configuration step on the Project Setup page. A valid Healthcare, Finance or Legal NLP license is required to deploy rules as a pre-annotation server after completing the project configuration step. The user is notified every time a rule in use is edited with the message “Redeploy preannotation server to apply these changes” on the Edit Rule form. Import and Export Rules Annotation Lab allows importing and exporting Rules from the Rules page. Import Rules Users can import rules from the Rules page. The rules can be both dictionary based or regex based. The rules can be imported in the following formats: JSON file or content. Zip archive of JSON file/s. Export Rules To export any rule, the user need to select the available rules and click on Export Rules button. Rules are then downloaded as a zip file. The zip file contains the JSON file for each rule. These exported rules can again be imported to Annotation Lab. The following blog posts explain how to create and use rules for jump starting your annotation projects: Using Rules to Jump Start Text Annotation Projects Using Rules and Pretrained Models in Text Annotation Projects Training and tuning models based on Rule-based annotation of text documents",
    "url": "/docs/en/alab/rules",
    "relUrl": "/docs/en/alab/rules"
  },
  "1519": {
    "id": "1519",
    "title": "",
    "content": "",
    "url": "/api/python/search.html",
    "relUrl": "/api/python/search.html"
  },
  "1520": {
    "id": "1520",
    "title": "Section Based Annotations",
    "content": "NLP Lab 5 - Harness the Power of Section-Based Annotation for Advanced NLP Tasks We’re excited to announce that NLP Lab 5 is now available! This major update offers out-of-the-box support for section-based annotation, a feature that makes annotating larger documents with deep learning (DL) models or large language models (LLMs) an absolute breeze. Section-based annotation is a cornerstone feature, that proposes a new strategy to handle manual and automatic text annotation. First of all, it allows the splitting of tasks into distinct sections, at various granular levels such as sentences, paragraphs, or even pages, depending on the requirement of the use case at hand. This approach gives annotators a clear view and fine-grained control over the document structure. Second, it allows users to specify what are the relevant sections for their project’s specific goals. This can be done by a combination of specific keywords that can be found inside the relevant texts, regular expressions (regex) matching particular patterns within the text, or by the use of classifiers specially trained to recognize specific types of sections.  This two-step process ensures that only relevant sections, those most likely to provide valuable insights, are selected for further annotation. The following are three essential benefits related to this process: - streamlined and targeted annotations that ignore irrelevant sections within a task,  - context limitation for text processing via LLMs, and DL models for increased performance and speed at lower costs, - customizable taxonomies for each section for focused (pre)annotations. Relevant sections can be automatically identified by the NLP Lab during the task import step but they can also be manually adjusted/created/removed when required, by the annotators themselves as part of their completions.  Limiting the (pre)annotation context is essential in view of the larger integration with LLM we are preparing (stay tuned for NLP Lab 5.2). By focusing on one relevant section at a time, instead of an entire document that can be hundreds of pages long, NLP Lab ensures that the LLM ingests only the relevant context, suppressing distraction by eliminating noise or irrelevant data. This will improve the response time and the precision of predictions while being considerate of the processing costs.  NER tasks are all about precision! Starting with NLP Lab 5 you will be able to associate relevant labels to specific sections of text. This results in more precise entity recognition and reduced chances of false positives. This granularity of annotation is crucial for those working on projects where each detail matters. For classification tasks, the section-based annotation feature enables classification to be performed at the sentence, paragraph, or page level. This offers unparalleled flexibility to split the task according to the required level of granularity. Whether you are classifying sentences or whole paragraphs, NLP Lab now accommodates your needs in a much more tailored way. We understand that annotators want to focus their efforts on the most pertinent areas of the documents they process. With section-based annotation, they can focus solely on the relevant sections, leading to better productivity and less time spent scrolling through irrelevant content. During model training, only the annotations from the relevant sections will be used. This feature drastically reduces the training time required, saving valuable computational resources and accelerating the project timelines. When it comes to pre-annotations, the models, prompts, and rules now evaluate solely the relevant sections. This thoughtful approach results in more precise pre-annotations and faster computation of results, thereby boosting your project efficiency. Overall, section-based annotation in NLP Lab streamlines the annotation process, enabling annotators to concentrate on the necessary sections while optimizing training time and enhancing the accuracy of pre-annotations. We’re confident that this new release will significantly improve your NLP project execution. We can’t wait to see what amazing things you’ll do with it! NLP Tasks compatible with Section-Based Annotation NLP Lab offers Section-Based Annotation features for the following tasks: Named Entity Recognition (NER): NER tasks involving text can now be partitioned into sections using bespoke rules, facilitating an efficient examination and annotation of only the pertinent sections.  Text Classification: With the introduction of Section-Based Annotation, tasks can now be divided into relevant sections, and each section can be independently classified, eliminating the limitations of classifying the entire task as a whole. Combined NER and Classification: NLP Lab’s versatility enables it to support project configurations combining NER and assertion labeling, with classification or relation extraction. Users can now identify relevant sections within the project and carry out classification as well as NER and relation labeling within each section. Specific taxonomies can be defined for each such section that offers more control over the annotation targets. Visual NER: Section-Based Annotation is now available for Visual NER projects, specifically designed for image-based tasks. This feature is particularly beneficial when dealing with lengthy PDFs that are divided into sections by page. Users have the ability to specify the specific pages that are relevant to their needs. With Section-Based Annotation, NLP Lab offers a more granular approach to annotation and analysis, allowing users to focus on specific sections and achieve more accurate and efficient results. Task Splitting  The project definition wizard introduces the task-splitting feature as an independent step, following the content type definition. In this second step of the project definition, users can opt for annotating the entire task at hand by choosing the “Entire Document” option or annotating only the relevant sections by choosing the “Relevant Sections” option. Three methods are available for splitting your tasks: Split by Page: In text projects, a page is delineated by a specific character count. Users will find a dropdown menu featuring the same two default options as seen in the annotation screen for identifying a page: 1800 and 3600 characters. For Visual NER projects, a page represents a single page in the PDF document or an image. The page boundaries are automatically established, eliminating the need for further user inputs. Split by Paragraph: Text tasks can be divided into paragraphs by using a dynamic regex such as “ n”. Custom regex expressions are also supported and can be defined to adapt the task splitting to the particularities of your documents.  Split by Sentence: This selection enables users to partition text documents into individual sentences, using single or multiple delimiters. The full-stop sign ‘.’ is the default delimiter used to identify sentence boundaries. Since a sentence may end with various delimiters. users have the flexibility to include multiple delimiters for sentence segmentation. IMPORTANT REMARKS: The Split by Paragraph and Split by Sentence options are not applicable for Visual NER projects. Section Based annotations cannot be enabled for pre-existing projects with annotated tasks or any project with tasks already in progress.  What Makes a Section Relevant? After enabling the “Relevant Sections” feature and selecting a method to split documents into smaller parts (either by page, paragraph, or sentence), users can proceed to define the rules for identifying the relevant sections they want to work on. Only the sections that match the added section rules will be considered relevant.  Each section has a name that can be linked to the taxonomy elements (NER, assertion, or classification labels) that apply to that specific section. As such, all taxonomy elements that do not apply to section A, for instance, will be hidden on the annotation screen when section A is active or selected, making it easier for human users to check pre-annotations or define new annotations.  Four types of rules can be combined to identify relevant sections: Index-Based Rules The section index refers to the crt. number of a section in the ordered list of sections created for a task. Index values are positive or negative integers, and can be specified in various formats. For example, you can define a sequence of integers such as 4, 5, 9 for the fourth, fifth and ninth sections, a range of values such as 1-10 to include all values from 1 to 10 or a negative value -1 to denote the last section in the task.  Keyword-Based Rules Keywords can be used to mark a section as relevant. Each keyword can be a single word or a phrase consisting of alphanumeric characters. Multiple keywords can be used by separating them with commas (“,”). All sections containing the specified (list of) keywords will be considered relevant.  Regex-Based Rules: Regex (regular expressions) can also be used to identify relevant sections. If a match is found within the document based on the provided regex, the corresponding page, paragraph, or sentence will be considered relevant. Classifier-Based Rules: Identification of relevant sections can also be done using pre-trained classifier models. Users can select one classifier from the available ones (downloaded or trained within NLP Lab) and pick the classes considered relevant for the current project. Those will be associated to a section name. Multiple relevant sections can be created with the same classifier. Please note that only one classifier can be used for section classification as part of one project. Saving this rule will deploy a classifier server, which can be viewed on the Cluster page. Licensed classifiers require a free valid license to run, and the deployment of a classifier is subject to the availability of server capacity. Merge Consecutive Sections for Simplified Workflows: Successive sections with the same name can be merged into one section. This feature is available by checking the corresponding option below the section definition widget. This simplifies the annotation process by grouping together neighboring sections with the same name for which the same taxonomy applies.  ) IMPORTANT REMARKS: For Visual NER projects, the rules for defining relevant sections are limited to index, keywords, and regex. Section Specific Taxonomies The section-based annotation options provide users with the flexibility to customize and configure the labels and choices that are displayed in specific sections. This setup can be conveniently accomplished via the project configuration page, which presents a visual mode for label customization. In the case of Named Entity Recognition (NER) labels, users can simply click on individual labels and choose the specific sections where they want the label to be visible. By doing so, users have the ability to define the sections within the task where each NER label should appear, ensuring that the annotation is precise and applicable to the intended sections. Similarly, for choices, users can navigate to the three-dot menu, typically located next to each choice name. By selecting this menu, users can access the configuration settings to designate the relevant sections where the particular choice should be displayed. This feature allows users to tailor the choices available for annotation in specific sections, making the annotation process more precise and efficient. By providing the ability to configure labels and choices at the section level, users can ensure that their annotation efforts are focused on the most relevant parts of the text. This ensures that the annotation process is efficient, saving valuable time and resources. Ultimately, this level of customization empowers users to create high-quality annotations tailored to their specific tasks and objectives. Pre-annotation Focused on Relevant Sections In Section-Based Annotation projects, users can mix DL models, rules, and prompts for pre-annotating relevant sections according to their specific taxonomies. By splitting tasks into relevant sections, pre-annotation leverages the trained/deployed model to generate predictions focusing exclusively on those smaller chunks of text. This significantly streamlines the pre-annotation workflow, enabling users to leverage the precision and efficiency of predictions derived from DL models, LLM prompts, and rules.  Also when leveraging prompts-based annotation it is important to consider the context limitations. The LLMs can only process a certain number of tokens (words or characters, depending on the model) at a time. For instance, for OpenAI’s GPT-3, the maximum limit is approximately 6500 words, while the context length of GPT-4 is limited to approximately 25,000 words. There is also a version that can handle up to 50 pages of text, but the more context you send to LLM the higher the costs. If the document you are trying to pre-annotate is larger than the LLM’s limit, you will need to break it down into smaller sections. This is where section-based annotation becomes particularly useful. It allows you to focus on the most relevant parts of the document without exceeding the token limit. It’s also important to note that LLMs do not have a memory of previous requests. Therefore, the context that is sent for each request should contain all the necessary information for generating accurate predictions. Model Training with Section-Level Annotations In projects that support Section-Based Annotation, each section is treated as an individual document during the training process. This means that the annotations contained within a given section, along with the section’s text, are provided to the training pipeline. By considering the specific content and context of the relevant sections, the training process becomes more targeted and accurate, resulting in improved model performance. This advanced training approach allows for a more focused training experience by excluding irrelevant sections and solely focusing on the sections that contain annotations. Training specifically on these relevant sections optimizes the training process, resulting in improved pre-annotation efficiency and accuracy. This targeted approach enhances the precision and overall accuracy of trained models. Manual Annotation of Relevant Sections Start from the Default Relevant Sections When importing a new task, the relevant sections are automatically created based on the rules defined on the section configuration page. This division allows the annotator to focus on annotating the relevant sections individually. By breaking down the task into manageable sections, the annotation process becomes more focused and efficient. When a task is opened in the annotation screen, a new completion is generated by default, based on the automatically detected sections. The first relevant section is active by default and shown as highlighted in the yellow background (see item 7 on the below image) on the UI. Additionally, the name of the active section is displayed in the top bar (5), providing clear context to the user. Manual Creation/Removal of Relevant Section There may be occasions when the predefined rules do not accurately capture the necessary relevant sections. For such scenarios, the user has the option to manually select the required text regions within the document and add a new section using the ‘Create’ button located at the top of the annotation area (see item 2 in the below image). A pop-up window allows users to choose the section to which the selected region belongs. (see item 3 in the image below). This ensures that no relevant information is overlooked or omitted during the annotation process. The custom-created sections are specific to the completions created by each user, and it can be possible that different users will submit starred completions with different relevant sections for the same task. This type of situation should be discussed in Inter Annotator Agreement meetings and consensus should be reached on what defines a relevant section.  By incorporating both automated section generation based on configuration rules and the ability to manually create sections, the annotation system offers a comprehensive approach that balances convenience and customization. Annotators can annotate efficiently on the automatically detected sections, while also having the flexibility to modify or create sections manually when necessary. It is also possible to remove an existing section. For this, users can simply click on the delete button associated with that section (see item 4 on the above images). Navigating Between Relevant sections Users can easily navigate to relevant sections using the ‘Previous’ and ‘Next’ buttons. Clicking these navigation buttons moves the user’s view to the appropriate area where the relevant section is located. If the relevant section is on the next page, the display will automatically transition to that page, ensuring seamless access to the desired section. Cloning Completions with Custom Sections In section-based tasks, cloning a completion entails automatically duplicating the section as well as the associated annotations. In other words, the process of copying completions ensures that the section structure, along with its corresponding annotations, is replicated in the new completion. This feature allows users to work on multiple iterations or variations of the task, each with its distinct relevant section, without losing any work - annotations, and labels - done in the original completion. By supporting the duplication of completions while preserving the section-based context, the annotation system grants users the flexibility to modify and refine their work as needed. It enables users to submit different versions of completions, each with its unique relevant section, facilitating a more nuanced and specific analysis of the underlying data. Creating New Completions If there are multiple completions submitted by different annotators and the user decides to create a new completion from scratch, the relevant sections will be generated based on the rules that were initially set when the task was imported. IMPORTANT REMARKS: Changes made to the section rules do not apply to existing imported tasks. The updated rules are only applied to newly imported tasks. Section-based annotation improvements Support for task splitting with external services We are excited to introduce a new feature in NLP Lab that allows users to import sections created outside of the platform. Users can now import tasks already split into sections using external tools like Open AI’s ChatGPT. For this, we added support for “Additional sections” – sections that do not have a definition to allow their automatic identification by NLP Lab. Those sections can only be manually created by annotators or imported via the JSON import format. On the import screen users must check the “Preserve Imported Sections” options, if the imported JSON file includes a section definition. Targeted pre-annotation for relevant sections While in previous versions the Annotation screen was set to filter out the list of available labels/choices based on their association with the active sections, this version takes things to the next level. It is now possible to also filter out pre-annotations based on section-specific configuration. Users can configure labels to be displayed exclusively in specific sections during the manual annotation and the automatic pre-annotation process. For instance, let’s consider a NER project with a taxonomy composed of two labels: Label1, which is now set to be shown only in Section1, and Label2, configured to be shown solely in Section2. When running pre-annotation, NLP Lab will automatically adhere to these associations. Consequently, during the pre-annotation process, in Section 1, users will only see annotations for Label1, and similarly, in Section 2, only instances of Label2 will be shown. Pre-annotations applied to all defined sections tasks NLP Lab 5.2, adds a new feature - “Preannotations for Union of Sections”. This enhancement ensures that pre-annotations cover all relevant sections – imported from outside sources, manually added by annotators, or automatically detected by the tool. With this feature, collaboration is enhanced, and all points of view are taken into account during pre-annotation, resulting in a more precise and efficient annotation process. Imagine there’s a task Task-1, and two annotators, Annotator-1 and Annotator-2, are working on it. Annotator-1 decides to customize the sections and manually deletes all the relevant sections generated through section rules. Instead, he adds a new relevant section manually. On the other hand, Annotator-2 prefers to keep the sections automatically detected and also manually creates a new relevant section, different from what Annotator-1 added. Now, when the project manager runs pre-annotation on Task-1, the pre-annotation process will consider the union of sections added by both annotators, along with the relevant sections generated from the section rules or imported from external sources. To further optimize the annotation experience, NLP Lab provides a checkbox “Filter pre-annotations according to my latest completion” within the Predictions card on the right-hand side of the labeling screen. Enabling this option ensures that the pre-annotation process only includes sections present in the latest completion of the current user.",
    "url": "/docs/en/alab/section_based_annotations",
    "relUrl": "/docs/en/alab/section_based_annotations"
  },
  "1521": {
    "id": "1521",
    "title": "Security and Privacy",
    "content": "We understand and take the security issues as the highest priority. On every release, all our artifacts and images ran through a series of security testing - Static Code analysis, Pen Test, Images Vulnerabilities Test, AWS AMI Scan Test. Every identified critical issue is remediated, code gets refactored to pass our standard Static Code Analysis. Role-based access Role-based access control is available for all Annotation Lab deployments. By default, all projects are private to the user who created them – the project owner. If necessary, project owners can add other users to the project and define their role(s) among annotator, reviewer, manager. The three roles supported by Annotation Lab offer different levels of task and feature visibility. Annotators can only see tasks assigned to them and their own completions. Reviewers can see the work of annotators who created completions for the tasks assigned to them. Annotators and reviewers do not have access to task import or annotation export nor to the Models Hub page. Managers have higher level of access. They can see all tasks content, can assign work to annotators and reviewers, can import tasks, export annotations, see completions created by team members or download models. When creating the annotation team, make sure the appropriate role is assigned to each team member according to the Need-To-Know Basis. Screen capture is not disabled, and given the high adoption of mobile technologies, team members can easily take pictures of the data. This is why, when dealing with sensitive documents, it is advisable to conduct periodical HIPPA/GDPR training with the annotation team to avoid data breaches. Data sharing Annotation Lab runs locally - all computation and model training run inside the boundaries of your deployment environment. The content related to any tasks within your projects is NOT SHARED with anyone. The Annotation Lab does not call home. Access to internet is used ONLY when downloading models from the NLP Models Hub. Document processing - OCR, pre-annotation, training, fine-tuning- runs entirely on your environment. Secure user access to Annotation Lab Access to Annotation Lab is restricted to users who are given access by an admin or project manager. Each user has an account; when created, passwords are enforced to best practice security policy. Annotation Lab keeps track of who has access to the defined projects and their actions regarding completions creation, cloning, submission, and starring. See User Management Page for more details. API access to Annotation Lab Access to Annotation Lab REST API requires an access token that is specific to a user account. To obtain your access token please follow the steps illustrated here. Complete project audit trail Annotation Lab keeps trail for all created completions. It is not possible for annotators or reviewers to delete any completions and only managers and project owners are able to remove tasks. Application development cycle The Annotation Lab development cycle currently includes static code analysis; everything is assembled as docker images whom are being scanned for vulnerabilities before being published. We are currently implementing web vulnerability scanning.",
    "url": "/docs/en/alab/security",
    "relUrl": "/docs/en/alab/security"
  },
  "1522": {
    "id": "1522",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/sentence/sentence_detector.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/sentence/sentence_detector.html"
  },
  "1523": {
    "id": "1523",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/sentence/sentence_detector_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/sentence/sentence_detector_dl.html"
  },
  "1524": {
    "id": "1524",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/sentence_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/sentence_embeddings.html"
  },
  "1525": {
    "id": "1525",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/sentiment/sentiment_detector.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/sentiment/sentiment_detector.html"
  },
  "1526": {
    "id": "1526",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/sentiment_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/sentiment_dl.html"
  },
  "1527": {
    "id": "1527",
    "title": "Serving Spark NLP&#58 MLFlow on Databricks",
    "content": "",
    "url": "/docs/en/serving_spark_nlp_via_api_databricks_mlflow",
    "relUrl": "/docs/en/serving_spark_nlp_via_api_databricks_mlflow"
  },
  "1528": {
    "id": "1528",
    "title": "Social Determinant - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/social_determinant",
    "relUrl": "/social_determinant"
  },
  "1529": {
    "id": "1529",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/spacy_to_annotation.html",
    "relUrl": "/api/python/modules/sparknlp/training/spacy_to_annotation.html"
  },
  "1530": {
    "id": "1530",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/coref/spanbert_coref.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/coref/spanbert_coref.html"
  },
  "1531": {
    "id": "1531",
    "title": "Spark NLP",
    "content": "",
    "url": "/docs/en/spark-nlp",
    "relUrl": "/docs/en/spark-nlp"
  },
  "1532": {
    "id": "1532",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp.html",
    "relUrl": "/api/python/modules/sparknlp.html"
  },
  "1533": {
    "id": "1533",
    "title": "Speech and Vision Recognition - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/speech_vision_recognition",
    "relUrl": "/speech_vision_recognition"
  },
  "1534": {
    "id": "1534",
    "title": "Starting a Spark Session",
    "content": "To use most features you must start a Spark Session with nlp.start()first. This will launch a Java Virtual Machine(JVM) process on your machine which has all of John Snow Labs and Sparks Scala/Java Libraries(JARs) you have access to loaded into memory. The nlp.start() method downloads loads and caches all jars for which credentials are provided if they are missing into ~/.jsl_home/java_installs. If you have installed via nlp.install() you can most likely skip the rest of this page, since your secrets have been cached in ~/.jsl_home and will be re-used. If you disabled license caching while installing or if you want to tweak settings about your spark session continue reading this section further. Outputs of running nlp.start() tell you which jars are loaded and versions of all relevant libraries. Authorization Flow Parameters Most of the authorization Flows and Parameters of nlp.install() are supported. Review detailed docs here Parameter Description Example Default None Load license automatically via one of the Auto-Detection Mechanisms nlp.start() False browser_login Browser based authorization, Button to click on Notebooks and Browser Pop-Up otherwise. nlp.start(browser_login=True) False access_token Vist my.johnsnowlabs.com to extract a token which you can provide to enable license access. See Access Token Example nlp.start(access_token=&#39;myToken&#39;) None secrets_file Define JSON license file with keys defined by License Variable Overview and provide file path nlp.start(secrets_file=&#39;path/to/license.json&#39;) None store_in_jsl_home Disable caching of new licenses to ~./jsl_home nlp.start(store_in_jsl_home=False) True local_license_number Specify which license to use, if you have access to multiple locally cached nlp.start(license_number=5) 0 remote_license_number Specify which license to use, if you have access to multiple via OAUTH on my.jsl.com nlp.start(license_number=5) 0 Manually specify License Parameters These can be omitted according to the License Variable Overview Parameter Description aws_access_key Corresponds to AWS_ACCESS_KEY_ID aws_key_id Corresponds to AWS_SECRET_ACCESS_KEY enterprise_nlp_secret Corresponds to HC_SECRET ocr_secret Corresponds to OCR_SECRET hc_license Corresponds to HC_LICENSE ocr_license Corresponds to OCR_LICENSE fin_license Corresponds to JSL_LEGAL_LICENSE leg_license Corresponds to JSL_FINANCE_LICENSE Sparksession Parameters These parameters configure how your spark Session is started up. See Spark Configuration for a comprehensive overview of all spark settings Parameter Default Description Example spark_conf None Dictionary Key/Value pairs of Spark Configurations for the Spark Session nlp.start(spark_conf={&#39;spark.executor.memory&#39;:&#39;6g&#39;}) master_url local[*] URL to Spark Cluster master nlp.start(master_url=&#39;spark://my.master&#39;) jar_paths None List of paths to jars which should be loaded into the Spark Session nlp.start(jar_paths=[&#39;my/jar_folder/jar1.zip&#39;,&#39;my/jar_folder/jar2.zip&#39;] ) exclude_nlp False Whether to include Spark NLP jar in Session or not. This will always load the jar if available, unless set to True. nlp.start(exclude_nlp=True) exclude_healthcare False Whether to include licensed NLP Jar for Legal,Finance or Healthcare. This will always load the jar if available using your provided license, unless set to True. nlp.start(exclude_healthcare=True) exclude_ocr False Whether to include licensed OCR Jar for Legal,Finance or Healthcare. This will always load the jar if available using your provided license, unless set to True. nlp.start(exclude_ocr=True) hardware_target cpu Specify for which hardware Jar should be optimized. Valid values are gpu,cpu,m1,aarch nlp.start(hardware_target=&#39;m1&#39;) model_cache_folder None Specify where models should be downloaded to when using model.pretrained() nlp.start(model_cache_folder=True)",
    "url": "/docs/en/jsl/start-a-sparksession",
    "relUrl": "/docs/en/jsl/start-a-sparksession"
  },
  "1535": {
    "id": "1535",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/stemmer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/stemmer.html"
  },
  "1536": {
    "id": "1536",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/stop_words_cleaner.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/stop_words_cleaner.html"
  },
  "1537": {
    "id": "1537",
    "title": "Streamlit visualization Examples",
    "content": "This page contains examples and tutorials on how to visualize the 10000+ state-of-the-art NLP models in just 1 line of code in streamlit. It includes simple 1-liners you can sprinkle into your Streamlit app to for features like Dependency Trees, Named Entities (NER), text classification results, semantic simmilarity, embedding visualizations via ELMO, BERT, ALBERT, XLNET and much more . Additionally, improvements for T5 and various resolvers have been added. This is the ultimate NLP research tool. You can visualize and compare the results of hundreds of context aware deep learning embeddings and compare them with classical vanilla embeddings like Glove and can see with your own eyes how context is encoded by transformer models like BERT or XLNETand many more ! Besides that, you can also compare the results of the 200+ NER models John Snow Labs provides and see how peformances changes with varrying ebeddings, like Contextual, Static and Domain Specific Embeddings. Install pip install streamlit sklearn plotly Problems? Connect with us on Slack! Impatient and want some action? Just run this Streamlit app, you can use it to generate python code for each Streamlit building block streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/01_dashboard.py Quick Starter cheat sheet - All you need to know in 1 picture for NLP + Streamlit For NLP models to load, see the NLP namespace or the John Snow Labs Modelshub or go straight to the source. Examples Just try out any of these. You can use the first example to generate python-code snippets which you can recycle as building blocks in your streamlit apps! Example: 01_dashboard streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/01_dashboard.py Example: 02_NER streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/02_NER.py Example: 03_text_similarity_matrix streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/03_text_similarity_matrix.py Example: 04_dependency_tree streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/04_dependency_tree.py Example: 05_classifiers streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/05_classifiers.py Example: 06_token_features streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/06_token_features.py Example: 07_token_embedding_dimension_reduction streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/07_token_embedding_manifolds.py Example: 08_token_embedding_dimension_reduction streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/08_sentence_embedding_manifolds.py Example: 09_entity_embedding_dimension_reduction streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/09_entity_embedding_manifolds.py How to use the nlp module? All you need to know about the nlp module is that there is the nlp.load() method which returns a NLUPipeline object which has a .predict() that works on most common data types in the pydata stack like Pandas dataframes . Ontop of that, there are various visualization methods a NLUPipeline provides easily integrate in Streamlit as re-usable components. viz() method Overview of NLP + Streamlit buildingblocks | Method | Description | |——————————————————————————–|————————————————————————————————————————————————————————————————————————————————————————-| | nlp.load(&#39;&lt;Model&gt;&#39;).predict(data) | Load any of the 1000+ models by providing the model name any predict on most Pythontic data strucutres like Pandas, strings, arrays of strings and more | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit(data) | Display full NLP exploration dashboard, that showcases every feature avaiable with dropdown selectors for 1000+ models | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_similarity([string1, string2]) | Display similarity matrix and scalar similarity for every word embedding loaded and 2 strings. | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_ner(data) | Visualize predicted NER tags from Named Entity Recognizer model | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_dep_tree(data) | Visualize Dependency Tree together with Part of Speech labels | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_classes(data) | Display all extracted class features and confidences for every classifier loaded in pipeline | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_token(data) | Display all detected token features and informations in Streamlit | | nlp.load(&#39;&lt;Model&gt;&#39;).viz(data, write_to_streamlit=True) | Display the raw visualization without any UI elements. See viz docs for more info. By default all aplicable nlp model references will be shown. | | nlp.enable_streamlit_caching() | Enable caching the nlp.load() call. Once enabled, the nlp.load() method will automatically cached. ** This is recommended** to run first and for large peformance gans | Detailed visualizer information and API docs function pipe.viz_streamlit Display a highly configurable UI that showcases almost every feature available for Streamlit visualization with model selection dropdowns in your applications. Ths includes : Similarity Matrix &amp; Scalars &amp; Embedding Information for any of the 100+ Word Embedding Models NER visualizations for any of the 200+ Named entity recognizers Labled &amp; Unlabled Dependency Trees visualizations with Part of Speech Tags for any of the 100+ Part of Speech Models Token informations predicted by any of the 1000+ models Classification results predicted by any of the 100+ models classification models Pipeline Configuration &amp; Model Information &amp; Link to John Snow Labs Modelshub for all loaded pipelines Auto generate Python code that can be copy pasted to re-create the individual Streamlit visualization blocks. NlLU takes the first model specified as nlp.load() for the first visualization run. Once the Streamlit app is running, additional models can easily be added via the UI. It is recommended to run this first, since you can generate Python code snippets to recreate individual Streamlit visualization blocks nlp.load(&#39;ner&#39;).viz_streamlit([&#39;I love NLP and Streamlit!&#39;, &#39;I hate buggy software&#39;]) function parameters pipe.viz_streamlit Argument Type Default Description text Union [str, List[str], pd.DataFrame, pd.Series] &#39;NLP and Streamlit go together like peanutbutter and jelly&#39; Default text for the Classification, Named Entitiy Recognizer, Token Information and Dependency Tree visualizations similarity_texts Union[List[str],Tuple[str,str]] (&#39;Donald Trump Likes to part&#39;, &#39;Angela Merkel likes to party&#39;) Default texts for the Text similarity visualization. Should contain exactly 2 strings which will be compared token embedding wise. For each embedding active, a token wise similarity matrix and a similarity scalar model_selection List[str] [] List of nlp references to display in the model selector, see the NLP namespace or the John Snow Labs Modelshub or go straight to the source for more info title str &#39;NLP ❤️ Streamlit - Prototype your NLP startup in 0 lines of code🚀&#39; Title of the Streamlit app sub_title str &#39;Play with over 1000+ scalable enterprise NLP models&#39; Sub title of the Streamlit app visualizers List[str] ( &quot;dependency_tree&quot;, &quot;ner&quot;, &quot;similarity&quot;, &quot;token_information&quot;, &#39;classification&#39;) Define which visualizations should be displayed. By default all visualizations are displayed. show_models_info bool True Show information for every model loaded in the bottom of the Streamlit app. show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click show_viz_selection bool False Show a selector in the sidebar which lets you configure which visualizations are displayed. show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLP namespace structure. set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_code_snippets bool False Display Python code snippets above visualizations that can be used to re-create the visualization num_similarity_cols int 2 How many columns should for the layout in Streamlit when rendering the similarity matrixes. function pipe.viz_streamlit_classes Visualize the predicted classes and their confidences and additional metadata to streamlit. Aplicable with any of the 100+ classifiers nlp.load(&#39;sentiment&#39;).viz_streamlit_classes( [&#39;I love NLP and Streamlit!&#39;, &#39;I love buggy software&#39;, &#39;Sign up now get a chance to win 1000$ !&#39;, &#39;I am afraid of Snakes&#39;, &#39;Unicorns have been sighted on Mars!&#39;, &#39;Where is the next bus stop?&#39;]) function parameters pipe.viz_streamlit_classes Argument Type Default Description text Union[str,list,pd.DataFrame, pd.Series, pyspark.sql.DataFrame ] &#39;I love NLU and Streamlit and sunny days!&#39; Text to predict classes for. Will predict on each input of the iteratable or dataframe if type is not str. output_level Optional[str] document Outputlevel of NLP pipeline, see pipe.predict() docsmore info include_text_col bool True Whether to include a e text column in the output table or just the prediction data title Optional[str] Text Classification Title of the Streamlit building block that will be visualized to screen metadata bool False whether to output addition metadata or not, see pipe.predict(meta=true) docs for more info positions bool False whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLP namespace structure. function pipe.viz_streamlit_ner Visualize the predicted classes and their confidences and additional metadata to Streamlit. Aplicable with any of the 250+ NER models. You can filter which NER tags to highlight via the dropdown in the main window. Basic usage nlp.load(&#39;ner&#39;).viz_streamlit_ner(&#39;Donald Trump from America and Angela Merkel from Germany dont share many views&#39;) Example for coloring # Color all entities of class GPE black nlp.load(&#39;ner&#39;).viz_streamlit_ner(&#39;Donald Trump from America and Angela Merkel from Germany dont share many views&#39;, colors={&#39;PERSON&#39;: &#39;#6e992e&#39;, &#39;GPE&#39;: &#39;#000000&#39;}) function parameters pipe.viz_streamlit_ner Argument Type Default Description text str &#39;Donald Trump from America and Anegela Merkel from Germany do not share many views&#39; Text to predict classes for. ner_tags Optional[List[str]] None Tags to display. By default all tags will be displayed show_label_select bool True Whether to include the label selector show_table bool True Whether show to predicted pandas table or not title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen sub_title Optional[str] &#39;&quot;Recognize various Named Entities (NER) in text entered and filter them. You can select from over 100 languages in the dropdown. On the left side.&quot;,&#39; Sub-title of the Streamlit building block that will be visualized to screen colors Dict[str,str] {} Dict with KEY=ENTITY_LABEL and VALUE=COLOR_AS_HEX_CODE,which will change color of highlighted entities.See custom color labels docs for more info. set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models available in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_text_input bool True Show text input field to input text in show_logo bool True Show logo display_infos bool False Display additional information about ISO codes and the NLP namespace structure. function pipe.viz_streamlit_dep_tree Visualize a typed dependency tree, the relations between tokens and part of speech tags predicted. Aplicable with any of the 100+ Part of Speech(POS) models and dep tree model nlp.load(&#39;dep.typed&#39;).viz_streamlit_dep_tree( &#39;POS tags define a grammatical label for each token and the Dependency Tree classifies Relations between the tokens&#39;) function parameters pipe.viz_streamlit_dep_tree Argument Type Default Description text str &#39;Billy likes to swim&#39; Text to predict classes for. title Optional[str] &#39;Dependency Parse Tree &amp; Part-of-speech tags&#39; Title of the Streamlit building block that will be visualized to screen set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLP namespace structure. function pipe.viz_streamlit_token Visualize predicted token and text features for every model loaded. You can use this with any of the 1000+ models and select them from the left dropdown. nlp.load(&#39;stemm pos spell&#39;).viz_streamlit_token(&#39;I liek pentut buttr and jelly !&#39;) function parameters pipe.viz_streamlit_token Argument Type Default Description text str &#39;NLU and Streamlit are great!&#39; Text to predict token information for. title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen show_feature_select bool True Whether to include the token feature selector features Optional[List[str]] None Features to to display. By default all Features will be displayed metadata bool False Whether to output addition metadata or not, see pipe.predict(meta=true) docs for more info output_level Optional[str] &#39;token&#39; Outputlevel of NLP pipeline, see pipe.predict() docsmore info positions bool False Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLP namespace structure. function pipe.viz_streamlit_similarity Displays a similarity matrix, where x-axis is every token in the first text and y-axis is every token in the second text. Index i,j in the matrix describes the similarity of token-i to token-j based on the loaded embeddings and distance metrics, based on Sklearns Pariwise Metrics. . See this article for more elaboration on similarities Displays a dropdown selectors from which various similarity metrics and over 100 embeddings can be selected. -There will be one similarity matrix per metric and embedding pair selected. num_plots = num_metric*num_embeddings Also displays embedding vector information. Applicable with any of the 100+ Word Embedding models nlp.load(&#39;bert&#39;).viz_streamlit_word_similarity( [&#39;I love love loooove NLP! &lt;3&#39;, &#39;I also love love looove Streamlit! &lt;3&#39;]) function parameters pipe.viz_streamlit_similarity Argument Type Default Description texts str &#39;Donald Trump from America and Anegela Merkel from Germany do not share many views.&#39; Text to predict token information for. title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen similarity_matrix bool None Whether to display similarity matrix or not show_algo_select bool True Whether to show dist algo select or not show_table bool True Whether show to predicted pandas table or not threshold float 0.5 Threshold for displaying result red on screen set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info write_raw_pandas bool False Write the raw pandas similarity df to streamlit display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more. dist_metrics List[str] [&#39;cosine&#39;] Which distance metrics to apply. If multiple are selected, there will be multiple plots for each embedding and metric. num_plots = num_metric*num_embeddings. Can use multiple at the same time, any of of cityblock,cosine,euclidean,l2,l1,manhattan,nan_euclidean. Provided via Sklearn metrics.pairwise package num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes. display_scalar_similarities bool False Display scalar similarities in an additional field. display_similarity_summary bool False Display summary of all similarities for all embeddings and metrics. show_logo bool True Show logo display_infos bool False Display additional information about ISO codes and the NLP namespace structure. Embedding visualization via Manifold and Matrix Decomposition algorithms function pipe.viz_streamlit_word_embed_manifold Visualize Word Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 11 Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms . Additionally, you can color the lower dimensional points with a label that has been previously assigned to the text by specifying a list of nlp references in the additional_classifiers_for_coloring parameter. Reduces Dimensionality of high dimensional Word Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 100+ Word Embedding models Color points by classifying with any of the 100+ Parts of Speech Classifiers or Document Classifiers Gemerates NUM-DIMENSIONS * NUM-EMBEDDINGS * NUM-DIMENSION-REDUCTION-ALGOS plots nlp.load(&#39;bert&#39;, verbose=True).viz_streamlit_word_embed_manifold(default_texts=[&#39;I love NLU &lt;3&#39;, &#39;I love streamlit &lt;3&#39;], default_algos_to_apply=[&#39;TSNE&#39;], MAX_DISPLAY_NUM=5) function parameters pipe.viz_streamlit_word_embed_manifold Argument Type Default Description   default_texts List[str] (“Donald Trump likes to party!”, “Angela Merkel likes to party!”, ‘Peter HATES TO PARTTY!!!! :(‘) List of strings to apply classifiers, embeddings, and manifolds to.   text Optional[str] &#39;Billy likes to swim&#39; Text to predict classes for.   sub_title Optional[str] “Apply any of the 11 Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Word Embeddings to 1-D, 2-D and 3-D “ Sub title of the Streamlit app   default_algos_to_apply List[str] [&quot;TSNE&quot;, &quot;PCA&quot;] A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;,   target_dimensions List[int] (1,2,3) Defines the target dimension embeddings will be reduced to   show_algo_select bool True Show selector for Manifold and Matrix Decomposition Algorithms   show_embed_select bool True Show selector for Embedding Selection   show_color_select bool True Show selector for coloring plots   MAX_DISPLAY_NUM int 100 Cap maximum number of Tokens displayed   display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more.   set_wide_layout_CSS bool True Whether to inject custom CSS or not.   num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes.   key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn   additional_classifiers_for_coloring List[str] [&#39;pos&#39;, &#39;sentiment.imdb&#39;] List of additional NLP references to load for generating hue colors   show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models available in 1 click   model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info   show_logo bool True Show logo   display_infos bool False Display additional information about ISO codes and the NLP namespace structure.   n_jobs Optional[int] 3 False How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. Larger Example showcasing more dimension reduction techniques on a larger corpus : function pipe.viz_streamlit_sentence_embed_manifold Visualize Sentence Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 12 Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms . Additionally, you can color the lower dimensional points with a label that has been previously assigned to the text by specifying a list of nlp references in the additional_classifiers_for_coloring parameter. You can also select additional classifiers via the GUI. Reduces Dimensionality of high dimensional Sentence Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 100+ Sentence Embedding models Color points by classifying with any of the 100+ Document Classifiers Gemerates NUM-DIMENSIONS * NUM-EMBEDDINGS * NUM-DIMENSION-REDUCTION-ALGOS plots nlp.load(&#39;embed_sentence.bert&#39;).viz_streamlit_sentence_embed_manifold([&#39;text1&#39;, &#39;text2tdo&#39;]) function parameters pipe.viz_streamlit_sentence_embed_manifold Argument Type Default Description   default_texts List[str] (“Donald Trump likes to party!”, “Angela Merkel likes to party!”, ‘Peter HATES TO PARTTY!!!! :(‘) List of strings to apply classifiers, embeddings, and manifolds to.   text Optional[str] &#39;Billy likes to swim&#39; Text to predict classes for.   sub_title Optional[str] “Apply any of the 11 Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Sentence Embeddings to 1-D, 2-D and 3-D “ Sub title of the Streamlit app   default_algos_to_apply List[str] [&quot;TSNE&quot;, &quot;PCA&quot;] A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;,   target_dimensions List[int] (1,2,3) Defines the target dimension embeddings will be reduced to   show_algo_select bool True Show selector for Manifold and Matrix Decomposition Algorithms   show_embed_select bool True Show selector for Embedding Selection   show_color_select bool True Show selector for coloring plots   display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more.   set_wide_layout_CSS bool True Whether to inject custom CSS or not.   num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes.   key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn   additional_classifiers_for_coloring List[str] [&#39;sentiment.imdb&#39;] List of additional NLP references to load for generting hue colors   show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click   model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info   show_logo bool True Show logo   display_infos bool False Display additional information about ISO codes and the NLP namespace structure.   n_jobs Optional[int] 3 How many cores to use for paralleling when using Sklearn Dimension Reduction algorithms.   Streamlit Entity Manifold visualization function pipe.viz_streamlit_entity_embed_manifold Visualize recognized entities by NER models via their Entity Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 10+ Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms . You can pick additional NER models and compare them via the GUI dropdown on the left. Reduces Dimensionality of high dimensional Entity Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 330+ Named Entity Recognizer models Generates NUM-DIMENSIONS * NUM-NER-MODELS * NUM-DIMENSION-REDUCTION-ALGOS plots nlp.load(&#39;ner&#39;).viz_streamlit_sentence_embed_manifold([&#39;Hello From John Snow Labs&#39;, &#39;Peter loves to visit New York&#39;]) function parameters pipe.viz_streamlit_sentence_embed_manifold Argument Type Default Description   default_texts List[str] “Donald Trump likes to visit New York”, “Angela Merkel likes to visit Berlin!”, ‘Peter hates visiting Paris’) List of strings to apply classifiers, embeddings, and manifolds to.   title str &#39;NLU ❤️ Streamlit - Prototype your NLP startup in 0 lines of code🚀&#39; Title of the Streamlit app   sub_title Optional[str] “Apply any of the 10+ Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Entity Embeddings to 1-D, 2-D and 3-D “ Sub title of the Streamlit app   default_algos_to_apply List[str] [&quot;TSNE&quot;, &quot;PCA&quot;] A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;,   target_dimensions List[int] (1,2,3) Defines the target dimension embeddings will be reduced to   show_algo_select bool True Show selector for Manifold and Matrix Decomposition Algorithms   set_wide_layout_CSS bool True Whether to inject custom CSS or not.   num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrices.   key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn   show_logo bool True Show logo   display_infos bool False Display additional information about ISO codes and the NLP namespace structure.   n_jobs Optional[int] 3 False How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. Supported Manifold Algorithms for Word, Sentence, and Entity Embeddings TSNE ISOMAP LLE Spectral Embedding MDS Supported Matrix Decomposition Algorithms for Word, Sentence and Entity Embeddings PCA Truncated SVD aka LSA DictionaryLearning FactorAnalysis FastICA KernelPCA Latent Dirichlet Allocation",
    "url": "/docs/en/jsl/streamlit_viz_examples",
    "relUrl": "/docs/en/jsl/streamlit_viz_examples"
  },
  "1538": {
    "id": "1538",
    "title": "Summarize & Paraphrase - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/summarize_paraphrase",
    "relUrl": "/summarize_paraphrase"
  },
  "1539": {
    "id": "1539",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/cv/swin_for_image_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/cv/swin_for_image_classification.html"
  },
  "1540": {
    "id": "1540",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/spell_check/symmetric_delete.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/spell_check/symmetric_delete.html"
  },
  "1541": {
    "id": "1541",
    "title": "Import Documents",
    "content": "Synthetic task generation with ChatGPT With NLP Lab 5.2, you can harness the potential of synthetic documents generated by LLMs such as ChatGPT. This integration allows you to easily create diverse and customizable synthetic text for your annotation tasks, enabling you to balance any entity skewness in your data and to train and evaluate your models more efficiently. NLP Labs offers seamless integration with ChatGPT, enabling on-the-fly text generation. Additionally, NLP Labs provides the flexibility to manage multiple service providers key pairs for robust and flexible integration. These service providers can be assigned to specific projects, simplifying resource management. During the integration process, Each Service Provider Key can be validated via the UI (User Interface), ensuring seamless integration. Once the service provider integration is completed, it can be utilized in projects that can benefit from the robust capabilities of this new integration. Text generation becomes straightforward and effortless. Provide a prompt adapted to your data needs (you can test it via the ChatGPT app and copy/paste it to NLP Lab when ready) to initiate the generation process and obtain the required tasks. Users can further control the results by setting the “Temperature” and the “Number of text to generate.” The “Temperature” parameter governs the “creativity” or randomness of the LLM-generated text. Higher temperature values (e.g., 0.7) yield more diverse and creative outputs, whereas lower values (e.g., 0.2) produce more deterministic and focused outputs. The NLP Lab integration delivers the generated text in a dedicated UI that allows users to review, edit, and tag it in place. After an initial verification and editing, the generated texts can be imported into the project as Tasks, serving as annotation tasks for model training. Additionally, the generated texts can be downloaded locally in CSV format, facilitating their reuse in other projects. NLP Labs will soon support integration with additional service providers, further empowering our users with more powerful capabilities for even more efficient and robust model generation.",
    "url": "/docs/en/alab/synthetic_task",
    "relUrl": "/docs/en/alab/synthetic_task"
  },
  "1542": {
    "id": "1542",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/seq2seq/t5_transformer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/seq2seq/t5_transformer.html"
  },
  "1543": {
    "id": "1543",
    "title": "Enterprise Spark NLP",
    "content": "{% include programmingLanguageSelectScalaPythonNLU.html %} {% include programmingLanguageSelectPythons.html %} ... pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;sentence&quot;]) .setOutputCol(&quot;pos&quot;) pos_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, pos]) light_pipeline = LightPipeline(pos_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))) result = light_pipeline.fullAnnotate(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) ... pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;sentence&quot;]) .setOutputCol(&quot;pos&quot;) pos_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, pos]) light_pipeline = LightPipeline(pos_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))) result = light_pipeline.fullAnnotate(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) val pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;token&quot;,&quot;sentence&quot;) .setOutputCol(&quot;pos&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, pos)) val data = Seq(&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) import nlu nlu.load(&quot;en.pos.clinical&quot;).predict(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;)",
    "url": "/docs/en/tab_example",
    "relUrl": "/docs/en/tab_example"
  },
  "1544": {
    "id": "1544",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/table_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/table_assembler.html"
  },
  "1545": {
    "id": "1545",
    "title": "Audio",
    "content": "The audio template is split into three parts: audio classification, emotion segmentation, and transcription. To play the audio, you need an Audio tag which requires a name and a value parameter. Audio Classification Suppose you have a sample JSON which contains some audio that you wish to classify (This input is set as default when you click on the template in NLP Lab): { &quot;audio&quot;: &quot;/static/samples/game.wav&quot;, &quot;title&quot;: &quot;MyTestTitle&quot; } The configuration for classification task can look as shown below. The preview should look as shown below. Emotion Segmentation This is a labeling task, and requires the Label tags to assign variables. The configuration is very straightforward, as shown below. Audio Transcription The transcription task is further divided into two parts - either by transcription per region or transcripting whole audio. If you are transcripting per region then it will become both labeling and transcription task. For this case the configuration would look as shown below. As shown in the image above, audio transcription requires a TextArea tag to enable a text box. The parameters name and toName are mandatory. For transcription of whole audio, the Label tags from the above image will disappear.",
    "url": "/docs/en/alab/tags_audio",
    "relUrl": "/docs/en/alab/tags_audio"
  },
  "1546": {
    "id": "1546",
    "title": "Image",
    "content": "The Image tag shows an image on the page. Use it for all image annotation tasks to display an image on the labeling interface. The name and value parameters in the Image tag are mandatory. Suppose you have an image sample in a JSON file as shown. { &quot;image&quot;: &quot;/static/samples/sample.jpg&quot;, &quot;title&quot;: &quot;MyTestTitle&quot; } There are many templates within image annotation to choose from. Visual NER and Image classification are the most used among all. Image Classification This task mainly uses the Image and Choices tags. You can optionally provide headers to the choices using the Headers tag. Visual NER Labeling To label entities in an image, you need to create rectangular labels spanning across the entity to be labeled. To enable this, you have to use RectangleLabels tag that creates labeled rectangles.They are used to apply labels to bounding box semantic segmentation tasks. The name and toName parameters are mandatory. The zoom and zoomControl parameters in the Image tag enable you too zoom in or out the image.",
    "url": "/docs/en/alab/tags_image",
    "relUrl": "/docs/en/alab/tags_image"
  },
  "1547": {
    "id": "1547",
    "title": "Overview",
    "content": "NLP Lab enables the utilization of XML-like tags to configure the labeling interface. NLP Lab contains three distinct tag types for labeling management: Object tags serve for data types, presenting labeled elements within a task, which can be labeled as video, audio, HTML, images, PDF, and text. Control tags facilitate the annotation of objects. For instance, labels are employed in semantic and named entity tasks, and choices for classification tasks inside NLP Lab. Visual tags allow for changes to the visual elements of the labelling interface, giving control over the presentation of particular labeling choices or the presence of a header. Custom Labeling Configuration A name parameter is required for each Control and Object tag. Every Control tag also needs a toName parameter that matches the name parameter of the object tag in the configuration. Suppose you wish to assign labels to text for a Named Entity Recognition task. In that case, you could use the following labeling configuration: In this case, text is annotated using the Label tags in combination with the Text tag. Multiple control and Object tags may be used in the same configuration by creating linkages between them using names. Variables All Object tags, as well as some Control and Visual tags, support variables within their arguments. Using variables enables for the creation of a labeling configuration, while also allowing for the control of given information on the labeling interface based on data in a given task. To use a variable, define it with the value parameter of a tag and specify it using the $ sign and the name of the field that you want to reference. For example, if you have a sample task which contains some partial JSON, then the configuration should look something like this: When you look on the preview window, you can see the header set on top of the labels/choices.",
    "url": "/docs/en/alab/tags_overview",
    "relUrl": "/docs/en/alab/tags_overview"
  },
  "1548": {
    "id": "1548",
    "title": "PDF",
    "content": "You can rate PDF in NLP Lab. The HyperText tag shows the PDF, when you specify “pdf” as the name parameter and pdf header of the JSON in the value parameter. To rate the article, you also need the Rating tag. The Rating tag adds a rating selection to the labeling interface. A simple example configuration is shown below.",
    "url": "/docs/en/alab/tags_pdf",
    "relUrl": "/docs/en/alab/tags_pdf"
  },
  "1549": {
    "id": "1549",
    "title": "Text",
    "content": "The Text tag shows text that can be labeled. The text template is divided into the following segments: Information extraction: Includes NER and extracting relations among entities. Classification: Includes text classification and multi-class classification. Text summarization. Information Extraction For simple NER related tasks, the configuration just needs the Text and Labels tags. The Labels tag provides a set of labels for labeling regions in your tasks. Use the Labels tag to create a set of labels that can be assigned to identified region and specify the values of labels to assign to regions. For example, you have the following JSON to label, as shown below. { &quot;text&quot;: &quot;The patient is a pleasant 17-year-old gentleman who was playing basketball today in gym. Two hours prior to presentation, he started to fall and someone stepped on his ankle and kind of twisted his right ankle and he cannot bear weight on it now. It hurts to move or bear weight. No other injuries noted. He does not think he has had injuries to his ankle in the past. He was given adderall and accutane.&quot;, &quot;title&quot;: &quot;MyTestTitle&quot; } The configuration in this case looks as shown below. The model parameter in the Label tag must be specified whenever a pre-trained model is used in the project for pre-annotation purposes. It is automatically defined when a model is chosen from Reuse Resources. For the case of relation extraction, the configuration additionally needs a Relations tag apart from Text and Labels. For the same input, the configuration would look as shown below. Classification For a classification task, the configuration needs the Text and Choices tags. For instance, you have the input JSON as shown below. The Choices tag is used to create a group of choices (a set of Choice tags), with radio buttons or checkboxes. It can be used for single or multi-class classification. { &quot;text&quot;: &quot;The patient is a pleasant 17-year-old gentleman who was playing basketball today in gym. Two hours prior to presentation, he started to fall and someone stepped on his ankle and kind of twisted his right ankle and he cannot bear weight on it now. It hurts to move or bear weight. No other injuries noted. He does not think he has had injuries to his ankle in the past. He was given adderall and accutane.&quot;, &quot;title&quot;: &quot;MyTestTitle&quot; } For simple single-class classification, the configuration is shown below. In the case of multi-class classification, the configuration would look as shown below. Text summarization For a simple text summarization, the configuration just needs the Text and TextArea tags. The TextArea tag is used to display a text area for the user input. It is mainly used for transcription, paraphrasing, or captioning task.",
    "url": "/docs/en/alab/tags_text",
    "relUrl": "/docs/en/alab/tags_text"
  },
  "1550": {
    "id": "1550",
    "title": "Video",
    "content": "The video template is split into two parts: video classification and video timeline segmentation. To play a video, you need a HyperText tag which requires the name parameter and value parameter. Video Classification Since it is a classification type, the configuration should use Choice tags to assign variables. For example, say that you have a sample task and you wish to classify that video as awesome or groove, inscribed in a JSON like this: { &quot;title&quot;: &quot;MyTestTitle&quot;, &quot;video&quot;: &quot;&lt;video src=&#39;/static/samples/opossum_snow.mp4&#39; width=100% controls&gt;&quot; } The simplest configuration in this case will look as shown below. Video Timeline Segmentation This is a labeling task, and thus requires the use of Label tags to assign variables. For example, you have a sample task with a video and it’s corresponding audio, and you wish to label segments. The sample JSON looks like this: { &quot;title&quot;: &quot;MyTestTitle&quot;, &quot;video&quot;: &quot;&lt;video src=&#39;/static/samples/opossum_snow.mp4&#39; width=100% controls&gt;&quot;, &quot;videoSource&quot;: &quot;/static/samples/game.wav&quot; } The configuration in this case is shown below. The background parameter refers to the color of the label. From above, you could see that the labels will work on the audio encryption since the name parameter in the AudioPlus tag is the same as the toName parameter in the Labels tag.",
    "url": "/docs/en/alab/tags_video",
    "relUrl": "/docs/en/alab/tags_video"
  },
  "1551": {
    "id": "1551",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/tapas_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/tapas_for_question_answering.html"
  },
  "1552": {
    "id": "1552",
    "title": "Tasks",
    "content": "The Tasks screen shows a list of all documents that have been imported into the current project. Under each task you can see meta data about the task: the time of import, the user who imported the task and the annotators and reviewers assigned to the task. Task Assignment Project Owners/Managers can assign tasks to annotator(s) and reviewer(s) in order to better plan/distribute project work. Annotators and Reviewers can only view tasks that are assigned to them which means there is no chance of accidental work overlap. For assigning a task to an annotator, from the task page select one or more tasks and from the Assign dropdown choose an annotator. You can only assign a task to annotators that have already been added to the project team. For adding an annotator to the project team, select your project and navigate to the Setup &gt; Team menu item. On the Add Team Member page, search for the user you want to add, select the role you want to assign to him/her and click on Add To Team button. Project Owners can also be explicitly assigned as annotators and/or reviewers for tasks. It is useful when working in a small team and when the Project Owners are also involved in the annotation process. A new option Only Assigned checkbox is now available on the labeling page that allows Project Owners to filter the tasks explicitly assigned to them when clicking the Next button. NOTE: When upgrading from an older version of the Annotation Lab, the annotators will no longer have access to the tasks they worked on unless they are assigned to those explicitely by the admin user who created the project. Once they are assigned, they can resume work and no information is lost. Task Status At high level, each task can have one of the following statuses: Incomplete, when none of the assigned annotators has started working on the task. In Progress, when at least one of the assigned annotators has submitted at least one completion for this task. Submitted, when all annotators which were assigned to the task have submitted a completion which is set as ground truth (starred). Reviewed, in the case there is a reviewer assigned to the task, and the reviewer has reviewed and accepted the submited completion. To Correct, in the case the assigned reviewer has rejected the completion created by the Annotator. The status of a task varies according to the type of account the logged in user has (his/her visibility over the project) and according to the tasks that have been assigned to him/her. For Project Owner, Manager and Reviewer On the Analytics page and Tasks page, the Project Owner/Manager/Reviewer will see the general overview of the projects which will take into consideration the task level statuses as follows: Incomplete - Assigned annotators have not started working on this task In Progress - At least one annotator still has not starred (marked as ground truth) one submitted completion Submitted - All annotators that are assigned to the task have starred (marked as ground truth) one submitted completion Reviewed - Reviewer has approved all starred submitted completions for the task For Annotators On the Annotator’s Task page, the task status will be shown with regards to the context of the logged-in Annotator’s work. As such, if the same task is assigned to two annotators then: if annotator1 is still working and not submitted the task, then he/she will see task status as In-progress if annotator2 submits the task from his/her side then he/she will see task status as Submitted The following statuses are available on the Annotator’s view. Incomplete – Current logged-in annotator has not started working on this task. In Progress - At least one saved/submitted completions exist, but there is no starred submitted completion. Submitted - Annotator has at least one starred submitted completion. Reviewed - Reviewer has approved the starred submitted completion for the task. To Correct - Reviewer has rejected the submitted work. In this case, the star is removed from the reviewed completion. The annotator should start working on the task and resubmit. Note: The status of a task is maintained/available only for the annotators assigned to the task. When multiple Annotators are assigned to a task, the reviewer will see the task as submitted when all annotators submit and star their completions. Otherwise, if one of the assigned Annotators has not submitted or has not starred one completion, then the Reviewer will see the task as In Progress. Task Filters As normally annotation projects involve a large number of tasks, the Task page includes filtering and sorting options which will help the user identify the tasks he/she needs faster. Tasks can be sorted by time of import ascending or descending. Tasks can be filtered by the assigned tags, by the user who imported the task and by the status. There is also a search functionality which will identify the tasks having a given string on their name. The number of tasks visible on the screeen is customizable by selecting the predefined values from the Tasks per page drop-down. From version 4.10 onwards, filtering tasks has been updated to allow users to select multiple tags from the Tags dropdown. This allows users to filter tasks based on multiple tags. Additionally, the same improved filter behaviour can be found in project page too. This provides users with increased flexibility and efficiency in filtering tasks based on multiple tags, thereby improving task and project management and facilitating a more streamlined workflow. Task Search by Text, Label and Choice Annotation Lab offers advanced search features that help users identify the tasks they need based on the text or based on the annotations defined so far. Currently supported search queries are: text: patient -&gt; returns all tasks which contain the string “patient”; label: ABC -&gt; returns all tasks that have at least one completion containing a chunk with label ABC; label: ABC=DEF -&gt; returns all tasks that have at least one completion containing the text DEF labeled as ABC; choice: Sport -&gt; returns all tasks that have at least one completion which classified the task as Sport; choice: Sport,Politics -&gt; returns all tasks that have at least one completion containing multiple choices Sport and Politics. Search functionality is case insensitive, thus the following queries label: ABC=DEF , label: Abc=Def or label: abc=def are considered equivalent. Example: Consider a project with 3 tasks which are annotated as below: Search-query “label:LOC” will list as results Task 1 and Task 3. Search-query “label:WORK_OF_ART” will list as result Task 1 and Task 2. Search-query “label:PERSON=Leonardo” will list as result Task 1. Comments Comments can be added to each task by any team member. This is done by clicking the View comments link present on the rightmost side of each Task in the Tasks List page. It is important to notice that these comments are visible to everyone who can view the particular task.",
    "url": "/docs/en/alab/tasks",
    "relUrl": "/docs/en/alab/tasks"
  },
  "1553": {
    "id": "1553",
    "title": "Terminology",
    "content": "Concept Definition Project A project in Annotation Lab resembles a set of tasks that need to be annotated and/or reviewed by users in order to extract structured data and/or to train a DL model.Think of it as a factory assembly line for producing labels. For jumpstarting annotations on a project preannotations generated by existing models and/or rules can be used. Project configuration Specifies the type of documents that will be annotated as well as the labels, classes and relations which will be used for annotation. A project configuration can also reuse existing labels, classes and relations from pre-trained models or rules. Model In the context of the Annotation Lab use, the term model refers to a DL model build using John Snow Labs NLP libraries. Predictions Annotations automatically generated by Spark NLP models or user defined Spark NLP rules. Completions A series of annotations manually created or copied from automatic predictions and edited/validated by human annotators. Task A document that needs to be annotated by an annotator with or without the use of preannotation.",
    "url": "/docs/en/alab/terminology",
    "relUrl": "/docs/en/alab/terminology"
  },
  "1554": {
    "id": "1554",
    "title": "Test Project Configuration",
    "content": "Annotation Lab offer testing features for projects that reuse existing models/rules. In other words, if a project’s configuration references one or several (pre)trained models/rules it is possible to check how efficient those are when applied on custom data. The Test Configuration feature is available on the Train page, accessible from the Project Menu. During the training, a progress bar is shown on the top of the train page to show the status of the testing. Note This feature is available for Project Owners or Managers. The Test Configuration feature applies to project tasks with status submitted or reviewed, and which are tagged as Test. After the evaluaton is completed, the resulting logs can be downloaded to view the performance metrics. Note: Model evaluation can only be triggered in the presence of a valid Healthcare, Finance or/and Legal NLP license.",
    "url": "/docs/en/alab/test_project_configuration",
    "relUrl": "/docs/en/alab/test_project_configuration"
  },
  "1555": {
    "id": "1555",
    "title": "Release Testing Utilities",
    "content": "Utilities for Testing Models &amp; Modelshub Code Snippets You can use the John Snow Labs library to automatically test 10000+ models and 100+ Notebooks in 1 line of code within a small machine like a single Google Colab Instance and generate very handy error reports of potentially broken Models, Notebooks or Models hub Markdown Snippets. You can test the following things with the test_markdown() function : A local Models Hub Markdown snippet via path. a remote Models Hub Markdown snippet via URL. a local folder of Models Hub Markdown files. Generates report a list of local paths or urls to .md files. Generates a report Test-Report Pandas Dataframe has the columns: Report Column Description test_script is the generated script for testing stderr Error logs of process ran. Print this to easily read stdout Standard Print logs of process ran. Print this to easily read success True if script ran successfully from top to bottom notebook The Source notebook for testing Test a Local Models Hub Markdown Snippet from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;path/to/my/file.md&#39;) Test a Remote Models Hub Markdown Snippet from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;https://nlp.johnsnowlabs.com/2022/08/31/legpipe_deid_en.html&#39;) Test a Folder with Models Hub Markdown Snippets This will scan the folder for all files ending with .md , test them and generate a report from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;my/markdown/folder&#39;) Test a List of Markdown References Can be mixed with Urls and paths, will generate a report from johnsnowlabs.utils.notebooks import test_ipynb md_to_test = [&#39;legpipe_deid_en.html&#39;, &#39;path/to/local/markdown_snippet.md&#39;,] test_markdown(md_to_test) Utilities for Testing Notebooks You can use the John Snow Labs library to automatically test 10000+ models and 100+ Notebooks in 1 line of code within a small machine like a single Google Colab Instance and generate very handy error reports of potentially broken Models, Notebooks or Models hub Markdown Snippets. You can test the following things with the test_ipynb() function : A local .ipynb file a remote .ipynb URL, point to RAW githubuser content URL of the file when using git. a local folder of ipynb files, generates report a list of local paths or urls to .ipynb files. Generates a Report The entire John Snow Labs Workshop Certification Folder Generates a Report A sub-folder of the John Snow Labs Workshop Certification Folder , i.e. only OCR or only Legal. Generates a Report The generated Test-Report Pandas Dataframe has the columns: Report Column Description test_script is the generated script for testing. If you think the notebook should not crash, check the file, there could be a generation error. stderr Error logs of process ran. Print this to easily read stdout Standard Print logs of process ran. Print this to easily read success True if script ran successfully from top to bottom notebook The Source notebook for testing Test a Local Notebook from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;path/to/local/notebook.ipynb&#39;) Test a Remote Notebook from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/5.Spark_OCR.ipynb&#39;,) Test a Folder with Notebooks This will scan the folder for all files ending with .ipynb , test them and generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;my/notebook/folder&#39;) Test a List of Notebook References Can be mixed with Urls and paths, will generate a report from johnsnowlabs.utils.notebooks import test_ipynb nb_to_test = [ &#39;https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/5.Spark_OCR.ipynb&#39;, &#39;path/to/local/notebook.ipynb&#39;,] test_ipynb(nb_to_test) Run All Certification Notebooks Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP&#39;) Run Finance Certification Notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-FIN&#39;) Run Legal notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-LEG&#39;) Run Medical notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-MED&#39;) Run Open Source notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-OS&#39;)",
    "url": "/docs/en/jsl/testing-utils",
    "relUrl": "/docs/en/jsl/testing-utils"
  },
  "1556": {
    "id": "1556",
    "title": "Utilities for Testing Models & Modelshub Code Snippets",
    "content": "You can use the John Snow Labs library to automatically test 10000+ models and 100+ Notebooks in 1 line of code within a small machine like a single Google Colab Instance and generate very handy error reports of potentially broken Models, Notebooks or Models hub Markdown Snippets. You can test the following things with the test_markdown() function : A local Models Hub Markdown snippet via path. a remote Models Hub Markdown snippet via URL. a local folder of Models Hub Markdown files. Generates report a list of local paths or urls to .md files. Generates a report Test-Report Pandas Dataframe has the columns: Report Column Description test_script is the generated script for testing stderr Error logs of process ran. Print this to easily read stdout Standard Print logs of process ran. Print this to easily read success True if script ran successfully from top to bottom notebook The Source notebook for testing Test a Local Models Hub Markdown Snippet from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;path/to/my/file.md&#39;) Test a Remote Models Hub Markdown Snippet from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;https://nlp.johnsnowlabs.com/2022/08/31/legpipe_deid_en.html&#39;) Test a Folder with Models Hub Markdown Snippets This will scan the folder for all files ending with .md , test them and generate a report from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;my/markdown/folder&#39;) Test a List of Markdown References Can be mixed with Urls and paths, will generate a report from johnsnowlabs.utils.notebooks import test_ipynb md_to_test = [&#39;legpipe_deid_en.html&#39;, &#39;path/to/local/markdown_snippet.md&#39;,] test_markdown(md_to_test)",
    "url": "/docs/en/jsl/testing-utils-modelshub",
    "relUrl": "/docs/en/jsl/testing-utils-modelshub"
  },
  "1557": {
    "id": "1557",
    "title": "Utilities for Testing Notebooks",
    "content": "You can use the John Snow Labs library to automatically test 10000+ models and 100+ Notebooks in 1 line of code within a small machine like a single Google Colab Instance and generate very handy error reports of potentially broken Models, Notebooks or Models hub Markdown Snippets. You can test the following things with the test_ipynb() function : A local .ipynb file a remote .ipynb URL, point to RAW githubuser content URL of the file when using git. a local folder of ipynb files, generates report a list of local paths or urls to .ipynb files. Generates a Report The entire John Snow Labs Workshop Certification Folder Generates a Report A sub-folder of the John Snow Labs Workshop Certification Folder , i.e. only OCR or only Legal. Generates a Report The generated Test-Report Pandas Dataframe has the columns: Report Column Description test_script is the generated script for testing. If you think the notebook should not crash, check the file, there could be a generation error. stderr Error logs of process ran. Print this to easily read stdout Standard Print logs of process ran. Print this to easily read success True if script ran successfully from top to bottom notebook The Source notebook for testing Test a Local Notebook from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;path/to/local/notebook.ipynb&#39;) Test a Remote Notebook from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/5.Spark_OCR.ipynb&#39;,) Test a Folder with Notebooks This will scan the folder for all files ending with .ipynb , test them and generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;my/notebook/folder&#39;) Test a List of Notebook References Can be mixed with Urls and paths, will generate a report from johnsnowlabs.utils.notebooks import test_ipynb nb_to_test = [ &#39;https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/5.Spark_OCR.ipynb&#39;, &#39;path/to/local/notebook.ipynb&#39;,] test_ipynb(nb_to_test) Run All Certification Notebooks Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP&#39;) Run Finance Certification Notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-FIN&#39;) Run Legal notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-LEG&#39;) Run Medical notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-MED&#39;) Run Open Source notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-OS&#39;)",
    "url": "/docs/en/jsl/testing-utils-notebooks",
    "relUrl": "/docs/en/jsl/testing-utils-notebooks"
  },
  "1558": {
    "id": "1558",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/text_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/text_matcher.html"
  },
  "1559": {
    "id": "1559",
    "title": "Text Summarization - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/text_summarization",
    "relUrl": "/text_summarization"
  },
  "1560": {
    "id": "1560",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/tf_ner_dl_graph_builder.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/tf_ner_dl_graph_builder.html"
  },
  "1561": {
    "id": "1561",
    "title": "Third Party Projects",
    "content": "",
    "url": "/docs/en/third-party-projects",
    "relUrl": "/docs/en/third-party-projects"
  },
  "1562": {
    "id": "1562",
    "title": "Annotation Settings",
    "content": "Optimize view for large taxonomy For projects that include a large number of labels, we have created a way to optimize the taxonomy display so that users can quickly find the label they are searching for. To obtain the above display please use the following configuration: &lt;View&gt; &lt;Filter name=&quot;fl&quot; toName=&quot;label&quot; hotkey=&quot;shift+f&quot; minlength=&quot;1&quot; /&gt; &lt;View style=&quot; background:white; height: 100px; overflow-y:scroll; resize:vertical; position:sticky; top:0;&quot; &gt; &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;Person&quot; background=&quot;red&quot;&gt;&lt;/Label&gt; &lt;Label value=&quot;Organization&quot; background=&quot;darkorange&quot;&gt;&lt;/Label&gt; &lt;/Labels&gt; &lt;/View&gt; &lt;View style=&quot; resize:vertical; margin-top:10px; max-height:400px; overflow-y:scroll;&quot; &gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;&gt;&lt;/Text&gt; &lt;/View&gt; &lt;/View&gt;",
    "url": "/docs/en/alab/tips",
    "relUrl": "/docs/en/alab/tips"
  },
  "1563": {
    "id": "1563",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/token2_chunk.html",
    "relUrl": "/api/python/modules/sparknlp/base/token2_chunk.html"
  },
  "1564": {
    "id": "1564",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/token_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/token_assembler.html"
  },
  "1565": {
    "id": "1565",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/token/tokenizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/token/tokenizer.html"
  },
  "1566": {
    "id": "1566",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/training.html",
    "relUrl": "/api/python/user_guide/training.html"
  },
  "1567": {
    "id": "1567",
    "title": "Training Models with the fit() function",
    "content": "You can fit load a trainable nlp pipeline via nlp.load(&#39;train.&lt;model&gt;&#39;) Binary Text Classifier Training Sentiment classification training demo To train a Sentiment classifier model, you must pass a dataframe with a text column and a y column for the label. Uses a Deep Neural Network built in Tensorflow. By default Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings. fitted_pipe = nlp.load(&#39;train.sentiment&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) To train on custom embeddings you can specify some sentence embeddings before the training reference which will be used instead of the default USE embeddings. #Train Classifier on BERT sentence embeddings fitted_pipe = nlp.load(&#39;embed_sentence.bert train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) #Train Classifier on ELECTRA sentence embeddings fitted_pipe = nlp.load(&#39;embed_sentence.electra train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Multi Class Text Classifier Training Multi Class Text Classifier Training Demo To train the Multi Class text classifier model, you must pass a dataframe with a text column and a y column for the label. By default Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings. fitted_pipe = nlp.load(&#39;train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) To train on custom embeddings you can specify some sentence embeddings before the training reference which will be used instead of the default USE embeddings. #Train on BERT sentence emebddings fitted_pipe = nlp.load(&#39;embed_sentence.bert train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Multi Label Classifier training Train Multi Label Classifier on E2E dataset Train Multi Label Classifier on Stack Overflow Question Tags dataset This model can predict multiple labels for one sentence. Uses a Bidirectional GRU with Convolution model that we have built inside TensorFlow and supports up to 100 classes. To train the Multi Class text classifier model, you must pass a dataframe with a text column and a y column for the label. The y label must be a string column where each label is seperated with a seperator. By default, , is assumed as line seperator. If your dataset is using a different label seperator, you must configure the label_seperator parameter while calling the fit() method. By default, Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings for training. fitted_pipe = nlp.load(&#39;train.multi_classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) To train on custom embeddings you can specify some sentence embeddings before the training reference which will be used instead of the default USE embeddings. #Train on BERT sentence embeddings fitted_pipe = nlp.load(&#39;embed_sentence.bert train.multi_classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Configure a custom line seperator #Use ; as label seperator fitted_pipe = nlp.load(&#39;embed_sentence.electra train.multi_classifier&#39;).fit(train_df, label_seperator=&#39;;&#39;) preds = fitted_pipe.predict(train_df) Part of Speech (POS) Training Your dataset must be in the form of Universal Dependencies. You must configure the dataset_path in the fit() method to point to the universal dependencies you wish to train on. You can configure the delimiter via the label_seperator parameter [POS training demo]](https://colab.research.google.com/drive/1CZqHQmrxkDf7y3rQHVjO-97tCnpUXu_3?usp=sharing) fitted_pipe = nlp.load(&#39;train.pos&#39;).fit(dataset_path=train_path, label_seperator=&#39;_&#39;) preds = fitted_pipe.predict(train_df) Named Entity Recognizer (NER) Training NER training demo You can train your own custom NER model with an CoNLL 20003 IOB formatted dataset. By default, Glove 100d Token Embeddings are used as features for the classifier. train_path = &#39;/content/eng.train&#39; fitted_pipe = nlp.load(&#39;train.ner&#39;).fit(dataset_path=train_path) If a nlp reference to a Token Embeddings model is added before the train reference, that Token Embedding will be used when training the NER model. # Train on BERT embeddigns train_path = &#39;/content/eng.train&#39; fitted_pipe = nlp.load(&#39;bert train.ner&#39;).fit(dataset_path=train_path) Chunk Entity Resolver Training Chunk Entity Resolver Training Tutorial Notebook Named Entities are sub pieces in textual data which are labled with classes. These classes and strings are still ambious though and it is not possible to group semantically identically entities withouth any definition of terminology. With the Chunk Resolver you can train a state of the art deep learning architecture to map entities to their unique terminological representation. Train a chunk resolver on a dataset with columns named y , _y and text. y is a label, _y is an extra identifier label, text is the raw text import pandas as pd dataset = pd.DataFrame({ &#39;text&#39;: [&#39;The Tesla company is good to invest is&#39;, &#39;TSLA is good to invest&#39;,&#39;TESLA INC. we should buy&#39;,&#39;PUT ALL MONEY IN TSLA inc!!&#39;], &#39;y&#39;: [&#39;23&#39;,&#39;23&#39;,&#39;23&#39;,&#39;23&#39;] &#39;_y&#39;: [&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;], }) trainable_pipe = nlp.load(&#39;train.resolve_chunks&#39;) fitted_pipe = trainable_pipe.fit(dataset) res = fitted_pipe.predict(dataset) fitted_pipe.predict([&quot;Peter told me to buy Tesla &quot;, &#39;I have money to loose, is TSLA a good option?&#39;]) entity_resolution_confidence entity_resolution_code entity_resolution document ‘1.0000’ ‘23] ‘TESLA’ Peter told me to buy Tesla ‘1.0000’ ‘23] ‘TESLA’ I have money to loose, is TSLA a good option? Train with default glove embeddings untrained_chunk_resolver = nlp.load(&#39;train.resolve_chunks&#39;) trained_chunk_resolver = untrained_chunk_resolver.fit(df) trained_chunk_resolver.predict(df) Train with custom embeddings # Use Healthcare Embeddings trainable_pipe = nlp.load(&#39;en.embed.glove.healthcare_100d train.resolve_chunks&#39;) trained_chunk_resolver = untrained_chunk_resolver.fit(df) trained_chunk_resolver.predict(df) Rule based NER with Context Matcher Rule based NER with context matching tutorial notebook Define a rule based NER algorithm by providing Regex Patterns and resolution mappings. The confidence value is computed using a heuristic approach based on how many matches it has. A dictionary can be provided with setDictionary to map extracted entities to a unified representation. The first column of the dictionary file should be the representation with following columns the possible matches. import json # Define helper functions to write NER rules to file &quot;&quot;&quot;Generate json with dict contexts at target path&quot;&quot;&quot; def dump_dict_to_json_file(dict, path): with open(path, &#39;w&#39;) as f: json.dump(dict, f) &quot;&quot;&quot;Dump raw text file &quot;&quot;&quot; def dump_file_to_csv(data,path): with open(path, &#39;w&#39;) as f:f.write(data) sample_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting. Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Twenty days ago. Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . At birth the typical boy is growing slightly faster than the typical girl, but the velocities become equal at about seven months, and then the girl grows faster until four years. From then until adolescence no differences in velocity can be detected. 21-02-2020 21/04/2020 &quot;&quot;&quot; # Define Gender NER matching rules gender_rules = { &quot;entity&quot;: &quot;Gender&quot;, &quot;ruleScope&quot;: &quot;sentence&quot;, &quot;completeMatchRegex&quot;: &quot;true&quot; } # Define dict data in csv format gender_data = &#39;&#39;&#39;male,man,male,boy,gentleman,he,him female,woman,female,girl,lady,old-lady,she,her neutral,neutral&#39;&#39;&#39; # Dump configs to file dump_dict_to_json_file(gender_data, &#39;gender.csv&#39;) dump_dict_to_json_file(gender_rules, &#39;gender.json&#39;) gender_NER_pipe = nlp.load(&#39;match.context&#39;) gender_NER_pipe.print_info() gender_NER_pipe[&#39;context_matcher&#39;].setJsonPath(&#39;gender.json&#39;) gender_NER_pipe[&#39;context_matcher&#39;].setDictionary(&#39;gender.csv&#39;, options={&quot;delimiter&quot;:&quot;,&quot;}) gender_NER_pipe.predict(sample_text) context_match context_match_confidence female 0.13 she 0.13 she 0.13 she 0.13 she 0.13 boy 0.13 girl 0.13 girl 0.13 Context Matcher Parameters You can define the following parameters in your rules.json file to define the entities to be matched Parameter Type Description entity str The name of this rule regex Optional[str] Regex Pattern to extract candidates contextLength Optional[int] defines the maximum distance a prefix and suffix words can be away from the word to match,whereas context are words that must be immediately after or before the word to match prefix Optional[List[str]] Words preceding the regex match, that are at most contextLength characters aways regexPrefix Optional[str] RegexPattern of words preceding the regex match, that are at most contextLength characters aways suffix Optional[List[str]] Words following the regex match, that are at most contextLength characters aways regexSuffix Optional[str] RegexPattern of words following the regex match, that are at most contextLength distance aways context Optional[List[str]] list of words that must be immediatly before/after a match contextException Optional[List[str]] ?? List of words that may not be immediatly before/after a match exceptionDistance Optional[int] Distance exceptions must be away from a match regexContextException Optional[str] Regex Pattern of exceptions that may not be within exceptionDistance range of the match matchScope Optional[str] Either token or sub-token to match on character basis completeMatchRegex Optional[str] Wether to use complete or partial matching, either &quot;true&quot; or &quot;false&quot; ruleScope str currently only sentence supported Saving a pipeline to disk train_path = &#39;/content/eng.train&#39; fitted_pipe = nlp.load(&#39;train.ner&#39;).fit(dataset_path=train_path) stored_model_path = &#39;./models/classifier_dl_trained&#39; fitted_pipe.save(stored_model_path) Loading a pipeline from disk train_path = &#39;/content/eng.train&#39; fitted_pipe = nlp.load(&#39;train.ner&#39;).fit(dataset_path=train_path) stored_model_path = &#39;./models/classifier_dl_trained&#39; fitted_pipe.save(stored_model_path) hdd_pipe = nlp.load(path=stored_model_path) Loading a pipeline as pyspark.ml.PipelineModel import pyspark # load the NLP pipeline as pyspark pipeline pyspark_pipe = pyspark.ml.PipelineModel.load(stored_model_path) # Generate spark Df and transform it with the pyspark Pipeline s_df = spark.createDataFrame(df) pyspark_pipe.transform(s_df).show()",
    "url": "/docs/en/jsl/training",
    "relUrl": "/docs/en/jsl/training"
  },
  "1568": {
    "id": "1568",
    "title": "Training",
    "content": "Training Datasets These are classes to load common datasets to train annotators for tasks such as part-of-speech tagging, named entity recognition, spell checking and more. {% include_relative training_entries/pos.md %} {% include_relative training_entries/conll.md %} {% include_relative training_entries/conllu.md %} {% include_relative training_entries/pubtator.md %} Spell Checkers Dataset (Corpus) In order to train a Norvig or Symmetric Spell Checkers, we need to get corpus data as a spark dataframe. We can read a plain text file and transforms it to a spark dataset. Example: {% include programmingLanguageSelectScalaPython.html %} train_corpus = spark.read .text(&quot;./sherlockholmes.txt&quot;) .withColumnRenamed(&quot;value&quot;, &quot;text&quot;) val trainCorpus = spark.read .text(&quot;./sherlockholmes.txt&quot;) .select(trainCorpus.col(&quot;value&quot;).as(&quot;text&quot;)) Text Processing These are annotators that can be trained to process text for tasks such as dependency parsing, lemmatisation, part-of-speech tagging, sentence detection and word segmentation. {% include_relative training_entries/DependencyParserApproach.md %} {% include_relative training_entries/Lemmatizer.md %} {% include_relative training_entries/PerceptronApproach.md %} {% include_relative training_entries/SentenceDetectorDLApproach.md %} {% include_relative training_entries/TypedDependencyParser.md %} {% include_relative training_entries/WordSegmenterApproach.md %} Spell Checkers These are annotators that can be trained to correct text. {% include_relative training_entries/ContextSpellCheckerApproach.md %} {% include_relative training_entries/NorvigSweeting.md %} {% include_relative training_entries/SymmetricDelete.md %} Token Classification These are annotators that can be trained to recognize named entities in text. {% include_relative training_entries/NerCrfApproach.md %} {% include_relative training_entries/NerDLApproach.md %} Text Classification These are annotators that can be trained to classify text into different classes, such as sentiment. {% include_relative training_entries/ClassifierDLApproach.md %} {% include_relative training_entries/MultiClassifierDLApproach.md %} {% include_relative training_entries/SentimentDLApproach.md %} {% include_relative training_entries/ViveknSentimentApproach.md %} Text Representation These are annotators that can be trained to turn text into a numerical representation. {% include_relative training_entries/Doc2VecApproach.md %} {% include_relative training_entries/Word2VecApproach.md %} External Trainable Models These are annotators that are trained in an external library, which are then loaded into Spark NLP. {% include_relative training_entries/AlbertForTokenClassification.md %} {% include_relative training_entries/BertForSequenceClassification.md %} {% include_relative training_entries/BertForTokenClassification.md %} {% include_relative training_entries/DistilBertForSequenceClassification.md %} {% include_relative training_entries/DistilBertForTokenClassification.md %} {% include_relative training_entries/RoBertaForTokenClassification.md %} {% include_relative training_entries/XlmRoBertaForTokenClassification.md %} TensorFlow Graphs NER DL uses Char CNNs - BiLSTM - CRF Neural Network architecture. Spark NLP defines this architecture through a Tensorflow graph, which requires the following parameters: Tags Embeddings Dimension Number of Chars Spark NLP infers these values from the training dataset used in NerDLApproach annotator and tries to load the graph embedded on spark-nlp package. Currently, Spark NLP has graphs for the most common combination of tags, embeddings, and number of chars values: Tags Embeddings Dimension 10 100 10 200 10 300 10 768 10 1024 25 300 All of these graphs use an LSTM of size 128 and number of chars 100 In case, your train dataset has a different number of tags, embeddings dimension, number of chars and LSTM size combinations shown in the table above, NerDLApproach will raise an IllegalArgumentException exception during runtime with the message below: Graph [parameter] should be [value]: Could not find a suitable tensorflow graph for embeddings dim: [value] tags: [value] nChars: [value]. Check https://nlp.johnsnowlabs.com/docs/en/graph for instructions to generate the required graph. To overcome this exception message we have to follow these steps: Clone spark-nlp github repo Run python file create_models with number of tags, embeddings dimension and number of char values mentioned on your exception message error. cd spark-nlp/python/tensorflow export PYTHONPATH=lib/ner python create_models.py [number_of_tags] [embeddings_dimension] [number_of_chars] [output_path] This will generate a graph on the directory defined on `output_path argument. Retry training with NerDLApproach annotator but this time use the parameter setGraphFolder with the path of your graph. Note: Make sure that you have Python 3 and Tensorflow 1.15.0 installed on your system since create_models requires those versions to generate the graph successfully. Note: We also have a notebook in the same directory if you prefer Jupyter notebook to cerate your custom graph.",
    "url": "/docs/en/training",
    "relUrl": "/docs/en/training"
  },
  "1569": {
    "id": "1569",
    "title": "Train New Model",
    "content": "A Project Owner or a Manager can use the completed tasks (completions) from a project to train a new Spark NLP model. The training feature can be found on the train page, accessible from the Project Menu. The training process can be triggered via a three step wizard that guides users and offers useful hints. Users can also opt for a synthesis view for initiating the training of a model. During the training, a progress bar is shown to give users basic information on the status of the training process. Deploy a new training job Users can perform multiple training jobs at the same time, depending on the available resources/license(s). Users can opt to create new training jobs independently from already running training/pre-annotation/OCR jobs. If resources/licenses are available when pressing the Train Model button a new training server is launched. The running servers can be seen by visiting the Clusters page. Named Entity Recognition For training a good Named Entity Recognition (NER) model, a relevant number of annotations must exist for all labels included in the project configuration. The recommendation is to have minimum 40-50 examples for each entity. Once this requirement is met, for training a new model users need to navigate to the Train page for the current project and follow some very simple steps: Select the type of model to train - Open source/Healthcare/Finance/Legal - and the embeddings to use; Define the training parameters and the train/test data split; Optionally turn on the Active Learning feature; Click the Train Model button. When triggering the training, users are prompted to choose either to immediately deploy models or just do training. If immediate deployment is chosen, then the Labeling config is updated according to the name of the new model. Notice how the name of the original model used for preannotations is replaced with the name of the new model in the configuration below. Information on the overall training progress is shown in the page. User can get indications on the success or failure of the training as well as check the live training logs (by pressing the Show Logs button). Once the training is finished, it is possible to download the training logs by clicking on the download logs icon of the recently trained NER model which includes information like training parameters and TF graph used along with precision, recall, f1 score, etc. This information is also accessible by clicking on the benchmarking icon available on the models on the Models page. Starting from version 4.3.0, it is possible to keep track of all previous training activities executed for a project. When pressing the History button from the Train page, users are presented with a list of all trainings triggered for the current project. Each training event is characterized by the source (manual, active learning), data used for training, date of event, and status. Training logs can also be downloaded for each training event. Training parameters In Annotation Lab, for mixed projects containing multiple types of annotations in a single project like classifications, NER, and assertion status, if multiple trainings were triggered at the same time using the same system resources and Spark NLP resources, the training component could fail because of resource limitations. In order to improve the usability of the system, dropdown options can be used to choose which type of training to run next. The project Owner or Manager of a project can scroll down to Training Settings and choose the training type. The drop-down gives a list of possible training types for that particular project based on its actual configuration. A second drop-down lists available embeddings which can be used for training the model. It is possible to tune the most common training parameters (Number of Epochs, Learning rate, Decay, Dropout, and Batch) by editing their values in Training Parameters. Test/Train data for a model can be randomly selected based on the Validation Split value or can be set using Test/Train tags. The later option is very useful when conducting experiments that require testing and training data to be the same on each run. It is also possible to train a model by using a sublist of tasks with predefined tags. This is done by specifying the targeted Tags on the Training Parameters (last option). Annotation Lab also includes additional filtering options for the training dataset based on the status of completions, either all submitted completions can be used for training or only the reviewed ones. Custom Training Script If users want to change the default Training script present within the Annotation Lab, they can upload their own training pipeline. In the Train Page, project owners can upload the training scripts. At the moment we are supporting custom training script just for NER projects. Selection of Completions During the annotation project lifetime, normally not all tasks/completions are ready to be used as a training dataset. This is why the training process selects completions based on their status: Filter tasks by tags (if defined in Training Parameters widget, otherwise all tasks are considered) For completed tasks, completions to be taken into account are also selected based on the following criteria: If a task has a completion accepted by a reviewer this is selected for training and all others are ignored; Completions rejected by a Reviewer are not used for training; If no reviewer is assigned to a task that has multiple submitted completions the completion to use for training purpose is the one created by the user with the highest priority. Assertion Status NER configurations for the healthcare domain are often mixed with Assertion Status labels. In this case, Annotation Lab offers support for training both types of models in one go. After the training is complete, the models will be listed in the Pretrained Labels section of the Project Configuration. Information such as the source of the model and time of training will be displayed as well. Once the model(s) has been trained, the project configuration will be automatically updated to reference the new model for prediction. Notice below, for the Assertion Status Label tag the addition of model attribute to indicate which model will be used for task pre-annotation for this label. &lt;Label value=&quot;Absent&quot; assertion=&quot;true&quot; model=&quot;assertion_jsl_annotation_manual.model&quot;/&gt; &lt;Label value=&quot;Past&quot; assertion=&quot;true&quot; model=&quot;assertion_jsl_annotation_manual.model&quot;/&gt; It is not possible to mark a label as an Assertion Status label and use a NER model to predict it. A validation error is shown in the Interface Preview in case an invalid Assertion model is used. The Annotation Lab only allows the use of one single Assertion Status model in the same project. Classification Annotation Lab supports two types of classification training: Single Choice Classification and Multi-Choice Classification. For doing so, it uses three important attributes of the Choices tag to drive the Classification Models training and pre-annotation. Those are name, choice and train. Attribute name The attribute name allows the naming of the different choices present in the project configuration, and thus the training of separate models based on the same project annotations. For example, in the sample configuration illustrated below, the name=”age” attribute, tells the system to only consider age-related classification information when training an Age Classifier. The value specified by the name attribute is also used to name the resulting Classification model (classification_age_annotation_manual). Attribute choice The choice attribute specifies the type of model that will be trained: multiple or single. For example, in the Labeling Config below, Age and Gender are Single Choice Classification categories while the Smoking Status is Multi-Choice Classification. Depending upon the value of this attribute, the respective model will be trained as a Single Choice Classifier or Multi-Choice Classifier. &lt;View&gt; &lt;View style=&quot;overflow: auto;&quot;&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt; &lt;Header value=&quot;Smoking Status&quot;/&gt; &lt;Choices name=&quot;smokingstatus&quot; toName=&quot;text&quot; choice=&quot;multiple&quot; showInLine=&quot;true&quot;&gt; &lt;Choice value=&quot;Smoker&quot;/&gt; &lt;Choice value=&quot;Past Smoker&quot;/&gt; &lt;Choice value=&quot;Nonsmoker&quot;/&gt; &lt;/Choices&gt; &lt;Header value=&quot;Age&quot;/&gt; &lt;Choices name=&quot;age&quot; toName=&quot;text&quot; choice=&quot;single&quot; showInLine=&quot;true&quot;&gt; &lt;Choice value=&quot;Child (less than 18y)&quot; hotkey=&quot;c&quot;/&gt; &lt;Choice value=&quot;Adult (19-50y)&quot; hotkey=&quot;a&quot;/&gt; &lt;Choice value=&quot;Aged (50+y)&quot; hotkey=&quot;o&quot;/&gt; &lt;/Choices&gt; &lt;Header value=&quot;Gender&quot;/&gt; &lt;Choices name=&quot;gender&quot; toName=&quot;text&quot; choice=&quot;single&quot; showInLine=&quot;true&quot;&gt; &lt;Choice value=&quot;Female&quot; hotkey=&quot;f&quot;/&gt; &lt;Choice value=&quot;Male&quot; hotkey=&quot;m&quot;/&gt; &lt;/Choices&gt; &lt;/View&gt; Attribute train Annotation Lab restricts the training of two or more Classification Models at the same time. If there are multiple Classification categories in a project (like the one above), only the category whose name comes first in alphabetical order will be trained by default. In the above example, based on the value of the name attribute, we conclude that the Age classifier model is trained. The model to be trained can also be specified by setting the train=”true” attribute for the targeted Choices tag (like the one defined in Gender category below). &lt;View&gt; &lt;View style=&quot;overflow: auto;&quot;&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt; &lt;Header value=&quot;Smoking Status&quot;/&gt; &lt;Choices name=&quot;smokingstatus&quot; toName=&quot;text&quot; choice=&quot;multiple&quot; showInLine=&quot;true&quot;&gt; ... &lt;/Choices&gt; &lt;Header value=&quot;Age&quot;/&gt; &lt;Choices name=&quot;age&quot; toName=&quot;text&quot; choice=&quot;single&quot; showInLine=&quot;true&quot;&gt; ... &lt;/Choices&gt; &lt;Header value=&quot;Gender&quot;/&gt; &lt;Choices name=&quot;gender&quot; train=&quot;true&quot; toName=&quot;text&quot; choice=&quot;single&quot; showInLine=&quot;true&quot;&gt; ... &lt;/Choices&gt; &lt;/View&gt; The trained classification models are available to reuse in any project and can be added on step 3 of the Project Configuration wizard. The classification models trained using Annotation Lab also have attached benchmarking information. The training logs include the confusion matrix, helpful in understanding the performance of the model and in checking if the model is underfitting or overfitting. The confusion matrix is also available on the models tiles on the Models page, and is accessible by clicking on the benchmarking icon. Visual NER Training Annotation Lab offers the ability to train Visual NER models, apply active learning for automatic model training, and preannotate image-based tasks with existing models in order to accelerate annotation work. Model Training The training feature for Visual NER projects can be activated from the Setup page via the “Train Now” button (See 1). From the Training Settings sections, users can tune the training parameters (e.g. Epoch, Batch) and choose the tasks to use for training the Visual NER model (See 3). Information on the training progress is shown in the top right corner of the Model Training tab (See 2). Users can check detailed information regarding the success or failure of the last training. Training Failure can occur because of: Insufficient number of completions Poor quality of completions Insufficient CPU and Memory Wrong training parameters When triggering the training, users can choose to immediately deploy the model or just train it without deploying. If immediate deployment is chosen, then the labeling config is updated with references to the new model so that it will be used for preannotations. License Requirements Visual NER annotation, training and preannotation features are dependent on the presence of a Visual NLP license. Licenses with scope ocr: inference and ocr: training are required for preannotation and training respectively. Training Server Specification The minimal required training configuration is 64 GB RAM, 16 Core CPU for Visual NER Training. Mixed Projects If a project is set up to include Classification, Named Entity Recognition and Assertion Status labels and the three kinds of annotations are present in the training data, it is possible to train three models: one for Named Entity Recognition, one for Assertion Status, and one for Classification at the same time. The training logs from all three trainings can be downloaded at once by clicking the download button present in the Training section of the Setup Page. The newly trained models will be added to the Spark NLP pipeline config. Support for European Languagues Users can download English, German, Spanish, Portuguese, Italian, Danish and Romanian pretrained models from the NLP Models Hub and use them for pre-annotation. Annotation Lab also offers support for training/tuning models in the above languages.",
    "url": "/docs/en/alab/training_configurations",
    "relUrl": "/docs/en/alab/training_configurations"
  },
  "1570": {
    "id": "1570",
    "title": "Training Parameters",
    "content": "Annotation Lab supports the Transfer Learning feature offered by Spark NLP for Healthcare 3.1.2. This feature is available for project manages and project owners, but only if a valid Healthcare NLP license is loaded into the Annotation Lab. In this case, the feature can be activated for any project by navigating to the Train page. It requires the presence of a base model trained with MedicalNERModel. If a MedicalNER model is available on the Models Hub section of the Annotation Lab, it can be chosen as a starting point of the training process. This means the base model will be Fine Tuned with the new training data. When Fine Tuning is enabled, the same embeddings used for training the base model will be used to train the new model. Those need to be available on the Models Hub section as well. If present, embeddings will be automatically selected, otherwise users must go to the Models Hub page and download or upload them.",
    "url": "/docs/en/alab/transfer_learning",
    "relUrl": "/docs/en/alab/transfer_learning"
  },
  "1571": {
    "id": "1571",
    "title": "Transformers",
    "content": "{% assign parent_path = “en/transformer_entries” %} {% for file in site.static_files %} {% if file.path contains parent_path %} {% assign file_name = file.path | remove: parent_path | remove: “/” | prepend: “transformer_entries/” %} {% include_relative {{ file_name }} %} {% endif %} {% endfor %} Import Transformers into Spark NLP Overview We have extended support for HuggingFace 🤗 and TF Hub exported models since 3.1.0 to equivalent Spark NLP 🚀 annotators. Starting this release, you can easily use the saved_model feature in HuggingFace within a few lines of codes and import any BERT, DistilBERT, CamemBERT, RoBERTa, DeBERTa, XLM-RoBERTa, Longformer, BertForTokenClassification, DistilBertForTokenClassification, AlbertForTokenClassification, RoBertaForTokenClassification, DeBertaForTokenClassification, XlmRoBertaForTokenClassification, XlnetForTokenClassification, LongformerForTokenClassification, CamemBertForTokenClassification, CamemBertForSequenceClassification, CamemBertForQuestionAnswering, BertForSequenceClassification, DistilBertForSequenceClassification, AlbertForSequenceClassification, RoBertaForSequenceClassification, DeBertaForSequenceClassification, XlmRoBertaForSequenceClassification, XlnetForSequenceClassification, LongformerForSequenceClassification, AlbertForQuestionAnswering, BertForQuestionAnswering, DeBertaForQuestionAnswering, DistilBertForQuestionAnswering, LongformerForQuestionAnswering, RoBertaForQuestionAnswering, XlmRoBertaForQuestionAnswering, TapasForQuestionAnswering, Vision Transformers (ViT), HubertForCTC, and SwinForImageClassification models to Spark NLP. We will work on the remaining annotators and extend this support to the rest with each release 😊 Compatibility Spark NLP: The equivalent annotator in Spark NLP TF Hub: Models from TF Hub HuggingFace: Models from HuggingFace Model Architecture: Which architecture is compatible with that annotator Flags: Fully supported ✅ Partially supported (requires workarounds) ✔️ Under development ❎ Not supported ❌ Spark NLP TF Hub HuggingFace Model Architecture BertEmbeddings ✅ ✅ BERT - Small BERT - ELECTRA BertSentenceEmbeddings ✅ ✅ BERT - Small BERT - ELECTRA DistilBertEmbeddings   ✅ DistilBERT CamemBertEmbeddings   ✅ CamemBERT RoBertaEmbeddings   ✅ RoBERTa - DistilRoBERTa DeBertaEmbeddings   ✅ DeBERTa-v2 - DeBERTa-v3 XlmRoBertaEmbeddings   ✅ XLM-RoBERTa AlbertEmbeddings ✅ ✅ ALBERT XlnetEmbeddings   ✅ XLNet LongformerEmbeddings   ✅ Longformer ElmoEmbeddings ❎     UniversalSentenceEncoder ❎     BertForTokenClassification   ✅ TFBertForTokenClassification DistilBertForTokenClassification   ✅ TFDistilBertForTokenClassification AlbertForTokenClassification   ✅ TFAlbertForTokenClassification RoBertaForTokenClassification   ✅ TFRobertaForTokenClassification DeBertaForTokenClassification   ✅ TFDebertaV2ForTokenClassification XlmRoBertaForTokenClassification   ✅ TFXLMRobertaForTokenClassification XlnetForTokenClassification   ✅ TFXLNetForTokenClassificationet LongformerForTokenClassification   ✅ TFLongformerForTokenClassification CamemBertForTokenClassification   ✅ TFCamemBertForTokenClassification CamemBertForSequenceClassification   ✅ TFCamemBertForSequenceClassification CamemBertForQuestionAnswering   ✅ TFCamembertForQuestionAnswering BertForSequenceClassification   ✅ TFBertForSequenceClassification DistilBertForSequenceClassification   ✅ TFDistilBertForSequenceClassification AlbertForSequenceClassification   ✅ TFAlbertForSequenceClassification RoBertaForSequenceClassification   ✅ TFRobertaForSequenceClassification DeBertaForSequenceClassification   ✅ TFDebertaV2ForSequenceClassification XlmRoBertaForSequenceClassification   ✅ TFXLMRobertaForSequenceClassification XlnetForSequenceClassification   ✅ TFXLNetForSequenceClassification LongformerForSequenceClassification   ✅ TFLongformerForSequenceClassification AlbertForQuestionAnswering   ✅ TFAlbertForQuestionAnswering BertForQuestionAnswering   ✅ TFBertForQuestionAnswering DeBertaForQuestionAnswering   ✅ TFDebertaV2ForQuestionAnswering DistilBertForQuestionAnswering   ✅ TFDistilBertForQuestionAnswering LongformerForQuestionAnswering   ✅ TFLongformerForQuestionAnswering RoBertaForQuestionAnswering   ✅ TFRobertaForQuestionAnswering XlmRoBertaForQuestionAnswering   ✅ TFXLMRobertaForQuestionAnswering TapasForQuestionAnswering   ❎ TFTapasForQuestionAnswering ViTForImageClassification ❌ ✅ TFViTForImageClassification Automatic Speech Recognition (Wav2Vec2ForCTC)   ❎ TFWav2Vec2ForCTC SwinForImageClassification   ❎ TFSwinForImageClassification HubertForCTC   ❎ TFHubertForCTC T5Transformer   ❌   MarianTransformer   ❌   OpenAI GPT2   ❌   Example Notebooks HuggingFace to Spark NLP Spark NLP HuggingFace Notebooks Colab BertEmbeddings HuggingFace in Spark NLP - BERT BertSentenceEmbeddings HuggingFace in Spark NLP - BERT Sentence DistilBertEmbeddings HuggingFace in Spark NLP - DistilBERT CamemBertEmbeddings HuggingFace in Spark NLP - CamemBERT RoBertaEmbeddings HuggingFace in Spark NLP - RoBERTa DeBertaEmbeddings HuggingFace in Spark NLP - DeBERTa XlmRoBertaEmbeddings HuggingFace in Spark NLP - XLM-RoBERTa AlbertEmbeddings HuggingFace in Spark NLP - ALBERT XlnetEmbeddings HuggingFace in Spark NLP - XLNet LongformerEmbeddings HuggingFace in Spark NLP - Longformer BertForTokenClassification HuggingFace in Spark NLP - BertForTokenClassification DistilBertForTokenClassification HuggingFace in Spark NLP - DistilBertForTokenClassification AlbertForTokenClassification HuggingFace in Spark NLP - AlbertForTokenClassification RoBertaForTokenClassification HuggingFace in Spark NLP - RoBertaForTokenClassification XlmRoBertaForTokenClassification HuggingFace in Spark NLP - XlmRoBertaForTokenClassification CamemBertForTokenClassification HuggingFace in Spark NLP - CamemBertForTokenClassification CamemBertForSequenceClassification HuggingFace in Spark NLP - CamemBertForSequenceClassification CamemBertForQuestionAnswering HuggingFace in Spark NLP - CamemBertForQuestionAnswering BertForSequenceClassification HuggingFace in Spark NLP - BertForSequenceClassification DistilBertForSequenceClassification HuggingFace in Spark NLP - DistilBertForSequenceClassification AlbertForSequenceClassification HuggingFace in Spark NLP - AlbertForSequenceClassification RoBertaForSequenceClassification HuggingFace in Spark NLP - RoBertaForSequenceClassification XlmRoBertaForSequenceClassification HuggingFace in Spark NLP - XlmRoBertaForSequenceClassification XlnetForSequenceClassification HuggingFace in Spark NLP - XlnetForSequenceClassification LongformerForSequenceClassification HuggingFace in Spark NLP - LongformerForSequenceClassification AlbertForQuestionAnswering HuggingFace in Spark NLP - AlbertForQuestionAnswering BertForQuestionAnswering HuggingFace in Spark NLP - BertForQuestionAnswering DeBertaForQuestionAnswering HuggingFace in Spark NLP - DeBertaForQuestionAnswering DistilBertForQuestionAnswering HuggingFace in Spark NLP - DistilBertForQuestionAnswering LongformerForQuestionAnswering HuggingFace in Spark NLP - LongformerForQuestionAnswering RoBertaForQuestionAnswering HuggingFace in Spark NLP - RoBertaForQuestionAnswering XlmRobertaForQuestionAnswering HuggingFace in Spark NLP - XlmRobertaForQuestionAnswering ViTForImageClassification HuggingFace in Spark NLP - ViTForImageClassification TF Hub to Spark NLP Spark NLP TF Hub Notebooks Colab BertEmbeddings TF Hub in Spark NLP - BERT BertSentenceEmbeddings TF Hub in Spark NLP - BERT Sentence AlbertEmbeddings TF Hub in Spark NLP - ALBERT",
    "url": "/docs/en/transformers",
    "relUrl": "/docs/en/transformers"
  },
  "1572": {
    "id": "1572",
    "title": "FAQ",
    "content": "Useful knowledge basebase for troubleshooting some of the common issues and tips for customizing the Annotation Lab set up and configurations. 1. How to deploy multiple preannotation/training servers in parallel? By default the Annotation Lab installation is configured to use only one model server. If you want to allow the deployment of multiple model servers (e.g. up to 3), open the annotationlab-upgrader.sh script located under the artifacts folder of your Annotation Lab installation directory. Update the below configuration properties in the annotaionlab-upgrader.sh script for deploying upto 3 model servers. --set airflow.model_server.count=3 --set model_server.count=3 Save the file and re-run this script for the changes to take effect. 2. How can I access the API documentation? API documentation is included in the Annotation Lab setup. So you will need to first set up Annotation Lab. Only admin user can view the API documentation available under Settings &gt; API Integration. 3. Can I upload/download tasks/data using API? Yes, it is possible to perform both the upload and download operations using API. There is import and export API for those operations. You can get more details about it from the API documentation. 4. Can the user who created a project/task be assigned annotation/review tasks? The project owner has by default all permissions (annotator, reviewer, manager). So we do not need to explicitly assign the annotator or reviewer role to the owner for the tasks. 5. Can I download the swagger API documentation? No. At present you can only access the API documentation directly from the API integration page under Settings &gt; API Integration. 6. How to uninstall Kubernetes during faulty install and re-install Annotation Lab? If you have access to backend CLI then you can follow the steps below to fix faulty installation issue. Go to /usr/local/bin cd /usr/local/bin Run the uninstall script ./k3s-uninstall.sh Re-run the installer script from the project folder ./k3s-installer.sh Run the annotation lab installer ./annotationlab-installer.sh This will take some time and produce the output below: NAME STATUS ROLES AGE VERSION ip-172-31-91-230 Ready control-plane,master 3m38s v1.22.4+k3s1 Image is up to date for sha256:18481c1d051558c1e2e3620ba4ddf15cf4734fe35dc45fbf8065752925753c9d Image is up to date for sha256:a5b6ca180ebba94863ac9310ebcfacaaa64aca9efaa3b1f07ff4fad90ff76f68 Image is up to date for sha256:55208fe5388a7974bc4e3d63cfe20b2f097a79e99e9d10916752c3f8da560aa6 Image is up to date for sha256:a566a53e9ae7171faac1ce58db1d48cf029fbeb6cbf28cd53fd9651d5039429c Image is up to date for sha256:09ad16bd0d3fb577cbfdbbdc754484f707b528997d64e431cba19ef7d97ed785 NAME: annotationlab LAST DEPLOYED: Thu Sep 22 14:16:10 2022 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: ############################################################################# Thank you for installing annotationlab. Please run the following commands to get the credentials. export KEYCLOAK_CLIENT_SECRET_KEY=$(kubectl get secret annotationlab-secret --template={{.data.KEYCLOAK_CLIENT_SECRET_KEY}} | base64 --decode; echo) export PG_PASSWORD=$(kubectl get secrets annotationlab-postgresql -o yaml | grep &#39; postgresql-password:&#39; | cut -d &#39; &#39; -f 4 | base64 -d; echo) export PG_KEYCLOAK_PASSWORD=$(kubectl get secrets annotationlab-keyclo-postgres -o yaml | grep &#39; postgresql-password:&#39; | cut -d &#39; &#39; -f 4 | base64 -d; echo) export ADMIN_PASSWORD=$(kubectl get secret annotationlab-keyclo-admincreds --template={{.data.password}} | base64 --decode; echo) #############################################################################",
    "url": "/docs/en/alab/troubleshooting",
    "relUrl": "/docs/en/alab/troubleshooting"
  },
  "1573": {
    "id": "1573",
    "title": "Video Tutorials",
    "content": "{%- include extensions/youtube.html id=&#39;ycrJX_UMA6I&#39; -%}Programmatic labeling in Annotation Lab. Suvrat Joshi - October, 2022 {%- include extensions/youtube.html id=&#39;tzEwzT_HmXM&#39; -%}How to create a NER project in Annotation Lab. Suvrat Joshi - September, 2022 {%- include extensions/youtube.html id=&#39;jgUylZlz3uA&#39; -%}End-to-End No-Code Development of NER model for Text with Annotation Lab. Dia Trambitas - April, 2022 {%- include extensions/youtube.html id=&#39;JDDmTF6ir9k&#39; -%}End-to-End No-Code Development of Visual NER Models for PDFs and Images. Dia Trambitas - April, 2022 Add a new user. Ida Lucente - January, 2021 Update password from User Profile. Ida Lucente - January, 2021 Collect the client secret. Ida Lucente - January, 2021 Setup 2FA. Ida Lucente - January, 2021 API usage example. Ida Lucente - January, 2021",
    "url": "/docs/en/alab/step_by_step_tutorials",
    "relUrl": "/docs/en/alab/step_by_step_tutorials"
  },
  "1574": {
    "id": "1574",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/dependency/typed_dependency_parser.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/dependency/typed_dependency_parser.html"
  },
  "1575": {
    "id": "1575",
    "title": "Understand Entities in Context - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/understand_financial_entities_context",
    "relUrl": "/understand_financial_entities_context"
  },
  "1576": {
    "id": "1576",
    "title": "Understand Entities in Context - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/understand_legal_entities_context",
    "relUrl": "/understand_legal_entities_context"
  },
  "1577": {
    "id": "1577",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/universal_sentence_encoder.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/universal_sentence_encoder.html"
  },
  "1578": {
    "id": "1578",
    "title": "User Management",
    "content": "Basic user management features are present in the Annotation Lab. The user with the admin privilege can add or remove other users from the system or can edit user information if necessary. This feature is available by selecting the Users option under the Settings menu from the navigation panel. All user accounts created on the Annotation Lab can be seen on the Users page. The table shows the username, first name, last name, and email address of all created user accounts. A user with the admin privilege can edit or delete that information, add a user to a group or change the user’s password. User Details Annotation Lab stores basic information for each user. Such as the First Name, Last Name, and Email. It is editable from the Details section by any user with admin privilege. User Groups Currently, two user groups are available: Annotators and Admins. By default, a new user gets added to the Annotators group. It means the user will not have access to any admin features, such as user management or other settings. To add a user to the admin group, a user with admin privilege needs to navigate to the Users page, click on the concerned username or select the Edit option from the More Actions icon, then go to the Group section and check the Admins checkbox. Reset User Credentials A user with the admin privilege can change the login credentials for another user by navigating to the Credentials section of the edit user page and defining a new (temporary) password. For extra protection, the user with the admin privilege can enforce the password change on the next login. SAML Integration AnnotationLab supports Security Assertion Markup Language (SAML). To login to AnnotationLab using SAML, follow the steps below. SAML Server Setup Run the following command to setup a sample SAML server in a Docker environment: docker run --rm --name mysamlserver -p 8081:8080 -p 8443:8443 -e SIMPLESAMLPHP_SP_ENTITY_ID=http://{IP}/auth/realms/master -e SIMPLESAMLPHP_SP_ASSERTION_CONSUMER_SERVICE=http://{IP}/auth/realms/master/broker/saml/endpoint --network annotationlab kristophjunge/test-saml-idp SAML Configuration Follow the steps described below to setup a SAML connection. Goto AnnotationLab Keyclock console and navigate to Identity Providers under Configure on the left-side menu. Choose SAML v2.0 from Add Provider drop-down menu and a configuration page should appear. Provide values for Alias(e.g: saml) and Display Name(e.g: SAML). The value for Display Name will be seen in the login page. Now, set the value of the following attributes as shown below: Enabled: On Store Tokens: On First Login Flow : first broker login Sync Mode: force Under SAML Config specify values for the following parameters as provided by SAML sever: Service Provider Entity ID Single Sign-On Service URL Single Logout Service URL Choose a Principal Type(e.g: Attribute[Name]) and add value to Principal Attribute(e.g. email) according to the data provided by SAML server Click on the Save button to save the changes. Identity Provider Mapper An Identity Provider Mapper must be defined for importing SAML data provided by the External Identity Provider (IDP) and using it for authenticating into Annotation Lab. This allows user profile and other user information to be imported and made available into Annotation Lab. On Identity Providers &gt; SAML page click on the Mappers tab located next to the Settings tab and follow the steps below: Click on Create. This should open a form to add a new Identity Provider Mapper Set the value for the following attributes: Name(e.g: uma_protection mapper) Sync Mode Override: inherit Mapper Type: Hardcoded Role Click on the Select Role button and under the Client Roles menu put annotationlab. Now, select uma_protection and click on Select client role. annotationlab.uma_protection should be the value displayed for Role Save the changes Default Group Default groups are used for assigning group membership automatically whenever any new user is created. Add Annotators as the default group using the following steps: Goto Groups, on the left side panel under Manages Select the Default Groups tab Under Available Groups select Annotators and then click on the Add button Now, Annotators should be listed under Default Groups. Login to Annotation Lab Goto the Annotation Lab’s login dashboard and click on the display name which was set earlier(e.g: SAML). This is displayed under Or sign in with. Login with the data provided by the SAML server here: The user account information is updated and the user is redirected to Annotation Lab and presented with the Project dashboard. NOTES: Users added as an IDP will be available in the Users tab on the left side under Manages",
    "url": "/docs/en/alab/user_management",
    "relUrl": "/docs/en/alab/user_management"
  },
  "1579": {
    "id": "1579",
    "title": "Utility & Helper Modules",
    "content": "NLP Lab (Annotation Lab) Interface Module Spark NLP for Healthcare provides functionality to interact with the NLP Lab using easy-to-use functions. NLP Lab is a tool for multi-modal data annotation. It allows annotation teams to efficiently collaborate to generate training data for ML models and/or to validate automatic annotations generated by those. NLP Lab Intreacting Module provides programmatic interactions with the NLP Lab. A detailed usage examples can be found at Complete NLP Lab Module SparkNLP JSL, and Python’s documentation in the Python API. Following are the functionalities supported by the module: Generating a CoNLL formatted file from the annotation JSON for training an NER model. Generating a csv/excel formatted file from the annotation JSON for training classification, assertion, and relation extraction models. Build preannotation JSON file using Spark NLP pipelines, saving it as a JSON and uploading preannotations to a project. Interacting with the NLP Lab instance, and setting up projects for NLP Lab. Getting the list of all projects in the NLP Lab instance. Creating New Projects. Deleting Projects. Setting &amp; editing configuration of projects. Accessing/getting configuration of any existing project. Upload tasks to a project. Deleting tasks of a project. Start Module # import the module from sparknlp_jsl.alab import AnnotationLab alab = AnnotationLab() Generate Data for Traing a Classification Model alab.get_classification_data( # required: path to NLP Lab JSON export input_json_path=&#39;alab_demo.json&#39;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False # ground_truth=False) Converting The Json Export into a Conll Format Suitable for Training an Ner Model alab.get_conll_data( # required: Spark session with spark-nlp-jsl jar spark=spark, # required: path to NLP Lab JSON export input_json_path=&quot;alab_demo.json&quot;, # required: name of the CoNLL file to save output_name=&quot;conll_demo&quot;, # optional: path for CoNLL file saving directory, defaults to &#39;exported_conll&#39; # save_dir=&quot;exported_conll&quot;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False # ground_truth=False, # optional: labels to exclude from CoNLL; these are all assertion labels and irrelevant NER labels, # defaults to empty list # excluded_labels=[&#39;ABSENT&#39;], # optional: set a pattern to use regex tokenizer, defaults to regular tokenizer if pattern not defined # regex_pattern=&quot; s+|(?=[-.:;*+,$&amp;% [ ]])|(?&lt;=[-.:;*+,$&amp;% [ ]])&quot; # optional: list of NLP Lab task titles to exclude from CoNLL, defaults to empty list # excluded_task_ids = [2, 3] # optional: list of NLP Lab task titles to exclude from CoNLL, defaults to None # excluded_task_titles = [&#39;Note 1&#39;]) Converting The JSON Export into a Dataframe Suitable for Training an Assertion Model alab.get_assertion_data( # required: SparkSession with spark-nlp-jsl jar spark=spark, # required: path to NLP Lab JSON export input_json_path = &#39;alab_demo.json&#39;, # required: annotated assertion labels to train on assertion_labels = [&#39;ABSENT&#39;], # required: relevant NER labels that are assigned assertion labels relevant_ner_labels = [&#39;PROBLEM&#39;, &#39;TREATMENT&#39;], # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False # ground_truth = False, # optional: assertion label to assign to entities that have no assertion labels, defaults to None # unannotated_label = &#39;PRESENT&#39;, # optional: set a pattern to use regex tokenizer, defaults to regular tokenizer if pattern not defined # regex_pattern = &quot; s+|(?=[-.:;*+,$&amp;% [ ]])|(?&lt;=[-.:;*+,$&amp;% [ ]])&quot;, # optional: set the strategy to control the number of occurrences of the unannotated assertion label # in the output dataframe, options are &#39;weighted&#39; or &#39;counts&#39;, &#39;weighted&#39; allows to sample using a # fraction, &#39;counts&#39; allows to sample using absolute counts, defaults to None # unannotated_label_strategy = None, # optional: dictionary in the format {&#39;ENTITY_LABEL&#39;: sample_weight_or_counts} to control the number of # occurrences of the unannotated assertion label in the output dataframe, where &#39;ENTITY_LABEL&#39; are the # NER labels that are assigned the unannotated assertion label, and sample_weight_or_counts should be # between 0 and 1 if `unannotated_label_strategy` is &#39;weighted&#39; or between 0 and the max number of # occurrences of that NER label if `unannotated_label_strategy` is &#39;counts&#39; # unannotated_label_strategy_dict = {&#39;PROBLEM&#39;: 0.5, &#39;TREATMENT&#39;: 0.5}, # optional: list of NLP Lab task IDs to exclude from output dataframe, defaults to None # excluded_task_ids = [2, 3] # optional: list of NLP Lab task titles to exclude from output dataframe, defaults to None # excluded_task_titles = [&#39;Note 1&#39;]) Converting The JSON Export into a Dataframe Suitable for Training a Relation Extraction Model alab.get_relation_extraction_data( # required: Spark session with spark-nlp-jsl jar spark=spark, # required: path to NLP Lab JSON export input_json_path=&#39;alab_demo.json&#39;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth=True, # optional: set to True to assign a relation label between entities where no relation was annotated, # defaults to False negative_relations=True, # optional: all assertion labels that were annotated in the NLP Lab, defaults to None assertion_labels=[&#39;ABSENT&#39;], # optional: plausible pairs of entities for relations, separated by a &#39;-&#39;, use the same casing as the # annotations, include only one relation direction, defaults to all possible pairs of annotated entities relation_pairs=[&#39;DATE-PROBLEM&#39;,&#39;TREATMENT-PROBLEM&#39;,&#39;TEST-PROBLEM&#39;], # optional: set the strategy to control the number of occurrences of the negative relation label # in the output dataframe, options are &#39;weighted&#39; or &#39;counts&#39;, &#39;weighted&#39; allows to sample using a # fraction, &#39;counts&#39; allows to sample using absolute counts, defaults to None negative_relation_strategy=&#39;weighted&#39;, # optional: dictionary in the format {&#39;ENTITY1-ENTITY2&#39;: sample_weight_or_counts} to control the number of # occurrences of negative relations in the output dataframe for each entity pair, where &#39;ENTITY1-ENTITY2&#39; # represent the pairs of entities for relations separated by a `-` (include only one relation direction), # and sample_weight_or_counts should be between 0 and 1 if `negative_relation_strategy` is &#39;weighted&#39; or # between 0 and the max number of occurrences of negative relations if `negative_relation_strategy` is # &#39;counts&#39;, defaults to None negative_relation_strategy_dict = {&#39;DATE-PROBLEM&#39;: 0.1, &#39;TREATMENT-PROBLEM&#39;: 0.5, &#39;TEST-PROBLEM&#39;: 0.2}, # optional: list of NLP Lab task IDs to exclude from output dataframe, defaults to None # excluded_task_ids = [2, 3] # optional: list of NLP Lab task titles to exclude from output dataframe, defaults to None # excluded_task_titles = [&#39;Note 1&#39;]) Generate JSON Containing Pre-annotations Using a Spark NLP Pipeline pre_annotations, summary = alab.generate_preannotations( # required: list of results. all_results = results, # requied: output column name of &#39;DocumentAssembler&#39; stage - to get original document string. document_column = &#39;document&#39;, # required: column name(s) of ner model(s). Note: multiple NER models can be used, but make sure their results don&#39;t overrlap. # Or use &#39;ChunkMergeApproach&#39; to combine results from multiple NER models. ner_columns = [&#39;ner_chunk&#39;], # optional: column name(s) of assertion model(s). Note: multiple assertion models can be used, but make sure their results don&#39;t overrlap. # assertion_columns = [&#39;assertion_res&#39;], # optional: column name(s) of relation extraction model(s). Note: multiple relation extraction models can be used, but make sure their results don&#39;t overrlap. # relations_columns = [&#39;relations_clinical&#39;, &#39;relations_pos&#39;], # optional: This can be defined to identify which pipeline/user/model was used to get predictions. # Default: &#39;model&#39; # user_name = &#39;model&#39;, # optional: Option to assign custom titles to tasks. By default, tasks will be titled as &#39;task_#&#39; # titles_list = [], # optional: If there are already tasks in project, then this id offset can be used to make sure default titles &#39;task_#&#39; do not overlap. # While upload a batch after the first one, this can be set to number of tasks currently present in the project # This number would be added to each tasks&#39;s ID and title. # id_offset=0) Interacting with NLP Lab alab = AnnotationLab() username=&#39;&#39; password=&#39;&#39; client_secret=&#39;&#39; annotationlab_url=&#39;&#39; alab.set_credentials( # required: username username=username, # required: password password=password, # required: secret for you alab instance (every alab installation has a different secret) client_secret=client_secret, # required: http(s) url for you NLP lab annotationlab_url=annotationlab_url) Get All Visible Projects alab.get_all_projects() Create a New Project alab.create_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: other details about project. Default: Empty string project_description=&#39;&#39;, # optional: Sampling option of tasks. Default: random project_sampling=&#39;&#39;, # optional: Annotation Guidelines of project project_instruction=&#39;&#39;) Delete a Project alab.delete_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: confirmation for deletion. Default: False - will ask for confirmation. If set to true, will delete directly. confirm=False) Upload Tasks to a Project alab.upload_tasks( # required: name of project to upload tasks to project_name=&#39;alab_demo&#39;, # required: list of examples / tasks as string (One string is one task). task_list=task_list, # optional: Option to assign custom titles to tasks. By default, tasks will be titled as &#39;task_#&#39; title_list = [], # optional: If there are already tasks in project, then this id offset can be used to make sure default titles &#39;task_#&#39; do not overlap. # While upload a batch after the first one, this can be set to number of tasks currently present in the project # This number would be added to each tasks&#39;s ID and title. id_offset=0) Delete Tasks from a Project alab.delete_tasks( # required: name of project to upload tasks to project_name=&#39;alab_demo&#39;, # required: list of ids of tasks. # note: you can get task ids from the above step. Look for &#39;task_ids&#39; key. task_ids=[1, 2], # optional: confirmation for deletion. Default: False - will ask for confirmation. If set to true, will delete directly. confirm=False) Upload Pre-annotations to NLP Lab alab.upload_preannotations( # required: name of project to upload annotations to project_name = &#39;alab_demo&#39;, # required: preannotation JSON preannotations = pre_annotations) Deidentification Module Spark NLP for Healthcare provides functionality to apply Deidentification using easy-to-use module named Deid. The Deid module is a tool for deidentifying Personal Health Information from data in a file path. It can be used with custom SparkNLP NER pipelines or without any pipeline specified. It returns the deidentification results as a pyspark dataframe as well as a csv or json file. The module also includes functionality for applying Structured Deidentification task to data from a file path. The function, deidentify(), can be used with a custom pipeline or without defining any custom pipeline. structured_deidentifier() function can be used for the Structured Deidentification task. Apply Deidentification With a Custom Pipeline from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark, # required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: A custom pipeline model to be used for deidentification. If not specified, the default is None. custom_pipeline=nlpModel, #optional: Fields to be deidentified and their deidentification modes, by default {&quot;text&quot;: &quot;mask&quot;} fields={&quot;text&quot;: &quot;mask&quot;, &quot;text_1&quot;: &quot;obfuscate&quot;}, #optional: The masking policy. Default is &quot;entity_labels&quot;. masking_policy=&quot;fixed_length_chars&quot;, #optional: The fixed mask length. Default is 4. fixed_mask_length=4, #optional: The final chunk column name of the custom pipeline that will be deidentified, if specified. Default is &quot;ner_chunk&quot;. ner_chunk=&quot;ner_chunk&quot;, #optional: The corresponding document column name of the custom pipeline, if specified. Default is &quot;document&quot; document=&quot;document&quot;, #optional: The corresponding sentence column name of the custom pipeline, if specified. Default is &quot;sentence&quot; sentence=&quot;sentence&quot;, #optional: The corresponding token column name of the custom pipeline, if specified. Default is &quot;token&quot; token=&quot;token&quot;, #optional: The source of the reference file for obfuscation. Default is &quot;faker&quot;. #obfuscate_ref_source=&quot;both&quot;, #optional: The path of the reference file for obfuscation. Default is None. #obfuscate_ref_file_path=&quot;obfuscation.txt&quot;, #optional: Obfuscate date. Default is True. #obfuscate_date=True, #optional: The document hash coder column name. Default is &quot;documentHash&quot;. #documentHashCoder_col_name= &quot;documentHash&quot; #optional: ID column name. Default is &quot;id&quot;. #id_column_name= &quot;ID&quot; #optional: Date shift column name. Default is &quot;date_shift&quot;. #date_shift_column_name= &quot;date_shift&quot; #optional: Json file path for multi-mode Deid. Default is NONE. #multi_mode_file_path= &quot;multi_mode_file_path.json&quot; #optional: The date tag. Default is &quot;DATE&quot;. #date_tag=&quot;DATE&quot; #optional: Language. Default is &quot;en&quot; #language=&quot;en&quot; #optional: Region. Default is &quot;us&quot; #region=&quot;us&quot; #optional: Age group obfuscation. Default is False. #age_group_obfuscation=True #optional: Age ranges for obfuscation. Default is [1, 4, 12, 20, 40, 60, 80]. #age_ranges=[1, 4, 12, 20, 40, 60, 80] #optional: Shift days. Default is False. #shift_days=False #optional: The number of days to shift. Default is None. #number_of_days=5 #optional: Use unnormalized date. Default is False. #unnormalized_date=True #optional: The unnormalized mode. Default is &quot;mask&quot;. #unnormalized_mode=&quot;obfuscate&quot; ) res= deid_implementor.deidentify() ++-+-+-+-+ | ID| text| text_deidentified| text_1| text_1_deidentified| ++-+-+-+-+ | 0|Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson ...|Record date : ** , ** , M.D . , Name : ** MR .|Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-...|Date : 10-16-1991 PCP : Alveda Castles , 26 years-old , Record date...| ++-+-+-+-+ Apply Deidentification With No Custom Pipeline from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark, # required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: Fields to be deidentified and their deidentification modes, by default {&quot;text&quot;: &quot;mask&quot;} fields={&quot;text&quot;: &quot;mask&quot;}, #optional: The masking policy. Default is &quot;entity_labels&quot;. masking_policy=&quot;entity_labels&quot;, #optional: Json file path for multi-mode Deid. Default is NONE. #multi_mode_file_path= &quot;multi_mode_file_path.json&quot;, #optional: Age group obfuscation. Default is False. #age_group_obfuscation=True #optional: Age ranges for obfuscation. Default is [1, 4, 12, 20, 40, 60, 80]. #age_ranges=[1, 4, 12, 20, 40, 60, 80] #optional: Shift days. Default is False. #shift_days=False #optional: The number of days to shift. Default is None. #number_of_days=5 #optional: Use unnormalized date. Default is False. #unnormalized_date=True #optional: The unnormalized mode. Default is &quot;mask&quot;. #unnormalized_mode=&quot;obfuscate&quot; ) res= deid_implementor.deidentify() ++-+-+ | ID| text_original| text_deid| ++-+-+ | 0| &quot;| &quot;| | 1|Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson ...|Record date : &lt;DATE&gt; , &lt;DOCTOR&gt; , M.D . , Name : &lt;PATIENT&gt; , MR # &lt;...| | 2| &quot;| &quot;| ++-+-+ Apply Structured Deidentification from sparknlp_jsl.utils.deidentification_utils import structured_deidentifier res= structured_deidentifier( # required: Spark session with spark-nlp-jsl jar spark #required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: A dictionary that contains the column names and the tags that should be used for deidentification. Default is {&quot;NAME&quot;:&quot;PATIENT&quot;,&quot;AGE&quot;:&quot;AGE&quot;} columns_dict= {&quot;NAME&quot;: &quot;ID&quot;, &quot;DOB&quot;: &quot;DATE&quot;}, #optional: The seed value for the random number generator. Default is {&quot;NAME&quot;: 23, &quot;AGE&quot;: 23} columns_seed= {&quot;NAME&quot;: 23, &quot;DOB&quot;: 23}, #optional: The source of the reference file. Default is faker. ref_source=&quot;faker&quot;, #optional: The number of days to be shifted. Default is None shift_days=5, #optional: The path of the reference file for obfuscation. Default is None. #obfuscateRefFile: &quot;obfuscator_unique_ref_test.txt&quot;, #optional: A list of date formats. Default is [&quot;dd/MM/yyyy&quot;, &quot;dd-MM-yyyy&quot;, &quot;d/M/yyyy&quot;, &quot;dd-MM-yyyy&quot;, &quot;d-M-yyyy&quot;] #date_formats=[&quot;dd/MM/yyyy&quot;, &quot;dd-MM-yyyy&quot;] ) +-++--++-+ | NAME| DOB| ADDRESS|SBP| TEL| +-++--++-+ |[N2649912]|[18/02/1977]| 711 Nulla St.|140| 673 431234| | [W466004]|[28/02/1977]| 1 Green Avenue.|140|+23 (673) 431234| | [M403810]|[16/04/1900]|Calle del Liberta...|100| 912 345623| +-++--++-+ Compatibility This module helps to find appropriate model versions depending your distribution of John Snow Labs products. By searching our vast repository of models available at NLP Model Hub, we can return a JSON-like file with the models’s information (using method .findVersion()) or print the models that match a given query (using method .showVersion()). To use it, simply run the following: from johnsnowlabs import medical # Or: from sparknlp_jsl.compatibility import Compatibility compatibility = medical.Compatibility() # Returns a list of dict objects found_models = compatibility.findVersion(&#39;ner_clinical&#39;) To tabulate and visualize all retrieved models, you can: import pandas as pd models_df = pd. | | name | sparkVersion | version | language | date | readyToUse | |:|:-|:|:-|:--|:|:-| | 0 | ner_clinical_noncontrib | 2.4 | 2.3.0 | en | 2019-11-14T17:07:35.434 | true | | 1 | ner_clinical_large | 2.4 | 2.5.0 | en | 2020-05-21T00:35:02.624 | true | | 2 | ner_clinical | 3 | 3.0.0 | en | 2021-01-27T12:52:59.087 | true | | 3 | ner_clinical_large_en | 3 | 3.0.0 | en | 2021-03-31T12:32:55.357 | true | | 4 | ner_clinical | 3 | 3.0.0 | en | 2021-03-31T16:33:39.368 | true | | 5 | ner_clinical_large | 3 | 3.0.0 | en | 2021-03-31T15:55:14.650 | true | | 6 | ner_clinical_biobert | 3 | 3.0.0 | en | 2021-04-01T07:06:52.919 | true | | 7 | ner_clinical | 2.3 | 3.0.0 | en | 2021-03-31T16:33:39.368 | true | | 8 | ner_clinical_biobert | 2.3 | 3.0.0 | en | 2021-04-01T07:06:52.919 | true | | 9 | ner_clinical | 2.3 | 3.0.0 | en | 2021-01-27T12:52:59.087 | true | | 10 | ner_clinical | 2.3 | 3.0.0 | en | 2021-03-31T16:33:39.368 | true | | 11 | ner_clinical_large | 2.3 | 3.0.0 | en | 2021-03-31T15:55:14.650 | true | | 12 | bert_token_classifier_ner_clinical | 2.4 | 3.2.0 | en | 2021-08-28T15:51:44.492 | true | | 13 | bert_token_classifier_ner_clinical | 2.4 | 3.3.4 | en | 2022-01-06T12:42:21.908 | true | | 14 | bert_token_classifier_ner_clinical_pipeline | 3 | 3.4.1 | en | 2022-03-15T12:08:50.209 | true | | 15 | bert_token_classifier_ner_clinical_pipeline | 2.4 | 3.4.1 | en | 2022-03-15T12:56:42.874 | true | | 16 | ner_clinical_biobert_pipeline | 3 | 3.4.1 | en | 2022-03-21T15:06:54.361 | true | | 17 | ner_clinical_large_pipeline | 3 | 3.4.1 | en | 2022-03-21T14:29:11.545 | true | | 18 | ner_clinical_pipeline | 3 | 3.4.1 | en | 2022-03-21T14:32:59.531 | true | | 19 | bert_token_classifier_ner_clinical_pipeline | 3 | 3.4.1 | en | 2022-03-21T18:51:36.583 | true | | 20 | ner_clinical_trials_abstracts | 3 | 3.5.3 | en | 2022-06-22T15:26:56.789 | true | | 21 | ner_clinical_trials_abstracts_pipeline | 3 | 3.5.3 | en | 2022-06-27T07:07:17.828 | true | | 22 | bert_token_classifier_ner_clinical_trials_abstracts | 3 | 3.5.3 | en | 2022-06-29T04:10:29.985 | true | | 23 | ner_clinical_bert | 3 | 4.0.0 | ro | 2022-06-30T21:36:31.573 | true | | 24 | ner_clinical | 3 | 4.0.0 | ro | 2022-07-01T14:55:02.322 | true | | 25 | ner_clinical_bert | 3 | 4.0.2 | ro | 2022-08-12T09:12:00.992 | true | | 26 | bert_token_classifier_ner_clinical_trials_abstracts | 3 | 4.0.2 | es | 2022-08-11T14:45:17.151 | true | | 27 | ner_clinical_trials_abstracts | 3 | 4.0.2 | es | 2022-08-12T21:19:27.613 | true | | 28 | ner_clinical_bert | 3 | 4.2.2 | ro | 2022-11-22T13:33:53.852 | true | Or simply run the showVersion() method instead: compatibility.showVersion(&#39;ner_clinical&#39;) +--+++ | Pipeline/Model | lang | version | +--+++ | ner_clinical_noncontrib | en | 2.3.0 | | ner_clinical_large | en | 2.5.0 | | ner_clinical | en | 3.0.0 | | ner_clinical_large_en | en | 3.0.0 | | ner_clinical | en | 3.0.0 | | ner_clinical_large | en | 3.0.0 | | ner_clinical_biobert | en | 3.0.0 | | ner_clinical | en | 3.0.0 | | ner_clinical_biobert | en | 3.0.0 | | ner_clinical | en | 3.0.0 | | ner_clinical | en | 3.0.0 | | ner_clinical_large | en | 3.0.0 | | bert_token_classifier_ner_clinical | en | 3.2.0 | | bert_token_classifier_ner_clinical | en | 3.3.4 | | bert_token_classifier_ner_clinical_pipeline | en | 3.4.1 | | bert_token_classifier_ner_clinical_pipeline | en | 3.4.1 | | ner_clinical_biobert_pipeline | en | 3.4.1 | | ner_clinical_large_pipeline | en | 3.4.1 | | ner_clinical_pipeline | en | 3.4.1 | | bert_token_classifier_ner_clinical_pipeline | en | 3.4.1 | | ner_clinical_trials_abstracts | en | 3.5.3 | | ner_clinical_trials_abstracts_pipeline | en | 3.5.3 | | bert_token_classifier_ner_clinical_trials_abstracts | en | 3.5.3 | | ner_clinical_bert | ro | 4.0.0 | | ner_clinical | ro | 4.0.0 | | ner_clinical_bert | ro | 4.0.2 | | bert_token_classifier_ner_clinical_trials_abstracts | es | 4.0.2 | | ner_clinical_trials_abstracts | es | 4.0.2 | | ner_clinical_bert | ro | 4.2.2 | +--+++ InternalResourceDownloader This module has extended functinalities to list and download models from John Snow Labs repositories. It is an auxiliary module for finding and downloading different models for studies and analysis. As with the Compatibility module, InternalResourceDownloader is also capable of displaying the available models. The difference is that this module can filter the results based on the Python’s class name of the annotator, while Compatibility searches for models’ name. Displaying available models To display the pipelines or models, you can use the .showPrivateModels(), .showPrivatePipelines(), .returnPrivateModels(), or .returnPrivatePipelines() methods, which return the results in a list or print the results directly. For example, to list all models with class MedicalNerModel, just run (some results were ommited for brevity): medical_ner_models = medical.InternalResourceDownloader.returnPrivateModels(&quot;MedicalNerModel&quot;) medical_ner_models[0] [&#39;nerdl_tumour_demo&#39;, &#39;en&#39;, &#39;1.7.3&#39;] medical.InternalResourceDownloader.showPrivateModels(&quot;MedicalNerModel&quot;) +-+++ | Model | lang | version | +-+++ | ner_deid_subentity_bert | ro | 4.0.0 | | ner_deid_subentity | ro | 4.0.0 | | ner_pathogen | en | 4.0.0 | | ner_clinical_bert | ro | 4.0.0 | | ner_clinical | ro | 4.0.0 | | ner_ade_binary | en | 4.0.0 | | ner_living_species_300 | es | 4.0.0 | | ner_clinical_bert | ro | 4.0.2 | | ner_clinical_trials_abstracts | es | 4.0.2 | | ner_pharmacology | es | 4.0.2 | | ner_negation_uncertainty | es | 4.0.2 | | disease_mentions_tweet | es | 4.0.2 | | ner_deid_generic_bert | ro | 4.0.2 | | ner_oncology_unspecific_posology_wip | en | 4.0.0 | | ner_oncology_wip | en | 4.0.0 | | ner_oncology_therapy_wip | en | 4.0.0 | | ner_oncology_posology_wip | en | 4.0.0 | | ner_oncology_anatomy_general_wip | en | 4.0.0 | | ner_oncology_tnm_wip | en | 4.0.0 | | ner_oncology_demographics_wip | en | 4.0.0 | | ner_oncology_biomarker_wip | en | 4.0.0 | | ner_oncology_anatomy_granular_wip | en | 4.0.0 | | ner_oncology_test_wip | en | 4.0.0 | | ner_oncology_diagnosis_wip | en | 4.0.0 | | ner_oncology_response_to_treatment_wip | en | 4.0.0 | | ner_jsl | en | 4.2.0 | | ner_covid_trials | en | 4.2.0 | | ner_oncology_unspecific_posology | en | 4.0.0 | | ner_oncology | en | 4.0.0 | | ner_oncology_tnm | en | 4.0.0 | | ner_oncology_anatomy_general | en | 4.0.0 | | ner_oncology_therapy | en | 4.0.0 | | ner_oncology_test | en | 4.0.0 | | ner_oncology_diagnosis | en | 4.0.0 | | ner_oncology_demographics | en | 4.0.0 | | ner_oncology_anatomy_granular | en | 4.0.0 | | ner_oncology_response_to_treatment | en | 4.0.0 | | ner_oncology_posology | en | 4.0.0 | | ner_oncology_biomarker | en | 4.0.0 | | ner_sdoh_slim_wip | en | 4.2.1 | | ner_clinical_bert | ro | 4.2.2 | | ner_living_species_300 | es | 4.2.2 | | ner_deid_generic_bert | ro | 4.2.2 | | ner_oncology_biomarker | en | 4.2.2 | | ner_oncology_response_to_treatment | en | 4.2.2 | | ner_oncology_demographics | en | 4.2.2 | | ner_oncology_therapy | en | 4.2.2 | | ner_oncology | en | 4.2.2 | | ner_oncology_anatomy_granular | en | 4.2.2 | | ner_oncology_anatomy_general | en | 4.2.2 | | ner_oncology_diagnosis | en | 4.2.2 | | ner_oncology_tnm | en | 4.2.2 | | ner_oncology_posology | en | 4.2.2 | | ner_oncology_unspecific_posology | en | 4.2.2 | | ner_oncology_test | en | 4.2.2 | +-+++ ModelTracer This module adds information on the data to help track uids and timestamps of each stage of the pipeline. Given the following pipeline for Medical NER: # Annotator that transforms a text column from dataframe into an Annotation ready for NLP documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) # Tokenizer splits words in a relevant format for NLP tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) # Clinical word embeddings trained on PubMED dataset word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # NER model trained on i2b2 (sampled from MIMIC) dataset clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical_large&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) .setLabelCasing(&quot;upper&quot;) #decide if we want to return the tags in upper or lower case ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = Pipeline( stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter ]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) To add the UID and timestamp of each pipeline step, simply use from sparknlp_jsl.modelTracer import ModelTracer df = model.transform(empty_data) tracer_result = ModelTracer().addUidCols(pipeline = nlpPipeline, df = df) tracer_result.show(truncate=False) +-++--+--+-+++-+-+--+--+--+--+ |text|document |sentence|token|embeddings|ner|ner_chunk|documentassembler_model_uid |sentencedetectordlmodel_model_uid |tokenizer_model_uid |word_embeddings_model_model_uid |medicalnermodel_model_uid |nerconverter_model_uid | +-++--+--+-+++-+-+--+--+--+--+ | |[{document, 0, -1, , {sentence -&gt; 0}, []}]|[] |[] |[] |[] |[] |{uid -&gt; DocumentAssembler_3e110f5ce3dc, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; SentenceDetectorDLModel_6bafc4746ea5, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; Tokenizer_bd74fe5f5860, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; WORD_EMBEDDINGS_MODEL_9004b1d00302, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; MedicalNerModel_1a8637089929, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; NerConverter_643c903e9161, timestamp -&gt; 2022-10-21_22:58}| +-++--+--+-+++-+-+--+--+--+--+",
    "url": "/docs/en/utility_helper_modules",
    "relUrl": "/docs/en/utility_helper_modules"
  },
  "1580": {
    "id": "1580",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/utils.html",
    "relUrl": "/api/python/modules/sparknlp/common/utils.html"
  },
  "1581": {
    "id": "1581",
    "title": "Utils for Spark NLP",
    "content": "You can see all features showcased in the demo notebook nlp.viz(pipe,data) Visualize input data with an already configured Spark NLP pipeline, for Algorithms of type (Ner,Assertion, Relation, Resolution, Dependency) using Spark NLP Display Automatically infers applicable viz type and output columns to use for visualization. Example: # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlp.viz(ade_pipeline, text) returns: If a pipeline has multiple models candidates that can be used for a viz, the first Annotator that is vizzable will be used to create viz. You can specify which type of viz to create with the viz_type parameter Output columns to use for the viz are automatically deducted from the pipeline, by using the first annotator that provides the correct output type for a specific viz. You can specify which columns to use for a viz by using the corresponding ner_col, pos_col, dep_untyped_col, dep_typed_col, resolution_col, relation_col, assertion_col, parameters. nlp.autocomplete_pipeline(pipe) Auto-Complete a pipeline or single annotator into a runnable pipeline by harnessing NLU’s DAG Autocompletion algorithm and returns it as NLU pipeline. The standard Spark pipeline is avaiable on the .vanilla_transformer_pipe attribute of the returned nlp pipe Every Annotator and Pipeline of Annotators defines a DAG of tasks, with various dependencies that must be satisfied in topoligical order. NLU enables the completion of an incomplete DAG by finding or creating a path between the very first input node which is almost always is DocumentAssembler/MultiDocumentAssembler and the very last node(s), which is given by the topoligical sorting the iterable annotators parameter. Paths are created by resolving input features of annotators to the corrrosponding providers with matching storage references. Example: # Lets autocomplete the pipeline for a RelationExtractionModel, which as many input columns and sub-dependencies. from sparknlp_jsl.annotator import RelationExtractionModel re_model = RelationExtractionModel().pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;).setOutputCol(&#39;relation&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu_pipe = nlp.autocomplete_pipeline(re_model) nlu_pipe.predict(text) returns : relation relation_confidence relation_entity1 relation_entity2 relation_entity2_class 1 1 allergic reaction vancomycin Drug_Ingredient 1 1 skin itchy Symptom 1 0.99998 skin sore throat/burning/itchy Symptom 1 0.956225 skin numbness Symptom 1 0.999092 skin tongue External_body_part_or_region 0 0.942927 skin gums External_body_part_or_region 1 0.806327 itchy sore throat/burning/itchy Symptom 1 0.526163 itchy numbness Symptom 1 0.999947 itchy tongue External_body_part_or_region 0 0.994618 itchy gums External_body_part_or_region 0 0.994162 sore throat/burning/itchy numbness Symptom 1 0.989304 sore throat/burning/itchy tongue External_body_part_or_region 0 0.999969 sore throat/burning/itchy gums External_body_part_or_region 1 1 numbness tongue External_body_part_or_region 1 1 numbness gums External_body_part_or_region 1 1 tongue gums External_body_part_or_region nlu.to_pretty_df(pipe,data) Annotates a Pandas Dataframe/Pandas Series/Numpy Array/Spark DataFrame/Python List strings /Python String with given Spark NLP pipeline, which is assumed to be complete and runnable and returns it in a pythonic pandas dataframe format. Example: # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; # output is same as nlp.autocomplete_pipeline(re_model).nlp_pipe.predict(text) nlp.to_pretty_df(ade_pipeline,text) returns : assertion asserted_entitiy entitiy_class assertion_confidence present allergic reaction ADE 0.998 present itchy ADE 0.8414 present sore throat/burning/itchy ADE 0.9019 present numbness in tongue and gums ADE 0.9991 Annotators are grouped internally by NLP into output levels token,sentence, document,chunk and relation Same level annotators output columns are zipped and exploded together to create the final output df. Additionally, most keys from the metadata dictionary in the result annotations will be collected and expanded into their own columns in the resulting Dataframe, with special handling for Annotators that encode multiple metadata fields inside of one, seperated by strings like ||| or :::. Some columns are omitted from metadata to reduce total amount of output columns, these can be re-enabled by setting metadata=True For a given pipeline output level is automatically set to the last annotators output level by default. This can be changed by defining to_preddty_df(pipe,text,output_level=&#39;my_level&#39; for levels token,sentence, document,chunk and relation . nlp.to_nlu_pipe(pipe) Convert a pipeline or list of annotators into a NLU pipeline making .predict() and .viz() avaiable for every Spark NLP pipeline. Assumes the pipeline is already runnable. # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu_pipe = nlp.to_nlu_pipe(ade_pipeline) # Same output as nlu.to_pretty_df(pipe,text) nlu_pipe.predict(text) # same output as nlu.viz(pipe,text) nlu_pipe.viz(text) # Acces auto-completed Spark NLP big data pipeline, nlu_pipe.vanilla_transformer_pipe.transform(spark_df) returns : assertion asserted_entitiy entitiy_class assertion_confidence present allergic reaction ADE 0.998 present itchy ADE 0.8414 present sore throat/burning/itchy ADE 0.9019 present numbness in tongue and gums ADE 0.9991 and",
    "url": "/docs/en/jsl/utils_for_spark_nlp",
    "relUrl": "/docs/en/jsl/utils_for_spark_nlp"
  },
  "1582": {
    "id": "1582",
    "title": "Vaccines - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/vaccinations",
    "relUrl": "/vaccinations"
  },
  "1583": {
    "id": "1583",
    "title": "Version Compatibility",
    "content": "Healthcare NLP Spark OCR Spark NLP 3.0.0 3.4.0 3.0.0 3.0.1 3.4.0 3.0.1 3.0.2 3.4.0 3.0.2 3.0.3 3.4.0 3.0.3 3.1.0 3.4.1 3.1.0 3.1.1 3.4.1 3.1.1 3.1.2 3.4.1 3.1.2 3.1.3 3.5.0 3.1.3 3.1.3 3.6.0 3.1.3 3.2.0 3.7.0 3.2.0 3.2.1 3.8.0 3.2.1 3.2.2 3.8.0 3.2.2 3.2.3 3.8.0 3.2.3 3.3.0 3.8.0 3.3.0 3.3.1 3.9.0 3.3.1 3.3.2 3.9.0 3.3.2 3.3.4 3.10.0 3.3.4 3.4.0 3.11.0 3.4.0 3.4.1 3.11.0 3.4.1 3.4.2 3.11.0 3.4.2 3.5.0 3.11.0 3.4.2 3.5.1 3.12.0 3.4.2 3.5.2 3.13.0 3.4.4 3.5.2 3.14.0 3.4.4 4.0.0 4.0.0 4.0.0 4.1.0 4.1.0 4.1.0 4.2.1 4.2.0 4.2.1 4.2.3 4.2.4 4.2.4 4.2.4 4.3.0 4.2.4 4.3.0 4.3.1 4.3.0 4.3.1 4.3.3 4.3.1 4.4.0 4.4.0 4.4.0 4.4.1 4.4.1 4.4.1 4.4.1 4.4.2 4.4.2 4.4.3 4.4.3 4.4.4 4.4.3 4.4.4 4.4.4 5.0.1 5.0.0 5.0.2",
    "url": "/docs/en/version_compatibility",
    "relUrl": "/docs/en/version_compatibility"
  },
  "1584": {
    "id": "1584",
    "title": "Video Tutorials",
    "content": "{%- include extensions/youtube.html id=&#39;isxffn4Tcds&#39; -%}How to Install NLP Server on Azure {%- include extensions/youtube.html id=&#39;YZFhsZZD6QM&#39; -%}How to Import a License in the NLP Server",
    "url": "/docs/en/nlp_server/video_tutorials",
    "relUrl": "/docs/en/nlp_server/video_tutorials"
  },
  "1585": {
    "id": "1585",
    "title": "Visual Document Understanding - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/visual_document_understanding",
    "relUrl": "/visual_document_understanding"
  },
  "1586": {
    "id": "1586",
    "title": "Visual NER",
    "content": "Annotating text included in image documents (e.g. scanned documents) is a common use case in many verticals but comes with several challenges. With the new Visual NER Labeling config, we aim to ease the work of annotators by allowing them to simply select text from an image and assign the corresponding label to it. This feature is powered by Spark OCR 3.5.0; thus a valid Spark OCR license is required to get access to it. Here is how this can be used: Upload a valid Spark OCR license. See how to do this here. Create a new project, specify a name for your project, add team members if necessary, and from the list of predefined templates (Default Project Configs) choose “Visual NER Labeling”. Update the configuration if necessary. This might be useful if you want to use other labels than the currently defined ones. Click the save button. While saving the project, a confirmation dialog is displayed to let you know that the Spark OCR pipeline for Visual NER is being deployed. Import the tasks you want to annotate (images). Start annotating text on top of the image by clicking on the text tokens or by drawing bounding boxes on top of chunks or image areas. Export annotations in your preferred format. The entire process is illustrated below: Support for multi-page PDF documents When a valid Saprk OCR license is available, Annotation Lab offers support for multi-page PDF annotation. The complete flow of import, annotation, and export for multi-page PDF files is currently supported. Users have two options for importing a new PDF file into the Visual NER project Import PDF file from local storage; Add a link to the PDF file in the file attribute. After import, the task becomes available on the Tasks Page. The title of the new task is the name of the imported file. On the labeling page, the PDF file is displayed with pagination so that annotators can annotate on the PDF document one page at a time. OCR and Visual NER servers Just like (preannotation servers)[], Annotation Lab 3.0.0 also supports the deployment of multiple OCR servers. If a user has uploaded a Spark OCR license, be it airgap or floating, OCR inference is enabled. To create a Visual NER project, users have to deploy at least one OCR server. Any OCR server can perform preannotation. To select the OCR server, users have to go to the Import page, toggle the OCR option and from the popup, choose one of the available OCR servers. In no suitable OCR server is available, one can be created by choosing the “Create Server” option. Visual NER Training And Preannotation With release 3.4.0 came support for Visual NER Automated Preannotation and Model Training. Visual NER Training Support Version 3.4.0 of the Annotation Lab offers the ability to train Visual NER models, apply active learning for automatic model training, and preannotate image-based tasks with existing models in order to accelerate annotation work. License Requirements Visual NER annotation, training and preannotation features are dependent on the presence of a Spark OCR license. Floating or airgap licenses with scope ocr: inference and ocr: training are required for preannotation and training respectively. Model Training The training feature for Visual NER projects can be activated from the Setup page via the “Train Now” button (See 1). From the Training Settings sections, users can tune the training parameters (e.g. Epoch, Batch) and choose the tasks to use for training the Visual NER model (See 3). Information on the training progress is shown in the top right corner of the Model Training tab (See 2). Users can check detailed information regarding the success or failure of the last training. Training Failure can occur because of: Insufficient number of completions Poor quality of completions Insufficient CPU and Memory Wrong training parameters When triggering the training, users can choose to immediately deploy the model or just train it without deploying. If immediate deployment is chosen, then the labeling config is updated with references to the new model so that it will be used for preannotations. Training Server Specification The minimal required training configuration is 64 GB RAM, 16 Core CPU for Visual NER Training. Visual NER Preannotation For running preannotation on one or several tasks, the Project Owner or the Manager must select the target tasks and can click on the Preannotate button from the upper right side of the Tasks Page. This will display a popup with information regarding the last deployment including the list of models deployed and the labels they predict. Known Limitations: When bulk preannotation is run on a lot of tasks, the preannotation can fail due to memory issues. Preannotation currently works at token level, and does not merge all tokens of a chunk into one entity. Preannotation Server Specification The minimal required training configuration is 32 GB RAM, 2 Core CPU for Visual NER Model.",
    "url": "/en/alab/visual_ner.html",
    "relUrl": "/en/alab/visual_ner.html"
  },
  "1587": {
    "id": "1587",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/cv/vit_for_image_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/cv/vit_for_image_classification.html"
  },
  "1588": {
    "id": "1588",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/sentiment/vivekn_sentiment.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/sentiment/vivekn_sentiment.html"
  },
  "1589": {
    "id": "1589",
    "title": "The nlp.viz() function",
    "content": "Visualizations using nlp.load().viz() You can use the build in visualization module on any pipeline or model returned by nlp.load(). Simply call viz() and an applicable visualization will be deducted. Alternatively, you can also manually specify, which visualization you want to invoke. These visualizations are provided via Spark-NLP-Display package Named Entity Recognizers Medical Named Entity Recognizers Dependency parser relationships which labels and part of speech tags Entity resolution for sentences and chunks Assertion of entity statuses See the visualization tutorial notebook for more info. NER visualization Applicable to any of the 100+ NER models! See here for an overview nlp.load(&#39;ner&#39;).viz(&quot;Donald Trump from America and Angela Merkel from Germany don&#39;t share many oppinions.&quot;) Dependency tree visualization Visualizes the structure of the labeled dependency tree and part of speech tags nlp.load(&#39;dep.typed&#39;).viz(&quot;Billy went to the mall&quot;) #Bigger Example nlp.load(&#39;dep.typed&#39;).viz(&quot;Donald Trump from America and Angela Merkel from Germany don&#39;t share many oppinions but they both love John Snow Labs software&quot;) Assertion status visualization Visualizes asserted statuses and entities. Applicable to any of the 10 + Assertion models! See here for an overview nlp.load(&#39;med_ner.clinical assert&#39;).viz(&quot;The MRI scan showed no signs of cancer in the left lung&quot;) #bigger example data =&#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.&#39; nlp.load(&#39;med_ner.clinical assert&#39;).viz(data) Relationship between entities visualization Visualizes the extracted entities between relationship. Applicable to any of the 20 + Relation Extractor models See here for an overview nlp.load(&#39;med_ner.jsl.wip.clinical relation.temporal_events&#39;).viz(&#39;The patient developed cancer after a mercury poisoning in 1999 &#39;) # bigger example data = &#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed&#39; pipe = nlp.load(&#39;med_ner.jsl.wip.clinical relation.clinical&#39;).viz(data) Entity Resolution visualization for chunks Visualizes resolutions of entities Applicable to any of the 100+ Resolver models See here for an overview nlp.load(&#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&#39;).viz(&quot;He took Prevacid 30 mg daily&quot;) # bigger example data = &quot;This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret &#39;s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .&quot; nlp.load(&#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&#39;).viz(data) Entity Resolution visualization for sentences Visualizes resolutions of entities in sentences Applicable to any of the 100+ Resolver models See here for an overview nlp.load(&#39;med_ner.jsl.wip.clinical resolve.icd10cm&#39;).viz(&#39;She was diagnosed with a respiratory congestion&#39;) # bigger example data = &#39;The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion&#39; nlp.load(&#39;med_ner.jsl.wip.clinical resolve.icd10cm&#39;).viz(data) Configure visualizations Define custom colors for labels Some entity and relation labels will be highlighted with a pre-defined color, which you can find here. For labels that have no color defined, a random color will be generated. You can define colors for labels manually, by specifying via the viz_colors parameter and defining hex color codes in a dictionary that maps labels to colors . data = &#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&#39; # Define custom colors for labels viz_colors={&#39;STRENGTH&#39;:&#39;#800080&#39;, &#39;DRUG_BRANDNAME&#39;:&#39;#77b5fe&#39;, &#39;GENDER&#39;:&#39;#77ffe&#39;} nlp.load(&#39;med_ner.jsl.wip.clinical&#39;).viz(data,viz_colors =viz_colors) Filter entities that get highlighted By default every entity class will be visualized. The labels_to_viz can be used to define a set of labels to highlight. Applicable for ner, resolution and assert. data = &#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&#39; # Filter wich NER label to viz labels_to_viz=[&#39;SYMPTOM&#39;] nlp.load(&#39;med_ner.jsl.wip.clinical&#39;).viz(data,labels_to_viz=labels_to_viz) Visualizations using Pandas Common Idioms The most common two liner you will use in NLU is loading a classifier like emotion or sentiment and then plotting the occurence of each predicted label . An few examples for this are the following : emotion_df = nlp.load(&#39;sentiment&#39;).predict(df) emotion_df[&#39;sentiment&#39;].value_counts().plot.bar() emotion_df = nlp.load(&#39;emotion&#39;).predict(df) emotion_df[&#39;emotion&#39;].value_counts().plot.bar() Another simple idiom is to group by an arbitrary feature from the original dataset and then plot the counts four each group. emotion_df = nlp.load(&#39;sentiment&#39;).predict(df) sentiment_df.groupby(&#39;source&#39;)[&#39;sentiment&#39;].value_counts().plot.bar(figsize=(20,8)) emotion_df = nlp.load(&#39;emotion&#39;).predict(df) emotion_df.groupby(&#39;airline&#39;)[&#39;emotion&#39;].value_counts().plot.bar(figsize=(20,8)) You can visualize a Keyword distribution generated by YAKE like this keyword_predictions.explode(&#39;keywords&#39;).keywords.value_counts()[0:100].plot.bar(title=&#39;Top 100 Keywords in Stack Overflow Questions&#39;, figsize=(20,8))",
    "url": "/docs/en/jsl/viz_examples",
    "relUrl": "/docs/en/jsl/viz_examples"
  },
  "1590": {
    "id": "1590",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/audio/wav2vec2_for_ctc.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/audio/wav2vec2_for_ctc.html"
  },
  "1591": {
    "id": "1591",
    "title": "",
    "content": "",
    "url": "/api/python/static/webpack-macros.html",
    "relUrl": "/api/python/static/webpack-macros.html"
  },
  "1592": {
    "id": "1592",
    "title": "Wiki",
    "content": "This page is created for sharing some tips and tricks for the Spark NLP library. You can find valuable information under the related highlights. Miscellaneous Loading the Same Model Into the Same Annotator More Than One Time There is 1 instance of a model when we use .pretrained or .load. So when we try to use the same model with the same annotator more than one time with different parameters, it fails. We cannot have more than 1 model per annotator in the memory. You can load 10 different NerModel, but not the same model twice with different parameters, it will just load once and reuse it the other times. It’s not possible to duplicate the annotator/model unless the model is different. (each model creates a unique id). You can only load 1 model per annotator, once that happens that model with all its parameters stays in the memory. So if you want to load the very same model on the very same annotator in another pipeline, whether you use .transform, or LightPipeline, it will take the already loaded model from the memory. So if the first one has different inputCol/outputCol then the second pipeline just can’t find the input/output or if the parameters are different in the second pipeline you may not see the desired outcome. So the lesson here is, if you want to use the same model in different places, you must make sure they all have the same parameters. This behavior is the same for LP and .transform. LightPipeline LightPipeline does not check the storageRef of resolver models. This feature will make LP so complicated and also slower. So, the resolver models can work with an embeddings model that is not trained with in LightPipeline, but they return irrelevant results. ChunkMergeApproach Chunk Prioritization in ChunkMergeApproach ChunkMergeApproach() has some prioritizing rules while merging chunks that come from entity extractors (NER models, ContextualParser, TextMatcher, RegexMatcher, etc.): In case of the extracted chunks are same in the all given entity extractors, ChunkMergeApproach prioritizes the leftmost chunk output. Example: When we use ner_posology and ner_clinical models together, and if there is insulin in the clinical text, merger will behave like this: chunk_merger = ChunkMergeApproach() .setInputCols([&quot;ner_posology_chunk&quot;, &quot;ner_clinical_chunk&quot;]) .setOutputCol(&quot;merger_output&quot;) ... &gt;&gt; ner_posology_chunk: insulin -&gt; DRUG &gt;&gt; ner_clinical_chunk: insulin -&gt; TREATMENT &gt;&gt; merger_output: insulin -&gt; DRUG In the event of chunk names being different but some of them are overlapped, ChunkMergeApproach prioritizes the longest chunk even though it is not in the leftmost. Example: If we use ner_posology and ner_posology_greedy models together in the same pipeline and merge their results on a clinical text that has “… bactrim for 14 days …”, merger result will be as shown below: chunk_merger = ChunkMergeApproach() .setInputCols([&quot;ner_posology_chunk&quot;, &quot;ner_posology_greedy_chunk&quot;]) .setOutputCol(&quot;merger_output&quot;) ... &gt;&gt; ner_posology_chunk: bactrim -&gt; DRUG &gt;&gt; ner_posology_greedy_chunk: bactrim for 14 days -&gt; DRUG &gt;&gt; merger_output: bactrim for 14 days -&gt; DRUG Confidence scores don’t have any effect on prioritization. Sentence Entity Resolver Confidence vs Cosine Distance Calculation of Resolvers Let’s assume we have the 10 closest candidates (close meaning lower cosine distance) in our results. The confidence score is calculated with Softmax (vector to vector function). The vector is the full input and the output is also a full vector, it is not a function that is calculated item by item. Each item in the output depends on all the distances. So, what you are expecting is not “expected”. If you get two distances 0.1 and 0.1, Softmax would return 0.5 and 0.5 for each. But if you have 0.1 and 10 distances, Softmax would be 1 and 0. You can have a low distance (chunks are very similar semantically) but low confidence if there are many other chunks also very similar. And sometimes you can have high confidence but high distance, meaning there is only one chunk “close” to your target but not so close. In general, we can see less distance and less confidence but not perfect linear relationships. We can say that using the distance is a better parameter to judge the “goodness” of the resolution than the confidence. So, We recommend that you consider the cosine distance.",
    "url": "/docs/en/wiki",
    "relUrl": "/docs/en/wiki"
  },
  "1593": {
    "id": "1593",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/word2vec.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/word2vec.html"
  },
  "1594": {
    "id": "1594",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/word_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/word_embeddings.html"
  },
  "1595": {
    "id": "1595",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ws/word_segmenter.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ws/word_segmenter.html"
  },
  "1596": {
    "id": "1596",
    "title": "Workflows",
    "content": "When a team of people collaborate on a large annotation project, the work can be organized into multi-step workflows for an easier management of each team member’s responsabilities. This is also necessary when the project has strict requirements such as the same document must be labeled by multiple annotators; the annotations must be checked by a senior annotator. The default workflow supported by the Annotation Lab involves task assignment to one or multiple Annotators and to maximum one Reviewer. In the majority of projects having one annotator working on a task and then one reviewer checking the work done by the annotator is sufficient. NOTE: In NER projects, we recommend that in the early stages of a project, a batch of 50 - 100 content rich tasks should be assigned to all annotators for checking the Inter Annotator Agreement (IAA). This is a best practice to follow in order to quickly identify the difference in annotations as a complementary way to ensure high agreement and completeness across team. NOTE: When multiple annotators are assigned to a task, multiple ground truth completions will be created for that task. The way Annotation Lab prioritises the ground truth completion used for model training and CONLL export is via the priority assigned for each user in the Team (see Project Configuration). When more complex workflows need to be implemented, this is possible using the task tagging functionality provided by the Annotation Lab. Tags can be used for splitting work across the team but also for differentiating between first-level annotators and second-level reviewers. To add a tag, select a task and press Tags &gt; Add More. Tasks can be filtered by tags, making it easier to identify, for example, which documents are completed and which ones need to be reviewed.",
    "url": "/docs/en/alab/workflow",
    "relUrl": "/docs/en/alab/workflow"
  },
  "1597": {
    "id": "1597",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/xlm_roberta_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/xlm_roberta_embeddings.html"
  },
  "1598": {
    "id": "1598",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering.html"
  },
  "1599": {
    "id": "1599",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification.html"
  },
  "1600": {
    "id": "1600",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification.html"
  },
  "1601": {
    "id": "1601",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings.html"
  },
  "1602": {
    "id": "1602",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/xlnet_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/xlnet_embeddings.html"
  },
  "1603": {
    "id": "1603",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification.html"
  },
  "1604": {
    "id": "1604",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlnet_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlnet_for_token_classification.html"
  },
  "1605": {
    "id": "1605",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/keyword_extraction/yake_keyword_extraction.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/keyword_extraction/yake_keyword_extraction.html"
  },
  "1606": {
    "id": "1606",
    "title": "Zero-shot Prompts",
    "content": "NLP Lab offers support for prompt engineering. On the Prompts page, from the resources HUB, users can easily discover and explore the existing prompts or create new prompts for identifying entities or relations. Currently, NLP Lab supports prompts for Healthcare, Finance, and Legal domains applied using pre-trained question-answering language models published on the NLP Models Hub and available to download in one click. The main advantage behind the use of prompts in entity or relation recognition is the ease of definition. Non-technical domain experts can easily create prompts, test and edit them on the Playground on custom text snippets and, when ready, deploy them for pre-annotation as part of larger NLP projects. Together with rules, prompts are very handy in situations where no pre-trained models exist, for the target entities and domains. With rules and prompts the annotators never start their projects from scratch but can capitalize on the power of zero-shot models and rules to help them pre-annotate the simple entities and relations and speed up the annotation process. As such, the NLP Lab ensures fewer manual annotations are required from any given task. Creating NER Prompts NER prompts, can be used to identify entities in natural language text documents. Those can be created based on healthcare, finance, and legal zero-shot models selectable from the “Domain” dropdown. For one prompt, the user adds one or more questions for which the answer represents the target entity to annotate. Creating Relation Prompts Prompts can also be used to identify relations between entities for healthcare, finance, and legal domains. The domain-specific zero-shot model to use for detecting relation can be selected from the “Domain” dropdown. The relation prompts are defined by a pair of entities related by a predicate. The entities can be selected from the available dropdowns listing all entities available in the current NLP Lab (included in available NER models, prompts or rules) for the specified domain. Mix and Match models, rules, and prompts The project configuration page was simplified by grouping into one page all available resources that can be reused for pre-annotation: models, rules, and prompts. Users can easily mix and match the relevant resources and add them to their configuration. Note: One project configuration can only reuse the prompts defined by one single zero-shot model. Prompts created based on multiple zero-shot models (e.g. finance or legal or healthcare) cannot be mixed into the same project because of high resource consumption. Furthermore, all prompts require a license with a scope that matches the domain of the prompt. Zero-Shot Models available in the NLP Models Hub NLP Models Hub now lists the newly released zero-shot models that are used to define prompts. These models need to be downloaded to NLP Lab instance before prompts can be created. A valid license must be available for the models to be downloaded to NLP Lab.",
    "url": "/docs/en/alab/zero_prompts",
    "relUrl": "/docs/en/alab/zero_prompts"
  },
  "1607": {
    "id": "1607",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/zero_shot_ner_model.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/zero_shot_ner_model.html"
  }
  
}
